(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_roberta-base_adapter__seed0/runs/Nov15_19-19-35_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_roberta-base_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_roberta-base_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:19:35 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:19:35 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_roberta-base_adapter__seed0/runs/Nov15_19-19-33_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_roberta-base_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_roberta-base_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  88%|████████▊ | 4142/4722 [00:00<00:00, 41159.30 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 40400.84 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 19:19:52,440 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:19:52,453 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 19:20:02,471 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 19:20:12,491 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:20:12,492 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:20:32,556 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:20:32,556 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:20:32,557 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:20:32,557 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:20:32,557 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:20:32,558 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 19:20:32,559 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:20:32,560 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:20:52,759 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 19:20:55,161 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:20:55,162 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 23473.67 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 22892.30 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 28367.48 examples/s]
11/15/2023 19:20:55 - INFO - __main__ - Sample 3388 of the training set: {'text': 'food <SEP> Had dinner here on a Friday and the food was great.', 'label': 0, 'input_ids': [0, 13193, 28696, 3388, 510, 15698, 7301, 3630, 259, 15, 10, 273, 8, 5, 689, 21, 372, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:20:55 - INFO - __main__ - Sample 871 of the training set: {'text': 'drinks <SEP> You get what you pay for and with that logic in mind, Spice is a great place to grab some cheap eats and drinks in a beautiful setting.', 'label': 0, 'input_ids': [0, 10232, 12935, 28696, 3388, 510, 15698, 370, 120, 99, 47, 582, 13, 8, 19, 14, 14578, 11, 1508, 6, 21665, 16, 10, 372, 317, 7, 6895, 103, 6162, 24923, 8, 6696, 11, 10, 2721, 2749, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:20:55 - INFO - __main__ - Sample 3773 of the training set: {'text': 'food <SEP> Good service, great food, good value, and never have to wait in line!', 'label': 0, 'input_ids': [0, 13193, 28696, 3388, 510, 15698, 2497, 544, 6, 372, 689, 6, 205, 923, 6, 8, 393, 33, 7, 2067, 11, 516, 328, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:20:55 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:20:57,098 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:20:57,106 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:20:57,106 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 19:20:57,107 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:20:57,107 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:20:57,107 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:20:57,108 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:20:57,108 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 19:20:57,109 >>   Number of trainable parameters = 124,647,939
[INFO|integration_utils.py:716] 2023-11-15 19:20:57,110 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:02<25:11,  2.54s/it]  0%|          | 2/595 [00:02<11:02,  1.12s/it]  1%|          | 3/595 [00:02<06:29,  1.52it/s]  1%|          | 4/595 [00:02<04:20,  2.27it/s]  1%|          | 5/595 [00:02<03:09,  3.11it/s]  1%|          | 6/595 [00:03<02:26,  4.03it/s]  1%|          | 7/595 [00:03<01:59,  4.91it/s]  1%|▏         | 8/595 [00:03<01:42,  5.73it/s]  2%|▏         | 9/595 [00:03<01:30,  6.49it/s]  2%|▏         | 10/595 [00:03<01:22,  7.11it/s]  2%|▏         | 11/595 [00:03<01:15,  7.68it/s]  2%|▏         | 12/595 [00:03<01:12,  8.04it/s]  2%|▏         | 13/595 [00:03<01:09,  8.42it/s]  2%|▏         | 14/595 [00:03<01:07,  8.55it/s]  3%|▎         | 15/595 [00:04<01:06,  8.70it/s]  3%|▎         | 16/595 [00:04<01:05,  8.83it/s]  3%|▎         | 17/595 [00:04<01:05,  8.89it/s]  3%|▎         | 18/595 [00:04<01:04,  8.92it/s]  3%|▎         | 19/595 [00:04<01:04,  8.92it/s]  3%|▎         | 20/595 [00:04<01:04,  8.98it/s]  4%|▎         | 21/595 [00:04<01:03,  8.99it/s]  4%|▎         | 22/595 [00:04<01:03,  9.07it/s]  4%|▍         | 23/595 [00:04<01:02,  9.14it/s]  4%|▍         | 24/595 [00:05<01:02,  9.16it/s]  4%|▍         | 25/595 [00:05<01:02,  9.05it/s]  4%|▍         | 26/595 [00:05<01:02,  9.04it/s]  5%|▍         | 27/595 [00:05<01:02,  9.05it/s]  5%|▍         | 28/595 [00:05<01:02,  9.04it/s]  5%|▍         | 29/595 [00:05<01:02,  9.02it/s]  5%|▌         | 30/595 [00:05<01:01,  9.13it/s]  5%|▌         | 31/595 [00:05<01:02,  9.08it/s]  5%|▌         | 32/595 [00:05<01:01,  9.13it/s]  6%|▌         | 33/595 [00:06<01:02,  9.04it/s]  6%|▌         | 34/595 [00:06<01:02,  9.05it/s]  6%|▌         | 35/595 [00:06<01:02,  9.03it/s]  6%|▌         | 36/595 [00:06<01:02,  8.99it/s]  6%|▌         | 37/595 [00:06<01:01,  9.05it/s]  6%|▋         | 38/595 [00:06<01:01,  9.11it/s]  7%|▋         | 39/595 [00:06<01:00,  9.17it/s]  7%|▋         | 40/595 [00:06<01:00,  9.24it/s]  7%|▋         | 41/595 [00:06<01:00,  9.13it/s]  7%|▋         | 42/595 [00:07<01:01,  9.06it/s]  7%|▋         | 43/595 [00:07<01:00,  9.05it/s]  7%|▋         | 44/595 [00:07<01:00,  9.05it/s]  8%|▊         | 45/595 [00:07<01:00,  9.07it/s]  8%|▊         | 46/595 [00:07<01:00,  9.13it/s]  8%|▊         | 47/595 [00:07<00:59,  9.23it/s]  8%|▊         | 48/595 [00:07<00:59,  9.13it/s]  8%|▊         | 49/595 [00:07<00:59,  9.10it/s]  8%|▊         | 50/595 [00:07<01:00,  9.08it/s]  9%|▊         | 51/595 [00:08<00:59,  9.08it/s]  9%|▊         | 52/595 [00:08<00:59,  9.06it/s]  9%|▉         | 53/595 [00:08<01:00,  8.99it/s]  9%|▉         | 54/595 [00:08<00:59,  9.13it/s]  9%|▉         | 55/595 [00:08<00:58,  9.15it/s]  9%|▉         | 56/595 [00:08<00:58,  9.14it/s] 10%|▉         | 57/595 [00:08<00:59,  9.05it/s] 10%|▉         | 58/595 [00:08<00:59,  9.08it/s] 10%|▉         | 59/595 [00:08<00:59,  9.05it/s] 10%|█         | 60/595 [00:09<00:59,  8.95it/s] 10%|█         | 61/595 [00:09<00:58,  9.05it/s] 10%|█         | 62/595 [00:09<00:59,  9.02it/s] 11%|█         | 63/595 [00:09<00:58,  9.05it/s] 11%|█         | 64/595 [00:09<00:58,  9.09it/s] 11%|█         | 65/595 [00:09<00:58,  9.13it/s] 11%|█         | 66/595 [00:09<00:58,  9.03it/s] 11%|█▏        | 67/595 [00:09<00:58,  8.99it/s] 11%|█▏        | 68/595 [00:09<00:58,  9.06it/s] 12%|█▏        | 69/595 [00:10<00:58,  9.01it/s] 12%|█▏        | 70/595 [00:10<00:58,  9.04it/s] 12%|█▏        | 71/595 [00:10<00:57,  9.10it/s] 12%|█▏        | 72/595 [00:10<00:57,  9.09it/s] 12%|█▏        | 73/595 [00:10<00:58,  8.97it/s] 12%|█▏        | 74/595 [00:10<00:57,  9.04it/s] 13%|█▎        | 75/595 [00:10<00:57,  9.03it/s] 13%|█▎        | 76/595 [00:10<00:57,  9.06it/s] 13%|█▎        | 77/595 [00:10<00:57,  9.01it/s] 13%|█▎        | 78/595 [00:11<00:56,  9.17it/s] 13%|█▎        | 79/595 [00:11<00:57,  9.04it/s] 13%|█▎        | 80/595 [00:11<00:56,  9.04it/s] 14%|█▎        | 81/595 [00:11<00:56,  9.08it/s] 14%|█▍        | 82/595 [00:11<00:56,  9.04it/s] 14%|█▍        | 83/595 [00:11<00:56,  9.05it/s] 14%|█▍        | 84/595 [00:11<00:56,  8.98it/s] 14%|█▍        | 85/595 [00:11<00:55,  9.18it/s] 14%|█▍        | 86/595 [00:11<00:56,  9.01it/s] 15%|█▍        | 87/595 [00:12<00:56,  9.03it/s] 15%|█▍        | 88/595 [00:12<00:56,  8.97it/s] 15%|█▍        | 89/595 [00:12<00:56,  8.95it/s] 15%|█▌        | 90/595 [00:12<00:56,  8.99it/s] 15%|█▌        | 91/595 [00:12<00:56,  8.91it/s] 15%|█▌        | 92/595 [00:12<00:54,  9.20it/s] 16%|█▌        | 93/595 [00:12<00:55,  9.05it/s] 16%|█▌        | 94/595 [00:12<00:56,  8.94it/s] 16%|█▌        | 95/595 [00:12<00:55,  8.98it/s] 16%|█▌        | 96/595 [00:13<00:55,  8.94it/s] 16%|█▋        | 97/595 [00:13<00:55,  9.00it/s] 16%|█▋        | 98/595 [00:13<00:54,  9.06it/s] 17%|█▋        | 99/595 [00:13<00:54,  9.06it/s] 17%|█▋        | 100/595 [00:13<00:54,  9.00it/s] 17%|█▋        | 101/595 [00:13<00:55,  8.94it/s] 17%|█▋        | 102/595 [00:13<00:55,  8.92it/s] 17%|█▋        | 103/595 [00:13<00:55,  8.90it/s] 17%|█▋        | 104/595 [00:13<00:54,  8.98it/s] 18%|█▊        | 105/595 [00:14<00:54,  8.94it/s] 18%|█▊        | 106/595 [00:14<00:54,  9.04it/s] 18%|█▊        | 107/595 [00:14<00:53,  9.04it/s] 18%|█▊        | 108/595 [00:14<00:54,  8.91it/s] 18%|█▊        | 109/595 [00:14<00:54,  8.93it/s] 18%|█▊        | 110/595 [00:14<00:53,  9.01it/s] 19%|█▊        | 111/595 [00:14<00:53,  9.08it/s] 19%|█▉        | 112/595 [00:14<00:53,  9.08it/s] 19%|█▉        | 113/595 [00:14<00:53,  9.09it/s] 19%|█▉        | 114/595 [00:15<00:52,  9.11it/s] 19%|█▉        | 115/595 [00:15<00:53,  8.96it/s] 19%|█▉        | 116/595 [00:15<00:53,  8.94it/s] 20%|█▉        | 117/595 [00:15<00:53,  8.99it/s] 20%|█▉        | 118/595 [00:15<00:53,  8.97it/s]                                                  20%|██        | 119/595 [00:15<00:53,  8.97it/s][INFO|trainer.py:755] 2023-11-15 19:21:12,651 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:21:12,653 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:21:12,653 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:21:12,654 >>   Batch size = 8
{'loss': 0.702, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 77.79it/s][A
 14%|█▍        | 17/119 [00:00<00:01, 75.72it/s][A
 21%|██        | 25/119 [00:00<00:01, 72.93it/s][A
 28%|██▊       | 33/119 [00:00<00:01, 69.69it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 72.32it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 71.62it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 70.80it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 72.15it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 70.40it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 69.69it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 71.32it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 71.40it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 71.19it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 71.73it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:17<00:53,  8.97it/s]
100%|██████████| 119/119 [00:01<00:00, 71.73it/s][A
                                                 [A 20%|██        | 120/595 [00:17<03:55,  2.02it/s] 20%|██        | 121/595 [00:17<03:10,  2.49it/s] 21%|██        | 122/595 [00:17<02:34,  3.06it/s] 21%|██        | 123/595 [00:17<02:06,  3.72it/s] 21%|██        | 124/595 [00:17<01:45,  4.46it/s] 21%|██        | 125/595 [00:17<01:30,  5.19it/s] 21%|██        | 126/595 [00:18<01:18,  5.95it/s] 21%|██▏       | 127/595 [00:18<01:11,  6.58it/s] 22%|██▏       | 128/595 [00:18<01:05,  7.10it/s] 22%|██▏       | 129/595 [00:18<01:01,  7.58it/s] 22%|██▏       | 130/595 [00:18<00:58,  7.92it/s] 22%|██▏       | 131/595 [00:18<00:56,  8.20it/s] 22%|██▏       | 132/595 [00:18<00:55,  8.30it/s] 22%|██▏       | 133/595 [00:18<00:54,  8.46it/s] 23%|██▎       | 134/595 [00:18<00:53,  8.59it/s] 23%|██▎       | 135/595 [00:19<00:52,  8.72it/s] 23%|██▎       | 136/595 [00:19<00:51,  8.86it/s] 23%|██▎       | 137/595 [00:19<00:51,  8.81it/s] 23%|██▎       | 138/595 [00:19<00:51,  8.86it/s] 23%|██▎       | 139/595 [00:19<00:51,  8.84it/s] 24%|██▎       | 140/595 [00:19<00:51,  8.86it/s] 24%|██▎       | 141/595 [00:19<00:50,  8.93it/s] 24%|██▍       | 142/595 [00:19<00:51,  8.82it/s] 24%|██▍       | 143/595 [00:19<00:50,  8.91it/s] 24%|██▍       | 144/595 [00:20<00:50,  8.90it/s] 24%|██▍       | 145/595 [00:20<00:50,  8.92it/s] 25%|██▍       | 146/595 [00:20<00:50,  8.94it/s] 25%|██▍       | 147/595 [00:20<00:49,  8.97it/s] 25%|██▍       | 148/595 [00:20<00:50,  8.86it/s] 25%|██▌       | 149/595 [00:20<00:50,  8.84it/s] 25%|██▌       | 150/595 [00:20<00:50,  8.86it/s] 25%|██▌       | 151/595 [00:20<00:50,  8.84it/s] 26%|██▌       | 152/595 [00:20<00:49,  8.89it/s] 26%|██▌       | 153/595 [00:21<00:49,  8.97it/s] 26%|██▌       | 154/595 [00:21<00:49,  8.85it/s] 26%|██▌       | 155/595 [00:21<00:49,  8.91it/s] 26%|██▌       | 156/595 [00:21<00:49,  8.87it/s] 26%|██▋       | 157/595 [00:21<00:49,  8.92it/s] 27%|██▋       | 158/595 [00:21<00:49,  8.90it/s] 27%|██▋       | 159/595 [00:21<00:49,  8.87it/s] 27%|██▋       | 160/595 [00:21<00:48,  8.91it/s] 27%|██▋       | 161/595 [00:21<00:48,  8.93it/s] 27%|██▋       | 162/595 [00:22<00:48,  8.93it/s] 27%|██▋       | 163/595 [00:22<00:47,  9.13it/s] 28%|██▊       | 164/595 [00:22<00:48,  8.97it/s] 28%|██▊       | 165/595 [00:22<00:48,  8.93it/s] 28%|██▊       | 166/595 [00:22<00:48,  8.93it/s] 28%|██▊       | 167/595 [00:22<00:47,  8.95it/s] 28%|██▊       | 168/595 [00:22<00:47,  8.96it/s] 28%|██▊       | 169/595 [00:22<00:48,  8.86it/s] 29%|██▊       | 170/595 [00:22<00:47,  8.95it/s] 29%|██▊       | 171/595 [00:23<00:47,  8.90it/s] 29%|██▉       | 172/595 [00:23<00:47,  8.91it/s] 29%|██▉       | 173/595 [00:23<00:46,  9.04it/s] 29%|██▉       | 174/595 [00:23<00:46,  8.99it/s] 29%|██▉       | 175/595 [00:23<00:46,  8.98it/s] 30%|██▉       | 176/595 [00:23<00:47,  8.89it/s] 30%|██▉       | 177/595 [00:23<00:46,  8.93it/s] 30%|██▉       | 178/595 [00:23<00:46,  9.02it/s] 30%|███       | 179/595 [00:23<00:46,  8.94it/s] 30%|███       | 180/595 [00:24<00:45,  9.06it/s] 30%|███       | 181/595 [00:24<00:45,  9.01it/s] 31%|███       | 182/595 [00:24<00:45,  9.04it/s] 31%|███       | 183/595 [00:24<00:45,  8.98it/s] 31%|███       | 184/595 [00:24<00:45,  8.99it/s] 31%|███       | 185/595 [00:24<00:46,  8.88it/s] 31%|███▏      | 186/595 [00:24<00:45,  8.92it/s] 31%|███▏      | 187/595 [00:24<00:45,  8.91it/s] 32%|███▏      | 188/595 [00:24<00:45,  8.96it/s] 32%|███▏      | 189/595 [00:25<00:44,  9.03it/s] 32%|███▏      | 190/595 [00:25<00:44,  9.14it/s] 32%|███▏      | 191/595 [00:25<00:44,  8.99it/s] 32%|███▏      | 192/595 [00:25<00:44,  9.01it/s] 32%|███▏      | 193/595 [00:25<00:44,  9.03it/s] 33%|███▎      | 194/595 [00:25<00:44,  8.96it/s] 33%|███▎      | 195/595 [00:25<00:44,  9.01it/s] 33%|███▎      | 196/595 [00:25<00:44,  8.92it/s] 33%|███▎      | 197/595 [00:25<00:43,  9.09it/s] 33%|███▎      | 198/595 [00:26<00:43,  9.04it/s] 33%|███▎      | 199/595 [00:26<00:43,  9.02it/s] 34%|███▎      | 200/595 [00:26<00:43,  9.00it/s] 34%|███▍      | 201/595 [00:26<00:43,  9.05it/s] 34%|███▍      | 202/595 [00:26<00:43,  8.95it/s] 34%|███▍      | 203/595 [00:26<00:44,  8.86it/s] 34%|███▍      | 204/595 [00:26<00:44,  8.86it/s] 34%|███▍      | 205/595 [00:26<00:43,  8.88it/s] 35%|███▍      | 206/595 [00:26<00:43,  8.94it/s] 35%|███▍      | 207/595 [00:27<00:42,  9.07it/s] 35%|███▍      | 208/595 [00:27<00:43,  8.94it/s] 35%|███▌      | 209/595 [00:27<00:43,  8.94it/s] 35%|███▌      | 210/595 [00:27<00:43,  8.89it/s] 35%|███▌      | 211/595 [00:27<00:43,  8.92it/s] 36%|███▌      | 212/595 [00:27<00:42,  9.00it/s] 36%|███▌      | 213/595 [00:27<00:42,  8.94it/s] 36%|███▌      | 214/595 [00:27<00:41,  9.12it/s] 36%|███▌      | 215/595 [00:27<00:42,  9.02it/s] 36%|███▋      | 216/595 [00:28<00:41,  9.04it/s] 36%|███▋      | 217/595 [00:28<00:41,  9.01it/s] 37%|███▋      | 218/595 [00:28<00:41,  9.00it/s] 37%|███▋      | 219/595 [00:28<00:41,  9.01it/s] 37%|███▋      | 220/595 [00:28<00:42,  8.93it/s] 37%|███▋      | 221/595 [00:28<00:41,  8.99it/s] 37%|███▋      | 222/595 [00:28<00:41,  8.97it/s] 37%|███▋      | 223/595 [00:28<00:41,  8.99it/s] 38%|███▊      | 224/595 [00:28<00:40,  9.06it/s] 38%|███▊      | 225/595 [00:29<00:40,  9.03it/s] 38%|███▊      | 226/595 [00:29<00:41,  8.91it/s] 38%|███▊      | 227/595 [00:29<00:41,  8.88it/s] 38%|███▊      | 228/595 [00:29<00:41,  8.88it/s] 38%|███▊      | 229/595 [00:29<00:40,  8.94it/s] 39%|███▊      | 230/595 [00:29<00:41,  8.89it/s] 39%|███▉      | 231/595 [00:29<00:40,  9.01it/s] 39%|███▉      | 232/595 [00:29<00:40,  8.98it/s] 39%|███▉      | 233/595 [00:29<00:40,  8.98it/s] 39%|███▉      | 234/595 [00:30<00:40,  8.96it/s] 39%|███▉      | 235/595 [00:30<00:40,  8.99it/s] 40%|███▉      | 236/595 [00:30<00:40,  8.97it/s] 40%|███▉      | 237/595 [00:30<00:40,  8.92it/s]                                                  40%|████      | 238/595 [00:30<00:40,  8.92it/s][INFO|trainer.py:755] 2023-11-15 19:21:27,607 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:21:27,609 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:21:27,610 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:21:27,610 >>   Batch size = 8
{'eval_loss': 0.5252121686935425, 'eval_accuracy': 0.7947089947089947, 'eval_micro_f1': 0.7947089947089947, 'eval_macro_f1': 0.6808510973969657, 'eval_runtime': 1.7116, 'eval_samples_per_second': 552.102, 'eval_steps_per_second': 69.524, 'epoch': 1.0}
{'loss': 0.4682, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 78.42it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 70.34it/s][A
 20%|██        | 24/119 [00:00<00:01, 71.04it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 71.32it/s][A
 34%|███▎      | 40/119 [00:00<00:01, 72.20it/s][A
 40%|████      | 48/119 [00:00<00:01, 70.82it/s][A
 48%|████▊     | 57/119 [00:00<00:00, 72.03it/s][A
 55%|█████▍    | 65/119 [00:00<00:00, 71.82it/s][A
 61%|██████▏   | 73/119 [00:01<00:00, 71.50it/s][A
 68%|██████▊   | 81/119 [00:01<00:00, 72.19it/s][A
 75%|███████▍  | 89/119 [00:01<00:00, 72.33it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 69.63it/s][A
 87%|████████▋ | 104/119 [00:01<00:00, 69.62it/s][A
 94%|█████████▍| 112/119 [00:01<00:00, 70.61it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:32<00:40,  8.92it/s]
100%|██████████| 119/119 [00:01<00:00, 70.61it/s][A
                                                 [A 40%|████      | 239/595 [00:32<02:55,  2.03it/s] 40%|████      | 240/595 [00:32<02:20,  2.52it/s] 41%|████      | 241/595 [00:32<01:54,  3.09it/s] 41%|████      | 242/595 [00:32<01:33,  3.76it/s] 41%|████      | 243/595 [00:32<01:18,  4.47it/s] 41%|████      | 244/595 [00:32<01:07,  5.23it/s] 41%|████      | 245/595 [00:32<00:58,  5.94it/s] 41%|████▏     | 246/595 [00:33<00:53,  6.51it/s] 42%|████▏     | 247/595 [00:33<00:49,  7.10it/s] 42%|████▏     | 248/595 [00:33<00:45,  7.57it/s] 42%|████▏     | 249/595 [00:33<00:43,  7.90it/s] 42%|████▏     | 250/595 [00:33<00:41,  8.24it/s] 42%|████▏     | 251/595 [00:33<00:40,  8.43it/s] 42%|████▏     | 252/595 [00:33<00:40,  8.50it/s] 43%|████▎     | 253/595 [00:33<00:39,  8.59it/s] 43%|████▎     | 254/595 [00:34<00:39,  8.64it/s] 43%|████▎     | 255/595 [00:34<00:38,  8.77it/s] 43%|████▎     | 256/595 [00:34<00:38,  8.79it/s] 43%|████▎     | 257/595 [00:34<00:37,  9.00it/s] 43%|████▎     | 258/595 [00:34<00:37,  8.92it/s] 44%|████▎     | 259/595 [00:34<00:37,  8.91it/s] 44%|████▎     | 260/595 [00:34<00:37,  8.88it/s] 44%|████▍     | 261/595 [00:34<00:37,  8.91it/s] 44%|████▍     | 262/595 [00:34<00:37,  8.88it/s] 44%|████▍     | 263/595 [00:35<00:37,  8.82it/s] 44%|████▍     | 264/595 [00:35<00:37,  8.89it/s] 45%|████▍     | 265/595 [00:35<00:37,  8.90it/s] 45%|████▍     | 266/595 [00:35<00:36,  8.92it/s] 45%|████▍     | 267/595 [00:35<00:36,  9.01it/s] 45%|████▌     | 268/595 [00:35<00:36,  8.89it/s] 45%|████▌     | 269/595 [00:35<00:36,  8.89it/s] 45%|████▌     | 270/595 [00:35<00:36,  8.88it/s] 46%|████▌     | 271/595 [00:35<00:36,  8.87it/s] 46%|████▌     | 272/595 [00:36<00:36,  8.93it/s] 46%|████▌     | 273/595 [00:36<00:36,  8.83it/s] 46%|████▌     | 274/595 [00:36<00:35,  8.94it/s] 46%|████▌     | 275/595 [00:36<00:35,  8.90it/s] 46%|████▋     | 276/595 [00:36<00:35,  8.95it/s] 47%|████▋     | 277/595 [00:36<00:35,  8.97it/s] 47%|████▋     | 278/595 [00:36<00:35,  8.98it/s] 47%|████▋     | 279/595 [00:36<00:35,  8.88it/s] 47%|████▋     | 280/595 [00:36<00:35,  8.83it/s] 47%|████▋     | 281/595 [00:37<00:35,  8.83it/s] 47%|████▋     | 282/595 [00:37<00:35,  8.90it/s] 48%|████▊     | 283/595 [00:37<00:35,  8.82it/s] 48%|████▊     | 284/595 [00:37<00:34,  9.03it/s] 48%|████▊     | 285/595 [00:37<00:34,  8.93it/s] 48%|████▊     | 286/595 [00:37<00:34,  8.96it/s] 48%|████▊     | 287/595 [00:37<00:34,  9.00it/s] 48%|████▊     | 288/595 [00:37<00:34,  9.03it/s] 49%|████▊     | 289/595 [00:37<00:34,  8.97it/s] 49%|████▊     | 290/595 [00:38<00:34,  8.92it/s] 49%|████▉     | 291/595 [00:38<00:33,  8.99it/s] 49%|████▉     | 292/595 [00:38<00:33,  9.00it/s] 49%|████▉     | 293/595 [00:38<00:33,  9.03it/s] 49%|████▉     | 294/595 [00:38<00:32,  9.13it/s] 50%|████▉     | 295/595 [00:38<00:33,  9.01it/s] 50%|████▉     | 296/595 [00:38<00:33,  9.02it/s] 50%|████▉     | 297/595 [00:38<00:33,  8.98it/s] 50%|█████     | 298/595 [00:38<00:33,  8.99it/s] 50%|█████     | 299/595 [00:39<00:33,  8.97it/s] 50%|█████     | 300/595 [00:39<00:32,  8.95it/s] 51%|█████     | 301/595 [00:39<00:32,  8.94it/s] 51%|█████     | 302/595 [00:39<00:32,  8.98it/s] 51%|█████     | 303/595 [00:39<00:32,  8.97it/s] 51%|█████     | 304/595 [00:39<00:32,  9.04it/s] 51%|█████▏    | 305/595 [00:39<00:32,  9.04it/s] 51%|█████▏    | 306/595 [00:39<00:32,  8.94it/s] 52%|█████▏    | 307/595 [00:39<00:32,  8.94it/s] 52%|█████▏    | 308/595 [00:40<00:32,  8.90it/s] 52%|█████▏    | 309/595 [00:40<00:32,  8.92it/s] 52%|█████▏    | 310/595 [00:40<00:32,  8.86it/s] 52%|█████▏    | 311/595 [00:40<00:31,  8.94it/s] 52%|█████▏    | 312/595 [00:40<00:31,  8.91it/s] 53%|█████▎    | 313/595 [00:40<00:31,  8.87it/s] 53%|█████▎    | 314/595 [00:40<00:31,  8.94it/s] 53%|█████▎    | 315/595 [00:40<00:31,  8.96it/s] 53%|█████▎    | 316/595 [00:40<00:31,  8.83it/s] 53%|█████▎    | 317/595 [00:41<00:31,  8.88it/s] 53%|█████▎    | 318/595 [00:41<00:31,  8.87it/s] 54%|█████▎    | 319/595 [00:41<00:31,  8.90it/s] 54%|█████▍    | 320/595 [00:41<00:31,  8.85it/s] 54%|█████▍    | 321/595 [00:41<00:30,  8.98it/s] 54%|█████▍    | 322/595 [00:41<00:30,  8.97it/s] 54%|█████▍    | 323/595 [00:41<00:30,  8.94it/s] 54%|█████▍    | 324/595 [00:41<00:30,  8.92it/s] 55%|█████▍    | 325/595 [00:41<00:30,  8.96it/s] 55%|█████▍    | 326/595 [00:42<00:30,  8.91it/s] 55%|█████▍    | 327/595 [00:42<00:30,  8.83it/s] 55%|█████▌    | 328/595 [00:42<00:30,  8.84it/s] 55%|█████▌    | 329/595 [00:42<00:30,  8.84it/s] 55%|█████▌    | 330/595 [00:42<00:29,  8.87it/s] 56%|█████▌    | 331/595 [00:42<00:29,  9.03it/s] 56%|█████▌    | 332/595 [00:42<00:29,  8.83it/s] 56%|█████▌    | 333/595 [00:42<00:29,  8.88it/s] 56%|█████▌    | 334/595 [00:42<00:29,  8.80it/s] 56%|█████▋    | 335/595 [00:43<00:29,  8.86it/s] 56%|█████▋    | 336/595 [00:43<00:29,  8.92it/s] 57%|█████▋    | 337/595 [00:43<00:28,  8.91it/s] 57%|█████▋    | 338/595 [00:43<00:28,  8.95it/s] 57%|█████▋    | 339/595 [00:43<00:28,  8.93it/s] 57%|█████▋    | 340/595 [00:43<00:28,  8.93it/s] 57%|█████▋    | 341/595 [00:43<00:28,  8.97it/s] 57%|█████▋    | 342/595 [00:43<00:28,  8.87it/s] 58%|█████▊    | 343/595 [00:43<00:28,  8.87it/s] 58%|█████▊    | 344/595 [00:44<00:28,  8.88it/s] 58%|█████▊    | 345/595 [00:44<00:28,  8.88it/s] 58%|█████▊    | 346/595 [00:44<00:27,  8.96it/s] 58%|█████▊    | 347/595 [00:44<00:28,  8.81it/s] 58%|█████▊    | 348/595 [00:44<00:27,  8.91it/s] 59%|█████▊    | 349/595 [00:44<00:27,  8.87it/s] 59%|█████▉    | 350/595 [00:44<00:27,  8.82it/s] 59%|█████▉    | 351/595 [00:44<00:27,  8.91it/s] 59%|█████▉    | 352/595 [00:44<00:27,  8.89it/s] 59%|█████▉    | 353/595 [00:45<00:27,  8.79it/s] 59%|█████▉    | 354/595 [00:45<00:27,  8.88it/s] 60%|█████▉    | 355/595 [00:45<00:27,  8.81it/s] 60%|█████▉    | 356/595 [00:45<00:26,  8.93it/s]                                                  60%|██████    | 357/595 [00:45<00:26,  8.93it/s][INFO|trainer.py:755] 2023-11-15 19:21:42,610 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:21:42,612 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:21:42,612 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:21:42,612 >>   Batch size = 8
{'eval_loss': 0.47594961524009705, 'eval_accuracy': 0.8296296296296296, 'eval_micro_f1': 0.8296296296296296, 'eval_macro_f1': 0.7700539111199008, 'eval_runtime': 1.7189, 'eval_samples_per_second': 549.759, 'eval_steps_per_second': 69.229, 'epoch': 2.0}
{'loss': 0.3506, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 83.71it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 74.19it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 72.99it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 72.49it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 72.48it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 72.52it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 69.02it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 71.00it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 71.40it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 71.55it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 71.96it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 69.74it/s][A
 88%|████████▊ | 105/119 [00:01<00:00, 69.37it/s][A
 95%|█████████▍| 113/119 [00:01<00:00, 70.65it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:47<00:26,  8.93it/s]
100%|██████████| 119/119 [00:01<00:00, 70.65it/s][A
                                                 [A 60%|██████    | 358/595 [00:47<01:56,  2.03it/s] 60%|██████    | 359/595 [00:47<01:34,  2.51it/s] 61%|██████    | 360/595 [00:47<01:16,  3.09it/s] 61%|██████    | 361/595 [00:47<01:02,  3.75it/s] 61%|██████    | 362/595 [00:47<00:52,  4.46it/s] 61%|██████    | 363/595 [00:47<00:44,  5.22it/s] 61%|██████    | 364/595 [00:47<00:38,  5.93it/s] 61%|██████▏   | 365/595 [00:48<00:35,  6.55it/s] 62%|██████▏   | 366/595 [00:48<00:32,  7.08it/s] 62%|██████▏   | 367/595 [00:48<00:30,  7.52it/s] 62%|██████▏   | 368/595 [00:48<00:28,  7.88it/s] 62%|██████▏   | 369/595 [00:48<00:27,  8.16it/s] 62%|██████▏   | 370/595 [00:48<00:26,  8.43it/s] 62%|██████▏   | 371/595 [00:48<00:26,  8.53it/s] 63%|██████▎   | 372/595 [00:48<00:25,  8.62it/s] 63%|██████▎   | 373/595 [00:49<00:25,  8.71it/s] 63%|██████▎   | 374/595 [00:49<00:25,  8.81it/s] 63%|██████▎   | 375/595 [00:49<00:25,  8.72it/s] 63%|██████▎   | 376/595 [00:49<00:25,  8.70it/s] 63%|██████▎   | 377/595 [00:49<00:25,  8.69it/s] 64%|██████▎   | 378/595 [00:49<00:24,  8.76it/s] 64%|██████▎   | 379/595 [00:49<00:24,  8.84it/s] 64%|██████▍   | 380/595 [00:49<00:23,  9.01it/s] 64%|██████▍   | 381/595 [00:49<00:24,  8.85it/s] 64%|██████▍   | 382/595 [00:50<00:23,  8.88it/s] 64%|██████▍   | 383/595 [00:50<00:23,  8.85it/s] 65%|██████▍   | 384/595 [00:50<00:23,  8.88it/s] 65%|██████▍   | 385/595 [00:50<00:23,  8.82it/s] 65%|██████▍   | 386/595 [00:50<00:23,  8.75it/s] 65%|██████▌   | 387/595 [00:50<00:23,  8.80it/s] 65%|██████▌   | 388/595 [00:50<00:23,  8.78it/s] 65%|██████▌   | 389/595 [00:50<00:23,  8.86it/s] 66%|██████▌   | 390/595 [00:50<00:22,  8.93it/s] 66%|██████▌   | 391/595 [00:51<00:22,  8.91it/s] 66%|██████▌   | 392/595 [00:51<00:22,  8.87it/s] 66%|██████▌   | 393/595 [00:51<00:22,  8.88it/s] 66%|██████▌   | 394/595 [00:51<00:22,  8.89it/s] 66%|██████▋   | 395/595 [00:51<00:22,  8.89it/s] 67%|██████▋   | 396/595 [00:51<00:22,  8.76it/s] 67%|██████▋   | 397/595 [00:51<00:22,  8.88it/s] 67%|██████▋   | 398/595 [00:51<00:22,  8.92it/s] 67%|██████▋   | 399/595 [00:51<00:22,  8.91it/s] 67%|██████▋   | 400/595 [00:52<00:21,  9.03it/s] 67%|██████▋   | 401/595 [00:52<00:21,  9.00it/s] 68%|██████▊   | 402/595 [00:52<00:21,  8.88it/s] 68%|██████▊   | 403/595 [00:52<00:21,  8.88it/s] 68%|██████▊   | 404/595 [00:52<00:21,  8.85it/s] 68%|██████▊   | 405/595 [00:52<00:21,  8.87it/s] 68%|██████▊   | 406/595 [00:52<00:21,  8.79it/s] 68%|██████▊   | 407/595 [00:52<00:21,  8.86it/s] 69%|██████▊   | 408/595 [00:52<00:21,  8.83it/s] 69%|██████▊   | 409/595 [00:53<00:20,  8.88it/s] 69%|██████▉   | 410/595 [00:53<00:20,  8.94it/s] 69%|██████▉   | 411/595 [00:53<00:20,  8.95it/s] 69%|██████▉   | 412/595 [00:53<00:20,  8.81it/s] 69%|██████▉   | 413/595 [00:53<00:20,  8.88it/s] 70%|██████▉   | 414/595 [00:53<00:20,  8.88it/s] 70%|██████▉   | 415/595 [00:53<00:20,  8.90it/s] 70%|██████▉   | 416/595 [00:53<00:20,  8.83it/s] 70%|███████   | 417/595 [00:53<00:19,  9.00it/s] 70%|███████   | 418/595 [00:54<00:19,  8.86it/s] 70%|███████   | 419/595 [00:54<00:19,  8.84it/s] 71%|███████   | 420/595 [00:54<00:19,  8.86it/s] 71%|███████   | 421/595 [00:54<00:19,  8.93it/s] 71%|███████   | 422/595 [00:54<00:19,  8.84it/s] 71%|███████   | 423/595 [00:54<00:19,  8.75it/s] 71%|███████▏  | 424/595 [00:54<00:19,  8.80it/s] 71%|███████▏  | 425/595 [00:54<00:19,  8.79it/s] 72%|███████▏  | 426/595 [00:54<00:19,  8.85it/s] 72%|███████▏  | 427/595 [00:55<00:18,  8.91it/s] 72%|███████▏  | 428/595 [00:55<00:18,  8.84it/s] 72%|███████▏  | 429/595 [00:55<00:18,  8.84it/s] 72%|███████▏  | 430/595 [00:55<00:18,  8.86it/s] 72%|███████▏  | 431/595 [00:55<00:18,  8.86it/s] 73%|███████▎  | 432/595 [00:55<00:18,  8.81it/s] 73%|███████▎  | 433/595 [00:55<00:18,  8.77it/s] 73%|███████▎  | 434/595 [00:55<00:18,  8.84it/s] 73%|███████▎  | 435/595 [00:56<00:18,  8.86it/s] 73%|███████▎  | 436/595 [00:56<00:17,  8.87it/s] 73%|███████▎  | 437/595 [00:56<00:17,  8.96it/s] 74%|███████▎  | 438/595 [00:56<00:17,  8.88it/s] 74%|███████▍  | 439/595 [00:56<00:17,  8.79it/s] 74%|███████▍  | 440/595 [00:56<00:17,  8.85it/s] 74%|███████▍  | 441/595 [00:56<00:17,  8.79it/s] 74%|███████▍  | 442/595 [00:56<00:17,  8.86it/s] 74%|███████▍  | 443/595 [00:56<00:17,  8.83it/s] 75%|███████▍  | 444/595 [00:57<00:17,  8.86it/s] 75%|███████▍  | 445/595 [00:57<00:16,  8.85it/s] 75%|███████▍  | 446/595 [00:57<00:16,  8.92it/s] 75%|███████▌  | 447/595 [00:57<00:16,  8.90it/s] 75%|███████▌  | 448/595 [00:57<00:16,  8.95it/s] 75%|███████▌  | 449/595 [00:57<00:16,  8.86it/s] 76%|███████▌  | 450/595 [00:57<00:16,  8.78it/s] 76%|███████▌  | 451/595 [00:57<00:16,  8.75it/s] 76%|███████▌  | 452/595 [00:57<00:16,  8.76it/s] 76%|███████▌  | 453/595 [00:58<00:16,  8.77it/s] 76%|███████▋  | 454/595 [00:58<00:16,  8.81it/s] 76%|███████▋  | 455/595 [00:58<00:15,  8.76it/s] 77%|███████▋  | 456/595 [00:58<00:15,  8.80it/s] 77%|███████▋  | 457/595 [00:58<00:15,  8.80it/s] 77%|███████▋  | 458/595 [00:58<00:15,  8.83it/s] 77%|███████▋  | 459/595 [00:58<00:15,  8.78it/s] 77%|███████▋  | 460/595 [00:58<00:15,  8.78it/s] 77%|███████▋  | 461/595 [00:58<00:15,  8.80it/s] 78%|███████▊  | 462/595 [00:59<00:15,  8.79it/s] 78%|███████▊  | 463/595 [00:59<00:14,  8.86it/s] 78%|███████▊  | 464/595 [00:59<00:14,  8.99it/s] 78%|███████▊  | 465/595 [00:59<00:14,  8.83it/s] 78%|███████▊  | 466/595 [00:59<00:14,  8.81it/s] 78%|███████▊  | 467/595 [00:59<00:14,  8.85it/s] 79%|███████▊  | 468/595 [00:59<00:14,  8.81it/s] 79%|███████▉  | 469/595 [00:59<00:14,  8.85it/s] 79%|███████▉  | 470/595 [00:59<00:14,  8.82it/s] 79%|███████▉  | 471/595 [01:00<00:13,  8.87it/s] 79%|███████▉  | 472/595 [01:00<00:13,  8.83it/s] 79%|███████▉  | 473/595 [01:00<00:13,  8.89it/s] 80%|███████▉  | 474/595 [01:00<00:13,  8.87it/s] 80%|███████▉  | 475/595 [01:00<00:13,  8.90it/s]                                                  80%|████████  | 476/595 [01:00<00:13,  8.90it/s][INFO|trainer.py:755] 2023-11-15 19:21:57,692 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:21:57,694 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:21:57,694 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:21:57,695 >>   Batch size = 8
{'eval_loss': 0.41667449474334717, 'eval_accuracy': 0.8455026455026455, 'eval_micro_f1': 0.8455026455026455, 'eval_macro_f1': 0.7938027747659189, 'eval_runtime': 1.7088, 'eval_samples_per_second': 553.035, 'eval_steps_per_second': 69.641, 'epoch': 3.0}
{'loss': 0.2426, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 79.27it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 76.71it/s][A
 20%|██        | 24/119 [00:00<00:01, 69.68it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 69.09it/s][A
 33%|███▎      | 39/119 [00:00<00:01, 68.27it/s][A
 39%|███▊      | 46/119 [00:00<00:01, 68.05it/s][A
 45%|████▍     | 53/119 [00:00<00:00, 68.32it/s][A
 50%|█████     | 60/119 [00:00<00:00, 68.61it/s][A
 56%|█████▋    | 67/119 [00:00<00:00, 68.73it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 68.86it/s][A
 68%|██████▊   | 81/119 [00:01<00:00, 69.02it/s][A
 74%|███████▍  | 88/119 [00:01<00:00, 66.83it/s][A
 81%|████████  | 96/119 [00:01<00:00, 68.56it/s][A
 87%|████████▋ | 103/119 [00:01<00:00, 67.57it/s][A
 92%|█████████▏| 110/119 [00:01<00:00, 68.03it/s][A
 98%|█████████▊| 117/119 [00:01<00:00, 68.46it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [01:02<00:13,  8.90it/s]
100%|██████████| 119/119 [00:01<00:00, 68.46it/s][A
                                                 [A 80%|████████  | 477/595 [01:02<01:00,  1.97it/s] 80%|████████  | 478/595 [01:02<00:48,  2.43it/s] 81%|████████  | 479/595 [01:02<00:38,  3.00it/s] 81%|████████  | 480/595 [01:02<00:31,  3.65it/s] 81%|████████  | 481/595 [01:02<00:26,  4.36it/s] 81%|████████  | 482/595 [01:03<00:22,  5.05it/s] 81%|████████  | 483/595 [01:03<00:19,  5.77it/s] 81%|████████▏ | 484/595 [01:03<00:17,  6.41it/s] 82%|████████▏ | 485/595 [01:03<00:15,  6.96it/s] 82%|████████▏ | 486/595 [01:03<00:14,  7.54it/s] 82%|████████▏ | 487/595 [01:03<00:13,  7.83it/s] 82%|████████▏ | 488/595 [01:03<00:13,  8.05it/s] 82%|████████▏ | 489/595 [01:03<00:12,  8.25it/s] 82%|████████▏ | 490/595 [01:03<00:12,  8.40it/s] 83%|████████▎ | 491/595 [01:04<00:12,  8.54it/s] 83%|████████▎ | 492/595 [01:04<00:12,  8.55it/s] 83%|████████▎ | 493/595 [01:04<00:11,  8.70it/s] 83%|████████▎ | 494/595 [01:04<00:11,  8.68it/s] 83%|████████▎ | 495/595 [01:04<00:11,  8.72it/s] 83%|████████▎ | 496/595 [01:04<00:11,  8.86it/s] 84%|████████▎ | 497/595 [01:04<00:11,  8.84it/s] 84%|████████▎ | 498/595 [01:04<00:11,  8.78it/s] 84%|████████▍ | 499/595 [01:04<00:10,  8.79it/s] 84%|████████▍ | 500/595 [01:05<00:10,  8.84it/s] 84%|████████▍ | 501/595 [01:05<00:10,  8.90it/s] 84%|████████▍ | 502/595 [01:05<00:10,  8.80it/s] 85%|████████▍ | 503/595 [01:05<00:10,  8.84it/s] 85%|████████▍ | 504/595 [01:05<00:10,  8.80it/s] 85%|████████▍ | 505/595 [01:05<00:10,  8.78it/s] 85%|████████▌ | 506/595 [01:05<00:10,  8.90it/s] 85%|████████▌ | 507/595 [01:05<00:10,  8.73it/s] 85%|████████▌ | 508/595 [01:05<00:09,  8.78it/s] 86%|████████▌ | 509/595 [01:06<00:09,  8.81it/s] 86%|████████▌ | 510/595 [01:06<00:09,  8.82it/s] 86%|████████▌ | 511/595 [01:06<00:09,  8.73it/s] 86%|████████▌ | 512/595 [01:06<00:09,  8.79it/s] 86%|████████▌ | 513/595 [01:06<00:09,  8.75it/s] 86%|████████▋ | 514/595 [01:06<00:09,  8.82it/s] 87%|████████▋ | 515/595 [01:06<00:09,  8.74it/s] 87%|████████▋ | 516/595 [01:06<00:08,  8.91it/s] 87%|████████▋ | 517/595 [01:07<00:08,  8.86it/s] 87%|████████▋ | 518/595 [01:07<00:08,  8.95it/s] 87%|████████▋ | 519/595 [01:07<00:08,  8.95it/s] 87%|████████▋ | 520/595 [01:07<00:08,  8.99it/s] 88%|████████▊ | 521/595 [01:07<00:08,  8.81it/s] 88%|████████▊ | 522/595 [01:07<00:08,  8.84it/s] 88%|████████▊ | 523/595 [01:07<00:08,  8.87it/s] 88%|████████▊ | 524/595 [01:07<00:07,  8.88it/s] 88%|████████▊ | 525/595 [01:07<00:07,  8.79it/s] 88%|████████▊ | 526/595 [01:08<00:07,  8.94it/s] 89%|████████▊ | 527/595 [01:08<00:07,  8.84it/s] 89%|████████▊ | 528/595 [01:08<00:07,  8.89it/s] 89%|████████▉ | 529/595 [01:08<00:07,  8.90it/s] 89%|████████▉ | 530/595 [01:08<00:07,  8.93it/s] 89%|████████▉ | 531/595 [01:08<00:07,  8.84it/s] 89%|████████▉ | 532/595 [01:08<00:07,  8.85it/s] 90%|████████▉ | 533/595 [01:08<00:07,  8.82it/s] 90%|████████▉ | 534/595 [01:08<00:06,  8.86it/s] 90%|████████▉ | 535/595 [01:09<00:06,  8.75it/s] 90%|█████████ | 536/595 [01:09<00:06,  8.82it/s] 90%|█████████ | 537/595 [01:09<00:06,  8.81it/s] 90%|█████████ | 538/595 [01:09<00:06,  8.85it/s] 91%|█████████ | 539/595 [01:09<00:06,  8.92it/s] 91%|█████████ | 540/595 [01:09<00:06,  8.84it/s] 91%|█████████ | 541/595 [01:09<00:06,  8.83it/s] 91%|█████████ | 542/595 [01:09<00:06,  8.81it/s] 91%|█████████▏| 543/595 [01:09<00:05,  8.85it/s] 91%|█████████▏| 544/595 [01:10<00:05,  8.92it/s] 92%|█████████▏| 545/595 [01:10<00:05,  8.74it/s] 92%|█████████▏| 546/595 [01:10<00:05,  8.84it/s] 92%|█████████▏| 547/595 [01:10<00:05,  8.91it/s] 92%|█████████▏| 548/595 [01:10<00:05,  8.89it/s] 92%|█████████▏| 549/595 [01:10<00:05,  8.96it/s] 92%|█████████▏| 550/595 [01:10<00:05,  8.90it/s] 93%|█████████▎| 551/595 [01:10<00:04,  8.89it/s] 93%|█████████▎| 552/595 [01:10<00:04,  8.90it/s] 93%|█████████▎| 553/595 [01:11<00:04,  8.91it/s] 93%|█████████▎| 554/595 [01:11<00:04,  8.92it/s] 93%|█████████▎| 555/595 [01:11<00:04,  8.82it/s] 93%|█████████▎| 556/595 [01:11<00:04,  8.80it/s] 94%|█████████▎| 557/595 [01:11<00:04,  8.85it/s] 94%|█████████▍| 558/595 [01:11<00:04,  8.89it/s] 94%|█████████▍| 559/595 [01:11<00:04,  8.96it/s] 94%|█████████▍| 560/595 [01:11<00:03,  8.91it/s] 94%|█████████▍| 561/595 [01:11<00:03,  8.88it/s] 94%|█████████▍| 562/595 [01:12<00:03,  8.88it/s] 95%|█████████▍| 563/595 [01:12<00:03,  8.93it/s] 95%|█████████▍| 564/595 [01:12<00:03,  8.88it/s] 95%|█████████▍| 565/595 [01:12<00:03,  8.86it/s] 95%|█████████▌| 566/595 [01:12<00:03,  8.79it/s] 95%|█████████▌| 567/595 [01:12<00:03,  8.86it/s] 95%|█████████▌| 568/595 [01:12<00:03,  8.84it/s] 96%|█████████▌| 569/595 [01:12<00:02,  9.00it/s] 96%|█████████▌| 570/595 [01:12<00:02,  8.90it/s] 96%|█████████▌| 571/595 [01:13<00:02,  8.95it/s] 96%|█████████▌| 572/595 [01:13<00:02,  8.94it/s] 96%|█████████▋| 573/595 [01:13<00:02,  8.89it/s] 96%|█████████▋| 574/595 [01:13<00:02,  8.76it/s] 97%|█████████▋| 575/595 [01:13<00:02,  8.85it/s] 97%|█████████▋| 576/595 [01:13<00:02,  8.84it/s] 97%|█████████▋| 577/595 [01:13<00:02,  8.87it/s] 97%|█████████▋| 578/595 [01:13<00:01,  8.77it/s] 97%|█████████▋| 579/595 [01:14<00:01,  8.86it/s] 97%|█████████▋| 580/595 [01:14<00:01,  8.88it/s] 98%|█████████▊| 581/595 [01:14<00:01,  8.87it/s] 98%|█████████▊| 582/595 [01:14<00:01,  8.99it/s] 98%|█████████▊| 583/595 [01:14<00:01,  8.89it/s] 98%|█████████▊| 584/595 [01:14<00:01,  8.89it/s] 98%|█████████▊| 585/595 [01:14<00:01,  8.91it/s] 98%|█████████▊| 586/595 [01:14<00:01,  8.92it/s] 99%|█████████▊| 587/595 [01:14<00:00,  8.92it/s] 99%|█████████▉| 588/595 [01:15<00:00,  8.80it/s] 99%|█████████▉| 589/595 [01:15<00:00,  8.85it/s] 99%|█████████▉| 590/595 [01:15<00:00,  8.84it/s] 99%|█████████▉| 591/595 [01:15<00:00,  8.88it/s] 99%|█████████▉| 592/595 [01:15<00:00,  8.84it/s]100%|█████████▉| 593/595 [01:15<00:00,  8.83it/s]100%|█████████▉| 594/595 [01:15<00:00,  8.83it/s]                                                 100%|██████████| 595/595 [01:15<00:00,  8.83it/s][INFO|trainer.py:755] 2023-11-15 19:22:12,861 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:22:12,864 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:22:12,864 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:22:12,864 >>   Batch size = 8
{'eval_loss': 0.42917150259017944, 'eval_accuracy': 0.8582010582010582, 'eval_micro_f1': 0.8582010582010582, 'eval_macro_f1': 0.7954866812625433, 'eval_runtime': 1.7769, 'eval_samples_per_second': 531.821, 'eval_steps_per_second': 66.97, 'epoch': 4.0}
{'loss': 0.1905, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 82.86it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 76.79it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 71.08it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 71.34it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 70.86it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 71.67it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 72.43it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 68.59it/s][A
 61%|██████▏   | 73/119 [00:01<00:00, 68.92it/s][A
 68%|██████▊   | 81/119 [00:01<00:00, 69.25it/s][A
 75%|███████▍  | 89/119 [00:01<00:00, 70.84it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 69.28it/s][A
 87%|████████▋ | 104/119 [00:01<00:00, 67.62it/s][A
 94%|█████████▍| 112/119 [00:01<00:00, 69.27it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:17<00:00,  8.83it/s]
100%|██████████| 119/119 [00:01<00:00, 69.27it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 19:22:14,603 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:17<00:00,  8.83it/s]100%|██████████| 595/595 [01:17<00:00,  7.68it/s]
[INFO|trainer.py:2855] 2023-11-15 19:22:14,608 >> Saving model checkpoint to ./result/restaurant_roberta-base_adapter__seed0
[INFO|configuration_utils.py:460] 2023-11-15 19:22:14,611 >> Configuration saved in ./result/restaurant_roberta-base_adapter__seed0/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:22:16,145 >> Model weights saved in ./result/restaurant_roberta-base_adapter__seed0/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:22:16,149 >> tokenizer config file saved in ./result/restaurant_roberta-base_adapter__seed0/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:22:16,151 >> Special tokens file saved in ./result/restaurant_roberta-base_adapter__seed0/special_tokens_map.json
{'eval_loss': 0.40974223613739014, 'eval_accuracy': 0.8698412698412699, 'eval_micro_f1': 0.8698412698412697, 'eval_macro_f1': 0.8182376362156442, 'eval_runtime': 1.7351, 'eval_samples_per_second': 544.645, 'eval_steps_per_second': 68.585, 'epoch': 5.0}
{'train_runtime': 77.4949, 'train_samples_per_second': 243.694, 'train_steps_per_second': 7.678, 'train_loss': 0.39081208685866925, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3908
  train_runtime            = 0:01:17.49
  train_samples            =       3777
  train_samples_per_second =    243.694
  train_steps_per_second   =      7.678
11/15/2023 19:22:16 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:22:16,259 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:22:16,260 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:22:16,261 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:22:16,261 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  8%|▊         | 9/119 [00:00<00:01, 83.57it/s] 15%|█▌        | 18/119 [00:00<00:01, 73.10it/s] 22%|██▏       | 26/119 [00:00<00:01, 72.01it/s] 29%|██▊       | 34/119 [00:00<00:01, 73.02it/s] 35%|███▌      | 42/119 [00:00<00:01, 73.25it/s] 42%|████▏     | 50/119 [00:00<00:00, 69.75it/s] 49%|████▊     | 58/119 [00:00<00:00, 71.86it/s] 55%|█████▌    | 66/119 [00:00<00:00, 71.51it/s] 62%|██████▏   | 74/119 [00:01<00:00, 71.48it/s] 69%|██████▉   | 82/119 [00:01<00:00, 73.25it/s] 76%|███████▌  | 90/119 [00:01<00:00, 70.52it/s] 82%|████████▏ | 98/119 [00:01<00:00, 71.35it/s] 89%|████████▉ | 106/119 [00:01<00:00, 70.94it/s] 96%|█████████▌| 114/119 [00:01<00:00, 71.76it/s]100%|██████████| 119/119 [00:01<00:00, 70.48it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8698
  eval_loss               =     0.4097
  eval_macro_f1           =     0.8182
  eval_micro_f1           =     0.8698
  eval_runtime            = 0:00:01.70
  eval_samples            =        945
  eval_samples_per_second =    554.961
  eval_steps_per_second   =     69.884
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▄▆▇██
wandb:                      eval/loss █▅▁▂▁▁
wandb:                  eval/macro_f1 ▁▆▇▇██
wandb:                  eval/micro_f1 ▁▄▆▇██
wandb:                   eval/runtime ▂▃▂█▄▁
wandb:        eval/samples_per_second ▇▆▇▁▅█
wandb:          eval/steps_per_second ▇▆▇▁▅█
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.86984
wandb:                      eval/loss 0.40974
wandb:                  eval/macro_f1 0.81824
wandb:                  eval/micro_f1 0.86984
wandb:                   eval/runtime 1.7028
wandb:        eval/samples_per_second 554.961
wandb:          eval/steps_per_second 69.884
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1905
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.39081
wandb:            train/train_runtime 77.4949
wandb: train/train_samples_per_second 243.694
wandb:   train/train_steps_per_second 7.678
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_191937-bke9wprk
wandb: Find logs at: ./wandb/offline-run-20231115_191937-bke9wprk/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_bert-base-cased_adapter__seed0/runs/Nov15_19-22-29_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_bert-base-cased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_bert-base-cased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:22:29 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:22:29 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_bert-base-cased_adapter__seed0/runs/Nov15_19-22-28_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_bert-base-cased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_bert-base-cased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  88%|████████▊ | 4167/4722 [00:00<00:00, 41231.70 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 40156.74 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 19:22:45,489 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:22:45,503 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 19:22:55,521 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:22:55,522 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:22:55,526 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:22:55,526 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:22:55,527 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:22:55,527 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:22:55,527 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 19:22:55,528 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:22:55,529 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:23:15,693 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 19:23:17,361 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:23:17,361 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 24105.01 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 23778.73 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 29198.13 examples/s]
11/15/2023 19:23:17 - INFO - __main__ - Sample 3388 of the training set: {'text': 'food <SEP> Had dinner here on a Friday and the food was great.', 'label': 0, 'input_ids': [101, 2094, 133, 12342, 2101, 135, 6467, 4014, 1303, 1113, 170, 5286, 1105, 1103, 2094, 1108, 1632, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:23:17 - INFO - __main__ - Sample 871 of the training set: {'text': 'drinks <SEP> You get what you pay for and with that logic in mind, Spice is a great place to grab some cheap eats and drinks in a beautiful setting.', 'label': 0, 'input_ids': [101, 8898, 133, 12342, 2101, 135, 1192, 1243, 1184, 1128, 2653, 1111, 1105, 1114, 1115, 8738, 1107, 1713, 117, 156, 15633, 1110, 170, 1632, 1282, 1106, 6387, 1199, 10928, 24347, 1105, 8898, 1107, 170, 2712, 3545, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:23:17 - INFO - __main__ - Sample 3773 of the training set: {'text': 'food <SEP> Good service, great food, good value, and never have to wait in line!', 'label': 0, 'input_ids': [101, 2094, 133, 12342, 2101, 135, 2750, 1555, 117, 1632, 2094, 117, 1363, 2860, 117, 1105, 1309, 1138, 1106, 3074, 1107, 1413, 106, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:23:17 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:23:19,119 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:23:19,127 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:23:19,127 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 19:23:19,128 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:23:19,128 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:23:19,129 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:23:19,129 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:23:19,129 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 19:23:19,130 >>   Number of trainable parameters = 108,312,579
[INFO|integration_utils.py:716] 2023-11-15 19:23:19,131 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<13:54,  1.41s/it]  0%|          | 2/595 [00:01<06:21,  1.56it/s]  1%|          | 3/595 [00:01<03:54,  2.52it/s]  1%|          | 4/595 [00:01<02:48,  3.51it/s]  1%|          | 5/595 [00:01<02:10,  4.53it/s]  1%|          | 6/595 [00:01<01:47,  5.46it/s]  1%|          | 7/595 [00:02<01:33,  6.31it/s]  1%|▏         | 8/595 [00:02<01:23,  7.02it/s]  2%|▏         | 9/595 [00:02<01:17,  7.54it/s]  2%|▏         | 10/595 [00:02<01:13,  8.00it/s]  2%|▏         | 11/595 [00:02<01:09,  8.37it/s]  2%|▏         | 12/595 [00:02<01:07,  8.64it/s]  2%|▏         | 13/595 [00:02<01:05,  8.88it/s]  2%|▏         | 14/595 [00:02<01:05,  8.91it/s]  3%|▎         | 15/595 [00:02<01:04,  8.95it/s]  3%|▎         | 16/595 [00:03<01:04,  9.03it/s]  3%|▎         | 17/595 [00:03<01:03,  9.03it/s]  3%|▎         | 18/595 [00:03<01:03,  9.09it/s]  3%|▎         | 19/595 [00:03<01:03,  9.13it/s]  3%|▎         | 20/595 [00:03<01:02,  9.23it/s]  4%|▎         | 21/595 [00:03<01:03,  9.09it/s]  4%|▎         | 22/595 [00:03<01:02,  9.15it/s]  4%|▍         | 23/595 [00:03<01:02,  9.16it/s]  4%|▍         | 24/595 [00:03<01:02,  9.20it/s]  4%|▍         | 25/595 [00:04<01:02,  9.13it/s]  4%|▍         | 26/595 [00:04<01:02,  9.11it/s]  5%|▍         | 27/595 [00:04<01:02,  9.16it/s]  5%|▍         | 28/595 [00:04<01:01,  9.16it/s]  5%|▍         | 29/595 [00:04<01:01,  9.24it/s]  5%|▌         | 30/595 [00:04<01:00,  9.36it/s]  5%|▌         | 31/595 [00:04<01:01,  9.19it/s]  5%|▌         | 32/595 [00:04<01:01,  9.19it/s]  6%|▌         | 33/595 [00:04<01:01,  9.16it/s]  6%|▌         | 34/595 [00:04<01:01,  9.17it/s]  6%|▌         | 35/595 [00:05<01:00,  9.22it/s]  6%|▌         | 36/595 [00:05<01:00,  9.18it/s]  6%|▌         | 37/595 [00:05<01:00,  9.26it/s]  6%|▋         | 38/595 [00:05<01:00,  9.18it/s]  7%|▋         | 39/595 [00:05<01:00,  9.16it/s]  7%|▋         | 40/595 [00:05<01:00,  9.25it/s]  7%|▋         | 41/595 [00:05<01:00,  9.20it/s]  7%|▋         | 42/595 [00:05<01:00,  9.13it/s]  7%|▋         | 43/595 [00:05<01:00,  9.15it/s]  7%|▋         | 44/595 [00:06<01:00,  9.12it/s]  8%|▊         | 45/595 [00:06<01:00,  9.14it/s]  8%|▊         | 46/595 [00:06<00:59,  9.16it/s]  8%|▊         | 47/595 [00:06<00:58,  9.30it/s]  8%|▊         | 48/595 [00:06<01:00,  9.11it/s]  8%|▊         | 49/595 [00:06<00:59,  9.19it/s]  8%|▊         | 50/595 [00:06<00:59,  9.17it/s]  9%|▊         | 51/595 [00:06<00:58,  9.23it/s]  9%|▊         | 52/595 [00:06<00:59,  9.17it/s]  9%|▉         | 53/595 [00:07<00:59,  9.08it/s]  9%|▉         | 54/595 [00:07<00:59,  9.16it/s]  9%|▉         | 55/595 [00:07<00:59,  9.15it/s]  9%|▉         | 56/595 [00:07<00:58,  9.19it/s] 10%|▉         | 57/595 [00:07<00:58,  9.27it/s] 10%|▉         | 58/595 [00:07<00:58,  9.15it/s] 10%|▉         | 59/595 [00:07<00:58,  9.17it/s] 10%|█         | 60/595 [00:07<00:58,  9.16it/s] 10%|█         | 61/595 [00:07<00:58,  9.16it/s] 10%|█         | 62/595 [00:08<00:57,  9.22it/s] 11%|█         | 63/595 [00:08<00:57,  9.18it/s] 11%|█         | 64/595 [00:08<00:56,  9.32it/s] 11%|█         | 65/595 [00:08<00:57,  9.16it/s] 11%|█         | 66/595 [00:08<00:57,  9.22it/s] 11%|█▏        | 67/595 [00:08<00:57,  9.23it/s] 11%|█▏        | 68/595 [00:08<00:57,  9.22it/s] 12%|█▏        | 69/595 [00:08<00:57,  9.19it/s] 12%|█▏        | 70/595 [00:08<00:57,  9.12it/s] 12%|█▏        | 71/595 [00:09<00:57,  9.11it/s] 12%|█▏        | 72/595 [00:09<00:57,  9.15it/s] 12%|█▏        | 73/595 [00:09<00:56,  9.18it/s] 12%|█▏        | 74/595 [00:09<00:56,  9.25it/s] 13%|█▎        | 75/595 [00:09<00:56,  9.18it/s] 13%|█▎        | 76/595 [00:09<00:56,  9.18it/s] 13%|█▎        | 77/595 [00:09<00:56,  9.14it/s] 13%|█▎        | 78/595 [00:09<00:56,  9.16it/s] 13%|█▎        | 79/595 [00:09<00:56,  9.12it/s] 13%|█▎        | 80/595 [00:10<00:57,  8.99it/s] 14%|█▎        | 81/595 [00:10<00:56,  9.09it/s] 14%|█▍        | 82/595 [00:10<00:56,  9.08it/s] 14%|█▍        | 83/595 [00:10<00:56,  9.14it/s] 14%|█▍        | 84/595 [00:10<00:55,  9.20it/s] 14%|█▍        | 85/595 [00:10<00:55,  9.13it/s] 14%|█▍        | 86/595 [00:10<00:56,  9.07it/s] 15%|█▍        | 87/595 [00:10<00:55,  9.11it/s] 15%|█▍        | 88/595 [00:10<00:55,  9.10it/s] 15%|█▍        | 89/595 [00:10<00:55,  9.15it/s] 15%|█▌        | 90/595 [00:11<00:55,  9.09it/s] 15%|█▌        | 91/595 [00:11<00:54,  9.19it/s] 15%|█▌        | 92/595 [00:11<00:55,  9.13it/s] 16%|█▌        | 93/595 [00:11<00:54,  9.20it/s] 16%|█▌        | 94/595 [00:11<00:54,  9.16it/s] 16%|█▌        | 95/595 [00:11<00:54,  9.16it/s] 16%|█▌        | 96/595 [00:11<00:55,  9.05it/s] 16%|█▋        | 97/595 [00:11<00:55,  9.05it/s] 16%|█▋        | 98/595 [00:11<00:54,  9.04it/s] 17%|█▋        | 99/595 [00:12<00:54,  9.03it/s] 17%|█▋        | 100/595 [00:12<00:54,  9.13it/s] 17%|█▋        | 101/595 [00:12<00:53,  9.18it/s] 17%|█▋        | 102/595 [00:12<00:53,  9.13it/s] 17%|█▋        | 103/595 [00:12<00:54,  9.09it/s] 17%|█▋        | 104/595 [00:12<00:53,  9.10it/s] 18%|█▊        | 105/595 [00:12<00:53,  9.11it/s] 18%|█▊        | 106/595 [00:12<00:53,  9.11it/s] 18%|█▊        | 107/595 [00:12<00:53,  9.08it/s] 18%|█▊        | 108/595 [00:13<00:53,  9.18it/s] 18%|█▊        | 109/595 [00:13<00:53,  9.16it/s] 18%|█▊        | 110/595 [00:13<00:53,  9.14it/s] 19%|█▊        | 111/595 [00:13<00:52,  9.24it/s] 19%|█▉        | 112/595 [00:13<00:52,  9.26it/s] 19%|█▉        | 113/595 [00:13<00:52,  9.11it/s] 19%|█▉        | 114/595 [00:13<00:52,  9.08it/s] 19%|█▉        | 115/595 [00:13<00:53,  9.01it/s] 19%|█▉        | 116/595 [00:13<00:52,  9.12it/s] 20%|█▉        | 117/595 [00:14<00:52,  9.15it/s] 20%|█▉        | 118/595 [00:14<00:51,  9.29it/s]                                                  20%|██        | 119/595 [00:14<00:51,  9.29it/s][INFO|trainer.py:755] 2023-11-15 19:23:33,360 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:23:33,362 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:23:33,362 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:23:33,363 >>   Batch size = 8
{'loss': 0.7183, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 77.88it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 71.09it/s][A
 20%|██        | 24/119 [00:00<00:01, 72.05it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 71.48it/s][A
 34%|███▎      | 40/119 [00:00<00:01, 70.66it/s][A
 40%|████      | 48/119 [00:00<00:00, 72.37it/s][A
 47%|████▋     | 56/119 [00:00<00:00, 69.78it/s][A
 54%|█████▍    | 64/119 [00:00<00:00, 70.52it/s][A
 61%|██████    | 72/119 [00:01<00:00, 71.23it/s][A
 67%|██████▋   | 80/119 [00:01<00:00, 69.85it/s][A
 74%|███████▍  | 88/119 [00:01<00:00, 68.76it/s][A
 80%|███████▉  | 95/119 [00:01<00:00, 68.93it/s][A
 86%|████████▌ | 102/119 [00:01<00:00, 68.69it/s][A
 92%|█████████▏| 110/119 [00:01<00:00, 70.31it/s][A
 99%|█████████▉| 118/119 [00:01<00:00, 69.59it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:15<00:51,  9.29it/s]
100%|██████████| 119/119 [00:01<00:00, 69.59it/s][A
                                                 [A 20%|██        | 120/595 [00:16<03:56,  2.00it/s] 20%|██        | 121/595 [00:16<03:10,  2.49it/s] 21%|██        | 122/595 [00:16<02:34,  3.07it/s] 21%|██        | 123/595 [00:16<02:05,  3.76it/s] 21%|██        | 124/595 [00:16<01:45,  4.48it/s] 21%|██        | 125/595 [00:16<01:29,  5.24it/s] 21%|██        | 126/595 [00:16<01:18,  5.98it/s] 21%|██▏       | 127/595 [00:16<01:10,  6.67it/s] 22%|██▏       | 128/595 [00:16<01:04,  7.23it/s] 22%|██▏       | 129/595 [00:17<01:00,  7.68it/s] 22%|██▏       | 130/595 [00:17<00:57,  8.06it/s] 22%|██▏       | 131/595 [00:17<00:55,  8.39it/s] 22%|██▏       | 132/595 [00:17<00:53,  8.62it/s] 22%|██▏       | 133/595 [00:17<00:52,  8.87it/s] 23%|██▎       | 134/595 [00:17<00:51,  8.91it/s] 23%|██▎       | 135/595 [00:17<00:51,  8.89it/s] 23%|██▎       | 136/595 [00:17<00:51,  8.96it/s] 23%|██▎       | 137/595 [00:17<00:50,  9.03it/s] 23%|██▎       | 138/595 [00:18<00:50,  9.12it/s] 23%|██▎       | 139/595 [00:18<00:50,  8.98it/s] 24%|██▎       | 140/595 [00:18<00:50,  9.04it/s] 24%|██▎       | 141/595 [00:18<00:50,  9.06it/s] 24%|██▍       | 142/595 [00:18<00:49,  9.07it/s] 24%|██▍       | 143/595 [00:18<00:49,  9.13it/s] 24%|██▍       | 144/595 [00:18<00:50,  9.01it/s] 24%|██▍       | 145/595 [00:18<00:49,  9.02it/s] 25%|██▍       | 146/595 [00:18<00:49,  9.06it/s] 25%|██▍       | 147/595 [00:19<00:49,  9.07it/s] 25%|██▍       | 148/595 [00:19<00:49,  9.08it/s] 25%|██▌       | 149/595 [00:19<00:49,  9.10it/s] 25%|██▌       | 150/595 [00:19<00:48,  9.15it/s] 25%|██▌       | 151/595 [00:19<00:49,  9.05it/s] 26%|██▌       | 152/595 [00:19<00:48,  9.07it/s] 26%|██▌       | 153/595 [00:19<00:48,  9.15it/s] 26%|██▌       | 154/595 [00:19<00:48,  9.11it/s] 26%|██▌       | 155/595 [00:19<00:48,  9.03it/s] 26%|██▌       | 156/595 [00:20<00:48,  9.06it/s] 26%|██▋       | 157/595 [00:20<00:48,  8.99it/s] 27%|██▋       | 158/595 [00:20<00:48,  9.08it/s] 27%|██▋       | 159/595 [00:20<00:47,  9.11it/s] 27%|██▋       | 160/595 [00:20<00:46,  9.26it/s] 27%|██▋       | 161/595 [00:20<00:47,  9.14it/s] 27%|██▋       | 162/595 [00:20<00:47,  9.16it/s] 27%|██▋       | 163/595 [00:20<00:47,  9.14it/s] 28%|██▊       | 164/595 [00:20<00:46,  9.17it/s] 28%|██▊       | 165/595 [00:21<00:47,  9.13it/s] 28%|██▊       | 166/595 [00:21<00:47,  9.07it/s] 28%|██▊       | 167/595 [00:21<00:47,  9.09it/s] 28%|██▊       | 168/595 [00:21<00:46,  9.11it/s] 28%|██▊       | 169/595 [00:21<00:46,  9.16it/s] 29%|██▊       | 170/595 [00:21<00:46,  9.19it/s] 29%|██▊       | 171/595 [00:21<00:46,  9.15it/s] 29%|██▉       | 172/595 [00:21<00:46,  9.13it/s] 29%|██▉       | 173/595 [00:21<00:46,  9.14it/s] 29%|██▉       | 174/595 [00:21<00:46,  9.15it/s] 29%|██▉       | 175/595 [00:22<00:45,  9.15it/s] 30%|██▉       | 176/595 [00:22<00:46,  9.03it/s] 30%|██▉       | 177/595 [00:22<00:45,  9.11it/s] 30%|██▉       | 178/595 [00:22<00:45,  9.07it/s] 30%|███       | 179/595 [00:22<00:45,  9.13it/s] 30%|███       | 180/595 [00:22<00:44,  9.25it/s] 30%|███       | 181/595 [00:22<00:45,  9.16it/s] 31%|███       | 182/595 [00:22<00:45,  9.13it/s] 31%|███       | 183/595 [00:22<00:44,  9.17it/s] 31%|███       | 184/595 [00:23<00:44,  9.17it/s] 31%|███       | 185/595 [00:23<00:44,  9.17it/s] 31%|███▏      | 186/595 [00:23<00:44,  9.15it/s] 31%|███▏      | 187/595 [00:23<00:44,  9.24it/s] 32%|███▏      | 188/595 [00:23<00:44,  9.12it/s] 32%|███▏      | 189/595 [00:23<00:44,  9.18it/s] 32%|███▏      | 190/595 [00:23<00:44,  9.19it/s] 32%|███▏      | 191/595 [00:23<00:43,  9.20it/s] 32%|███▏      | 192/595 [00:23<00:44,  9.07it/s] 32%|███▏      | 193/595 [00:24<00:44,  9.08it/s] 33%|███▎      | 194/595 [00:24<00:44,  8.99it/s] 33%|███▎      | 195/595 [00:24<00:44,  9.06it/s] 33%|███▎      | 196/595 [00:24<00:44,  9.01it/s] 33%|███▎      | 197/595 [00:24<00:43,  9.06it/s] 33%|███▎      | 198/595 [00:24<00:43,  9.03it/s] 33%|███▎      | 199/595 [00:24<00:43,  9.04it/s] 34%|███▎      | 200/595 [00:24<00:43,  9.07it/s] 34%|███▍      | 201/595 [00:24<00:43,  9.13it/s] 34%|███▍      | 202/595 [00:25<00:43,  9.06it/s] 34%|███▍      | 203/595 [00:25<00:43,  9.04it/s] 34%|███▍      | 204/595 [00:25<00:43,  9.03it/s] 34%|███▍      | 205/595 [00:25<00:42,  9.07it/s] 35%|███▍      | 206/595 [00:25<00:42,  9.12it/s] 35%|███▍      | 207/595 [00:25<00:42,  9.16it/s] 35%|███▍      | 208/595 [00:25<00:42,  9.06it/s] 35%|███▌      | 209/595 [00:25<00:42,  9.13it/s] 35%|███▌      | 210/595 [00:25<00:42,  9.14it/s] 35%|███▌      | 211/595 [00:26<00:41,  9.17it/s] 36%|███▌      | 212/595 [00:26<00:42,  9.11it/s] 36%|███▌      | 213/595 [00:26<00:42,  9.02it/s] 36%|███▌      | 214/595 [00:26<00:42,  9.01it/s] 36%|███▌      | 215/595 [00:26<00:41,  9.05it/s] 36%|███▋      | 216/595 [00:26<00:41,  9.09it/s] 36%|███▋      | 217/595 [00:26<00:41,  9.20it/s] 37%|███▋      | 218/595 [00:26<00:41,  9.16it/s] 37%|███▋      | 219/595 [00:26<00:41,  9.11it/s] 37%|███▋      | 220/595 [00:27<00:41,  9.08it/s] 37%|███▋      | 221/595 [00:27<00:40,  9.13it/s] 37%|███▋      | 222/595 [00:27<00:40,  9.14it/s] 37%|███▋      | 223/595 [00:27<00:41,  9.05it/s] 38%|███▊      | 224/595 [00:27<00:40,  9.08it/s] 38%|███▊      | 225/595 [00:27<00:40,  9.04it/s] 38%|███▊      | 226/595 [00:27<00:40,  9.08it/s] 38%|███▊      | 227/595 [00:27<00:39,  9.23it/s] 38%|███▊      | 228/595 [00:27<00:40,  9.08it/s] 38%|███▊      | 229/595 [00:28<00:40,  9.00it/s] 39%|███▊      | 230/595 [00:28<00:40,  9.03it/s] 39%|███▉      | 231/595 [00:28<00:40,  9.05it/s] 39%|███▉      | 232/595 [00:28<00:39,  9.09it/s] 39%|███▉      | 233/595 [00:28<00:40,  8.97it/s] 39%|███▉      | 234/595 [00:28<00:40,  9.02it/s] 39%|███▉      | 235/595 [00:28<00:39,  9.01it/s] 40%|███▉      | 236/595 [00:28<00:39,  9.04it/s] 40%|███▉      | 237/595 [00:28<00:39,  9.17it/s]                                                  40%|████      | 238/595 [00:28<00:38,  9.17it/s][INFO|trainer.py:755] 2023-11-15 19:23:48,106 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:23:48,108 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:23:48,109 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:23:48,109 >>   Batch size = 8
{'eval_loss': 0.5384855270385742, 'eval_accuracy': 0.7915343915343915, 'eval_micro_f1': 0.7915343915343915, 'eval_macro_f1': 0.6944881655550993, 'eval_runtime': 1.7388, 'eval_samples_per_second': 543.483, 'eval_steps_per_second': 68.439, 'epoch': 1.0}
{'loss': 0.4599, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 83.17it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 73.87it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 72.94it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 73.08it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 71.07it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 72.05it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 70.81it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 71.06it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 72.06it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 70.10it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 69.78it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 69.60it/s][A
 87%|████████▋ | 104/119 [00:01<00:00, 69.50it/s][A
 94%|█████████▍| 112/119 [00:01<00:00, 71.00it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:30<00:38,  9.17it/s]
100%|██████████| 119/119 [00:01<00:00, 71.00it/s][A
                                                 [A 40%|████      | 239/595 [00:30<02:54,  2.04it/s] 40%|████      | 240/595 [00:30<02:20,  2.52it/s] 41%|████      | 241/595 [00:31<01:54,  3.10it/s] 41%|████      | 242/595 [00:31<01:33,  3.79it/s] 41%|████      | 243/595 [00:31<01:18,  4.50it/s] 41%|████      | 244/595 [00:31<01:06,  5.25it/s] 41%|████      | 245/595 [00:31<00:58,  6.00it/s] 41%|████▏     | 246/595 [00:31<00:52,  6.65it/s] 42%|████▏     | 247/595 [00:31<00:48,  7.16it/s] 42%|████▏     | 248/595 [00:31<00:45,  7.58it/s] 42%|████▏     | 249/595 [00:31<00:43,  8.01it/s] 42%|████▏     | 250/595 [00:32<00:41,  8.26it/s] 42%|████▏     | 251/595 [00:32<00:40,  8.54it/s] 42%|████▏     | 252/595 [00:32<00:39,  8.75it/s] 43%|████▎     | 253/595 [00:32<00:38,  8.81it/s] 43%|████▎     | 254/595 [00:32<00:39,  8.74it/s] 43%|████▎     | 255/595 [00:32<00:38,  8.83it/s] 43%|████▎     | 256/595 [00:32<00:38,  8.82it/s] 43%|████▎     | 257/595 [00:32<00:37,  8.92it/s] 43%|████▎     | 258/595 [00:32<00:37,  8.90it/s] 44%|████▎     | 259/595 [00:33<00:37,  9.01it/s] 44%|████▎     | 260/595 [00:33<00:37,  9.00it/s] 44%|████▍     | 261/595 [00:33<00:37,  8.98it/s] 44%|████▍     | 262/595 [00:33<00:37,  8.96it/s] 44%|████▍     | 263/595 [00:33<00:36,  9.01it/s] 44%|████▍     | 264/595 [00:33<00:37,  8.91it/s] 45%|████▍     | 265/595 [00:33<00:36,  8.94it/s] 45%|████▍     | 266/595 [00:33<00:37,  8.85it/s] 45%|████▍     | 267/595 [00:33<00:36,  8.94it/s] 45%|████▌     | 268/595 [00:34<00:36,  8.88it/s] 45%|████▌     | 269/595 [00:34<00:36,  8.99it/s] 45%|████▌     | 270/595 [00:34<00:36,  8.97it/s] 46%|████▌     | 271/595 [00:34<00:36,  8.94it/s] 46%|████▌     | 272/595 [00:34<00:36,  8.94it/s] 46%|████▌     | 273/595 [00:34<00:35,  8.97it/s] 46%|████▌     | 274/595 [00:34<00:36,  8.78it/s] 46%|████▌     | 275/595 [00:34<00:36,  8.87it/s] 46%|████▋     | 276/595 [00:34<00:36,  8.84it/s] 47%|████▋     | 277/595 [00:35<00:35,  8.92it/s] 47%|████▋     | 278/595 [00:35<00:35,  8.87it/s] 47%|████▋     | 279/595 [00:35<00:34,  9.05it/s] 47%|████▋     | 280/595 [00:35<00:35,  8.96it/s] 47%|████▋     | 281/595 [00:35<00:34,  9.01it/s] 47%|████▋     | 282/595 [00:35<00:34,  9.00it/s] 48%|████▊     | 283/595 [00:35<00:34,  9.04it/s] 48%|████▊     | 284/595 [00:35<00:34,  8.98it/s] 48%|████▊     | 285/595 [00:35<00:34,  8.95it/s] 48%|████▊     | 286/595 [00:36<00:34,  8.90it/s] 48%|████▊     | 287/595 [00:36<00:34,  8.94it/s] 48%|████▊     | 288/595 [00:36<00:34,  9.00it/s] 49%|████▊     | 289/595 [00:36<00:33,  9.14it/s] 49%|████▊     | 290/595 [00:36<00:34,  8.95it/s] 49%|████▉     | 291/595 [00:36<00:33,  8.98it/s] 49%|████▉     | 292/595 [00:36<00:33,  8.94it/s] 49%|████▉     | 293/595 [00:36<00:33,  9.00it/s] 49%|████▉     | 294/595 [00:36<00:33,  8.99it/s] 50%|████▉     | 295/595 [00:37<00:33,  8.92it/s] 50%|████▉     | 296/595 [00:37<00:33,  8.94it/s] 50%|████▉     | 297/595 [00:37<00:33,  8.96it/s] 50%|█████     | 298/595 [00:37<00:33,  8.97it/s] 50%|█████     | 299/595 [00:37<00:32,  9.10it/s] 50%|█████     | 300/595 [00:37<00:32,  8.95it/s] 51%|█████     | 301/595 [00:37<00:32,  9.00it/s] 51%|█████     | 302/595 [00:37<00:32,  8.99it/s] 51%|█████     | 303/595 [00:37<00:32,  9.04it/s] 51%|█████     | 304/595 [00:38<00:32,  8.98it/s] 51%|█████▏    | 305/595 [00:38<00:32,  9.00it/s] 51%|█████▏    | 306/595 [00:38<00:32,  9.00it/s] 52%|█████▏    | 307/595 [00:38<00:31,  9.06it/s] 52%|█████▏    | 308/595 [00:38<00:31,  9.11it/s] 52%|█████▏    | 309/595 [00:38<00:31,  9.12it/s] 52%|█████▏    | 310/595 [00:38<00:31,  8.98it/s] 52%|█████▏    | 311/595 [00:38<00:31,  9.05it/s] 52%|█████▏    | 312/595 [00:38<00:31,  9.06it/s] 53%|█████▎    | 313/595 [00:39<00:31,  9.07it/s] 53%|█████▎    | 314/595 [00:39<00:30,  9.08it/s] 53%|█████▎    | 315/595 [00:39<00:30,  9.05it/s] 53%|█████▎    | 316/595 [00:39<00:30,  9.28it/s] 53%|█████▎    | 317/595 [00:39<00:30,  9.10it/s] 53%|█████▎    | 318/595 [00:39<00:30,  9.09it/s] 54%|█████▎    | 319/595 [00:39<00:30,  9.17it/s] 54%|█████▍    | 320/595 [00:39<00:30,  9.04it/s] 54%|█████▍    | 321/595 [00:39<00:30,  8.94it/s] 54%|█████▍    | 322/595 [00:40<00:30,  9.01it/s] 54%|█████▍    | 323/595 [00:40<00:29,  9.07it/s] 54%|█████▍    | 324/595 [00:40<00:29,  9.04it/s] 55%|█████▍    | 325/595 [00:40<00:30,  8.99it/s] 55%|█████▍    | 326/595 [00:40<00:29,  9.03it/s] 55%|█████▍    | 327/595 [00:40<00:29,  9.05it/s] 55%|█████▌    | 328/595 [00:40<00:29,  9.06it/s] 55%|█████▌    | 329/595 [00:40<00:29,  9.16it/s] 55%|█████▌    | 330/595 [00:40<00:29,  9.07it/s] 56%|█████▌    | 331/595 [00:41<00:29,  9.04it/s] 56%|█████▌    | 332/595 [00:41<00:28,  9.11it/s] 56%|█████▌    | 333/595 [00:41<00:28,  9.08it/s] 56%|█████▌    | 334/595 [00:41<00:28,  9.07it/s] 56%|█████▋    | 335/595 [00:41<00:28,  8.98it/s] 56%|█████▋    | 336/595 [00:41<00:28,  9.11it/s] 57%|█████▋    | 337/595 [00:41<00:28,  9.13it/s] 57%|█████▋    | 338/595 [00:41<00:28,  9.09it/s] 57%|█████▋    | 339/595 [00:41<00:27,  9.21it/s] 57%|█████▋    | 340/595 [00:42<00:28,  9.09it/s] 57%|█████▋    | 341/595 [00:42<00:28,  8.99it/s] 57%|█████▋    | 342/595 [00:42<00:28,  9.00it/s] 58%|█████▊    | 343/595 [00:42<00:27,  9.00it/s] 58%|█████▊    | 344/595 [00:42<00:27,  8.98it/s] 58%|█████▊    | 345/595 [00:42<00:27,  8.93it/s] 58%|█████▊    | 346/595 [00:42<00:27,  9.06it/s] 58%|█████▊    | 347/595 [00:42<00:27,  9.05it/s] 58%|█████▊    | 348/595 [00:42<00:27,  9.10it/s] 59%|█████▊    | 349/595 [00:42<00:26,  9.20it/s] 59%|█████▉    | 350/595 [00:43<00:27,  9.02it/s] 59%|█████▉    | 351/595 [00:43<00:27,  9.02it/s] 59%|█████▉    | 352/595 [00:43<00:27,  8.99it/s] 59%|█████▉    | 353/595 [00:43<00:26,  9.03it/s] 59%|█████▉    | 354/595 [00:43<00:26,  8.98it/s] 60%|█████▉    | 355/595 [00:43<00:26,  8.89it/s] 60%|█████▉    | 356/595 [00:43<00:26,  9.03it/s]                                                  60%|██████    | 357/595 [00:43<00:26,  9.03it/s][INFO|trainer.py:755] 2023-11-15 19:24:02,960 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:24:02,962 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:24:02,963 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:24:02,963 >>   Batch size = 8
{'eval_loss': 0.47502821683883667, 'eval_accuracy': 0.8232804232804233, 'eval_micro_f1': 0.8232804232804233, 'eval_macro_f1': 0.7618111686661672, 'eval_runtime': 1.7127, 'eval_samples_per_second': 551.768, 'eval_steps_per_second': 69.482, 'epoch': 2.0}
{'loss': 0.3079, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 83.19it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 77.01it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 72.79it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 70.05it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 69.51it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 70.70it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 68.30it/s][A
 55%|█████▍    | 65/119 [00:00<00:00, 67.71it/s][A
 61%|██████    | 72/119 [00:01<00:00, 68.36it/s][A
 67%|██████▋   | 80/119 [00:01<00:00, 69.08it/s][A
 74%|███████▍  | 88/119 [00:01<00:00, 69.64it/s][A
 81%|████████  | 96/119 [00:01<00:00, 69.96it/s][A
 87%|████████▋ | 103/119 [00:01<00:00, 68.81it/s][A
 92%|█████████▏| 110/119 [00:01<00:00, 68.83it/s][A
 99%|█████████▉| 118/119 [00:01<00:00, 68.84it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:45<00:26,  9.03it/s]
100%|██████████| 119/119 [00:01<00:00, 68.84it/s][A
                                                 [A 60%|██████    | 358/595 [00:45<01:59,  1.99it/s] 60%|██████    | 359/595 [00:45<01:35,  2.47it/s] 61%|██████    | 360/595 [00:45<01:17,  3.05it/s] 61%|██████    | 361/595 [00:46<01:02,  3.72it/s] 61%|██████    | 362/595 [00:46<00:52,  4.45it/s] 61%|██████    | 363/595 [00:46<00:44,  5.19it/s] 61%|██████    | 364/595 [00:46<00:39,  5.90it/s] 61%|██████▏   | 365/595 [00:46<00:34,  6.58it/s] 62%|██████▏   | 366/595 [00:46<00:31,  7.17it/s] 62%|██████▏   | 367/595 [00:46<00:29,  7.67it/s] 62%|██████▏   | 368/595 [00:46<00:28,  7.96it/s] 62%|██████▏   | 369/595 [00:46<00:27,  8.30it/s] 62%|██████▏   | 370/595 [00:47<00:26,  8.51it/s] 62%|██████▏   | 371/595 [00:47<00:25,  8.72it/s] 63%|██████▎   | 372/595 [00:47<00:25,  8.81it/s] 63%|██████▎   | 373/595 [00:47<00:25,  8.84it/s] 63%|██████▎   | 374/595 [00:47<00:24,  8.85it/s] 63%|██████▎   | 375/595 [00:47<00:24,  8.95it/s] 63%|██████▎   | 376/595 [00:47<00:24,  8.95it/s] 63%|██████▎   | 377/595 [00:47<00:24,  9.02it/s] 64%|██████▎   | 378/595 [00:47<00:24,  8.97it/s] 64%|██████▎   | 379/595 [00:48<00:24,  8.94it/s] 64%|██████▍   | 380/595 [00:48<00:23,  9.04it/s] 64%|██████▍   | 381/595 [00:48<00:23,  9.07it/s] 64%|██████▍   | 382/595 [00:48<00:23,  8.97it/s] 64%|██████▍   | 383/595 [00:48<00:23,  8.96it/s] 65%|██████▍   | 384/595 [00:48<00:23,  8.97it/s] 65%|██████▍   | 385/595 [00:48<00:23,  9.03it/s] 65%|██████▍   | 386/595 [00:48<00:23,  8.96it/s] 65%|██████▌   | 387/595 [00:48<00:23,  8.95it/s] 65%|██████▌   | 388/595 [00:49<00:23,  8.96it/s] 65%|██████▌   | 389/595 [00:49<00:22,  8.98it/s] 66%|██████▌   | 390/595 [00:49<00:22,  9.02it/s] 66%|██████▌   | 391/595 [00:49<00:22,  8.99it/s] 66%|██████▌   | 392/595 [00:49<00:22,  8.91it/s] 66%|██████▌   | 393/595 [00:49<00:22,  8.98it/s] 66%|██████▌   | 394/595 [00:49<00:22,  8.96it/s] 66%|██████▋   | 395/595 [00:49<00:22,  9.03it/s] 67%|██████▋   | 396/595 [00:49<00:22,  8.96it/s] 67%|██████▋   | 397/595 [00:50<00:22,  9.00it/s] 67%|██████▋   | 398/595 [00:50<00:21,  9.02it/s] 67%|██████▋   | 399/595 [00:50<00:21,  9.03it/s] 67%|██████▋   | 400/595 [00:50<00:21,  9.13it/s] 67%|██████▋   | 401/595 [00:50<00:21,  9.05it/s] 68%|██████▊   | 402/595 [00:50<00:21,  8.91it/s] 68%|██████▊   | 403/595 [00:50<00:21,  8.91it/s] 68%|██████▊   | 404/595 [00:50<00:21,  8.97it/s] 68%|██████▊   | 405/595 [00:50<00:21,  8.97it/s] 68%|██████▊   | 406/595 [00:51<00:21,  8.91it/s] 68%|██████▊   | 407/595 [00:51<00:20,  9.00it/s] 69%|██████▊   | 408/595 [00:51<00:20,  8.99it/s] 69%|██████▊   | 409/595 [00:51<00:20,  9.03it/s] 69%|██████▉   | 410/595 [00:51<00:20,  9.12it/s] 69%|██████▉   | 411/595 [00:51<00:20,  8.97it/s] 69%|██████▉   | 412/595 [00:51<00:20,  8.93it/s] 69%|██████▉   | 413/595 [00:51<00:20,  8.93it/s] 70%|██████▉   | 414/595 [00:51<00:20,  8.99it/s] 70%|██████▉   | 415/595 [00:52<00:20,  9.00it/s] 70%|██████▉   | 416/595 [00:52<00:20,  8.87it/s] 70%|███████   | 417/595 [00:52<00:20,  8.90it/s] 70%|███████   | 418/595 [00:52<00:19,  8.91it/s] 70%|███████   | 419/595 [00:52<00:19,  8.95it/s] 71%|███████   | 420/595 [00:52<00:19,  9.08it/s] 71%|███████   | 421/595 [00:52<00:19,  8.95it/s] 71%|███████   | 422/595 [00:52<00:19,  8.96it/s] 71%|███████   | 423/595 [00:52<00:19,  8.97it/s] 71%|███████▏  | 424/595 [00:53<00:18,  9.01it/s] 71%|███████▏  | 425/595 [00:53<00:18,  8.98it/s] 72%|███████▏  | 426/595 [00:53<00:18,  8.92it/s] 72%|███████▏  | 427/595 [00:53<00:18,  8.92it/s] 72%|███████▏  | 428/595 [00:53<00:18,  8.95it/s] 72%|███████▏  | 429/595 [00:53<00:18,  8.98it/s] 72%|███████▏  | 430/595 [00:53<00:18,  9.03it/s] 72%|███████▏  | 431/595 [00:53<00:18,  8.90it/s] 73%|███████▎  | 432/595 [00:53<00:18,  8.90it/s] 73%|███████▎  | 433/595 [00:54<00:18,  8.99it/s] 73%|███████▎  | 434/595 [00:54<00:17,  9.07it/s] 73%|███████▎  | 435/595 [00:54<00:17,  8.90it/s] 73%|███████▎  | 436/595 [00:54<00:17,  8.97it/s] 73%|███████▎  | 437/595 [00:54<00:17,  8.94it/s] 74%|███████▎  | 438/595 [00:54<00:17,  9.06it/s] 74%|███████▍  | 439/595 [00:54<00:17,  8.94it/s] 74%|███████▍  | 440/595 [00:54<00:17,  9.04it/s] 74%|███████▍  | 441/595 [00:54<00:17,  9.00it/s] 74%|███████▍  | 442/595 [00:55<00:16,  9.00it/s] 74%|███████▍  | 443/595 [00:55<00:16,  9.11it/s] 75%|███████▍  | 444/595 [00:55<00:16,  9.06it/s] 75%|███████▍  | 445/595 [00:55<00:16,  8.98it/s] 75%|███████▍  | 446/595 [00:55<00:16,  9.02it/s] 75%|███████▌  | 447/595 [00:55<00:16,  8.96it/s] 75%|███████▌  | 448/595 [00:55<00:16,  9.00it/s] 75%|███████▌  | 449/595 [00:55<00:16,  8.94it/s] 76%|███████▌  | 450/595 [00:55<00:16,  9.00it/s] 76%|███████▌  | 451/595 [00:56<00:15,  9.02it/s] 76%|███████▌  | 452/595 [00:56<00:15,  8.97it/s] 76%|███████▌  | 453/595 [00:56<00:15,  9.12it/s] 76%|███████▋  | 454/595 [00:56<00:15,  9.02it/s] 76%|███████▋  | 455/595 [00:56<00:15,  9.05it/s] 77%|███████▋  | 456/595 [00:56<00:15,  9.03it/s] 77%|███████▋  | 457/595 [00:56<00:15,  9.07it/s] 77%|███████▋  | 458/595 [00:56<00:15,  9.03it/s] 77%|███████▋  | 459/595 [00:56<00:15,  8.99it/s] 77%|███████▋  | 460/595 [00:57<00:14,  9.04it/s] 77%|███████▋  | 461/595 [00:57<00:14,  9.06it/s] 78%|███████▊  | 462/595 [00:57<00:14,  9.07it/s] 78%|███████▊  | 463/595 [00:57<00:14,  9.18it/s] 78%|███████▊  | 464/595 [00:57<00:14,  9.05it/s] 78%|███████▊  | 465/595 [00:57<00:14,  9.02it/s] 78%|███████▊  | 466/595 [00:57<00:14,  9.04it/s] 78%|███████▊  | 467/595 [00:57<00:14,  9.10it/s] 79%|███████▊  | 468/595 [00:57<00:14,  9.06it/s] 79%|███████▉  | 469/595 [00:58<00:14,  8.96it/s] 79%|███████▉  | 470/595 [00:58<00:13,  8.95it/s] 79%|███████▉  | 471/595 [00:58<00:13,  8.99it/s] 79%|███████▉  | 472/595 [00:58<00:13,  9.09it/s] 79%|███████▉  | 473/595 [00:58<00:13,  9.15it/s] 80%|███████▉  | 474/595 [00:58<00:13,  9.12it/s] 80%|███████▉  | 475/595 [00:58<00:13,  9.16it/s]                                                  80%|████████  | 476/595 [00:58<00:12,  9.16it/s][INFO|trainer.py:755] 2023-11-15 19:24:17,869 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:24:17,871 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:24:17,871 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:24:17,872 >>   Batch size = 8
{'eval_loss': 0.44740116596221924, 'eval_accuracy': 0.8380952380952381, 'eval_micro_f1': 0.8380952380952381, 'eval_macro_f1': 0.7851108987835059, 'eval_runtime': 1.759, 'eval_samples_per_second': 537.246, 'eval_steps_per_second': 67.653, 'epoch': 3.0}
{'loss': 0.2159, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 82.77it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 76.45it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 72.61it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 72.64it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 71.46it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 71.36it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 72.43it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 70.43it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 70.03it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 70.13it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 71.16it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 69.97it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 69.97it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 69.73it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [01:00<00:12,  9.16it/s]
100%|██████████| 119/119 [00:01<00:00, 69.73it/s][A
                                                 [A 80%|████████  | 477/595 [01:00<00:58,  2.02it/s] 80%|████████  | 478/595 [01:00<00:46,  2.51it/s] 81%|████████  | 479/595 [01:00<00:37,  3.08it/s] 81%|████████  | 480/595 [01:00<00:30,  3.75it/s] 81%|████████  | 481/595 [01:01<00:25,  4.50it/s] 81%|████████  | 482/595 [01:01<00:21,  5.24it/s] 81%|████████  | 483/595 [01:01<00:18,  5.93it/s] 81%|████████▏ | 484/595 [01:01<00:16,  6.58it/s] 82%|████████▏ | 485/595 [01:01<00:15,  7.17it/s] 82%|████████▏ | 486/595 [01:01<00:14,  7.66it/s] 82%|████████▏ | 487/595 [01:01<00:13,  7.96it/s] 82%|████████▏ | 488/595 [01:01<00:12,  8.28it/s] 82%|████████▏ | 489/595 [01:01<00:12,  8.49it/s] 82%|████████▏ | 490/595 [01:02<00:12,  8.67it/s] 83%|████████▎ | 491/595 [01:02<00:11,  8.88it/s] 83%|████████▎ | 492/595 [01:02<00:11,  8.84it/s] 83%|████████▎ | 493/595 [01:02<00:11,  8.90it/s] 83%|████████▎ | 494/595 [01:02<00:11,  8.89it/s] 83%|████████▎ | 495/595 [01:02<00:11,  8.98it/s] 83%|████████▎ | 496/595 [01:02<00:11,  8.92it/s] 84%|████████▎ | 497/595 [01:02<00:10,  8.95it/s] 84%|████████▎ | 498/595 [01:02<00:10,  8.91it/s] 84%|████████▍ | 499/595 [01:03<00:10,  8.97it/s] 84%|████████▍ | 500/595 [01:03<00:10,  9.00it/s] 84%|████████▍ | 501/595 [01:03<00:10,  9.02it/s] 84%|████████▍ | 502/595 [01:03<00:10,  8.93it/s] 85%|████████▍ | 503/595 [01:03<00:10,  8.94it/s] 85%|████████▍ | 504/595 [01:03<00:10,  9.01it/s] 85%|████████▍ | 505/595 [01:03<00:09,  9.01it/s] 85%|████████▌ | 506/595 [01:03<00:09,  8.97it/s] 85%|████████▌ | 507/595 [01:03<00:09,  9.04it/s] 85%|████████▌ | 508/595 [01:04<00:09,  9.04it/s] 86%|████████▌ | 509/595 [01:04<00:09,  9.08it/s] 86%|████████▌ | 510/595 [01:04<00:09,  8.96it/s] 86%|████████▌ | 511/595 [01:04<00:09,  9.06it/s] 86%|████████▌ | 512/595 [01:04<00:09,  9.01it/s] 86%|████████▌ | 513/595 [01:04<00:09,  8.98it/s] 86%|████████▋ | 514/595 [01:04<00:08,  9.08it/s] 87%|████████▋ | 515/595 [01:04<00:08,  8.97it/s] 87%|████████▋ | 516/595 [01:04<00:08,  8.95it/s] 87%|████████▋ | 517/595 [01:05<00:08,  8.98it/s] 87%|████████▋ | 518/595 [01:05<00:08,  9.01it/s] 87%|████████▋ | 519/595 [01:05<00:08,  9.00it/s] 87%|████████▋ | 520/595 [01:05<00:08,  8.90it/s] 88%|████████▊ | 521/595 [01:05<00:08,  8.92it/s] 88%|████████▊ | 522/595 [01:05<00:08,  8.94it/s] 88%|████████▊ | 523/595 [01:05<00:08,  8.98it/s] 88%|████████▊ | 524/595 [01:05<00:07,  9.07it/s] 88%|████████▊ | 525/595 [01:05<00:07,  8.97it/s] 88%|████████▊ | 526/595 [01:06<00:07,  8.98it/s] 89%|████████▊ | 527/595 [01:06<00:07,  9.02it/s] 89%|████████▊ | 528/595 [01:06<00:07,  9.07it/s] 89%|████████▉ | 529/595 [01:06<00:07,  8.98it/s] 89%|████████▉ | 530/595 [01:06<00:07,  8.96it/s] 89%|████████▉ | 531/595 [01:06<00:07,  8.94it/s] 89%|████████▉ | 532/595 [01:06<00:07,  8.96it/s] 90%|████████▉ | 533/595 [01:06<00:06,  8.94it/s] 90%|████████▉ | 534/595 [01:06<00:06,  9.00it/s] 90%|████████▉ | 535/595 [01:07<00:06,  8.96it/s] 90%|█████████ | 536/595 [01:07<00:06,  8.98it/s] 90%|█████████ | 537/595 [01:07<00:06,  9.05it/s] 90%|█████████ | 538/595 [01:07<00:06,  9.01it/s] 91%|█████████ | 539/595 [01:07<00:06,  8.94it/s] 91%|█████████ | 540/595 [01:07<00:06,  8.96it/s] 91%|█████████ | 541/595 [01:07<00:05,  9.00it/s] 91%|█████████ | 542/595 [01:07<00:05,  9.03it/s] 91%|█████████▏| 543/595 [01:07<00:05,  8.96it/s] 91%|█████████▏| 544/595 [01:08<00:05,  9.02it/s] 92%|█████████▏| 545/595 [01:08<00:05,  9.08it/s] 92%|█████████▏| 546/595 [01:08<00:05,  9.07it/s] 92%|█████████▏| 547/595 [01:08<00:05,  9.16it/s] 92%|█████████▏| 548/595 [01:08<00:05,  8.87it/s] 92%|█████████▏| 549/595 [01:08<00:05,  8.90it/s] 92%|█████████▏| 550/595 [01:08<00:05,  8.90it/s] 93%|█████████▎| 551/595 [01:08<00:04,  8.97it/s] 93%|█████████▎| 552/595 [01:08<00:04,  8.89it/s] 93%|█████████▎| 553/595 [01:09<00:04,  8.86it/s] 93%|█████████▎| 554/595 [01:09<00:04,  8.88it/s] 93%|█████████▎| 555/595 [01:09<00:04,  8.96it/s] 93%|█████████▎| 556/595 [01:09<00:04,  8.91it/s] 94%|█████████▎| 557/595 [01:09<00:04,  9.03it/s] 94%|█████████▍| 558/595 [01:09<00:04,  9.03it/s] 94%|█████████▍| 559/595 [01:09<00:03,  9.07it/s] 94%|█████████▍| 560/595 [01:09<00:03,  9.12it/s] 94%|█████████▍| 561/595 [01:09<00:03,  9.10it/s] 94%|█████████▍| 562/595 [01:10<00:03,  8.98it/s] 95%|█████████▍| 563/595 [01:10<00:03,  8.98it/s] 95%|█████████▍| 564/595 [01:10<00:03,  9.00it/s] 95%|█████████▍| 565/595 [01:10<00:03,  9.00it/s] 95%|█████████▌| 566/595 [01:10<00:03,  8.97it/s] 95%|█████████▌| 567/595 [01:10<00:03,  9.03it/s] 95%|█████████▌| 568/595 [01:10<00:02,  9.01it/s] 96%|█████████▌| 569/595 [01:10<00:02,  9.04it/s] 96%|█████████▌| 570/595 [01:10<00:02,  9.19it/s] 96%|█████████▌| 571/595 [01:11<00:02,  9.07it/s] 96%|█████████▌| 572/595 [01:11<00:02,  9.01it/s] 96%|█████████▋| 573/595 [01:11<00:02,  9.01it/s] 96%|█████████▋| 574/595 [01:11<00:02,  9.05it/s] 97%|█████████▋| 575/595 [01:11<00:02,  9.04it/s] 97%|█████████▋| 576/595 [01:11<00:02,  8.96it/s] 97%|█████████▋| 577/595 [01:11<00:01,  9.00it/s] 97%|█████████▋| 578/595 [01:11<00:01,  8.99it/s] 97%|█████████▋| 579/595 [01:11<00:01,  8.99it/s] 97%|█████████▋| 580/595 [01:12<00:01,  9.03it/s] 98%|█████████▊| 581/595 [01:12<00:01,  8.93it/s] 98%|█████████▊| 582/595 [01:12<00:01,  8.96it/s] 98%|█████████▊| 583/595 [01:12<00:01,  8.90it/s] 98%|█████████▊| 584/595 [01:12<00:01,  8.94it/s] 98%|█████████▊| 585/595 [01:12<00:01,  8.92it/s] 98%|█████████▊| 586/595 [01:12<00:01,  8.91it/s] 99%|█████████▊| 587/595 [01:12<00:00,  8.93it/s] 99%|█████████▉| 588/595 [01:12<00:00,  8.91it/s] 99%|█████████▉| 589/595 [01:13<00:00,  8.93it/s] 99%|█████████▉| 590/595 [01:13<00:00,  9.08it/s] 99%|█████████▉| 591/595 [01:13<00:00,  8.98it/s] 99%|█████████▉| 592/595 [01:13<00:00,  9.01it/s]100%|█████████▉| 593/595 [01:13<00:00,  9.01it/s]100%|█████████▉| 594/595 [01:13<00:00,  9.14it/s]                                                 100%|██████████| 595/595 [01:13<00:00,  9.14it/s][INFO|trainer.py:755] 2023-11-15 19:24:32,762 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:24:32,764 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:24:32,765 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:24:32,765 >>   Batch size = 8
{'eval_loss': 0.4870011508464813, 'eval_accuracy': 0.8507936507936508, 'eval_micro_f1': 0.8507936507936508, 'eval_macro_f1': 0.7898348070789244, 'eval_runtime': 1.7265, 'eval_samples_per_second': 547.349, 'eval_steps_per_second': 68.925, 'epoch': 4.0}
{'loss': 0.1506, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 80.70it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 74.10it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 70.79it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 69.95it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 70.09it/s][A
 42%|████▏     | 50/119 [00:00<00:01, 67.27it/s][A
 48%|████▊     | 57/119 [00:00<00:00, 67.95it/s][A
 54%|█████▍    | 64/119 [00:00<00:00, 67.63it/s][A
 60%|█████▉    | 71/119 [00:01<00:00, 68.06it/s][A
 66%|██████▌   | 78/119 [00:01<00:00, 68.49it/s][A
 71%|███████▏  | 85/119 [00:01<00:00, 68.70it/s][A
 78%|███████▊  | 93/119 [00:01<00:00, 69.53it/s][A
 84%|████████▍ | 100/119 [00:01<00:00, 66.39it/s][A
 90%|████████▉ | 107/119 [00:01<00:00, 67.27it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 67.36it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:15<00:00,  9.14it/s]
100%|██████████| 119/119 [00:01<00:00, 67.36it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 19:24:34,544 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:15<00:00,  9.14it/s]100%|██████████| 595/595 [01:15<00:00,  7.89it/s]
[INFO|trainer.py:2855] 2023-11-15 19:24:34,548 >> Saving model checkpoint to ./result/restaurant_bert-base-cased_adapter__seed0
[INFO|configuration_utils.py:460] 2023-11-15 19:24:34,551 >> Configuration saved in ./result/restaurant_bert-base-cased_adapter__seed0/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:24:35,865 >> Model weights saved in ./result/restaurant_bert-base-cased_adapter__seed0/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:24:35,868 >> tokenizer config file saved in ./result/restaurant_bert-base-cased_adapter__seed0/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:24:35,870 >> Special tokens file saved in ./result/restaurant_bert-base-cased_adapter__seed0/special_tokens_map.json
{'eval_loss': 0.49590635299682617, 'eval_accuracy': 0.8518518518518519, 'eval_micro_f1': 0.8518518518518519, 'eval_macro_f1': 0.8023441560026926, 'eval_runtime': 1.7752, 'eval_samples_per_second': 532.324, 'eval_steps_per_second': 67.033, 'epoch': 5.0}
{'train_runtime': 75.4138, 'train_samples_per_second': 250.418, 'train_steps_per_second': 7.89, 'train_loss': 0.3705420550178079, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3705
  train_runtime            = 0:01:15.41
  train_samples            =       3777
  train_samples_per_second =    250.418
  train_steps_per_second   =       7.89
11/15/2023 19:24:35 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:24:35,911 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:24:35,913 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:24:35,914 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:24:35,914 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  8%|▊         | 9/119 [00:00<00:01, 83.98it/s] 15%|█▌        | 18/119 [00:00<00:01, 72.73it/s] 22%|██▏       | 26/119 [00:00<00:01, 72.27it/s] 29%|██▊       | 34/119 [00:00<00:01, 71.63it/s] 35%|███▌      | 42/119 [00:00<00:01, 72.25it/s] 42%|████▏     | 50/119 [00:00<00:00, 69.36it/s] 49%|████▊     | 58/119 [00:00<00:00, 69.41it/s] 55%|█████▌    | 66/119 [00:00<00:00, 69.80it/s] 62%|██████▏   | 74/119 [00:01<00:00, 70.76it/s] 69%|██████▉   | 82/119 [00:01<00:00, 71.73it/s] 76%|███████▌  | 90/119 [00:01<00:00, 69.21it/s] 82%|████████▏ | 98/119 [00:01<00:00, 70.05it/s] 89%|████████▉ | 106/119 [00:01<00:00, 70.64it/s] 96%|█████████▌| 114/119 [00:01<00:00, 70.57it/s]100%|██████████| 119/119 [00:01<00:00, 69.77it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8519
  eval_loss               =     0.4959
  eval_macro_f1           =     0.8023
  eval_micro_f1           =     0.8519
  eval_runtime            = 0:00:01.72
  eval_samples            =        945
  eval_samples_per_second =    547.942
  eval_steps_per_second   =       69.0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▅▆███
wandb:                      eval/loss █▃▁▄▅▅
wandb:                  eval/macro_f1 ▁▅▇▇██
wandb:                  eval/micro_f1 ▁▅▆███
wandb:                   eval/runtime ▄▁▆▃█▂
wandb:        eval/samples_per_second ▅█▃▆▁▇
wandb:          eval/steps_per_second ▅█▃▆▁▇
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.85185
wandb:                      eval/loss 0.49591
wandb:                  eval/macro_f1 0.80234
wandb:                  eval/micro_f1 0.85185
wandb:                   eval/runtime 1.7246
wandb:        eval/samples_per_second 547.942
wandb:          eval/steps_per_second 69.0
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1506
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.37054
wandb:            train/train_runtime 75.4138
wandb: train/train_samples_per_second 250.418
wandb:   train/train_steps_per_second 7.89
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_192230-73kw7ska
wandb: Find logs at: ./wandb/offline-run-20231115_192230-73kw7ska/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0/runs/Nov15_19-24-48_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:24:48 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:24:48 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0/runs/Nov15_19-24-47_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  83%|████████▎ | 3921/4722 [00:00<00:00, 39003.32 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 38124.83 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 19:25:04,855 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:25:04,866 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 19:25:14,882 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 19:25:24,901 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:25:24,902 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:25:44,940 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:25:44,941 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:25:44,941 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:25:44,942 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:25:44,942 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 19:25:44,943 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:25:44,944 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 19:25:44,967 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:25:44,967 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:26:05,971 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 19:26:07,871 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:26:07,872 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 20253.50 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 19950.97 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 25921.41 examples/s]
11/15/2023 19:26:08 - INFO - __main__ - Sample 3388 of the training set: {'text': 'food <SEP> Had dinner here on a Friday and the food was great.', 'label': 0, 'input_ids': [102, 2599, 962, 9892, 1374, 883, 11764, 1347, 1530, 191, 106, 5438, 3113, 137, 111, 2599, 241, 2815, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:26:08 - INFO - __main__ - Sample 871 of the training set: {'text': 'drinks <SEP> You get what you pay for and with that logic in mind, Spice is a great place to grab some cheap eats and drinks in a beautiful setting.', 'label': 0, 'input_ids': [102, 25409, 962, 9892, 1374, 3034, 2744, 1792, 3034, 3982, 168, 137, 190, 198, 4856, 121, 6262, 422, 14621, 176, 165, 106, 2815, 2608, 147, 29530, 693, 20896, 17692, 30113, 137, 25409, 121, 106, 25724, 3238, 161, 2707, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:26:08 - INFO - __main__ - Sample 3773 of the training set: {'text': 'food <SEP> Good service, great food, good value, and never have to wait in line!', 'label': 0, 'input_ids': [102, 2599, 962, 9892, 1374, 1846, 2289, 422, 2815, 2599, 422, 1846, 973, 422, 137, 3449, 360, 147, 13775, 121, 972, 3190, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:26:08 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:26:09,759 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:26:09,766 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:26:09,767 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 19:26:09,767 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:26:09,767 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:26:09,768 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:26:09,768 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:26:09,768 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 19:26:09,769 >>   Number of trainable parameters = 109,920,771
[INFO|integration_utils.py:716] 2023-11-15 19:26:09,770 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<15:27,  1.56s/it]  0%|          | 2/595 [00:01<07:00,  1.41it/s]  1%|          | 3/595 [00:01<04:17,  2.30it/s]  1%|          | 4/595 [00:01<03:00,  3.27it/s]  1%|          | 5/595 [00:02<02:18,  4.25it/s]  1%|          | 6/595 [00:02<01:54,  5.17it/s]  1%|          | 7/595 [00:02<01:38,  5.99it/s]  1%|▏         | 8/595 [00:02<01:27,  6.68it/s]  2%|▏         | 9/595 [00:02<01:20,  7.25it/s]  2%|▏         | 10/595 [00:02<01:15,  7.74it/s]  2%|▏         | 11/595 [00:02<01:11,  8.17it/s]  2%|▏         | 12/595 [00:02<01:09,  8.36it/s]  2%|▏         | 13/595 [00:02<01:08,  8.54it/s]  2%|▏         | 14/595 [00:02<01:06,  8.75it/s]  3%|▎         | 15/595 [00:03<01:05,  8.80it/s]  3%|▎         | 16/595 [00:03<01:04,  8.91it/s]  3%|▎         | 17/595 [00:03<01:04,  8.98it/s]  3%|▎         | 18/595 [00:03<01:03,  9.13it/s]  3%|▎         | 19/595 [00:03<01:04,  8.99it/s]  3%|▎         | 20/595 [00:03<01:03,  9.03it/s]  4%|▎         | 21/595 [00:03<01:03,  9.05it/s]  4%|▎         | 22/595 [00:03<01:03,  9.06it/s]  4%|▍         | 23/595 [00:03<01:03,  9.06it/s]  4%|▍         | 24/595 [00:04<01:03,  9.06it/s]  4%|▍         | 25/595 [00:04<01:01,  9.25it/s]  4%|▍         | 26/595 [00:04<01:02,  9.15it/s]  5%|▍         | 27/595 [00:04<01:02,  9.11it/s]  5%|▍         | 28/595 [00:04<01:02,  9.07it/s]  5%|▍         | 29/595 [00:04<01:02,  9.01it/s]  5%|▌         | 30/595 [00:04<01:02,  9.08it/s]  5%|▌         | 31/595 [00:04<01:02,  9.01it/s]  5%|▌         | 32/595 [00:04<01:01,  9.21it/s]  6%|▌         | 33/595 [00:05<01:01,  9.09it/s]  6%|▌         | 34/595 [00:05<01:01,  9.07it/s]  6%|▌         | 35/595 [00:05<01:01,  9.06it/s]  6%|▌         | 36/595 [00:05<01:01,  9.05it/s]  6%|▌         | 37/595 [00:05<01:01,  9.06it/s]  6%|▋         | 38/595 [00:05<01:01,  9.08it/s]  7%|▋         | 39/595 [00:05<01:00,  9.27it/s]  7%|▋         | 40/595 [00:05<01:00,  9.11it/s]  7%|▋         | 41/595 [00:05<01:01,  9.03it/s]  7%|▋         | 42/595 [00:06<01:01,  9.05it/s]  7%|▋         | 43/595 [00:06<01:00,  9.07it/s]  7%|▋         | 44/595 [00:06<01:00,  9.08it/s]  8%|▊         | 45/595 [00:06<01:01,  9.02it/s]  8%|▊         | 46/595 [00:06<01:00,  9.10it/s]  8%|▊         | 47/595 [00:06<01:00,  9.12it/s]  8%|▊         | 48/595 [00:06<01:00,  9.09it/s]  8%|▊         | 49/595 [00:06<01:00,  9.04it/s]  8%|▊         | 50/595 [00:06<01:00,  9.08it/s]  9%|▊         | 51/595 [00:07<00:59,  9.17it/s]  9%|▊         | 52/595 [00:07<00:59,  9.06it/s]  9%|▉         | 53/595 [00:07<00:59,  9.18it/s]  9%|▉         | 54/595 [00:07<00:59,  9.13it/s]  9%|▉         | 55/595 [00:07<00:59,  9.11it/s]  9%|▉         | 56/595 [00:07<00:59,  9.00it/s] 10%|▉         | 57/595 [00:07<00:59,  9.01it/s] 10%|▉         | 58/595 [00:07<00:59,  9.05it/s] 10%|▉         | 59/595 [00:07<00:59,  8.95it/s] 10%|█         | 60/595 [00:08<00:58,  9.09it/s] 10%|█         | 61/595 [00:08<00:59,  9.05it/s] 10%|█         | 62/595 [00:08<00:58,  9.13it/s] 11%|█         | 63/595 [00:08<00:58,  9.11it/s] 11%|█         | 64/595 [00:08<00:58,  9.15it/s] 11%|█         | 65/595 [00:08<00:58,  9.08it/s] 11%|█         | 66/595 [00:08<00:58,  9.08it/s] 11%|█▏        | 67/595 [00:08<00:58,  9.02it/s] 11%|█▏        | 68/595 [00:08<00:58,  9.02it/s] 12%|█▏        | 69/595 [00:09<00:58,  9.04it/s] 12%|█▏        | 70/595 [00:09<00:57,  9.06it/s] 12%|█▏        | 71/595 [00:09<00:57,  9.09it/s] 12%|█▏        | 72/595 [00:09<00:58,  9.00it/s] 12%|█▏        | 73/595 [00:09<00:58,  8.95it/s] 12%|█▏        | 74/595 [00:09<00:57,  9.01it/s] 13%|█▎        | 75/595 [00:09<00:58,  8.94it/s] 13%|█▎        | 76/595 [00:09<00:57,  8.96it/s] 13%|█▎        | 77/595 [00:09<00:57,  9.05it/s] 13%|█▎        | 78/595 [00:10<00:57,  9.02it/s] 13%|█▎        | 79/595 [00:10<00:57,  8.95it/s] 13%|█▎        | 80/595 [00:10<00:57,  9.02it/s] 14%|█▎        | 81/595 [00:10<00:57,  8.98it/s] 14%|█▍        | 82/595 [00:10<00:57,  8.98it/s] 14%|█▍        | 83/595 [00:10<00:56,  9.03it/s] 14%|█▍        | 84/595 [00:10<00:56,  9.12it/s] 14%|█▍        | 85/595 [00:10<00:56,  9.05it/s] 14%|█▍        | 86/595 [00:10<00:56,  9.03it/s] 15%|█▍        | 87/595 [00:11<00:56,  9.03it/s] 15%|█▍        | 88/595 [00:11<00:56,  9.05it/s] 15%|█▍        | 89/595 [00:11<00:56,  9.00it/s] 15%|█▌        | 90/595 [00:11<00:55,  9.03it/s] 15%|█▌        | 91/595 [00:11<00:54,  9.21it/s] 15%|█▌        | 92/595 [00:11<00:55,  9.13it/s] 16%|█▌        | 93/595 [00:11<00:55,  9.07it/s] 16%|█▌        | 94/595 [00:11<00:54,  9.11it/s] 16%|█▌        | 95/595 [00:11<00:55,  9.05it/s] 16%|█▌        | 96/595 [00:12<00:55,  9.05it/s] 16%|█▋        | 97/595 [00:12<00:55,  9.05it/s] 16%|█▋        | 98/595 [00:12<00:54,  9.11it/s] 17%|█▋        | 99/595 [00:12<00:55,  9.01it/s] 17%|█▋        | 100/595 [00:12<00:55,  8.99it/s] 17%|█▋        | 101/595 [00:12<00:55,  8.96it/s] 17%|█▋        | 102/595 [00:12<00:54,  8.97it/s] 17%|█▋        | 103/595 [00:12<00:54,  9.03it/s] 17%|█▋        | 104/595 [00:12<00:54,  8.95it/s] 18%|█▊        | 105/595 [00:13<00:53,  9.15it/s] 18%|█▊        | 106/595 [00:13<00:54,  9.00it/s] 18%|█▊        | 107/595 [00:13<00:54,  8.95it/s] 18%|█▊        | 108/595 [00:13<00:54,  8.93it/s] 18%|█▊        | 109/595 [00:13<00:54,  8.96it/s] 18%|█▊        | 110/595 [00:13<00:53,  8.98it/s] 19%|█▊        | 111/595 [00:13<00:54,  8.92it/s] 19%|█▉        | 112/595 [00:13<00:53,  9.04it/s] 19%|█▉        | 113/595 [00:13<00:53,  9.01it/s] 19%|█▉        | 114/595 [00:14<00:53,  9.05it/s] 19%|█▉        | 115/595 [00:14<00:53,  9.00it/s] 19%|█▉        | 116/595 [00:14<00:52,  9.07it/s] 20%|█▉        | 117/595 [00:14<00:53,  8.99it/s] 20%|█▉        | 118/595 [00:14<00:53,  9.00it/s]                                                  20%|██        | 119/595 [00:14<00:52,  9.00it/s][INFO|trainer.py:755] 2023-11-15 19:26:24,318 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:26:24,320 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:26:24,320 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:26:24,321 >>   Batch size = 8
{'loss': 0.7304, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 75.44it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 69.19it/s][A
 19%|█▉        | 23/119 [00:00<00:01, 69.07it/s][A
 25%|██▌       | 30/119 [00:00<00:01, 68.30it/s][A
 31%|███       | 37/119 [00:00<00:01, 68.36it/s][A
 37%|███▋      | 44/119 [00:00<00:01, 68.15it/s][A
 43%|████▎     | 51/119 [00:00<00:01, 67.45it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 67.85it/s][A
 55%|█████▍    | 65/119 [00:00<00:00, 68.10it/s][A
 61%|██████    | 72/119 [00:01<00:00, 68.30it/s][A
 67%|██████▋   | 80/119 [00:01<00:00, 69.78it/s][A
 73%|███████▎  | 87/119 [00:01<00:00, 67.29it/s][A
 79%|███████▉  | 94/119 [00:01<00:00, 65.91it/s][A
 85%|████████▍ | 101/119 [00:01<00:00, 66.69it/s][A
 92%|█████████▏| 109/119 [00:01<00:00, 67.14it/s][A
 97%|█████████▋| 116/119 [00:01<00:00, 67.74it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:16<00:52,  9.00it/s]
100%|██████████| 119/119 [00:01<00:00, 67.74it/s][A
                                                 [A 20%|██        | 120/595 [00:16<04:03,  1.95it/s] 20%|██        | 121/595 [00:16<03:16,  2.42it/s] 21%|██        | 122/595 [00:16<02:38,  2.98it/s] 21%|██        | 123/595 [00:16<02:09,  3.64it/s] 21%|██        | 124/595 [00:16<01:46,  4.40it/s] 21%|██        | 125/595 [00:17<01:31,  5.12it/s] 21%|██        | 126/595 [00:17<01:20,  5.85it/s] 21%|██▏       | 127/595 [00:17<01:11,  6.53it/s] 22%|██▏       | 128/595 [00:17<01:06,  7.05it/s] 22%|██▏       | 129/595 [00:17<01:01,  7.56it/s] 22%|██▏       | 130/595 [00:17<00:58,  7.91it/s] 22%|██▏       | 131/595 [00:17<00:56,  8.27it/s] 22%|██▏       | 132/595 [00:17<00:54,  8.43it/s] 22%|██▏       | 133/595 [00:17<00:53,  8.61it/s] 23%|██▎       | 134/595 [00:18<00:53,  8.68it/s] 23%|██▎       | 135/595 [00:18<00:52,  8.77it/s] 23%|██▎       | 136/595 [00:18<00:51,  8.87it/s] 23%|██▎       | 137/595 [00:18<00:51,  8.84it/s] 23%|██▎       | 138/595 [00:18<00:51,  8.93it/s] 23%|██▎       | 139/595 [00:18<00:50,  8.98it/s] 24%|██▎       | 140/595 [00:18<00:50,  9.03it/s] 24%|██▎       | 141/595 [00:18<00:50,  8.97it/s] 24%|██▍       | 142/595 [00:18<00:50,  9.00it/s] 24%|██▍       | 143/595 [00:19<00:50,  8.99it/s] 24%|██▍       | 144/595 [00:19<00:50,  8.95it/s] 24%|██▍       | 145/595 [00:19<00:49,  9.00it/s] 25%|██▍       | 146/595 [00:19<00:49,  9.04it/s] 25%|██▍       | 147/595 [00:19<00:49,  9.02it/s] 25%|██▍       | 148/595 [00:19<00:49,  9.07it/s] 25%|██▌       | 149/595 [00:19<00:49,  9.08it/s] 25%|██▌       | 150/595 [00:19<00:49,  9.01it/s] 25%|██▌       | 151/595 [00:19<00:49,  8.92it/s] 26%|██▌       | 152/595 [00:20<00:49,  9.01it/s] 26%|██▌       | 153/595 [00:20<00:49,  8.95it/s] 26%|██▌       | 154/595 [00:20<00:48,  9.00it/s] 26%|██▌       | 155/595 [00:20<00:48,  9.03it/s] 26%|██▌       | 156/595 [00:20<00:48,  9.07it/s] 26%|██▋       | 157/595 [00:20<00:48,  9.01it/s] 27%|██▋       | 158/595 [00:20<00:48,  8.95it/s] 27%|██▋       | 159/595 [00:20<00:48,  9.00it/s] 27%|██▋       | 160/595 [00:20<00:48,  8.94it/s] 27%|██▋       | 161/595 [00:21<00:48,  8.98it/s] 27%|██▋       | 162/595 [00:21<00:47,  9.04it/s] 27%|██▋       | 163/595 [00:21<00:47,  9.00it/s] 28%|██▊       | 164/595 [00:21<00:48,  8.88it/s] 28%|██▊       | 165/595 [00:21<00:48,  8.91it/s] 28%|██▊       | 166/595 [00:21<00:47,  8.94it/s] 28%|██▊       | 167/595 [00:21<00:48,  8.91it/s] 28%|██▊       | 168/595 [00:21<00:47,  8.94it/s] 28%|██▊       | 169/595 [00:21<00:47,  9.05it/s] 29%|██▊       | 170/595 [00:22<00:47,  8.93it/s] 29%|██▊       | 171/595 [00:22<00:47,  8.84it/s] 29%|██▉       | 172/595 [00:22<00:47,  8.84it/s] 29%|██▉       | 173/595 [00:22<00:47,  8.95it/s] 29%|██▉       | 174/595 [00:22<00:47,  8.90it/s] 29%|██▉       | 175/595 [00:22<00:46,  8.94it/s] 30%|██▉       | 176/595 [00:22<00:46,  9.02it/s] 30%|██▉       | 177/595 [00:22<00:46,  8.99it/s] 30%|██▉       | 178/595 [00:22<00:46,  8.89it/s] 30%|███       | 179/595 [00:23<00:46,  8.87it/s] 30%|███       | 180/595 [00:23<00:47,  8.81it/s] 30%|███       | 181/595 [00:23<00:46,  8.88it/s] 31%|███       | 182/595 [00:23<00:46,  8.91it/s] 31%|███       | 183/595 [00:23<00:45,  9.06it/s] 31%|███       | 184/595 [00:23<00:46,  8.91it/s] 31%|███       | 185/595 [00:23<00:45,  8.92it/s] 31%|███▏      | 186/595 [00:23<00:45,  8.94it/s] 31%|███▏      | 187/595 [00:23<00:45,  8.92it/s] 32%|███▏      | 188/595 [00:24<00:45,  9.01it/s] 32%|███▏      | 189/595 [00:24<00:45,  8.99it/s] 32%|███▏      | 190/595 [00:24<00:44,  9.06it/s] 32%|███▏      | 191/595 [00:24<00:44,  9.01it/s] 32%|███▏      | 192/595 [00:24<00:44,  8.99it/s] 32%|███▏      | 193/595 [00:24<00:44,  9.02it/s] 33%|███▎      | 194/595 [00:24<00:44,  9.03it/s] 33%|███▎      | 195/595 [00:24<00:44,  8.97it/s] 33%|███▎      | 196/595 [00:24<00:44,  8.91it/s] 33%|███▎      | 197/595 [00:25<00:44,  9.01it/s] 33%|███▎      | 198/595 [00:25<00:43,  9.05it/s] 33%|███▎      | 199/595 [00:25<00:43,  9.04it/s] 34%|███▎      | 200/595 [00:25<00:43,  9.05it/s] 34%|███▍      | 201/595 [00:25<00:43,  9.06it/s] 34%|███▍      | 202/595 [00:25<00:43,  8.98it/s] 34%|███▍      | 203/595 [00:25<00:43,  8.96it/s] 34%|███▍      | 204/595 [00:25<00:43,  9.00it/s] 34%|███▍      | 205/595 [00:25<00:43,  8.98it/s] 35%|███▍      | 206/595 [00:26<00:43,  9.04it/s] 35%|███▍      | 207/595 [00:26<00:42,  9.07it/s] 35%|███▍      | 208/595 [00:26<00:42,  9.08it/s] 35%|███▌      | 209/595 [00:26<00:42,  9.00it/s] 35%|███▌      | 210/595 [00:26<00:42,  9.01it/s] 35%|███▌      | 211/595 [00:26<00:42,  8.97it/s] 36%|███▌      | 212/595 [00:26<00:42,  8.99it/s] 36%|███▌      | 213/595 [00:26<00:42,  9.01it/s] 36%|███▌      | 214/595 [00:26<00:41,  9.08it/s] 36%|███▌      | 215/595 [00:27<00:42,  9.01it/s] 36%|███▋      | 216/595 [00:27<00:42,  8.93it/s] 36%|███▋      | 217/595 [00:27<00:42,  8.93it/s] 37%|███▋      | 218/595 [00:27<00:42,  8.92it/s] 37%|███▋      | 219/595 [00:27<00:42,  8.94it/s] 37%|███▋      | 220/595 [00:27<00:41,  8.93it/s] 37%|███▋      | 221/595 [00:27<00:41,  9.07it/s] 37%|███▋      | 222/595 [00:27<00:41,  8.98it/s] 37%|███▋      | 223/595 [00:27<00:41,  8.99it/s] 38%|███▊      | 224/595 [00:28<00:41,  8.95it/s] 38%|███▊      | 225/595 [00:28<00:41,  8.97it/s] 38%|███▊      | 226/595 [00:28<00:41,  8.96it/s] 38%|███▊      | 227/595 [00:28<00:41,  8.88it/s] 38%|███▊      | 228/595 [00:28<00:40,  9.02it/s] 38%|███▊      | 229/595 [00:28<00:40,  9.00it/s] 39%|███▊      | 230/595 [00:28<00:40,  8.97it/s] 39%|███▉      | 231/595 [00:28<00:40,  8.97it/s] 39%|███▉      | 232/595 [00:28<00:40,  9.00it/s] 39%|███▉      | 233/595 [00:29<00:40,  8.97it/s] 39%|███▉      | 234/595 [00:29<00:40,  8.86it/s] 39%|███▉      | 235/595 [00:29<00:40,  8.95it/s] 40%|███▉      | 236/595 [00:29<00:40,  8.96it/s] 40%|███▉      | 237/595 [00:29<00:39,  9.09it/s]                                                  40%|████      | 238/595 [00:29<00:39,  9.09it/s][INFO|trainer.py:755] 2023-11-15 19:26:39,302 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:26:39,304 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:26:39,305 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:26:39,305 >>   Batch size = 8
{'eval_loss': 0.5671906471252441, 'eval_accuracy': 0.7767195767195767, 'eval_micro_f1': 0.7767195767195768, 'eval_macro_f1': 0.6506670083552359, 'eval_runtime': 1.7937, 'eval_samples_per_second': 526.851, 'eval_steps_per_second': 66.344, 'epoch': 1.0}
{'loss': 0.4762, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 81.94it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 75.81it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 72.62it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 73.43it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 70.66it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 70.44it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 69.81it/s][A
 55%|█████▍    | 65/119 [00:00<00:00, 69.71it/s][A
 61%|██████    | 72/119 [00:01<00:00, 68.96it/s][A
 66%|██████▋   | 79/119 [00:01<00:00, 68.91it/s][A
 73%|███████▎  | 87/119 [00:01<00:00, 70.85it/s][A
 80%|███████▉  | 95/119 [00:01<00:00, 68.17it/s][A
 86%|████████▌ | 102/119 [00:01<00:00, 68.67it/s][A
 92%|█████████▏| 109/119 [00:01<00:00, 68.59it/s][A
 98%|█████████▊| 117/119 [00:01<00:00, 69.58it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:31<00:39,  9.09it/s]
100%|██████████| 119/119 [00:01<00:00, 69.58it/s][A
                                                 [A 40%|████      | 239/595 [00:31<02:57,  2.01it/s] 40%|████      | 240/595 [00:31<02:22,  2.49it/s] 41%|████      | 241/595 [00:31<01:55,  3.06it/s] 41%|████      | 242/595 [00:31<01:34,  3.72it/s] 41%|████      | 243/595 [00:31<01:19,  4.45it/s] 41%|████      | 244/595 [00:31<01:07,  5.22it/s] 41%|████      | 245/595 [00:32<00:59,  5.87it/s] 41%|████▏     | 246/595 [00:32<00:53,  6.54it/s] 42%|████▏     | 247/595 [00:32<00:49,  7.04it/s] 42%|████▏     | 248/595 [00:32<00:46,  7.53it/s] 42%|████▏     | 249/595 [00:32<00:43,  7.91it/s] 42%|████▏     | 250/595 [00:32<00:42,  8.16it/s] 42%|████▏     | 251/595 [00:32<00:40,  8.40it/s] 42%|████▏     | 252/595 [00:32<00:40,  8.48it/s] 43%|████▎     | 253/595 [00:32<00:39,  8.56it/s] 43%|████▎     | 254/595 [00:33<00:39,  8.66it/s] 43%|████▎     | 255/595 [00:33<00:39,  8.70it/s] 43%|████▎     | 256/595 [00:33<00:38,  8.75it/s] 43%|████▎     | 257/595 [00:33<00:38,  8.78it/s] 43%|████▎     | 258/595 [00:33<00:38,  8.77it/s] 44%|████▎     | 259/595 [00:33<00:38,  8.74it/s] 44%|████▎     | 260/595 [00:33<00:38,  8.77it/s] 44%|████▍     | 261/595 [00:33<00:37,  8.93it/s] 44%|████▍     | 262/595 [00:33<00:37,  8.91it/s] 44%|████▍     | 263/595 [00:34<00:37,  8.86it/s] 44%|████▍     | 264/595 [00:34<00:37,  8.82it/s] 45%|████▍     | 265/595 [00:34<00:37,  8.82it/s] 45%|████▍     | 266/595 [00:34<00:37,  8.85it/s] 45%|████▍     | 267/595 [00:34<00:37,  8.85it/s] 45%|████▌     | 268/595 [00:34<00:36,  9.00it/s] 45%|████▌     | 269/595 [00:34<00:36,  8.83it/s] 45%|████▌     | 270/595 [00:34<00:36,  8.80it/s] 46%|████▌     | 271/595 [00:34<00:36,  8.87it/s] 46%|████▌     | 272/595 [00:35<00:36,  8.86it/s] 46%|████▌     | 273/595 [00:35<00:36,  8.91it/s] 46%|████▌     | 274/595 [00:35<00:36,  8.84it/s] 46%|████▌     | 275/595 [00:35<00:35,  8.90it/s] 46%|████▋     | 276/595 [00:35<00:36,  8.86it/s] 47%|████▋     | 277/595 [00:35<00:36,  8.82it/s] 47%|████▋     | 278/595 [00:35<00:35,  8.82it/s] 47%|████▋     | 279/595 [00:35<00:35,  8.88it/s] 47%|████▋     | 280/595 [00:36<00:35,  8.80it/s] 47%|████▋     | 281/595 [00:36<00:35,  8.76it/s] 47%|████▋     | 282/595 [00:36<00:35,  8.75it/s] 48%|████▊     | 283/595 [00:36<00:35,  8.76it/s] 48%|████▊     | 284/595 [00:36<00:35,  8.82it/s] 48%|████▊     | 285/595 [00:36<00:34,  8.90it/s] 48%|████▊     | 286/595 [00:36<00:34,  8.86it/s] 48%|████▊     | 287/595 [00:36<00:35,  8.75it/s] 48%|████▊     | 288/595 [00:36<00:34,  8.81it/s] 49%|████▊     | 289/595 [00:37<00:34,  8.80it/s] 49%|████▊     | 290/595 [00:37<00:34,  8.79it/s] 49%|████▉     | 291/595 [00:37<00:34,  8.86it/s] 49%|████▉     | 292/595 [00:37<00:33,  8.98it/s] 49%|████▉     | 293/595 [00:37<00:34,  8.86it/s] 49%|████▉     | 294/595 [00:37<00:34,  8.70it/s] 50%|████▉     | 295/595 [00:37<00:34,  8.71it/s] 50%|████▉     | 296/595 [00:37<00:34,  8.64it/s] 50%|████▉     | 297/595 [00:37<00:34,  8.75it/s] 50%|█████     | 298/595 [00:38<00:33,  8.78it/s] 50%|█████     | 299/595 [00:38<00:33,  8.93it/s] 50%|█████     | 300/595 [00:38<00:33,  8.78it/s] 51%|█████     | 301/595 [00:38<00:33,  8.82it/s] 51%|█████     | 302/595 [00:38<00:33,  8.74it/s] 51%|█████     | 303/595 [00:38<00:33,  8.71it/s] 51%|█████     | 304/595 [00:38<00:33,  8.76it/s] 51%|█████▏    | 305/595 [00:38<00:33,  8.77it/s] 51%|█████▏    | 306/595 [00:38<00:32,  8.89it/s] 52%|█████▏    | 307/595 [00:39<00:32,  8.80it/s] 52%|█████▏    | 308/595 [00:39<00:32,  8.78it/s] 52%|█████▏    | 309/595 [00:39<00:32,  8.68it/s] 52%|█████▏    | 310/595 [00:39<00:32,  8.65it/s] 52%|█████▏    | 311/595 [00:39<00:32,  8.72it/s] 52%|█████▏    | 312/595 [00:39<00:32,  8.70it/s] 53%|█████▎    | 313/595 [00:39<00:31,  8.83it/s] 53%|█████▎    | 314/595 [00:39<00:32,  8.73it/s] 53%|█████▎    | 315/595 [00:39<00:31,  8.75it/s] 53%|█████▎    | 316/595 [00:40<00:32,  8.69it/s] 53%|█████▎    | 317/595 [00:40<00:32,  8.66it/s] 53%|█████▎    | 318/595 [00:40<00:31,  8.71it/s] 54%|█████▎    | 319/595 [00:40<00:31,  8.64it/s] 54%|█████▍    | 320/595 [00:40<00:31,  8.77it/s] 54%|█████▍    | 321/595 [00:40<00:31,  8.67it/s] 54%|█████▍    | 322/595 [00:40<00:31,  8.69it/s] 54%|█████▍    | 323/595 [00:40<00:31,  8.66it/s] 54%|█████▍    | 324/595 [00:41<00:31,  8.68it/s] 55%|█████▍    | 325/595 [00:41<00:31,  8.69it/s] 55%|█████▍    | 326/595 [00:41<00:31,  8.62it/s] 55%|█████▍    | 327/595 [00:41<00:30,  8.77it/s] 55%|█████▌    | 328/595 [00:41<00:30,  8.68it/s] 55%|█████▌    | 329/595 [00:41<00:30,  8.69it/s] 55%|█████▌    | 330/595 [00:41<00:30,  8.70it/s] 56%|█████▌    | 331/595 [00:41<00:30,  8.72it/s] 56%|█████▌    | 332/595 [00:41<00:30,  8.65it/s] 56%|█████▌    | 333/595 [00:42<00:30,  8.65it/s] 56%|█████▌    | 334/595 [00:42<00:30,  8.68it/s] 56%|█████▋    | 335/595 [00:42<00:30,  8.65it/s] 56%|█████▋    | 336/595 [00:42<00:29,  8.67it/s] 57%|█████▋    | 337/595 [00:42<00:29,  8.81it/s] 57%|█████▋    | 338/595 [00:42<00:29,  8.77it/s] 57%|█████▋    | 339/595 [00:42<00:29,  8.81it/s] 57%|█████▋    | 340/595 [00:42<00:28,  8.81it/s] 57%|█████▋    | 341/595 [00:42<00:28,  8.76it/s] 57%|█████▋    | 342/595 [00:43<00:28,  8.73it/s] 58%|█████▊    | 343/595 [00:43<00:28,  8.80it/s] 58%|█████▊    | 344/595 [00:43<00:28,  8.87it/s] 58%|█████▊    | 345/595 [00:43<00:28,  8.75it/s] 58%|█████▊    | 346/595 [00:43<00:28,  8.76it/s] 58%|█████▊    | 347/595 [00:43<00:28,  8.75it/s] 58%|█████▊    | 348/595 [00:43<00:28,  8.70it/s] 59%|█████▊    | 349/595 [00:43<00:28,  8.73it/s] 59%|█████▉    | 350/595 [00:44<00:27,  8.76it/s] 59%|█████▉    | 351/595 [00:44<00:27,  8.81it/s] 59%|█████▉    | 352/595 [00:44<00:27,  8.77it/s] 59%|█████▉    | 353/595 [00:44<00:27,  8.77it/s] 59%|█████▉    | 354/595 [00:44<00:27,  8.76it/s] 60%|█████▉    | 355/595 [00:44<00:27,  8.81it/s] 60%|█████▉    | 356/595 [00:44<00:26,  8.86it/s]                                                  60%|██████    | 357/595 [00:44<00:26,  8.86it/s][INFO|trainer.py:755] 2023-11-15 19:26:54,513 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:26:54,515 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:26:54,516 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:26:54,516 >>   Batch size = 8
{'eval_loss': 0.4697487950325012, 'eval_accuracy': 0.8232804232804233, 'eval_micro_f1': 0.8232804232804233, 'eval_macro_f1': 0.7630510390497474, 'eval_runtime': 1.7356, 'eval_samples_per_second': 544.466, 'eval_steps_per_second': 68.562, 'epoch': 2.0}
{'loss': 0.3224, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 76.52it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 73.57it/s][A
 20%|██        | 24/119 [00:00<00:01, 68.53it/s][A
 26%|██▌       | 31/119 [00:00<00:01, 66.75it/s][A
 33%|███▎      | 39/119 [00:00<00:01, 67.76it/s][A
 39%|███▊      | 46/119 [00:00<00:01, 67.20it/s][A
 45%|████▍     | 53/119 [00:00<00:00, 66.76it/s][A
 50%|█████     | 60/119 [00:00<00:00, 66.10it/s][A
 56%|█████▋    | 67/119 [00:00<00:00, 66.82it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 67.19it/s][A
 68%|██████▊   | 81/119 [00:01<00:00, 66.63it/s][A
 75%|███████▍  | 89/119 [00:01<00:00, 67.31it/s][A
 81%|████████  | 96/119 [00:01<00:00, 64.79it/s][A
 87%|████████▋ | 103/119 [00:01<00:00, 65.46it/s][A
 92%|█████████▏| 110/119 [00:01<00:00, 65.98it/s][A
 98%|█████████▊| 117/119 [00:01<00:00, 65.95it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:46<00:26,  8.86it/s]
100%|██████████| 119/119 [00:01<00:00, 65.95it/s][A
                                                 [A 60%|██████    | 358/595 [00:46<02:02,  1.93it/s] 60%|██████    | 359/595 [00:46<01:38,  2.39it/s] 61%|██████    | 360/595 [00:46<01:19,  2.95it/s] 61%|██████    | 361/595 [00:47<01:05,  3.60it/s] 61%|██████    | 362/595 [00:47<00:54,  4.31it/s] 61%|██████    | 363/595 [00:47<00:45,  5.08it/s] 61%|██████    | 364/595 [00:47<00:40,  5.77it/s] 61%|██████▏   | 365/595 [00:47<00:36,  6.38it/s] 62%|██████▏   | 366/595 [00:47<00:32,  6.94it/s] 62%|██████▏   | 367/595 [00:47<00:30,  7.41it/s] 62%|██████▏   | 368/595 [00:47<00:29,  7.78it/s] 62%|██████▏   | 369/595 [00:47<00:27,  8.12it/s] 62%|██████▏   | 370/595 [00:48<00:26,  8.40it/s] 62%|██████▏   | 371/595 [00:48<00:26,  8.49it/s] 63%|██████▎   | 372/595 [00:48<00:26,  8.50it/s] 63%|██████▎   | 373/595 [00:48<00:25,  8.54it/s] 63%|██████▎   | 374/595 [00:48<00:25,  8.62it/s] 63%|██████▎   | 375/595 [00:48<00:25,  8.66it/s] 63%|██████▎   | 376/595 [00:48<00:25,  8.70it/s] 63%|██████▎   | 377/595 [00:48<00:24,  8.81it/s] 64%|██████▎   | 378/595 [00:48<00:24,  8.73it/s] 64%|██████▎   | 379/595 [00:49<00:24,  8.72it/s] 64%|██████▍   | 380/595 [00:49<00:24,  8.73it/s] 64%|██████▍   | 381/595 [00:49<00:24,  8.70it/s] 64%|██████▍   | 382/595 [00:49<00:24,  8.77it/s] 64%|██████▍   | 383/595 [00:49<00:23,  8.85it/s] 65%|██████▍   | 384/595 [00:49<00:23,  8.87it/s] 65%|██████▍   | 385/595 [00:49<00:23,  8.80it/s] 65%|██████▍   | 386/595 [00:49<00:23,  8.74it/s] 65%|██████▌   | 387/595 [00:49<00:23,  8.73it/s] 65%|██████▌   | 388/595 [00:50<00:23,  8.69it/s] 65%|██████▌   | 389/595 [00:50<00:23,  8.73it/s] 66%|██████▌   | 390/595 [00:50<00:23,  8.75it/s] 66%|██████▌   | 391/595 [00:50<00:22,  8.91it/s] 66%|██████▌   | 392/595 [00:50<00:23,  8.78it/s] 66%|██████▌   | 393/595 [00:50<00:23,  8.61it/s] 66%|██████▌   | 394/595 [00:50<00:23,  8.67it/s] 66%|██████▋   | 395/595 [00:50<00:22,  8.73it/s] 67%|██████▋   | 396/595 [00:51<00:22,  8.69it/s] 67%|██████▋   | 397/595 [00:51<00:22,  8.73it/s] 67%|██████▋   | 398/595 [00:51<00:22,  8.78it/s] 67%|██████▋   | 399/595 [00:51<00:22,  8.71it/s] 67%|██████▋   | 400/595 [00:51<00:22,  8.68it/s] 67%|██████▋   | 401/595 [00:51<00:22,  8.59it/s] 68%|██████▊   | 402/595 [00:51<00:22,  8.61it/s] 68%|██████▊   | 403/595 [00:51<00:22,  8.66it/s] 68%|██████▊   | 404/595 [00:51<00:22,  8.62it/s] 68%|██████▊   | 405/595 [00:52<00:21,  8.78it/s] 68%|██████▊   | 406/595 [00:52<00:21,  8.67it/s] 68%|██████▊   | 407/595 [00:52<00:21,  8.70it/s] 69%|██████▊   | 408/595 [00:52<00:21,  8.69it/s] 69%|██████▊   | 409/595 [00:52<00:21,  8.63it/s] 69%|██████▉   | 410/595 [00:52<00:21,  8.72it/s] 69%|██████▉   | 411/595 [00:52<00:21,  8.67it/s] 69%|██████▉   | 412/595 [00:52<00:20,  8.84it/s] 69%|██████▉   | 413/595 [00:52<00:20,  8.77it/s] 70%|██████▉   | 414/595 [00:53<00:20,  8.66it/s] 70%|██████▉   | 415/595 [00:53<00:20,  8.70it/s] 70%|██████▉   | 416/595 [00:53<00:20,  8.62it/s] 70%|███████   | 417/595 [00:53<00:20,  8.67it/s] 70%|███████   | 418/595 [00:53<00:20,  8.68it/s] 70%|███████   | 419/595 [00:53<00:20,  8.78it/s] 71%|███████   | 420/595 [00:53<00:20,  8.67it/s] 71%|███████   | 421/595 [00:53<00:20,  8.63it/s] 71%|███████   | 422/595 [00:54<00:20,  8.61it/s] 71%|███████   | 423/595 [00:54<00:19,  8.66it/s] 71%|███████▏  | 424/595 [00:54<00:19,  8.60it/s] 71%|███████▏  | 425/595 [00:54<00:19,  8.61it/s] 72%|███████▏  | 426/595 [00:54<00:19,  8.77it/s] 72%|███████▏  | 427/595 [00:54<00:19,  8.60it/s] 72%|███████▏  | 428/595 [00:54<00:19,  8.55it/s] 72%|███████▏  | 429/595 [00:54<00:19,  8.58it/s] 72%|███████▏  | 430/595 [00:54<00:19,  8.62it/s] 72%|███████▏  | 431/595 [00:55<00:18,  8.67it/s] 73%|███████▎  | 432/595 [00:55<00:19,  8.58it/s] 73%|███████▎  | 433/595 [00:55<00:18,  8.66it/s] 73%|███████▎  | 434/595 [00:55<00:18,  8.65it/s] 73%|███████▎  | 435/595 [00:55<00:18,  8.56it/s] 73%|███████▎  | 436/595 [00:55<00:18,  8.60it/s] 73%|███████▎  | 437/595 [00:55<00:18,  8.63it/s] 74%|███████▎  | 438/595 [00:55<00:18,  8.66it/s] 74%|███████▍  | 439/595 [00:55<00:18,  8.58it/s] 74%|███████▍  | 440/595 [00:56<00:17,  8.74it/s] 74%|███████▍  | 441/595 [00:56<00:17,  8.62it/s] 74%|███████▍  | 442/595 [00:56<00:17,  8.63it/s] 74%|███████▍  | 443/595 [00:56<00:17,  8.62it/s] 75%|███████▍  | 444/595 [00:56<00:17,  8.69it/s] 75%|███████▍  | 445/595 [00:56<00:17,  8.73it/s] 75%|███████▍  | 446/595 [00:56<00:17,  8.67it/s] 75%|███████▌  | 447/595 [00:56<00:16,  8.81it/s] 75%|███████▌  | 448/595 [00:57<00:16,  8.76it/s] 75%|███████▌  | 449/595 [00:57<00:16,  8.72it/s] 76%|███████▌  | 450/595 [00:57<00:16,  8.72it/s] 76%|███████▌  | 451/595 [00:57<00:16,  8.78it/s] 76%|███████▌  | 452/595 [00:57<00:16,  8.79it/s] 76%|███████▌  | 453/595 [00:57<00:16,  8.75it/s] 76%|███████▋  | 454/595 [00:57<00:16,  8.74it/s] 76%|███████▋  | 455/595 [00:57<00:16,  8.71it/s] 77%|███████▋  | 456/595 [00:57<00:15,  8.69it/s] 77%|███████▋  | 457/595 [00:58<00:15,  8.75it/s] 77%|███████▋  | 458/595 [00:58<00:15,  8.77it/s] 77%|███████▋  | 459/595 [00:58<00:15,  8.67it/s] 77%|███████▋  | 460/595 [00:58<00:15,  8.67it/s] 77%|███████▋  | 461/595 [00:58<00:15,  8.73it/s] 78%|███████▊  | 462/595 [00:58<00:15,  8.71it/s] 78%|███████▊  | 463/595 [00:58<00:15,  8.71it/s] 78%|███████▊  | 464/595 [00:58<00:14,  8.77it/s] 78%|███████▊  | 465/595 [00:58<00:14,  8.73it/s] 78%|███████▊  | 466/595 [00:59<00:15,  8.59it/s] 78%|███████▊  | 467/595 [00:59<00:14,  8.63it/s] 79%|███████▊  | 468/595 [00:59<00:14,  8.67it/s] 79%|███████▉  | 469/595 [00:59<00:14,  8.69it/s] 79%|███████▉  | 470/595 [00:59<00:14,  8.70it/s] 79%|███████▉  | 471/595 [00:59<00:14,  8.84it/s] 79%|███████▉  | 472/595 [00:59<00:14,  8.77it/s] 79%|███████▉  | 473/595 [00:59<00:13,  8.73it/s] 80%|███████▉  | 474/595 [00:59<00:13,  8.80it/s] 80%|███████▉  | 475/595 [01:00<00:13,  8.85it/s]                                                  80%|████████  | 476/595 [01:00<00:13,  8.85it/s][INFO|trainer.py:755] 2023-11-15 19:27:09,922 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:27:09,924 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:27:09,925 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:27:09,925 >>   Batch size = 8
{'eval_loss': 0.5162771344184875, 'eval_accuracy': 0.8052910052910053, 'eval_micro_f1': 0.8052910052910053, 'eval_macro_f1': 0.7580046840136289, 'eval_runtime': 1.8233, 'eval_samples_per_second': 518.291, 'eval_steps_per_second': 65.266, 'epoch': 3.0}
{'loss': 0.2248, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 78.49it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 70.85it/s][A
 20%|██        | 24/119 [00:00<00:01, 70.47it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 69.09it/s][A
 33%|███▎      | 39/119 [00:00<00:01, 68.16it/s][A
 39%|███▉      | 47/119 [00:00<00:01, 70.03it/s][A
 46%|████▌     | 55/119 [00:00<00:00, 68.06it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 66.82it/s][A
 58%|█████▊    | 69/119 [00:01<00:00, 67.17it/s][A
 64%|██████▍   | 76/119 [00:01<00:00, 66.87it/s][A
 70%|██████▉   | 83/119 [00:01<00:00, 66.84it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 66.82it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 67.38it/s][A
 87%|████████▋ | 104/119 [00:01<00:00, 67.62it/s][A
 93%|█████████▎| 111/119 [00:01<00:00, 66.63it/s][A
 99%|█████████▉| 118/119 [00:01<00:00, 66.63it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [01:01<00:13,  8.85it/s]
100%|██████████| 119/119 [00:01<00:00, 66.63it/s][A
                                                 [A 80%|████████  | 477/595 [01:02<01:01,  1.93it/s] 80%|████████  | 478/595 [01:02<00:48,  2.39it/s] 81%|████████  | 479/595 [01:02<00:39,  2.95it/s] 81%|████████  | 480/595 [01:02<00:31,  3.62it/s] 81%|████████  | 481/595 [01:02<00:26,  4.32it/s] 81%|████████  | 482/595 [01:02<00:22,  5.06it/s] 81%|████████  | 483/595 [01:02<00:19,  5.77it/s] 81%|████████▏ | 484/595 [01:02<00:17,  6.41it/s] 82%|████████▏ | 485/595 [01:02<00:15,  6.96it/s] 82%|████████▏ | 486/595 [01:03<00:14,  7.40it/s] 82%|████████▏ | 487/595 [01:03<00:13,  7.76it/s] 82%|████████▏ | 488/595 [01:03<00:13,  8.05it/s] 82%|████████▏ | 489/595 [01:03<00:12,  8.26it/s] 82%|████████▏ | 490/595 [01:03<00:12,  8.53it/s] 83%|████████▎ | 491/595 [01:03<00:12,  8.53it/s] 83%|████████▎ | 492/595 [01:03<00:11,  8.60it/s] 83%|████████▎ | 493/595 [01:03<00:11,  8.62it/s] 83%|████████▎ | 494/595 [01:04<00:11,  8.64it/s] 83%|████████▎ | 495/595 [01:04<00:11,  8.69it/s] 83%|████████▎ | 496/595 [01:04<00:11,  8.66it/s] 84%|████████▎ | 497/595 [01:04<00:11,  8.80it/s] 84%|████████▎ | 498/595 [01:04<00:11,  8.71it/s] 84%|████████▍ | 499/595 [01:04<00:10,  8.78it/s] 84%|████████▍ | 500/595 [01:04<00:10,  8.85it/s] 84%|████████▍ | 501/595 [01:04<00:10,  8.90it/s] 84%|████████▍ | 502/595 [01:04<00:10,  8.84it/s] 85%|████████▍ | 503/595 [01:05<00:10,  8.85it/s] 85%|████████▍ | 504/595 [01:05<00:10,  8.84it/s] 85%|████████▍ | 505/595 [01:05<00:10,  8.82it/s] 85%|████████▌ | 506/595 [01:05<00:10,  8.88it/s] 85%|████████▌ | 507/595 [01:05<00:09,  9.00it/s] 85%|████████▌ | 508/595 [01:05<00:09,  8.89it/s] 86%|████████▌ | 509/595 [01:05<00:09,  8.76it/s] 86%|████████▌ | 510/595 [01:05<00:09,  8.77it/s] 86%|████████▌ | 511/595 [01:05<00:09,  8.75it/s] 86%|████████▌ | 512/595 [01:06<00:09,  8.83it/s] 86%|████████▌ | 513/595 [01:06<00:09,  8.79it/s] 86%|████████▋ | 514/595 [01:06<00:09,  8.93it/s] 87%|████████▋ | 515/595 [01:06<00:09,  8.86it/s] 87%|████████▋ | 516/595 [01:06<00:08,  8.83it/s] 87%|████████▋ | 517/595 [01:06<00:08,  8.83it/s] 87%|████████▋ | 518/595 [01:06<00:08,  8.92it/s] 87%|████████▋ | 519/595 [01:06<00:08,  8.84it/s] 87%|████████▋ | 520/595 [01:06<00:08,  8.85it/s] 88%|████████▊ | 521/595 [01:07<00:08,  8.84it/s] 88%|████████▊ | 522/595 [01:07<00:08,  8.84it/s] 88%|████████▊ | 523/595 [01:07<00:08,  8.83it/s] 88%|████████▊ | 524/595 [01:07<00:07,  8.97it/s] 88%|████████▊ | 525/595 [01:07<00:07,  8.93it/s] 88%|████████▊ | 526/595 [01:07<00:07,  8.82it/s] 89%|████████▊ | 527/595 [01:07<00:07,  8.90it/s] 89%|████████▊ | 528/595 [01:07<00:07,  8.81it/s] 89%|████████▉ | 529/595 [01:07<00:07,  8.82it/s] 89%|████████▉ | 530/595 [01:08<00:07,  8.82it/s] 89%|████████▉ | 531/595 [01:08<00:07,  8.68it/s] 89%|████████▉ | 532/595 [01:08<00:07,  8.62it/s] 90%|████████▉ | 533/595 [01:08<00:07,  8.70it/s] 90%|████████▉ | 534/595 [01:08<00:06,  8.73it/s] 90%|████████▉ | 535/595 [01:08<00:06,  8.81it/s] 90%|█████████ | 536/595 [01:08<00:06,  8.75it/s] 90%|█████████ | 537/595 [01:08<00:06,  8.66it/s] 90%|█████████ | 538/595 [01:09<00:06,  8.70it/s] 91%|█████████ | 539/595 [01:09<00:06,  8.74it/s] 91%|█████████ | 540/595 [01:09<00:06,  8.77it/s] 91%|█████████ | 541/595 [01:09<00:06,  8.90it/s] 91%|█████████ | 542/595 [01:09<00:06,  8.81it/s] 91%|█████████▏| 543/595 [01:09<00:05,  8.79it/s] 91%|█████████▏| 544/595 [01:09<00:05,  8.72it/s] 92%|█████████▏| 545/595 [01:09<00:05,  8.76it/s] 92%|█████████▏| 546/595 [01:09<00:05,  8.84it/s] 92%|█████████▏| 547/595 [01:10<00:05,  8.77it/s] 92%|█████████▏| 548/595 [01:10<00:05,  8.94it/s] 92%|█████████▏| 549/595 [01:10<00:05,  8.85it/s] 92%|█████████▏| 550/595 [01:10<00:05,  8.82it/s] 93%|█████████▎| 551/595 [01:10<00:05,  8.79it/s] 93%|█████████▎| 552/595 [01:10<00:04,  8.81it/s] 93%|█████████▎| 553/595 [01:10<00:04,  8.74it/s] 93%|█████████▎| 554/595 [01:10<00:04,  8.73it/s] 93%|█████████▎| 555/595 [01:10<00:04,  8.80it/s] 93%|█████████▎| 556/595 [01:11<00:04,  8.80it/s] 94%|█████████▎| 557/595 [01:11<00:04,  8.81it/s] 94%|█████████▍| 558/595 [01:11<00:04,  8.85it/s] 94%|█████████▍| 559/595 [01:11<00:04,  8.76it/s] 94%|█████████▍| 560/595 [01:11<00:03,  8.82it/s] 94%|█████████▍| 561/595 [01:11<00:03,  8.78it/s] 94%|█████████▍| 562/595 [01:11<00:03,  8.81it/s] 95%|█████████▍| 563/595 [01:11<00:03,  8.91it/s] 95%|█████████▍| 564/595 [01:11<00:03,  8.84it/s] 95%|█████████▍| 565/595 [01:12<00:03,  8.86it/s] 95%|█████████▌| 566/595 [01:12<00:03,  8.76it/s] 95%|█████████▌| 567/595 [01:12<00:03,  8.81it/s] 95%|█████████▌| 568/595 [01:12<00:03,  8.81it/s] 96%|█████████▌| 569/595 [01:12<00:02,  8.85it/s] 96%|█████████▌| 570/595 [01:12<00:02,  8.81it/s] 96%|█████████▌| 571/595 [01:12<00:02,  8.72it/s] 96%|█████████▌| 572/595 [01:12<00:02,  8.79it/s] 96%|█████████▋| 573/595 [01:12<00:02,  8.81it/s] 96%|█████████▋| 574/595 [01:13<00:02,  8.87it/s] 97%|█████████▋| 575/595 [01:13<00:02,  8.92it/s] 97%|█████████▋| 576/595 [01:13<00:02,  8.86it/s] 97%|█████████▋| 577/595 [01:13<00:02,  8.88it/s] 97%|█████████▋| 578/595 [01:13<00:01,  8.80it/s] 97%|█████████▋| 579/595 [01:13<00:01,  8.82it/s] 97%|█████████▋| 580/595 [01:13<00:01,  8.83it/s] 98%|█████████▊| 581/595 [01:13<00:01,  8.79it/s] 98%|█████████▊| 582/595 [01:13<00:01,  8.89it/s] 98%|█████████▊| 583/595 [01:14<00:01,  8.93it/s] 98%|█████████▊| 584/595 [01:14<00:01,  8.95it/s] 98%|█████████▊| 585/595 [01:14<00:01,  8.96it/s] 98%|█████████▊| 586/595 [01:14<00:01,  8.93it/s] 99%|█████████▊| 587/595 [01:14<00:00,  8.89it/s] 99%|█████████▉| 588/595 [01:14<00:00,  8.89it/s] 99%|█████████▉| 589/595 [01:14<00:00,  8.83it/s] 99%|█████████▉| 590/595 [01:14<00:00,  8.86it/s] 99%|█████████▉| 591/595 [01:15<00:00,  8.81it/s] 99%|█████████▉| 592/595 [01:15<00:00,  8.88it/s]100%|█████████▉| 593/595 [01:15<00:00,  8.80it/s]100%|█████████▉| 594/595 [01:15<00:00,  8.92it/s]                                                 100%|██████████| 595/595 [01:15<00:00,  8.92it/s][INFO|trainer.py:755] 2023-11-15 19:27:25,167 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:27:25,169 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:27:25,169 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:27:25,169 >>   Batch size = 8
{'eval_loss': 0.5003036260604858, 'eval_accuracy': 0.837037037037037, 'eval_micro_f1': 0.837037037037037, 'eval_macro_f1': 0.7783541269851045, 'eval_runtime': 1.8136, 'eval_samples_per_second': 521.052, 'eval_steps_per_second': 65.614, 'epoch': 4.0}
{'loss': 0.1724, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 81.17it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 71.61it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 69.64it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 69.15it/s][A
 34%|███▍      | 41/119 [00:00<00:01, 66.96it/s][A
 40%|████      | 48/119 [00:00<00:01, 67.22it/s][A
 46%|████▌     | 55/119 [00:00<00:00, 66.26it/s][A
 53%|█████▎    | 63/119 [00:00<00:00, 67.04it/s][A
 59%|█████▉    | 70/119 [00:01<00:00, 67.25it/s][A
 65%|██████▍   | 77/119 [00:01<00:00, 66.33it/s][A
 71%|███████▏  | 85/119 [00:01<00:00, 68.08it/s][A
 77%|███████▋  | 92/119 [00:01<00:00, 66.53it/s][A
 83%|████████▎ | 99/119 [00:01<00:00, 66.49it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 67.13it/s][A
 95%|█████████▍| 113/119 [00:01<00:00, 66.78it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:17<00:00,  8.92it/s]
100%|██████████| 119/119 [00:01<00:00, 66.78it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 19:27:26,988 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:17<00:00,  8.92it/s]100%|██████████| 595/595 [01:17<00:00,  7.71it/s]
[INFO|trainer.py:2855] 2023-11-15 19:27:26,992 >> Saving model checkpoint to ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0
[INFO|configuration_utils.py:460] 2023-11-15 19:27:26,995 >> Configuration saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:27:28,313 >> Model weights saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:27:28,316 >> tokenizer config file saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:27:28,318 >> Special tokens file saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed0/special_tokens_map.json
{'eval_loss': 0.5317295789718628, 'eval_accuracy': 0.8275132275132275, 'eval_micro_f1': 0.8275132275132275, 'eval_macro_f1': 0.7716630020961518, 'eval_runtime': 1.8148, 'eval_samples_per_second': 520.733, 'eval_steps_per_second': 65.574, 'epoch': 5.0}
{'train_runtime': 77.219, 'train_samples_per_second': 244.564, 'train_steps_per_second': 7.705, 'train_loss': 0.3852582915490415, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3853
  train_runtime            = 0:01:17.21
  train_samples            =       3777
  train_samples_per_second =    244.564
  train_steps_per_second   =      7.705
11/15/2023 19:27:28 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:27:28,364 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:27:28,366 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:27:28,366 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:27:28,367 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  7%|▋         | 8/119 [00:00<00:01, 76.11it/s] 13%|█▎        | 16/119 [00:00<00:01, 69.92it/s] 20%|██        | 24/119 [00:00<00:01, 69.77it/s] 27%|██▋       | 32/119 [00:00<00:01, 70.52it/s] 34%|███▎      | 40/119 [00:00<00:01, 71.87it/s] 40%|████      | 48/119 [00:00<00:01, 69.76it/s] 47%|████▋     | 56/119 [00:00<00:00, 72.29it/s] 54%|█████▍    | 64/119 [00:00<00:00, 69.02it/s] 60%|█████▉    | 71/119 [00:01<00:00, 69.17it/s] 66%|██████▌   | 78/119 [00:01<00:00, 69.35it/s] 71%|███████▏  | 85/119 [00:01<00:00, 69.23it/s] 78%|███████▊  | 93/119 [00:01<00:00, 69.15it/s] 84%|████████▍ | 100/119 [00:01<00:00, 69.37it/s] 90%|████████▉ | 107/119 [00:01<00:00, 68.28it/s] 97%|█████████▋| 115/119 [00:01<00:00, 69.79it/s]100%|██████████| 119/119 [00:01<00:00, 68.54it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8275
  eval_loss               =     0.5317
  eval_macro_f1           =     0.7717
  eval_micro_f1           =     0.8275
  eval_runtime            = 0:00:01.75
  eval_samples            =        945
  eval_samples_per_second =    539.469
  eval_steps_per_second   =     67.933
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▆▄█▇▇
wandb:                      eval/loss █▁▄▃▅▅
wandb:                  eval/macro_f1 ▁▇▇███
wandb:                  eval/micro_f1 ▁▆▄█▇▇
wandb:                   eval/runtime ▆▁█▇▇▂
wandb:        eval/samples_per_second ▃█▁▂▂▇
wandb:          eval/steps_per_second ▃█▁▂▂▇
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.82751
wandb:                      eval/loss 0.53173
wandb:                  eval/macro_f1 0.77166
wandb:                  eval/micro_f1 0.82751
wandb:                   eval/runtime 1.7517
wandb:        eval/samples_per_second 539.469
wandb:          eval/steps_per_second 67.933
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1724
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.38526
wandb:            train/train_runtime 77.219
wandb: train/train_samples_per_second 244.564
wandb:   train/train_steps_per_second 7.705
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_192449-ahsx4b39
wandb: Find logs at: ./wandb/offline-run-20231115_192449-ahsx4b39/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_roberta-base_adapter__seed0/runs/Nov15_19-27-40_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_roberta-base_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_roberta-base_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:27:40 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:27:40 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_roberta-base_adapter__seed0/runs/Nov15_19-27-39_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_roberta-base_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_roberta-base_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  36%|███▋      | 4006/11020 [00:00<00:00, 39453.23 examples/s]Map:  73%|███████▎  | 8056/11020 [00:00<00:00, 40059.93 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 39785.15 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 19:27:56,794 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:27:56,805 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 19:28:06,814 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 19:28:16,832 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:28:16,833 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:28:36,889 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:28:36,889 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:28:36,890 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:28:36,890 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:28:36,890 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:28:36,890 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 19:28:36,892 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:28:36,892 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:28:57,090 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 19:28:57,890 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:28:57,891 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  23%|██▎       | 2000/8816 [00:00<00:00, 17433.63 examples/s]Running tokenizer on dataset:  45%|████▌     | 4000/8816 [00:00<00:00, 18514.39 examples/s]Running tokenizer on dataset:  68%|██████▊   | 6000/8816 [00:00<00:00, 18961.24 examples/s]Running tokenizer on dataset:  91%|█████████ | 8000/8816 [00:00<00:00, 18913.60 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 18700.58 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 19163.71 examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 18843.66 examples/s]
11/15/2023 19:28:58 - INFO - __main__ - Sample 3485 of the training set: {'text': 'ERGMs are particularly useful for testing hypotheses about network relations, and they have started to be applied more widely in public health [27].', 'label': 0, 'input_ids': [0, 39042, 13123, 32, 1605, 5616, 13, 3044, 44850, 59, 1546, 3115, 6, 8, 51, 33, 554, 7, 28, 5049, 55, 3924, 11, 285, 474, 646, 2518, 8174, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:28:58 - INFO - __main__ - Sample 5176 of the training set: {'text': 'Consistent with previous results (Koroch et al. 2002; Liu et al. 2002; Staniszewska et al. 2003; Washida et al. 2004), the addition of IBA at optimum levels enhanced the growth of HRC of Echinacea but had no effect on the production of secondary metabolites.', 'label': 2, 'input_ids': [0, 24514, 21464, 19, 986, 775, 36, 530, 368, 4306, 4400, 1076, 4, 5241, 131, 13768, 4400, 1076, 4, 5241, 131, 8995, 354, 329, 10269, 2348, 4400, 1076, 4, 4999, 131, 13852, 4347, 4400, 1076, 4, 4482, 238, 5, 1285, 9, 38, 3813, 23, 33771, 1389, 9094, 5, 434, 9, 43204, 9, 381, 16682, 38937, 53, 56, 117, 1683, 15, 5, 931, 9, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 19:28:58 - INFO - __main__ - Sample 8092 of the training set: {'text': 'Syllables with a voiced onset developed a low tone, and those with a voiceless initial induced a high tone, resulting in a six-way tonal contrast (2 pitch heights x 3 contours).1\n(Kang 2014, Kim 2000, Oh 2011, Silva 2006, Wright 2007).', 'label': 0, 'input_ids': [0, 35615, 890, 6058, 19, 10, 12559, 23808, 2226, 10, 614, 6328, 6, 8, 167, 19, 10, 30118, 13802, 2557, 26914, 10, 239, 6328, 6, 5203, 11, 10, 411, 12, 1970, 4866, 337, 5709, 36, 176, 3242, 16889, 3023, 155, 8541, 5634, 322, 134, 50118, 1640, 530, 1097, 777, 6, 1636, 3788, 6, 5534, 1466, 6, 9392, 3503, 6, 5825, 3010, 322, 2, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]}.
11/15/2023 19:28:58 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:29:00,244 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:29:00,251 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:29:00,252 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 19:29:00,252 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:29:00,252 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:29:00,252 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:29:00,253 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:29:00,253 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 19:29:00,254 >>   Number of trainable parameters = 124,647,939
[INFO|integration_utils.py:716] 2023-11-15 19:29:00,255 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<34:39,  1.51s/it]  0%|          | 2/1380 [00:01<15:46,  1.46it/s]  0%|          | 3/1380 [00:01<09:47,  2.35it/s]  0%|          | 4/1380 [00:01<06:56,  3.31it/s]  0%|          | 5/1380 [00:01<05:22,  4.27it/s]  0%|          | 6/1380 [00:02<04:24,  5.19it/s]  1%|          | 7/1380 [00:02<03:47,  6.04it/s]  1%|          | 8/1380 [00:02<03:24,  6.72it/s]  1%|          | 9/1380 [00:02<03:08,  7.29it/s]  1%|          | 10/1380 [00:02<02:59,  7.63it/s]  1%|          | 11/1380 [00:02<02:52,  7.93it/s]  1%|          | 12/1380 [00:02<02:47,  8.17it/s]  1%|          | 13/1380 [00:02<02:43,  8.34it/s]  1%|          | 14/1380 [00:02<02:42,  8.40it/s]  1%|          | 15/1380 [00:03<02:40,  8.51it/s]  1%|          | 16/1380 [00:03<02:38,  8.63it/s]  1%|          | 17/1380 [00:03<02:36,  8.69it/s]  1%|▏         | 18/1380 [00:03<02:35,  8.75it/s]  1%|▏         | 19/1380 [00:03<02:34,  8.82it/s]  1%|▏         | 20/1380 [00:03<02:34,  8.80it/s]  2%|▏         | 21/1380 [00:03<02:35,  8.73it/s]  2%|▏         | 22/1380 [00:03<02:36,  8.65it/s]  2%|▏         | 23/1380 [00:04<02:37,  8.62it/s]  2%|▏         | 24/1380 [00:04<02:35,  8.73it/s]  2%|▏         | 25/1380 [00:04<02:34,  8.75it/s]  2%|▏         | 26/1380 [00:04<02:32,  8.88it/s]  2%|▏         | 27/1380 [00:04<02:33,  8.84it/s]  2%|▏         | 28/1380 [00:04<02:34,  8.77it/s]  2%|▏         | 29/1380 [00:04<02:34,  8.75it/s]  2%|▏         | 30/1380 [00:04<02:35,  8.70it/s]  2%|▏         | 31/1380 [00:04<02:34,  8.75it/s]  2%|▏         | 32/1380 [00:05<02:33,  8.78it/s]  2%|▏         | 33/1380 [00:05<02:31,  8.87it/s]  2%|▏         | 34/1380 [00:05<02:32,  8.85it/s]  3%|▎         | 35/1380 [00:05<02:32,  8.81it/s]  3%|▎         | 36/1380 [00:05<02:31,  8.84it/s]  3%|▎         | 37/1380 [00:05<02:32,  8.82it/s]  3%|▎         | 38/1380 [00:05<02:31,  8.88it/s]  3%|▎         | 39/1380 [00:05<02:30,  8.92it/s]  3%|▎         | 40/1380 [00:05<02:29,  8.95it/s]  3%|▎         | 41/1380 [00:06<02:30,  8.89it/s]  3%|▎         | 42/1380 [00:06<02:32,  8.79it/s]  3%|▎         | 43/1380 [00:06<02:32,  8.79it/s]  3%|▎         | 44/1380 [00:06<02:31,  8.79it/s]  3%|▎         | 45/1380 [00:06<02:31,  8.83it/s]  3%|▎         | 46/1380 [00:06<02:30,  8.84it/s]  3%|▎         | 47/1380 [00:06<02:28,  8.96it/s]  3%|▎         | 48/1380 [00:06<02:30,  8.82it/s]  4%|▎         | 49/1380 [00:06<02:31,  8.81it/s]  4%|▎         | 50/1380 [00:07<02:31,  8.80it/s]  4%|▎         | 51/1380 [00:07<02:30,  8.83it/s]  4%|▍         | 52/1380 [00:07<02:30,  8.85it/s]  4%|▍         | 53/1380 [00:07<02:30,  8.82it/s]  4%|▍         | 54/1380 [00:07<02:29,  8.89it/s]  4%|▍         | 55/1380 [00:07<02:30,  8.77it/s]  4%|▍         | 56/1380 [00:07<02:30,  8.81it/s]  4%|▍         | 57/1380 [00:07<02:30,  8.82it/s]  4%|▍         | 58/1380 [00:07<02:29,  8.85it/s]  4%|▍         | 59/1380 [00:08<02:27,  8.94it/s]  4%|▍         | 60/1380 [00:08<02:29,  8.83it/s]  4%|▍         | 61/1380 [00:08<02:26,  9.02it/s]  4%|▍         | 62/1380 [00:08<02:27,  8.94it/s]  5%|▍         | 63/1380 [00:08<02:26,  8.97it/s]  5%|▍         | 64/1380 [00:08<02:23,  9.17it/s]  5%|▍         | 65/1380 [00:08<02:23,  9.17it/s]  5%|▍         | 66/1380 [00:08<02:25,  9.04it/s]  5%|▍         | 67/1380 [00:08<02:27,  8.90it/s]  5%|▌         | 69/1380 [00:09<02:14,  9.76it/s]  5%|▌         | 71/1380 [00:09<02:07, 10.23it/s]  5%|▌         | 73/1380 [00:09<02:04, 10.51it/s]  5%|▌         | 75/1380 [00:09<02:01, 10.71it/s]  6%|▌         | 77/1380 [00:09<02:09, 10.04it/s]  6%|▌         | 79/1380 [00:10<02:13,  9.73it/s]  6%|▌         | 80/1380 [00:10<02:15,  9.59it/s]  6%|▌         | 81/1380 [00:10<02:16,  9.51it/s]  6%|▌         | 82/1380 [00:10<02:17,  9.42it/s]  6%|▌         | 83/1380 [00:10<02:19,  9.32it/s]  6%|▌         | 84/1380 [00:10<02:21,  9.17it/s]  6%|▌         | 85/1380 [00:10<02:22,  9.12it/s]  6%|▌         | 86/1380 [00:10<02:22,  9.08it/s]  6%|▋         | 87/1380 [00:11<02:22,  9.11it/s]  6%|▋         | 88/1380 [00:11<02:22,  9.07it/s]  6%|▋         | 89/1380 [00:11<02:20,  9.19it/s]  7%|▋         | 90/1380 [00:11<02:21,  9.09it/s]  7%|▋         | 91/1380 [00:11<02:22,  9.03it/s]  7%|▋         | 92/1380 [00:11<02:22,  9.03it/s]  7%|▋         | 93/1380 [00:11<02:22,  9.01it/s]  7%|▋         | 94/1380 [00:11<02:23,  8.99it/s]  7%|▋         | 95/1380 [00:11<02:23,  8.99it/s]  7%|▋         | 96/1380 [00:12<02:23,  8.97it/s]  7%|▋         | 97/1380 [00:12<02:22,  9.03it/s]  7%|▋         | 98/1380 [00:12<02:21,  9.09it/s]  7%|▋         | 99/1380 [00:12<02:19,  9.15it/s]  7%|▋         | 100/1380 [00:12<02:21,  9.07it/s]  7%|▋         | 101/1380 [00:12<02:22,  8.99it/s]  7%|▋         | 102/1380 [00:12<02:21,  9.00it/s]  7%|▋         | 103/1380 [00:12<02:22,  8.98it/s]  8%|▊         | 104/1380 [00:12<02:21,  9.03it/s]  8%|▊         | 105/1380 [00:13<02:22,  8.97it/s]  8%|▊         | 106/1380 [00:13<02:20,  9.06it/s]  8%|▊         | 107/1380 [00:13<02:21,  9.02it/s]  8%|▊         | 108/1380 [00:13<02:21,  9.02it/s]  8%|▊         | 109/1380 [00:13<02:20,  9.02it/s]  8%|▊         | 110/1380 [00:13<02:20,  9.04it/s]  8%|▊         | 111/1380 [00:13<02:20,  9.01it/s]  8%|▊         | 112/1380 [00:13<02:21,  8.96it/s]  8%|▊         | 113/1380 [00:13<02:20,  9.03it/s]  8%|▊         | 114/1380 [00:14<02:20,  9.02it/s]  8%|▊         | 115/1380 [00:14<02:20,  9.01it/s]  8%|▊         | 116/1380 [00:14<02:18,  9.12it/s]  8%|▊         | 117/1380 [00:14<02:20,  8.96it/s]  9%|▊         | 118/1380 [00:14<02:20,  8.98it/s]  9%|▊         | 119/1380 [00:14<02:20,  8.97it/s]  9%|▊         | 120/1380 [00:14<02:20,  8.97it/s]  9%|▉         | 121/1380 [00:14<02:20,  8.97it/s]  9%|▉         | 122/1380 [00:14<02:22,  8.86it/s]  9%|▉         | 123/1380 [00:15<02:20,  8.94it/s]  9%|▉         | 124/1380 [00:15<02:20,  8.95it/s]  9%|▉         | 125/1380 [00:15<02:19,  9.01it/s]  9%|▉         | 126/1380 [00:15<02:17,  9.13it/s]  9%|▉         | 127/1380 [00:15<02:18,  9.04it/s]  9%|▉         | 128/1380 [00:15<02:19,  8.95it/s]  9%|▉         | 129/1380 [00:15<02:19,  8.97it/s]  9%|▉         | 130/1380 [00:15<02:19,  8.95it/s]  9%|▉         | 131/1380 [00:15<02:18,  9.04it/s] 10%|▉         | 132/1380 [00:16<02:18,  9.01it/s] 10%|▉         | 133/1380 [00:16<02:17,  9.06it/s] 10%|▉         | 134/1380 [00:16<02:18,  9.00it/s] 10%|▉         | 135/1380 [00:16<02:18,  9.01it/s] 10%|▉         | 136/1380 [00:16<02:17,  9.07it/s] 10%|▉         | 137/1380 [00:16<02:17,  9.02it/s] 10%|█         | 138/1380 [00:16<02:18,  8.97it/s] 10%|█         | 139/1380 [00:16<02:17,  8.99it/s] 10%|█         | 140/1380 [00:16<02:18,  8.96it/s] 10%|█         | 141/1380 [00:17<02:17,  8.98it/s] 10%|█         | 142/1380 [00:17<02:17,  8.99it/s] 10%|█         | 143/1380 [00:17<02:15,  9.10it/s] 10%|█         | 144/1380 [00:17<02:17,  9.02it/s] 11%|█         | 145/1380 [00:17<02:15,  9.09it/s] 11%|█         | 146/1380 [00:17<02:15,  9.09it/s] 11%|█         | 147/1380 [00:17<02:14,  9.14it/s] 11%|█         | 148/1380 [00:17<02:15,  9.06it/s] 11%|█         | 149/1380 [00:17<02:16,  9.00it/s] 11%|█         | 150/1380 [00:18<02:16,  9.04it/s] 11%|█         | 151/1380 [00:18<02:16,  9.03it/s] 11%|█         | 152/1380 [00:18<02:15,  9.07it/s] 11%|█         | 153/1380 [00:18<02:13,  9.17it/s] 11%|█         | 154/1380 [00:18<02:14,  9.09it/s] 11%|█         | 155/1380 [00:18<02:16,  9.00it/s] 11%|█▏        | 156/1380 [00:18<02:15,  9.00it/s] 11%|█▏        | 157/1380 [00:18<02:16,  8.97it/s] 11%|█▏        | 158/1380 [00:18<02:15,  9.00it/s] 12%|█▏        | 159/1380 [00:19<02:15,  8.99it/s] 12%|█▏        | 160/1380 [00:19<02:13,  9.16it/s] 12%|█▏        | 161/1380 [00:19<02:15,  9.01it/s] 12%|█▏        | 162/1380 [00:19<02:15,  8.99it/s] 12%|█▏        | 163/1380 [00:19<02:15,  9.00it/s] 12%|█▏        | 164/1380 [00:19<02:15,  8.99it/s] 12%|█▏        | 165/1380 [00:19<02:15,  8.95it/s] 12%|█▏        | 166/1380 [00:19<02:16,  8.93it/s] 12%|█▏        | 167/1380 [00:19<02:12,  9.15it/s] 12%|█▏        | 168/1380 [00:20<02:15,  8.94it/s] 12%|█▏        | 169/1380 [00:20<02:15,  8.92it/s] 12%|█▏        | 170/1380 [00:20<02:14,  9.00it/s] 12%|█▏        | 171/1380 [00:20<02:15,  8.95it/s] 12%|█▏        | 172/1380 [00:20<02:14,  8.95it/s] 13%|█▎        | 173/1380 [00:20<02:15,  8.92it/s] 13%|█▎        | 174/1380 [00:20<02:12,  9.08it/s] 13%|█▎        | 175/1380 [00:20<02:13,  9.04it/s] 13%|█▎        | 176/1380 [00:20<02:12,  9.06it/s] 13%|█▎        | 177/1380 [00:21<02:13,  9.04it/s] 13%|█▎        | 178/1380 [00:21<02:13,  9.02it/s] 13%|█▎        | 179/1380 [00:21<02:13,  9.00it/s] 13%|█▎        | 180/1380 [00:21<02:14,  8.89it/s] 13%|█▎        | 181/1380 [00:21<02:13,  9.01it/s] 13%|█▎        | 182/1380 [00:21<02:13,  8.99it/s] 13%|█▎        | 183/1380 [00:21<02:12,  9.04it/s] 13%|█▎        | 184/1380 [00:21<02:11,  9.11it/s] 13%|█▎        | 185/1380 [00:21<02:12,  9.02it/s] 13%|█▎        | 186/1380 [00:22<02:13,  8.94it/s] 14%|█▎        | 187/1380 [00:22<02:13,  8.96it/s] 14%|█▎        | 188/1380 [00:22<02:13,  8.94it/s] 14%|█▎        | 189/1380 [00:22<02:12,  9.02it/s] 14%|█▍        | 190/1380 [00:22<02:12,  8.95it/s] 14%|█▍        | 191/1380 [00:22<02:10,  9.10it/s] 14%|█▍        | 192/1380 [00:22<02:11,  9.03it/s] 14%|█▍        | 193/1380 [00:22<02:13,  8.92it/s] 14%|█▍        | 194/1380 [00:22<02:13,  8.90it/s] 14%|█▍        | 195/1380 [00:23<02:13,  8.90it/s] 14%|█▍        | 196/1380 [00:23<02:12,  8.94it/s] 14%|█▍        | 197/1380 [00:23<02:12,  8.91it/s] 14%|█▍        | 198/1380 [00:23<02:10,  9.08it/s] 14%|█▍        | 199/1380 [00:23<02:10,  9.03it/s] 14%|█▍        | 200/1380 [00:23<02:12,  8.94it/s] 15%|█▍        | 201/1380 [00:23<02:11,  8.94it/s] 15%|█▍        | 202/1380 [00:23<02:11,  8.98it/s] 15%|█▍        | 203/1380 [00:23<02:10,  9.01it/s] 15%|█▍        | 204/1380 [00:24<02:11,  8.96it/s] 15%|█▍        | 205/1380 [00:24<02:08,  9.11it/s] 15%|█▍        | 206/1380 [00:24<02:10,  8.99it/s] 15%|█▌        | 207/1380 [00:24<02:10,  8.96it/s] 15%|█▌        | 208/1380 [00:24<02:11,  8.91it/s] 15%|█▌        | 209/1380 [00:24<02:09,  9.02it/s] 15%|█▌        | 210/1380 [00:24<02:10,  8.97it/s] 15%|█▌        | 211/1380 [00:24<02:10,  8.98it/s] 15%|█▌        | 212/1380 [00:24<02:09,  9.01it/s] 15%|█▌        | 213/1380 [00:25<02:10,  8.93it/s] 16%|█▌        | 214/1380 [00:25<02:11,  8.84it/s] 16%|█▌        | 215/1380 [00:25<02:11,  8.88it/s] 16%|█▌        | 216/1380 [00:25<02:09,  9.01it/s] 16%|█▌        | 217/1380 [00:25<02:08,  9.03it/s] 16%|█▌        | 218/1380 [00:25<02:08,  9.05it/s] 16%|█▌        | 219/1380 [00:25<02:08,  9.04it/s] 16%|█▌        | 220/1380 [00:25<02:08,  9.01it/s] 16%|█▌        | 221/1380 [00:25<02:09,  8.98it/s] 16%|█▌        | 222/1380 [00:26<02:10,  8.89it/s] 16%|█▌        | 223/1380 [00:26<02:09,  8.92it/s] 16%|█▌        | 224/1380 [00:26<02:09,  8.95it/s] 16%|█▋        | 225/1380 [00:26<02:09,  8.93it/s] 16%|█▋        | 226/1380 [00:26<02:07,  9.02it/s] 16%|█▋        | 227/1380 [00:26<02:07,  9.02it/s] 17%|█▋        | 228/1380 [00:26<02:09,  8.90it/s] 17%|█▋        | 229/1380 [00:26<02:08,  8.95it/s] 17%|█▋        | 230/1380 [00:26<02:08,  8.94it/s] 17%|█▋        | 231/1380 [00:27<02:08,  8.94it/s] 17%|█▋        | 232/1380 [00:27<02:08,  8.96it/s] 17%|█▋        | 233/1380 [00:27<02:05,  9.14it/s] 17%|█▋        | 234/1380 [00:27<02:06,  9.05it/s] 17%|█▋        | 235/1380 [00:27<02:07,  9.01it/s] 17%|█▋        | 236/1380 [00:27<02:07,  8.97it/s] 17%|█▋        | 237/1380 [00:27<02:06,  9.01it/s] 17%|█▋        | 238/1380 [00:27<02:06,  9.05it/s] 17%|█▋        | 239/1380 [00:27<02:07,  8.91it/s] 17%|█▋        | 240/1380 [00:28<02:06,  9.03it/s] 17%|█▋        | 241/1380 [00:28<02:06,  8.99it/s] 18%|█▊        | 242/1380 [00:28<02:06,  8.97it/s] 18%|█▊        | 243/1380 [00:28<02:06,  9.01it/s] 18%|█▊        | 244/1380 [00:28<02:07,  8.88it/s] 18%|█▊        | 245/1380 [00:28<02:08,  8.86it/s] 18%|█▊        | 246/1380 [00:28<02:07,  8.88it/s] 18%|█▊        | 247/1380 [00:28<02:07,  8.89it/s] 18%|█▊        | 248/1380 [00:28<02:07,  8.88it/s] 18%|█▊        | 249/1380 [00:29<02:07,  8.85it/s] 18%|█▊        | 250/1380 [00:29<02:06,  8.91it/s] 18%|█▊        | 251/1380 [00:29<02:06,  8.89it/s] 18%|█▊        | 252/1380 [00:29<02:05,  8.98it/s] 18%|█▊        | 253/1380 [00:29<02:03,  9.10it/s] 18%|█▊        | 254/1380 [00:29<02:05,  8.97it/s] 18%|█▊        | 255/1380 [00:29<02:06,  8.89it/s] 19%|█▊        | 256/1380 [00:29<02:06,  8.89it/s] 19%|█▊        | 257/1380 [00:29<02:05,  8.95it/s] 19%|█▊        | 258/1380 [00:30<02:04,  9.01it/s] 19%|█▉        | 259/1380 [00:30<02:05,  8.92it/s] 19%|█▉        | 260/1380 [00:30<02:04,  9.01it/s] 19%|█▉        | 261/1380 [00:30<02:04,  8.99it/s] 19%|█▉        | 262/1380 [00:30<02:04,  8.97it/s] 19%|█▉        | 263/1380 [00:30<02:03,  9.03it/s] 19%|█▉        | 264/1380 [00:30<02:03,  9.02it/s] 19%|█▉        | 265/1380 [00:30<02:05,  8.91it/s] 19%|█▉        | 266/1380 [00:30<02:04,  8.97it/s] 19%|█▉        | 267/1380 [00:31<02:04,  8.93it/s] 19%|█▉        | 268/1380 [00:31<02:04,  8.94it/s] 19%|█▉        | 269/1380 [00:31<02:04,  8.94it/s] 20%|█▉        | 270/1380 [00:31<02:04,  8.95it/s] 20%|█▉        | 271/1380 [00:31<02:04,  8.90it/s] 20%|█▉        | 272/1380 [00:31<02:04,  8.91it/s] 20%|█▉        | 273/1380 [00:31<02:03,  8.96it/s] 20%|█▉        | 274/1380 [00:31<02:03,  8.98it/s] 20%|█▉        | 275/1380 [00:31<02:03,  8.95it/s]                                                   20%|██        | 276/1380 [00:32<02:03,  8.95it/s][INFO|trainer.py:755] 2023-11-15 19:29:32,281 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:29:32,283 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:29:32,284 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:29:32,284 >>   Batch size = 8
{'loss': 0.4899, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 86.19it/s][A
  7%|▋         | 18/276 [00:00<00:03, 76.16it/s][A
  9%|▉         | 26/276 [00:00<00:03, 73.22it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 73.36it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 70.66it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 71.49it/s][A
 21%|██        | 58/276 [00:00<00:03, 71.43it/s][A
 24%|██▍       | 66/276 [00:00<00:02, 71.78it/s][A
 27%|██▋       | 74/276 [00:01<00:02, 68.33it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 70.00it/s][A
 33%|███▎      | 90/276 [00:01<00:02, 69.97it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 70.70it/s][A
 38%|███▊      | 106/276 [00:01<00:02, 68.12it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 69.48it/s][A
 44%|████▍     | 121/276 [00:01<00:02, 69.55it/s][A
 46%|████▋     | 128/276 [00:01<00:02, 69.43it/s][A
 49%|████▉     | 136/276 [00:01<00:02, 69.41it/s][A
 52%|█████▏    | 143/276 [00:02<00:01, 69.52it/s][A
 54%|█████▍    | 150/276 [00:02<00:01, 69.59it/s][A
 57%|█████▋    | 157/276 [00:02<00:01, 69.54it/s][A
 59%|█████▉    | 164/276 [00:02<00:01, 69.53it/s][A
 62%|██████▏   | 172/276 [00:02<00:01, 70.14it/s][A
 65%|██████▌   | 180/276 [00:02<00:01, 67.71it/s][A
 68%|██████▊   | 187/276 [00:02<00:01, 67.82it/s][A
 71%|███████   | 195/276 [00:02<00:01, 69.01it/s][A
 74%|███████▎  | 203/276 [00:02<00:01, 68.55it/s][A
 76%|███████▌  | 210/276 [00:03<00:00, 68.48it/s][A
 79%|███████▊  | 217/276 [00:03<00:00, 68.75it/s][A
 82%|████████▏ | 225/276 [00:03<00:00, 69.84it/s][A
 84%|████████▍ | 232/276 [00:03<00:00, 69.53it/s][A
 87%|████████▋ | 239/276 [00:03<00:00, 67.52it/s][A
 89%|████████▉ | 247/276 [00:03<00:00, 70.44it/s][A
 92%|█████████▏| 255/276 [00:03<00:00, 68.72it/s][A
 95%|█████████▍| 262/276 [00:03<00:00, 69.04it/s][A
 97%|█████████▋| 269/276 [00:03<00:00, 69.31it/s][A                                                  
                                                 [A 20%|██        | 276/1380 [00:36<02:03,  8.95it/s]
100%|██████████| 276/276 [00:03<00:00, 69.31it/s][A
                                                 [A 20%|██        | 277/1380 [00:36<18:58,  1.03s/it] 20%|██        | 278/1380 [00:36<14:47,  1.24it/s] 20%|██        | 279/1380 [00:36<11:28,  1.60it/s] 20%|██        | 280/1380 [00:36<08:54,  2.06it/s] 20%|██        | 281/1380 [00:36<06:58,  2.63it/s] 20%|██        | 282/1380 [00:36<05:32,  3.30it/s] 21%|██        | 283/1380 [00:36<04:33,  4.02it/s] 21%|██        | 284/1380 [00:36<03:49,  4.78it/s] 21%|██        | 285/1380 [00:37<03:17,  5.55it/s] 21%|██        | 286/1380 [00:37<02:55,  6.23it/s] 21%|██        | 287/1380 [00:37<02:40,  6.80it/s] 21%|██        | 288/1380 [00:37<02:30,  7.23it/s] 21%|██        | 289/1380 [00:37<02:23,  7.61it/s] 21%|██        | 290/1380 [00:37<02:16,  7.97it/s] 21%|██        | 291/1380 [00:37<02:12,  8.22it/s] 21%|██        | 292/1380 [00:37<02:07,  8.56it/s] 21%|██        | 293/1380 [00:37<02:07,  8.51it/s] 21%|██▏       | 294/1380 [00:38<02:06,  8.57it/s] 21%|██▏       | 295/1380 [00:38<02:06,  8.60it/s] 21%|██▏       | 296/1380 [00:38<02:04,  8.68it/s] 22%|██▏       | 297/1380 [00:38<02:04,  8.73it/s] 22%|██▏       | 298/1380 [00:38<02:03,  8.75it/s] 22%|██▏       | 299/1380 [00:38<02:02,  8.80it/s] 22%|██▏       | 300/1380 [00:38<02:02,  8.78it/s] 22%|██▏       | 301/1380 [00:38<02:02,  8.79it/s] 22%|██▏       | 302/1380 [00:38<02:02,  8.81it/s] 22%|██▏       | 303/1380 [00:39<02:01,  8.85it/s] 22%|██▏       | 304/1380 [00:39<02:01,  8.83it/s] 22%|██▏       | 305/1380 [00:39<02:02,  8.74it/s] 22%|██▏       | 306/1380 [00:39<02:02,  8.76it/s] 22%|██▏       | 307/1380 [00:39<02:03,  8.72it/s] 22%|██▏       | 308/1380 [00:39<02:02,  8.74it/s] 22%|██▏       | 309/1380 [00:39<02:01,  8.85it/s] 22%|██▏       | 310/1380 [00:39<02:01,  8.80it/s] 23%|██▎       | 311/1380 [00:40<02:02,  8.72it/s] 23%|██▎       | 312/1380 [00:40<02:02,  8.73it/s] 23%|██▎       | 313/1380 [00:40<02:02,  8.69it/s] 23%|██▎       | 314/1380 [00:40<02:02,  8.74it/s] 23%|██▎       | 315/1380 [00:40<02:02,  8.72it/s] 23%|██▎       | 316/1380 [00:40<02:00,  8.85it/s] 23%|██▎       | 317/1380 [00:40<02:01,  8.76it/s] 23%|██▎       | 318/1380 [00:40<02:01,  8.73it/s] 23%|██▎       | 319/1380 [00:40<02:01,  8.74it/s] 23%|██▎       | 320/1380 [00:41<02:00,  8.79it/s] 23%|██▎       | 321/1380 [00:41<02:01,  8.74it/s] 23%|██▎       | 322/1380 [00:41<02:01,  8.72it/s] 23%|██▎       | 323/1380 [00:41<02:00,  8.79it/s] 23%|██▎       | 324/1380 [00:41<02:00,  8.76it/s] 24%|██▎       | 325/1380 [00:41<01:59,  8.81it/s] 24%|██▎       | 326/1380 [00:41<01:58,  8.91it/s] 24%|██▎       | 327/1380 [00:41<01:58,  8.85it/s] 24%|██▍       | 328/1380 [00:41<02:00,  8.72it/s] 24%|██▍       | 329/1380 [00:42<02:00,  8.72it/s] 24%|██▍       | 330/1380 [00:42<02:00,  8.71it/s] 24%|██▍       | 331/1380 [00:42<01:59,  8.76it/s] 24%|██▍       | 332/1380 [00:42<02:00,  8.73it/s] 24%|██▍       | 333/1380 [00:42<01:58,  8.83it/s] 24%|██▍       | 334/1380 [00:42<01:59,  8.75it/s] 24%|██▍       | 335/1380 [00:42<02:00,  8.70it/s] 24%|██▍       | 336/1380 [00:42<01:59,  8.71it/s] 24%|██▍       | 337/1380 [00:42<01:59,  8.73it/s] 24%|██▍       | 338/1380 [00:43<01:58,  8.77it/s] 25%|██▍       | 339/1380 [00:43<02:00,  8.63it/s] 25%|██▍       | 340/1380 [00:43<01:59,  8.71it/s] 25%|██▍       | 341/1380 [00:43<01:59,  8.72it/s] 25%|██▍       | 342/1380 [00:43<01:58,  8.73it/s] 25%|██▍       | 343/1380 [00:43<01:58,  8.78it/s] 25%|██▍       | 344/1380 [00:43<01:58,  8.78it/s] 25%|██▌       | 345/1380 [00:43<01:59,  8.64it/s] 25%|██▌       | 346/1380 [00:44<01:59,  8.67it/s] 25%|██▌       | 347/1380 [00:44<01:59,  8.68it/s] 25%|██▌       | 348/1380 [00:44<01:58,  8.68it/s] 25%|██▌       | 349/1380 [00:44<01:58,  8.74it/s] 25%|██▌       | 350/1380 [00:44<01:56,  8.88it/s] 25%|██▌       | 351/1380 [00:44<01:57,  8.75it/s] 26%|██▌       | 352/1380 [00:44<01:58,  8.69it/s] 26%|██▌       | 353/1380 [00:44<01:57,  8.73it/s] 26%|██▌       | 354/1380 [00:44<01:58,  8.69it/s] 26%|██▌       | 355/1380 [00:45<01:57,  8.75it/s] 26%|██▌       | 356/1380 [00:45<01:57,  8.68it/s] 26%|██▌       | 357/1380 [00:45<01:55,  8.87it/s] 26%|██▌       | 358/1380 [00:45<01:57,  8.73it/s] 26%|██▌       | 359/1380 [00:45<01:56,  8.73it/s] 26%|██▌       | 360/1380 [00:45<01:56,  8.76it/s] 26%|██▌       | 361/1380 [00:45<01:57,  8.70it/s] 26%|██▌       | 362/1380 [00:45<01:56,  8.75it/s] 26%|██▋       | 363/1380 [00:45<01:56,  8.72it/s] 26%|██▋       | 364/1380 [00:46<01:53,  8.92it/s] 26%|██▋       | 365/1380 [00:46<01:56,  8.68it/s] 27%|██▋       | 366/1380 [00:46<01:56,  8.74it/s] 27%|██▋       | 367/1380 [00:46<01:55,  8.76it/s] 27%|██▋       | 368/1380 [00:46<01:56,  8.70it/s] 27%|██▋       | 369/1380 [00:46<01:54,  8.81it/s] 27%|██▋       | 370/1380 [00:46<01:55,  8.77it/s] 27%|██▋       | 371/1380 [00:46<01:53,  8.87it/s] 27%|██▋       | 372/1380 [00:46<01:55,  8.71it/s] 27%|██▋       | 373/1380 [00:47<01:55,  8.73it/s] 27%|██▋       | 374/1380 [00:47<01:55,  8.69it/s] 27%|██▋       | 375/1380 [00:47<01:55,  8.69it/s] 27%|██▋       | 376/1380 [00:47<01:55,  8.73it/s] 27%|██▋       | 377/1380 [00:47<01:55,  8.70it/s] 27%|██▋       | 378/1380 [00:47<01:53,  8.85it/s] 27%|██▋       | 379/1380 [00:47<01:54,  8.73it/s] 28%|██▊       | 380/1380 [00:47<01:54,  8.75it/s] 28%|██▊       | 381/1380 [00:48<01:55,  8.68it/s] 28%|██▊       | 382/1380 [00:48<01:54,  8.68it/s] 28%|██▊       | 383/1380 [00:48<01:54,  8.70it/s] 28%|██▊       | 384/1380 [00:48<01:56,  8.59it/s] 28%|██▊       | 385/1380 [00:48<01:53,  8.75it/s] 28%|██▊       | 386/1380 [00:48<01:54,  8.70it/s] 28%|██▊       | 387/1380 [00:48<01:53,  8.73it/s] 28%|██▊       | 388/1380 [00:48<01:53,  8.71it/s] 28%|██▊       | 389/1380 [00:48<01:53,  8.74it/s] 28%|██▊       | 390/1380 [00:49<01:53,  8.75it/s] 28%|██▊       | 391/1380 [00:49<01:53,  8.68it/s] 28%|██▊       | 392/1380 [00:49<01:52,  8.79it/s] 28%|██▊       | 393/1380 [00:49<01:52,  8.78it/s] 29%|██▊       | 394/1380 [00:49<01:52,  8.77it/s] 29%|██▊       | 395/1380 [00:49<01:51,  8.80it/s] 29%|██▊       | 396/1380 [00:49<01:51,  8.80it/s] 29%|██▉       | 397/1380 [00:49<01:53,  8.69it/s] 29%|██▉       | 398/1380 [00:49<01:52,  8.72it/s] 29%|██▉       | 399/1380 [00:50<01:51,  8.78it/s] 29%|██▉       | 400/1380 [00:50<01:52,  8.74it/s] 29%|██▉       | 401/1380 [00:50<01:51,  8.77it/s] 29%|██▉       | 402/1380 [00:50<01:50,  8.87it/s] 29%|██▉       | 403/1380 [00:50<01:51,  8.75it/s] 29%|██▉       | 404/1380 [00:50<01:51,  8.72it/s] 29%|██▉       | 405/1380 [00:50<01:51,  8.77it/s] 29%|██▉       | 406/1380 [00:50<01:51,  8.70it/s] 29%|██▉       | 407/1380 [00:50<01:51,  8.74it/s] 30%|██▉       | 408/1380 [00:51<01:51,  8.71it/s] 30%|██▉       | 409/1380 [00:51<01:50,  8.80it/s] 30%|██▉       | 410/1380 [00:51<01:50,  8.77it/s] 30%|██▉       | 411/1380 [00:51<01:50,  8.79it/s] 30%|██▉       | 412/1380 [00:51<01:50,  8.78it/s] 30%|██▉       | 413/1380 [00:51<01:49,  8.86it/s] 30%|███       | 414/1380 [00:51<01:49,  8.79it/s] 30%|███       | 415/1380 [00:51<01:50,  8.73it/s] 30%|███       | 416/1380 [00:52<01:49,  8.83it/s] 30%|███       | 417/1380 [00:52<01:49,  8.80it/s] 30%|███       | 418/1380 [00:52<01:49,  8.80it/s] 30%|███       | 419/1380 [00:52<01:48,  8.87it/s] 30%|███       | 420/1380 [00:52<01:49,  8.81it/s] 31%|███       | 421/1380 [00:52<01:49,  8.75it/s] 31%|███       | 422/1380 [00:52<01:49,  8.74it/s] 31%|███       | 423/1380 [00:52<01:49,  8.74it/s] 31%|███       | 424/1380 [00:52<01:48,  8.77it/s] 31%|███       | 425/1380 [00:53<01:48,  8.77it/s] 31%|███       | 426/1380 [00:53<01:47,  8.90it/s] 31%|███       | 427/1380 [00:53<01:48,  8.77it/s] 31%|███       | 428/1380 [00:53<01:49,  8.67it/s] 31%|███       | 429/1380 [00:53<01:49,  8.68it/s] 31%|███       | 430/1380 [00:53<01:48,  8.74it/s] 31%|███       | 431/1380 [00:53<01:48,  8.73it/s] 31%|███▏      | 432/1380 [00:53<01:49,  8.66it/s] 31%|███▏      | 433/1380 [00:53<01:48,  8.74it/s] 31%|███▏      | 434/1380 [00:54<01:47,  8.76it/s] 32%|███▏      | 435/1380 [00:54<01:47,  8.78it/s] 32%|███▏      | 436/1380 [00:54<01:47,  8.81it/s] 32%|███▏      | 437/1380 [00:54<01:46,  8.86it/s] 32%|███▏      | 438/1380 [00:54<01:47,  8.74it/s] 32%|███▏      | 439/1380 [00:54<01:48,  8.68it/s] 32%|███▏      | 440/1380 [00:54<01:48,  8.69it/s] 32%|███▏      | 441/1380 [00:54<01:47,  8.70it/s] 32%|███▏      | 442/1380 [00:54<01:47,  8.73it/s] 32%|███▏      | 443/1380 [00:55<01:46,  8.82it/s] 32%|███▏      | 444/1380 [00:55<01:47,  8.72it/s] 32%|███▏      | 445/1380 [00:55<01:48,  8.65it/s] 32%|███▏      | 446/1380 [00:55<01:47,  8.66it/s] 32%|███▏      | 447/1380 [00:55<01:47,  8.69it/s] 32%|███▏      | 448/1380 [00:55<01:47,  8.69it/s] 33%|███▎      | 449/1380 [00:55<01:47,  8.67it/s] 33%|███▎      | 450/1380 [00:55<01:46,  8.76it/s] 33%|███▎      | 451/1380 [00:56<01:46,  8.71it/s] 33%|███▎      | 452/1380 [00:56<01:46,  8.70it/s] 33%|███▎      | 453/1380 [00:56<01:45,  8.80it/s] 33%|███▎      | 454/1380 [00:56<01:46,  8.71it/s] 33%|███▎      | 455/1380 [00:56<01:47,  8.64it/s] 33%|███▎      | 456/1380 [00:56<01:47,  8.62it/s] 33%|███▎      | 457/1380 [00:56<01:47,  8.60it/s] 33%|███▎      | 458/1380 [00:56<01:47,  8.60it/s] 33%|███▎      | 459/1380 [00:56<01:46,  8.63it/s] 33%|███▎      | 460/1380 [00:57<01:44,  8.78it/s] 33%|███▎      | 461/1380 [00:57<01:45,  8.68it/s] 33%|███▎      | 462/1380 [00:57<01:45,  8.68it/s] 34%|███▎      | 463/1380 [00:57<01:45,  8.65it/s] 34%|███▎      | 464/1380 [00:57<01:44,  8.74it/s] 34%|███▎      | 465/1380 [00:57<01:45,  8.64it/s] 34%|███▍      | 466/1380 [00:57<01:45,  8.63it/s] 34%|███▍      | 467/1380 [00:57<01:45,  8.66it/s] 34%|███▍      | 468/1380 [00:57<01:45,  8.66it/s] 34%|███▍      | 469/1380 [00:58<01:44,  8.72it/s] 34%|███▍      | 470/1380 [00:58<01:43,  8.82it/s] 34%|███▍      | 471/1380 [00:58<01:44,  8.72it/s] 34%|███▍      | 472/1380 [00:58<01:45,  8.64it/s] 34%|███▍      | 473/1380 [00:58<01:44,  8.66it/s] 34%|███▍      | 474/1380 [00:58<01:45,  8.57it/s] 34%|███▍      | 475/1380 [00:58<01:44,  8.63it/s] 34%|███▍      | 476/1380 [00:58<01:44,  8.62it/s] 35%|███▍      | 477/1380 [00:59<01:42,  8.80it/s] 35%|███▍      | 478/1380 [00:59<01:43,  8.71it/s] 35%|███▍      | 479/1380 [00:59<01:43,  8.67it/s] 35%|███▍      | 480/1380 [00:59<01:43,  8.66it/s] 35%|███▍      | 481/1380 [00:59<01:42,  8.74it/s] 35%|███▍      | 482/1380 [00:59<01:43,  8.64it/s] 35%|███▌      | 483/1380 [00:59<01:44,  8.60it/s] 35%|███▌      | 484/1380 [00:59<01:43,  8.69it/s] 35%|███▌      | 485/1380 [00:59<01:43,  8.67it/s] 35%|███▌      | 486/1380 [01:00<01:43,  8.64it/s] 35%|███▌      | 487/1380 [01:00<01:42,  8.74it/s] 35%|███▌      | 488/1380 [01:00<01:43,  8.66it/s] 35%|███▌      | 489/1380 [01:00<01:43,  8.63it/s] 36%|███▌      | 490/1380 [01:00<01:43,  8.57it/s] 36%|███▌      | 491/1380 [01:00<01:43,  8.60it/s] 36%|███▌      | 492/1380 [01:00<01:42,  8.67it/s] 36%|███▌      | 493/1380 [01:00<01:42,  8.67it/s] 36%|███▌      | 494/1380 [01:00<01:40,  8.80it/s] 36%|███▌      | 495/1380 [01:01<01:41,  8.71it/s] 36%|███▌      | 496/1380 [01:01<01:41,  8.71it/s] 36%|███▌      | 497/1380 [01:01<01:41,  8.71it/s] 36%|███▌      | 498/1380 [01:01<01:41,  8.73it/s] 36%|███▌      | 499/1380 [01:01<01:40,  8.73it/s] 36%|███▌      | 500/1380 [01:01<01:41,  8.70it/s] 36%|███▋      | 501/1380 [01:01<01:40,  8.77it/s] 36%|███▋      | 502/1380 [01:01<01:40,  8.73it/s] 36%|███▋      | 503/1380 [01:02<01:40,  8.72it/s] 37%|███▋      | 504/1380 [01:02<01:39,  8.81it/s] 37%|███▋      | 505/1380 [01:02<01:40,  8.74it/s] 37%|███▋      | 506/1380 [01:02<01:40,  8.70it/s] 37%|███▋      | 507/1380 [01:02<01:40,  8.66it/s] 37%|███▋      | 508/1380 [01:02<01:40,  8.67it/s] 37%|███▋      | 509/1380 [01:02<01:39,  8.73it/s] 37%|███▋      | 510/1380 [01:02<01:40,  8.69it/s] 37%|███▋      | 511/1380 [01:02<01:38,  8.79it/s] 37%|███▋      | 512/1380 [01:03<01:40,  8.67it/s] 37%|███▋      | 513/1380 [01:03<01:39,  8.69it/s] 37%|███▋      | 514/1380 [01:03<01:39,  8.70it/s] 37%|███▋      | 515/1380 [01:03<01:39,  8.74it/s] 37%|███▋      | 516/1380 [01:03<01:39,  8.68it/s] 37%|███▋      | 517/1380 [01:03<01:39,  8.65it/s] 38%|███▊      | 518/1380 [01:03<01:38,  8.74it/s] 38%|███▊      | 519/1380 [01:03<01:39,  8.66it/s] 38%|███▊      | 520/1380 [01:03<01:38,  8.71it/s] 38%|███▊      | 521/1380 [01:04<01:37,  8.83it/s] 38%|███▊      | 522/1380 [01:04<01:38,  8.75it/s] 38%|███▊      | 523/1380 [01:04<01:37,  8.77it/s] 38%|███▊      | 524/1380 [01:04<01:37,  8.78it/s] 38%|███▊      | 525/1380 [01:04<01:38,  8.72it/s] 38%|███▊      | 526/1380 [01:04<01:37,  8.74it/s] 38%|███▊      | 527/1380 [01:04<01:38,  8.66it/s] 38%|███▊      | 528/1380 [01:04<01:36,  8.79it/s] 38%|███▊      | 529/1380 [01:05<01:38,  8.63it/s] 38%|███▊      | 530/1380 [01:05<01:37,  8.69it/s] 38%|███▊      | 531/1380 [01:05<01:36,  8.79it/s] 39%|███▊      | 532/1380 [01:05<01:36,  8.80it/s] 39%|███▊      | 533/1380 [01:05<01:37,  8.67it/s] 39%|███▊      | 534/1380 [01:05<01:37,  8.69it/s] 39%|███▉      | 535/1380 [01:05<01:36,  8.75it/s] 39%|███▉      | 536/1380 [01:05<01:36,  8.73it/s] 39%|███▉      | 537/1380 [01:05<01:36,  8.77it/s] 39%|███▉      | 538/1380 [01:06<01:35,  8.86it/s] 39%|███▉      | 539/1380 [01:06<01:36,  8.67it/s] 39%|███▉      | 540/1380 [01:06<01:36,  8.71it/s] 39%|███▉      | 541/1380 [01:06<01:36,  8.65it/s] 39%|███▉      | 542/1380 [01:06<01:36,  8.72it/s] 39%|███▉      | 543/1380 [01:06<01:35,  8.78it/s] 39%|███▉      | 544/1380 [01:06<01:35,  8.72it/s] 39%|███▉      | 545/1380 [01:06<01:35,  8.73it/s] 40%|███▉      | 546/1380 [01:06<01:36,  8.66it/s] 40%|███▉      | 547/1380 [01:07<01:35,  8.74it/s] 40%|███▉      | 548/1380 [01:07<01:34,  8.79it/s] 40%|███▉      | 549/1380 [01:07<01:34,  8.79it/s] 40%|███▉      | 550/1380 [01:07<01:35,  8.68it/s] 40%|███▉      | 551/1380 [01:07<01:35,  8.67it/s]                                                   40%|████      | 552/1380 [01:07<01:35,  8.67it/s][INFO|trainer.py:755] 2023-11-15 19:30:07,860 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:30:07,862 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:30:07,863 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:30:07,863 >>   Batch size = 8
{'eval_loss': 0.41675227880477905, 'eval_accuracy': 0.8507259528130672, 'eval_micro_f1': 0.8507259528130672, 'eval_macro_f1': 0.8343847634591578, 'eval_runtime': 4.0196, 'eval_samples_per_second': 548.31, 'eval_steps_per_second': 68.663, 'epoch': 1.0}
{'loss': 0.339, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 8/276 [00:00<00:03, 79.79it/s][A
  6%|▌         | 16/276 [00:00<00:03, 73.77it/s][A
  9%|▊         | 24/276 [00:00<00:03, 73.62it/s][A
 12%|█▏        | 32/276 [00:00<00:03, 70.88it/s][A
 14%|█▍        | 40/276 [00:00<00:03, 68.84it/s][A
 17%|█▋        | 47/276 [00:00<00:03, 68.31it/s][A
 20%|█▉        | 55/276 [00:00<00:03, 68.67it/s][A
 22%|██▏       | 62/276 [00:00<00:03, 68.75it/s][A
 25%|██▌       | 69/276 [00:00<00:03, 68.04it/s][A
 28%|██▊       | 76/276 [00:01<00:02, 68.59it/s][A
 30%|███       | 83/276 [00:01<00:02, 68.81it/s][A
 33%|███▎      | 90/276 [00:01<00:02, 68.16it/s][A
 35%|███▌      | 97/276 [00:01<00:02, 66.21it/s][A
 38%|███▊      | 105/276 [00:01<00:02, 67.76it/s][A
 41%|████      | 112/276 [00:01<00:02, 66.91it/s][A
 43%|████▎     | 119/276 [00:01<00:02, 67.62it/s][A
 46%|████▌     | 126/276 [00:01<00:02, 67.99it/s][A
 49%|████▊     | 134/276 [00:01<00:02, 68.05it/s][A
 51%|█████     | 141/276 [00:02<00:01, 68.42it/s][A
 54%|█████▎    | 148/276 [00:02<00:01, 68.60it/s][A
 56%|█████▌    | 155/276 [00:02<00:01, 68.80it/s][A
 59%|█████▉    | 163/276 [00:02<00:01, 69.93it/s][A
 62%|██████▏   | 170/276 [00:02<00:01, 69.75it/s][A
 64%|██████▍   | 177/276 [00:02<00:01, 67.10it/s][A
 67%|██████▋   | 185/276 [00:02<00:01, 69.21it/s][A
 70%|██████▉   | 192/276 [00:02<00:01, 68.08it/s][A
 72%|███████▏  | 199/276 [00:02<00:01, 67.13it/s][A
 75%|███████▍  | 206/276 [00:03<00:01, 67.41it/s][A
 77%|███████▋  | 213/276 [00:03<00:00, 67.12it/s][A
 80%|███████▉  | 220/276 [00:03<00:00, 67.76it/s][A
 83%|████████▎ | 228/276 [00:03<00:00, 69.11it/s][A
 86%|████████▌ | 236/276 [00:03<00:00, 70.66it/s][A
 88%|████████▊ | 244/276 [00:03<00:00, 68.10it/s][A
 91%|█████████ | 251/276 [00:03<00:00, 66.42it/s][A
 94%|█████████▍| 259/276 [00:03<00:00, 67.33it/s][A
 96%|█████████▋| 266/276 [00:03<00:00, 67.98it/s][A
 99%|█████████▉| 273/276 [00:03<00:00, 68.19it/s][A                                                  
                                                 [A 40%|████      | 552/1380 [01:11<01:35,  8.67it/s]
100%|██████████| 276/276 [00:04<00:00, 68.19it/s][A
                                                 [A 40%|████      | 553/1380 [01:11<14:30,  1.05s/it] 40%|████      | 554/1380 [01:11<11:17,  1.22it/s] 40%|████      | 555/1380 [01:12<08:45,  1.57it/s] 40%|████      | 556/1380 [01:12<06:48,  2.02it/s] 40%|████      | 557/1380 [01:12<05:20,  2.57it/s] 40%|████      | 558/1380 [01:12<04:15,  3.22it/s] 41%|████      | 559/1380 [01:12<03:27,  3.95it/s] 41%|████      | 560/1380 [01:12<02:53,  4.74it/s] 41%|████      | 561/1380 [01:12<02:29,  5.46it/s] 41%|████      | 562/1380 [01:12<02:13,  6.14it/s] 41%|████      | 563/1380 [01:12<02:01,  6.71it/s] 41%|████      | 564/1380 [01:13<01:53,  7.20it/s] 41%|████      | 565/1380 [01:13<01:47,  7.61it/s] 41%|████      | 566/1380 [01:13<01:43,  7.85it/s] 41%|████      | 567/1380 [01:13<01:39,  8.16it/s] 41%|████      | 568/1380 [01:13<01:38,  8.27it/s] 41%|████      | 569/1380 [01:13<01:36,  8.44it/s] 41%|████▏     | 570/1380 [01:13<01:34,  8.59it/s] 41%|████▏     | 571/1380 [01:13<01:33,  8.65it/s] 41%|████▏     | 572/1380 [01:13<01:35,  8.48it/s] 42%|████▏     | 573/1380 [01:14<01:34,  8.52it/s] 42%|████▏     | 574/1380 [01:14<01:33,  8.58it/s] 42%|████▏     | 575/1380 [01:14<01:33,  8.63it/s] 42%|████▏     | 576/1380 [01:14<01:33,  8.63it/s] 42%|████▏     | 577/1380 [01:14<01:31,  8.75it/s] 42%|████▏     | 578/1380 [01:14<01:32,  8.69it/s] 42%|████▏     | 579/1380 [01:14<01:32,  8.67it/s] 42%|████▏     | 580/1380 [01:14<01:32,  8.68it/s] 42%|████▏     | 581/1380 [01:15<01:31,  8.74it/s] 42%|████▏     | 582/1380 [01:15<01:31,  8.72it/s] 42%|████▏     | 583/1380 [01:15<01:31,  8.71it/s] 42%|████▏     | 584/1380 [01:15<01:31,  8.71it/s] 42%|████▏     | 585/1380 [01:15<01:31,  8.66it/s] 42%|████▏     | 586/1380 [01:15<01:31,  8.71it/s] 43%|████▎     | 587/1380 [01:15<01:30,  8.78it/s] 43%|████▎     | 588/1380 [01:15<01:31,  8.68it/s] 43%|████▎     | 589/1380 [01:15<01:31,  8.66it/s] 43%|████▎     | 590/1380 [01:16<01:31,  8.66it/s] 43%|████▎     | 591/1380 [01:16<01:30,  8.67it/s] 43%|████▎     | 592/1380 [01:16<01:30,  8.73it/s] 43%|████▎     | 593/1380 [01:16<01:30,  8.70it/s] 43%|████▎     | 594/1380 [01:16<01:29,  8.76it/s] 43%|████▎     | 595/1380 [01:16<01:29,  8.73it/s] 43%|████▎     | 596/1380 [01:16<01:30,  8.70it/s] 43%|████▎     | 597/1380 [01:16<01:29,  8.71it/s] 43%|████▎     | 598/1380 [01:16<01:29,  8.73it/s] 43%|████▎     | 599/1380 [01:17<01:29,  8.71it/s] 43%|████▎     | 600/1380 [01:17<01:30,  8.64it/s] 44%|████▎     | 601/1380 [01:17<01:29,  8.67it/s] 44%|████▎     | 602/1380 [01:17<01:29,  8.72it/s] 44%|████▎     | 603/1380 [01:17<01:29,  8.68it/s] 44%|████▍     | 604/1380 [01:17<01:28,  8.80it/s] 44%|████▍     | 605/1380 [01:17<01:28,  8.71it/s] 44%|████▍     | 606/1380 [01:17<01:29,  8.68it/s] 44%|████▍     | 607/1380 [01:18<01:29,  8.68it/s] 44%|████▍     | 608/1380 [01:18<01:29,  8.63it/s] 44%|████▍     | 609/1380 [01:18<01:28,  8.69it/s] 44%|████▍     | 610/1380 [01:18<01:28,  8.72it/s] 44%|████▍     | 611/1380 [01:18<01:27,  8.76it/s] 44%|████▍     | 612/1380 [01:18<01:28,  8.71it/s] 44%|████▍     | 613/1380 [01:18<01:28,  8.67it/s] 44%|████▍     | 614/1380 [01:18<01:28,  8.66it/s] 45%|████▍     | 615/1380 [01:18<01:28,  8.67it/s] 45%|████▍     | 616/1380 [01:19<01:27,  8.69it/s] 45%|████▍     | 617/1380 [01:19<01:27,  8.69it/s] 45%|████▍     | 618/1380 [01:19<01:27,  8.75it/s] 45%|████▍     | 619/1380 [01:19<01:27,  8.72it/s] 45%|████▍     | 620/1380 [01:19<01:27,  8.67it/s] 45%|████▌     | 621/1380 [01:19<01:26,  8.73it/s] 45%|████▌     | 622/1380 [01:19<01:27,  8.65it/s] 45%|████▌     | 623/1380 [01:19<01:27,  8.63it/s] 45%|████▌     | 624/1380 [01:19<01:27,  8.62it/s] 45%|████▌     | 625/1380 [01:20<01:27,  8.62it/s] 45%|████▌     | 626/1380 [01:20<01:27,  8.67it/s] 45%|████▌     | 627/1380 [01:20<01:27,  8.65it/s] 46%|████▌     | 628/1380 [01:20<01:26,  8.70it/s] 46%|████▌     | 629/1380 [01:20<01:26,  8.69it/s] 46%|████▌     | 630/1380 [01:20<01:26,  8.67it/s] 46%|████▌     | 631/1380 [01:20<01:26,  8.69it/s] 46%|████▌     | 632/1380 [01:20<01:25,  8.74it/s] 46%|████▌     | 633/1380 [01:21<01:26,  8.63it/s] 46%|████▌     | 634/1380 [01:21<01:26,  8.59it/s] 46%|████▌     | 635/1380 [01:21<01:27,  8.54it/s] 46%|████▌     | 636/1380 [01:21<01:26,  8.59it/s] 46%|████▌     | 637/1380 [01:21<01:25,  8.68it/s] 46%|████▌     | 638/1380 [01:21<01:24,  8.77it/s] 46%|████▋     | 639/1380 [01:21<01:26,  8.60it/s] 46%|████▋     | 640/1380 [01:21<01:25,  8.65it/s] 46%|████▋     | 641/1380 [01:21<01:25,  8.61it/s] 47%|████▋     | 642/1380 [01:22<01:25,  8.65it/s] 47%|████▋     | 643/1380 [01:22<01:25,  8.66it/s] 47%|████▋     | 644/1380 [01:22<01:25,  8.60it/s] 47%|████▋     | 645/1380 [01:22<01:24,  8.65it/s] 47%|████▋     | 646/1380 [01:22<01:24,  8.71it/s] 47%|████▋     | 647/1380 [01:22<01:24,  8.72it/s] 47%|████▋     | 648/1380 [01:22<01:23,  8.76it/s] 47%|████▋     | 649/1380 [01:22<01:24,  8.65it/s] 47%|████▋     | 650/1380 [01:22<01:24,  8.64it/s] 47%|████▋     | 651/1380 [01:23<01:24,  8.65it/s] 47%|████▋     | 652/1380 [01:23<01:24,  8.63it/s] 47%|████▋     | 653/1380 [01:23<01:23,  8.68it/s] 47%|████▋     | 654/1380 [01:23<01:23,  8.65it/s] 47%|████▋     | 655/1380 [01:23<01:22,  8.82it/s] 48%|████▊     | 656/1380 [01:23<01:23,  8.72it/s] 48%|████▊     | 657/1380 [01:23<01:23,  8.69it/s] 48%|████▊     | 658/1380 [01:23<01:22,  8.70it/s] 48%|████▊     | 659/1380 [01:24<01:23,  8.68it/s] 48%|████▊     | 660/1380 [01:24<01:23,  8.65it/s] 48%|████▊     | 661/1380 [01:24<01:22,  8.67it/s] 48%|████▊     | 662/1380 [01:24<01:22,  8.69it/s] 48%|████▊     | 663/1380 [01:24<01:22,  8.68it/s] 48%|████▊     | 664/1380 [01:24<01:22,  8.68it/s] 48%|████▊     | 665/1380 [01:24<01:21,  8.81it/s] 48%|████▊     | 666/1380 [01:24<01:22,  8.66it/s] 48%|████▊     | 667/1380 [01:24<01:22,  8.64it/s] 48%|████▊     | 668/1380 [01:25<01:22,  8.63it/s] 48%|████▊     | 669/1380 [01:25<01:22,  8.67it/s] 49%|████▊     | 670/1380 [01:25<01:21,  8.68it/s] 49%|████▊     | 671/1380 [01:25<01:22,  8.64it/s] 49%|████▊     | 672/1380 [01:25<01:21,  8.66it/s] 49%|████▉     | 673/1380 [01:25<01:22,  8.60it/s] 49%|████▉     | 674/1380 [01:25<01:21,  8.63it/s] 49%|████▉     | 675/1380 [01:25<01:20,  8.71it/s] 49%|████▉     | 676/1380 [01:25<01:21,  8.59it/s] 49%|████▉     | 677/1380 [01:26<01:22,  8.57it/s] 49%|████▉     | 678/1380 [01:26<01:22,  8.56it/s] 49%|████▉     | 679/1380 [01:26<01:21,  8.56it/s] 49%|████▉     | 680/1380 [01:26<01:21,  8.61it/s] 49%|████▉     | 681/1380 [01:26<01:21,  8.63it/s] 49%|████▉     | 682/1380 [01:26<01:20,  8.72it/s] 49%|████▉     | 683/1380 [01:26<01:20,  8.67it/s] 50%|████▉     | 684/1380 [01:26<01:20,  8.61it/s] 50%|████▉     | 685/1380 [01:27<01:20,  8.61it/s] 50%|████▉     | 686/1380 [01:27<01:20,  8.66it/s] 50%|████▉     | 687/1380 [01:27<01:20,  8.59it/s] 50%|████▉     | 688/1380 [01:27<01:20,  8.55it/s] 50%|████▉     | 689/1380 [01:27<01:20,  8.63it/s] 50%|█████     | 690/1380 [01:27<01:20,  8.58it/s] 50%|█████     | 691/1380 [01:27<01:19,  8.64it/s] 50%|█████     | 692/1380 [01:27<01:18,  8.72it/s] 50%|█████     | 693/1380 [01:27<01:19,  8.63it/s] 50%|█████     | 694/1380 [01:28<01:19,  8.60it/s] 50%|█████     | 695/1380 [01:28<01:19,  8.59it/s] 50%|█████     | 696/1380 [01:28<01:18,  8.66it/s] 51%|█████     | 697/1380 [01:28<01:18,  8.67it/s] 51%|█████     | 698/1380 [01:28<01:19,  8.62it/s] 51%|█████     | 699/1380 [01:28<01:18,  8.71it/s] 51%|█████     | 700/1380 [01:28<01:18,  8.68it/s] 51%|█████     | 701/1380 [01:28<01:18,  8.65it/s] 51%|█████     | 702/1380 [01:28<01:18,  8.64it/s] 51%|█████     | 703/1380 [01:29<01:18,  8.68it/s] 51%|█████     | 704/1380 [01:29<01:18,  8.58it/s] 51%|█████     | 705/1380 [01:29<01:18,  8.57it/s] 51%|█████     | 706/1380 [01:29<01:18,  8.56it/s] 51%|█████     | 707/1380 [01:29<01:18,  8.58it/s] 51%|█████▏    | 708/1380 [01:29<01:17,  8.62it/s] 51%|█████▏    | 709/1380 [01:29<01:16,  8.75it/s] 51%|█████▏    | 710/1380 [01:29<01:17,  8.63it/s] 52%|█████▏    | 711/1380 [01:30<01:17,  8.62it/s] 52%|█████▏    | 712/1380 [01:30<01:17,  8.56it/s] 52%|█████▏    | 713/1380 [01:30<01:17,  8.60it/s] 52%|█████▏    | 714/1380 [01:30<01:16,  8.66it/s] 52%|█████▏    | 715/1380 [01:30<01:16,  8.64it/s] 52%|█████▏    | 716/1380 [01:30<01:16,  8.70it/s] 52%|█████▏    | 717/1380 [01:30<01:16,  8.66it/s] 52%|█████▏    | 718/1380 [01:30<01:16,  8.68it/s] 52%|█████▏    | 719/1380 [01:30<01:16,  8.69it/s] 52%|█████▏    | 720/1380 [01:31<01:16,  8.65it/s] 52%|█████▏    | 721/1380 [01:31<01:16,  8.61it/s] 52%|█████▏    | 722/1380 [01:31<01:16,  8.61it/s] 52%|█████▏    | 723/1380 [01:31<01:16,  8.61it/s] 52%|█████▏    | 724/1380 [01:31<01:16,  8.60it/s] 53%|█████▎    | 725/1380 [01:31<01:15,  8.65it/s] 53%|█████▎    | 726/1380 [01:31<01:14,  8.78it/s] 53%|█████▎    | 727/1380 [01:31<01:15,  8.68it/s] 53%|█████▎    | 728/1380 [01:31<01:15,  8.67it/s] 53%|█████▎    | 729/1380 [01:32<01:15,  8.65it/s] 53%|█████▎    | 730/1380 [01:32<01:15,  8.64it/s] 53%|█████▎    | 731/1380 [01:32<01:15,  8.65it/s] 53%|█████▎    | 732/1380 [01:32<01:15,  8.58it/s] 53%|█████▎    | 733/1380 [01:32<01:14,  8.69it/s] 53%|█████▎    | 734/1380 [01:32<01:14,  8.62it/s] 53%|█████▎    | 735/1380 [01:32<01:15,  8.59it/s] 53%|█████▎    | 736/1380 [01:32<01:14,  8.68it/s] 53%|█████▎    | 737/1380 [01:33<01:14,  8.62it/s] 53%|█████▎    | 738/1380 [01:33<01:14,  8.62it/s] 54%|█████▎    | 739/1380 [01:33<01:14,  8.60it/s] 54%|█████▎    | 740/1380 [01:33<01:14,  8.58it/s] 54%|█████▎    | 741/1380 [01:33<01:13,  8.64it/s] 54%|█████▍    | 742/1380 [01:33<01:14,  8.57it/s] 54%|█████▍    | 743/1380 [01:33<01:13,  8.66it/s] 54%|█████▍    | 744/1380 [01:33<01:13,  8.65it/s] 54%|█████▍    | 745/1380 [01:33<01:13,  8.68it/s] 54%|█████▍    | 746/1380 [01:34<01:13,  8.66it/s] 54%|█████▍    | 747/1380 [01:34<01:12,  8.71it/s] 54%|█████▍    | 748/1380 [01:34<01:13,  8.63it/s] 54%|█████▍    | 749/1380 [01:34<01:13,  8.62it/s] 54%|█████▍    | 750/1380 [01:34<01:13,  8.59it/s] 54%|█████▍    | 751/1380 [01:34<01:12,  8.62it/s] 54%|█████▍    | 752/1380 [01:34<01:13,  8.60it/s] 55%|█████▍    | 753/1380 [01:34<01:12,  8.67it/s] 55%|█████▍    | 754/1380 [01:35<01:12,  8.63it/s] 55%|█████▍    | 755/1380 [01:35<01:12,  8.61it/s] 55%|█████▍    | 756/1380 [01:35<01:12,  8.60it/s] 55%|█████▍    | 757/1380 [01:35<01:11,  8.68it/s] 55%|█████▍    | 758/1380 [01:35<01:11,  8.68it/s] 55%|█████▌    | 759/1380 [01:35<01:12,  8.58it/s] 55%|█████▌    | 760/1380 [01:35<01:12,  8.61it/s] 55%|█████▌    | 761/1380 [01:35<01:11,  8.66it/s] 55%|█████▌    | 762/1380 [01:35<01:11,  8.66it/s] 55%|█████▌    | 763/1380 [01:36<01:10,  8.74it/s] 55%|█████▌    | 764/1380 [01:36<01:11,  8.59it/s] 55%|█████▌    | 765/1380 [01:36<01:12,  8.54it/s] 56%|█████▌    | 766/1380 [01:36<01:11,  8.54it/s] 56%|█████▌    | 767/1380 [01:36<01:11,  8.62it/s] 56%|█████▌    | 768/1380 [01:36<01:10,  8.64it/s] 56%|█████▌    | 769/1380 [01:36<01:11,  8.57it/s] 56%|█████▌    | 770/1380 [01:36<01:11,  8.59it/s] 56%|█████▌    | 771/1380 [01:36<01:11,  8.55it/s] 56%|█████▌    | 772/1380 [01:37<01:10,  8.60it/s] 56%|█████▌    | 773/1380 [01:37<01:09,  8.71it/s] 56%|█████▌    | 774/1380 [01:37<01:10,  8.60it/s] 56%|█████▌    | 775/1380 [01:37<01:10,  8.59it/s] 56%|█████▌    | 776/1380 [01:37<01:10,  8.59it/s] 56%|█████▋    | 777/1380 [01:37<01:10,  8.60it/s] 56%|█████▋    | 778/1380 [01:37<01:09,  8.64it/s] 56%|█████▋    | 779/1380 [01:37<01:09,  8.59it/s] 57%|█████▋    | 780/1380 [01:38<01:08,  8.72it/s] 57%|█████▋    | 781/1380 [01:38<01:09,  8.67it/s] 57%|█████▋    | 782/1380 [01:38<01:09,  8.65it/s] 57%|█████▋    | 783/1380 [01:38<01:08,  8.73it/s] 57%|█████▋    | 784/1380 [01:38<01:07,  8.77it/s] 57%|█████▋    | 785/1380 [01:38<01:08,  8.68it/s] 57%|█████▋    | 786/1380 [01:38<01:08,  8.65it/s] 57%|█████▋    | 787/1380 [01:38<01:08,  8.65it/s] 57%|█████▋    | 788/1380 [01:38<01:08,  8.64it/s] 57%|█████▋    | 789/1380 [01:39<01:08,  8.64it/s] 57%|█████▋    | 790/1380 [01:39<01:07,  8.77it/s] 57%|█████▋    | 791/1380 [01:39<01:07,  8.70it/s] 57%|█████▋    | 792/1380 [01:39<01:07,  8.67it/s] 57%|█████▋    | 793/1380 [01:39<01:08,  8.61it/s] 58%|█████▊    | 794/1380 [01:39<01:07,  8.66it/s] 58%|█████▊    | 795/1380 [01:39<01:07,  8.67it/s] 58%|█████▊    | 796/1380 [01:39<01:08,  8.57it/s] 58%|█████▊    | 797/1380 [01:39<01:07,  8.62it/s] 58%|█████▊    | 798/1380 [01:40<01:07,  8.62it/s] 58%|█████▊    | 799/1380 [01:40<01:07,  8.62it/s] 58%|█████▊    | 800/1380 [01:40<01:06,  8.70it/s] 58%|█████▊    | 801/1380 [01:40<01:06,  8.68it/s] 58%|█████▊    | 802/1380 [01:40<01:07,  8.60it/s] 58%|█████▊    | 803/1380 [01:40<01:07,  8.59it/s] 58%|█████▊    | 804/1380 [01:40<01:06,  8.62it/s] 58%|█████▊    | 805/1380 [01:40<01:06,  8.67it/s] 58%|█████▊    | 806/1380 [01:41<01:06,  8.61it/s] 58%|█████▊    | 807/1380 [01:41<01:05,  8.72it/s] 59%|█████▊    | 808/1380 [01:41<01:06,  8.63it/s] 59%|█████▊    | 809/1380 [01:41<01:05,  8.70it/s] 59%|█████▊    | 810/1380 [01:41<01:05,  8.70it/s] 59%|█████▉    | 811/1380 [01:41<01:05,  8.73it/s] 59%|█████▉    | 812/1380 [01:41<01:06,  8.56it/s] 59%|█████▉    | 813/1380 [01:41<01:05,  8.63it/s] 59%|█████▉    | 814/1380 [01:41<01:05,  8.61it/s] 59%|█████▉    | 815/1380 [01:42<01:05,  8.66it/s] 59%|█████▉    | 816/1380 [01:42<01:04,  8.68it/s] 59%|█████▉    | 817/1380 [01:42<01:04,  8.71it/s] 59%|█████▉    | 818/1380 [01:42<01:04,  8.68it/s] 59%|█████▉    | 819/1380 [01:42<01:04,  8.66it/s] 59%|█████▉    | 820/1380 [01:42<01:04,  8.63it/s] 59%|█████▉    | 821/1380 [01:42<01:04,  8.68it/s] 60%|█████▉    | 822/1380 [01:42<01:04,  8.60it/s] 60%|█████▉    | 823/1380 [01:42<01:04,  8.57it/s] 60%|█████▉    | 824/1380 [01:43<01:04,  8.67it/s] 60%|█████▉    | 825/1380 [01:43<01:04,  8.62it/s] 60%|█████▉    | 826/1380 [01:43<01:03,  8.66it/s] 60%|█████▉    | 827/1380 [01:43<01:03,  8.75it/s]                                                   60%|██████    | 828/1380 [01:43<01:03,  8.75it/s][INFO|trainer.py:755] 2023-11-15 19:30:43,808 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:30:43,809 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:30:43,810 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:30:43,810 >>   Batch size = 8
{'eval_loss': 0.3810403645038605, 'eval_accuracy': 0.8575317604355717, 'eval_micro_f1': 0.8575317604355718, 'eval_macro_f1': 0.8374421058485572, 'eval_runtime': 4.0951, 'eval_samples_per_second': 538.202, 'eval_steps_per_second': 67.397, 'epoch': 2.0}
{'loss': 0.2637, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 8/276 [00:00<00:03, 75.85it/s][A
  6%|▌         | 16/276 [00:00<00:03, 70.46it/s][A
  9%|▊         | 24/276 [00:00<00:03, 69.39it/s][A
 11%|█         | 31/276 [00:00<00:03, 69.19it/s][A
 14%|█▍        | 38/276 [00:00<00:03, 68.96it/s][A
 16%|█▋        | 45/276 [00:00<00:03, 68.81it/s][A
 19%|█▉        | 52/276 [00:00<00:03, 68.60it/s][A
 21%|██▏       | 59/276 [00:00<00:03, 68.28it/s][A
 24%|██▍       | 66/276 [00:00<00:03, 65.25it/s][A
 27%|██▋       | 74/276 [00:01<00:03, 67.21it/s][A
 29%|██▉       | 81/276 [00:01<00:02, 66.54it/s][A
 32%|███▏      | 88/276 [00:01<00:02, 65.84it/s][A
 34%|███▍      | 95/276 [00:01<00:02, 66.31it/s][A
 37%|███▋      | 102/276 [00:01<00:02, 65.51it/s][A
 39%|███▉      | 109/276 [00:01<00:02, 66.26it/s][A
 42%|████▏     | 116/276 [00:01<00:02, 66.81it/s][A
 45%|████▍     | 123/276 [00:01<00:02, 67.09it/s][A
 47%|████▋     | 130/276 [00:01<00:02, 67.40it/s][A
 50%|████▉     | 137/276 [00:02<00:02, 67.55it/s][A
 52%|█████▏    | 144/276 [00:02<00:02, 65.70it/s][A
 55%|█████▌    | 152/276 [00:02<00:01, 67.16it/s][A
 58%|█████▊    | 159/276 [00:02<00:01, 66.47it/s][A
 60%|██████    | 166/276 [00:02<00:01, 66.57it/s][A
 63%|██████▎   | 173/276 [00:02<00:01, 65.97it/s][A
 65%|██████▌   | 180/276 [00:02<00:01, 66.60it/s][A
 68%|██████▊   | 187/276 [00:02<00:01, 66.75it/s][A
 70%|███████   | 194/276 [00:02<00:01, 66.87it/s][A
 73%|███████▎  | 201/276 [00:02<00:01, 65.88it/s][A
 75%|███████▌  | 208/276 [00:03<00:01, 66.27it/s][A
 78%|███████▊  | 215/276 [00:03<00:00, 66.94it/s][A
 80%|████████  | 222/276 [00:03<00:00, 65.65it/s][A
 83%|████████▎ | 230/276 [00:03<00:00, 66.41it/s][A
 86%|████████▌ | 237/276 [00:03<00:00, 66.12it/s][A
 88%|████████▊ | 244/276 [00:03<00:00, 65.75it/s][A
 91%|█████████ | 251/276 [00:03<00:00, 66.16it/s][A
 94%|█████████▍| 259/276 [00:03<00:00, 67.46it/s][A
 96%|█████████▋| 266/276 [00:03<00:00, 67.05it/s][A
 99%|█████████▉| 273/276 [00:04<00:00, 67.15it/s][A                                                  
                                                 [A 60%|██████    | 828/1380 [01:47<01:03,  8.75it/s]
100%|██████████| 276/276 [00:04<00:00, 67.15it/s][A
                                                 [A 60%|██████    | 829/1380 [01:47<09:54,  1.08s/it] 60%|██████    | 830/1380 [01:47<07:41,  1.19it/s] 60%|██████    | 831/1380 [01:48<05:57,  1.53it/s] 60%|██████    | 832/1380 [01:48<04:36,  1.98it/s] 60%|██████    | 833/1380 [01:48<03:37,  2.52it/s] 60%|██████    | 834/1380 [01:48<02:53,  3.15it/s] 61%|██████    | 835/1380 [01:48<02:20,  3.87it/s] 61%|██████    | 836/1380 [01:48<01:58,  4.60it/s] 61%|██████    | 837/1380 [01:48<01:42,  5.30it/s] 61%|██████    | 838/1380 [01:48<01:30,  5.98it/s] 61%|██████    | 839/1380 [01:49<01:22,  6.58it/s] 61%|██████    | 840/1380 [01:49<01:16,  7.09it/s] 61%|██████    | 841/1380 [01:49<01:12,  7.39it/s] 61%|██████    | 842/1380 [01:49<01:09,  7.79it/s] 61%|██████    | 843/1380 [01:49<01:07,  7.99it/s] 61%|██████    | 844/1380 [01:49<01:05,  8.16it/s] 61%|██████    | 845/1380 [01:49<01:04,  8.29it/s] 61%|██████▏   | 846/1380 [01:49<01:03,  8.45it/s] 61%|██████▏   | 847/1380 [01:49<01:03,  8.43it/s] 61%|██████▏   | 848/1380 [01:50<01:03,  8.44it/s] 62%|██████▏   | 849/1380 [01:50<01:02,  8.52it/s] 62%|██████▏   | 850/1380 [01:50<01:02,  8.55it/s] 62%|██████▏   | 851/1380 [01:50<01:01,  8.60it/s] 62%|██████▏   | 852/1380 [01:50<01:00,  8.70it/s] 62%|██████▏   | 853/1380 [01:50<01:01,  8.62it/s] 62%|██████▏   | 854/1380 [01:50<01:01,  8.58it/s] 62%|██████▏   | 855/1380 [01:50<01:01,  8.58it/s] 62%|██████▏   | 856/1380 [01:51<01:01,  8.54it/s] 62%|██████▏   | 857/1380 [01:51<01:00,  8.60it/s] 62%|██████▏   | 858/1380 [01:51<01:00,  8.58it/s] 62%|██████▏   | 859/1380 [01:51<01:00,  8.65it/s] 62%|██████▏   | 860/1380 [01:51<01:00,  8.62it/s] 62%|██████▏   | 861/1380 [01:51<01:00,  8.55it/s] 62%|██████▏   | 862/1380 [01:51<01:00,  8.56it/s] 63%|██████▎   | 863/1380 [01:51<01:00,  8.61it/s] 63%|██████▎   | 864/1380 [01:51<00:59,  8.66it/s] 63%|██████▎   | 865/1380 [01:52<01:00,  8.55it/s] 63%|██████▎   | 866/1380 [01:52<00:59,  8.65it/s] 63%|██████▎   | 867/1380 [01:52<00:59,  8.68it/s] 63%|██████▎   | 868/1380 [01:52<00:59,  8.61it/s] 63%|██████▎   | 869/1380 [01:52<00:58,  8.71it/s] 63%|██████▎   | 870/1380 [01:52<00:58,  8.67it/s] 63%|██████▎   | 871/1380 [01:52<00:59,  8.60it/s] 63%|██████▎   | 872/1380 [01:52<00:59,  8.49it/s] 63%|██████▎   | 873/1380 [01:52<00:59,  8.45it/s] 63%|██████▎   | 874/1380 [01:53<00:59,  8.53it/s] 63%|██████▎   | 875/1380 [01:53<00:58,  8.57it/s] 63%|██████▎   | 876/1380 [01:53<00:58,  8.62it/s] 64%|██████▎   | 877/1380 [01:53<00:58,  8.54it/s] 64%|██████▎   | 878/1380 [01:53<00:58,  8.54it/s] 64%|██████▎   | 879/1380 [01:53<00:58,  8.57it/s] 64%|██████▍   | 880/1380 [01:53<00:58,  8.59it/s] 64%|██████▍   | 881/1380 [01:53<00:58,  8.57it/s] 64%|██████▍   | 882/1380 [01:54<00:58,  8.54it/s] 64%|██████▍   | 883/1380 [01:54<00:57,  8.59it/s] 64%|██████▍   | 884/1380 [01:54<00:57,  8.56it/s] 64%|██████▍   | 885/1380 [01:54<00:57,  8.61it/s] 64%|██████▍   | 886/1380 [01:54<00:57,  8.65it/s] 64%|██████▍   | 887/1380 [01:54<00:57,  8.62it/s] 64%|██████▍   | 888/1380 [01:54<00:57,  8.51it/s] 64%|██████▍   | 889/1380 [01:54<00:57,  8.55it/s] 64%|██████▍   | 890/1380 [01:54<00:57,  8.56it/s] 65%|██████▍   | 891/1380 [01:55<00:56,  8.59it/s] 65%|██████▍   | 892/1380 [01:55<00:56,  8.61it/s] 65%|██████▍   | 893/1380 [01:55<00:55,  8.70it/s] 65%|██████▍   | 894/1380 [01:55<00:56,  8.62it/s] 65%|██████▍   | 895/1380 [01:55<00:57,  8.50it/s] 65%|██████▍   | 896/1380 [01:55<00:56,  8.57it/s] 65%|██████▌   | 897/1380 [01:55<00:56,  8.59it/s] 65%|██████▌   | 898/1380 [01:55<00:56,  8.53it/s] 65%|██████▌   | 899/1380 [01:56<00:56,  8.54it/s] 65%|██████▌   | 900/1380 [01:56<00:56,  8.56it/s] 65%|██████▌   | 901/1380 [01:56<00:55,  8.57it/s] 65%|██████▌   | 902/1380 [01:56<00:55,  8.61it/s] 65%|██████▌   | 903/1380 [01:56<00:54,  8.77it/s] 66%|██████▌   | 904/1380 [01:56<00:55,  8.59it/s] 66%|██████▌   | 905/1380 [01:56<00:55,  8.58it/s] 66%|██████▌   | 906/1380 [01:56<00:54,  8.62it/s] 66%|██████▌   | 907/1380 [01:56<00:54,  8.64it/s] 66%|██████▌   | 908/1380 [01:57<00:54,  8.60it/s] 66%|██████▌   | 909/1380 [01:57<00:55,  8.56it/s] 66%|██████▌   | 910/1380 [01:57<00:54,  8.65it/s] 66%|██████▌   | 911/1380 [01:57<00:53,  8.69it/s] 66%|██████▌   | 912/1380 [01:57<00:54,  8.64it/s] 66%|██████▌   | 913/1380 [01:57<00:53,  8.74it/s] 66%|██████▌   | 914/1380 [01:57<00:53,  8.68it/s] 66%|██████▋   | 915/1380 [01:57<00:53,  8.64it/s] 66%|██████▋   | 916/1380 [01:57<00:53,  8.64it/s] 66%|██████▋   | 917/1380 [01:58<00:53,  8.63it/s] 67%|██████▋   | 918/1380 [01:58<00:53,  8.66it/s] 67%|██████▋   | 919/1380 [01:58<00:53,  8.63it/s] 67%|██████▋   | 920/1380 [01:58<00:52,  8.73it/s] 67%|██████▋   | 921/1380 [01:58<00:52,  8.68it/s] 67%|██████▋   | 922/1380 [01:58<00:53,  8.63it/s] 67%|██████▋   | 923/1380 [01:58<00:52,  8.67it/s] 67%|██████▋   | 924/1380 [01:58<00:52,  8.73it/s] 67%|██████▋   | 925/1380 [01:59<00:52,  8.66it/s] 67%|██████▋   | 926/1380 [01:59<00:52,  8.62it/s] 67%|██████▋   | 927/1380 [01:59<00:52,  8.63it/s] 67%|██████▋   | 928/1380 [01:59<00:52,  8.63it/s] 67%|██████▋   | 929/1380 [01:59<00:52,  8.65it/s] 67%|██████▋   | 930/1380 [01:59<00:51,  8.77it/s] 67%|██████▋   | 931/1380 [01:59<00:52,  8.63it/s] 68%|██████▊   | 932/1380 [01:59<00:52,  8.60it/s] 68%|██████▊   | 933/1380 [01:59<00:51,  8.62it/s] 68%|██████▊   | 934/1380 [02:00<00:51,  8.62it/s] 68%|██████▊   | 935/1380 [02:00<00:51,  8.64it/s] 68%|██████▊   | 936/1380 [02:00<00:51,  8.62it/s] 68%|██████▊   | 937/1380 [02:00<00:51,  8.66it/s] 68%|██████▊   | 938/1380 [02:00<00:51,  8.63it/s] 68%|██████▊   | 939/1380 [02:00<00:51,  8.60it/s] 68%|██████▊   | 940/1380 [02:00<00:50,  8.66it/s] 68%|██████▊   | 941/1380 [02:00<00:50,  8.64it/s] 68%|██████▊   | 942/1380 [02:00<00:50,  8.61it/s] 68%|██████▊   | 943/1380 [02:01<00:50,  8.63it/s] 68%|██████▊   | 944/1380 [02:01<00:50,  8.62it/s] 68%|██████▊   | 945/1380 [02:01<00:50,  8.62it/s] 69%|██████▊   | 946/1380 [02:01<00:50,  8.66it/s] 69%|██████▊   | 947/1380 [02:01<00:49,  8.71it/s] 69%|██████▊   | 948/1380 [02:01<00:49,  8.65it/s] 69%|██████▉   | 949/1380 [02:01<00:50,  8.58it/s] 69%|██████▉   | 950/1380 [02:01<00:49,  8.60it/s] 69%|██████▉   | 951/1380 [02:02<00:49,  8.66it/s] 69%|██████▉   | 952/1380 [02:02<00:49,  8.61it/s] 69%|██████▉   | 953/1380 [02:02<00:49,  8.60it/s] 69%|██████▉   | 954/1380 [02:02<00:48,  8.71it/s] 69%|██████▉   | 955/1380 [02:02<00:49,  8.58it/s] 69%|██████▉   | 956/1380 [02:02<00:49,  8.61it/s] 69%|██████▉   | 957/1380 [02:02<00:48,  8.70it/s] 69%|██████▉   | 958/1380 [02:02<00:49,  8.60it/s] 69%|██████▉   | 959/1380 [02:02<00:48,  8.60it/s] 70%|██████▉   | 960/1380 [02:03<00:48,  8.61it/s] 70%|██████▉   | 961/1380 [02:03<00:48,  8.65it/s] 70%|██████▉   | 962/1380 [02:03<00:47,  8.72it/s] 70%|██████▉   | 963/1380 [02:03<00:47,  8.70it/s] 70%|██████▉   | 964/1380 [02:03<00:47,  8.74it/s] 70%|██████▉   | 965/1380 [02:03<00:47,  8.68it/s] 70%|███████   | 966/1380 [02:03<00:47,  8.69it/s] 70%|███████   | 967/1380 [02:03<00:47,  8.68it/s] 70%|███████   | 968/1380 [02:03<00:47,  8.70it/s] 70%|███████   | 969/1380 [02:04<00:47,  8.69it/s] 70%|███████   | 970/1380 [02:04<00:47,  8.72it/s] 70%|███████   | 971/1380 [02:04<00:47,  8.65it/s] 70%|███████   | 972/1380 [02:04<00:47,  8.60it/s] 71%|███████   | 973/1380 [02:04<00:47,  8.65it/s] 71%|███████   | 974/1380 [02:04<00:46,  8.68it/s] 71%|███████   | 975/1380 [02:04<00:46,  8.66it/s] 71%|███████   | 976/1380 [02:04<00:47,  8.57it/s] 71%|███████   | 977/1380 [02:05<00:47,  8.57it/s] 71%|███████   | 978/1380 [02:05<00:46,  8.59it/s] 71%|███████   | 979/1380 [02:05<00:46,  8.61it/s] 71%|███████   | 980/1380 [02:05<00:46,  8.56it/s] 71%|███████   | 981/1380 [02:05<00:46,  8.62it/s] 71%|███████   | 982/1380 [02:05<00:46,  8.56it/s] 71%|███████   | 983/1380 [02:05<00:46,  8.60it/s] 71%|███████▏  | 984/1380 [02:05<00:45,  8.69it/s] 71%|███████▏  | 985/1380 [02:05<00:45,  8.65it/s] 71%|███████▏  | 986/1380 [02:06<00:45,  8.62it/s] 72%|███████▏  | 987/1380 [02:06<00:45,  8.68it/s] 72%|███████▏  | 988/1380 [02:06<00:45,  8.58it/s] 72%|███████▏  | 989/1380 [02:06<00:45,  8.64it/s] 72%|███████▏  | 990/1380 [02:06<00:45,  8.64it/s] 72%|███████▏  | 991/1380 [02:06<00:44,  8.68it/s] 72%|███████▏  | 992/1380 [02:06<00:44,  8.69it/s] 72%|███████▏  | 993/1380 [02:06<00:44,  8.68it/s] 72%|███████▏  | 994/1380 [02:07<00:44,  8.75it/s] 72%|███████▏  | 995/1380 [02:07<00:43,  8.77it/s] 72%|███████▏  | 996/1380 [02:07<00:44,  8.71it/s] 72%|███████▏  | 997/1380 [02:07<00:44,  8.68it/s] 72%|███████▏  | 998/1380 [02:07<00:43,  8.74it/s] 72%|███████▏  | 999/1380 [02:07<00:43,  8.73it/s] 72%|███████▏  | 1000/1380 [02:07<00:43,  8.72it/s] 73%|███████▎  | 1001/1380 [02:07<00:43,  8.77it/s] 73%|███████▎  | 1002/1380 [02:07<00:43,  8.71it/s] 73%|███████▎  | 1003/1380 [02:08<00:43,  8.72it/s] 73%|███████▎  | 1004/1380 [02:08<00:43,  8.72it/s] 73%|███████▎  | 1005/1380 [02:08<00:42,  8.76it/s] 73%|███████▎  | 1006/1380 [02:08<00:43,  8.69it/s] 73%|███████▎  | 1007/1380 [02:08<00:43,  8.57it/s] 73%|███████▎  | 1008/1380 [02:08<00:43,  8.62it/s] 73%|███████▎  | 1009/1380 [02:08<00:42,  8.70it/s] 73%|███████▎  | 1010/1380 [02:08<00:42,  8.66it/s] 73%|███████▎  | 1011/1380 [02:08<00:42,  8.74it/s] 73%|███████▎  | 1012/1380 [02:09<00:42,  8.72it/s] 73%|███████▎  | 1013/1380 [02:09<00:42,  8.68it/s] 73%|███████▎  | 1014/1380 [02:09<00:41,  8.72it/s] 74%|███████▎  | 1015/1380 [02:09<00:41,  8.76it/s] 74%|███████▎  | 1016/1380 [02:09<00:41,  8.68it/s] 74%|███████▎  | 1017/1380 [02:09<00:41,  8.72it/s] 74%|███████▍  | 1018/1380 [02:09<00:41,  8.75it/s] 74%|███████▍  | 1019/1380 [02:09<00:41,  8.74it/s] 74%|███████▍  | 1020/1380 [02:09<00:41,  8.68it/s] 74%|███████▍  | 1021/1380 [02:10<00:41,  8.74it/s] 74%|███████▍  | 1022/1380 [02:10<00:41,  8.70it/s] 74%|███████▍  | 1023/1380 [02:10<00:41,  8.67it/s] 74%|███████▍  | 1024/1380 [02:10<00:40,  8.72it/s] 74%|███████▍  | 1025/1380 [02:10<00:40,  8.69it/s] 74%|███████▍  | 1026/1380 [02:10<00:41,  8.58it/s] 74%|███████▍  | 1027/1380 [02:10<00:40,  8.65it/s] 74%|███████▍  | 1028/1380 [02:10<00:40,  8.61it/s] 75%|███████▍  | 1029/1380 [02:11<00:40,  8.63it/s] 75%|███████▍  | 1030/1380 [02:11<00:40,  8.65it/s] 75%|███████▍  | 1031/1380 [02:11<00:39,  8.77it/s] 75%|███████▍  | 1032/1380 [02:11<00:40,  8.70it/s] 75%|███████▍  | 1033/1380 [02:11<00:40,  8.65it/s] 75%|███████▍  | 1034/1380 [02:11<00:39,  8.71it/s] 75%|███████▌  | 1035/1380 [02:11<00:39,  8.74it/s] 75%|███████▌  | 1036/1380 [02:11<00:39,  8.61it/s] 75%|███████▌  | 1037/1380 [02:11<00:39,  8.64it/s] 75%|███████▌  | 1038/1380 [02:12<00:39,  8.63it/s] 75%|███████▌  | 1039/1380 [02:12<00:39,  8.66it/s] 75%|███████▌  | 1040/1380 [02:12<00:39,  8.66it/s] 75%|███████▌  | 1041/1380 [02:12<00:38,  8.73it/s] 76%|███████▌  | 1042/1380 [02:12<00:39,  8.64it/s] 76%|███████▌  | 1043/1380 [02:12<00:38,  8.68it/s] 76%|███████▌  | 1044/1380 [02:12<00:38,  8.68it/s] 76%|███████▌  | 1045/1380 [02:12<00:38,  8.70it/s] 76%|███████▌  | 1046/1380 [02:12<00:38,  8.69it/s] 76%|███████▌  | 1047/1380 [02:13<00:38,  8.65it/s] 76%|███████▌  | 1048/1380 [02:13<00:38,  8.72it/s] 76%|███████▌  | 1049/1380 [02:13<00:38,  8.68it/s] 76%|███████▌  | 1050/1380 [02:13<00:37,  8.69it/s] 76%|███████▌  | 1051/1380 [02:13<00:37,  8.78it/s] 76%|███████▌  | 1052/1380 [02:13<00:37,  8.64it/s] 76%|███████▋  | 1053/1380 [02:13<00:37,  8.64it/s] 76%|███████▋  | 1054/1380 [02:13<00:37,  8.62it/s] 76%|███████▋  | 1055/1380 [02:14<00:37,  8.63it/s] 77%|███████▋  | 1056/1380 [02:14<00:37,  8.71it/s] 77%|███████▋  | 1057/1380 [02:14<00:37,  8.66it/s] 77%|███████▋  | 1058/1380 [02:14<00:37,  8.65it/s] 77%|███████▋  | 1059/1380 [02:14<00:37,  8.59it/s] 77%|███████▋  | 1060/1380 [02:14<00:37,  8.64it/s] 77%|███████▋  | 1061/1380 [02:14<00:36,  8.71it/s] 77%|███████▋  | 1062/1380 [02:14<00:36,  8.68it/s] 77%|███████▋  | 1063/1380 [02:14<00:36,  8.64it/s] 77%|███████▋  | 1064/1380 [02:15<00:36,  8.61it/s] 77%|███████▋  | 1065/1380 [02:15<00:36,  8.65it/s] 77%|███████▋  | 1066/1380 [02:15<00:36,  8.72it/s] 77%|███████▋  | 1067/1380 [02:15<00:36,  8.67it/s] 77%|███████▋  | 1068/1380 [02:15<00:35,  8.78it/s] 77%|███████▋  | 1069/1380 [02:15<00:35,  8.72it/s] 78%|███████▊  | 1070/1380 [02:15<00:35,  8.70it/s] 78%|███████▊  | 1071/1380 [02:15<00:35,  8.78it/s] 78%|███████▊  | 1072/1380 [02:15<00:35,  8.77it/s] 78%|███████▊  | 1073/1380 [02:16<00:34,  8.78it/s] 78%|███████▊  | 1074/1380 [02:16<00:35,  8.71it/s] 78%|███████▊  | 1075/1380 [02:16<00:35,  8.64it/s] 78%|███████▊  | 1076/1380 [02:16<00:34,  8.72it/s] 78%|███████▊  | 1077/1380 [02:16<00:34,  8.73it/s] 78%|███████▊  | 1078/1380 [02:16<00:34,  8.73it/s] 78%|███████▊  | 1079/1380 [02:16<00:34,  8.72it/s] 78%|███████▊  | 1080/1380 [02:16<00:34,  8.74it/s] 78%|███████▊  | 1081/1380 [02:17<00:34,  8.76it/s] 78%|███████▊  | 1082/1380 [02:17<00:33,  8.78it/s] 78%|███████▊  | 1083/1380 [02:17<00:34,  8.72it/s] 79%|███████▊  | 1084/1380 [02:17<00:34,  8.65it/s] 79%|███████▊  | 1085/1380 [02:17<00:33,  8.71it/s] 79%|███████▊  | 1086/1380 [02:17<00:33,  8.72it/s] 79%|███████▉  | 1087/1380 [02:17<00:33,  8.75it/s] 79%|███████▉  | 1088/1380 [02:17<00:32,  8.87it/s] 79%|███████▉  | 1089/1380 [02:17<00:33,  8.79it/s] 79%|███████▉  | 1090/1380 [02:18<00:33,  8.71it/s] 79%|███████▉  | 1091/1380 [02:18<00:33,  8.68it/s] 79%|███████▉  | 1092/1380 [02:18<00:33,  8.71it/s] 79%|███████▉  | 1093/1380 [02:18<00:32,  8.72it/s] 79%|███████▉  | 1094/1380 [02:18<00:32,  8.68it/s] 79%|███████▉  | 1095/1380 [02:18<00:32,  8.72it/s] 79%|███████▉  | 1096/1380 [02:18<00:32,  8.65it/s] 79%|███████▉  | 1097/1380 [02:18<00:32,  8.72it/s] 80%|███████▉  | 1098/1380 [02:18<00:32,  8.74it/s] 80%|███████▉  | 1099/1380 [02:19<00:32,  8.71it/s] 80%|███████▉  | 1100/1380 [02:19<00:32,  8.68it/s] 80%|███████▉  | 1101/1380 [02:19<00:32,  8.62it/s] 80%|███████▉  | 1102/1380 [02:19<00:32,  8.59it/s] 80%|███████▉  | 1103/1380 [02:19<00:31,  8.67it/s]                                                    80%|████████  | 1104/1380 [02:19<00:31,  8.67it/s][INFO|trainer.py:755] 2023-11-15 19:31:19,891 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:31:19,894 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:31:19,894 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:31:19,894 >>   Batch size = 8
{'eval_loss': 0.4108123481273651, 'eval_accuracy': 0.8661524500907442, 'eval_micro_f1': 0.8661524500907442, 'eval_macro_f1': 0.8486800644585615, 'eval_runtime': 4.1968, 'eval_samples_per_second': 525.16, 'eval_steps_per_second': 65.764, 'epoch': 3.0}
{'loss': 0.195, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 80.72it/s][A
  7%|▋         | 18/276 [00:00<00:03, 71.59it/s][A
  9%|▉         | 26/276 [00:00<00:03, 70.11it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 70.80it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 68.87it/s][A
 18%|█▊        | 49/276 [00:00<00:03, 67.47it/s][A
 20%|██        | 56/276 [00:00<00:03, 67.58it/s][A
 23%|██▎       | 63/276 [00:00<00:03, 68.28it/s][A
 25%|██▌       | 70/276 [00:01<00:03, 67.34it/s][A
 28%|██▊       | 77/276 [00:01<00:03, 66.27it/s][A
 30%|███       | 84/276 [00:01<00:02, 65.91it/s][A
 33%|███▎      | 91/276 [00:01<00:02, 66.11it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 66.77it/s][A
 38%|███▊      | 105/276 [00:01<00:02, 67.36it/s][A
 41%|████      | 112/276 [00:01<00:02, 68.03it/s][A
 43%|████▎     | 119/276 [00:01<00:02, 67.64it/s][A
 46%|████▌     | 126/276 [00:01<00:02, 67.29it/s][A
 48%|████▊     | 133/276 [00:01<00:02, 64.73it/s][A
 51%|█████     | 141/276 [00:02<00:02, 67.04it/s][A
 54%|█████▎    | 148/276 [00:02<00:01, 66.77it/s][A
 56%|█████▌    | 155/276 [00:02<00:01, 66.59it/s][A
 59%|█████▊    | 162/276 [00:02<00:01, 65.26it/s][A
 61%|██████    | 169/276 [00:02<00:01, 66.56it/s][A
 64%|██████▍   | 176/276 [00:02<00:01, 66.42it/s][A
 67%|██████▋   | 184/276 [00:02<00:01, 67.69it/s][A
 69%|██████▉   | 191/276 [00:02<00:01, 67.84it/s][A
 72%|███████▏  | 198/276 [00:02<00:01, 67.92it/s][A
 74%|███████▍  | 205/276 [00:03<00:01, 66.92it/s][A
 77%|███████▋  | 212/276 [00:03<00:00, 66.43it/s][A
 80%|███████▉  | 220/276 [00:03<00:00, 68.07it/s][A
 82%|████████▏ | 227/276 [00:03<00:00, 68.21it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 67.01it/s][A
 87%|████████▋ | 241/276 [00:03<00:00, 65.89it/s][A
 90%|█████████ | 249/276 [00:03<00:00, 66.89it/s][A
 93%|█████████▎| 256/276 [00:03<00:00, 67.41it/s][A
 95%|█████████▌| 263/276 [00:03<00:00, 67.00it/s][A
 98%|█████████▊| 270/276 [00:04<00:00, 67.26it/s][A                                                   
                                                 [A 80%|████████  | 1104/1380 [02:23<00:31,  8.67it/s]
100%|██████████| 276/276 [00:04<00:00, 67.26it/s][A
                                                 [A 80%|████████  | 1105/1380 [02:23<04:54,  1.07s/it] 80%|████████  | 1106/1380 [02:24<03:48,  1.20it/s] 80%|████████  | 1107/1380 [02:24<02:56,  1.55it/s] 80%|████████  | 1108/1380 [02:24<02:16,  1.99it/s] 80%|████████  | 1109/1380 [02:24<01:46,  2.54it/s] 80%|████████  | 1110/1380 [02:24<01:24,  3.19it/s] 81%|████████  | 1111/1380 [02:24<01:09,  3.90it/s] 81%|████████  | 1112/1380 [02:24<00:57,  4.66it/s] 81%|████████  | 1113/1380 [02:24<00:49,  5.41it/s] 81%|████████  | 1114/1380 [02:24<00:43,  6.09it/s] 81%|████████  | 1115/1380 [02:25<00:39,  6.64it/s] 81%|████████  | 1116/1380 [02:25<00:36,  7.16it/s] 81%|████████  | 1117/1380 [02:25<00:34,  7.59it/s] 81%|████████  | 1118/1380 [02:25<00:33,  7.88it/s] 81%|████████  | 1119/1380 [02:25<00:32,  8.13it/s] 81%|████████  | 1120/1380 [02:25<00:31,  8.36it/s] 81%|████████  | 1121/1380 [02:25<00:30,  8.41it/s] 81%|████████▏ | 1122/1380 [02:25<00:30,  8.48it/s] 81%|████████▏ | 1123/1380 [02:25<00:30,  8.51it/s] 81%|████████▏ | 1124/1380 [02:26<00:29,  8.59it/s] 82%|████████▏ | 1125/1380 [02:26<00:29,  8.57it/s] 82%|████████▏ | 1126/1380 [02:26<00:29,  8.48it/s] 82%|████████▏ | 1127/1380 [02:26<00:29,  8.59it/s] 82%|████████▏ | 1128/1380 [02:26<00:29,  8.58it/s] 82%|████████▏ | 1129/1380 [02:26<00:29,  8.63it/s] 82%|████████▏ | 1130/1380 [02:26<00:28,  8.70it/s] 82%|████████▏ | 1131/1380 [02:26<00:28,  8.65it/s] 82%|████████▏ | 1132/1380 [02:27<00:28,  8.64it/s] 82%|████████▏ | 1133/1380 [02:27<00:28,  8.64it/s] 82%|████████▏ | 1134/1380 [02:27<00:28,  8.75it/s] 82%|████████▏ | 1135/1380 [02:27<00:28,  8.72it/s] 82%|████████▏ | 1136/1380 [02:27<00:28,  8.68it/s] 82%|████████▏ | 1137/1380 [02:27<00:27,  8.76it/s] 82%|████████▏ | 1138/1380 [02:27<00:28,  8.60it/s] 83%|████████▎ | 1139/1380 [02:27<00:27,  8.65it/s] 83%|████████▎ | 1140/1380 [02:27<00:27,  8.63it/s] 83%|████████▎ | 1141/1380 [02:28<00:27,  8.71it/s] 83%|████████▎ | 1142/1380 [02:28<00:27,  8.66it/s] 83%|████████▎ | 1143/1380 [02:28<00:27,  8.66it/s] 83%|████████▎ | 1144/1380 [02:28<00:27,  8.64it/s] 83%|████████▎ | 1145/1380 [02:28<00:27,  8.63it/s] 83%|████████▎ | 1146/1380 [02:28<00:27,  8.67it/s] 83%|████████▎ | 1147/1380 [02:28<00:26,  8.77it/s] 83%|████████▎ | 1148/1380 [02:28<00:26,  8.69it/s] 83%|████████▎ | 1149/1380 [02:28<00:26,  8.68it/s] 83%|████████▎ | 1150/1380 [02:29<00:26,  8.66it/s] 83%|████████▎ | 1151/1380 [02:29<00:26,  8.64it/s] 83%|████████▎ | 1152/1380 [02:29<00:26,  8.69it/s] 84%|████████▎ | 1153/1380 [02:29<00:26,  8.64it/s] 84%|████████▎ | 1154/1380 [02:29<00:25,  8.81it/s] 84%|████████▎ | 1155/1380 [02:29<00:25,  8.68it/s] 84%|████████▍ | 1156/1380 [02:29<00:25,  8.66it/s] 84%|████████▍ | 1157/1380 [02:29<00:25,  8.63it/s] 84%|████████▍ | 1158/1380 [02:30<00:25,  8.65it/s] 84%|████████▍ | 1159/1380 [02:30<00:25,  8.63it/s] 84%|████████▍ | 1160/1380 [02:30<00:25,  8.66it/s] 84%|████████▍ | 1161/1380 [02:30<00:25,  8.69it/s] 84%|████████▍ | 1162/1380 [02:30<00:25,  8.67it/s] 84%|████████▍ | 1163/1380 [02:30<00:25,  8.65it/s] 84%|████████▍ | 1164/1380 [02:30<00:24,  8.71it/s] 84%|████████▍ | 1165/1380 [02:30<00:25,  8.60it/s] 84%|████████▍ | 1166/1380 [02:30<00:24,  8.61it/s] 85%|████████▍ | 1167/1380 [02:31<00:24,  8.55it/s] 85%|████████▍ | 1168/1380 [02:31<00:24,  8.59it/s] 85%|████████▍ | 1169/1380 [02:31<00:24,  8.66it/s] 85%|████████▍ | 1170/1380 [02:31<00:24,  8.62it/s] 85%|████████▍ | 1171/1380 [02:31<00:23,  8.71it/s] 85%|████████▍ | 1172/1380 [02:31<00:23,  8.73it/s] 85%|████████▌ | 1173/1380 [02:31<00:23,  8.71it/s] 85%|████████▌ | 1174/1380 [02:31<00:23,  8.73it/s] 85%|████████▌ | 1175/1380 [02:31<00:23,  8.66it/s] 85%|████████▌ | 1176/1380 [02:32<00:23,  8.64it/s] 85%|████████▌ | 1177/1380 [02:32<00:23,  8.62it/s] 85%|████████▌ | 1178/1380 [02:32<00:23,  8.63it/s] 85%|████████▌ | 1179/1380 [02:32<00:23,  8.55it/s] 86%|████████▌ | 1180/1380 [02:32<00:23,  8.63it/s] 86%|████████▌ | 1181/1380 [02:32<00:22,  8.74it/s] 86%|████████▌ | 1182/1380 [02:32<00:22,  8.65it/s] 86%|████████▌ | 1183/1380 [02:32<00:22,  8.60it/s] 86%|████████▌ | 1184/1380 [02:33<00:22,  8.59it/s] 86%|████████▌ | 1185/1380 [02:33<00:22,  8.57it/s] 86%|████████▌ | 1186/1380 [02:33<00:22,  8.62it/s] 86%|████████▌ | 1187/1380 [02:33<00:22,  8.62it/s] 86%|████████▌ | 1188/1380 [02:33<00:22,  8.59it/s] 86%|████████▌ | 1189/1380 [02:33<00:22,  8.57it/s] 86%|████████▌ | 1190/1380 [02:33<00:22,  8.58it/s] 86%|████████▋ | 1191/1380 [02:33<00:21,  8.61it/s] 86%|████████▋ | 1192/1380 [02:33<00:21,  8.62it/s] 86%|████████▋ | 1193/1380 [02:34<00:21,  8.61it/s] 87%|████████▋ | 1194/1380 [02:34<00:21,  8.57it/s] 87%|████████▋ | 1195/1380 [02:34<00:21,  8.63it/s] 87%|████████▋ | 1196/1380 [02:34<00:21,  8.61it/s] 87%|████████▋ | 1197/1380 [02:34<00:21,  8.60it/s] 87%|████████▋ | 1198/1380 [02:34<00:20,  8.76it/s] 87%|████████▋ | 1199/1380 [02:34<00:21,  8.58it/s] 87%|████████▋ | 1200/1380 [02:34<00:20,  8.59it/s] 87%|████████▋ | 1201/1380 [02:35<00:20,  8.62it/s] 87%|████████▋ | 1202/1380 [02:35<00:20,  8.61it/s] 87%|████████▋ | 1203/1380 [02:35<00:20,  8.68it/s] 87%|████████▋ | 1204/1380 [02:35<00:20,  8.64it/s] 87%|████████▋ | 1205/1380 [02:35<00:20,  8.75it/s] 87%|████████▋ | 1206/1380 [02:35<00:20,  8.63it/s] 87%|████████▋ | 1207/1380 [02:35<00:20,  8.54it/s] 88%|████████▊ | 1208/1380 [02:35<00:20,  8.59it/s] 88%|████████▊ | 1209/1380 [02:35<00:19,  8.62it/s] 88%|████████▊ | 1210/1380 [02:36<00:19,  8.57it/s] 88%|████████▊ | 1211/1380 [02:36<00:19,  8.54it/s] 88%|████████▊ | 1212/1380 [02:36<00:19,  8.62it/s] 88%|████████▊ | 1213/1380 [02:36<00:19,  8.64it/s] 88%|████████▊ | 1214/1380 [02:36<00:19,  8.65it/s] 88%|████████▊ | 1215/1380 [02:36<00:18,  8.71it/s] 88%|████████▊ | 1216/1380 [02:36<00:18,  8.64it/s] 88%|████████▊ | 1217/1380 [02:36<00:18,  8.62it/s] 88%|████████▊ | 1218/1380 [02:36<00:18,  8.62it/s] 88%|████████▊ | 1219/1380 [02:37<00:18,  8.61it/s] 88%|████████▊ | 1220/1380 [02:37<00:18,  8.67it/s] 88%|████████▊ | 1221/1380 [02:37<00:18,  8.62it/s] 89%|████████▊ | 1222/1380 [02:37<00:18,  8.70it/s] 89%|████████▊ | 1223/1380 [02:37<00:18,  8.69it/s] 89%|████████▊ | 1224/1380 [02:37<00:17,  8.69it/s] 89%|████████▉ | 1225/1380 [02:37<00:17,  8.73it/s] 89%|████████▉ | 1226/1380 [02:37<00:17,  8.70it/s] 89%|████████▉ | 1227/1380 [02:38<00:17,  8.69it/s] 89%|████████▉ | 1228/1380 [02:38<00:17,  8.61it/s] 89%|████████▉ | 1229/1380 [02:38<00:17,  8.57it/s] 89%|████████▉ | 1230/1380 [02:38<00:17,  8.60it/s] 89%|████████▉ | 1231/1380 [02:38<00:17,  8.64it/s] 89%|████████▉ | 1232/1380 [02:38<00:17,  8.69it/s] 89%|████████▉ | 1233/1380 [02:38<00:17,  8.63it/s] 89%|████████▉ | 1234/1380 [02:38<00:16,  8.65it/s] 89%|████████▉ | 1235/1380 [02:38<00:16,  8.78it/s] 90%|████████▉ | 1236/1380 [02:39<00:16,  8.72it/s] 90%|████████▉ | 1237/1380 [02:39<00:16,  8.67it/s] 90%|████████▉ | 1238/1380 [02:39<00:16,  8.71it/s] 90%|████████▉ | 1239/1380 [02:39<00:16,  8.71it/s] 90%|████████▉ | 1240/1380 [02:39<00:16,  8.71it/s] 90%|████████▉ | 1241/1380 [02:39<00:15,  8.70it/s] 90%|█████████ | 1242/1380 [02:39<00:15,  8.78it/s] 90%|█████████ | 1243/1380 [02:39<00:15,  8.69it/s] 90%|█████████ | 1244/1380 [02:39<00:15,  8.69it/s] 90%|█████████ | 1245/1380 [02:40<00:15,  8.76it/s] 90%|█████████ | 1246/1380 [02:40<00:15,  8.74it/s] 90%|█████████ | 1247/1380 [02:40<00:15,  8.69it/s] 90%|█████████ | 1248/1380 [02:40<00:15,  8.70it/s] 91%|█████████ | 1249/1380 [02:40<00:15,  8.68it/s] 91%|█████████ | 1250/1380 [02:40<00:14,  8.70it/s] 91%|█████████ | 1251/1380 [02:40<00:14,  8.63it/s] 91%|█████████ | 1252/1380 [02:40<00:14,  8.70it/s] 91%|█████████ | 1253/1380 [02:41<00:14,  8.68it/s] 91%|█████████ | 1254/1380 [02:41<00:14,  8.71it/s] 91%|█████████ | 1255/1380 [02:41<00:14,  8.78it/s] 91%|█████████ | 1256/1380 [02:41<00:14,  8.80it/s] 91%|█████████ | 1257/1380 [02:41<00:14,  8.74it/s] 91%|█████████ | 1258/1380 [02:41<00:13,  8.78it/s] 91%|█████████ | 1259/1380 [02:41<00:13,  8.75it/s] 91%|█████████▏| 1260/1380 [02:41<00:13,  8.81it/s] 91%|█████████▏| 1261/1380 [02:41<00:13,  8.75it/s] 91%|█████████▏| 1262/1380 [02:42<00:13,  8.78it/s] 92%|█████████▏| 1263/1380 [02:42<00:13,  8.69it/s] 92%|█████████▏| 1264/1380 [02:42<00:13,  8.70it/s] 92%|█████████▏| 1265/1380 [02:42<00:13,  8.82it/s] 92%|█████████▏| 1266/1380 [02:42<00:12,  8.79it/s] 92%|█████████▏| 1267/1380 [02:42<00:12,  8.73it/s] 92%|█████████▏| 1268/1380 [02:42<00:12,  8.73it/s] 92%|█████████▏| 1269/1380 [02:42<00:12,  8.81it/s] 92%|█████████▏| 1270/1380 [02:42<00:12,  8.71it/s] 92%|█████████▏| 1271/1380 [02:43<00:12,  8.75it/s] 92%|█████████▏| 1272/1380 [02:43<00:12,  8.81it/s] 92%|█████████▏| 1273/1380 [02:43<00:12,  8.74it/s] 92%|█████████▏| 1274/1380 [02:43<00:12,  8.76it/s] 92%|█████████▏| 1275/1380 [02:43<00:11,  8.90it/s] 92%|█████████▏| 1276/1380 [02:43<00:11,  8.84it/s] 93%|█████████▎| 1277/1380 [02:43<00:11,  8.80it/s] 93%|█████████▎| 1278/1380 [02:43<00:11,  8.80it/s] 93%|█████████▎| 1279/1380 [02:43<00:11,  8.81it/s] 93%|█████████▎| 1280/1380 [02:44<00:11,  8.75it/s] 93%|█████████▎| 1281/1380 [02:44<00:11,  8.67it/s] 93%|█████████▎| 1282/1380 [02:44<00:11,  8.71it/s] 93%|█████████▎| 1283/1380 [02:44<00:11,  8.74it/s] 93%|█████████▎| 1284/1380 [02:44<00:11,  8.67it/s] 93%|█████████▎| 1285/1380 [02:44<00:10,  8.70it/s] 93%|█████████▎| 1286/1380 [02:44<00:10,  8.65it/s] 93%|█████████▎| 1287/1380 [02:44<00:10,  8.72it/s] 93%|█████████▎| 1288/1380 [02:44<00:10,  8.83it/s] 93%|█████████▎| 1289/1380 [02:45<00:10,  8.78it/s] 93%|█████████▎| 1290/1380 [02:45<00:10,  8.79it/s] 94%|█████████▎| 1291/1380 [02:45<00:10,  8.76it/s] 94%|█████████▎| 1292/1380 [02:45<00:09,  8.84it/s] 94%|█████████▎| 1293/1380 [02:45<00:09,  8.78it/s] 94%|█████████▍| 1294/1380 [02:45<00:09,  8.77it/s] 94%|█████████▍| 1295/1380 [02:45<00:09,  8.86it/s] 94%|█████████▍| 1296/1380 [02:45<00:09,  8.82it/s] 94%|█████████▍| 1297/1380 [02:46<00:09,  8.83it/s] 94%|█████████▍| 1298/1380 [02:46<00:09,  8.86it/s] 94%|█████████▍| 1299/1380 [02:46<00:09,  8.83it/s] 94%|█████████▍| 1300/1380 [02:46<00:09,  8.78it/s] 94%|█████████▍| 1301/1380 [02:46<00:09,  8.76it/s] 94%|█████████▍| 1302/1380 [02:46<00:08,  8.83it/s] 94%|█████████▍| 1303/1380 [02:46<00:08,  8.79it/s] 94%|█████████▍| 1304/1380 [02:46<00:08,  8.69it/s] 95%|█████████▍| 1305/1380 [02:46<00:08,  8.63it/s] 95%|█████████▍| 1306/1380 [02:47<00:08,  8.75it/s] 95%|█████████▍| 1307/1380 [02:47<00:08,  8.68it/s] 95%|█████████▍| 1308/1380 [02:47<00:08,  8.75it/s] 95%|█████████▍| 1309/1380 [02:47<00:08,  8.66it/s] 95%|█████████▍| 1310/1380 [02:47<00:08,  8.68it/s] 95%|█████████▌| 1311/1380 [02:47<00:07,  8.78it/s] 95%|█████████▌| 1312/1380 [02:47<00:07,  8.68it/s] 95%|█████████▌| 1313/1380 [02:47<00:07,  8.70it/s] 95%|█████████▌| 1314/1380 [02:47<00:07,  8.72it/s] 95%|█████████▌| 1315/1380 [02:48<00:07,  8.79it/s] 95%|█████████▌| 1316/1380 [02:48<00:07,  8.73it/s] 95%|█████████▌| 1317/1380 [02:48<00:07,  8.68it/s] 96%|█████████▌| 1318/1380 [02:48<00:07,  8.63it/s] 96%|█████████▌| 1319/1380 [02:48<00:06,  8.73it/s] 96%|█████████▌| 1320/1380 [02:48<00:06,  8.76it/s] 96%|█████████▌| 1321/1380 [02:48<00:06,  8.75it/s] 96%|█████████▌| 1322/1380 [02:48<00:06,  8.78it/s] 96%|█████████▌| 1323/1380 [02:48<00:06,  8.79it/s] 96%|█████████▌| 1324/1380 [02:49<00:06,  8.82it/s] 96%|█████████▌| 1325/1380 [02:49<00:06,  8.81it/s] 96%|█████████▌| 1326/1380 [02:49<00:06,  8.81it/s] 96%|█████████▌| 1327/1380 [02:49<00:06,  8.74it/s] 96%|█████████▌| 1328/1380 [02:49<00:05,  8.72it/s] 96%|█████████▋| 1329/1380 [02:49<00:05,  8.77it/s] 96%|█████████▋| 1330/1380 [02:49<00:05,  8.69it/s] 96%|█████████▋| 1331/1380 [02:49<00:05,  8.75it/s] 97%|█████████▋| 1332/1380 [02:50<00:05,  8.68it/s] 97%|█████████▋| 1333/1380 [02:50<00:05,  8.74it/s] 97%|█████████▋| 1334/1380 [02:50<00:05,  8.83it/s] 97%|█████████▋| 1335/1380 [02:50<00:05,  8.76it/s] 97%|█████████▋| 1336/1380 [02:50<00:05,  8.77it/s] 97%|█████████▋| 1337/1380 [02:50<00:04,  8.81it/s] 97%|█████████▋| 1338/1380 [02:50<00:04,  8.77it/s] 97%|█████████▋| 1339/1380 [02:50<00:04,  8.76it/s] 97%|█████████▋| 1340/1380 [02:50<00:04,  8.73it/s] 97%|█████████▋| 1341/1380 [02:51<00:04,  8.82it/s] 97%|█████████▋| 1342/1380 [02:51<00:04,  8.78it/s] 97%|█████████▋| 1343/1380 [02:51<00:04,  8.78it/s] 97%|█████████▋| 1344/1380 [02:51<00:04,  8.84it/s] 97%|█████████▋| 1345/1380 [02:51<00:03,  8.80it/s] 98%|█████████▊| 1346/1380 [02:51<00:03,  8.72it/s] 98%|█████████▊| 1347/1380 [02:51<00:03,  8.73it/s] 98%|█████████▊| 1348/1380 [02:51<00:03,  8.80it/s] 98%|█████████▊| 1349/1380 [02:51<00:03,  8.72it/s] 98%|█████████▊| 1350/1380 [02:52<00:03,  8.74it/s] 98%|█████████▊| 1351/1380 [02:52<00:03,  8.67it/s] 98%|█████████▊| 1352/1380 [02:52<00:03,  8.76it/s] 98%|█████████▊| 1353/1380 [02:52<00:03,  8.72it/s] 98%|█████████▊| 1354/1380 [02:52<00:02,  8.86it/s] 98%|█████████▊| 1355/1380 [02:52<00:02,  8.84it/s] 98%|█████████▊| 1356/1380 [02:52<00:02,  8.80it/s] 98%|█████████▊| 1357/1380 [02:52<00:02,  8.87it/s] 98%|█████████▊| 1358/1380 [02:52<00:02,  8.91it/s] 98%|█████████▊| 1359/1380 [02:53<00:02,  8.81it/s] 99%|█████████▊| 1360/1380 [02:53<00:02,  8.79it/s] 99%|█████████▊| 1361/1380 [02:53<00:02,  8.76it/s] 99%|█████████▊| 1362/1380 [02:53<00:02,  8.82it/s] 99%|█████████▉| 1363/1380 [02:53<00:01,  8.72it/s] 99%|█████████▉| 1364/1380 [02:53<00:01,  8.78it/s] 99%|█████████▉| 1365/1380 [02:53<00:01,  8.75it/s] 99%|█████████▉| 1366/1380 [02:53<00:01,  8.80it/s] 99%|█████████▉| 1367/1380 [02:54<00:01,  8.90it/s] 99%|█████████▉| 1368/1380 [02:54<00:01,  8.82it/s] 99%|█████████▉| 1369/1380 [02:54<00:01,  8.82it/s] 99%|█████████▉| 1370/1380 [02:54<00:01,  8.78it/s] 99%|█████████▉| 1371/1380 [02:54<00:01,  8.81it/s] 99%|█████████▉| 1372/1380 [02:54<00:00,  8.79it/s] 99%|█████████▉| 1373/1380 [02:54<00:00,  8.74it/s]100%|█████████▉| 1374/1380 [02:54<00:00,  8.81it/s]100%|█████████▉| 1375/1380 [02:54<00:00,  8.78it/s]100%|█████████▉| 1376/1380 [02:55<00:00,  8.83it/s]100%|█████████▉| 1377/1380 [02:55<00:00,  8.92it/s]100%|█████████▉| 1378/1380 [02:55<00:00,  8.84it/s]100%|█████████▉| 1379/1380 [02:55<00:00,  8.87it/s]                                                   100%|██████████| 1380/1380 [02:55<00:00,  8.87it/s][INFO|trainer.py:755] 2023-11-15 19:31:55,720 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:31:55,722 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:31:55,722 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:31:55,722 >>   Batch size = 8
{'eval_loss': 0.48632869124412537, 'eval_accuracy': 0.8570780399274047, 'eval_micro_f1': 0.8570780399274048, 'eval_macro_f1': 0.8413086523050911, 'eval_runtime': 4.164, 'eval_samples_per_second': 529.305, 'eval_steps_per_second': 66.283, 'epoch': 4.0}
{'loss': 0.1479, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 82.49it/s][A
  7%|▋         | 18/276 [00:00<00:03, 70.65it/s][A
  9%|▉         | 26/276 [00:00<00:03, 70.24it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 71.50it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 69.38it/s][A
 18%|█▊        | 49/276 [00:00<00:03, 69.04it/s][A
 21%|██        | 57/276 [00:00<00:03, 70.22it/s][A
 24%|██▎       | 65/276 [00:00<00:03, 69.97it/s][A
 26%|██▋       | 73/276 [00:01<00:02, 70.22it/s][A
 29%|██▉       | 81/276 [00:01<00:02, 70.44it/s][A
 32%|███▏      | 89/276 [00:01<00:02, 69.91it/s][A
 35%|███▌      | 97/276 [00:01<00:02, 70.47it/s][A
 38%|███▊      | 105/276 [00:01<00:02, 71.16it/s][A
 41%|████      | 113/276 [00:01<00:02, 70.09it/s][A
 44%|████▍     | 121/276 [00:01<00:02, 70.07it/s][A
 47%|████▋     | 129/276 [00:01<00:02, 69.77it/s][A
 50%|████▉     | 137/276 [00:01<00:01, 70.64it/s][A
 53%|█████▎    | 145/276 [00:02<00:01, 71.11it/s][A
 55%|█████▌    | 153/276 [00:02<00:01, 69.55it/s][A
 58%|█████▊    | 161/276 [00:02<00:01, 69.99it/s][A
 61%|██████    | 169/276 [00:02<00:01, 70.07it/s][A
 64%|██████▍   | 177/276 [00:02<00:01, 70.03it/s][A
 67%|██████▋   | 185/276 [00:02<00:01, 70.53it/s][A
 70%|██████▉   | 193/276 [00:02<00:01, 69.58it/s][A
 73%|███████▎  | 201/276 [00:02<00:01, 70.19it/s][A
 76%|███████▌  | 209/276 [00:02<00:00, 70.62it/s][A
 79%|███████▊  | 217/276 [00:03<00:00, 69.67it/s][A
 81%|████████  | 224/276 [00:03<00:00, 69.74it/s][A
 84%|████████▎ | 231/276 [00:03<00:00, 69.34it/s][A
 87%|████████▋ | 239/276 [00:03<00:00, 69.69it/s][A
 89%|████████▉ | 247/276 [00:03<00:00, 70.36it/s][A
 92%|█████████▏| 255/276 [00:03<00:00, 70.89it/s][A
 95%|█████████▌| 263/276 [00:03<00:00, 71.71it/s][A
 98%|█████████▊| 271/276 [00:03<00:00, 70.36it/s][A                                                   
                                                 [A100%|██████████| 1380/1380 [02:59<00:00,  8.87it/s]
100%|██████████| 276/276 [00:03<00:00, 70.36it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 19:31:59,714 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:59<00:00,  8.87it/s]100%|██████████| 1380/1380 [02:59<00:00,  7.69it/s]
[INFO|trainer.py:2855] 2023-11-15 19:31:59,718 >> Saving model checkpoint to ./result/acl_roberta-base_adapter__seed0
[INFO|configuration_utils.py:460] 2023-11-15 19:31:59,720 >> Configuration saved in ./result/acl_roberta-base_adapter__seed0/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:32:01,166 >> Model weights saved in ./result/acl_roberta-base_adapter__seed0/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:32:01,170 >> tokenizer config file saved in ./result/acl_roberta-base_adapter__seed0/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:32:01,172 >> Special tokens file saved in ./result/acl_roberta-base_adapter__seed0/special_tokens_map.json
{'eval_loss': 0.5401247143745422, 'eval_accuracy': 0.852994555353902, 'eval_micro_f1': 0.852994555353902, 'eval_macro_f1': 0.8366602720222508, 'eval_runtime': 3.9878, 'eval_samples_per_second': 552.689, 'eval_steps_per_second': 69.212, 'epoch': 5.0}
{'train_runtime': 179.4609, 'train_samples_per_second': 245.624, 'train_steps_per_second': 7.69, 'train_loss': 0.2870974305747212, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2871
  train_runtime            = 0:02:59.46
  train_samples            =       8816
  train_samples_per_second =    245.624
  train_steps_per_second   =       7.69
11/15/2023 19:32:01 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:32:01,274 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:32:01,275 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:32:01,275 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:32:01,276 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  3%|▎         | 9/276 [00:00<00:03, 86.85it/s]  7%|▋         | 18/276 [00:00<00:03, 74.30it/s]  9%|▉         | 26/276 [00:00<00:03, 72.65it/s] 12%|█▏        | 34/276 [00:00<00:03, 72.19it/s] 15%|█▌        | 42/276 [00:00<00:03, 71.78it/s] 18%|█▊        | 50/276 [00:00<00:03, 70.05it/s] 21%|██        | 58/276 [00:00<00:03, 71.54it/s] 24%|██▍       | 66/276 [00:00<00:02, 71.05it/s] 27%|██▋       | 74/276 [00:01<00:02, 70.34it/s] 30%|██▉       | 82/276 [00:01<00:02, 71.87it/s] 33%|███▎      | 90/276 [00:01<00:02, 69.37it/s] 36%|███▌      | 98/276 [00:01<00:02, 71.07it/s] 38%|███▊      | 106/276 [00:01<00:02, 71.53it/s] 41%|████▏     | 114/276 [00:01<00:02, 72.28it/s] 44%|████▍     | 122/276 [00:01<00:02, 71.38it/s] 47%|████▋     | 130/276 [00:01<00:02, 70.43it/s] 50%|█████     | 138/276 [00:01<00:01, 70.55it/s] 53%|█████▎    | 146/276 [00:02<00:01, 71.84it/s] 56%|█████▌    | 154/276 [00:02<00:01, 70.41it/s] 59%|█████▊    | 162/276 [00:02<00:01, 70.78it/s] 62%|██████▏   | 170/276 [00:02<00:01, 71.06it/s] 64%|██████▍   | 178/276 [00:02<00:01, 71.21it/s] 67%|██████▋   | 186/276 [00:02<00:01, 72.32it/s] 70%|███████   | 194/276 [00:02<00:01, 71.47it/s] 73%|███████▎  | 202/276 [00:02<00:01, 70.12it/s] 76%|███████▌  | 210/276 [00:02<00:00, 70.51it/s] 79%|███████▉  | 218/276 [00:03<00:00, 71.73it/s] 82%|████████▏ | 226/276 [00:03<00:00, 71.89it/s] 85%|████████▍ | 234/276 [00:03<00:00, 70.83it/s] 88%|████████▊ | 242/276 [00:03<00:00, 70.17it/s] 91%|█████████ | 250/276 [00:03<00:00, 70.84it/s] 93%|█████████▎| 258/276 [00:03<00:00, 70.78it/s] 96%|█████████▋| 266/276 [00:03<00:00, 71.80it/s] 99%|█████████▉| 274/276 [00:03<00:00, 71.57it/s]100%|██████████| 276/276 [00:03<00:00, 70.49it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.853
  eval_loss               =     0.5401
  eval_macro_f1           =     0.8367
  eval_micro_f1           =      0.853
  eval_runtime            = 0:00:03.93
  eval_samples            =       2204
  eval_samples_per_second =     560.66
  eval_steps_per_second   =      70.21
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▄█▄▂▂
wandb:                      eval/loss ▃▁▂▆██
wandb:                  eval/macro_f1 ▁▂█▄▂▂
wandb:                  eval/micro_f1 ▁▄█▄▂▂
wandb:                   eval/runtime ▃▅█▇▂▁
wandb:        eval/samples_per_second ▆▄▁▂▆█
wandb:          eval/steps_per_second ▆▄▁▂▆█
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.85299
wandb:                      eval/loss 0.54012
wandb:                  eval/macro_f1 0.83666
wandb:                  eval/micro_f1 0.85299
wandb:                   eval/runtime 3.9311
wandb:        eval/samples_per_second 560.66
wandb:          eval/steps_per_second 70.21
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1479
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.2871
wandb:            train/train_runtime 179.4609
wandb: train/train_samples_per_second 245.624
wandb:   train/train_steps_per_second 7.69
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_192741-g89qurfz
wandb: Find logs at: ./wandb/offline-run-20231115_192741-g89qurfz/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_bert-base-cased_adapter__seed0/runs/Nov15_19-32-16_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_bert-base-cased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_bert-base-cased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:32:16 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:32:16 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_bert-base-cased_adapter__seed0/runs/Nov15_19-32-16_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_bert-base-cased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_bert-base-cased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  37%|███▋      | 4081/11020 [00:00<00:00, 40532.21 examples/s]Map:  75%|███████▍  | 8238/11020 [00:00<00:00, 41135.00 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 40566.97 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 19:32:33,210 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:32:33,223 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 19:32:43,240 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:32:43,241 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:32:43,245 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:32:43,245 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:32:43,246 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:32:43,246 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:32:43,246 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 19:32:43,247 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:32:43,248 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:33:03,409 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 19:33:04,122 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:33:04,123 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  34%|███▍      | 3000/8816 [00:00<00:00, 21107.42 examples/s]Running tokenizer on dataset:  79%|███████▉  | 7000/8816 [00:00<00:00, 22002.65 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 21220.60 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 22943.81 examples/s]
11/15/2023 19:33:04 - INFO - __main__ - Sample 3485 of the training set: {'text': 'ERGMs are particularly useful for testing hypotheses about network relations, and they have started to be applied more widely in public health [27].', 'label': 0, 'input_ids': [101, 23580, 23169, 1116, 1132, 2521, 5616, 1111, 5193, 177, 1183, 11439, 18769, 1164, 2443, 4125, 117, 1105, 1152, 1138, 1408, 1106, 1129, 3666, 1167, 3409, 1107, 1470, 2332, 164, 1765, 166, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:33:04 - INFO - __main__ - Sample 5176 of the training set: {'text': 'Consistent with previous results (Koroch et al. 2002; Liu et al. 2002; Staniszewska et al. 2003; Washida et al. 2004), the addition of IBA at optimum levels enhanced the growth of HRC of Echinacea but had no effect on the production of secondary metabolites.', 'label': 2, 'input_ids': [101, 16752, 22398, 3452, 1114, 2166, 2686, 113, 19892, 2180, 1732, 3084, 2393, 119, 1617, 132, 8411, 3084, 2393, 119, 1617, 132, 9633, 1548, 3171, 10732, 1968, 3084, 2393, 119, 1581, 132, 3982, 3031, 1810, 3084, 2393, 119, 1516, 114, 117, 1103, 1901, 1104, 146, 8215, 1120, 11769, 3121, 16268, 3001, 9927, 1103, 3213, 1104, 145, 10036, 1104, 142, 22952, 20287, 1133, 1125, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 19:33:04 - INFO - __main__ - Sample 8092 of the training set: {'text': 'Syllables with a voiced onset developed a low tone, and those with a voiceless initial induced a high tone, resulting in a six-way tonal contrast (2 pitch heights x 3 contours).1\n(Kang 2014, Kim 2000, Oh 2011, Silva 2006, Wright 2007).', 'label': 0, 'input_ids': [101, 156, 7777, 1742, 8350, 1114, 170, 7350, 15415, 1872, 170, 1822, 3586, 117, 1105, 1343, 1114, 170, 1490, 2008, 3288, 10645, 170, 1344, 3586, 117, 3694, 1107, 170, 1565, 118, 1236, 11371, 1348, 5014, 113, 123, 6158, 16291, 193, 124, 14255, 18834, 1116, 114, 119, 122, 113, 17614, 1387, 117, 4246, 1539, 117, 2048, 1349, 117, 11211, 1386, 117, 5445, 1384, 114, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 19:33:04 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:33:06,230 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:33:06,239 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:33:06,239 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 19:33:06,239 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:33:06,240 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:33:06,240 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:33:06,240 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:33:06,240 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 19:33:06,241 >>   Number of trainable parameters = 108,312,579
[INFO|integration_utils.py:716] 2023-11-15 19:33:06,242 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<33:37,  1.46s/it]  0%|          | 2/1380 [00:01<15:17,  1.50it/s]  0%|          | 3/1380 [00:01<09:26,  2.43it/s]  0%|          | 4/1380 [00:01<06:44,  3.40it/s]  0%|          | 5/1380 [00:01<05:14,  4.38it/s]  0%|          | 6/1380 [00:02<04:19,  5.29it/s]  1%|          | 7/1380 [00:02<03:44,  6.11it/s]  1%|          | 8/1380 [00:02<03:21,  6.81it/s]  1%|          | 9/1380 [00:02<03:07,  7.31it/s]  1%|          | 10/1380 [00:02<02:55,  7.81it/s]  1%|          | 11/1380 [00:02<02:49,  8.08it/s]  1%|          | 12/1380 [00:02<02:45,  8.28it/s]  1%|          | 13/1380 [00:02<02:39,  8.57it/s]  1%|          | 14/1380 [00:02<02:37,  8.68it/s]  1%|          | 15/1380 [00:03<02:36,  8.69it/s]  1%|          | 16/1380 [00:03<02:35,  8.75it/s]  1%|          | 17/1380 [00:03<02:34,  8.81it/s]  1%|▏         | 18/1380 [00:03<02:33,  8.88it/s]  1%|▏         | 19/1380 [00:03<02:33,  8.89it/s]  1%|▏         | 20/1380 [00:03<02:30,  9.04it/s]  2%|▏         | 21/1380 [00:03<02:33,  8.88it/s]  2%|▏         | 22/1380 [00:03<02:32,  8.91it/s]  2%|▏         | 23/1380 [00:03<02:31,  8.98it/s]  2%|▏         | 24/1380 [00:04<02:29,  9.04it/s]  2%|▏         | 25/1380 [00:04<02:30,  9.00it/s]  2%|▏         | 26/1380 [00:04<02:30,  8.97it/s]  2%|▏         | 27/1380 [00:04<02:30,  8.97it/s]  2%|▏         | 28/1380 [00:04<02:30,  8.99it/s]  2%|▏         | 29/1380 [00:04<02:30,  9.00it/s]  2%|▏         | 30/1380 [00:04<02:27,  9.15it/s]  2%|▏         | 31/1380 [00:04<02:28,  9.07it/s]  2%|▏         | 32/1380 [00:04<02:29,  9.01it/s]  2%|▏         | 33/1380 [00:05<02:30,  8.96it/s]  2%|▏         | 34/1380 [00:05<02:29,  8.98it/s]  3%|▎         | 35/1380 [00:05<02:29,  9.03it/s]  3%|▎         | 36/1380 [00:05<02:29,  8.98it/s]  3%|▎         | 37/1380 [00:05<02:29,  9.01it/s]  3%|▎         | 38/1380 [00:05<02:29,  8.95it/s]  3%|▎         | 39/1380 [00:05<02:29,  9.00it/s]  3%|▎         | 40/1380 [00:05<02:28,  9.04it/s]  3%|▎         | 41/1380 [00:05<02:28,  9.04it/s]  3%|▎         | 42/1380 [00:06<02:29,  8.96it/s]  3%|▎         | 43/1380 [00:06<02:30,  8.90it/s]  3%|▎         | 44/1380 [00:06<02:30,  8.87it/s]  3%|▎         | 45/1380 [00:06<02:29,  8.93it/s]  3%|▎         | 46/1380 [00:06<02:29,  8.92it/s]  3%|▎         | 47/1380 [00:06<02:27,  9.02it/s]  3%|▎         | 48/1380 [00:06<02:27,  9.01it/s]  4%|▎         | 49/1380 [00:06<02:27,  9.00it/s]  4%|▎         | 50/1380 [00:06<02:27,  8.99it/s]  4%|▎         | 51/1380 [00:07<02:26,  9.05it/s]  4%|▍         | 52/1380 [00:07<02:28,  8.94it/s]  4%|▍         | 53/1380 [00:07<02:27,  8.97it/s]  4%|▍         | 54/1380 [00:07<02:26,  9.03it/s]  4%|▍         | 55/1380 [00:07<02:27,  9.00it/s]  4%|▍         | 56/1380 [00:07<02:27,  9.01it/s]  4%|▍         | 57/1380 [00:07<02:25,  9.07it/s]  4%|▍         | 58/1380 [00:07<02:25,  9.08it/s]  4%|▍         | 59/1380 [00:07<02:28,  8.92it/s]  4%|▍         | 60/1380 [00:08<02:27,  8.95it/s]  4%|▍         | 61/1380 [00:08<02:26,  9.00it/s]  4%|▍         | 62/1380 [00:08<02:26,  9.01it/s]  5%|▍         | 63/1380 [00:08<02:27,  8.93it/s]  5%|▍         | 64/1380 [00:08<02:25,  9.01it/s]  5%|▍         | 65/1380 [00:08<02:27,  8.93it/s]  5%|▍         | 66/1380 [00:08<02:25,  9.00it/s]  5%|▍         | 67/1380 [00:08<02:24,  9.06it/s]  5%|▍         | 68/1380 [00:08<02:25,  9.00it/s]  5%|▌         | 69/1380 [00:09<02:27,  8.92it/s]  5%|▌         | 70/1380 [00:09<02:26,  8.92it/s]  5%|▌         | 71/1380 [00:09<02:27,  8.88it/s]  5%|▌         | 72/1380 [00:09<02:27,  8.89it/s]  5%|▌         | 73/1380 [00:09<02:28,  8.81it/s]  5%|▌         | 74/1380 [00:09<02:26,  8.89it/s]  5%|▌         | 75/1380 [00:09<02:26,  8.88it/s]  6%|▌         | 76/1380 [00:09<02:26,  8.92it/s]  6%|▌         | 77/1380 [00:09<02:25,  8.95it/s]  6%|▌         | 78/1380 [00:10<02:26,  8.88it/s]  6%|▌         | 79/1380 [00:10<02:25,  8.92it/s]  6%|▌         | 80/1380 [00:10<02:25,  8.94it/s]  6%|▌         | 81/1380 [00:10<02:25,  8.91it/s]  6%|▌         | 82/1380 [00:10<02:24,  9.01it/s]  6%|▌         | 83/1380 [00:10<02:25,  8.93it/s]  6%|▌         | 84/1380 [00:10<02:22,  9.07it/s]  6%|▌         | 85/1380 [00:10<02:23,  8.99it/s]  6%|▌         | 86/1380 [00:10<02:24,  8.98it/s]  6%|▋         | 87/1380 [00:11<02:24,  8.95it/s]  6%|▋         | 88/1380 [00:11<02:23,  9.00it/s]  6%|▋         | 89/1380 [00:11<02:24,  8.95it/s]  7%|▋         | 90/1380 [00:11<02:24,  8.94it/s]  7%|▋         | 91/1380 [00:11<02:23,  9.00it/s]  7%|▋         | 92/1380 [00:11<02:23,  8.97it/s]  7%|▋         | 93/1380 [00:11<02:22,  9.01it/s]  7%|▋         | 94/1380 [00:11<02:20,  9.12it/s]  7%|▋         | 95/1380 [00:11<02:23,  8.99it/s]  7%|▋         | 96/1380 [00:12<02:23,  8.96it/s]  7%|▋         | 97/1380 [00:12<02:24,  8.91it/s]  7%|▋         | 98/1380 [00:12<02:24,  8.89it/s]  7%|▋         | 99/1380 [00:12<02:23,  8.93it/s]  7%|▋         | 100/1380 [00:12<02:24,  8.84it/s]  7%|▋         | 101/1380 [00:12<02:22,  8.97it/s]  7%|▋         | 102/1380 [00:12<02:22,  8.96it/s]  7%|▋         | 103/1380 [00:12<02:22,  8.96it/s]  8%|▊         | 104/1380 [00:12<02:22,  8.94it/s]  8%|▊         | 105/1380 [00:13<02:22,  8.97it/s]  8%|▊         | 106/1380 [00:13<02:23,  8.90it/s]  8%|▊         | 107/1380 [00:13<02:23,  8.89it/s]  8%|▊         | 108/1380 [00:13<02:23,  8.86it/s]  8%|▊         | 109/1380 [00:13<02:22,  8.92it/s]  8%|▊         | 110/1380 [00:13<02:22,  8.93it/s]  8%|▊         | 111/1380 [00:13<02:19,  9.11it/s]  8%|▊         | 112/1380 [00:13<02:20,  9.01it/s]  8%|▊         | 113/1380 [00:13<02:20,  9.04it/s]  8%|▊         | 114/1380 [00:14<02:20,  9.02it/s]  8%|▊         | 115/1380 [00:14<02:20,  9.00it/s]  8%|▊         | 116/1380 [00:14<02:19,  9.05it/s]  8%|▊         | 117/1380 [00:14<02:20,  9.01it/s]  9%|▊         | 118/1380 [00:14<02:19,  9.07it/s]  9%|▊         | 119/1380 [00:14<02:21,  8.94it/s]  9%|▊         | 120/1380 [00:14<02:21,  8.93it/s]  9%|▉         | 121/1380 [00:14<02:20,  8.94it/s]  9%|▉         | 122/1380 [00:14<02:20,  8.97it/s]  9%|▉         | 123/1380 [00:15<02:21,  8.86it/s]  9%|▉         | 124/1380 [00:15<02:20,  8.92it/s]  9%|▉         | 125/1380 [00:15<02:20,  8.95it/s]  9%|▉         | 126/1380 [00:15<02:20,  8.95it/s]  9%|▉         | 127/1380 [00:15<02:19,  8.99it/s]  9%|▉         | 128/1380 [00:15<02:17,  9.10it/s]  9%|▉         | 129/1380 [00:15<02:19,  8.96it/s]  9%|▉         | 130/1380 [00:15<02:20,  8.87it/s]  9%|▉         | 131/1380 [00:15<02:20,  8.91it/s] 10%|▉         | 132/1380 [00:16<02:19,  8.95it/s] 10%|▉         | 133/1380 [00:16<02:18,  8.99it/s] 10%|▉         | 134/1380 [00:16<02:19,  8.93it/s] 10%|▉         | 135/1380 [00:16<02:18,  9.00it/s] 10%|▉         | 136/1380 [00:16<02:18,  8.96it/s] 10%|▉         | 137/1380 [00:16<02:18,  8.96it/s] 10%|█         | 138/1380 [00:16<02:17,  9.01it/s] 10%|█         | 139/1380 [00:16<02:18,  8.99it/s] 10%|█         | 140/1380 [00:16<02:18,  8.95it/s] 10%|█         | 141/1380 [00:17<02:18,  8.94it/s] 10%|█         | 142/1380 [00:17<02:19,  8.87it/s] 10%|█         | 143/1380 [00:17<02:18,  8.93it/s] 10%|█         | 144/1380 [00:17<02:18,  8.94it/s] 11%|█         | 145/1380 [00:17<02:18,  8.94it/s] 11%|█         | 146/1380 [00:17<02:17,  8.97it/s] 11%|█         | 147/1380 [00:17<02:18,  8.92it/s] 11%|█         | 148/1380 [00:17<02:17,  8.96it/s] 11%|█         | 149/1380 [00:17<02:16,  8.99it/s] 11%|█         | 150/1380 [00:18<02:18,  8.91it/s] 11%|█         | 151/1380 [00:18<02:18,  8.88it/s] 11%|█         | 152/1380 [00:18<02:17,  8.91it/s] 11%|█         | 153/1380 [00:18<02:18,  8.86it/s] 11%|█         | 154/1380 [00:18<02:17,  8.94it/s] 11%|█         | 155/1380 [00:18<02:16,  8.99it/s] 11%|█▏        | 156/1380 [00:18<02:16,  8.97it/s] 11%|█▏        | 157/1380 [00:18<02:16,  8.98it/s] 11%|█▏        | 158/1380 [00:18<02:16,  8.93it/s] 12%|█▏        | 159/1380 [00:19<02:16,  8.94it/s] 12%|█▏        | 160/1380 [00:19<02:16,  8.92it/s] 12%|█▏        | 161/1380 [00:19<02:17,  8.86it/s] 12%|█▏        | 162/1380 [00:19<02:15,  9.00it/s] 12%|█▏        | 163/1380 [00:19<02:16,  8.89it/s] 12%|█▏        | 164/1380 [00:19<02:16,  8.93it/s] 12%|█▏        | 165/1380 [00:19<02:15,  8.98it/s] 12%|█▏        | 166/1380 [00:19<02:14,  9.00it/s] 12%|█▏        | 167/1380 [00:19<02:16,  8.91it/s] 12%|█▏        | 168/1380 [00:20<02:16,  8.85it/s] 12%|█▏        | 169/1380 [00:20<02:17,  8.83it/s] 12%|█▏        | 170/1380 [00:20<02:15,  8.92it/s] 12%|█▏        | 171/1380 [00:20<02:15,  8.90it/s] 12%|█▏        | 172/1380 [00:20<02:13,  9.04it/s] 13%|█▎        | 173/1380 [00:20<02:15,  8.89it/s] 13%|█▎        | 174/1380 [00:20<02:14,  8.97it/s] 13%|█▎        | 175/1380 [00:20<02:15,  8.92it/s] 13%|█▎        | 176/1380 [00:20<02:14,  8.98it/s] 13%|█▎        | 177/1380 [00:21<02:15,  8.91it/s] 13%|█▎        | 178/1380 [00:21<02:15,  8.89it/s] 13%|█▎        | 179/1380 [00:21<02:13,  9.00it/s] 13%|█▎        | 180/1380 [00:21<02:14,  8.90it/s] 13%|█▎        | 181/1380 [00:21<02:14,  8.89it/s] 13%|█▎        | 182/1380 [00:21<02:13,  9.00it/s] 13%|█▎        | 183/1380 [00:21<02:13,  8.95it/s] 13%|█▎        | 184/1380 [00:21<02:14,  8.88it/s] 13%|█▎        | 185/1380 [00:22<02:15,  8.84it/s] 13%|█▎        | 186/1380 [00:22<02:14,  8.90it/s] 14%|█▎        | 187/1380 [00:22<02:12,  8.98it/s] 14%|█▎        | 188/1380 [00:22<02:13,  8.93it/s] 14%|█▎        | 189/1380 [00:22<02:13,  8.93it/s] 14%|█▍        | 190/1380 [00:22<02:13,  8.91it/s] 14%|█▍        | 191/1380 [00:22<02:12,  8.97it/s] 14%|█▍        | 192/1380 [00:22<02:12,  8.96it/s] 14%|█▍        | 193/1380 [00:22<02:12,  8.96it/s] 14%|█▍        | 194/1380 [00:23<02:13,  8.87it/s] 14%|█▍        | 195/1380 [00:23<02:13,  8.86it/s] 14%|█▍        | 196/1380 [00:23<02:13,  8.86it/s] 14%|█▍        | 197/1380 [00:23<02:14,  8.80it/s] 14%|█▍        | 198/1380 [00:23<02:13,  8.82it/s] 14%|█▍        | 199/1380 [00:23<02:12,  8.94it/s] 14%|█▍        | 200/1380 [00:23<02:13,  8.84it/s] 15%|█▍        | 201/1380 [00:23<02:16,  8.67it/s] 15%|█▍        | 202/1380 [00:23<02:15,  8.67it/s] 15%|█▍        | 203/1380 [00:24<02:15,  8.71it/s] 15%|█▍        | 204/1380 [00:24<02:14,  8.77it/s] 15%|█▍        | 205/1380 [00:24<02:15,  8.70it/s] 15%|█▍        | 206/1380 [00:24<02:13,  8.80it/s] 15%|█▌        | 207/1380 [00:24<02:12,  8.82it/s] 15%|█▌        | 208/1380 [00:24<02:12,  8.82it/s] 15%|█▌        | 209/1380 [00:24<02:12,  8.84it/s] 15%|█▌        | 210/1380 [00:24<02:11,  8.87it/s] 15%|█▌        | 211/1380 [00:24<02:12,  8.83it/s] 15%|█▌        | 212/1380 [00:25<02:12,  8.85it/s] 15%|█▌        | 213/1380 [00:25<02:11,  8.86it/s] 16%|█▌        | 214/1380 [00:25<02:11,  8.84it/s] 16%|█▌        | 215/1380 [00:25<02:11,  8.86it/s] 16%|█▌        | 216/1380 [00:25<02:10,  8.95it/s] 16%|█▌        | 217/1380 [00:25<02:11,  8.84it/s] 16%|█▌        | 218/1380 [00:25<02:11,  8.81it/s] 16%|█▌        | 219/1380 [00:25<02:12,  8.73it/s] 16%|█▌        | 220/1380 [00:25<02:12,  8.75it/s] 16%|█▌        | 221/1380 [00:26<02:11,  8.82it/s] 16%|█▌        | 222/1380 [00:26<02:12,  8.72it/s] 16%|█▌        | 223/1380 [00:26<02:11,  8.83it/s] 16%|█▌        | 224/1380 [00:26<02:12,  8.74it/s] 16%|█▋        | 225/1380 [00:26<02:11,  8.79it/s] 16%|█▋        | 226/1380 [00:26<02:10,  8.86it/s] 16%|█▋        | 227/1380 [00:26<02:09,  8.88it/s] 17%|█▋        | 228/1380 [00:26<02:10,  8.84it/s] 17%|█▋        | 229/1380 [00:26<02:09,  8.85it/s] 17%|█▋        | 230/1380 [00:27<02:10,  8.84it/s] 17%|█▋        | 231/1380 [00:27<02:10,  8.79it/s] 17%|█▋        | 232/1380 [00:27<02:09,  8.89it/s] 17%|█▋        | 233/1380 [00:27<02:07,  9.00it/s] 17%|█▋        | 234/1380 [00:27<02:09,  8.86it/s] 17%|█▋        | 235/1380 [00:27<02:09,  8.87it/s] 17%|█▋        | 236/1380 [00:27<02:09,  8.85it/s] 17%|█▋        | 237/1380 [00:27<02:08,  8.87it/s] 17%|█▋        | 238/1380 [00:27<02:08,  8.87it/s] 17%|█▋        | 239/1380 [00:28<02:09,  8.82it/s] 17%|█▋        | 240/1380 [00:28<02:08,  8.89it/s] 17%|█▋        | 241/1380 [00:28<02:09,  8.80it/s] 18%|█▊        | 242/1380 [00:28<02:09,  8.82it/s] 18%|█▊        | 243/1380 [00:28<02:08,  8.88it/s] 18%|█▊        | 244/1380 [00:28<02:08,  8.84it/s] 18%|█▊        | 245/1380 [00:28<02:07,  8.87it/s] 18%|█▊        | 246/1380 [00:28<02:06,  8.95it/s] 18%|█▊        | 247/1380 [00:29<02:06,  8.92it/s] 18%|█▊        | 248/1380 [00:29<02:07,  8.90it/s] 18%|█▊        | 249/1380 [00:29<02:07,  8.86it/s] 18%|█▊        | 250/1380 [00:29<02:05,  8.99it/s] 18%|█▊        | 251/1380 [00:29<02:06,  8.91it/s] 18%|█▊        | 252/1380 [00:29<02:07,  8.82it/s] 18%|█▊        | 253/1380 [00:29<02:07,  8.84it/s] 18%|█▊        | 254/1380 [00:29<02:06,  8.87it/s] 18%|█▊        | 255/1380 [00:29<02:07,  8.84it/s] 19%|█▊        | 256/1380 [00:30<02:08,  8.77it/s] 19%|█▊        | 257/1380 [00:30<02:07,  8.84it/s] 19%|█▊        | 258/1380 [00:30<02:06,  8.86it/s] 19%|█▉        | 259/1380 [00:30<02:06,  8.89it/s] 19%|█▉        | 260/1380 [00:30<02:05,  8.96it/s] 19%|█▉        | 261/1380 [00:30<02:06,  8.87it/s] 19%|█▉        | 262/1380 [00:30<02:06,  8.86it/s] 19%|█▉        | 263/1380 [00:30<02:07,  8.78it/s] 19%|█▉        | 264/1380 [00:30<02:06,  8.84it/s] 19%|█▉        | 265/1380 [00:31<02:05,  8.92it/s] 19%|█▉        | 266/1380 [00:31<02:06,  8.77it/s] 19%|█▉        | 267/1380 [00:31<02:05,  8.87it/s] 19%|█▉        | 268/1380 [00:31<02:06,  8.78it/s] 19%|█▉        | 269/1380 [00:31<02:06,  8.78it/s] 20%|█▉        | 270/1380 [00:31<02:04,  8.91it/s] 20%|█▉        | 271/1380 [00:31<02:04,  8.91it/s] 20%|█▉        | 272/1380 [00:31<02:05,  8.85it/s] 20%|█▉        | 273/1380 [00:31<02:05,  8.84it/s] 20%|█▉        | 274/1380 [00:32<02:05,  8.81it/s] 20%|█▉        | 275/1380 [00:32<02:04,  8.88it/s]                                                   20%|██        | 276/1380 [00:32<02:04,  8.88it/s][INFO|trainer.py:755] 2023-11-15 19:33:38,503 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:33:38,505 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:33:38,505 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:33:38,506 >>   Batch size = 8
{'loss': 0.5095, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 79.94it/s][A
  6%|▌         | 17/276 [00:00<00:03, 72.86it/s][A
  9%|▉         | 25/276 [00:00<00:03, 71.20it/s][A
 12%|█▏        | 33/276 [00:00<00:03, 70.33it/s][A
 15%|█▍        | 41/276 [00:00<00:03, 68.50it/s][A
 17%|█▋        | 48/276 [00:00<00:03, 68.25it/s][A
 20%|█▉        | 55/276 [00:00<00:03, 68.59it/s][A
 23%|██▎       | 63/276 [00:00<00:03, 68.04it/s][A
 25%|██▌       | 70/276 [00:01<00:03, 67.86it/s][A
 28%|██▊       | 77/276 [00:01<00:02, 68.12it/s][A
 30%|███       | 84/276 [00:01<00:02, 68.24it/s][A
 33%|███▎      | 92/276 [00:01<00:02, 69.40it/s][A
 36%|███▌      | 99/276 [00:01<00:02, 69.38it/s][A
 38%|███▊      | 106/276 [00:01<00:02, 67.47it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 69.41it/s][A
 44%|████▍     | 121/276 [00:01<00:02, 67.73it/s][A
 46%|████▋     | 128/276 [00:01<00:02, 68.26it/s][A
 49%|████▉     | 135/276 [00:01<00:02, 68.03it/s][A
 51%|█████▏    | 142/276 [00:02<00:01, 67.92it/s][A
 54%|█████▍    | 150/276 [00:02<00:01, 69.45it/s][A
 57%|█████▋    | 157/276 [00:02<00:01, 67.66it/s][A
 60%|█████▉    | 165/276 [00:02<00:01, 69.72it/s][A
 62%|██████▏   | 172/276 [00:02<00:01, 68.75it/s][A
 65%|██████▍   | 179/276 [00:02<00:01, 68.86it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 67.87it/s][A
 70%|██████▉   | 193/276 [00:02<00:01, 67.84it/s][A
 72%|███████▏  | 200/276 [00:02<00:01, 68.35it/s][A
 75%|███████▌  | 207/276 [00:03<00:01, 67.67it/s][A
 78%|███████▊  | 215/276 [00:03<00:00, 69.73it/s][A
 80%|████████  | 222/276 [00:03<00:00, 68.40it/s][A
 83%|████████▎ | 229/276 [00:03<00:00, 67.06it/s][A
 86%|████████▌ | 236/276 [00:03<00:00, 66.61it/s][A
 88%|████████▊ | 244/276 [00:03<00:00, 68.12it/s][A
 91%|█████████ | 251/276 [00:03<00:00, 67.94it/s][A
 94%|█████████▍| 259/276 [00:03<00:00, 68.93it/s][A
 97%|█████████▋| 267/276 [00:03<00:00, 69.96it/s][A
 99%|█████████▉| 274/276 [00:03<00:00, 68.98it/s][A                                                  
                                                 [A 20%|██        | 276/1380 [00:36<02:04,  8.88it/s]
100%|██████████| 276/276 [00:04<00:00, 68.98it/s][A
                                                 [A 20%|██        | 277/1380 [00:36<19:18,  1.05s/it] 20%|██        | 278/1380 [00:36<15:00,  1.22it/s] 20%|██        | 279/1380 [00:36<11:37,  1.58it/s] 20%|██        | 280/1380 [00:36<09:00,  2.03it/s] 20%|██        | 281/1380 [00:36<07:02,  2.60it/s] 20%|██        | 282/1380 [00:37<05:37,  3.25it/s] 21%|██        | 283/1380 [00:37<04:35,  3.98it/s] 21%|██        | 284/1380 [00:37<03:50,  4.75it/s] 21%|██        | 285/1380 [00:37<03:20,  5.46it/s] 21%|██        | 286/1380 [00:37<02:57,  6.18it/s] 21%|██        | 287/1380 [00:37<02:40,  6.80it/s] 21%|██        | 288/1380 [00:37<02:28,  7.36it/s] 21%|██        | 289/1380 [00:37<02:21,  7.73it/s] 21%|██        | 290/1380 [00:37<02:14,  8.08it/s] 21%|██        | 291/1380 [00:38<02:10,  8.36it/s] 21%|██        | 292/1380 [00:38<02:07,  8.52it/s] 21%|██        | 293/1380 [00:38<02:06,  8.56it/s] 21%|██▏       | 294/1380 [00:38<02:05,  8.66it/s] 21%|██▏       | 295/1380 [00:38<02:05,  8.67it/s] 21%|██▏       | 296/1380 [00:38<02:03,  8.78it/s] 22%|██▏       | 297/1380 [00:38<02:03,  8.80it/s] 22%|██▏       | 298/1380 [00:38<02:02,  8.86it/s] 22%|██▏       | 299/1380 [00:38<02:02,  8.82it/s] 22%|██▏       | 300/1380 [00:39<02:01,  8.85it/s] 22%|██▏       | 301/1380 [00:39<02:01,  8.90it/s] 22%|██▏       | 302/1380 [00:39<02:01,  8.90it/s] 22%|██▏       | 303/1380 [00:39<02:01,  8.88it/s] 22%|██▏       | 304/1380 [00:39<02:01,  8.87it/s] 22%|██▏       | 305/1380 [00:39<02:01,  8.84it/s] 22%|██▏       | 306/1380 [00:39<02:00,  8.90it/s] 22%|██▏       | 307/1380 [00:39<02:00,  8.91it/s] 22%|██▏       | 308/1380 [00:39<01:59,  8.98it/s] 22%|██▏       | 309/1380 [00:40<02:00,  8.92it/s] 22%|██▏       | 310/1380 [00:40<02:00,  8.86it/s] 23%|██▎       | 311/1380 [00:40<02:00,  8.85it/s] 23%|██▎       | 312/1380 [00:40<02:00,  8.83it/s] 23%|██▎       | 313/1380 [00:40<02:01,  8.81it/s] 23%|██▎       | 314/1380 [00:40<02:01,  8.78it/s] 23%|██▎       | 315/1380 [00:40<02:01,  8.76it/s] 23%|██▎       | 316/1380 [00:40<02:00,  8.80it/s] 23%|██▎       | 317/1380 [00:40<02:01,  8.78it/s] 23%|██▎       | 318/1380 [00:41<02:00,  8.85it/s] 23%|██▎       | 319/1380 [00:41<02:00,  8.77it/s] 23%|██▎       | 320/1380 [00:41<02:00,  8.83it/s] 23%|██▎       | 321/1380 [00:41<01:58,  8.90it/s] 23%|██▎       | 322/1380 [00:41<01:58,  8.94it/s] 23%|██▎       | 323/1380 [00:41<01:58,  8.89it/s] 23%|██▎       | 324/1380 [00:41<01:59,  8.85it/s] 24%|██▎       | 325/1380 [00:41<01:59,  8.85it/s] 24%|██▎       | 326/1380 [00:41<01:58,  8.87it/s] 24%|██▎       | 327/1380 [00:42<01:59,  8.84it/s] 24%|██▍       | 328/1380 [00:42<01:58,  8.90it/s] 24%|██▍       | 329/1380 [00:42<01:58,  8.88it/s] 24%|██▍       | 330/1380 [00:42<01:57,  8.91it/s] 24%|██▍       | 331/1380 [00:42<01:57,  8.96it/s] 24%|██▍       | 332/1380 [00:42<01:57,  8.96it/s] 24%|██▍       | 333/1380 [00:42<01:57,  8.94it/s] 24%|██▍       | 334/1380 [00:42<01:58,  8.86it/s] 24%|██▍       | 335/1380 [00:42<01:57,  8.87it/s] 24%|██▍       | 336/1380 [00:43<01:57,  8.91it/s] 24%|██▍       | 337/1380 [00:43<01:57,  8.86it/s] 24%|██▍       | 338/1380 [00:43<01:56,  8.97it/s] 25%|██▍       | 339/1380 [00:43<01:56,  8.92it/s] 25%|██▍       | 340/1380 [00:43<01:56,  8.93it/s] 25%|██▍       | 341/1380 [00:43<01:56,  8.88it/s] 25%|██▍       | 342/1380 [00:43<01:56,  8.88it/s] 25%|██▍       | 343/1380 [00:43<01:57,  8.84it/s] 25%|██▍       | 344/1380 [00:44<01:56,  8.88it/s] 25%|██▌       | 345/1380 [00:44<01:56,  8.88it/s] 25%|██▌       | 346/1380 [00:44<01:56,  8.89it/s] 25%|██▌       | 347/1380 [00:44<01:56,  8.90it/s] 25%|██▌       | 348/1380 [00:44<01:55,  8.95it/s] 25%|██▌       | 349/1380 [00:44<01:55,  8.93it/s] 25%|██▌       | 350/1380 [00:44<01:56,  8.84it/s] 25%|██▌       | 351/1380 [00:44<01:56,  8.85it/s] 26%|██▌       | 352/1380 [00:44<01:55,  8.88it/s] 26%|██▌       | 353/1380 [00:45<01:56,  8.83it/s] 26%|██▌       | 354/1380 [00:45<01:56,  8.84it/s] 26%|██▌       | 355/1380 [00:45<01:55,  8.85it/s] 26%|██▌       | 356/1380 [00:45<01:55,  8.83it/s] 26%|██▌       | 357/1380 [00:45<01:55,  8.84it/s] 26%|██▌       | 358/1380 [00:45<01:54,  8.90it/s] 26%|██▌       | 359/1380 [00:45<01:55,  8.83it/s] 26%|██▌       | 360/1380 [00:45<01:55,  8.84it/s] 26%|██▌       | 361/1380 [00:45<01:54,  8.87it/s] 26%|██▌       | 362/1380 [00:46<01:54,  8.91it/s] 26%|██▋       | 363/1380 [00:46<01:54,  8.87it/s] 26%|██▋       | 364/1380 [00:46<01:54,  8.88it/s] 26%|██▋       | 365/1380 [00:46<01:54,  8.89it/s] 27%|██▋       | 366/1380 [00:46<01:54,  8.86it/s] 27%|██▋       | 367/1380 [00:46<01:53,  8.89it/s] 27%|██▋       | 368/1380 [00:46<01:52,  8.96it/s] 27%|██▋       | 369/1380 [00:46<01:54,  8.85it/s] 27%|██▋       | 370/1380 [00:46<01:54,  8.79it/s] 27%|██▋       | 371/1380 [00:47<01:54,  8.78it/s] 27%|██▋       | 372/1380 [00:47<01:53,  8.88it/s] 27%|██▋       | 373/1380 [00:47<01:53,  8.86it/s] 27%|██▋       | 374/1380 [00:47<01:54,  8.82it/s] 27%|██▋       | 375/1380 [00:47<01:53,  8.87it/s] 27%|██▋       | 376/1380 [00:47<01:53,  8.84it/s] 27%|██▋       | 377/1380 [00:47<01:53,  8.86it/s] 27%|██▋       | 378/1380 [00:47<01:51,  8.96it/s] 27%|██▋       | 379/1380 [00:47<01:53,  8.83it/s] 28%|██▊       | 380/1380 [00:48<01:52,  8.86it/s] 28%|██▊       | 381/1380 [00:48<01:52,  8.87it/s] 28%|██▊       | 382/1380 [00:48<01:52,  8.90it/s] 28%|██▊       | 383/1380 [00:48<01:52,  8.89it/s] 28%|██▊       | 384/1380 [00:48<01:52,  8.83it/s] 28%|██▊       | 385/1380 [00:48<01:51,  8.90it/s] 28%|██▊       | 386/1380 [00:48<01:52,  8.82it/s] 28%|██▊       | 387/1380 [00:48<01:51,  8.91it/s] 28%|██▊       | 388/1380 [00:48<01:50,  8.98it/s] 28%|██▊       | 389/1380 [00:49<01:51,  8.88it/s] 28%|██▊       | 390/1380 [00:49<01:51,  8.86it/s] 28%|██▊       | 391/1380 [00:49<01:52,  8.82it/s] 28%|██▊       | 392/1380 [00:49<01:51,  8.87it/s] 28%|██▊       | 393/1380 [00:49<01:51,  8.87it/s] 29%|██▊       | 394/1380 [00:49<01:51,  8.82it/s] 29%|██▊       | 395/1380 [00:49<01:50,  8.90it/s] 29%|██▊       | 396/1380 [00:49<01:50,  8.88it/s] 29%|██▉       | 397/1380 [00:49<01:50,  8.93it/s] 29%|██▉       | 398/1380 [00:50<01:48,  9.01it/s] 29%|██▉       | 399/1380 [00:50<01:50,  8.88it/s] 29%|██▉       | 400/1380 [00:50<01:51,  8.79it/s] 29%|██▉       | 401/1380 [00:50<01:51,  8.75it/s] 29%|██▉       | 402/1380 [00:50<01:50,  8.85it/s] 29%|██▉       | 403/1380 [00:50<01:50,  8.86it/s] 29%|██▉       | 404/1380 [00:50<01:50,  8.82it/s] 29%|██▉       | 405/1380 [00:50<01:50,  8.83it/s] 29%|██▉       | 406/1380 [00:50<01:48,  8.96it/s] 29%|██▉       | 407/1380 [00:51<01:48,  8.95it/s] 30%|██▉       | 408/1380 [00:51<01:48,  8.99it/s] 30%|██▉       | 409/1380 [00:51<01:49,  8.85it/s] 30%|██▉       | 410/1380 [00:51<01:49,  8.86it/s] 30%|██▉       | 411/1380 [00:51<01:49,  8.82it/s] 30%|██▉       | 412/1380 [00:51<01:49,  8.87it/s] 30%|██▉       | 413/1380 [00:51<01:48,  8.92it/s] 30%|███       | 414/1380 [00:51<01:48,  8.91it/s] 30%|███       | 415/1380 [00:52<01:47,  9.00it/s] 30%|███       | 416/1380 [00:52<01:48,  8.92it/s] 30%|███       | 417/1380 [00:52<01:47,  8.92it/s] 30%|███       | 418/1380 [00:52<01:46,  9.00it/s] 30%|███       | 419/1380 [00:52<01:47,  8.93it/s] 30%|███       | 420/1380 [00:52<01:47,  8.90it/s] 31%|███       | 421/1380 [00:52<01:48,  8.84it/s] 31%|███       | 422/1380 [00:52<01:48,  8.86it/s] 31%|███       | 423/1380 [00:52<01:47,  8.94it/s] 31%|███       | 424/1380 [00:53<01:47,  8.89it/s] 31%|███       | 425/1380 [00:53<01:45,  9.02it/s] 31%|███       | 426/1380 [00:53<01:46,  8.93it/s] 31%|███       | 427/1380 [00:53<01:45,  9.00it/s] 31%|███       | 428/1380 [00:53<01:45,  9.03it/s] 31%|███       | 429/1380 [00:53<01:45,  8.98it/s] 31%|███       | 430/1380 [00:53<01:46,  8.93it/s] 31%|███       | 431/1380 [00:53<01:46,  8.88it/s] 31%|███▏      | 432/1380 [00:53<01:47,  8.82it/s] 31%|███▏      | 433/1380 [00:54<01:46,  8.91it/s] 31%|███▏      | 434/1380 [00:54<01:46,  8.86it/s] 32%|███▏      | 435/1380 [00:54<01:45,  8.93it/s] 32%|███▏      | 436/1380 [00:54<01:45,  8.92it/s] 32%|███▏      | 437/1380 [00:54<01:45,  8.95it/s] 32%|███▏      | 438/1380 [00:54<01:45,  8.95it/s] 32%|███▏      | 439/1380 [00:54<01:45,  8.95it/s] 32%|███▏      | 440/1380 [00:54<01:45,  8.90it/s] 32%|███▏      | 441/1380 [00:54<01:45,  8.91it/s] 32%|███▏      | 442/1380 [00:55<01:45,  8.87it/s] 32%|███▏      | 443/1380 [00:55<01:44,  8.92it/s] 32%|███▏      | 444/1380 [00:55<01:45,  8.89it/s] 32%|███▏      | 445/1380 [00:55<01:44,  8.98it/s] 32%|███▏      | 446/1380 [00:55<01:44,  8.96it/s] 32%|███▏      | 447/1380 [00:55<01:44,  8.94it/s] 32%|███▏      | 448/1380 [00:55<01:43,  9.01it/s] 33%|███▎      | 449/1380 [00:55<01:43,  9.01it/s] 33%|███▎      | 450/1380 [00:55<01:44,  8.92it/s] 33%|███▎      | 451/1380 [00:56<01:44,  8.90it/s] 33%|███▎      | 452/1380 [00:56<01:44,  8.92it/s] 33%|███▎      | 453/1380 [00:56<01:43,  8.95it/s] 33%|███▎      | 454/1380 [00:56<01:43,  8.95it/s] 33%|███▎      | 455/1380 [00:56<01:43,  8.97it/s] 33%|███▎      | 456/1380 [00:56<01:43,  8.94it/s] 33%|███▎      | 457/1380 [00:56<01:43,  8.90it/s] 33%|███▎      | 458/1380 [00:56<01:42,  8.98it/s] 33%|███▎      | 459/1380 [00:56<01:43,  8.93it/s] 33%|███▎      | 460/1380 [00:57<01:43,  8.90it/s] 33%|███▎      | 461/1380 [00:57<01:43,  8.88it/s] 33%|███▎      | 462/1380 [00:57<01:43,  8.86it/s] 34%|███▎      | 463/1380 [00:57<01:43,  8.87it/s] 34%|███▎      | 464/1380 [00:57<01:43,  8.89it/s] 34%|███▎      | 465/1380 [00:57<01:41,  9.00it/s] 34%|███▍      | 466/1380 [00:57<01:41,  8.96it/s] 34%|███▍      | 467/1380 [00:57<01:42,  8.88it/s] 34%|███▍      | 468/1380 [00:57<01:41,  8.97it/s] 34%|███▍      | 469/1380 [00:58<01:41,  8.96it/s] 34%|███▍      | 470/1380 [00:58<01:43,  8.83it/s] 34%|███▍      | 471/1380 [00:58<01:42,  8.85it/s] 34%|███▍      | 472/1380 [00:58<01:43,  8.81it/s] 34%|███▍      | 473/1380 [00:58<01:41,  8.91it/s] 34%|███▍      | 474/1380 [00:58<01:42,  8.87it/s] 34%|███▍      | 475/1380 [00:58<01:40,  8.97it/s] 34%|███▍      | 476/1380 [00:58<01:41,  8.87it/s] 35%|███▍      | 477/1380 [00:58<01:41,  8.90it/s] 35%|███▍      | 478/1380 [00:59<01:40,  8.95it/s] 35%|███▍      | 479/1380 [00:59<01:41,  8.87it/s] 35%|███▍      | 480/1380 [00:59<01:41,  8.86it/s] 35%|███▍      | 481/1380 [00:59<01:41,  8.86it/s] 35%|███▍      | 482/1380 [00:59<01:41,  8.89it/s] 35%|███▌      | 483/1380 [00:59<01:40,  8.94it/s] 35%|███▌      | 484/1380 [00:59<01:40,  8.93it/s] 35%|███▌      | 485/1380 [00:59<01:39,  8.97it/s] 35%|███▌      | 486/1380 [00:59<01:40,  8.87it/s] 35%|███▌      | 487/1380 [01:00<01:40,  8.90it/s] 35%|███▌      | 488/1380 [01:00<01:39,  8.99it/s] 35%|███▌      | 489/1380 [01:00<01:40,  8.90it/s] 36%|███▌      | 490/1380 [01:00<01:40,  8.88it/s] 36%|███▌      | 491/1380 [01:00<01:40,  8.89it/s] 36%|███▌      | 492/1380 [01:00<01:39,  8.89it/s] 36%|███▌      | 493/1380 [01:00<01:39,  8.94it/s] 36%|███▌      | 494/1380 [01:00<01:39,  8.88it/s] 36%|███▌      | 495/1380 [01:00<01:38,  8.96it/s] 36%|███▌      | 496/1380 [01:01<01:39,  8.89it/s] 36%|███▌      | 497/1380 [01:01<01:39,  8.91it/s] 36%|███▌      | 498/1380 [01:01<01:38,  8.99it/s] 36%|███▌      | 499/1380 [01:01<01:39,  8.89it/s] 36%|███▌      | 500/1380 [01:01<01:38,  8.95it/s] 36%|███▋      | 501/1380 [01:01<01:38,  8.93it/s] 36%|███▋      | 502/1380 [01:01<01:38,  8.91it/s] 36%|███▋      | 503/1380 [01:01<01:38,  8.88it/s] 37%|███▋      | 504/1380 [01:01<01:38,  8.86it/s] 37%|███▋      | 505/1380 [01:02<01:38,  8.91it/s] 37%|███▋      | 506/1380 [01:02<01:38,  8.87it/s] 37%|███▋      | 507/1380 [01:02<01:38,  8.90it/s] 37%|███▋      | 508/1380 [01:02<01:36,  9.00it/s] 37%|███▋      | 509/1380 [01:02<01:38,  8.86it/s] 37%|███▋      | 510/1380 [01:02<01:37,  8.89it/s] 37%|███▋      | 511/1380 [01:02<01:38,  8.86it/s] 37%|███▋      | 512/1380 [01:02<01:37,  8.86it/s] 37%|███▋      | 513/1380 [01:02<01:37,  8.88it/s] 37%|███▋      | 514/1380 [01:03<01:38,  8.80it/s] 37%|███▋      | 515/1380 [01:03<01:37,  8.87it/s] 37%|███▋      | 516/1380 [01:03<01:37,  8.85it/s] 37%|███▋      | 517/1380 [01:03<01:37,  8.89it/s] 38%|███▊      | 518/1380 [01:03<01:36,  8.97it/s] 38%|███▊      | 519/1380 [01:03<01:36,  8.89it/s] 38%|███▊      | 520/1380 [01:03<01:36,  8.87it/s] 38%|███▊      | 521/1380 [01:03<01:36,  8.87it/s] 38%|███▊      | 522/1380 [01:04<01:36,  8.90it/s] 38%|███▊      | 523/1380 [01:04<01:36,  8.90it/s] 38%|███▊      | 524/1380 [01:04<01:36,  8.88it/s] 38%|███▊      | 525/1380 [01:04<01:36,  8.82it/s] 38%|███▊      | 526/1380 [01:04<01:36,  8.84it/s] 38%|███▊      | 527/1380 [01:04<01:35,  8.90it/s] 38%|███▊      | 528/1380 [01:04<01:34,  9.00it/s] 38%|███▊      | 529/1380 [01:04<01:35,  8.87it/s] 38%|███▊      | 530/1380 [01:04<01:35,  8.88it/s] 38%|███▊      | 531/1380 [01:05<01:36,  8.82it/s] 39%|███▊      | 532/1380 [01:05<01:35,  8.85it/s] 39%|███▊      | 533/1380 [01:05<01:35,  8.86it/s] 39%|███▊      | 534/1380 [01:05<01:36,  8.73it/s] 39%|███▉      | 535/1380 [01:05<01:35,  8.83it/s] 39%|███▉      | 536/1380 [01:05<01:35,  8.85it/s] 39%|███▉      | 537/1380 [01:05<01:35,  8.83it/s] 39%|███▉      | 538/1380 [01:05<01:34,  8.88it/s] 39%|███▉      | 539/1380 [01:05<01:34,  8.87it/s] 39%|███▉      | 540/1380 [01:06<01:35,  8.80it/s] 39%|███▉      | 541/1380 [01:06<01:34,  8.85it/s] 39%|███▉      | 542/1380 [01:06<01:34,  8.89it/s] 39%|███▉      | 543/1380 [01:06<01:33,  8.93it/s] 39%|███▉      | 544/1380 [01:06<01:34,  8.85it/s] 39%|███▉      | 545/1380 [01:06<01:33,  8.90it/s] 40%|███▉      | 546/1380 [01:06<01:34,  8.84it/s] 40%|███▉      | 547/1380 [01:06<01:33,  8.86it/s] 40%|███▉      | 548/1380 [01:06<01:33,  8.89it/s] 40%|███▉      | 549/1380 [01:07<01:33,  8.84it/s] 40%|███▉      | 550/1380 [01:07<01:33,  8.87it/s] 40%|███▉      | 551/1380 [01:07<01:33,  8.83it/s]                                                   40%|████      | 552/1380 [01:07<01:33,  8.83it/s][INFO|trainer.py:755] 2023-11-15 19:34:13,618 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:34:13,621 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:34:13,621 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:34:13,621 >>   Batch size = 8
{'eval_loss': 0.40452882647514343, 'eval_accuracy': 0.8539019963702359, 'eval_micro_f1': 0.8539019963702359, 'eval_macro_f1': 0.8356429029410086, 'eval_runtime': 4.0891, 'eval_samples_per_second': 539.0, 'eval_steps_per_second': 67.497, 'epoch': 1.0}
{'loss': 0.3109, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 81.35it/s][A
  7%|▋         | 18/276 [00:00<00:03, 71.04it/s][A
  9%|▉         | 26/276 [00:00<00:03, 69.53it/s][A
 12%|█▏        | 33/276 [00:00<00:03, 69.37it/s][A
 14%|█▍        | 40/276 [00:00<00:03, 69.17it/s][A
 17%|█▋        | 48/276 [00:00<00:03, 70.93it/s][A
 20%|██        | 56/276 [00:00<00:03, 68.44it/s][A
 23%|██▎       | 63/276 [00:00<00:03, 67.83it/s][A
 25%|██▌       | 70/276 [00:01<00:03, 67.40it/s][A
 28%|██▊       | 77/276 [00:01<00:02, 67.44it/s][A
 31%|███       | 85/276 [00:01<00:02, 69.30it/s][A
 33%|███▎      | 92/276 [00:01<00:02, 68.88it/s][A
 36%|███▌      | 100/276 [00:01<00:02, 69.40it/s][A
 39%|███▉      | 107/276 [00:01<00:02, 68.99it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 69.08it/s][A
 44%|████▍     | 121/276 [00:01<00:02, 68.33it/s][A
 46%|████▋     | 128/276 [00:01<00:02, 68.07it/s][A
 49%|████▉     | 135/276 [00:01<00:02, 68.49it/s][A
 51%|█████▏    | 142/276 [00:02<00:01, 68.48it/s][A
 54%|█████▍    | 150/276 [00:02<00:01, 70.00it/s][A
 57%|█████▋    | 157/276 [00:02<00:01, 68.93it/s][A
 59%|█████▉    | 164/276 [00:02<00:01, 67.20it/s][A
 62%|██████▏   | 171/276 [00:02<00:01, 67.35it/s][A
 65%|██████▍   | 179/276 [00:02<00:01, 68.22it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 68.50it/s][A
 70%|███████   | 194/276 [00:02<00:01, 68.77it/s][A
 73%|███████▎  | 202/276 [00:02<00:01, 70.25it/s][A
 76%|███████▌  | 210/276 [00:03<00:00, 67.54it/s][A
 79%|███████▊  | 217/276 [00:03<00:00, 67.35it/s][A
 81%|████████  | 224/276 [00:03<00:00, 67.12it/s][A
 84%|████████▎ | 231/276 [00:03<00:00, 67.46it/s][A
 87%|████████▋ | 239/276 [00:03<00:00, 69.20it/s][A
 89%|████████▉ | 246/276 [00:03<00:00, 68.48it/s][A
 92%|█████████▏| 254/276 [00:03<00:00, 69.64it/s][A
 95%|█████████▍| 261/276 [00:03<00:00, 68.38it/s][A
 97%|█████████▋| 268/276 [00:03<00:00, 67.40it/s][A
100%|██████████| 276/276 [00:04<00:00, 69.52it/s][A                                                  
                                                 [A 40%|████      | 552/1380 [01:11<01:33,  8.83it/s]
100%|██████████| 276/276 [00:04<00:00, 69.52it/s][A
                                                 [A 40%|████      | 553/1380 [01:11<14:27,  1.05s/it] 40%|████      | 554/1380 [01:11<11:15,  1.22it/s] 40%|████      | 555/1380 [01:11<08:42,  1.58it/s] 40%|████      | 556/1380 [01:11<06:45,  2.03it/s] 40%|████      | 557/1380 [01:12<05:18,  2.58it/s] 40%|████      | 558/1380 [01:12<04:13,  3.24it/s] 41%|████      | 559/1380 [01:12<03:27,  3.96it/s] 41%|████      | 560/1380 [01:12<02:53,  4.73it/s] 41%|████      | 561/1380 [01:12<02:29,  5.49it/s] 41%|████      | 562/1380 [01:12<02:11,  6.20it/s] 41%|████      | 563/1380 [01:12<02:00,  6.80it/s] 41%|████      | 564/1380 [01:12<01:51,  7.32it/s] 41%|████      | 565/1380 [01:12<01:45,  7.73it/s] 41%|████      | 566/1380 [01:13<01:42,  7.98it/s] 41%|████      | 567/1380 [01:13<01:38,  8.21it/s] 41%|████      | 568/1380 [01:13<01:36,  8.38it/s] 41%|████      | 569/1380 [01:13<01:35,  8.46it/s] 41%|████▏     | 570/1380 [01:13<01:34,  8.62it/s] 41%|████▏     | 571/1380 [01:13<01:34,  8.60it/s] 41%|████▏     | 572/1380 [01:13<01:32,  8.78it/s] 42%|████▏     | 573/1380 [01:13<01:32,  8.76it/s] 42%|████▏     | 574/1380 [01:13<01:31,  8.85it/s] 42%|████▏     | 575/1380 [01:14<01:30,  8.92it/s] 42%|████▏     | 576/1380 [01:14<01:30,  8.90it/s] 42%|████▏     | 577/1380 [01:14<01:30,  8.86it/s] 42%|████▏     | 578/1380 [01:14<01:30,  8.85it/s] 42%|████▏     | 579/1380 [01:14<01:30,  8.84it/s] 42%|████▏     | 580/1380 [01:14<01:30,  8.85it/s] 42%|████▏     | 581/1380 [01:14<01:30,  8.84it/s] 42%|████▏     | 582/1380 [01:14<01:29,  8.88it/s] 42%|████▏     | 583/1380 [01:14<01:30,  8.85it/s] 42%|████▏     | 584/1380 [01:15<01:29,  8.87it/s] 42%|████▏     | 585/1380 [01:15<01:28,  8.94it/s] 42%|████▏     | 586/1380 [01:15<01:30,  8.81it/s] 43%|████▎     | 587/1380 [01:15<01:30,  8.79it/s] 43%|████▎     | 588/1380 [01:15<01:30,  8.78it/s] 43%|████▎     | 589/1380 [01:15<01:29,  8.85it/s] 43%|████▎     | 590/1380 [01:15<01:29,  8.86it/s] 43%|████▎     | 591/1380 [01:15<01:29,  8.83it/s] 43%|████▎     | 592/1380 [01:15<01:28,  8.88it/s] 43%|████▎     | 593/1380 [01:16<01:29,  8.77it/s] 43%|████▎     | 594/1380 [01:16<01:28,  8.83it/s] 43%|████▎     | 595/1380 [01:16<01:27,  8.92it/s] 43%|████▎     | 596/1380 [01:16<01:28,  8.84it/s] 43%|████▎     | 597/1380 [01:16<01:28,  8.82it/s] 43%|████▎     | 598/1380 [01:16<01:28,  8.84it/s] 43%|████▎     | 599/1380 [01:16<01:27,  8.90it/s] 43%|████▎     | 600/1380 [01:16<01:27,  8.87it/s] 44%|████▎     | 601/1380 [01:17<01:28,  8.80it/s] 44%|████▎     | 602/1380 [01:17<01:27,  8.86it/s] 44%|████▎     | 603/1380 [01:17<01:28,  8.79it/s] 44%|████▍     | 604/1380 [01:17<01:27,  8.84it/s] 44%|████▍     | 605/1380 [01:17<01:26,  8.96it/s] 44%|████▍     | 606/1380 [01:17<01:27,  8.84it/s] 44%|████▍     | 607/1380 [01:17<01:28,  8.77it/s] 44%|████▍     | 608/1380 [01:17<01:28,  8.76it/s] 44%|████▍     | 609/1380 [01:17<01:27,  8.80it/s] 44%|████▍     | 610/1380 [01:18<01:28,  8.74it/s] 44%|████▍     | 611/1380 [01:18<01:27,  8.77it/s] 44%|████▍     | 612/1380 [01:18<01:27,  8.75it/s] 44%|████▍     | 613/1380 [01:18<01:27,  8.79it/s] 44%|████▍     | 614/1380 [01:18<01:27,  8.76it/s] 45%|████▍     | 615/1380 [01:18<01:26,  8.89it/s] 45%|████▍     | 616/1380 [01:18<01:26,  8.82it/s] 45%|████▍     | 617/1380 [01:18<01:26,  8.81it/s] 45%|████▍     | 618/1380 [01:18<01:26,  8.80it/s] 45%|████▍     | 619/1380 [01:19<01:25,  8.88it/s] 45%|████▍     | 620/1380 [01:19<01:25,  8.87it/s] 45%|████▌     | 621/1380 [01:19<01:25,  8.84it/s] 45%|████▌     | 622/1380 [01:19<01:24,  8.93it/s] 45%|████▌     | 623/1380 [01:19<01:25,  8.84it/s] 45%|████▌     | 624/1380 [01:19<01:25,  8.87it/s] 45%|████▌     | 625/1380 [01:19<01:24,  8.99it/s] 45%|████▌     | 626/1380 [01:19<01:25,  8.86it/s] 45%|████▌     | 627/1380 [01:19<01:24,  8.86it/s] 46%|████▌     | 628/1380 [01:20<01:25,  8.80it/s] 46%|████▌     | 629/1380 [01:20<01:24,  8.84it/s] 46%|████▌     | 630/1380 [01:20<01:24,  8.84it/s] 46%|████▌     | 631/1380 [01:20<01:24,  8.82it/s] 46%|████▌     | 632/1380 [01:20<01:24,  8.89it/s] 46%|████▌     | 633/1380 [01:20<01:24,  8.79it/s] 46%|████▌     | 634/1380 [01:20<01:24,  8.85it/s] 46%|████▌     | 635/1380 [01:20<01:23,  8.94it/s] 46%|████▌     | 636/1380 [01:20<01:24,  8.85it/s] 46%|████▌     | 637/1380 [01:21<01:24,  8.82it/s] 46%|████▌     | 638/1380 [01:21<01:24,  8.80it/s] 46%|████▋     | 639/1380 [01:21<01:24,  8.79it/s] 46%|████▋     | 640/1380 [01:21<01:23,  8.82it/s] 46%|████▋     | 641/1380 [01:21<01:23,  8.83it/s] 47%|████▋     | 642/1380 [01:21<01:22,  8.90it/s] 47%|████▋     | 643/1380 [01:21<01:23,  8.83it/s] 47%|████▋     | 644/1380 [01:21<01:23,  8.81it/s] 47%|████▋     | 645/1380 [01:21<01:22,  8.89it/s] 47%|████▋     | 646/1380 [01:22<01:22,  8.91it/s] 47%|████▋     | 647/1380 [01:22<01:23,  8.82it/s] 47%|████▋     | 648/1380 [01:22<01:23,  8.81it/s] 47%|████▋     | 649/1380 [01:22<01:22,  8.81it/s] 47%|████▋     | 650/1380 [01:22<01:22,  8.81it/s] 47%|████▋     | 651/1380 [01:22<01:22,  8.83it/s] 47%|████▋     | 652/1380 [01:22<01:21,  8.92it/s] 47%|████▋     | 653/1380 [01:22<01:22,  8.82it/s] 47%|████▋     | 654/1380 [01:22<01:22,  8.81it/s] 47%|████▋     | 655/1380 [01:23<01:22,  8.74it/s] 48%|████▊     | 656/1380 [01:23<01:22,  8.82it/s] 48%|████▊     | 657/1380 [01:23<01:22,  8.78it/s] 48%|████▊     | 658/1380 [01:23<01:21,  8.81it/s] 48%|████▊     | 659/1380 [01:23<01:21,  8.83it/s] 48%|████▊     | 660/1380 [01:23<01:22,  8.75it/s] 48%|████▊     | 661/1380 [01:23<01:21,  8.80it/s] 48%|████▊     | 662/1380 [01:23<01:19,  8.98it/s] 48%|████▊     | 663/1380 [01:24<01:20,  8.88it/s] 48%|████▊     | 664/1380 [01:24<01:21,  8.76it/s] 48%|████▊     | 665/1380 [01:24<01:21,  8.75it/s] 48%|████▊     | 666/1380 [01:24<01:21,  8.77it/s] 48%|████▊     | 667/1380 [01:24<01:21,  8.79it/s] 48%|████▊     | 668/1380 [01:24<01:21,  8.71it/s] 48%|████▊     | 669/1380 [01:24<01:20,  8.82it/s] 49%|████▊     | 670/1380 [01:24<01:21,  8.72it/s] 49%|████▊     | 671/1380 [01:24<01:20,  8.80it/s] 49%|████▊     | 672/1380 [01:25<01:19,  8.91it/s] 49%|████▉     | 673/1380 [01:25<01:20,  8.79it/s] 49%|████▉     | 674/1380 [01:25<01:20,  8.81it/s] 49%|████▉     | 675/1380 [01:25<01:20,  8.78it/s] 49%|████▉     | 676/1380 [01:25<01:19,  8.87it/s] 49%|████▉     | 677/1380 [01:25<01:19,  8.87it/s] 49%|████▉     | 678/1380 [01:25<01:19,  8.80it/s] 49%|████▉     | 679/1380 [01:25<01:19,  8.87it/s] 49%|████▉     | 680/1380 [01:25<01:19,  8.86it/s] 49%|████▉     | 681/1380 [01:26<01:19,  8.83it/s] 49%|████▉     | 682/1380 [01:26<01:18,  8.92it/s] 49%|████▉     | 683/1380 [01:26<01:19,  8.82it/s] 50%|████▉     | 684/1380 [01:26<01:18,  8.81it/s] 50%|████▉     | 685/1380 [01:26<01:18,  8.82it/s] 50%|████▉     | 686/1380 [01:26<01:18,  8.80it/s] 50%|████▉     | 687/1380 [01:26<01:18,  8.80it/s] 50%|████▉     | 688/1380 [01:26<01:19,  8.72it/s] 50%|████▉     | 689/1380 [01:26<01:18,  8.78it/s] 50%|█████     | 690/1380 [01:27<01:18,  8.81it/s] 50%|█████     | 691/1380 [01:27<01:18,  8.79it/s] 50%|█████     | 692/1380 [01:27<01:17,  8.87it/s] 50%|█████     | 693/1380 [01:27<01:18,  8.81it/s] 50%|█████     | 694/1380 [01:27<01:18,  8.79it/s] 50%|█████     | 695/1380 [01:27<01:17,  8.83it/s] 50%|█████     | 696/1380 [01:27<01:17,  8.78it/s] 51%|█████     | 697/1380 [01:27<01:17,  8.80it/s] 51%|█████     | 698/1380 [01:27<01:18,  8.72it/s] 51%|█████     | 699/1380 [01:28<01:17,  8.80it/s] 51%|█████     | 700/1380 [01:28<01:17,  8.79it/s] 51%|█████     | 701/1380 [01:28<01:17,  8.81it/s] 51%|█████     | 702/1380 [01:28<01:16,  8.89it/s] 51%|█████     | 703/1380 [01:28<01:16,  8.81it/s] 51%|█████     | 704/1380 [01:28<01:17,  8.75it/s] 51%|█████     | 705/1380 [01:28<01:16,  8.79it/s] 51%|█████     | 706/1380 [01:28<01:17,  8.74it/s] 51%|█████     | 707/1380 [01:29<01:16,  8.81it/s] 51%|█████▏    | 708/1380 [01:29<01:16,  8.79it/s] 51%|█████▏    | 709/1380 [01:29<01:15,  8.86it/s] 51%|█████▏    | 710/1380 [01:29<01:16,  8.80it/s] 52%|█████▏    | 711/1380 [01:29<01:15,  8.81it/s] 52%|█████▏    | 712/1380 [01:29<01:15,  8.87it/s] 52%|█████▏    | 713/1380 [01:29<01:15,  8.84it/s] 52%|█████▏    | 714/1380 [01:29<01:15,  8.77it/s] 52%|█████▏    | 715/1380 [01:29<01:16,  8.75it/s] 52%|█████▏    | 716/1380 [01:30<01:15,  8.75it/s] 52%|█████▏    | 717/1380 [01:30<01:15,  8.73it/s] 52%|█████▏    | 718/1380 [01:30<01:15,  8.72it/s] 52%|█████▏    | 719/1380 [01:30<01:14,  8.82it/s] 52%|█████▏    | 720/1380 [01:30<01:15,  8.75it/s] 52%|█████▏    | 721/1380 [01:30<01:14,  8.82it/s] 52%|█████▏    | 722/1380 [01:30<01:14,  8.79it/s] 52%|█████▏    | 723/1380 [01:30<01:14,  8.83it/s] 52%|█████▏    | 724/1380 [01:30<01:14,  8.75it/s] 53%|█████▎    | 725/1380 [01:31<01:14,  8.82it/s] 53%|█████▎    | 726/1380 [01:31<01:14,  8.76it/s] 53%|█████▎    | 727/1380 [01:31<01:14,  8.81it/s] 53%|█████▎    | 728/1380 [01:31<01:13,  8.81it/s] 53%|█████▎    | 729/1380 [01:31<01:13,  8.81it/s] 53%|█████▎    | 730/1380 [01:31<01:13,  8.79it/s] 53%|█████▎    | 731/1380 [01:31<01:13,  8.82it/s] 53%|█████▎    | 732/1380 [01:31<01:13,  8.82it/s] 53%|█████▎    | 733/1380 [01:31<01:12,  8.88it/s] 53%|█████▎    | 734/1380 [01:32<01:13,  8.78it/s] 53%|█████▎    | 735/1380 [01:32<01:13,  8.79it/s] 53%|█████▎    | 736/1380 [01:32<01:13,  8.78it/s] 53%|█████▎    | 737/1380 [01:32<01:13,  8.77it/s] 53%|█████▎    | 738/1380 [01:32<01:12,  8.84it/s] 54%|█████▎    | 739/1380 [01:32<01:11,  8.91it/s] 54%|█████▎    | 740/1380 [01:32<01:12,  8.80it/s] 54%|█████▎    | 741/1380 [01:32<01:12,  8.79it/s] 54%|█████▍    | 742/1380 [01:32<01:12,  8.83it/s] 54%|█████▍    | 743/1380 [01:33<01:11,  8.88it/s] 54%|█████▍    | 744/1380 [01:33<01:12,  8.83it/s] 54%|█████▍    | 745/1380 [01:33<01:12,  8.77it/s] 54%|█████▍    | 746/1380 [01:33<01:12,  8.76it/s] 54%|█████▍    | 747/1380 [01:33<01:12,  8.78it/s] 54%|█████▍    | 748/1380 [01:33<01:11,  8.79it/s] 54%|█████▍    | 749/1380 [01:33<01:11,  8.83it/s] 54%|█████▍    | 750/1380 [01:33<01:11,  8.85it/s] 54%|█████▍    | 751/1380 [01:34<01:11,  8.84it/s] 54%|█████▍    | 752/1380 [01:34<01:10,  8.85it/s] 55%|█████▍    | 753/1380 [01:34<01:10,  8.90it/s] 55%|█████▍    | 754/1380 [01:34<01:11,  8.78it/s] 55%|█████▍    | 755/1380 [01:34<01:11,  8.79it/s] 55%|█████▍    | 756/1380 [01:34<01:11,  8.73it/s] 55%|█████▍    | 757/1380 [01:34<01:10,  8.82it/s] 55%|█████▍    | 758/1380 [01:34<01:10,  8.78it/s] 55%|█████▌    | 759/1380 [01:34<01:10,  8.86it/s] 55%|█████▌    | 760/1380 [01:35<01:10,  8.82it/s] 55%|█████▌    | 761/1380 [01:35<01:09,  8.86it/s] 55%|█████▌    | 762/1380 [01:35<01:09,  8.92it/s] 55%|█████▌    | 763/1380 [01:35<01:09,  8.94it/s] 55%|█████▌    | 764/1380 [01:35<01:09,  8.92it/s] 55%|█████▌    | 765/1380 [01:35<01:09,  8.87it/s] 56%|█████▌    | 766/1380 [01:35<01:09,  8.86it/s] 56%|█████▌    | 767/1380 [01:35<01:08,  8.90it/s] 56%|█████▌    | 768/1380 [01:35<01:09,  8.82it/s] 56%|█████▌    | 769/1380 [01:36<01:08,  8.88it/s] 56%|█████▌    | 770/1380 [01:36<01:09,  8.81it/s] 56%|█████▌    | 771/1380 [01:36<01:08,  8.86it/s] 56%|█████▌    | 772/1380 [01:36<01:07,  8.94it/s] 56%|█████▌    | 773/1380 [01:36<01:08,  8.92it/s] 56%|█████▌    | 774/1380 [01:36<01:08,  8.83it/s] 56%|█████▌    | 775/1380 [01:36<01:08,  8.82it/s] 56%|█████▌    | 776/1380 [01:36<01:07,  8.91it/s] 56%|█████▋    | 777/1380 [01:36<01:07,  8.89it/s] 56%|█████▋    | 778/1380 [01:37<01:07,  8.87it/s] 56%|█████▋    | 779/1380 [01:37<01:07,  8.88it/s] 57%|█████▋    | 780/1380 [01:37<01:07,  8.89it/s] 57%|█████▋    | 781/1380 [01:37<01:07,  8.92it/s] 57%|█████▋    | 782/1380 [01:37<01:06,  8.96it/s] 57%|█████▋    | 783/1380 [01:37<01:06,  8.92it/s] 57%|█████▋    | 784/1380 [01:37<01:06,  8.91it/s] 57%|█████▋    | 785/1380 [01:37<01:06,  8.90it/s] 57%|█████▋    | 786/1380 [01:37<01:06,  8.94it/s] 57%|█████▋    | 787/1380 [01:38<01:07,  8.80it/s] 57%|█████▋    | 788/1380 [01:38<01:06,  8.86it/s] 57%|█████▋    | 789/1380 [01:38<01:07,  8.82it/s] 57%|█████▋    | 790/1380 [01:38<01:06,  8.87it/s] 57%|█████▋    | 791/1380 [01:38<01:06,  8.81it/s] 57%|█████▋    | 792/1380 [01:38<01:06,  8.87it/s] 57%|█████▋    | 793/1380 [01:38<01:06,  8.84it/s] 58%|█████▊    | 794/1380 [01:38<01:06,  8.88it/s] 58%|█████▊    | 795/1380 [01:38<01:05,  8.95it/s] 58%|█████▊    | 796/1380 [01:39<01:05,  8.88it/s] 58%|█████▊    | 797/1380 [01:39<01:06,  8.83it/s] 58%|█████▊    | 798/1380 [01:39<01:06,  8.80it/s] 58%|█████▊    | 799/1380 [01:39<01:05,  8.84it/s] 58%|█████▊    | 800/1380 [01:39<01:05,  8.86it/s] 58%|█████▊    | 801/1380 [01:39<01:05,  8.79it/s] 58%|█████▊    | 802/1380 [01:39<01:05,  8.81it/s] 58%|█████▊    | 803/1380 [01:39<01:05,  8.80it/s] 58%|█████▊    | 804/1380 [01:39<01:05,  8.82it/s] 58%|█████▊    | 805/1380 [01:40<01:04,  8.88it/s] 58%|█████▊    | 806/1380 [01:40<01:05,  8.81it/s] 58%|█████▊    | 807/1380 [01:40<01:05,  8.76it/s] 59%|█████▊    | 808/1380 [01:40<01:05,  8.72it/s] 59%|█████▊    | 809/1380 [01:40<01:04,  8.80it/s] 59%|█████▊    | 810/1380 [01:40<01:04,  8.84it/s] 59%|█████▉    | 811/1380 [01:40<01:04,  8.80it/s] 59%|█████▉    | 812/1380 [01:40<01:04,  8.85it/s] 59%|█████▉    | 813/1380 [01:41<01:04,  8.78it/s] 59%|█████▉    | 814/1380 [01:41<01:04,  8.79it/s] 59%|█████▉    | 815/1380 [01:41<01:03,  8.93it/s] 59%|█████▉    | 816/1380 [01:41<01:03,  8.89it/s] 59%|█████▉    | 817/1380 [01:41<01:03,  8.85it/s] 59%|█████▉    | 818/1380 [01:41<01:03,  8.85it/s] 59%|█████▉    | 819/1380 [01:41<01:02,  8.91it/s] 59%|█████▉    | 820/1380 [01:41<01:03,  8.86it/s] 59%|█████▉    | 821/1380 [01:41<01:02,  8.88it/s] 60%|█████▉    | 822/1380 [01:42<01:03,  8.84it/s] 60%|█████▉    | 823/1380 [01:42<01:02,  8.87it/s] 60%|█████▉    | 824/1380 [01:42<01:02,  8.87it/s] 60%|█████▉    | 825/1380 [01:42<01:01,  8.99it/s] 60%|█████▉    | 826/1380 [01:42<01:02,  8.89it/s] 60%|█████▉    | 827/1380 [01:42<01:01,  8.93it/s]                                                   60%|██████    | 828/1380 [01:42<01:01,  8.93it/s][INFO|trainer.py:755] 2023-11-15 19:34:48,925 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:34:48,927 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:34:48,927 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:34:48,928 >>   Batch size = 8
{'eval_loss': 0.3960191309452057, 'eval_accuracy': 0.8620689655172413, 'eval_micro_f1': 0.8620689655172413, 'eval_macro_f1': 0.8416952399347316, 'eval_runtime': 4.0771, 'eval_samples_per_second': 540.583, 'eval_steps_per_second': 67.695, 'epoch': 2.0}
{'loss': 0.2178, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 84.03it/s][A
  7%|▋         | 18/276 [00:00<00:03, 72.07it/s][A
  9%|▉         | 26/276 [00:00<00:03, 70.10it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 70.21it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 70.51it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 68.25it/s][A
 21%|██        | 57/276 [00:00<00:03, 68.58it/s][A
 23%|██▎       | 64/276 [00:00<00:03, 67.31it/s][A
 26%|██▌       | 71/276 [00:01<00:03, 67.97it/s][A
 28%|██▊       | 78/276 [00:01<00:02, 67.22it/s][A
 31%|███       | 86/276 [00:01<00:02, 68.64it/s][A
 34%|███▎      | 93/276 [00:01<00:02, 68.60it/s][A
 36%|███▌      | 100/276 [00:01<00:02, 66.94it/s][A
 39%|███▉      | 108/276 [00:01<00:02, 67.90it/s][A
 42%|████▏     | 115/276 [00:01<00:02, 67.51it/s][A
 44%|████▍     | 122/276 [00:01<00:02, 67.06it/s][A
 47%|████▋     | 129/276 [00:01<00:02, 67.18it/s][A
 49%|████▉     | 136/276 [00:01<00:02, 67.88it/s][A
 52%|█████▏    | 143/276 [00:02<00:01, 67.60it/s][A
 54%|█████▍    | 150/276 [00:02<00:01, 66.15it/s][A
 57%|█████▋    | 157/276 [00:02<00:01, 66.81it/s][A
 59%|█████▉    | 164/276 [00:02<00:01, 66.72it/s][A
 62%|██████▏   | 171/276 [00:02<00:01, 66.41it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 65.94it/s][A
 67%|██████▋   | 185/276 [00:02<00:01, 66.10it/s][A
 70%|██████▉   | 193/276 [00:02<00:01, 67.90it/s][A
 72%|███████▏  | 200/276 [00:02<00:01, 65.76it/s][A
 75%|███████▌  | 208/276 [00:03<00:01, 67.62it/s][A
 78%|███████▊  | 215/276 [00:03<00:00, 67.39it/s][A
 80%|████████  | 222/276 [00:03<00:00, 67.19it/s][A
 83%|████████▎ | 229/276 [00:03<00:00, 67.09it/s][A
 86%|████████▌ | 236/276 [00:03<00:00, 67.08it/s][A
 88%|████████▊ | 243/276 [00:03<00:00, 67.77it/s][A
 91%|█████████ | 250/276 [00:03<00:00, 67.30it/s][A
 93%|█████████▎| 257/276 [00:03<00:00, 67.43it/s][A
 96%|█████████▌| 264/276 [00:03<00:00, 65.83it/s][A
 98%|█████████▊| 271/276 [00:04<00:00, 65.93it/s][A                                                  
                                                 [A 60%|██████    | 828/1380 [01:46<01:01,  8.93it/s]
100%|██████████| 276/276 [00:04<00:00, 65.93it/s][A
                                                 [A 60%|██████    | 829/1380 [01:46<09:46,  1.07s/it] 60%|██████    | 830/1380 [01:47<07:36,  1.21it/s] 60%|██████    | 831/1380 [01:47<05:53,  1.56it/s] 60%|██████    | 832/1380 [01:47<04:33,  2.00it/s] 60%|██████    | 833/1380 [01:47<03:34,  2.55it/s] 60%|██████    | 834/1380 [01:47<02:50,  3.21it/s] 61%|██████    | 835/1380 [01:47<02:18,  3.95it/s] 61%|██████    | 836/1380 [01:47<01:55,  4.70it/s] 61%|██████    | 837/1380 [01:47<01:39,  5.43it/s] 61%|██████    | 838/1380 [01:47<01:28,  6.14it/s] 61%|██████    | 839/1380 [01:48<01:19,  6.77it/s] 61%|██████    | 840/1380 [01:48<01:14,  7.29it/s] 61%|██████    | 841/1380 [01:48<01:10,  7.62it/s] 61%|██████    | 842/1380 [01:48<01:07,  7.96it/s] 61%|██████    | 843/1380 [01:48<01:05,  8.20it/s] 61%|██████    | 844/1380 [01:48<01:04,  8.37it/s] 61%|██████    | 845/1380 [01:48<01:01,  8.63it/s] 61%|██████▏   | 846/1380 [01:48<01:01,  8.63it/s] 61%|██████▏   | 847/1380 [01:48<01:01,  8.72it/s] 61%|██████▏   | 848/1380 [01:49<01:00,  8.78it/s] 62%|██████▏   | 849/1380 [01:49<00:59,  8.86it/s] 62%|██████▏   | 850/1380 [01:49<01:00,  8.83it/s] 62%|██████▏   | 851/1380 [01:49<00:59,  8.84it/s] 62%|██████▏   | 852/1380 [01:49<00:59,  8.81it/s] 62%|██████▏   | 853/1380 [01:49<00:59,  8.87it/s] 62%|██████▏   | 854/1380 [01:49<00:59,  8.89it/s] 62%|██████▏   | 855/1380 [01:49<00:58,  8.91it/s] 62%|██████▏   | 856/1380 [01:49<00:58,  8.92it/s] 62%|██████▏   | 857/1380 [01:50<00:58,  8.88it/s] 62%|██████▏   | 858/1380 [01:50<00:58,  8.93it/s] 62%|██████▏   | 859/1380 [01:50<00:58,  8.94it/s] 62%|██████▏   | 860/1380 [01:50<00:58,  8.90it/s] 62%|██████▏   | 861/1380 [01:50<00:58,  8.85it/s] 62%|██████▏   | 862/1380 [01:50<00:58,  8.82it/s] 63%|██████▎   | 863/1380 [01:50<00:58,  8.84it/s] 63%|██████▎   | 864/1380 [01:50<00:58,  8.82it/s] 63%|██████▎   | 865/1380 [01:51<00:57,  8.90it/s] 63%|██████▎   | 866/1380 [01:51<00:58,  8.83it/s] 63%|██████▎   | 867/1380 [01:51<00:57,  8.90it/s] 63%|██████▎   | 868/1380 [01:51<00:56,  8.99it/s] 63%|██████▎   | 869/1380 [01:51<00:57,  8.96it/s] 63%|██████▎   | 870/1380 [01:51<00:57,  8.92it/s] 63%|██████▎   | 871/1380 [01:51<00:57,  8.90it/s] 63%|██████▎   | 872/1380 [01:51<00:57,  8.87it/s] 63%|██████▎   | 873/1380 [01:51<00:56,  8.90it/s] 63%|██████▎   | 874/1380 [01:52<00:57,  8.82it/s] 63%|██████▎   | 875/1380 [01:52<00:56,  8.87it/s] 63%|██████▎   | 876/1380 [01:52<00:57,  8.83it/s] 64%|██████▎   | 877/1380 [01:52<00:56,  8.82it/s] 64%|██████▎   | 878/1380 [01:52<00:56,  8.96it/s] 64%|██████▎   | 879/1380 [01:52<00:56,  8.91it/s] 64%|██████▍   | 880/1380 [01:52<00:56,  8.79it/s] 64%|██████▍   | 881/1380 [01:52<00:56,  8.83it/s] 64%|██████▍   | 882/1380 [01:52<00:55,  8.91it/s] 64%|██████▍   | 883/1380 [01:53<00:55,  8.93it/s] 64%|██████▍   | 884/1380 [01:53<00:56,  8.84it/s] 64%|██████▍   | 885/1380 [01:53<00:55,  8.90it/s] 64%|██████▍   | 886/1380 [01:53<00:55,  8.87it/s] 64%|██████▍   | 887/1380 [01:53<00:55,  8.89it/s] 64%|██████▍   | 888/1380 [01:53<00:55,  8.94it/s] 64%|██████▍   | 889/1380 [01:53<00:55,  8.90it/s] 64%|██████▍   | 890/1380 [01:53<00:55,  8.86it/s] 65%|██████▍   | 891/1380 [01:53<00:55,  8.86it/s] 65%|██████▍   | 892/1380 [01:54<00:55,  8.86it/s] 65%|██████▍   | 893/1380 [01:54<00:54,  8.87it/s] 65%|██████▍   | 894/1380 [01:54<00:55,  8.82it/s] 65%|██████▍   | 895/1380 [01:54<00:54,  8.85it/s] 65%|██████▍   | 896/1380 [01:54<00:54,  8.88it/s] 65%|██████▌   | 897/1380 [01:54<00:53,  8.95it/s] 65%|██████▌   | 898/1380 [01:54<00:53,  9.01it/s] 65%|██████▌   | 899/1380 [01:54<00:53,  8.94it/s] 65%|██████▌   | 900/1380 [01:54<00:54,  8.88it/s] 65%|██████▌   | 901/1380 [01:55<00:53,  8.89it/s] 65%|██████▌   | 902/1380 [01:55<00:53,  8.93it/s] 65%|██████▌   | 903/1380 [01:55<00:53,  8.89it/s] 66%|██████▌   | 904/1380 [01:55<00:53,  8.87it/s] 66%|██████▌   | 905/1380 [01:55<00:53,  8.87it/s] 66%|██████▌   | 906/1380 [01:55<00:53,  8.87it/s] 66%|██████▌   | 907/1380 [01:55<00:52,  8.95it/s] 66%|██████▌   | 908/1380 [01:55<00:52,  9.01it/s] 66%|██████▌   | 909/1380 [01:55<00:52,  8.91it/s] 66%|██████▌   | 910/1380 [01:56<00:52,  8.87it/s] 66%|██████▌   | 911/1380 [01:56<00:52,  8.86it/s] 66%|██████▌   | 912/1380 [01:56<00:52,  8.86it/s] 66%|██████▌   | 913/1380 [01:56<00:52,  8.86it/s] 66%|██████▌   | 914/1380 [01:56<00:52,  8.82it/s] 66%|██████▋   | 915/1380 [01:56<00:52,  8.78it/s] 66%|██████▋   | 916/1380 [01:56<00:52,  8.86it/s] 66%|██████▋   | 917/1380 [01:56<00:52,  8.84it/s] 67%|██████▋   | 918/1380 [01:56<00:51,  8.95it/s] 67%|██████▋   | 919/1380 [01:57<00:51,  8.95it/s] 67%|██████▋   | 920/1380 [01:57<00:51,  8.95it/s] 67%|██████▋   | 921/1380 [01:57<00:51,  8.93it/s] 67%|██████▋   | 922/1380 [01:57<00:50,  9.02it/s] 67%|██████▋   | 923/1380 [01:57<00:51,  8.93it/s] 67%|██████▋   | 924/1380 [01:57<00:51,  8.91it/s] 67%|██████▋   | 925/1380 [01:57<00:51,  8.85it/s] 67%|██████▋   | 926/1380 [01:57<00:51,  8.85it/s] 67%|██████▋   | 927/1380 [01:57<00:51,  8.80it/s] 67%|██████▋   | 928/1380 [01:58<00:50,  8.88it/s] 67%|██████▋   | 929/1380 [01:58<00:50,  8.88it/s] 67%|██████▋   | 930/1380 [01:58<00:50,  8.91it/s] 67%|██████▋   | 931/1380 [01:58<00:49,  9.02it/s] 68%|██████▊   | 932/1380 [01:58<00:50,  8.94it/s] 68%|██████▊   | 933/1380 [01:58<00:50,  8.92it/s] 68%|██████▊   | 934/1380 [01:58<00:50,  8.91it/s] 68%|██████▊   | 935/1380 [01:58<00:50,  8.89it/s] 68%|██████▊   | 936/1380 [01:58<00:49,  8.89it/s] 68%|██████▊   | 937/1380 [01:59<00:50,  8.85it/s] 68%|██████▊   | 938/1380 [01:59<00:49,  8.92it/s] 68%|██████▊   | 939/1380 [01:59<00:49,  8.89it/s] 68%|██████▊   | 940/1380 [01:59<00:49,  8.90it/s] 68%|██████▊   | 941/1380 [01:59<00:48,  8.99it/s] 68%|██████▊   | 942/1380 [01:59<00:49,  8.90it/s] 68%|██████▊   | 943/1380 [01:59<00:49,  8.87it/s] 68%|██████▊   | 944/1380 [01:59<00:49,  8.88it/s] 68%|██████▊   | 945/1380 [02:00<00:48,  8.91it/s] 69%|██████▊   | 946/1380 [02:00<00:48,  8.86it/s] 69%|██████▊   | 947/1380 [02:00<00:48,  8.84it/s] 69%|██████▊   | 948/1380 [02:00<00:48,  8.84it/s] 69%|██████▉   | 949/1380 [02:00<00:48,  8.90it/s] 69%|██████▉   | 950/1380 [02:00<00:48,  8.91it/s] 69%|██████▉   | 951/1380 [02:00<00:47,  9.02it/s] 69%|██████▉   | 952/1380 [02:00<00:48,  8.83it/s] 69%|██████▉   | 953/1380 [02:00<00:48,  8.81it/s] 69%|██████▉   | 954/1380 [02:01<00:48,  8.81it/s] 69%|██████▉   | 955/1380 [02:01<00:47,  8.90it/s] 69%|██████▉   | 956/1380 [02:01<00:47,  8.87it/s] 69%|██████▉   | 957/1380 [02:01<00:47,  8.85it/s] 69%|██████▉   | 958/1380 [02:01<00:47,  8.85it/s] 69%|██████▉   | 959/1380 [02:01<00:47,  8.90it/s] 70%|██████▉   | 960/1380 [02:01<00:47,  8.88it/s] 70%|██████▉   | 961/1380 [02:01<00:47,  8.88it/s] 70%|██████▉   | 962/1380 [02:01<00:47,  8.87it/s] 70%|██████▉   | 963/1380 [02:02<00:46,  8.92it/s] 70%|██████▉   | 964/1380 [02:02<00:46,  8.95it/s] 70%|██████▉   | 965/1380 [02:02<00:46,  8.90it/s] 70%|███████   | 966/1380 [02:02<00:47,  8.79it/s] 70%|███████   | 967/1380 [02:02<00:46,  8.81it/s] 70%|███████   | 968/1380 [02:02<00:46,  8.80it/s] 70%|███████   | 969/1380 [02:02<00:46,  8.86it/s] 70%|███████   | 970/1380 [02:02<00:46,  8.81it/s] 70%|███████   | 971/1380 [02:02<00:46,  8.84it/s] 70%|███████   | 972/1380 [02:03<00:46,  8.85it/s] 71%|███████   | 973/1380 [02:03<00:46,  8.84it/s] 71%|███████   | 974/1380 [02:03<00:45,  8.96it/s] 71%|███████   | 975/1380 [02:03<00:45,  8.89it/s] 71%|███████   | 976/1380 [02:03<00:45,  8.91it/s] 71%|███████   | 977/1380 [02:03<00:45,  8.93it/s] 71%|███████   | 978/1380 [02:03<00:45,  8.93it/s] 71%|███████   | 979/1380 [02:03<00:44,  8.98it/s] 71%|███████   | 980/1380 [02:03<00:45,  8.89it/s] 71%|███████   | 981/1380 [02:04<00:44,  8.89it/s] 71%|███████   | 982/1380 [02:04<00:44,  8.86it/s] 71%|███████   | 983/1380 [02:04<00:44,  8.84it/s] 71%|███████▏  | 984/1380 [02:04<00:44,  8.93it/s] 71%|███████▏  | 985/1380 [02:04<00:44,  8.85it/s] 71%|███████▏  | 986/1380 [02:04<00:44,  8.84it/s] 72%|███████▏  | 987/1380 [02:04<00:44,  8.79it/s] 72%|███████▏  | 988/1380 [02:04<00:44,  8.86it/s] 72%|███████▏  | 989/1380 [02:04<00:44,  8.84it/s] 72%|███████▏  | 990/1380 [02:05<00:44,  8.84it/s] 72%|███████▏  | 991/1380 [02:05<00:43,  8.92it/s] 72%|███████▏  | 992/1380 [02:05<00:43,  8.83it/s] 72%|███████▏  | 993/1380 [02:05<00:43,  8.91it/s] 72%|███████▏  | 994/1380 [02:05<00:42,  9.03it/s] 72%|███████▏  | 995/1380 [02:05<00:42,  8.96it/s] 72%|███████▏  | 996/1380 [02:05<00:43,  8.92it/s] 72%|███████▏  | 997/1380 [02:05<00:43,  8.89it/s] 72%|███████▏  | 998/1380 [02:05<00:42,  8.95it/s] 72%|███████▏  | 999/1380 [02:06<00:42,  8.91it/s] 72%|███████▏  | 1000/1380 [02:06<00:42,  8.87it/s] 73%|███████▎  | 1001/1380 [02:06<00:42,  8.82it/s] 73%|███████▎  | 1002/1380 [02:06<00:42,  8.82it/s] 73%|███████▎  | 1003/1380 [02:06<00:42,  8.88it/s] 73%|███████▎  | 1004/1380 [02:06<00:41,  9.02it/s] 73%|███████▎  | 1005/1380 [02:06<00:42,  8.91it/s] 73%|███████▎  | 1006/1380 [02:06<00:42,  8.88it/s] 73%|███████▎  | 1007/1380 [02:06<00:41,  8.90it/s] 73%|███████▎  | 1008/1380 [02:07<00:42,  8.85it/s] 73%|███████▎  | 1009/1380 [02:07<00:42,  8.75it/s] 73%|███████▎  | 1010/1380 [02:07<00:42,  8.78it/s] 73%|███████▎  | 1011/1380 [02:07<00:41,  8.80it/s] 73%|███████▎  | 1012/1380 [02:07<00:41,  8.82it/s] 73%|███████▎  | 1013/1380 [02:07<00:41,  8.81it/s] 73%|███████▎  | 1014/1380 [02:07<00:41,  8.91it/s] 74%|███████▎  | 1015/1380 [02:07<00:41,  8.88it/s] 74%|███████▎  | 1016/1380 [02:08<00:40,  8.88it/s] 74%|███████▎  | 1017/1380 [02:08<00:40,  8.89it/s] 74%|███████▍  | 1018/1380 [02:08<00:40,  8.94it/s] 74%|███████▍  | 1019/1380 [02:08<00:40,  8.83it/s] 74%|███████▍  | 1020/1380 [02:08<00:40,  8.80it/s] 74%|███████▍  | 1021/1380 [02:08<00:40,  8.77it/s] 74%|███████▍  | 1022/1380 [02:08<00:40,  8.83it/s] 74%|███████▍  | 1023/1380 [02:08<00:40,  8.86it/s] 74%|███████▍  | 1024/1380 [02:08<00:39,  8.94it/s] 74%|███████▍  | 1025/1380 [02:09<00:39,  8.88it/s] 74%|███████▍  | 1026/1380 [02:09<00:39,  8.92it/s] 74%|███████▍  | 1027/1380 [02:09<00:39,  8.92it/s] 74%|███████▍  | 1028/1380 [02:09<00:39,  8.88it/s] 75%|███████▍  | 1029/1380 [02:09<00:39,  8.87it/s] 75%|███████▍  | 1030/1380 [02:09<00:39,  8.80it/s] 75%|███████▍  | 1031/1380 [02:09<00:39,  8.75it/s] 75%|███████▍  | 1032/1380 [02:09<00:39,  8.86it/s] 75%|███████▍  | 1033/1380 [02:09<00:39,  8.84it/s] 75%|███████▍  | 1034/1380 [02:10<00:38,  8.88it/s] 75%|███████▌  | 1035/1380 [02:10<00:39,  8.84it/s] 75%|███████▌  | 1036/1380 [02:10<00:38,  8.86it/s] 75%|███████▌  | 1037/1380 [02:10<00:38,  8.94it/s] 75%|███████▌  | 1038/1380 [02:10<00:38,  8.95it/s] 75%|███████▌  | 1039/1380 [02:10<00:38,  8.89it/s] 75%|███████▌  | 1040/1380 [02:10<00:38,  8.90it/s] 75%|███████▌  | 1041/1380 [02:10<00:38,  8.83it/s] 76%|███████▌  | 1042/1380 [02:10<00:37,  8.92it/s] 76%|███████▌  | 1043/1380 [02:11<00:38,  8.85it/s] 76%|███████▌  | 1044/1380 [02:11<00:37,  8.96it/s] 76%|███████▌  | 1045/1380 [02:11<00:37,  8.99it/s] 76%|███████▌  | 1046/1380 [02:11<00:37,  8.99it/s] 76%|███████▌  | 1047/1380 [02:11<00:37,  9.00it/s] 76%|███████▌  | 1048/1380 [02:11<00:36,  8.97it/s] 76%|███████▌  | 1049/1380 [02:11<00:37,  8.91it/s] 76%|███████▌  | 1050/1380 [02:11<00:37,  8.88it/s] 76%|███████▌  | 1051/1380 [02:11<00:37,  8.87it/s] 76%|███████▌  | 1052/1380 [02:12<00:36,  8.89it/s] 76%|███████▋  | 1053/1380 [02:12<00:36,  8.86it/s] 76%|███████▋  | 1054/1380 [02:12<00:36,  8.97it/s] 76%|███████▋  | 1055/1380 [02:12<00:36,  8.90it/s] 77%|███████▋  | 1056/1380 [02:12<00:36,  8.92it/s] 77%|███████▋  | 1057/1380 [02:12<00:36,  8.93it/s] 77%|███████▋  | 1058/1380 [02:12<00:35,  8.98it/s] 77%|███████▋  | 1059/1380 [02:12<00:36,  8.85it/s] 77%|███████▋  | 1060/1380 [02:12<00:36,  8.78it/s] 77%|███████▋  | 1061/1380 [02:13<00:36,  8.82it/s] 77%|███████▋  | 1062/1380 [02:13<00:35,  8.87it/s] 77%|███████▋  | 1063/1380 [02:13<00:35,  8.90it/s] 77%|███████▋  | 1064/1380 [02:13<00:35,  9.01it/s] 77%|███████▋  | 1065/1380 [02:13<00:35,  8.92it/s] 77%|███████▋  | 1066/1380 [02:13<00:35,  8.89it/s] 77%|███████▋  | 1067/1380 [02:13<00:35,  8.89it/s] 77%|███████▋  | 1068/1380 [02:13<00:34,  8.92it/s] 77%|███████▋  | 1069/1380 [02:13<00:35,  8.85it/s] 78%|███████▊  | 1070/1380 [02:14<00:35,  8.83it/s] 78%|███████▊  | 1071/1380 [02:14<00:34,  8.89it/s] 78%|███████▊  | 1072/1380 [02:14<00:34,  8.85it/s] 78%|███████▊  | 1073/1380 [02:14<00:34,  8.83it/s] 78%|███████▊  | 1074/1380 [02:14<00:34,  8.87it/s] 78%|███████▊  | 1075/1380 [02:14<00:34,  8.80it/s] 78%|███████▊  | 1076/1380 [02:14<00:34,  8.77it/s] 78%|███████▊  | 1077/1380 [02:14<00:34,  8.83it/s] 78%|███████▊  | 1078/1380 [02:14<00:33,  8.88it/s] 78%|███████▊  | 1079/1380 [02:15<00:34,  8.80it/s] 78%|███████▊  | 1080/1380 [02:15<00:34,  8.73it/s] 78%|███████▊  | 1081/1380 [02:15<00:33,  8.81it/s] 78%|███████▊  | 1082/1380 [02:15<00:33,  8.80it/s] 78%|███████▊  | 1083/1380 [02:15<00:33,  8.84it/s] 79%|███████▊  | 1084/1380 [02:15<00:32,  8.98it/s] 79%|███████▊  | 1085/1380 [02:15<00:33,  8.91it/s] 79%|███████▊  | 1086/1380 [02:15<00:33,  8.87it/s] 79%|███████▉  | 1087/1380 [02:16<00:33,  8.83it/s] 79%|███████▉  | 1088/1380 [02:16<00:32,  8.88it/s] 79%|███████▉  | 1089/1380 [02:16<00:33,  8.81it/s] 79%|███████▉  | 1090/1380 [02:16<00:32,  8.83it/s] 79%|███████▉  | 1091/1380 [02:16<00:32,  8.83it/s] 79%|███████▉  | 1092/1380 [02:16<00:32,  8.90it/s] 79%|███████▉  | 1093/1380 [02:16<00:32,  8.89it/s] 79%|███████▉  | 1094/1380 [02:16<00:31,  9.01it/s] 79%|███████▉  | 1095/1380 [02:16<00:32,  8.89it/s] 79%|███████▉  | 1096/1380 [02:17<00:31,  8.88it/s] 79%|███████▉  | 1097/1380 [02:17<00:32,  8.83it/s] 80%|███████▉  | 1098/1380 [02:17<00:31,  8.86it/s] 80%|███████▉  | 1099/1380 [02:17<00:31,  8.87it/s] 80%|███████▉  | 1100/1380 [02:17<00:32,  8.74it/s] 80%|███████▉  | 1101/1380 [02:17<00:31,  8.93it/s] 80%|███████▉  | 1102/1380 [02:17<00:31,  8.88it/s] 80%|███████▉  | 1103/1380 [02:17<00:31,  8.89it/s]                                                    80%|████████  | 1104/1380 [02:17<00:31,  8.89it/s][INFO|trainer.py:755] 2023-11-15 19:35:24,144 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:35:24,146 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:35:24,146 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:35:24,147 >>   Batch size = 8
{'eval_loss': 0.4492742121219635, 'eval_accuracy': 0.8638838475499092, 'eval_micro_f1': 0.8638838475499093, 'eval_macro_f1': 0.8440038137923834, 'eval_runtime': 4.153, 'eval_samples_per_second': 530.699, 'eval_steps_per_second': 66.458, 'epoch': 3.0}
{'loss': 0.1417, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 8/276 [00:00<00:03, 79.34it/s][A
  6%|▌         | 16/276 [00:00<00:03, 69.75it/s][A
  9%|▊         | 24/276 [00:00<00:03, 68.78it/s][A
 12%|█▏        | 32/276 [00:00<00:03, 68.52it/s][A
 14%|█▍        | 40/276 [00:00<00:03, 69.79it/s][A
 17%|█▋        | 48/276 [00:00<00:03, 67.63it/s][A
 20%|██        | 56/276 [00:00<00:03, 68.54it/s][A
 23%|██▎       | 63/276 [00:00<00:03, 68.75it/s][A
 25%|██▌       | 70/276 [00:01<00:03, 68.12it/s][A
 28%|██▊       | 77/276 [00:01<00:02, 68.65it/s][A
 30%|███       | 84/276 [00:01<00:02, 67.07it/s][A
 33%|███▎      | 92/276 [00:01<00:02, 68.76it/s][A
 36%|███▌      | 99/276 [00:01<00:02, 68.74it/s][A
 39%|███▉      | 107/276 [00:01<00:02, 70.30it/s][A
 42%|████▏     | 115/276 [00:01<00:02, 67.49it/s][A
 44%|████▍     | 122/276 [00:01<00:02, 66.58it/s][A
 47%|████▋     | 129/276 [00:01<00:02, 66.61it/s][A
 49%|████▉     | 136/276 [00:01<00:02, 66.40it/s][A
 52%|█████▏    | 143/276 [00:02<00:01, 66.70it/s][A
 54%|█████▍    | 150/276 [00:02<00:01, 66.96it/s][A
 57%|█████▋    | 157/276 [00:02<00:01, 67.66it/s][A
 59%|█████▉    | 164/276 [00:02<00:01, 67.46it/s][A
 62%|██████▏   | 171/276 [00:02<00:01, 64.66it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 64.66it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 66.44it/s][A
 70%|██████▉   | 193/276 [00:02<00:01, 66.43it/s][A
 72%|███████▏  | 200/276 [00:02<00:01, 67.18it/s][A
 75%|███████▌  | 207/276 [00:03<00:01, 66.67it/s][A
 78%|███████▊  | 214/276 [00:03<00:00, 67.49it/s][A
 80%|████████  | 221/276 [00:03<00:00, 67.30it/s][A
 83%|████████▎ | 228/276 [00:03<00:00, 66.31it/s][A
 86%|████████▌ | 236/276 [00:03<00:00, 66.85it/s][A
 88%|████████▊ | 243/276 [00:03<00:00, 65.63it/s][A
 91%|█████████ | 250/276 [00:03<00:00, 65.25it/s][A
 93%|█████████▎| 257/276 [00:03<00:00, 66.00it/s][A
 96%|█████████▌| 264/276 [00:03<00:00, 66.10it/s][A
 98%|█████████▊| 271/276 [00:04<00:00, 66.58it/s][A                                                   
                                                 [A 80%|████████  | 1104/1380 [02:22<00:31,  8.89it/s]
100%|██████████| 276/276 [00:04<00:00, 66.58it/s][A
                                                 [A 80%|████████  | 1105/1380 [02:22<04:53,  1.07s/it] 80%|████████  | 1106/1380 [02:22<03:48,  1.20it/s] 80%|████████  | 1107/1380 [02:22<02:56,  1.55it/s] 80%|████████  | 1108/1380 [02:22<02:16,  1.99it/s] 80%|████████  | 1109/1380 [02:22<01:46,  2.55it/s] 80%|████████  | 1110/1380 [02:22<01:24,  3.19it/s] 81%|████████  | 1111/1380 [02:22<01:09,  3.89it/s] 81%|████████  | 1112/1380 [02:22<00:57,  4.66it/s] 81%|████████  | 1113/1380 [02:23<00:49,  5.36it/s] 81%|████████  | 1114/1380 [02:23<00:43,  6.06it/s] 81%|████████  | 1115/1380 [02:23<00:39,  6.73it/s] 81%|████████  | 1116/1380 [02:23<00:36,  7.16it/s] 81%|████████  | 1117/1380 [02:23<00:34,  7.57it/s] 81%|████████  | 1118/1380 [02:23<00:33,  7.91it/s] 81%|████████  | 1119/1380 [02:23<00:32,  8.10it/s] 81%|████████  | 1120/1380 [02:23<00:31,  8.30it/s] 81%|████████  | 1121/1380 [02:24<00:30,  8.37it/s] 81%|████████▏ | 1122/1380 [02:24<00:30,  8.45it/s] 81%|████████▏ | 1123/1380 [02:24<00:30,  8.53it/s] 81%|████████▏ | 1124/1380 [02:24<00:29,  8.58it/s] 82%|████████▏ | 1125/1380 [02:24<00:29,  8.66it/s] 82%|████████▏ | 1126/1380 [02:24<00:29,  8.67it/s] 82%|████████▏ | 1127/1380 [02:24<00:29,  8.63it/s] 82%|████████▏ | 1128/1380 [02:24<00:29,  8.66it/s] 82%|████████▏ | 1129/1380 [02:24<00:28,  8.70it/s] 82%|████████▏ | 1130/1380 [02:25<00:28,  8.77it/s] 82%|████████▏ | 1131/1380 [02:25<00:28,  8.81it/s] 82%|████████▏ | 1132/1380 [02:25<00:27,  8.93it/s] 82%|████████▏ | 1133/1380 [02:25<00:27,  8.83it/s] 82%|████████▏ | 1134/1380 [02:25<00:27,  8.80it/s] 82%|████████▏ | 1135/1380 [02:25<00:28,  8.72it/s] 82%|████████▏ | 1136/1380 [02:25<00:27,  8.78it/s] 82%|████████▏ | 1137/1380 [02:25<00:27,  8.82it/s] 82%|████████▏ | 1138/1380 [02:25<00:27,  8.74it/s] 83%|████████▎ | 1139/1380 [02:26<00:27,  8.75it/s] 83%|████████▎ | 1140/1380 [02:26<00:27,  8.74it/s] 83%|████████▎ | 1141/1380 [02:26<00:27,  8.71it/s] 83%|████████▎ | 1142/1380 [02:26<00:26,  8.85it/s] 83%|████████▎ | 1143/1380 [02:26<00:26,  8.78it/s] 83%|████████▎ | 1144/1380 [02:26<00:26,  8.74it/s] 83%|████████▎ | 1145/1380 [02:26<00:27,  8.69it/s] 83%|████████▎ | 1146/1380 [02:26<00:26,  8.68it/s] 83%|████████▎ | 1147/1380 [02:26<00:26,  8.74it/s] 83%|████████▎ | 1148/1380 [02:27<00:26,  8.68it/s] 83%|████████▎ | 1149/1380 [02:27<00:26,  8.69it/s] 83%|████████▎ | 1150/1380 [02:27<00:26,  8.74it/s] 83%|████████▎ | 1151/1380 [02:27<00:26,  8.72it/s] 83%|████████▎ | 1152/1380 [02:27<00:25,  8.80it/s] 84%|████████▎ | 1153/1380 [02:27<00:25,  8.82it/s] 84%|████████▎ | 1154/1380 [02:27<00:25,  8.79it/s] 84%|████████▎ | 1155/1380 [02:27<00:25,  8.69it/s] 84%|████████▍ | 1156/1380 [02:28<00:25,  8.70it/s] 84%|████████▍ | 1157/1380 [02:28<00:25,  8.75it/s] 84%|████████▍ | 1158/1380 [02:28<00:25,  8.71it/s] 84%|████████▍ | 1159/1380 [02:28<00:25,  8.79it/s] 84%|████████▍ | 1160/1380 [02:28<00:25,  8.74it/s] 84%|████████▍ | 1161/1380 [02:28<00:25,  8.71it/s] 84%|████████▍ | 1162/1380 [02:28<00:25,  8.71it/s] 84%|████████▍ | 1163/1380 [02:28<00:25,  8.60it/s] 84%|████████▍ | 1164/1380 [02:28<00:25,  8.64it/s] 84%|████████▍ | 1165/1380 [02:29<00:24,  8.69it/s] 84%|████████▍ | 1166/1380 [02:29<00:24,  8.66it/s] 85%|████████▍ | 1167/1380 [02:29<00:24,  8.68it/s] 85%|████████▍ | 1168/1380 [02:29<00:24,  8.74it/s] 85%|████████▍ | 1169/1380 [02:29<00:23,  8.80it/s] 85%|████████▍ | 1170/1380 [02:29<00:24,  8.75it/s] 85%|████████▍ | 1171/1380 [02:29<00:23,  8.75it/s] 85%|████████▍ | 1172/1380 [02:29<00:23,  8.74it/s] 85%|████████▌ | 1173/1380 [02:29<00:23,  8.80it/s] 85%|████████▌ | 1174/1380 [02:30<00:23,  8.75it/s] 85%|████████▌ | 1175/1380 [02:30<00:23,  8.70it/s] 85%|████████▌ | 1176/1380 [02:30<00:23,  8.77it/s] 85%|████████▌ | 1177/1380 [02:30<00:23,  8.78it/s] 85%|████████▌ | 1178/1380 [02:30<00:22,  8.79it/s] 85%|████████▌ | 1179/1380 [02:30<00:22,  8.91it/s] 86%|████████▌ | 1180/1380 [02:30<00:22,  8.75it/s] 86%|████████▌ | 1181/1380 [02:30<00:22,  8.75it/s] 86%|████████▌ | 1182/1380 [02:31<00:22,  8.68it/s] 86%|████████▌ | 1183/1380 [02:31<00:22,  8.69it/s] 86%|████████▌ | 1184/1380 [02:31<00:22,  8.78it/s] 86%|████████▌ | 1185/1380 [02:31<00:22,  8.61it/s] 86%|████████▌ | 1186/1380 [02:31<00:22,  8.69it/s] 86%|████████▌ | 1187/1380 [02:31<00:22,  8.65it/s] 86%|████████▌ | 1188/1380 [02:31<00:21,  8.73it/s] 86%|████████▌ | 1189/1380 [02:31<00:21,  8.84it/s] 86%|████████▌ | 1190/1380 [02:31<00:21,  8.75it/s] 86%|████████▋ | 1191/1380 [02:32<00:21,  8.74it/s] 86%|████████▋ | 1192/1380 [02:32<00:21,  8.73it/s] 86%|████████▋ | 1193/1380 [02:32<00:21,  8.75it/s] 87%|████████▋ | 1194/1380 [02:32<00:21,  8.76it/s] 87%|████████▋ | 1195/1380 [02:32<00:21,  8.77it/s] 87%|████████▋ | 1196/1380 [02:32<00:20,  8.90it/s] 87%|████████▋ | 1197/1380 [02:32<00:20,  8.84it/s] 87%|████████▋ | 1198/1380 [02:32<00:20,  8.78it/s] 87%|████████▋ | 1199/1380 [02:32<00:20,  8.88it/s] 87%|████████▋ | 1200/1380 [02:33<00:20,  8.87it/s] 87%|████████▋ | 1201/1380 [02:33<00:20,  8.76it/s] 87%|████████▋ | 1202/1380 [02:33<00:20,  8.75it/s] 87%|████████▋ | 1203/1380 [02:33<00:20,  8.76it/s] 87%|████████▋ | 1204/1380 [02:33<00:19,  8.81it/s] 87%|████████▋ | 1205/1380 [02:33<00:20,  8.70it/s] 87%|████████▋ | 1206/1380 [02:33<00:19,  8.74it/s] 87%|████████▋ | 1207/1380 [02:33<00:19,  8.70it/s] 88%|████████▊ | 1208/1380 [02:33<00:19,  8.73it/s] 88%|████████▊ | 1209/1380 [02:34<00:19,  8.81it/s] 88%|████████▊ | 1210/1380 [02:34<00:19,  8.83it/s] 88%|████████▊ | 1211/1380 [02:34<00:19,  8.71it/s] 88%|████████▊ | 1212/1380 [02:34<00:19,  8.76it/s] 88%|████████▊ | 1213/1380 [02:34<00:19,  8.77it/s] 88%|████████▊ | 1214/1380 [02:34<00:18,  8.80it/s] 88%|████████▊ | 1215/1380 [02:34<00:18,  8.69it/s] 88%|████████▊ | 1216/1380 [02:34<00:18,  8.75it/s] 88%|████████▊ | 1217/1380 [02:34<00:18,  8.75it/s] 88%|████████▊ | 1218/1380 [02:35<00:18,  8.63it/s] 88%|████████▊ | 1219/1380 [02:35<00:18,  8.79it/s] 88%|████████▊ | 1220/1380 [02:35<00:18,  8.72it/s] 88%|████████▊ | 1221/1380 [02:35<00:18,  8.66it/s] 89%|████████▊ | 1222/1380 [02:35<00:18,  8.73it/s] 89%|████████▊ | 1223/1380 [02:35<00:17,  8.80it/s] 89%|████████▊ | 1224/1380 [02:35<00:17,  8.79it/s] 89%|████████▉ | 1225/1380 [02:35<00:17,  8.78it/s] 89%|████████▉ | 1226/1380 [02:36<00:17,  8.83it/s] 89%|████████▉ | 1227/1380 [02:36<00:17,  8.78it/s] 89%|████████▉ | 1228/1380 [02:36<00:17,  8.79it/s] 89%|████████▉ | 1229/1380 [02:36<00:17,  8.87it/s] 89%|████████▉ | 1230/1380 [02:36<00:16,  8.88it/s] 89%|████████▉ | 1231/1380 [02:36<00:16,  8.81it/s] 89%|████████▉ | 1232/1380 [02:36<00:16,  8.78it/s] 89%|████████▉ | 1233/1380 [02:36<00:16,  8.85it/s] 89%|████████▉ | 1234/1380 [02:36<00:16,  8.85it/s] 89%|████████▉ | 1235/1380 [02:37<00:16,  8.78it/s] 90%|████████▉ | 1236/1380 [02:37<00:16,  8.85it/s] 90%|████████▉ | 1237/1380 [02:37<00:16,  8.82it/s] 90%|████████▉ | 1238/1380 [02:37<00:16,  8.81it/s] 90%|████████▉ | 1239/1380 [02:37<00:15,  8.91it/s] 90%|████████▉ | 1240/1380 [02:37<00:15,  8.87it/s] 90%|████████▉ | 1241/1380 [02:37<00:15,  8.82it/s] 90%|█████████ | 1242/1380 [02:37<00:15,  8.83it/s] 90%|█████████ | 1243/1380 [02:37<00:15,  8.85it/s] 90%|█████████ | 1244/1380 [02:38<00:15,  8.87it/s] 90%|█████████ | 1245/1380 [02:38<00:15,  8.79it/s] 90%|█████████ | 1246/1380 [02:38<00:15,  8.85it/s] 90%|█████████ | 1247/1380 [02:38<00:15,  8.78it/s] 90%|█████████ | 1248/1380 [02:38<00:15,  8.79it/s] 91%|█████████ | 1249/1380 [02:38<00:14,  8.97it/s] 91%|█████████ | 1250/1380 [02:38<00:14,  8.85it/s] 91%|█████████ | 1251/1380 [02:38<00:14,  8.78it/s] 91%|█████████ | 1252/1380 [02:38<00:14,  8.78it/s] 91%|█████████ | 1253/1380 [02:39<00:14,  8.83it/s] 91%|█████████ | 1254/1380 [02:39<00:14,  8.78it/s] 91%|█████████ | 1255/1380 [02:39<00:14,  8.77it/s] 91%|█████████ | 1256/1380 [02:39<00:14,  8.86it/s] 91%|█████████ | 1257/1380 [02:39<00:13,  8.81it/s] 91%|█████████ | 1258/1380 [02:39<00:13,  8.84it/s] 91%|█████████ | 1259/1380 [02:39<00:13,  8.97it/s] 91%|█████████▏| 1260/1380 [02:39<00:13,  8.86it/s] 91%|█████████▏| 1261/1380 [02:39<00:13,  8.83it/s] 91%|█████████▏| 1262/1380 [02:40<00:13,  8.81it/s] 92%|█████████▏| 1263/1380 [02:40<00:13,  8.88it/s] 92%|█████████▏| 1264/1380 [02:40<00:13,  8.81it/s] 92%|█████████▏| 1265/1380 [02:40<00:13,  8.79it/s] 92%|█████████▏| 1266/1380 [02:40<00:12,  8.84it/s] 92%|█████████▏| 1267/1380 [02:40<00:12,  8.78it/s] 92%|█████████▏| 1268/1380 [02:40<00:12,  8.80it/s] 92%|█████████▏| 1269/1380 [02:40<00:12,  8.90it/s] 92%|█████████▏| 1270/1380 [02:41<00:12,  8.75it/s] 92%|█████████▏| 1271/1380 [02:41<00:12,  8.78it/s] 92%|█████████▏| 1272/1380 [02:41<00:12,  8.79it/s] 92%|█████████▏| 1273/1380 [02:41<00:12,  8.85it/s] 92%|█████████▏| 1274/1380 [02:41<00:12,  8.73it/s] 92%|█████████▏| 1275/1380 [02:41<00:12,  8.68it/s] 92%|█████████▏| 1276/1380 [02:41<00:11,  8.75it/s] 93%|█████████▎| 1277/1380 [02:41<00:11,  8.78it/s] 93%|█████████▎| 1278/1380 [02:41<00:11,  8.81it/s] 93%|█████████▎| 1279/1380 [02:42<00:11,  8.90it/s] 93%|█████████▎| 1280/1380 [02:42<00:11,  8.84it/s] 93%|█████████▎| 1281/1380 [02:42<00:11,  8.80it/s] 93%|█████████▎| 1282/1380 [02:42<00:11,  8.85it/s] 93%|█████████▎| 1283/1380 [02:42<00:11,  8.81it/s] 93%|█████████▎| 1284/1380 [02:42<00:10,  8.79it/s] 93%|█████████▎| 1285/1380 [02:42<00:10,  8.78it/s] 93%|█████████▎| 1286/1380 [02:42<00:10,  8.72it/s] 93%|█████████▎| 1287/1380 [02:42<00:10,  8.81it/s] 93%|█████████▎| 1288/1380 [02:43<00:10,  8.80it/s] 93%|█████████▎| 1289/1380 [02:43<00:10,  8.89it/s] 93%|█████████▎| 1290/1380 [02:43<00:10,  8.84it/s] 94%|█████████▎| 1291/1380 [02:43<00:10,  8.84it/s] 94%|█████████▎| 1292/1380 [02:43<00:09,  8.92it/s] 94%|█████████▎| 1293/1380 [02:43<00:09,  8.88it/s] 94%|█████████▍| 1294/1380 [02:43<00:09,  8.86it/s] 94%|█████████▍| 1295/1380 [02:43<00:09,  8.92it/s] 94%|█████████▍| 1296/1380 [02:43<00:09,  8.84it/s] 94%|█████████▍| 1297/1380 [02:44<00:09,  8.91it/s] 94%|█████████▍| 1298/1380 [02:44<00:09,  8.86it/s] 94%|█████████▍| 1299/1380 [02:44<00:09,  8.93it/s] 94%|█████████▍| 1300/1380 [02:44<00:09,  8.89it/s] 94%|█████████▍| 1301/1380 [02:44<00:08,  8.90it/s] 94%|█████████▍| 1302/1380 [02:44<00:08,  8.99it/s] 94%|█████████▍| 1303/1380 [02:44<00:08,  8.95it/s] 94%|█████████▍| 1304/1380 [02:44<00:08,  8.92it/s] 95%|█████████▍| 1305/1380 [02:44<00:08,  8.88it/s] 95%|█████████▍| 1306/1380 [02:45<00:08,  8.90it/s] 95%|█████████▍| 1307/1380 [02:45<00:08,  8.89it/s] 95%|█████████▍| 1308/1380 [02:45<00:08,  8.85it/s] 95%|█████████▍| 1309/1380 [02:45<00:07,  8.91it/s] 95%|█████████▍| 1310/1380 [02:45<00:07,  8.92it/s] 95%|█████████▌| 1311/1380 [02:45<00:07,  8.95it/s] 95%|█████████▌| 1312/1380 [02:45<00:07,  9.01it/s] 95%|█████████▌| 1313/1380 [02:45<00:07,  8.87it/s] 95%|█████████▌| 1314/1380 [02:45<00:07,  8.80it/s] 95%|█████████▌| 1315/1380 [02:46<00:07,  8.76it/s] 95%|█████████▌| 1316/1380 [02:46<00:07,  8.89it/s] 95%|█████████▌| 1317/1380 [02:46<00:07,  8.81it/s] 96%|█████████▌| 1318/1380 [02:46<00:07,  8.84it/s] 96%|█████████▌| 1319/1380 [02:46<00:06,  8.83it/s] 96%|█████████▌| 1320/1380 [02:46<00:06,  8.83it/s] 96%|█████████▌| 1321/1380 [02:46<00:06,  8.87it/s] 96%|█████████▌| 1322/1380 [02:46<00:06,  8.97it/s] 96%|█████████▌| 1323/1380 [02:46<00:06,  8.90it/s] 96%|█████████▌| 1324/1380 [02:47<00:06,  8.89it/s] 96%|█████████▌| 1325/1380 [02:47<00:06,  8.83it/s] 96%|█████████▌| 1326/1380 [02:47<00:06,  8.91it/s] 96%|█████████▌| 1327/1380 [02:47<00:06,  8.82it/s] 96%|█████████▌| 1328/1380 [02:47<00:05,  8.84it/s] 96%|█████████▋| 1329/1380 [02:47<00:05,  8.75it/s] 96%|█████████▋| 1330/1380 [02:47<00:05,  8.80it/s] 96%|█████████▋| 1331/1380 [02:47<00:05,  8.75it/s] 97%|█████████▋| 1332/1380 [02:48<00:05,  8.77it/s] 97%|█████████▋| 1333/1380 [02:48<00:05,  8.80it/s] 97%|█████████▋| 1334/1380 [02:48<00:05,  8.77it/s] 97%|█████████▋| 1335/1380 [02:48<00:05,  8.82it/s] 97%|█████████▋| 1336/1380 [02:48<00:05,  8.80it/s] 97%|█████████▋| 1337/1380 [02:48<00:04,  8.73it/s] 97%|█████████▋| 1338/1380 [02:48<00:04,  8.75it/s] 97%|█████████▋| 1339/1380 [02:48<00:04,  8.73it/s] 97%|█████████▋| 1340/1380 [02:48<00:04,  8.80it/s] 97%|█████████▋| 1341/1380 [02:49<00:04,  8.63it/s] 97%|█████████▋| 1342/1380 [02:49<00:04,  8.71it/s] 97%|█████████▋| 1343/1380 [02:49<00:04,  8.68it/s] 97%|█████████▋| 1344/1380 [02:49<00:04,  8.73it/s] 97%|█████████▋| 1345/1380 [02:49<00:03,  8.84it/s] 98%|█████████▊| 1346/1380 [02:49<00:03,  8.76it/s] 98%|█████████▊| 1347/1380 [02:49<00:03,  8.81it/s] 98%|█████████▊| 1348/1380 [02:49<00:03,  8.77it/s] 98%|█████████▊| 1349/1380 [02:49<00:03,  8.84it/s] 98%|█████████▊| 1350/1380 [02:50<00:03,  8.77it/s] 98%|█████████▊| 1351/1380 [02:50<00:03,  8.75it/s] 98%|█████████▊| 1352/1380 [02:50<00:03,  8.77it/s] 98%|█████████▊| 1353/1380 [02:50<00:03,  8.81it/s] 98%|█████████▊| 1354/1380 [02:50<00:02,  8.87it/s] 98%|█████████▊| 1355/1380 [02:50<00:02,  8.88it/s] 98%|█████████▊| 1356/1380 [02:50<00:02,  8.81it/s] 98%|█████████▊| 1357/1380 [02:50<00:02,  8.77it/s] 98%|█████████▊| 1358/1380 [02:50<00:02,  8.78it/s] 98%|█████████▊| 1359/1380 [02:51<00:02,  8.71it/s] 99%|█████████▊| 1360/1380 [02:51<00:02,  8.69it/s] 99%|█████████▊| 1361/1380 [02:51<00:02,  8.71it/s] 99%|█████████▊| 1362/1380 [02:51<00:02,  8.72it/s] 99%|█████████▉| 1363/1380 [02:51<00:01,  8.80it/s] 99%|█████████▉| 1364/1380 [02:51<00:01,  8.73it/s] 99%|█████████▉| 1365/1380 [02:51<00:01,  8.77it/s] 99%|█████████▉| 1366/1380 [02:51<00:01,  8.76it/s] 99%|█████████▉| 1367/1380 [02:52<00:01,  8.77it/s] 99%|█████████▉| 1368/1380 [02:52<00:01,  8.84it/s] 99%|█████████▉| 1369/1380 [02:52<00:01,  8.84it/s] 99%|█████████▉| 1370/1380 [02:52<00:01,  8.82it/s] 99%|█████████▉| 1371/1380 [02:52<00:01,  8.83it/s] 99%|█████████▉| 1372/1380 [02:52<00:00,  8.88it/s] 99%|█████████▉| 1373/1380 [02:52<00:00,  8.83it/s]100%|█████████▉| 1374/1380 [02:52<00:00,  8.82it/s]100%|█████████▉| 1375/1380 [02:52<00:00,  8.82it/s]100%|█████████▉| 1376/1380 [02:53<00:00,  8.83it/s]100%|█████████▉| 1377/1380 [02:53<00:00,  8.85it/s]100%|█████████▉| 1378/1380 [02:53<00:00,  8.97it/s]100%|█████████▉| 1379/1380 [02:53<00:00,  8.94it/s]                                                   100%|██████████| 1380/1380 [02:53<00:00,  8.94it/s][INFO|trainer.py:755] 2023-11-15 19:35:59,684 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:35:59,686 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:35:59,686 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:35:59,686 >>   Batch size = 8
{'eval_loss': 0.5473086833953857, 'eval_accuracy': 0.8620689655172413, 'eval_micro_f1': 0.8620689655172413, 'eval_macro_f1': 0.8424768308239292, 'eval_runtime': 4.1604, 'eval_samples_per_second': 529.763, 'eval_steps_per_second': 66.341, 'epoch': 4.0}
{'loss': 0.0996, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 8/276 [00:00<00:03, 78.70it/s][A
  6%|▌         | 16/276 [00:00<00:03, 74.48it/s][A
  9%|▊         | 24/276 [00:00<00:03, 68.91it/s][A
 11%|█         | 31/276 [00:00<00:03, 67.88it/s][A
 14%|█▍        | 38/276 [00:00<00:03, 68.57it/s][A
 17%|█▋        | 46/276 [00:00<00:03, 68.36it/s][A
 20%|█▉        | 54/276 [00:00<00:03, 69.26it/s][A
 22%|██▏       | 62/276 [00:00<00:03, 70.58it/s][A
 25%|██▌       | 70/276 [00:01<00:03, 67.78it/s][A
 28%|██▊       | 77/276 [00:01<00:02, 66.98it/s][A
 30%|███       | 84/276 [00:01<00:02, 66.96it/s][A
 33%|███▎      | 91/276 [00:01<00:02, 67.05it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 67.82it/s][A
 38%|███▊      | 105/276 [00:01<00:02, 67.86it/s][A
 41%|████      | 113/276 [00:01<00:02, 68.41it/s][A
 43%|████▎     | 120/276 [00:01<00:02, 67.34it/s][A
 46%|████▋     | 128/276 [00:01<00:02, 68.03it/s][A
 49%|████▉     | 135/276 [00:01<00:02, 67.26it/s][A
 51%|█████▏    | 142/276 [00:02<00:01, 68.00it/s][A
 54%|█████▍    | 149/276 [00:02<00:01, 68.32it/s][A
 57%|█████▋    | 156/276 [00:02<00:01, 68.32it/s][A
 59%|█████▉    | 164/276 [00:02<00:01, 68.27it/s][A
 62%|██████▏   | 171/276 [00:02<00:01, 66.75it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 66.06it/s][A
 67%|██████▋   | 185/276 [00:02<00:01, 66.14it/s][A
 70%|██████▉   | 192/276 [00:02<00:01, 66.64it/s][A
 72%|███████▏  | 199/276 [00:02<00:01, 67.41it/s][A
 75%|███████▍  | 206/276 [00:03<00:01, 67.94it/s][A
 77%|███████▋  | 213/276 [00:03<00:00, 68.21it/s][A
 80%|███████▉  | 220/276 [00:03<00:00, 66.44it/s][A
 82%|████████▏ | 227/276 [00:03<00:00, 66.10it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 66.01it/s][A
 87%|████████▋ | 241/276 [00:03<00:00, 66.06it/s][A
 90%|████████▉ | 248/276 [00:03<00:00, 66.98it/s][A
 92%|█████████▏| 255/276 [00:03<00:00, 66.84it/s][A
 95%|█████████▌| 263/276 [00:03<00:00, 67.99it/s][A
 98%|█████████▊| 270/276 [00:03<00:00, 67.38it/s][A                                                   
                                                 [A100%|██████████| 1380/1380 [02:57<00:00,  8.94it/s]
100%|██████████| 276/276 [00:04<00:00, 67.38it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 19:36:03,835 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:57<00:00,  8.94it/s]100%|██████████| 1380/1380 [02:57<00:00,  7.77it/s]
[INFO|trainer.py:2855] 2023-11-15 19:36:03,839 >> Saving model checkpoint to ./result/acl_bert-base-cased_adapter__seed0
[INFO|configuration_utils.py:460] 2023-11-15 19:36:03,841 >> Configuration saved in ./result/acl_bert-base-cased_adapter__seed0/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:36:05,162 >> Model weights saved in ./result/acl_bert-base-cased_adapter__seed0/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:36:05,165 >> tokenizer config file saved in ./result/acl_bert-base-cased_adapter__seed0/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:36:05,167 >> Special tokens file saved in ./result/acl_bert-base-cased_adapter__seed0/special_tokens_map.json
{'eval_loss': 0.564936101436615, 'eval_accuracy': 0.8579854809437386, 'eval_micro_f1': 0.8579854809437386, 'eval_macro_f1': 0.8408168978046691, 'eval_runtime': 4.1447, 'eval_samples_per_second': 531.769, 'eval_steps_per_second': 66.592, 'epoch': 5.0}
{'train_runtime': 177.5941, 'train_samples_per_second': 248.206, 'train_steps_per_second': 7.771, 'train_loss': 0.25588230464769446, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2559
  train_runtime            = 0:02:57.59
  train_samples            =       8816
  train_samples_per_second =    248.206
  train_steps_per_second   =      7.771
11/15/2023 19:36:05 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:36:05,211 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:36:05,213 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:36:05,213 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:36:05,213 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  3%|▎         | 8/276 [00:00<00:03, 75.93it/s]  6%|▌         | 16/276 [00:00<00:03, 71.87it/s]  9%|▊         | 24/276 [00:00<00:03, 72.59it/s] 12%|█▏        | 32/276 [00:00<00:03, 70.32it/s] 14%|█▍        | 40/276 [00:00<00:03, 69.91it/s] 17%|█▋        | 48/276 [00:00<00:03, 69.76it/s] 20%|█▉        | 55/276 [00:00<00:03, 69.41it/s] 23%|██▎       | 63/276 [00:00<00:03, 69.59it/s] 26%|██▌       | 71/276 [00:01<00:02, 71.53it/s] 29%|██▊       | 79/276 [00:01<00:02, 70.01it/s] 32%|███▏      | 87/276 [00:01<00:02, 69.63it/s] 34%|███▍      | 95/276 [00:01<00:02, 69.85it/s] 37%|███▋      | 103/276 [00:01<00:02, 70.98it/s] 40%|████      | 111/276 [00:01<00:02, 70.93it/s] 43%|████▎     | 119/276 [00:01<00:02, 69.83it/s] 46%|████▌     | 127/276 [00:01<00:02, 70.94it/s] 49%|████▉     | 135/276 [00:01<00:02, 70.32it/s] 52%|█████▏    | 143/276 [00:02<00:01, 70.16it/s] 55%|█████▍    | 151/276 [00:02<00:01, 71.79it/s] 58%|█████▊    | 159/276 [00:02<00:01, 69.43it/s] 61%|██████    | 167/276 [00:02<00:01, 69.70it/s] 63%|██████▎   | 174/276 [00:02<00:01, 69.17it/s] 66%|██████▌   | 181/276 [00:02<00:01, 68.96it/s] 68%|██████▊   | 189/276 [00:02<00:01, 70.02it/s] 71%|███████▏  | 197/276 [00:02<00:01, 69.36it/s] 74%|███████▍  | 205/276 [00:02<00:01, 70.33it/s] 77%|███████▋  | 213/276 [00:03<00:00, 69.41it/s] 80%|███████▉  | 220/276 [00:03<00:00, 69.48it/s] 82%|████████▏ | 227/276 [00:03<00:00, 68.46it/s] 85%|████████▌ | 235/276 [00:03<00:00, 70.14it/s] 88%|████████▊ | 243/276 [00:03<00:00, 68.38it/s] 91%|█████████ | 250/276 [00:03<00:00, 67.99it/s] 93%|█████████▎| 258/276 [00:03<00:00, 69.83it/s] 96%|█████████▌| 265/276 [00:03<00:00, 68.85it/s] 99%|█████████▉| 273/276 [00:03<00:00, 69.29it/s]100%|██████████| 276/276 [00:03<00:00, 69.08it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.858
  eval_loss               =     0.5649
  eval_macro_f1           =     0.8408
  eval_micro_f1           =      0.858
  eval_runtime            = 0:00:04.01
  eval_samples            =       2204
  eval_samples_per_second =    549.063
  eval_steps_per_second   =     68.757
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▇█▇▄▄
wandb:                      eval/loss ▁▁▃▇██
wandb:                  eval/macro_f1 ▁▆█▇▅▅
wandb:                  eval/micro_f1 ▁▇█▇▄▄
wandb:                   eval/runtime ▅▄██▇▁
wandb:        eval/samples_per_second ▄▅▁▁▂█
wandb:          eval/steps_per_second ▄▅▁▁▂█
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.85799
wandb:                      eval/loss 0.56494
wandb:                  eval/macro_f1 0.84082
wandb:                  eval/micro_f1 0.85799
wandb:                   eval/runtime 4.0141
wandb:        eval/samples_per_second 549.063
wandb:          eval/steps_per_second 68.757
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0996
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.25588
wandb:            train/train_runtime 177.5941
wandb: train/train_samples_per_second 248.206
wandb:   train/train_steps_per_second 7.771
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_193218-ks7p6pu0
wandb: Find logs at: ./wandb/offline-run-20231115_193218-ks7p6pu0/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0/runs/Nov15_19-36-20_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:36:20 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:36:20 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0/runs/Nov15_19-36-19_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  37%|███▋      | 4090/11020 [00:00<00:00, 39960.83 examples/s]Map:  74%|███████▍  | 8158/11020 [00:00<00:00, 40373.50 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 40135.56 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 19:36:36,898 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:36:36,910 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 19:36:46,928 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 19:36:56,947 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:36:56,948 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:37:16,981 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:37:16,981 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:37:16,982 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:37:16,982 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:37:16,982 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 19:37:16,984 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:37:16,985 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 19:37:17,006 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:37:17,007 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:37:37,202 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 19:37:39,038 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:37:39,038 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  34%|███▍      | 3000/8816 [00:00<00:00, 20573.53 examples/s]Running tokenizer on dataset:  68%|██████▊   | 6000/8816 [00:00<00:00, 19984.71 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 20156.59 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 20029.96 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 19457.68 examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 19149.93 examples/s]
11/15/2023 19:37:39 - INFO - __main__ - Sample 3485 of the training set: {'text': 'ERGMs are particularly useful for testing hypotheses about network relations, and they have started to be applied more widely in public health [27].', 'label': 0, 'input_ids': [102, 9124, 530, 220, 3220, 2700, 168, 2712, 8138, 1011, 934, 1405, 422, 137, 698, 360, 6774, 147, 195, 1765, 475, 4276, 121, 1771, 947, 260, 2532, 1901, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:37:39 - INFO - __main__ - Sample 5176 of the training set: {'text': 'Consistent with previous results (Koroch et al. 2002; Liu et al. 2002; Staniszewska et al. 2003; Washida et al. 2004), the addition of IBA at optimum levels enhanced the growth of HRC of Echinacea but had no effect on the production of secondary metabolites.', 'label': 2, 'input_ids': [102, 2478, 190, 1061, 545, 145, 13568, 1616, 365, 186, 205, 8063, 1814, 6401, 365, 186, 205, 8063, 1814, 11499, 129, 26445, 15032, 365, 186, 205, 7587, 1814, 13798, 5693, 365, 186, 205, 6706, 546, 422, 111, 867, 131, 6749, 30110, 235, 8041, 1049, 4006, 111, 1503, 131, 3938, 30116, 131, 6101, 1869, 176, 30110, 563, 883, 425, 907, 191, 111, 1865, 131, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 19:37:39 - INFO - __main__ - Sample 8092 of the training set: {'text': 'Syllables with a voiced onset developed a low tone, and those with a voiceless initial induced a high tone, resulting in a six-way tonal contrast (2 pitch heights x 3 contours).1\n(Kang 2014, Kim 2000, Oh 2011, Silva 2006, Wright 2007).', 'label': 0, 'input_ids': [102, 28870, 190, 106, 9769, 30118, 4986, 1815, 106, 629, 11191, 422, 137, 1052, 190, 106, 9769, 2095, 1700, 2651, 106, 597, 11191, 422, 2429, 121, 106, 2781, 579, 1804, 13354, 120, 2144, 145, 170, 10673, 18215, 412, 239, 16064, 546, 205, 158, 145, 18290, 4521, 422, 6128, 4708, 422, 5059, 5228, 422, 19117, 6186, 422, 17244, 5248, 546, 205, 103, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}.
11/15/2023 19:37:39 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:37:41,188 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:37:41,196 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:37:41,197 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 19:37:41,197 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:37:41,197 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:37:41,198 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:37:41,199 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:37:41,199 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 19:37:41,200 >>   Number of trainable parameters = 109,920,771
[INFO|integration_utils.py:716] 2023-11-15 19:37:41,201 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<34:32,  1.50s/it]  0%|          | 2/1380 [00:01<15:43,  1.46it/s]  0%|          | 3/1380 [00:01<09:40,  2.37it/s]  0%|          | 4/1380 [00:01<06:50,  3.35it/s]  0%|          | 5/1380 [00:01<05:18,  4.31it/s]  0%|          | 6/1380 [00:02<04:22,  5.23it/s]  1%|          | 7/1380 [00:02<03:48,  6.00it/s]  1%|          | 8/1380 [00:02<03:24,  6.71it/s]  1%|          | 9/1380 [00:02<03:09,  7.25it/s]  1%|          | 10/1380 [00:02<02:55,  7.80it/s]  1%|          | 11/1380 [00:02<02:50,  8.04it/s]  1%|          | 12/1380 [00:02<02:45,  8.25it/s]  1%|          | 13/1380 [00:02<02:41,  8.45it/s]  1%|          | 14/1380 [00:02<02:38,  8.64it/s]  1%|          | 15/1380 [00:03<02:36,  8.70it/s]  1%|          | 16/1380 [00:03<02:36,  8.69it/s]  1%|          | 17/1380 [00:03<02:33,  8.86it/s]  1%|▏         | 18/1380 [00:03<02:33,  8.85it/s]  1%|▏         | 19/1380 [00:03<02:32,  8.92it/s]  1%|▏         | 20/1380 [00:03<02:30,  9.05it/s]  2%|▏         | 21/1380 [00:03<02:31,  9.00it/s]  2%|▏         | 22/1380 [00:03<02:31,  8.97it/s]  2%|▏         | 23/1380 [00:03<02:32,  8.90it/s]  2%|▏         | 24/1380 [00:04<02:32,  8.89it/s]  2%|▏         | 25/1380 [00:04<02:31,  8.94it/s]  2%|▏         | 26/1380 [00:04<02:31,  8.96it/s]  2%|▏         | 27/1380 [00:04<02:28,  9.12it/s]  2%|▏         | 28/1380 [00:04<02:30,  9.00it/s]  2%|▏         | 29/1380 [00:04<02:32,  8.84it/s]  2%|▏         | 30/1380 [00:04<02:31,  8.89it/s]  2%|▏         | 31/1380 [00:04<02:30,  8.97it/s]  2%|▏         | 32/1380 [00:04<02:30,  8.96it/s]  2%|▏         | 33/1380 [00:05<02:31,  8.90it/s]  2%|▏         | 34/1380 [00:05<02:29,  8.98it/s]  3%|▎         | 35/1380 [00:05<02:31,  8.90it/s]  3%|▎         | 36/1380 [00:05<02:30,  8.94it/s]  3%|▎         | 37/1380 [00:05<02:28,  9.03it/s]  3%|▎         | 38/1380 [00:05<02:29,  8.99it/s]  3%|▎         | 39/1380 [00:05<02:30,  8.92it/s]  3%|▎         | 40/1380 [00:05<02:30,  8.88it/s]  3%|▎         | 41/1380 [00:05<02:31,  8.86it/s]  3%|▎         | 42/1380 [00:06<02:29,  8.93it/s]  3%|▎         | 43/1380 [00:06<02:28,  8.99it/s]  3%|▎         | 44/1380 [00:06<02:26,  9.10it/s]  3%|▎         | 45/1380 [00:06<02:28,  8.99it/s]  3%|▎         | 46/1380 [00:06<02:28,  8.97it/s]  3%|▎         | 47/1380 [00:06<02:28,  8.98it/s]  3%|▎         | 48/1380 [00:06<02:29,  8.94it/s]  4%|▎         | 49/1380 [00:06<02:28,  8.99it/s]  4%|▎         | 50/1380 [00:06<02:28,  8.93it/s]  4%|▎         | 51/1380 [00:07<02:26,  9.07it/s]  4%|▍         | 52/1380 [00:07<02:27,  8.98it/s]  4%|▍         | 53/1380 [00:07<02:28,  8.91it/s]  4%|▍         | 54/1380 [00:07<02:29,  8.89it/s]  4%|▍         | 55/1380 [00:07<02:28,  8.93it/s]  4%|▍         | 56/1380 [00:07<02:28,  8.93it/s]  4%|▍         | 57/1380 [00:07<02:28,  8.92it/s]  4%|▍         | 58/1380 [00:07<02:27,  8.94it/s]  4%|▍         | 59/1380 [00:07<02:28,  8.91it/s]  4%|▍         | 60/1380 [00:08<02:28,  8.91it/s]  4%|▍         | 61/1380 [00:08<02:26,  8.99it/s]  4%|▍         | 62/1380 [00:08<02:26,  8.99it/s]  5%|▍         | 63/1380 [00:08<02:27,  8.96it/s]  5%|▍         | 64/1380 [00:08<02:27,  8.95it/s]  5%|▍         | 65/1380 [00:08<02:25,  9.04it/s]  5%|▍         | 66/1380 [00:08<02:25,  9.03it/s]  5%|▍         | 67/1380 [00:08<02:25,  9.05it/s]  5%|▍         | 68/1380 [00:08<02:24,  9.08it/s]  5%|▌         | 69/1380 [00:09<02:24,  9.09it/s]  5%|▌         | 70/1380 [00:09<02:25,  9.03it/s]  5%|▌         | 71/1380 [00:09<02:25,  8.97it/s]  5%|▌         | 72/1380 [00:09<02:25,  9.01it/s]  5%|▌         | 73/1380 [00:09<02:26,  8.93it/s]  5%|▌         | 74/1380 [00:09<02:25,  8.95it/s]  5%|▌         | 75/1380 [00:09<02:23,  9.08it/s]  6%|▌         | 76/1380 [00:09<02:24,  9.03it/s]  6%|▌         | 77/1380 [00:09<02:24,  8.99it/s]  6%|▌         | 78/1380 [00:10<02:24,  9.00it/s]  6%|▌         | 79/1380 [00:10<02:23,  9.06it/s]  6%|▌         | 80/1380 [00:10<02:23,  9.05it/s]  6%|▌         | 81/1380 [00:10<02:23,  9.06it/s]  6%|▌         | 82/1380 [00:10<02:20,  9.23it/s]  6%|▌         | 83/1380 [00:10<02:23,  9.05it/s]  6%|▌         | 84/1380 [00:10<02:23,  9.05it/s]  6%|▌         | 85/1380 [00:10<02:23,  9.00it/s]  6%|▌         | 86/1380 [00:10<02:23,  9.04it/s]  6%|▋         | 87/1380 [00:11<02:22,  9.09it/s]  6%|▋         | 88/1380 [00:11<02:23,  9.02it/s]  6%|▋         | 89/1380 [00:11<02:21,  9.11it/s]  7%|▋         | 90/1380 [00:11<02:21,  9.09it/s]  7%|▋         | 91/1380 [00:11<02:23,  8.99it/s]  7%|▋         | 92/1380 [00:11<02:22,  9.02it/s]  7%|▋         | 93/1380 [00:11<02:22,  9.05it/s]  7%|▋         | 94/1380 [00:11<02:22,  9.04it/s]  7%|▋         | 95/1380 [00:11<02:22,  8.99it/s]  7%|▋         | 96/1380 [00:12<02:20,  9.11it/s]  7%|▋         | 97/1380 [00:12<02:21,  9.08it/s]  7%|▋         | 98/1380 [00:12<02:20,  9.11it/s]  7%|▋         | 99/1380 [00:12<02:19,  9.18it/s]  7%|▋         | 100/1380 [00:12<02:19,  9.17it/s]  7%|▋         | 101/1380 [00:12<02:20,  9.11it/s]  7%|▋         | 102/1380 [00:12<02:21,  9.04it/s]  7%|▋         | 103/1380 [00:12<02:20,  9.10it/s]  8%|▊         | 104/1380 [00:12<02:21,  9.03it/s]  8%|▊         | 105/1380 [00:13<02:20,  9.09it/s]  8%|▊         | 106/1380 [00:13<02:19,  9.14it/s]  8%|▊         | 107/1380 [00:13<02:20,  9.03it/s]  8%|▊         | 108/1380 [00:13<02:21,  9.00it/s]  8%|▊         | 109/1380 [00:13<02:21,  9.00it/s]  8%|▊         | 110/1380 [00:13<02:21,  8.98it/s]  8%|▊         | 111/1380 [00:13<02:20,  9.04it/s]  8%|▊         | 112/1380 [00:13<02:19,  9.07it/s]  8%|▊         | 113/1380 [00:13<02:18,  9.13it/s]  8%|▊         | 114/1380 [00:14<02:19,  9.06it/s]  8%|▊         | 115/1380 [00:14<02:20,  9.03it/s]  8%|▊         | 116/1380 [00:14<02:20,  8.98it/s]  8%|▊         | 117/1380 [00:14<02:19,  9.04it/s]  9%|▊         | 118/1380 [00:14<02:19,  9.07it/s]  9%|▊         | 119/1380 [00:14<02:18,  9.08it/s]  9%|▊         | 120/1380 [00:14<02:18,  9.07it/s]  9%|▉         | 121/1380 [00:14<02:19,  9.04it/s]  9%|▉         | 122/1380 [00:14<02:18,  9.05it/s]  9%|▉         | 123/1380 [00:15<02:17,  9.11it/s]  9%|▉         | 124/1380 [00:15<02:18,  9.05it/s]  9%|▉         | 125/1380 [00:15<02:19,  8.98it/s]  9%|▉         | 126/1380 [00:15<02:18,  9.05it/s]  9%|▉         | 127/1380 [00:15<02:19,  9.01it/s]  9%|▉         | 128/1380 [00:15<02:18,  9.06it/s]  9%|▉         | 129/1380 [00:15<02:17,  9.10it/s]  9%|▉         | 130/1380 [00:15<02:15,  9.22it/s]  9%|▉         | 131/1380 [00:15<02:17,  9.08it/s] 10%|▉         | 132/1380 [00:16<02:17,  9.08it/s] 10%|▉         | 133/1380 [00:16<02:17,  9.10it/s] 10%|▉         | 134/1380 [00:16<02:17,  9.05it/s] 10%|▉         | 135/1380 [00:16<02:16,  9.09it/s] 10%|▉         | 136/1380 [00:16<02:17,  9.07it/s] 10%|▉         | 137/1380 [00:16<02:15,  9.20it/s] 10%|█         | 138/1380 [00:16<02:17,  9.06it/s] 10%|█         | 139/1380 [00:16<02:16,  9.08it/s] 10%|█         | 140/1380 [00:16<02:17,  9.03it/s] 10%|█         | 141/1380 [00:17<02:16,  9.09it/s] 10%|█         | 142/1380 [00:17<02:17,  9.02it/s] 10%|█         | 143/1380 [00:17<02:17,  8.97it/s] 10%|█         | 144/1380 [00:17<02:17,  9.01it/s] 11%|█         | 145/1380 [00:17<02:18,  8.89it/s] 11%|█         | 146/1380 [00:17<02:17,  8.98it/s] 11%|█         | 147/1380 [00:17<02:15,  9.07it/s] 11%|█         | 148/1380 [00:17<02:17,  8.98it/s] 11%|█         | 149/1380 [00:17<02:16,  8.99it/s] 11%|█         | 150/1380 [00:18<02:16,  9.02it/s] 11%|█         | 151/1380 [00:18<02:16,  8.99it/s] 11%|█         | 152/1380 [00:18<02:15,  9.06it/s] 11%|█         | 153/1380 [00:18<02:16,  9.01it/s] 11%|█         | 154/1380 [00:18<02:15,  9.07it/s] 11%|█         | 155/1380 [00:18<02:16,  8.99it/s] 11%|█▏        | 156/1380 [00:18<02:14,  9.09it/s] 11%|█▏        | 157/1380 [00:18<02:14,  9.09it/s] 11%|█▏        | 158/1380 [00:18<02:14,  9.08it/s] 12%|█▏        | 159/1380 [00:19<02:14,  9.07it/s] 12%|█▏        | 160/1380 [00:19<02:14,  9.05it/s] 12%|█▏        | 161/1380 [00:19<02:14,  9.03it/s] 12%|█▏        | 162/1380 [00:19<02:15,  9.00it/s] 12%|█▏        | 163/1380 [00:19<02:14,  9.07it/s] 12%|█▏        | 164/1380 [00:19<02:12,  9.20it/s] 12%|█▏        | 165/1380 [00:19<02:14,  9.04it/s] 12%|█▏        | 166/1380 [00:19<02:14,  9.00it/s] 12%|█▏        | 167/1380 [00:19<02:13,  9.06it/s] 12%|█▏        | 168/1380 [00:20<02:13,  9.08it/s] 12%|█▏        | 169/1380 [00:20<02:12,  9.11it/s] 12%|█▏        | 170/1380 [00:20<02:13,  9.08it/s] 12%|█▏        | 171/1380 [00:20<02:12,  9.12it/s] 12%|█▏        | 172/1380 [00:20<02:13,  9.04it/s] 13%|█▎        | 173/1380 [00:20<02:12,  9.10it/s] 13%|█▎        | 174/1380 [00:20<02:11,  9.15it/s] 13%|█▎        | 175/1380 [00:20<02:12,  9.09it/s] 13%|█▎        | 176/1380 [00:20<02:13,  9.00it/s] 13%|█▎        | 177/1380 [00:21<02:12,  9.09it/s] 13%|█▎        | 178/1380 [00:21<02:13,  8.99it/s] 13%|█▎        | 179/1380 [00:21<02:13,  9.03it/s] 13%|█▎        | 180/1380 [00:21<02:12,  9.09it/s] 13%|█▎        | 181/1380 [00:21<02:10,  9.19it/s] 13%|█▎        | 182/1380 [00:21<02:11,  9.08it/s] 13%|█▎        | 183/1380 [00:21<02:11,  9.07it/s] 13%|█▎        | 184/1380 [00:21<02:12,  9.06it/s] 13%|█▎        | 185/1380 [00:21<02:11,  9.11it/s] 13%|█▎        | 186/1380 [00:22<02:11,  9.05it/s] 14%|█▎        | 187/1380 [00:22<02:12,  9.03it/s] 14%|█▎        | 188/1380 [00:22<02:10,  9.13it/s] 14%|█▎        | 189/1380 [00:22<02:10,  9.10it/s] 14%|█▍        | 190/1380 [00:22<02:11,  9.08it/s] 14%|█▍        | 191/1380 [00:22<02:10,  9.14it/s] 14%|█▍        | 192/1380 [00:22<02:11,  9.05it/s] 14%|█▍        | 193/1380 [00:22<02:11,  9.03it/s] 14%|█▍        | 194/1380 [00:22<02:11,  9.03it/s] 14%|█▍        | 195/1380 [00:23<02:11,  9.04it/s] 14%|█▍        | 196/1380 [00:23<02:11,  9.00it/s] 14%|█▍        | 197/1380 [00:23<02:11,  8.97it/s] 14%|█▍        | 198/1380 [00:23<02:10,  9.03it/s] 14%|█▍        | 199/1380 [00:23<02:10,  9.03it/s] 14%|█▍        | 200/1380 [00:23<02:10,  9.06it/s] 15%|█▍        | 201/1380 [00:23<02:09,  9.11it/s] 15%|█▍        | 202/1380 [00:23<02:09,  9.10it/s] 15%|█▍        | 203/1380 [00:23<02:09,  9.06it/s] 15%|█▍        | 204/1380 [00:23<02:10,  9.02it/s] 15%|█▍        | 205/1380 [00:24<02:10,  8.99it/s] 15%|█▍        | 206/1380 [00:24<02:09,  9.05it/s] 15%|█▌        | 207/1380 [00:24<02:10,  9.00it/s] 15%|█▌        | 208/1380 [00:24<02:08,  9.13it/s] 15%|█▌        | 209/1380 [00:24<02:08,  9.08it/s] 15%|█▌        | 210/1380 [00:24<02:09,  9.06it/s] 15%|█▌        | 211/1380 [00:24<02:08,  9.09it/s] 15%|█▌        | 212/1380 [00:24<02:08,  9.07it/s] 15%|█▌        | 213/1380 [00:24<02:08,  9.07it/s] 16%|█▌        | 214/1380 [00:25<02:09,  9.02it/s] 16%|█▌        | 215/1380 [00:25<02:07,  9.11it/s] 16%|█▌        | 216/1380 [00:25<02:07,  9.10it/s] 16%|█▌        | 217/1380 [00:25<02:08,  9.06it/s] 16%|█▌        | 218/1380 [00:25<02:06,  9.20it/s] 16%|█▌        | 219/1380 [00:25<02:07,  9.09it/s] 16%|█▌        | 220/1380 [00:25<02:08,  9.03it/s] 16%|█▌        | 221/1380 [00:25<02:08,  9.04it/s] 16%|█▌        | 222/1380 [00:25<02:08,  9.02it/s] 16%|█▌        | 223/1380 [00:26<02:08,  9.03it/s] 16%|█▌        | 224/1380 [00:26<02:08,  9.00it/s] 16%|█▋        | 225/1380 [00:26<02:07,  9.06it/s] 16%|█▋        | 226/1380 [00:26<02:07,  9.02it/s] 16%|█▋        | 227/1380 [00:26<02:07,  9.05it/s] 17%|█▋        | 228/1380 [00:26<02:05,  9.17it/s] 17%|█▋        | 229/1380 [00:26<02:05,  9.16it/s] 17%|█▋        | 230/1380 [00:26<02:06,  9.08it/s] 17%|█▋        | 231/1380 [00:26<02:07,  9.03it/s] 17%|█▋        | 232/1380 [00:27<02:08,  8.97it/s] 17%|█▋        | 233/1380 [00:27<02:06,  9.09it/s] 17%|█▋        | 234/1380 [00:27<02:06,  9.08it/s] 17%|█▋        | 235/1380 [00:27<02:04,  9.18it/s] 17%|█▋        | 236/1380 [00:27<02:06,  9.06it/s] 17%|█▋        | 237/1380 [00:27<02:06,  9.02it/s] 17%|█▋        | 238/1380 [00:27<02:06,  9.01it/s] 17%|█▋        | 239/1380 [00:27<02:06,  9.04it/s] 17%|█▋        | 240/1380 [00:27<02:06,  9.02it/s] 17%|█▋        | 241/1380 [00:28<02:06,  9.01it/s] 18%|█▊        | 242/1380 [00:28<02:05,  9.06it/s] 18%|█▊        | 243/1380 [00:28<02:05,  9.06it/s] 18%|█▊        | 244/1380 [00:28<02:05,  9.08it/s] 18%|█▊        | 245/1380 [00:28<02:04,  9.15it/s] 18%|█▊        | 246/1380 [00:28<02:05,  9.06it/s] 18%|█▊        | 247/1380 [00:28<02:06,  8.99it/s] 18%|█▊        | 248/1380 [00:28<02:05,  8.99it/s] 18%|█▊        | 249/1380 [00:28<02:05,  9.02it/s] 18%|█▊        | 250/1380 [00:29<02:05,  9.03it/s] 18%|█▊        | 251/1380 [00:29<02:04,  9.09it/s] 18%|█▊        | 252/1380 [00:29<02:02,  9.22it/s] 18%|█▊        | 253/1380 [00:29<02:04,  9.06it/s] 18%|█▊        | 254/1380 [00:29<02:04,  9.03it/s] 18%|█▊        | 255/1380 [00:29<02:05,  8.99it/s] 19%|█▊        | 256/1380 [00:29<02:04,  9.02it/s] 19%|█▊        | 257/1380 [00:29<02:04,  9.01it/s] 19%|█▊        | 258/1380 [00:29<02:04,  8.98it/s] 19%|█▉        | 259/1380 [00:30<02:04,  9.03it/s] 19%|█▉        | 260/1380 [00:30<02:04,  9.00it/s] 19%|█▉        | 261/1380 [00:30<02:04,  9.01it/s] 19%|█▉        | 262/1380 [00:30<02:02,  9.13it/s] 19%|█▉        | 263/1380 [00:30<02:03,  9.06it/s] 19%|█▉        | 264/1380 [00:30<02:03,  9.00it/s] 19%|█▉        | 265/1380 [00:30<02:03,  9.01it/s] 19%|█▉        | 266/1380 [00:30<02:04,  8.96it/s] 19%|█▉        | 267/1380 [00:30<02:02,  9.05it/s] 19%|█▉        | 268/1380 [00:31<02:02,  9.08it/s] 19%|█▉        | 269/1380 [00:31<02:02,  9.08it/s] 20%|█▉        | 270/1380 [00:31<02:02,  9.06it/s] 20%|█▉        | 271/1380 [00:31<02:02,  9.06it/s] 20%|█▉        | 272/1380 [00:31<02:02,  9.05it/s] 20%|█▉        | 273/1380 [00:31<02:01,  9.08it/s] 20%|█▉        | 274/1380 [00:31<02:02,  9.01it/s] 20%|█▉        | 275/1380 [00:31<02:02,  9.05it/s]                                                   20%|██        | 276/1380 [00:31<02:02,  9.05it/s][INFO|trainer.py:755] 2023-11-15 19:38:13,118 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:38:13,120 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:38:13,121 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:38:13,121 >>   Batch size = 8
{'loss': 0.4324, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 8/276 [00:00<00:03, 75.69it/s][A
  6%|▌         | 16/276 [00:00<00:03, 72.87it/s][A
  9%|▊         | 24/276 [00:00<00:03, 72.48it/s][A
 12%|█▏        | 32/276 [00:00<00:03, 70.31it/s][A
 14%|█▍        | 40/276 [00:00<00:03, 69.72it/s][A
 17%|█▋        | 47/276 [00:00<00:03, 68.81it/s][A
 20%|█▉        | 55/276 [00:00<00:03, 70.70it/s][A
 23%|██▎       | 63/276 [00:00<00:03, 70.14it/s][A
 26%|██▌       | 71/276 [00:01<00:02, 68.48it/s][A
 29%|██▊       | 79/276 [00:01<00:02, 70.22it/s][A
 32%|███▏      | 87/276 [00:01<00:02, 68.87it/s][A
 34%|███▍      | 95/276 [00:01<00:02, 68.75it/s][A
 37%|███▋      | 103/276 [00:01<00:02, 69.85it/s][A
 40%|███▉      | 110/276 [00:01<00:02, 67.96it/s][A
 42%|████▏     | 117/276 [00:01<00:02, 67.51it/s][A
 45%|████▍     | 124/276 [00:01<00:02, 68.19it/s][A
 48%|████▊     | 132/276 [00:01<00:02, 69.11it/s][A
 50%|█████     | 139/276 [00:02<00:01, 69.04it/s][A
 53%|█████▎    | 147/276 [00:02<00:01, 69.42it/s][A
 56%|█████▌    | 155/276 [00:02<00:01, 70.73it/s][A
 59%|█████▉    | 163/276 [00:02<00:01, 69.33it/s][A
 62%|██████▏   | 170/276 [00:02<00:01, 67.81it/s][A
 64%|██████▍   | 177/276 [00:02<00:01, 67.97it/s][A
 67%|██████▋   | 185/276 [00:02<00:01, 69.00it/s][A
 70%|██████▉   | 192/276 [00:02<00:01, 69.20it/s][A
 72%|███████▏  | 199/276 [00:02<00:01, 68.98it/s][A
 75%|███████▌  | 207/276 [00:02<00:00, 70.89it/s][A
 78%|███████▊  | 215/276 [00:03<00:00, 68.77it/s][A
 80%|████████  | 222/276 [00:03<00:00, 67.95it/s][A
 83%|████████▎ | 229/276 [00:03<00:00, 67.50it/s][A
 86%|████████▌ | 237/276 [00:03<00:00, 67.77it/s][A
 89%|████████▉ | 245/276 [00:03<00:00, 69.45it/s][A
 91%|█████████▏| 252/276 [00:03<00:00, 69.16it/s][A
 94%|█████████▍| 260/276 [00:03<00:00, 70.06it/s][A
 97%|█████████▋| 268/276 [00:03<00:00, 68.01it/s][A
100%|█████████▉| 275/276 [00:03<00:00, 67.36it/s][A                                                  
                                                 [A 20%|██        | 276/1380 [00:35<02:02,  9.05it/s]
100%|██████████| 276/276 [00:04<00:00, 67.36it/s][A
                                                 [A 20%|██        | 277/1380 [00:36<19:05,  1.04s/it] 20%|██        | 278/1380 [00:36<14:51,  1.24it/s] 20%|██        | 279/1380 [00:36<11:30,  1.59it/s] 20%|██        | 280/1380 [00:36<08:55,  2.05it/s] 20%|██        | 281/1380 [00:36<06:59,  2.62it/s] 20%|██        | 282/1380 [00:36<05:35,  3.27it/s] 21%|██        | 283/1380 [00:36<04:34,  3.99it/s] 21%|██        | 284/1380 [00:36<03:50,  4.76it/s] 21%|██        | 285/1380 [00:36<03:17,  5.53it/s] 21%|██        | 286/1380 [00:37<02:55,  6.25it/s] 21%|██        | 287/1380 [00:37<02:36,  6.96it/s] 21%|██        | 288/1380 [00:37<02:27,  7.41it/s] 21%|██        | 289/1380 [00:37<02:19,  7.83it/s] 21%|██        | 290/1380 [00:37<02:13,  8.14it/s] 21%|██        | 291/1380 [00:37<02:10,  8.35it/s] 21%|██        | 292/1380 [00:37<02:07,  8.56it/s] 21%|██        | 293/1380 [00:37<02:05,  8.68it/s] 21%|██▏       | 294/1380 [00:37<02:02,  8.88it/s] 21%|██▏       | 295/1380 [00:38<02:03,  8.80it/s] 21%|██▏       | 296/1380 [00:38<02:02,  8.84it/s] 22%|██▏       | 297/1380 [00:38<02:02,  8.87it/s] 22%|██▏       | 298/1380 [00:38<02:01,  8.92it/s] 22%|██▏       | 299/1380 [00:38<02:01,  8.87it/s] 22%|██▏       | 300/1380 [00:38<02:01,  8.90it/s] 22%|██▏       | 301/1380 [00:38<02:00,  8.92it/s] 22%|██▏       | 302/1380 [00:38<02:00,  8.92it/s] 22%|██▏       | 303/1380 [00:38<02:00,  8.94it/s] 22%|██▏       | 304/1380 [00:39<01:58,  9.05it/s] 22%|██▏       | 305/1380 [00:39<01:59,  8.97it/s] 22%|██▏       | 306/1380 [00:39<01:59,  8.99it/s] 22%|██▏       | 307/1380 [00:39<01:59,  8.94it/s] 22%|██▏       | 308/1380 [00:39<01:59,  8.97it/s] 22%|██▏       | 309/1380 [00:39<01:59,  8.97it/s] 22%|██▏       | 310/1380 [00:39<01:59,  8.95it/s] 23%|██▎       | 311/1380 [00:39<01:58,  9.03it/s] 23%|██▎       | 312/1380 [00:39<01:58,  9.01it/s] 23%|██▎       | 313/1380 [00:40<01:59,  8.93it/s] 23%|██▎       | 314/1380 [00:40<01:59,  8.95it/s] 23%|██▎       | 315/1380 [00:40<01:58,  8.95it/s] 23%|██▎       | 316/1380 [00:40<01:59,  8.92it/s] 23%|██▎       | 317/1380 [00:40<02:00,  8.82it/s] 23%|██▎       | 318/1380 [00:40<02:00,  8.84it/s] 23%|██▎       | 319/1380 [00:40<02:00,  8.80it/s] 23%|██▎       | 320/1380 [00:40<01:59,  8.87it/s] 23%|██▎       | 321/1380 [00:41<01:57,  8.98it/s] 23%|██▎       | 322/1380 [00:41<01:59,  8.87it/s] 23%|██▎       | 323/1380 [00:41<02:00,  8.75it/s] 23%|██▎       | 324/1380 [00:41<01:59,  8.84it/s] 24%|██▎       | 325/1380 [00:41<01:59,  8.86it/s] 24%|██▎       | 326/1380 [00:41<01:58,  8.86it/s] 24%|██▎       | 327/1380 [00:41<01:59,  8.81it/s] 24%|██▍       | 328/1380 [00:41<01:58,  8.87it/s] 24%|██▍       | 329/1380 [00:41<01:59,  8.81it/s] 24%|██▍       | 330/1380 [00:42<01:58,  8.88it/s] 24%|██▍       | 331/1380 [00:42<01:57,  8.89it/s] 24%|██▍       | 332/1380 [00:42<01:57,  8.93it/s] 24%|██▍       | 333/1380 [00:42<01:58,  8.83it/s] 24%|██▍       | 334/1380 [00:42<01:58,  8.81it/s] 24%|██▍       | 335/1380 [00:42<01:58,  8.82it/s] 24%|██▍       | 336/1380 [00:42<01:58,  8.81it/s] 24%|██▍       | 337/1380 [00:42<01:57,  8.86it/s] 24%|██▍       | 338/1380 [00:42<01:56,  8.96it/s] 25%|██▍       | 339/1380 [00:43<01:57,  8.89it/s] 25%|██▍       | 340/1380 [00:43<01:57,  8.88it/s] 25%|██▍       | 341/1380 [00:43<01:57,  8.85it/s] 25%|██▍       | 342/1380 [00:43<01:57,  8.84it/s] 25%|██▍       | 343/1380 [00:43<01:57,  8.85it/s] 25%|██▍       | 344/1380 [00:43<01:57,  8.79it/s] 25%|██▌       | 345/1380 [00:43<01:55,  8.94it/s] 25%|██▌       | 346/1380 [00:43<01:57,  8.82it/s] 25%|██▌       | 347/1380 [00:43<01:57,  8.77it/s] 25%|██▌       | 348/1380 [00:44<01:56,  8.83it/s] 25%|██▌       | 349/1380 [00:44<01:56,  8.87it/s] 25%|██▌       | 350/1380 [00:44<01:56,  8.83it/s] 25%|██▌       | 351/1380 [00:44<01:57,  8.79it/s] 26%|██▌       | 352/1380 [00:44<01:56,  8.85it/s] 26%|██▌       | 353/1380 [00:44<01:56,  8.84it/s] 26%|██▌       | 354/1380 [00:44<01:55,  8.86it/s] 26%|██▌       | 355/1380 [00:44<01:54,  8.94it/s] 26%|██▌       | 356/1380 [00:44<01:55,  8.88it/s] 26%|██▌       | 357/1380 [00:45<01:55,  8.84it/s] 26%|██▌       | 358/1380 [00:45<01:55,  8.82it/s] 26%|██▌       | 359/1380 [00:45<01:55,  8.81it/s] 26%|██▌       | 360/1380 [00:45<01:55,  8.83it/s] 26%|██▌       | 361/1380 [00:45<01:54,  8.89it/s] 26%|██▌       | 362/1380 [00:45<01:52,  9.01it/s] 26%|██▋       | 363/1380 [00:45<01:55,  8.83it/s] 26%|██▋       | 364/1380 [00:45<01:56,  8.75it/s] 26%|██▋       | 365/1380 [00:45<01:55,  8.81it/s] 27%|██▋       | 366/1380 [00:46<01:55,  8.78it/s] 27%|██▋       | 367/1380 [00:46<01:55,  8.79it/s] 27%|██▋       | 368/1380 [00:46<01:55,  8.73it/s] 27%|██▋       | 369/1380 [00:46<01:54,  8.85it/s] 27%|██▋       | 370/1380 [00:46<01:54,  8.80it/s] 27%|██▋       | 371/1380 [00:46<01:54,  8.79it/s] 27%|██▋       | 372/1380 [00:46<01:53,  8.88it/s] 27%|██▋       | 373/1380 [00:46<01:52,  8.92it/s] 27%|██▋       | 374/1380 [00:46<01:53,  8.90it/s] 27%|██▋       | 375/1380 [00:47<01:54,  8.79it/s] 27%|██▋       | 376/1380 [00:47<01:54,  8.81it/s] 27%|██▋       | 377/1380 [00:47<01:52,  8.88it/s] 27%|██▋       | 378/1380 [00:47<01:52,  8.93it/s] 27%|██▋       | 379/1380 [00:47<01:51,  8.99it/s] 28%|██▊       | 380/1380 [00:47<01:52,  8.93it/s] 28%|██▊       | 381/1380 [00:47<01:52,  8.88it/s] 28%|██▊       | 382/1380 [00:47<01:52,  8.85it/s] 28%|██▊       | 383/1380 [00:48<01:52,  8.86it/s] 28%|██▊       | 384/1380 [00:48<01:52,  8.87it/s] 28%|██▊       | 385/1380 [00:48<01:51,  8.92it/s] 28%|██▊       | 386/1380 [00:48<01:49,  9.06it/s] 28%|██▊       | 387/1380 [00:48<01:51,  8.90it/s] 28%|██▊       | 388/1380 [00:48<01:51,  8.86it/s] 28%|██▊       | 389/1380 [00:48<01:51,  8.91it/s] 28%|██▊       | 390/1380 [00:48<01:51,  8.87it/s] 28%|██▊       | 391/1380 [00:48<01:50,  8.92it/s] 28%|██▊       | 392/1380 [00:49<01:50,  8.94it/s] 28%|██▊       | 393/1380 [00:49<01:49,  9.05it/s] 29%|██▊       | 394/1380 [00:49<01:50,  8.96it/s] 29%|██▊       | 395/1380 [00:49<01:51,  8.85it/s] 29%|██▊       | 396/1380 [00:49<01:51,  8.86it/s] 29%|██▉       | 397/1380 [00:49<01:50,  8.87it/s] 29%|██▉       | 398/1380 [00:49<01:51,  8.82it/s] 29%|██▉       | 399/1380 [00:49<01:51,  8.81it/s] 29%|██▉       | 400/1380 [00:49<01:50,  8.84it/s] 29%|██▉       | 401/1380 [00:50<01:51,  8.81it/s] 29%|██▉       | 402/1380 [00:50<01:51,  8.79it/s] 29%|██▉       | 403/1380 [00:50<01:49,  8.89it/s] 29%|██▉       | 404/1380 [00:50<01:50,  8.87it/s] 29%|██▉       | 405/1380 [00:50<01:51,  8.77it/s] 29%|██▉       | 406/1380 [00:50<01:50,  8.81it/s] 29%|██▉       | 407/1380 [00:50<01:50,  8.78it/s] 30%|██▉       | 408/1380 [00:50<01:50,  8.79it/s] 30%|██▉       | 409/1380 [00:50<01:49,  8.86it/s] 30%|██▉       | 410/1380 [00:51<01:47,  8.99it/s] 30%|██▉       | 411/1380 [00:51<01:48,  8.91it/s] 30%|██▉       | 412/1380 [00:51<01:48,  8.93it/s] 30%|██▉       | 413/1380 [00:51<01:48,  8.95it/s] 30%|███       | 414/1380 [00:51<01:48,  8.93it/s] 30%|███       | 415/1380 [00:51<01:46,  9.03it/s] 30%|███       | 416/1380 [00:51<01:47,  8.99it/s] 30%|███       | 417/1380 [00:51<01:45,  9.09it/s] 30%|███       | 418/1380 [00:51<01:46,  9.01it/s] 30%|███       | 419/1380 [00:52<01:46,  9.01it/s] 30%|███       | 420/1380 [00:52<01:46,  9.00it/s] 31%|███       | 421/1380 [00:52<01:46,  8.98it/s] 31%|███       | 422/1380 [00:52<01:47,  8.95it/s] 31%|███       | 423/1380 [00:52<01:46,  8.97it/s] 31%|███       | 424/1380 [00:52<01:46,  8.98it/s] 31%|███       | 425/1380 [00:52<01:46,  8.94it/s] 31%|███       | 426/1380 [00:52<01:46,  8.96it/s] 31%|███       | 427/1380 [00:52<01:44,  9.11it/s] 31%|███       | 428/1380 [00:53<01:46,  8.93it/s] 31%|███       | 429/1380 [00:53<01:45,  9.01it/s] 31%|███       | 430/1380 [00:53<01:46,  8.95it/s] 31%|███       | 431/1380 [00:53<01:45,  8.98it/s] 31%|███▏      | 432/1380 [00:53<01:46,  8.94it/s] 31%|███▏      | 433/1380 [00:53<01:47,  8.80it/s] 31%|███▏      | 434/1380 [00:53<01:46,  8.92it/s] 32%|███▏      | 435/1380 [00:53<01:46,  8.89it/s] 32%|███▏      | 436/1380 [00:53<01:45,  8.91it/s] 32%|███▏      | 437/1380 [00:54<01:44,  9.05it/s] 32%|███▏      | 438/1380 [00:54<01:44,  8.98it/s] 32%|███▏      | 439/1380 [00:54<01:45,  8.96it/s] 32%|███▏      | 440/1380 [00:54<01:45,  8.92it/s] 32%|███▏      | 441/1380 [00:54<01:45,  8.91it/s] 32%|███▏      | 442/1380 [00:54<01:44,  8.96it/s] 32%|███▏      | 443/1380 [00:54<01:45,  8.91it/s] 32%|███▏      | 444/1380 [00:54<01:44,  8.95it/s] 32%|███▏      | 445/1380 [00:54<01:44,  8.92it/s] 32%|███▏      | 446/1380 [00:55<01:44,  8.91it/s] 32%|███▏      | 447/1380 [00:55<01:43,  8.98it/s] 32%|███▏      | 448/1380 [00:55<01:44,  8.94it/s] 33%|███▎      | 449/1380 [00:55<01:44,  8.90it/s] 33%|███▎      | 450/1380 [00:55<01:44,  8.93it/s] 33%|███▎      | 451/1380 [00:55<01:43,  8.93it/s] 33%|███▎      | 452/1380 [00:55<01:43,  8.95it/s] 33%|███▎      | 453/1380 [00:55<01:44,  8.89it/s] 33%|███▎      | 454/1380 [00:55<01:43,  8.96it/s] 33%|███▎      | 455/1380 [00:56<01:43,  8.90it/s] 33%|███▎      | 456/1380 [00:56<01:43,  8.91it/s] 33%|███▎      | 457/1380 [00:56<01:42,  8.99it/s] 33%|███▎      | 458/1380 [00:56<01:42,  8.96it/s] 33%|███▎      | 459/1380 [00:56<01:43,  8.93it/s] 33%|███▎      | 460/1380 [00:56<01:43,  8.92it/s] 33%|███▎      | 461/1380 [00:56<01:43,  8.90it/s] 33%|███▎      | 462/1380 [00:56<01:42,  8.94it/s] 34%|███▎      | 463/1380 [00:56<01:42,  8.92it/s] 34%|███▎      | 464/1380 [00:57<01:41,  9.00it/s] 34%|███▎      | 465/1380 [00:57<01:42,  8.95it/s] 34%|███▍      | 466/1380 [00:57<01:42,  8.94it/s] 34%|███▍      | 467/1380 [00:57<01:41,  9.02it/s] 34%|███▍      | 468/1380 [00:57<01:41,  9.01it/s] 34%|███▍      | 469/1380 [00:57<01:41,  8.96it/s] 34%|███▍      | 470/1380 [00:57<01:41,  8.94it/s] 34%|███▍      | 471/1380 [00:57<01:41,  8.96it/s] 34%|███▍      | 472/1380 [00:57<01:41,  8.96it/s] 34%|███▍      | 473/1380 [00:58<01:41,  8.91it/s] 34%|███▍      | 474/1380 [00:58<01:40,  8.99it/s] 34%|███▍      | 475/1380 [00:58<01:41,  8.94it/s] 34%|███▍      | 476/1380 [00:58<01:40,  8.96it/s] 35%|███▍      | 477/1380 [00:58<01:40,  8.99it/s] 35%|███▍      | 478/1380 [00:58<01:39,  9.03it/s] 35%|███▍      | 479/1380 [00:58<01:40,  8.97it/s] 35%|███▍      | 480/1380 [00:58<01:41,  8.91it/s] 35%|███▍      | 481/1380 [00:58<01:40,  8.99it/s] 35%|███▍      | 482/1380 [00:59<01:40,  8.94it/s] 35%|███▌      | 483/1380 [00:59<01:40,  8.92it/s] 35%|███▌      | 484/1380 [00:59<01:39,  9.05it/s] 35%|███▌      | 485/1380 [00:59<01:39,  9.02it/s] 35%|███▌      | 486/1380 [00:59<01:39,  8.97it/s] 35%|███▌      | 487/1380 [00:59<01:39,  9.00it/s] 35%|███▌      | 488/1380 [00:59<01:38,  9.03it/s] 35%|███▌      | 489/1380 [00:59<01:38,  9.03it/s] 36%|███▌      | 490/1380 [00:59<01:39,  8.98it/s] 36%|███▌      | 491/1380 [01:00<01:38,  9.02it/s] 36%|███▌      | 492/1380 [01:00<01:39,  8.95it/s] 36%|███▌      | 493/1380 [01:00<01:39,  8.96it/s] 36%|███▌      | 494/1380 [01:00<01:37,  9.06it/s] 36%|███▌      | 495/1380 [01:00<01:38,  8.98it/s] 36%|███▌      | 496/1380 [01:00<01:39,  8.88it/s] 36%|███▌      | 497/1380 [01:00<01:38,  8.92it/s] 36%|███▌      | 498/1380 [01:00<01:38,  8.97it/s] 36%|███▌      | 499/1380 [01:00<01:38,  8.95it/s] 36%|███▌      | 500/1380 [01:01<01:38,  8.92it/s] 36%|███▋      | 501/1380 [01:01<01:38,  8.95it/s] 36%|███▋      | 502/1380 [01:01<01:37,  8.96it/s] 36%|███▋      | 503/1380 [01:01<01:37,  9.00it/s] 37%|███▋      | 504/1380 [01:01<01:37,  9.03it/s] 37%|███▋      | 505/1380 [01:01<01:37,  9.01it/s] 37%|███▋      | 506/1380 [01:01<01:36,  9.03it/s] 37%|███▋      | 507/1380 [01:01<01:37,  8.98it/s] 37%|███▋      | 508/1380 [01:01<01:37,  8.96it/s] 37%|███▋      | 509/1380 [01:02<01:36,  8.99it/s] 37%|███▋      | 510/1380 [01:02<01:37,  8.95it/s] 37%|███▋      | 511/1380 [01:02<01:36,  9.02it/s] 37%|███▋      | 512/1380 [01:02<01:36,  9.02it/s] 37%|███▋      | 513/1380 [01:02<01:36,  9.00it/s] 37%|███▋      | 514/1380 [01:02<01:35,  9.08it/s] 37%|███▋      | 515/1380 [01:02<01:36,  8.96it/s] 37%|███▋      | 516/1380 [01:02<01:36,  8.97it/s] 37%|███▋      | 517/1380 [01:02<01:36,  8.96it/s] 38%|███▊      | 518/1380 [01:03<01:36,  8.92it/s] 38%|███▊      | 519/1380 [01:03<01:35,  8.98it/s] 38%|███▊      | 520/1380 [01:03<01:36,  8.93it/s] 38%|███▊      | 521/1380 [01:03<01:35,  8.99it/s] 38%|███▊      | 522/1380 [01:03<01:35,  8.98it/s] 38%|███▊      | 523/1380 [01:03<01:35,  8.97it/s] 38%|███▊      | 524/1380 [01:03<01:34,  9.04it/s] 38%|███▊      | 525/1380 [01:03<01:35,  8.98it/s] 38%|███▊      | 526/1380 [01:03<01:35,  8.95it/s] 38%|███▊      | 527/1380 [01:04<01:35,  8.93it/s] 38%|███▊      | 528/1380 [01:04<01:35,  8.95it/s] 38%|███▊      | 529/1380 [01:04<01:35,  8.94it/s] 38%|███▊      | 530/1380 [01:04<01:34,  8.97it/s] 38%|███▊      | 531/1380 [01:04<01:33,  9.04it/s] 39%|███▊      | 532/1380 [01:04<01:34,  8.99it/s] 39%|███▊      | 533/1380 [01:04<01:34,  8.97it/s] 39%|███▊      | 534/1380 [01:04<01:34,  8.98it/s] 39%|███▉      | 535/1380 [01:04<01:33,  9.02it/s] 39%|███▉      | 536/1380 [01:05<01:34,  8.94it/s] 39%|███▉      | 537/1380 [01:05<01:35,  8.84it/s] 39%|███▉      | 538/1380 [01:05<01:34,  8.91it/s] 39%|███▉      | 539/1380 [01:05<01:34,  8.93it/s] 39%|███▉      | 540/1380 [01:05<01:34,  8.93it/s] 39%|███▉      | 541/1380 [01:05<01:32,  9.07it/s] 39%|███▉      | 542/1380 [01:05<01:32,  9.02it/s] 39%|███▉      | 543/1380 [01:05<01:32,  9.00it/s] 39%|███▉      | 544/1380 [01:05<01:33,  8.98it/s] 39%|███▉      | 545/1380 [01:06<01:32,  9.03it/s] 40%|███▉      | 546/1380 [01:06<01:32,  8.97it/s] 40%|███▉      | 547/1380 [01:06<01:33,  8.95it/s] 40%|███▉      | 548/1380 [01:06<01:32,  9.01it/s] 40%|███▉      | 549/1380 [01:06<01:32,  9.00it/s] 40%|███▉      | 550/1380 [01:06<01:32,  9.00it/s] 40%|███▉      | 551/1380 [01:06<01:30,  9.11it/s]                                                   40%|████      | 552/1380 [01:06<01:30,  9.11it/s][INFO|trainer.py:755] 2023-11-15 19:38:48,057 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:38:48,059 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:38:48,060 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:38:48,060 >>   Batch size = 8
{'eval_loss': 0.3798580467700958, 'eval_accuracy': 0.8575317604355717, 'eval_micro_f1': 0.8575317604355718, 'eval_macro_f1': 0.8419269215350441, 'eval_runtime': 4.06, 'eval_samples_per_second': 542.857, 'eval_steps_per_second': 67.98, 'epoch': 1.0}
{'loss': 0.2849, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 79.04it/s][A
  6%|▌         | 17/276 [00:00<00:03, 73.45it/s][A
  9%|▉         | 25/276 [00:00<00:03, 73.65it/s][A
 12%|█▏        | 33/276 [00:00<00:03, 70.24it/s][A
 15%|█▍        | 41/276 [00:00<00:03, 69.13it/s][A
 18%|█▊        | 49/276 [00:00<00:03, 69.06it/s][A
 21%|██        | 57/276 [00:00<00:03, 70.59it/s][A
 24%|██▎       | 65/276 [00:00<00:03, 68.46it/s][A
 26%|██▋       | 73/276 [00:01<00:02, 70.06it/s][A
 29%|██▉       | 81/276 [00:01<00:02, 69.36it/s][A
 32%|███▏      | 89/276 [00:01<00:02, 70.30it/s][A
 35%|███▌      | 97/276 [00:01<00:02, 71.29it/s][A
 38%|███▊      | 105/276 [00:01<00:02, 69.25it/s][A
 41%|████      | 113/276 [00:01<00:02, 69.49it/s][A
 43%|████▎     | 120/276 [00:01<00:02, 69.10it/s][A
 46%|████▌     | 127/276 [00:01<00:02, 68.83it/s][A
 49%|████▉     | 135/276 [00:01<00:02, 70.08it/s][A
 52%|█████▏    | 143/276 [00:02<00:01, 68.44it/s][A
 55%|█████▍    | 151/276 [00:02<00:01, 70.78it/s][A
 58%|█████▊    | 159/276 [00:02<00:01, 69.59it/s][A
 60%|██████    | 166/276 [00:02<00:01, 68.86it/s][A
 63%|██████▎   | 173/276 [00:02<00:01, 68.77it/s][A
 66%|██████▌   | 181/276 [00:02<00:01, 69.95it/s][A
 68%|██████▊   | 188/276 [00:02<00:01, 67.42it/s][A
 71%|███████   | 195/276 [00:02<00:01, 67.22it/s][A
 74%|███████▎  | 203/276 [00:02<00:01, 68.94it/s][A
 76%|███████▌  | 210/276 [00:03<00:00, 68.27it/s][A
 79%|███████▉  | 218/276 [00:03<00:00, 68.62it/s][A
 82%|████████▏ | 226/276 [00:03<00:00, 69.69it/s][A
 84%|████████▍ | 233/276 [00:03<00:00, 68.46it/s][A
 87%|████████▋ | 240/276 [00:03<00:00, 68.07it/s][A
 89%|████████▉ | 247/276 [00:03<00:00, 68.13it/s][A
 92%|█████████▏| 255/276 [00:03<00:00, 68.69it/s][A
 95%|█████████▍| 262/276 [00:03<00:00, 68.24it/s][A
 97%|█████████▋| 269/276 [00:03<00:00, 67.87it/s][A                                                  
                                                 [A 40%|████      | 552/1380 [01:10<01:30,  9.11it/s]
100%|██████████| 276/276 [00:04<00:00, 67.87it/s][A
                                                 [A 40%|████      | 553/1380 [01:11<14:20,  1.04s/it] 40%|████      | 554/1380 [01:11<11:09,  1.23it/s] 40%|████      | 555/1380 [01:11<08:37,  1.59it/s] 40%|████      | 556/1380 [01:11<06:41,  2.05it/s] 40%|████      | 557/1380 [01:11<05:16,  2.60it/s] 40%|████      | 558/1380 [01:11<04:12,  3.26it/s] 41%|████      | 559/1380 [01:11<03:25,  3.99it/s] 41%|████      | 560/1380 [01:11<02:52,  4.77it/s] 41%|████      | 561/1380 [01:11<02:28,  5.52it/s] 41%|████      | 562/1380 [01:12<02:10,  6.26it/s] 41%|████      | 563/1380 [01:12<01:59,  6.83it/s] 41%|████      | 564/1380 [01:12<01:51,  7.31it/s] 41%|████      | 565/1380 [01:12<01:45,  7.73it/s] 41%|████      | 566/1380 [01:12<01:40,  8.10it/s] 41%|████      | 567/1380 [01:12<01:38,  8.24it/s] 41%|████      | 568/1380 [01:12<01:38,  8.28it/s] 41%|████      | 569/1380 [01:12<01:36,  8.44it/s] 41%|████▏     | 570/1380 [01:12<01:34,  8.56it/s] 41%|████▏     | 571/1380 [01:13<01:33,  8.62it/s] 41%|████▏     | 572/1380 [01:13<01:31,  8.79it/s] 42%|████▏     | 573/1380 [01:13<01:32,  8.75it/s] 42%|████▏     | 574/1380 [01:13<01:31,  8.79it/s] 42%|████▏     | 575/1380 [01:13<01:31,  8.83it/s] 42%|████▏     | 576/1380 [01:13<01:30,  8.89it/s] 42%|████▏     | 577/1380 [01:13<01:31,  8.81it/s] 42%|████▏     | 578/1380 [01:13<01:30,  8.82it/s] 42%|████▏     | 579/1380 [01:13<01:31,  8.78it/s] 42%|████▏     | 580/1380 [01:14<01:30,  8.88it/s] 42%|████▏     | 581/1380 [01:14<01:30,  8.84it/s] 42%|████▏     | 582/1380 [01:14<01:29,  8.96it/s] 42%|████▏     | 583/1380 [01:14<01:29,  8.92it/s] 42%|████▏     | 584/1380 [01:14<01:28,  8.95it/s] 42%|████▏     | 585/1380 [01:14<01:29,  8.90it/s] 42%|████▏     | 586/1380 [01:14<01:28,  8.93it/s] 43%|████▎     | 587/1380 [01:14<01:29,  8.84it/s] 43%|████▎     | 588/1380 [01:14<01:30,  8.78it/s] 43%|████▎     | 589/1380 [01:15<01:29,  8.80it/s] 43%|████▎     | 590/1380 [01:15<01:29,  8.84it/s] 43%|████▎     | 591/1380 [01:15<01:29,  8.78it/s] 43%|████▎     | 592/1380 [01:15<01:28,  8.91it/s] 43%|████▎     | 593/1380 [01:15<01:28,  8.87it/s] 43%|████▎     | 594/1380 [01:15<01:29,  8.82it/s] 43%|████▎     | 595/1380 [01:15<01:28,  8.87it/s] 43%|████▎     | 596/1380 [01:15<01:27,  8.92it/s] 43%|████▎     | 597/1380 [01:15<01:28,  8.85it/s] 43%|████▎     | 598/1380 [01:16<01:28,  8.88it/s] 43%|████▎     | 599/1380 [01:16<01:28,  8.85it/s] 43%|████▎     | 600/1380 [01:16<01:27,  8.88it/s] 44%|████▎     | 601/1380 [01:16<01:27,  8.90it/s] 44%|████▎     | 602/1380 [01:16<01:26,  9.04it/s] 44%|████▎     | 603/1380 [01:16<01:27,  8.93it/s] 44%|████▍     | 604/1380 [01:16<01:27,  8.85it/s] 44%|████▍     | 605/1380 [01:16<01:27,  8.89it/s] 44%|████▍     | 606/1380 [01:16<01:26,  8.96it/s] 44%|████▍     | 607/1380 [01:17<01:27,  8.85it/s] 44%|████▍     | 608/1380 [01:17<01:27,  8.83it/s] 44%|████▍     | 609/1380 [01:17<01:26,  8.87it/s] 44%|████▍     | 610/1380 [01:17<01:26,  8.89it/s] 44%|████▍     | 611/1380 [01:17<01:26,  8.92it/s] 44%|████▍     | 612/1380 [01:17<01:25,  8.96it/s] 44%|████▍     | 613/1380 [01:17<01:25,  8.94it/s] 44%|████▍     | 614/1380 [01:17<01:25,  8.92it/s] 45%|████▍     | 615/1380 [01:18<01:26,  8.89it/s] 45%|████▍     | 616/1380 [01:18<01:25,  8.90it/s] 45%|████▍     | 617/1380 [01:18<01:25,  8.95it/s] 45%|████▍     | 618/1380 [01:18<01:24,  8.97it/s] 45%|████▍     | 619/1380 [01:18<01:25,  8.93it/s] 45%|████▍     | 620/1380 [01:18<01:25,  8.91it/s] 45%|████▌     | 621/1380 [01:18<01:24,  8.98it/s] 45%|████▌     | 622/1380 [01:18<01:23,  9.03it/s] 45%|████▌     | 623/1380 [01:18<01:24,  8.98it/s] 45%|████▌     | 624/1380 [01:19<01:24,  8.93it/s] 45%|████▌     | 625/1380 [01:19<01:24,  8.91it/s] 45%|████▌     | 626/1380 [01:19<01:24,  8.95it/s] 45%|████▌     | 627/1380 [01:19<01:23,  8.97it/s] 46%|████▌     | 628/1380 [01:19<01:24,  8.90it/s] 46%|████▌     | 629/1380 [01:19<01:24,  8.92it/s] 46%|████▌     | 630/1380 [01:19<01:24,  8.85it/s] 46%|████▌     | 631/1380 [01:19<01:24,  8.88it/s] 46%|████▌     | 632/1380 [01:19<01:23,  8.95it/s] 46%|████▌     | 633/1380 [01:20<01:24,  8.88it/s] 46%|████▌     | 634/1380 [01:20<01:24,  8.86it/s] 46%|████▌     | 635/1380 [01:20<01:23,  8.88it/s] 46%|████▌     | 636/1380 [01:20<01:23,  8.93it/s] 46%|████▌     | 637/1380 [01:20<01:23,  8.92it/s] 46%|████▌     | 638/1380 [01:20<01:23,  8.86it/s] 46%|████▋     | 639/1380 [01:20<01:22,  8.93it/s] 46%|████▋     | 640/1380 [01:20<01:23,  8.91it/s] 46%|████▋     | 641/1380 [01:20<01:22,  8.91it/s] 47%|████▋     | 642/1380 [01:21<01:21,  9.03it/s] 47%|████▋     | 643/1380 [01:21<01:22,  8.90it/s] 47%|████▋     | 644/1380 [01:21<01:23,  8.86it/s] 47%|████▋     | 645/1380 [01:21<01:22,  8.91it/s] 47%|████▋     | 646/1380 [01:21<01:22,  8.92it/s] 47%|████▋     | 647/1380 [01:21<01:22,  8.89it/s] 47%|████▋     | 648/1380 [01:21<01:23,  8.81it/s] 47%|████▋     | 649/1380 [01:21<01:22,  8.91it/s] 47%|████▋     | 650/1380 [01:21<01:21,  8.91it/s] 47%|████▋     | 651/1380 [01:22<01:21,  8.90it/s] 47%|████▋     | 652/1380 [01:22<01:20,  9.03it/s] 47%|████▋     | 653/1380 [01:22<01:21,  8.91it/s] 47%|████▋     | 654/1380 [01:22<01:21,  8.91it/s] 47%|████▋     | 655/1380 [01:22<01:21,  8.91it/s] 48%|████▊     | 656/1380 [01:22<01:20,  8.94it/s] 48%|████▊     | 657/1380 [01:22<01:21,  8.92it/s] 48%|████▊     | 658/1380 [01:22<01:21,  8.89it/s] 48%|████▊     | 659/1380 [01:22<01:20,  8.98it/s] 48%|████▊     | 660/1380 [01:23<01:20,  8.90it/s] 48%|████▊     | 661/1380 [01:23<01:20,  8.88it/s] 48%|████▊     | 662/1380 [01:23<01:19,  9.01it/s] 48%|████▊     | 663/1380 [01:23<01:20,  8.89it/s] 48%|████▊     | 664/1380 [01:23<01:21,  8.84it/s] 48%|████▊     | 665/1380 [01:23<01:20,  8.87it/s] 48%|████▊     | 666/1380 [01:23<01:19,  8.93it/s] 48%|████▊     | 667/1380 [01:23<01:20,  8.89it/s] 48%|████▊     | 668/1380 [01:23<01:20,  8.87it/s] 48%|████▊     | 669/1380 [01:24<01:19,  8.94it/s] 49%|████▊     | 670/1380 [01:24<01:19,  8.94it/s] 49%|████▊     | 671/1380 [01:24<01:19,  8.92it/s] 49%|████▊     | 672/1380 [01:24<01:18,  9.01it/s] 49%|████▉     | 673/1380 [01:24<01:19,  8.90it/s] 49%|████▉     | 674/1380 [01:24<01:19,  8.84it/s] 49%|████▉     | 675/1380 [01:24<01:19,  8.81it/s] 49%|████▉     | 676/1380 [01:24<01:19,  8.86it/s] 49%|████▉     | 677/1380 [01:24<01:19,  8.86it/s] 49%|████▉     | 678/1380 [01:25<01:19,  8.84it/s] 49%|████▉     | 679/1380 [01:25<01:19,  8.81it/s] 49%|████▉     | 680/1380 [01:25<01:19,  8.82it/s] 49%|████▉     | 681/1380 [01:25<01:18,  8.88it/s] 49%|████▉     | 682/1380 [01:25<01:17,  8.95it/s] 49%|████▉     | 683/1380 [01:25<01:18,  8.89it/s] 50%|████▉     | 684/1380 [01:25<01:18,  8.89it/s] 50%|████▉     | 685/1380 [01:25<01:18,  8.88it/s] 50%|████▉     | 686/1380 [01:25<01:17,  8.97it/s] 50%|████▉     | 687/1380 [01:26<01:17,  8.92it/s] 50%|████▉     | 688/1380 [01:26<01:17,  8.88it/s] 50%|████▉     | 689/1380 [01:26<01:17,  8.89it/s] 50%|█████     | 690/1380 [01:26<01:17,  8.93it/s] 50%|█████     | 691/1380 [01:26<01:17,  8.95it/s] 50%|█████     | 692/1380 [01:26<01:16,  8.99it/s] 50%|█████     | 693/1380 [01:26<01:17,  8.89it/s] 50%|█████     | 694/1380 [01:26<01:17,  8.88it/s] 50%|█████     | 695/1380 [01:26<01:16,  8.90it/s] 50%|█████     | 696/1380 [01:27<01:16,  8.93it/s] 51%|█████     | 697/1380 [01:27<01:16,  8.89it/s] 51%|█████     | 698/1380 [01:27<01:16,  8.88it/s] 51%|█████     | 699/1380 [01:27<01:17,  8.84it/s] 51%|█████     | 700/1380 [01:27<01:17,  8.83it/s] 51%|█████     | 701/1380 [01:27<01:16,  8.91it/s] 51%|█████     | 702/1380 [01:27<01:15,  8.98it/s] 51%|█████     | 703/1380 [01:27<01:16,  8.90it/s] 51%|█████     | 704/1380 [01:28<01:16,  8.89it/s] 51%|█████     | 705/1380 [01:28<01:16,  8.87it/s] 51%|█████     | 706/1380 [01:28<01:15,  8.92it/s] 51%|█████     | 707/1380 [01:28<01:15,  8.86it/s] 51%|█████▏    | 708/1380 [01:28<01:16,  8.79it/s] 51%|█████▏    | 709/1380 [01:28<01:16,  8.80it/s] 51%|█████▏    | 710/1380 [01:28<01:15,  8.86it/s] 52%|█████▏    | 711/1380 [01:28<01:15,  8.86it/s] 52%|█████▏    | 712/1380 [01:28<01:14,  8.95it/s] 52%|█████▏    | 713/1380 [01:29<01:15,  8.84it/s] 52%|█████▏    | 714/1380 [01:29<01:14,  8.91it/s] 52%|█████▏    | 715/1380 [01:29<01:14,  8.94it/s] 52%|█████▏    | 716/1380 [01:29<01:14,  8.91it/s] 52%|█████▏    | 717/1380 [01:29<01:15,  8.83it/s] 52%|█████▏    | 718/1380 [01:29<01:15,  8.82it/s] 52%|█████▏    | 719/1380 [01:29<01:15,  8.81it/s] 52%|█████▏    | 720/1380 [01:29<01:14,  8.88it/s] 52%|█████▏    | 721/1380 [01:29<01:14,  8.81it/s] 52%|█████▏    | 722/1380 [01:30<01:13,  8.92it/s] 52%|█████▏    | 723/1380 [01:30<01:14,  8.83it/s] 52%|█████▏    | 724/1380 [01:30<01:13,  8.89it/s] 53%|█████▎    | 725/1380 [01:30<01:13,  8.92it/s] 53%|█████▎    | 726/1380 [01:30<01:13,  8.95it/s] 53%|█████▎    | 727/1380 [01:30<01:13,  8.90it/s] 53%|█████▎    | 728/1380 [01:30<01:13,  8.89it/s] 53%|█████▎    | 729/1380 [01:30<01:13,  8.89it/s] 53%|█████▎    | 730/1380 [01:30<01:13,  8.89it/s] 53%|█████▎    | 731/1380 [01:31<01:12,  8.93it/s] 53%|█████▎    | 732/1380 [01:31<01:11,  9.05it/s] 53%|█████▎    | 733/1380 [01:31<01:12,  8.93it/s] 53%|█████▎    | 734/1380 [01:31<01:12,  8.94it/s] 53%|█████▎    | 735/1380 [01:31<01:12,  8.92it/s] 53%|█████▎    | 736/1380 [01:31<01:11,  8.94it/s] 53%|█████▎    | 737/1380 [01:31<01:12,  8.84it/s] 53%|█████▎    | 738/1380 [01:31<01:12,  8.82it/s] 54%|█████▎    | 739/1380 [01:31<01:12,  8.80it/s] 54%|█████▎    | 740/1380 [01:32<01:12,  8.84it/s] 54%|█████▎    | 741/1380 [01:32<01:12,  8.83it/s] 54%|█████▍    | 742/1380 [01:32<01:11,  8.93it/s] 54%|█████▍    | 743/1380 [01:32<01:12,  8.79it/s] 54%|█████▍    | 744/1380 [01:32<01:11,  8.87it/s] 54%|█████▍    | 745/1380 [01:32<01:11,  8.90it/s] 54%|█████▍    | 746/1380 [01:32<01:10,  8.94it/s] 54%|█████▍    | 747/1380 [01:32<01:11,  8.85it/s] 54%|█████▍    | 748/1380 [01:32<01:11,  8.82it/s] 54%|█████▍    | 749/1380 [01:33<01:11,  8.77it/s] 54%|█████▍    | 750/1380 [01:33<01:11,  8.82it/s] 54%|█████▍    | 751/1380 [01:33<01:12,  8.74it/s] 54%|█████▍    | 752/1380 [01:33<01:10,  8.89it/s] 55%|█████▍    | 753/1380 [01:33<01:10,  8.85it/s] 55%|█████▍    | 754/1380 [01:33<01:10,  8.88it/s] 55%|█████▍    | 755/1380 [01:33<01:09,  8.96it/s] 55%|█████▍    | 756/1380 [01:33<01:10,  8.91it/s] 55%|█████▍    | 757/1380 [01:33<01:10,  8.89it/s] 55%|█████▍    | 758/1380 [01:34<01:09,  8.90it/s] 55%|█████▌    | 759/1380 [01:34<01:09,  8.89it/s] 55%|█████▌    | 760/1380 [01:34<01:09,  8.97it/s] 55%|█████▌    | 761/1380 [01:34<01:09,  8.88it/s] 55%|█████▌    | 762/1380 [01:34<01:09,  8.94it/s] 55%|█████▌    | 763/1380 [01:34<01:09,  8.90it/s] 55%|█████▌    | 764/1380 [01:34<01:09,  8.90it/s] 55%|█████▌    | 765/1380 [01:34<01:08,  9.01it/s] 56%|█████▌    | 766/1380 [01:34<01:08,  8.98it/s] 56%|█████▌    | 767/1380 [01:35<01:08,  8.89it/s] 56%|█████▌    | 768/1380 [01:35<01:08,  8.90it/s] 56%|█████▌    | 769/1380 [01:35<01:08,  8.88it/s] 56%|█████▌    | 770/1380 [01:35<01:08,  8.90it/s] 56%|█████▌    | 771/1380 [01:35<01:09,  8.80it/s] 56%|█████▌    | 772/1380 [01:35<01:08,  8.88it/s] 56%|█████▌    | 773/1380 [01:35<01:08,  8.83it/s] 56%|█████▌    | 774/1380 [01:35<01:08,  8.86it/s] 56%|█████▌    | 775/1380 [01:35<01:07,  8.98it/s] 56%|█████▌    | 776/1380 [01:36<01:08,  8.78it/s] 56%|█████▋    | 777/1380 [01:36<01:08,  8.77it/s] 56%|█████▋    | 778/1380 [01:36<01:08,  8.78it/s] 56%|█████▋    | 779/1380 [01:36<01:08,  8.83it/s] 57%|█████▋    | 780/1380 [01:36<01:08,  8.82it/s] 57%|█████▋    | 781/1380 [01:36<01:07,  8.83it/s] 57%|█████▋    | 782/1380 [01:36<01:07,  8.88it/s] 57%|█████▋    | 783/1380 [01:36<01:07,  8.88it/s] 57%|█████▋    | 784/1380 [01:37<01:07,  8.86it/s] 57%|█████▋    | 785/1380 [01:37<01:06,  8.94it/s] 57%|█████▋    | 786/1380 [01:37<01:06,  8.87it/s] 57%|█████▋    | 787/1380 [01:37<01:06,  8.88it/s] 57%|█████▋    | 788/1380 [01:37<01:06,  8.90it/s] 57%|█████▋    | 789/1380 [01:37<01:06,  8.94it/s] 57%|█████▋    | 790/1380 [01:37<01:06,  8.83it/s] 57%|█████▋    | 791/1380 [01:37<01:07,  8.78it/s] 57%|█████▋    | 792/1380 [01:37<01:07,  8.73it/s] 57%|█████▋    | 793/1380 [01:38<01:06,  8.81it/s] 58%|█████▊    | 794/1380 [01:38<01:06,  8.79it/s] 58%|█████▊    | 795/1380 [01:38<01:05,  8.90it/s] 58%|█████▊    | 796/1380 [01:38<01:06,  8.85it/s] 58%|█████▊    | 797/1380 [01:38<01:05,  8.97it/s] 58%|█████▊    | 798/1380 [01:38<01:04,  8.99it/s] 58%|█████▊    | 799/1380 [01:38<01:05,  8.87it/s] 58%|█████▊    | 800/1380 [01:38<01:05,  8.86it/s] 58%|█████▊    | 801/1380 [01:38<01:05,  8.87it/s] 58%|█████▊    | 802/1380 [01:39<01:05,  8.89it/s] 58%|█████▊    | 803/1380 [01:39<01:04,  8.96it/s] 58%|█████▊    | 804/1380 [01:39<01:05,  8.82it/s] 58%|█████▊    | 805/1380 [01:39<01:04,  8.88it/s] 58%|█████▊    | 806/1380 [01:39<01:04,  8.88it/s] 58%|█████▊    | 807/1380 [01:39<01:04,  8.92it/s] 59%|█████▊    | 808/1380 [01:39<01:03,  8.97it/s] 59%|█████▊    | 809/1380 [01:39<01:04,  8.89it/s] 59%|█████▊    | 810/1380 [01:39<01:03,  8.91it/s] 59%|█████▉    | 811/1380 [01:40<01:03,  8.92it/s] 59%|█████▉    | 812/1380 [01:40<01:03,  8.93it/s] 59%|█████▉    | 813/1380 [01:40<01:03,  8.95it/s] 59%|█████▉    | 814/1380 [01:40<01:03,  8.87it/s] 59%|█████▉    | 815/1380 [01:40<01:03,  8.94it/s] 59%|█████▉    | 816/1380 [01:40<01:03,  8.87it/s] 59%|█████▉    | 817/1380 [01:40<01:03,  8.84it/s] 59%|█████▉    | 818/1380 [01:40<01:02,  8.97it/s] 59%|█████▉    | 819/1380 [01:40<01:02,  8.91it/s] 59%|█████▉    | 820/1380 [01:41<01:03,  8.83it/s] 59%|█████▉    | 821/1380 [01:41<01:03,  8.82it/s] 60%|█████▉    | 822/1380 [01:41<01:02,  8.87it/s] 60%|█████▉    | 823/1380 [01:41<01:03,  8.82it/s] 60%|█████▉    | 824/1380 [01:41<01:03,  8.81it/s] 60%|█████▉    | 825/1380 [01:41<01:02,  8.88it/s] 60%|█████▉    | 826/1380 [01:41<01:02,  8.83it/s] 60%|█████▉    | 827/1380 [01:41<01:02,  8.88it/s]                                                   60%|██████    | 828/1380 [01:41<01:02,  8.88it/s][INFO|trainer.py:755] 2023-11-15 19:39:23,149 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:39:23,151 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:39:23,151 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:39:23,151 >>   Batch size = 8
{'eval_loss': 0.39256373047828674, 'eval_accuracy': 0.8661524500907442, 'eval_micro_f1': 0.8661524500907442, 'eval_macro_f1': 0.8460045681595395, 'eval_runtime': 4.0535, 'eval_samples_per_second': 543.724, 'eval_steps_per_second': 68.089, 'epoch': 2.0}
{'loss': 0.193, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 8/276 [00:00<00:03, 75.39it/s][A
  6%|▌         | 16/276 [00:00<00:03, 71.42it/s][A
  9%|▊         | 24/276 [00:00<00:03, 69.71it/s][A
 11%|█         | 31/276 [00:00<00:03, 69.47it/s][A
 14%|█▍        | 38/276 [00:00<00:03, 69.12it/s][A
 16%|█▋        | 45/276 [00:00<00:03, 67.22it/s][A
 19%|█▉        | 53/276 [00:00<00:03, 68.54it/s][A
 22%|██▏       | 60/276 [00:00<00:03, 68.51it/s][A
 24%|██▍       | 67/276 [00:00<00:03, 67.92it/s][A
 27%|██▋       | 74/276 [00:01<00:02, 67.40it/s][A
 29%|██▉       | 81/276 [00:01<00:02, 67.66it/s][A
 32%|███▏      | 88/276 [00:01<00:02, 67.91it/s][A
 34%|███▍      | 95/276 [00:01<00:02, 67.78it/s][A
 37%|███▋      | 103/276 [00:01<00:02, 69.17it/s][A
 40%|███▉      | 110/276 [00:01<00:02, 67.86it/s][A
 42%|████▏     | 117/276 [00:01<00:02, 67.31it/s][A
 45%|████▍     | 124/276 [00:01<00:02, 66.92it/s][A
 47%|████▋     | 131/276 [00:01<00:02, 66.87it/s][A
 50%|█████     | 138/276 [00:02<00:02, 67.31it/s][A
 53%|█████▎    | 145/276 [00:02<00:01, 66.63it/s][A
 55%|█████▌    | 153/276 [00:02<00:01, 67.59it/s][A
 58%|█████▊    | 160/276 [00:02<00:01, 66.77it/s][A
 61%|██████    | 167/276 [00:02<00:01, 66.11it/s][A
 63%|██████▎   | 174/276 [00:02<00:01, 66.57it/s][A
 66%|██████▌   | 182/276 [00:02<00:01, 66.62it/s][A
 68%|██████▊   | 189/276 [00:02<00:01, 67.12it/s][A
 71%|███████   | 196/276 [00:02<00:01, 67.25it/s][A
 74%|███████▍  | 204/276 [00:03<00:01, 68.79it/s][A
 76%|███████▋  | 211/276 [00:03<00:00, 67.33it/s][A
 79%|███████▉  | 218/276 [00:03<00:00, 67.29it/s][A
 82%|████████▏ | 225/276 [00:03<00:00, 66.93it/s][A
 84%|████████▍ | 232/276 [00:03<00:00, 67.29it/s][A
 87%|████████▋ | 239/276 [00:03<00:00, 67.37it/s][A
 89%|████████▉ | 246/276 [00:03<00:00, 67.66it/s][A
 92%|█████████▏| 253/276 [00:03<00:00, 67.48it/s][A
 94%|█████████▍| 260/276 [00:03<00:00, 67.16it/s][A
 97%|█████████▋| 267/276 [00:03<00:00, 65.49it/s][A
 99%|█████████▉| 274/276 [00:04<00:00, 65.68it/s][A                                                  
                                                 [A 60%|██████    | 828/1380 [01:46<01:02,  8.88it/s]
100%|██████████| 276/276 [00:04<00:00, 65.68it/s][A
                                                 [A 60%|██████    | 829/1380 [01:46<09:47,  1.07s/it] 60%|██████    | 830/1380 [01:46<07:36,  1.20it/s] 60%|██████    | 831/1380 [01:46<05:53,  1.56it/s] 60%|██████    | 832/1380 [01:46<04:33,  2.01it/s] 60%|██████    | 833/1380 [01:46<03:33,  2.56it/s] 60%|██████    | 834/1380 [01:46<02:50,  3.21it/s] 61%|██████    | 835/1380 [01:46<02:18,  3.94it/s] 61%|██████    | 836/1380 [01:47<01:56,  4.69it/s] 61%|██████    | 837/1380 [01:47<01:39,  5.47it/s] 61%|██████    | 838/1380 [01:47<01:27,  6.22it/s] 61%|██████    | 839/1380 [01:47<01:19,  6.82it/s] 61%|██████    | 840/1380 [01:47<01:14,  7.29it/s] 61%|██████    | 841/1380 [01:47<01:10,  7.69it/s] 61%|██████    | 842/1380 [01:47<01:07,  8.01it/s] 61%|██████    | 843/1380 [01:47<01:05,  8.20it/s] 61%|██████    | 844/1380 [01:47<01:04,  8.37it/s] 61%|██████    | 845/1380 [01:48<01:02,  8.53it/s] 61%|██████▏   | 846/1380 [01:48<01:01,  8.66it/s] 61%|██████▏   | 847/1380 [01:48<01:01,  8.72it/s] 61%|██████▏   | 848/1380 [01:48<00:59,  8.90it/s] 62%|██████▏   | 849/1380 [01:48<01:00,  8.82it/s] 62%|██████▏   | 850/1380 [01:48<01:00,  8.78it/s] 62%|██████▏   | 851/1380 [01:48<00:59,  8.84it/s] 62%|██████▏   | 852/1380 [01:48<00:59,  8.87it/s] 62%|██████▏   | 853/1380 [01:48<00:59,  8.86it/s] 62%|██████▏   | 854/1380 [01:49<00:59,  8.81it/s] 62%|██████▏   | 855/1380 [01:49<00:59,  8.85it/s] 62%|██████▏   | 856/1380 [01:49<00:59,  8.83it/s] 62%|██████▏   | 857/1380 [01:49<00:59,  8.86it/s] 62%|██████▏   | 858/1380 [01:49<00:58,  8.98it/s] 62%|██████▏   | 859/1380 [01:49<00:58,  8.91it/s] 62%|██████▏   | 860/1380 [01:49<00:58,  8.85it/s] 62%|██████▏   | 861/1380 [01:49<00:58,  8.84it/s] 62%|██████▏   | 862/1380 [01:49<00:58,  8.89it/s] 63%|██████▎   | 863/1380 [01:50<00:58,  8.89it/s] 63%|██████▎   | 864/1380 [01:50<00:58,  8.84it/s] 63%|██████▎   | 865/1380 [01:50<00:57,  8.93it/s] 63%|██████▎   | 866/1380 [01:50<00:57,  8.88it/s] 63%|██████▎   | 867/1380 [01:50<00:57,  8.91it/s] 63%|██████▎   | 868/1380 [01:50<00:56,  9.00it/s] 63%|██████▎   | 869/1380 [01:50<00:57,  8.91it/s] 63%|██████▎   | 870/1380 [01:50<00:57,  8.86it/s] 63%|██████▎   | 871/1380 [01:50<00:57,  8.79it/s] 63%|██████▎   | 872/1380 [01:51<00:57,  8.83it/s] 63%|██████▎   | 873/1380 [01:51<00:57,  8.84it/s] 63%|██████▎   | 874/1380 [01:51<00:57,  8.80it/s] 63%|██████▎   | 875/1380 [01:51<00:56,  8.89it/s] 63%|██████▎   | 876/1380 [01:51<00:57,  8.82it/s] 64%|██████▎   | 877/1380 [01:51<00:56,  8.85it/s] 64%|██████▎   | 878/1380 [01:51<00:55,  8.98it/s] 64%|██████▎   | 879/1380 [01:51<00:56,  8.90it/s] 64%|██████▍   | 880/1380 [01:51<00:56,  8.93it/s] 64%|██████▍   | 881/1380 [01:52<00:55,  8.95it/s] 64%|██████▍   | 882/1380 [01:52<00:55,  8.93it/s] 64%|██████▍   | 883/1380 [01:52<00:55,  8.96it/s] 64%|██████▍   | 884/1380 [01:52<00:55,  8.86it/s] 64%|██████▍   | 885/1380 [01:52<00:55,  8.91it/s] 64%|██████▍   | 886/1380 [01:52<00:55,  8.94it/s] 64%|██████▍   | 887/1380 [01:52<00:55,  8.92it/s] 64%|██████▍   | 888/1380 [01:52<00:54,  9.05it/s] 64%|██████▍   | 889/1380 [01:52<00:54,  8.95it/s] 64%|██████▍   | 890/1380 [01:53<00:54,  8.93it/s] 65%|██████▍   | 891/1380 [01:53<00:54,  8.91it/s] 65%|██████▍   | 892/1380 [01:53<00:54,  8.91it/s] 65%|██████▍   | 893/1380 [01:53<00:54,  8.97it/s] 65%|██████▍   | 894/1380 [01:53<00:54,  8.86it/s] 65%|██████▍   | 895/1380 [01:53<00:54,  8.98it/s] 65%|██████▍   | 896/1380 [01:53<00:54,  8.88it/s] 65%|██████▌   | 897/1380 [01:53<00:54,  8.89it/s] 65%|██████▌   | 898/1380 [01:53<00:53,  8.99it/s] 65%|██████▌   | 899/1380 [01:54<00:54,  8.88it/s] 65%|██████▌   | 900/1380 [01:54<00:54,  8.87it/s] 65%|██████▌   | 901/1380 [01:54<00:53,  8.89it/s] 65%|██████▌   | 902/1380 [01:54<00:53,  8.87it/s] 65%|██████▌   | 903/1380 [01:54<00:53,  8.91it/s] 66%|██████▌   | 904/1380 [01:54<00:53,  8.85it/s] 66%|██████▌   | 905/1380 [01:54<00:53,  8.89it/s] 66%|██████▌   | 906/1380 [01:54<00:53,  8.86it/s] 66%|██████▌   | 907/1380 [01:54<00:53,  8.87it/s] 66%|██████▌   | 908/1380 [01:55<00:53,  8.84it/s] 66%|██████▌   | 909/1380 [01:55<00:53,  8.83it/s] 66%|██████▌   | 910/1380 [01:55<00:53,  8.79it/s] 66%|██████▌   | 911/1380 [01:55<00:53,  8.69it/s] 66%|██████▌   | 912/1380 [01:55<00:53,  8.70it/s] 66%|██████▌   | 913/1380 [01:55<00:53,  8.76it/s] 66%|██████▌   | 914/1380 [01:55<00:53,  8.78it/s] 66%|██████▋   | 915/1380 [01:55<00:52,  8.93it/s] 66%|██████▋   | 916/1380 [01:56<00:52,  8.88it/s] 66%|██████▋   | 917/1380 [01:56<00:51,  8.94it/s] 67%|██████▋   | 918/1380 [01:56<00:51,  8.89it/s] 67%|██████▋   | 919/1380 [01:56<00:51,  8.88it/s] 67%|██████▋   | 920/1380 [01:56<00:51,  8.90it/s] 67%|██████▋   | 921/1380 [01:56<00:52,  8.80it/s] 67%|██████▋   | 922/1380 [01:56<00:51,  8.89it/s] 67%|██████▋   | 923/1380 [01:56<00:51,  8.85it/s] 67%|██████▋   | 924/1380 [01:56<00:51,  8.84it/s] 67%|██████▋   | 925/1380 [01:57<00:50,  8.95it/s] 67%|██████▋   | 926/1380 [01:57<00:50,  8.99it/s] 67%|██████▋   | 927/1380 [01:57<00:50,  8.91it/s] 67%|██████▋   | 928/1380 [01:57<00:51,  8.81it/s] 67%|██████▋   | 929/1380 [01:57<00:51,  8.78it/s] 67%|██████▋   | 930/1380 [01:57<00:51,  8.81it/s] 67%|██████▋   | 931/1380 [01:57<00:50,  8.81it/s] 68%|██████▊   | 932/1380 [01:57<00:50,  8.91it/s] 68%|██████▊   | 933/1380 [01:57<00:50,  8.88it/s] 68%|██████▊   | 934/1380 [01:58<00:50,  8.84it/s] 68%|██████▊   | 935/1380 [01:58<00:50,  8.85it/s] 68%|██████▊   | 936/1380 [01:58<00:49,  8.89it/s] 68%|██████▊   | 937/1380 [01:58<00:49,  8.86it/s] 68%|██████▊   | 938/1380 [01:58<00:49,  8.85it/s] 68%|██████▊   | 939/1380 [01:58<00:49,  8.89it/s] 68%|██████▊   | 940/1380 [01:58<00:49,  8.83it/s] 68%|██████▊   | 941/1380 [01:58<00:49,  8.87it/s] 68%|██████▊   | 942/1380 [01:58<00:48,  8.96it/s] 68%|██████▊   | 943/1380 [01:59<00:49,  8.87it/s] 68%|██████▊   | 944/1380 [01:59<00:49,  8.83it/s] 68%|██████▊   | 945/1380 [01:59<00:49,  8.85it/s] 69%|██████▊   | 946/1380 [01:59<00:48,  8.86it/s] 69%|██████▊   | 947/1380 [01:59<00:48,  8.91it/s] 69%|██████▊   | 948/1380 [01:59<00:49,  8.78it/s] 69%|██████▉   | 949/1380 [01:59<00:48,  8.84it/s] 69%|██████▉   | 950/1380 [01:59<00:48,  8.89it/s] 69%|██████▉   | 951/1380 [01:59<00:48,  8.78it/s] 69%|██████▉   | 952/1380 [02:00<00:48,  8.89it/s] 69%|██████▉   | 953/1380 [02:00<00:47,  8.91it/s] 69%|██████▉   | 954/1380 [02:00<00:48,  8.80it/s] 69%|██████▉   | 955/1380 [02:00<00:48,  8.79it/s] 69%|██████▉   | 956/1380 [02:00<00:48,  8.79it/s] 69%|██████▉   | 957/1380 [02:00<00:47,  8.83it/s] 69%|██████▉   | 958/1380 [02:00<00:47,  8.84it/s] 69%|██████▉   | 959/1380 [02:00<00:46,  8.97it/s] 70%|██████▉   | 960/1380 [02:00<00:47,  8.87it/s] 70%|██████▉   | 961/1380 [02:01<00:47,  8.84it/s] 70%|██████▉   | 962/1380 [02:01<00:47,  8.82it/s] 70%|██████▉   | 963/1380 [02:01<00:46,  8.88it/s] 70%|██████▉   | 964/1380 [02:01<00:47,  8.83it/s] 70%|██████▉   | 965/1380 [02:01<00:47,  8.81it/s] 70%|███████   | 966/1380 [02:01<00:47,  8.80it/s] 70%|███████   | 967/1380 [02:01<00:47,  8.75it/s] 70%|███████   | 968/1380 [02:01<00:46,  8.83it/s] 70%|███████   | 969/1380 [02:01<00:45,  8.95it/s] 70%|███████   | 970/1380 [02:02<00:46,  8.82it/s] 70%|███████   | 971/1380 [02:02<00:46,  8.76it/s] 70%|███████   | 972/1380 [02:02<00:46,  8.78it/s] 71%|███████   | 973/1380 [02:02<00:46,  8.82it/s] 71%|███████   | 974/1380 [02:02<00:46,  8.81it/s] 71%|███████   | 975/1380 [02:02<00:46,  8.75it/s] 71%|███████   | 976/1380 [02:02<00:45,  8.81it/s] 71%|███████   | 977/1380 [02:02<00:45,  8.77it/s] 71%|███████   | 978/1380 [02:03<00:45,  8.82it/s] 71%|███████   | 979/1380 [02:03<00:45,  8.90it/s] 71%|███████   | 980/1380 [02:03<00:45,  8.84it/s] 71%|███████   | 981/1380 [02:03<00:45,  8.78it/s] 71%|███████   | 982/1380 [02:03<00:45,  8.76it/s] 71%|███████   | 983/1380 [02:03<00:45,  8.78it/s] 71%|███████▏  | 984/1380 [02:03<00:44,  8.84it/s] 71%|███████▏  | 985/1380 [02:03<00:44,  8.79it/s] 71%|███████▏  | 986/1380 [02:03<00:44,  8.89it/s] 72%|███████▏  | 987/1380 [02:04<00:44,  8.87it/s] 72%|███████▏  | 988/1380 [02:04<00:44,  8.79it/s] 72%|███████▏  | 989/1380 [02:04<00:44,  8.81it/s] 72%|███████▏  | 990/1380 [02:04<00:44,  8.80it/s] 72%|███████▏  | 991/1380 [02:04<00:44,  8.74it/s] 72%|███████▏  | 992/1380 [02:04<00:44,  8.78it/s] 72%|███████▏  | 993/1380 [02:04<00:43,  8.82it/s] 72%|███████▏  | 994/1380 [02:04<00:43,  8.79it/s] 72%|███████▏  | 995/1380 [02:04<00:43,  8.83it/s] 72%|███████▏  | 996/1380 [02:05<00:42,  8.98it/s] 72%|███████▏  | 997/1380 [02:05<00:43,  8.88it/s] 72%|███████▏  | 998/1380 [02:05<00:43,  8.86it/s] 72%|███████▏  | 999/1380 [02:05<00:43,  8.81it/s] 72%|███████▏  | 1000/1380 [02:05<00:43,  8.83it/s] 73%|███████▎  | 1001/1380 [02:05<00:42,  8.83it/s] 73%|███████▎  | 1002/1380 [02:05<00:43,  8.79it/s] 73%|███████▎  | 1003/1380 [02:05<00:42,  8.84it/s] 73%|███████▎  | 1004/1380 [02:05<00:42,  8.81it/s] 73%|███████▎  | 1005/1380 [02:06<00:42,  8.75it/s] 73%|███████▎  | 1006/1380 [02:06<00:42,  8.83it/s] 73%|███████▎  | 1007/1380 [02:06<00:42,  8.85it/s] 73%|███████▎  | 1008/1380 [02:06<00:42,  8.80it/s] 73%|███████▎  | 1009/1380 [02:06<00:42,  8.74it/s] 73%|███████▎  | 1010/1380 [02:06<00:42,  8.74it/s] 73%|███████▎  | 1011/1380 [02:06<00:41,  8.79it/s] 73%|███████▎  | 1012/1380 [02:06<00:41,  8.77it/s] 73%|███████▎  | 1013/1380 [02:06<00:41,  8.90it/s] 73%|███████▎  | 1014/1380 [02:07<00:41,  8.86it/s] 74%|███████▎  | 1015/1380 [02:07<00:41,  8.80it/s] 74%|███████▎  | 1016/1380 [02:07<00:41,  8.82it/s] 74%|███████▎  | 1017/1380 [02:07<00:41,  8.84it/s] 74%|███████▍  | 1018/1380 [02:07<00:40,  8.86it/s] 74%|███████▍  | 1019/1380 [02:07<00:40,  8.81it/s] 74%|███████▍  | 1020/1380 [02:07<00:40,  8.90it/s] 74%|███████▍  | 1021/1380 [02:07<00:40,  8.80it/s] 74%|███████▍  | 1022/1380 [02:08<00:40,  8.81it/s] 74%|███████▍  | 1023/1380 [02:08<00:40,  8.90it/s] 74%|███████▍  | 1024/1380 [02:08<00:40,  8.87it/s] 74%|███████▍  | 1025/1380 [02:08<00:40,  8.83it/s] 74%|███████▍  | 1026/1380 [02:08<00:40,  8.83it/s] 74%|███████▍  | 1027/1380 [02:08<00:40,  8.78it/s] 74%|███████▍  | 1028/1380 [02:08<00:39,  8.83it/s] 75%|███████▍  | 1029/1380 [02:08<00:39,  8.80it/s] 75%|███████▍  | 1030/1380 [02:08<00:39,  8.87it/s] 75%|███████▍  | 1031/1380 [02:09<00:39,  8.85it/s] 75%|███████▍  | 1032/1380 [02:09<00:39,  8.90it/s] 75%|███████▍  | 1033/1380 [02:09<00:39,  8.88it/s] 75%|███████▍  | 1034/1380 [02:09<00:39,  8.87it/s] 75%|███████▌  | 1035/1380 [02:09<00:39,  8.84it/s] 75%|███████▌  | 1036/1380 [02:09<00:38,  8.84it/s] 75%|███████▌  | 1037/1380 [02:09<00:38,  8.84it/s] 75%|███████▌  | 1038/1380 [02:09<00:38,  8.83it/s] 75%|███████▌  | 1039/1380 [02:09<00:38,  8.85it/s] 75%|███████▌  | 1040/1380 [02:10<00:37,  8.99it/s] 75%|███████▌  | 1041/1380 [02:10<00:38,  8.88it/s] 76%|███████▌  | 1042/1380 [02:10<00:38,  8.86it/s] 76%|███████▌  | 1043/1380 [02:10<00:37,  8.87it/s] 76%|███████▌  | 1044/1380 [02:10<00:37,  8.87it/s] 76%|███████▌  | 1045/1380 [02:10<00:37,  8.85it/s] 76%|███████▌  | 1046/1380 [02:10<00:37,  8.80it/s] 76%|███████▌  | 1047/1380 [02:10<00:37,  8.85it/s] 76%|███████▌  | 1048/1380 [02:10<00:37,  8.81it/s] 76%|███████▌  | 1049/1380 [02:11<00:37,  8.88it/s] 76%|███████▌  | 1050/1380 [02:11<00:36,  9.02it/s] 76%|███████▌  | 1051/1380 [02:11<00:36,  8.94it/s] 76%|███████▌  | 1052/1380 [02:11<00:36,  8.89it/s] 76%|███████▋  | 1053/1380 [02:11<00:37,  8.84it/s] 76%|███████▋  | 1054/1380 [02:11<00:36,  8.85it/s] 76%|███████▋  | 1055/1380 [02:11<00:36,  8.91it/s] 77%|███████▋  | 1056/1380 [02:11<00:36,  8.89it/s] 77%|███████▋  | 1057/1380 [02:11<00:35,  8.98it/s] 77%|███████▋  | 1058/1380 [02:12<00:36,  8.87it/s] 77%|███████▋  | 1059/1380 [02:12<00:36,  8.90it/s] 77%|███████▋  | 1060/1380 [02:12<00:35,  8.98it/s] 77%|███████▋  | 1061/1380 [02:12<00:36,  8.86it/s] 77%|███████▋  | 1062/1380 [02:12<00:35,  8.89it/s] 77%|███████▋  | 1063/1380 [02:12<00:35,  8.85it/s] 77%|███████▋  | 1064/1380 [02:12<00:35,  8.91it/s] 77%|███████▋  | 1065/1380 [02:12<00:35,  8.93it/s] 77%|███████▋  | 1066/1380 [02:12<00:35,  8.82it/s] 77%|███████▋  | 1067/1380 [02:13<00:35,  8.90it/s] 77%|███████▋  | 1068/1380 [02:13<00:35,  8.87it/s] 77%|███████▋  | 1069/1380 [02:13<00:34,  8.89it/s] 78%|███████▊  | 1070/1380 [02:13<00:34,  8.98it/s] 78%|███████▊  | 1071/1380 [02:13<00:34,  8.91it/s] 78%|███████▊  | 1072/1380 [02:13<00:34,  8.89it/s] 78%|███████▊  | 1073/1380 [02:13<00:34,  8.83it/s] 78%|███████▊  | 1074/1380 [02:13<00:34,  8.86it/s] 78%|███████▊  | 1075/1380 [02:13<00:34,  8.93it/s] 78%|███████▊  | 1076/1380 [02:14<00:34,  8.90it/s] 78%|███████▊  | 1077/1380 [02:14<00:33,  9.01it/s] 78%|███████▊  | 1078/1380 [02:14<00:33,  8.92it/s] 78%|███████▊  | 1079/1380 [02:14<00:33,  8.99it/s] 78%|███████▊  | 1080/1380 [02:14<00:33,  9.07it/s] 78%|███████▊  | 1081/1380 [02:14<00:33,  8.98it/s] 78%|███████▊  | 1082/1380 [02:14<00:33,  8.94it/s] 78%|███████▊  | 1083/1380 [02:14<00:33,  8.90it/s] 79%|███████▊  | 1084/1380 [02:14<00:33,  8.90it/s] 79%|███████▊  | 1085/1380 [02:15<00:32,  8.96it/s] 79%|███████▊  | 1086/1380 [02:15<00:33,  8.87it/s] 79%|███████▉  | 1087/1380 [02:15<00:32,  8.92it/s] 79%|███████▉  | 1088/1380 [02:15<00:32,  8.88it/s] 79%|███████▉  | 1089/1380 [02:15<00:32,  8.89it/s] 79%|███████▉  | 1090/1380 [02:15<00:32,  8.98it/s] 79%|███████▉  | 1091/1380 [02:15<00:32,  8.86it/s] 79%|███████▉  | 1092/1380 [02:15<00:32,  8.81it/s] 79%|███████▉  | 1093/1380 [02:16<00:32,  8.81it/s] 79%|███████▉  | 1094/1380 [02:16<00:32,  8.90it/s] 79%|███████▉  | 1095/1380 [02:16<00:32,  8.85it/s] 79%|███████▉  | 1096/1380 [02:16<00:32,  8.85it/s] 79%|███████▉  | 1097/1380 [02:16<00:32,  8.83it/s] 80%|███████▉  | 1098/1380 [02:16<00:31,  8.86it/s] 80%|███████▉  | 1099/1380 [02:16<00:31,  8.86it/s] 80%|███████▉  | 1100/1380 [02:16<00:31,  9.02it/s] 80%|███████▉  | 1101/1380 [02:16<00:31,  8.95it/s] 80%|███████▉  | 1102/1380 [02:17<00:30,  8.98it/s] 80%|███████▉  | 1103/1380 [02:17<00:30,  9.02it/s]                                                    80%|████████  | 1104/1380 [02:17<00:30,  9.02it/s][INFO|trainer.py:755] 2023-11-15 19:39:58,410 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:39:58,412 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:39:58,412 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:39:58,413 >>   Batch size = 8
{'eval_loss': 0.4320797920227051, 'eval_accuracy': 0.8629764065335753, 'eval_micro_f1': 0.8629764065335753, 'eval_macro_f1': 0.8454972870118304, 'eval_runtime': 4.1536, 'eval_samples_per_second': 530.621, 'eval_steps_per_second': 66.448, 'epoch': 3.0}
{'loss': 0.1197, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 8/276 [00:00<00:03, 75.96it/s][A
  6%|▌         | 16/276 [00:00<00:03, 70.74it/s][A
  9%|▊         | 24/276 [00:00<00:03, 71.11it/s][A
 12%|█▏        | 32/276 [00:00<00:03, 72.57it/s][A
 14%|█▍        | 40/276 [00:00<00:03, 70.87it/s][A
 17%|█▋        | 48/276 [00:00<00:03, 72.39it/s][A
 20%|██        | 56/276 [00:00<00:03, 70.29it/s][A
 23%|██▎       | 64/276 [00:00<00:03, 70.34it/s][A
 26%|██▌       | 72/276 [00:01<00:02, 72.01it/s][A
 29%|██▉       | 80/276 [00:01<00:02, 69.83it/s][A
 32%|███▏      | 88/276 [00:01<00:02, 69.99it/s][A
 35%|███▍      | 96/276 [00:01<00:02, 70.24it/s][A
 38%|███▊      | 104/276 [00:01<00:02, 70.47it/s][A
 41%|████      | 112/276 [00:01<00:02, 69.65it/s][A
 43%|████▎     | 119/276 [00:01<00:02, 69.17it/s][A
 46%|████▌     | 126/276 [00:01<00:02, 69.09it/s][A
 49%|████▊     | 134/276 [00:01<00:02, 69.91it/s][A
 51%|█████▏    | 142/276 [00:02<00:01, 69.54it/s][A
 54%|█████▍    | 150/276 [00:02<00:01, 70.61it/s][A
 57%|█████▋    | 158/276 [00:02<00:01, 69.26it/s][A
 60%|██████    | 166/276 [00:02<00:01, 69.26it/s][A
 63%|██████▎   | 174/276 [00:02<00:01, 71.13it/s][A
 66%|██████▌   | 182/276 [00:02<00:01, 69.81it/s][A
 69%|██████▉   | 190/276 [00:02<00:01, 71.15it/s][A
 72%|███████▏  | 198/276 [00:02<00:01, 71.14it/s][A
 75%|███████▍  | 206/276 [00:02<00:00, 71.12it/s][A
 78%|███████▊  | 214/276 [00:03<00:00, 69.76it/s][A
 80%|████████  | 221/276 [00:03<00:00, 69.61it/s][A
 83%|████████▎ | 229/276 [00:03<00:00, 70.03it/s][A
 86%|████████▌ | 237/276 [00:03<00:00, 71.27it/s][A
 89%|████████▉ | 245/276 [00:03<00:00, 69.82it/s][A
 92%|█████████▏| 253/276 [00:03<00:00, 70.97it/s][A
 95%|█████████▍| 261/276 [00:03<00:00, 70.54it/s][A
 97%|█████████▋| 269/276 [00:03<00:00, 70.05it/s][A                                                   
                                                 [A 80%|████████  | 1104/1380 [02:21<00:30,  9.02it/s]
100%|██████████| 276/276 [00:03<00:00, 70.05it/s][A
                                                 [A 80%|████████  | 1105/1380 [02:21<04:41,  1.02s/it] 80%|████████  | 1106/1380 [02:21<03:38,  1.26it/s] 80%|████████  | 1107/1380 [02:21<02:48,  1.62it/s] 80%|████████  | 1108/1380 [02:21<02:10,  2.08it/s] 80%|████████  | 1109/1380 [02:21<01:42,  2.65it/s] 80%|████████  | 1110/1380 [02:21<01:21,  3.32it/s] 81%|████████  | 1111/1380 [02:21<01:06,  4.07it/s] 81%|████████  | 1112/1380 [02:22<00:55,  4.83it/s] 81%|████████  | 1113/1380 [02:22<00:47,  5.59it/s] 81%|████████  | 1114/1380 [02:22<00:42,  6.28it/s] 81%|████████  | 1115/1380 [02:22<00:38,  6.93it/s] 81%|████████  | 1116/1380 [02:22<00:35,  7.37it/s] 81%|████████  | 1117/1380 [02:22<00:33,  7.85it/s] 81%|████████  | 1118/1380 [02:22<00:32,  8.15it/s] 81%|████████  | 1119/1380 [02:22<00:30,  8.42it/s] 81%|████████  | 1120/1380 [02:22<00:29,  8.68it/s] 81%|████████  | 1121/1380 [02:23<00:29,  8.77it/s] 81%|████████▏ | 1122/1380 [02:23<00:29,  8.84it/s] 81%|████████▏ | 1123/1380 [02:23<00:28,  8.91it/s] 81%|████████▏ | 1124/1380 [02:23<00:28,  9.03it/s] 82%|████████▏ | 1125/1380 [02:23<00:28,  9.02it/s] 82%|████████▏ | 1126/1380 [02:23<00:28,  9.04it/s] 82%|████████▏ | 1127/1380 [02:23<00:28,  9.03it/s] 82%|████████▏ | 1128/1380 [02:23<00:27,  9.05it/s] 82%|████████▏ | 1129/1380 [02:23<00:28,  8.95it/s] 82%|████████▏ | 1130/1380 [02:24<00:27,  9.07it/s] 82%|████████▏ | 1131/1380 [02:24<00:27,  9.01it/s] 82%|████████▏ | 1132/1380 [02:24<00:27,  9.09it/s] 82%|████████▏ | 1133/1380 [02:24<00:27,  9.15it/s] 82%|████████▏ | 1134/1380 [02:24<00:27,  9.10it/s] 82%|████████▏ | 1135/1380 [02:24<00:26,  9.14it/s] 82%|████████▏ | 1136/1380 [02:24<00:26,  9.16it/s] 82%|████████▏ | 1137/1380 [02:24<00:26,  9.20it/s] 82%|████████▏ | 1138/1380 [02:24<00:26,  9.10it/s] 83%|████████▎ | 1139/1380 [02:25<00:26,  9.13it/s] 83%|████████▎ | 1140/1380 [02:25<00:26,  9.11it/s] 83%|████████▎ | 1141/1380 [02:25<00:26,  9.14it/s] 83%|████████▎ | 1142/1380 [02:25<00:26,  9.07it/s] 83%|████████▎ | 1143/1380 [02:25<00:26,  9.04it/s] 83%|████████▎ | 1144/1380 [02:25<00:25,  9.13it/s] 83%|████████▎ | 1145/1380 [02:25<00:25,  9.10it/s] 83%|████████▎ | 1146/1380 [02:25<00:25,  9.12it/s] 83%|████████▎ | 1147/1380 [02:25<00:25,  9.14it/s] 83%|████████▎ | 1148/1380 [02:26<00:25,  9.18it/s] 83%|████████▎ | 1149/1380 [02:26<00:24,  9.25it/s] 83%|████████▎ | 1150/1380 [02:26<00:25,  9.19it/s] 83%|████████▎ | 1151/1380 [02:26<00:24,  9.23it/s] 83%|████████▎ | 1152/1380 [02:26<00:24,  9.24it/s] 84%|████████▎ | 1153/1380 [02:26<00:24,  9.20it/s] 84%|████████▎ | 1154/1380 [02:26<00:24,  9.12it/s] 84%|████████▎ | 1155/1380 [02:26<00:24,  9.12it/s] 84%|████████▍ | 1156/1380 [02:26<00:24,  9.18it/s] 84%|████████▍ | 1157/1380 [02:27<00:24,  9.10it/s] 84%|████████▍ | 1158/1380 [02:27<00:24,  9.08it/s] 84%|████████▍ | 1159/1380 [02:27<00:24,  9.06it/s] 84%|████████▍ | 1160/1380 [02:27<00:24,  9.13it/s] 84%|████████▍ | 1161/1380 [02:27<00:24,  9.06it/s] 84%|████████▍ | 1162/1380 [02:27<00:23,  9.09it/s] 84%|████████▍ | 1163/1380 [02:27<00:23,  9.11it/s] 84%|████████▍ | 1164/1380 [02:27<00:23,  9.12it/s] 84%|████████▍ | 1165/1380 [02:27<00:23,  9.17it/s] 84%|████████▍ | 1166/1380 [02:28<00:23,  9.13it/s] 85%|████████▍ | 1167/1380 [02:28<00:23,  9.08it/s] 85%|████████▍ | 1168/1380 [02:28<00:23,  9.19it/s] 85%|████████▍ | 1169/1380 [02:28<00:23,  9.11it/s] 85%|████████▍ | 1170/1380 [02:28<00:22,  9.15it/s] 85%|████████▍ | 1171/1380 [02:28<00:22,  9.17it/s] 85%|████████▍ | 1172/1380 [02:28<00:22,  9.18it/s] 85%|████████▌ | 1173/1380 [02:28<00:22,  9.03it/s] 85%|████████▌ | 1174/1380 [02:28<00:22,  9.09it/s] 85%|████████▌ | 1175/1380 [02:28<00:22,  9.13it/s] 85%|████████▌ | 1176/1380 [02:29<00:22,  9.10it/s] 85%|████████▌ | 1177/1380 [02:29<00:22,  9.02it/s] 85%|████████▌ | 1178/1380 [02:29<00:22,  9.04it/s] 85%|████████▌ | 1179/1380 [02:29<00:22,  9.08it/s] 86%|████████▌ | 1180/1380 [02:29<00:22,  9.08it/s] 86%|████████▌ | 1181/1380 [02:29<00:21,  9.15it/s] 86%|████████▌ | 1182/1380 [02:29<00:21,  9.15it/s] 86%|████████▌ | 1183/1380 [02:29<00:21,  9.11it/s] 86%|████████▌ | 1184/1380 [02:29<00:21,  9.18it/s] 86%|████████▌ | 1185/1380 [02:30<00:21,  9.10it/s] 86%|████████▌ | 1186/1380 [02:30<00:21,  9.18it/s] 86%|████████▌ | 1187/1380 [02:30<00:20,  9.28it/s] 86%|████████▌ | 1188/1380 [02:30<00:20,  9.18it/s] 86%|████████▌ | 1189/1380 [02:30<00:20,  9.19it/s] 86%|████████▌ | 1190/1380 [02:30<00:20,  9.16it/s] 86%|████████▋ | 1191/1380 [02:30<00:20,  9.21it/s] 86%|████████▋ | 1192/1380 [02:30<00:20,  9.18it/s] 86%|████████▋ | 1193/1380 [02:30<00:20,  9.16it/s] 87%|████████▋ | 1194/1380 [02:31<00:20,  9.07it/s] 87%|████████▋ | 1195/1380 [02:31<00:20,  9.14it/s] 87%|████████▋ | 1196/1380 [02:31<00:20,  9.03it/s] 87%|████████▋ | 1197/1380 [02:31<00:19,  9.18it/s] 87%|████████▋ | 1198/1380 [02:31<00:19,  9.14it/s] 87%|████████▋ | 1199/1380 [02:31<00:19,  9.16it/s] 87%|████████▋ | 1200/1380 [02:31<00:19,  9.23it/s] 87%|████████▋ | 1201/1380 [02:31<00:19,  9.15it/s] 87%|████████▋ | 1202/1380 [02:31<00:19,  9.17it/s] 87%|████████▋ | 1203/1380 [02:32<00:19,  9.17it/s] 87%|████████▋ | 1204/1380 [02:32<00:19,  9.14it/s] 87%|████████▋ | 1205/1380 [02:32<00:19,  9.10it/s] 87%|████████▋ | 1206/1380 [02:32<00:19,  9.16it/s] 87%|████████▋ | 1207/1380 [02:32<00:19,  9.10it/s] 88%|████████▊ | 1208/1380 [02:32<00:18,  9.13it/s] 88%|████████▊ | 1209/1380 [02:32<00:19,  9.00it/s] 88%|████████▊ | 1210/1380 [02:32<00:18,  9.11it/s] 88%|████████▊ | 1211/1380 [02:32<00:18,  8.99it/s] 88%|████████▊ | 1212/1380 [02:33<00:18,  9.02it/s] 88%|████████▊ | 1213/1380 [02:33<00:18,  9.14it/s] 88%|████████▊ | 1214/1380 [02:33<00:18,  9.04it/s] 88%|████████▊ | 1215/1380 [02:33<00:18,  9.10it/s] 88%|████████▊ | 1216/1380 [02:33<00:18,  9.09it/s] 88%|████████▊ | 1217/1380 [02:33<00:17,  9.09it/s] 88%|████████▊ | 1218/1380 [02:33<00:18,  8.96it/s] 88%|████████▊ | 1219/1380 [02:33<00:17,  9.05it/s] 88%|████████▊ | 1220/1380 [02:33<00:17,  8.96it/s] 88%|████████▊ | 1221/1380 [02:34<00:17,  9.03it/s] 89%|████████▊ | 1222/1380 [02:34<00:17,  8.89it/s] 89%|████████▊ | 1223/1380 [02:34<00:17,  9.08it/s] 89%|████████▊ | 1224/1380 [02:34<00:17,  9.07it/s] 89%|████████▉ | 1225/1380 [02:34<00:17,  9.08it/s] 89%|████████▉ | 1226/1380 [02:34<00:16,  9.18it/s] 89%|████████▉ | 1227/1380 [02:34<00:16,  9.02it/s] 89%|████████▉ | 1228/1380 [02:34<00:16,  8.98it/s] 89%|████████▉ | 1229/1380 [02:34<00:16,  8.98it/s] 89%|████████▉ | 1230/1380 [02:35<00:16,  9.02it/s] 89%|████████▉ | 1231/1380 [02:35<00:16,  8.99it/s] 89%|████████▉ | 1232/1380 [02:35<00:16,  8.89it/s] 89%|████████▉ | 1233/1380 [02:35<00:16,  8.91it/s] 89%|████████▉ | 1234/1380 [02:35<00:16,  8.99it/s] 89%|████████▉ | 1235/1380 [02:35<00:16,  8.97it/s] 90%|████████▉ | 1236/1380 [02:35<00:15,  9.02it/s] 90%|████████▉ | 1237/1380 [02:35<00:15,  8.98it/s] 90%|████████▉ | 1238/1380 [02:35<00:15,  9.03it/s] 90%|████████▉ | 1239/1380 [02:36<00:15,  9.11it/s] 90%|████████▉ | 1240/1380 [02:36<00:15,  9.05it/s] 90%|████████▉ | 1241/1380 [02:36<00:15,  8.96it/s] 90%|█████████ | 1242/1380 [02:36<00:15,  8.95it/s] 90%|█████████ | 1243/1380 [02:36<00:15,  8.99it/s] 90%|█████████ | 1244/1380 [02:36<00:15,  8.96it/s] 90%|█████████ | 1245/1380 [02:36<00:15,  8.84it/s] 90%|█████████ | 1246/1380 [02:36<00:15,  8.88it/s] 90%|█████████ | 1247/1380 [02:36<00:14,  8.92it/s] 90%|█████████ | 1248/1380 [02:37<00:14,  8.84it/s] 91%|█████████ | 1249/1380 [02:37<00:14,  8.93it/s] 91%|█████████ | 1250/1380 [02:37<00:14,  8.91it/s] 91%|█████████ | 1251/1380 [02:37<00:14,  8.93it/s] 91%|█████████ | 1252/1380 [02:37<00:14,  8.99it/s] 91%|█████████ | 1253/1380 [02:37<00:14,  8.91it/s] 91%|█████████ | 1254/1380 [02:37<00:14,  8.93it/s] 91%|█████████ | 1255/1380 [02:37<00:14,  8.87it/s] 91%|█████████ | 1256/1380 [02:37<00:13,  8.96it/s] 91%|█████████ | 1257/1380 [02:38<00:13,  8.93it/s] 91%|█████████ | 1258/1380 [02:38<00:13,  8.86it/s] 91%|█████████ | 1259/1380 [02:38<00:13,  8.84it/s] 91%|█████████▏| 1260/1380 [02:38<00:13,  8.89it/s] 91%|█████████▏| 1261/1380 [02:38<00:13,  8.89it/s] 91%|█████████▏| 1262/1380 [02:38<00:13,  8.96it/s] 92%|█████████▏| 1263/1380 [02:38<00:13,  8.94it/s] 92%|█████████▏| 1264/1380 [02:38<00:12,  9.02it/s] 92%|█████████▏| 1265/1380 [02:38<00:12,  9.07it/s] 92%|█████████▏| 1266/1380 [02:39<00:12,  8.99it/s] 92%|█████████▏| 1267/1380 [02:39<00:12,  8.92it/s] 92%|█████████▏| 1268/1380 [02:39<00:12,  8.92it/s] 92%|█████████▏| 1269/1380 [02:39<00:12,  8.95it/s] 92%|█████████▏| 1270/1380 [02:39<00:12,  8.89it/s] 92%|█████████▏| 1271/1380 [02:39<00:12,  8.91it/s] 92%|█████████▏| 1272/1380 [02:39<00:12,  8.95it/s] 92%|█████████▏| 1273/1380 [02:39<00:12,  8.91it/s] 92%|█████████▏| 1274/1380 [02:39<00:11,  8.94it/s] 92%|█████████▏| 1275/1380 [02:40<00:11,  9.02it/s] 92%|█████████▏| 1276/1380 [02:40<00:11,  8.92it/s] 93%|█████████▎| 1277/1380 [02:40<00:11,  8.94it/s] 93%|█████████▎| 1278/1380 [02:40<00:11,  8.96it/s] 93%|█████████▎| 1279/1380 [02:40<00:11,  8.97it/s] 93%|█████████▎| 1280/1380 [02:40<00:11,  8.89it/s] 93%|█████████▎| 1281/1380 [02:40<00:11,  8.91it/s] 93%|█████████▎| 1282/1380 [02:40<00:10,  8.92it/s] 93%|█████████▎| 1283/1380 [02:40<00:10,  8.91it/s] 93%|█████████▎| 1284/1380 [02:41<00:10,  8.85it/s] 93%|█████████▎| 1285/1380 [02:41<00:10,  8.92it/s] 93%|█████████▎| 1286/1380 [02:41<00:10,  8.90it/s] 93%|█████████▎| 1287/1380 [02:41<00:10,  8.90it/s] 93%|█████████▎| 1288/1380 [02:41<00:10,  8.98it/s] 93%|█████████▎| 1289/1380 [02:41<00:10,  8.93it/s] 93%|█████████▎| 1290/1380 [02:41<00:10,  8.85it/s] 94%|█████████▎| 1291/1380 [02:41<00:10,  8.86it/s] 94%|█████████▎| 1292/1380 [02:41<00:09,  8.90it/s] 94%|█████████▎| 1293/1380 [02:42<00:09,  8.93it/s] 94%|█████████▍| 1294/1380 [02:42<00:09,  8.79it/s] 94%|█████████▍| 1295/1380 [02:42<00:09,  8.84it/s] 94%|█████████▍| 1296/1380 [02:42<00:09,  8.84it/s] 94%|█████████▍| 1297/1380 [02:42<00:09,  8.88it/s] 94%|█████████▍| 1298/1380 [02:42<00:09,  8.94it/s] 94%|█████████▍| 1299/1380 [02:42<00:09,  8.82it/s] 94%|█████████▍| 1300/1380 [02:42<00:08,  8.89it/s] 94%|█████████▍| 1301/1380 [02:42<00:08,  8.90it/s] 94%|█████████▍| 1302/1380 [02:43<00:08,  8.94it/s] 94%|█████████▍| 1303/1380 [02:43<00:08,  8.87it/s] 94%|█████████▍| 1304/1380 [02:43<00:08,  8.82it/s] 95%|█████████▍| 1305/1380 [02:43<00:08,  8.89it/s] 95%|█████████▍| 1306/1380 [02:43<00:08,  8.91it/s] 95%|█████████▍| 1307/1380 [02:43<00:08,  8.87it/s] 95%|█████████▍| 1308/1380 [02:43<00:07,  9.06it/s] 95%|█████████▍| 1309/1380 [02:43<00:07,  8.90it/s] 95%|█████████▍| 1310/1380 [02:44<00:07,  8.92it/s] 95%|█████████▌| 1311/1380 [02:44<00:07,  8.95it/s] 95%|█████████▌| 1312/1380 [02:44<00:07,  8.94it/s] 95%|█████████▌| 1313/1380 [02:44<00:07,  8.92it/s] 95%|█████████▌| 1314/1380 [02:44<00:07,  8.84it/s] 95%|█████████▌| 1315/1380 [02:44<00:07,  8.91it/s] 95%|█████████▌| 1316/1380 [02:44<00:07,  8.99it/s] 95%|█████████▌| 1317/1380 [02:44<00:07,  8.97it/s] 96%|█████████▌| 1318/1380 [02:44<00:06,  9.05it/s] 96%|█████████▌| 1319/1380 [02:45<00:06,  8.93it/s] 96%|█████████▌| 1320/1380 [02:45<00:06,  8.84it/s] 96%|█████████▌| 1321/1380 [02:45<00:06,  8.91it/s] 96%|█████████▌| 1322/1380 [02:45<00:06,  8.90it/s] 96%|█████████▌| 1323/1380 [02:45<00:06,  8.87it/s] 96%|█████████▌| 1324/1380 [02:45<00:06,  8.85it/s] 96%|█████████▌| 1325/1380 [02:45<00:06,  8.86it/s] 96%|█████████▌| 1326/1380 [02:45<00:06,  8.86it/s] 96%|█████████▌| 1327/1380 [02:45<00:05,  8.87it/s] 96%|█████████▌| 1328/1380 [02:46<00:05,  8.96it/s] 96%|█████████▋| 1329/1380 [02:46<00:05,  8.83it/s] 96%|█████████▋| 1330/1380 [02:46<00:05,  8.83it/s] 96%|█████████▋| 1331/1380 [02:46<00:05,  8.82it/s] 97%|█████████▋| 1332/1380 [02:46<00:05,  8.82it/s] 97%|█████████▋| 1333/1380 [02:46<00:05,  8.84it/s] 97%|█████████▋| 1334/1380 [02:46<00:05,  8.70it/s] 97%|█████████▋| 1335/1380 [02:46<00:05,  8.77it/s] 97%|█████████▋| 1336/1380 [02:46<00:05,  8.79it/s] 97%|█████████▋| 1337/1380 [02:47<00:04,  8.87it/s] 97%|█████████▋| 1338/1380 [02:47<00:04,  8.90it/s] 97%|█████████▋| 1339/1380 [02:47<00:04,  8.82it/s] 97%|█████████▋| 1340/1380 [02:47<00:04,  8.86it/s] 97%|█████████▋| 1341/1380 [02:47<00:04,  8.85it/s] 97%|█████████▋| 1342/1380 [02:47<00:04,  8.88it/s] 97%|█████████▋| 1343/1380 [02:47<00:04,  8.82it/s] 97%|█████████▋| 1344/1380 [02:47<00:04,  8.75it/s] 97%|█████████▋| 1345/1380 [02:47<00:04,  8.72it/s] 98%|█████████▊| 1346/1380 [02:48<00:03,  8.77it/s] 98%|█████████▊| 1347/1380 [02:48<00:03,  8.85it/s] 98%|█████████▊| 1348/1380 [02:48<00:03,  8.91it/s] 98%|█████████▊| 1349/1380 [02:48<00:03,  8.81it/s] 98%|█████████▊| 1350/1380 [02:48<00:03,  8.77it/s] 98%|█████████▊| 1351/1380 [02:48<00:03,  8.83it/s] 98%|█████████▊| 1352/1380 [02:48<00:03,  8.85it/s] 98%|█████████▊| 1353/1380 [02:48<00:03,  8.76it/s] 98%|█████████▊| 1354/1380 [02:48<00:02,  8.81it/s] 98%|█████████▊| 1355/1380 [02:49<00:02,  8.73it/s] 98%|█████████▊| 1356/1380 [02:49<00:02,  8.80it/s] 98%|█████████▊| 1357/1380 [02:49<00:02,  8.79it/s] 98%|█████████▊| 1358/1380 [02:49<00:02,  8.84it/s] 98%|█████████▊| 1359/1380 [02:49<00:02,  8.84it/s] 99%|█████████▊| 1360/1380 [02:49<00:02,  8.83it/s] 99%|█████████▊| 1361/1380 [02:49<00:02,  8.95it/s] 99%|█████████▊| 1362/1380 [02:49<00:02,  8.93it/s] 99%|█████████▉| 1363/1380 [02:49<00:01,  8.87it/s] 99%|█████████▉| 1364/1380 [02:50<00:01,  8.86it/s] 99%|█████████▉| 1365/1380 [02:50<00:01,  8.95it/s] 99%|█████████▉| 1366/1380 [02:50<00:01,  8.88it/s] 99%|█████████▉| 1367/1380 [02:50<00:01,  8.82it/s] 99%|█████████▉| 1368/1380 [02:50<00:01,  8.85it/s] 99%|█████████▉| 1369/1380 [02:50<00:01,  8.90it/s] 99%|█████████▉| 1370/1380 [02:50<00:01,  8.89it/s] 99%|█████████▉| 1371/1380 [02:50<00:00,  9.00it/s] 99%|█████████▉| 1372/1380 [02:51<00:00,  8.94it/s] 99%|█████████▉| 1373/1380 [02:51<00:00,  8.93it/s]100%|█████████▉| 1374/1380 [02:51<00:00,  9.04it/s]100%|█████████▉| 1375/1380 [02:51<00:00,  8.97it/s]100%|█████████▉| 1376/1380 [02:51<00:00,  8.95it/s]100%|█████████▉| 1377/1380 [02:51<00:00,  8.98it/s]100%|█████████▉| 1378/1380 [02:51<00:00,  8.99it/s]100%|█████████▉| 1379/1380 [02:51<00:00,  8.98it/s]                                                   100%|██████████| 1380/1380 [02:51<00:00,  8.98it/s][INFO|trainer.py:755] 2023-11-15 19:40:33,066 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:40:33,068 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:40:33,069 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:40:33,069 >>   Batch size = 8
{'eval_loss': 0.5557199120521545, 'eval_accuracy': 0.8638838475499092, 'eval_micro_f1': 0.8638838475499093, 'eval_macro_f1': 0.848497559826327, 'eval_runtime': 3.972, 'eval_samples_per_second': 554.889, 'eval_steps_per_second': 69.487, 'epoch': 4.0}
{'loss': 0.0854, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 80.62it/s][A
  7%|▋         | 18/276 [00:00<00:03, 72.53it/s][A
  9%|▉         | 26/276 [00:00<00:03, 65.72it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 67.65it/s][A
 15%|█▍        | 41/276 [00:00<00:03, 67.89it/s][A
 17%|█▋        | 48/276 [00:00<00:03, 68.13it/s][A
 20%|██        | 56/276 [00:00<00:03, 69.86it/s][A
 23%|██▎       | 64/276 [00:00<00:03, 66.47it/s][A
 26%|██▌       | 71/276 [00:01<00:03, 67.25it/s][A
 28%|██▊       | 78/276 [00:01<00:02, 67.55it/s][A
 31%|███       | 85/276 [00:01<00:02, 67.73it/s][A
 33%|███▎      | 92/276 [00:01<00:02, 68.01it/s][A
 36%|███▌      | 99/276 [00:01<00:02, 67.90it/s][A
 39%|███▉      | 107/276 [00:01<00:02, 68.05it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 67.39it/s][A
 44%|████▍     | 121/276 [00:01<00:02, 68.08it/s][A
 46%|████▋     | 128/276 [00:01<00:02, 68.40it/s][A
 49%|████▉     | 135/276 [00:01<00:02, 67.51it/s][A
 51%|█████▏    | 142/276 [00:02<00:01, 68.21it/s][A
 54%|█████▍    | 149/276 [00:02<00:01, 68.10it/s][A
 57%|█████▋    | 157/276 [00:02<00:01, 68.04it/s][A
 59%|█████▉    | 164/276 [00:02<00:01, 66.17it/s][A
 62%|██████▏   | 171/276 [00:02<00:01, 66.82it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 66.28it/s][A
 67%|██████▋   | 185/276 [00:02<00:01, 67.01it/s][A
 70%|██████▉   | 192/276 [00:02<00:01, 67.85it/s][A
 72%|███████▏  | 199/276 [00:02<00:01, 66.90it/s][A
 75%|███████▌  | 207/276 [00:03<00:01, 68.18it/s][A
 78%|███████▊  | 214/276 [00:03<00:00, 67.20it/s][A
 80%|████████  | 221/276 [00:03<00:00, 67.72it/s][A
 83%|████████▎ | 228/276 [00:03<00:00, 67.92it/s][A
 85%|████████▌ | 235/276 [00:03<00:00, 67.60it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 68.07it/s][A
 91%|█████████ | 250/276 [00:03<00:00, 68.24it/s][A
 93%|█████████▎| 258/276 [00:03<00:00, 68.14it/s][A
 96%|█████████▌| 265/276 [00:03<00:00, 66.81it/s][A
 99%|█████████▊| 272/276 [00:04<00:00, 67.24it/s][A                                                   
                                                 [A100%|██████████| 1380/1380 [02:56<00:00,  8.98it/s]
100%|██████████| 276/276 [00:04<00:00, 67.24it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 19:40:37,218 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:56<00:00,  8.98it/s]100%|██████████| 1380/1380 [02:56<00:00,  7.84it/s]
[INFO|trainer.py:2855] 2023-11-15 19:40:37,222 >> Saving model checkpoint to ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0
[INFO|configuration_utils.py:460] 2023-11-15 19:40:37,225 >> Configuration saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:40:38,569 >> Model weights saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:40:38,572 >> tokenizer config file saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:40:38,574 >> Special tokens file saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed0/special_tokens_map.json
{'eval_loss': 0.5713958740234375, 'eval_accuracy': 0.8620689655172413, 'eval_micro_f1': 0.8620689655172413, 'eval_macro_f1': 0.8472448631264831, 'eval_runtime': 4.146, 'eval_samples_per_second': 531.598, 'eval_steps_per_second': 66.57, 'epoch': 5.0}
{'train_runtime': 176.0182, 'train_samples_per_second': 250.429, 'train_steps_per_second': 7.84, 'train_loss': 0.22308351267939028, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2231
  train_runtime            = 0:02:56.01
  train_samples            =       8816
  train_samples_per_second =    250.429
  train_steps_per_second   =       7.84
11/15/2023 19:40:38 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:40:38,623 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:40:38,625 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:40:38,625 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 19:40:38,626 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  3%|▎         | 9/276 [00:00<00:03, 85.19it/s]  7%|▋         | 18/276 [00:00<00:03, 72.95it/s]  9%|▉         | 26/276 [00:00<00:03, 71.73it/s] 12%|█▏        | 34/276 [00:00<00:03, 72.78it/s] 15%|█▌        | 42/276 [00:00<00:03, 69.97it/s] 18%|█▊        | 50/276 [00:00<00:03, 70.08it/s] 21%|██        | 58/276 [00:00<00:03, 70.28it/s] 24%|██▍       | 66/276 [00:00<00:02, 71.34it/s] 27%|██▋       | 74/276 [00:01<00:02, 69.56it/s] 29%|██▉       | 81/276 [00:01<00:02, 68.53it/s] 32%|███▏      | 89/276 [00:01<00:02, 70.56it/s] 35%|███▌      | 97/276 [00:01<00:02, 70.93it/s] 38%|███▊      | 105/276 [00:01<00:02, 70.57it/s] 41%|████      | 113/276 [00:01<00:02, 71.65it/s] 44%|████▍     | 121/276 [00:01<00:02, 69.74it/s] 47%|████▋     | 129/276 [00:01<00:02, 70.84it/s] 50%|████▉     | 137/276 [00:01<00:01, 71.39it/s] 53%|█████▎    | 145/276 [00:02<00:01, 69.13it/s] 55%|█████▌    | 152/276 [00:02<00:01, 68.36it/s] 58%|█████▊    | 160/276 [00:02<00:01, 69.98it/s] 61%|██████    | 168/276 [00:02<00:01, 70.07it/s] 64%|██████▍   | 176/276 [00:02<00:01, 71.03it/s] 67%|██████▋   | 184/276 [00:02<00:01, 68.41it/s] 70%|██████▉   | 192/276 [00:02<00:01, 69.80it/s] 72%|███████▏  | 200/276 [00:02<00:01, 70.49it/s] 75%|███████▌  | 208/276 [00:02<00:00, 70.75it/s] 78%|███████▊  | 216/276 [00:03<00:00, 70.24it/s] 81%|████████  | 224/276 [00:03<00:00, 69.88it/s] 84%|████████▍ | 232/276 [00:03<00:00, 70.67it/s] 87%|████████▋ | 240/276 [00:03<00:00, 71.15it/s] 90%|████████▉ | 248/276 [00:03<00:00, 69.16it/s] 92%|█████████▏| 255/276 [00:03<00:00, 68.09it/s] 95%|█████████▌| 263/276 [00:03<00:00, 69.11it/s] 98%|█████████▊| 270/276 [00:03<00:00, 69.33it/s]100%|██████████| 276/276 [00:03<00:00, 69.55it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8621
  eval_loss               =     0.5714
  eval_macro_f1           =     0.8472
  eval_micro_f1           =     0.8621
  eval_runtime            = 0:00:03.98
  eval_samples            =       2204
  eval_samples_per_second =    552.739
  eval_steps_per_second   =     69.218
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁█▅▆▅▅
wandb:                      eval/loss ▁▁▃▇██
wandb:                  eval/macro_f1 ▁▅▅█▇▇
wandb:                  eval/micro_f1 ▁█▅▆▅▅
wandb:                   eval/runtime ▄▄█▁█▂
wandb:        eval/samples_per_second ▅▅▁█▁▇
wandb:          eval/steps_per_second ▅▅▁█▁▇
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.86207
wandb:                      eval/loss 0.5714
wandb:                  eval/macro_f1 0.84724
wandb:                  eval/micro_f1 0.86207
wandb:                   eval/runtime 3.9874
wandb:        eval/samples_per_second 552.739
wandb:          eval/steps_per_second 69.218
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0854
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.22308
wandb:            train/train_runtime 176.0182
wandb: train/train_samples_per_second 250.429
wandb:   train/train_steps_per_second 7.84
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_193621-jrb3hjux
wandb: Find logs at: ./wandb/offline-run-20231115_193621-jrb3hjux/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_roberta-base_adapter__seed0/runs/Nov15_19-40-54_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_roberta-base_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_roberta-base_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:40:54 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:40:54 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_roberta-base_adapter__seed0/runs/Nov15_19-40-53_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_roberta-base_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_roberta-base_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 19:41:10,522 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:41:10,534 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 19:41:20,551 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 19:41:30,570 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:41:30,571 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:41:50,626 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:41:50,627 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:41:50,627 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:41:50,627 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:41:50,628 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:41:50,628 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 19:41:50,629 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:41:50,630 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:42:10,872 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 19:42:11,704 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:42:11,705 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  29%|██▉       | 2000/6840 [00:00<00:00, 17845.10 examples/s]Running tokenizer on dataset:  58%|█████▊    | 4000/6840 [00:00<00:00, 16292.31 examples/s]Running tokenizer on dataset:  88%|████████▊ | 6000/6840 [00:00<00:00, 16054.56 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 16444.89 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 19878.47 examples/s]
11/15/2023 19:42:12 - INFO - __main__ - Sample 6776 of the training set: {'text': 'Cup chase lands in Dover When the green flag drops for today #39;s MBNA America 400 at Dover International Speedway, 43 drivers will be lined up to cross the start/finish line.', 'label': 0, 'input_ids': [0, 347, 658, 7859, 8952, 11, 21860, 520, 5, 2272, 3794, 9305, 13, 452, 849, 3416, 131, 29, 17025, 4444, 730, 3675, 23, 21860, 1016, 13243, 6, 3557, 2377, 40, 28, 9321, 62, 7, 2116, 5, 386, 73, 13597, 1173, 516, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:42:12 - INFO - __main__ - Sample 1742 of the training set: {'text': 'Louisiana Tech Bulldogs RUSTON, Louisiana (Ticker) -- No. 17 Fresno State could not overcome a dominant performance by Ryan Moats or a poor one by Paul Pinegar.', 'label': 0, 'input_ids': [0, 29923, 8878, 4569, 10135, 248, 11120, 2191, 6, 5993, 36, 565, 13917, 43, 480, 440, 4, 601, 18084, 331, 115, 45, 6647, 10, 7353, 819, 30, 1774, 3713, 2923, 50, 10, 2129, 65, 30, 1206, 11542, 6276, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:42:12 - INFO - __main__ - Sample 2588 of the training set: {'text': 'Rossi:  #39;I #39;m fairly happy #39; Valentino Rossi, who on Thursday pledged his future to Yamaha, entered the final qualifying session with the fastest time to date, but with the morning rain having washed the circuit clean, the Italian was unable to challenge Makoto Tamada for the pole.', 'label': 0, 'input_ids': [0, 35978, 118, 35, 1437, 849, 3416, 131, 100, 849, 3416, 131, 119, 5342, 1372, 849, 3416, 131, 18352, 1696, 21873, 6, 54, 15, 296, 7114, 39, 499, 7, 25297, 6, 2867, 5, 507, 7310, 1852, 19, 5, 6273, 86, 7, 1248, 6, 53, 19, 5, 662, 1895, 519, 15158, 5, 9326, 2382, 6, 5, 3108, 21, 3276, 7, 1539, 46383, 7736, 2095, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 19:42:12 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:42:13,797 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:42:13,805 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:42:13,805 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 19:42:13,806 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:42:13,806 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:42:13,806 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:42:13,807 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:42:13,807 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 19:42:13,808 >>   Number of trainable parameters = 124,648,708
[INFO|integration_utils.py:716] 2023-11-15 19:42:13,808 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<25:02,  1.41s/it]  0%|          | 2/1070 [00:01<11:28,  1.55it/s]  0%|          | 3/1070 [00:01<07:09,  2.49it/s]  0%|          | 4/1070 [00:01<05:06,  3.48it/s]  0%|          | 5/1070 [00:01<03:58,  4.47it/s]  1%|          | 6/1070 [00:01<03:17,  5.38it/s]  1%|          | 7/1070 [00:02<02:50,  6.22it/s]  1%|          | 8/1070 [00:02<02:34,  6.86it/s]  1%|          | 9/1070 [00:02<02:23,  7.41it/s]  1%|          | 10/1070 [00:02<02:15,  7.81it/s]  1%|          | 11/1070 [00:02<02:11,  8.07it/s]  1%|          | 12/1070 [00:02<02:07,  8.29it/s]  1%|          | 13/1070 [00:02<02:05,  8.40it/s]  1%|▏         | 14/1070 [00:02<02:03,  8.57it/s]  1%|▏         | 15/1070 [00:02<02:02,  8.65it/s]  1%|▏         | 16/1070 [00:03<02:00,  8.74it/s]  2%|▏         | 17/1070 [00:03<01:58,  8.86it/s]  2%|▏         | 18/1070 [00:03<01:59,  8.83it/s]  2%|▏         | 19/1070 [00:03<01:59,  8.79it/s]  2%|▏         | 20/1070 [00:03<01:58,  8.87it/s]  2%|▏         | 21/1070 [00:03<01:58,  8.83it/s]  2%|▏         | 22/1070 [00:03<01:58,  8.85it/s]  2%|▏         | 23/1070 [00:03<01:58,  8.80it/s]  2%|▏         | 24/1070 [00:03<01:57,  8.92it/s]  2%|▏         | 25/1070 [00:04<01:57,  8.92it/s]  2%|▏         | 26/1070 [00:04<01:57,  8.90it/s]  3%|▎         | 27/1070 [00:04<01:57,  8.86it/s]  3%|▎         | 28/1070 [00:04<01:56,  8.92it/s]  3%|▎         | 29/1070 [00:04<01:57,  8.86it/s]  3%|▎         | 30/1070 [00:04<01:57,  8.88it/s]  3%|▎         | 31/1070 [00:04<01:57,  8.84it/s]  3%|▎         | 32/1070 [00:04<01:56,  8.90it/s]  3%|▎         | 33/1070 [00:05<01:56,  8.90it/s]  3%|▎         | 34/1070 [00:05<01:54,  9.02it/s]  3%|▎         | 35/1070 [00:05<01:56,  8.92it/s]  3%|▎         | 36/1070 [00:05<01:56,  8.84it/s]  3%|▎         | 37/1070 [00:05<01:56,  8.84it/s]  4%|▎         | 38/1070 [00:05<01:56,  8.87it/s]  4%|▎         | 39/1070 [00:05<01:55,  8.92it/s]  4%|▎         | 40/1070 [00:05<01:57,  8.80it/s]  4%|▍         | 41/1070 [00:05<01:55,  8.91it/s]  4%|▍         | 42/1070 [00:06<01:56,  8.84it/s]  4%|▍         | 43/1070 [00:06<01:54,  8.94it/s]  4%|▍         | 44/1070 [00:06<01:54,  8.94it/s]  4%|▍         | 45/1070 [00:06<01:54,  8.98it/s]  4%|▍         | 46/1070 [00:06<01:55,  8.90it/s]  4%|▍         | 47/1070 [00:06<01:54,  8.94it/s]  4%|▍         | 48/1070 [00:06<01:53,  8.99it/s]  5%|▍         | 49/1070 [00:06<01:53,  8.98it/s]  5%|▍         | 50/1070 [00:06<01:53,  8.96it/s]  5%|▍         | 51/1070 [00:07<01:52,  9.04it/s]  5%|▍         | 52/1070 [00:07<01:53,  9.00it/s]  5%|▍         | 53/1070 [00:07<01:54,  8.91it/s]  5%|▌         | 54/1070 [00:07<01:53,  8.98it/s]  5%|▌         | 55/1070 [00:07<01:53,  8.96it/s]  5%|▌         | 56/1070 [00:07<01:53,  8.94it/s]  5%|▌         | 57/1070 [00:07<01:53,  8.95it/s]  5%|▌         | 58/1070 [00:07<01:52,  9.01it/s]  6%|▌         | 59/1070 [00:07<01:52,  9.01it/s]  6%|▌         | 60/1070 [00:08<01:52,  8.95it/s]  6%|▌         | 61/1070 [00:08<01:52,  8.99it/s]  6%|▌         | 62/1070 [00:08<01:51,  9.01it/s]  6%|▌         | 63/1070 [00:08<01:52,  8.97it/s]  6%|▌         | 64/1070 [00:08<01:51,  9.01it/s]  6%|▌         | 65/1070 [00:08<01:51,  9.00it/s]  6%|▌         | 66/1070 [00:08<01:52,  8.91it/s]  6%|▋         | 67/1070 [00:08<01:52,  8.91it/s]  6%|▋         | 68/1070 [00:08<01:51,  9.01it/s]  6%|▋         | 69/1070 [00:09<01:52,  8.91it/s]  7%|▋         | 70/1070 [00:09<01:52,  8.88it/s]  7%|▋         | 71/1070 [00:09<01:52,  8.90it/s]  7%|▋         | 72/1070 [00:09<01:51,  8.91it/s]  7%|▋         | 73/1070 [00:09<01:51,  8.94it/s]  7%|▋         | 74/1070 [00:09<01:51,  8.90it/s]  7%|▋         | 75/1070 [00:09<01:50,  8.98it/s]  7%|▋         | 76/1070 [00:09<01:51,  8.94it/s]  7%|▋         | 77/1070 [00:09<01:50,  8.95it/s]  7%|▋         | 78/1070 [00:10<01:50,  9.01it/s]  7%|▋         | 79/1070 [00:10<01:50,  9.00it/s]  7%|▋         | 80/1070 [00:10<01:50,  8.94it/s]  8%|▊         | 81/1070 [00:10<01:50,  8.93it/s]  8%|▊         | 82/1070 [00:10<01:51,  8.90it/s]  8%|▊         | 83/1070 [00:10<01:50,  8.96it/s]  8%|▊         | 84/1070 [00:10<01:50,  8.93it/s]  8%|▊         | 85/1070 [00:10<01:48,  9.06it/s]  8%|▊         | 86/1070 [00:10<01:49,  8.96it/s]  8%|▊         | 87/1070 [00:11<01:49,  9.00it/s]  8%|▊         | 88/1070 [00:11<01:49,  8.94it/s]  8%|▊         | 89/1070 [00:11<01:49,  8.97it/s]  8%|▊         | 90/1070 [00:11<01:49,  8.97it/s]  9%|▊         | 91/1070 [00:11<01:50,  8.90it/s]  9%|▊         | 92/1070 [00:11<01:49,  8.92it/s]  9%|▊         | 93/1070 [00:11<01:49,  8.91it/s]  9%|▉         | 94/1070 [00:11<01:48,  8.97it/s]  9%|▉         | 95/1070 [00:11<01:47,  9.04it/s]  9%|▉         | 96/1070 [00:12<01:49,  8.93it/s]  9%|▉         | 97/1070 [00:12<01:48,  8.95it/s]  9%|▉         | 98/1070 [00:12<01:49,  8.89it/s]  9%|▉         | 99/1070 [00:12<01:48,  8.92it/s]  9%|▉         | 100/1070 [00:12<01:48,  8.95it/s]  9%|▉         | 101/1070 [00:12<01:48,  8.89it/s] 10%|▉         | 102/1070 [00:12<01:48,  8.94it/s] 10%|▉         | 103/1070 [00:12<01:47,  8.97it/s] 10%|▉         | 104/1070 [00:12<01:48,  8.90it/s] 10%|▉         | 105/1070 [00:13<01:47,  8.98it/s] 10%|▉         | 106/1070 [00:13<01:46,  9.02it/s] 10%|█         | 107/1070 [00:13<01:47,  8.94it/s] 10%|█         | 108/1070 [00:13<01:47,  8.97it/s] 10%|█         | 109/1070 [00:13<01:47,  8.94it/s] 10%|█         | 110/1070 [00:13<01:47,  8.97it/s] 10%|█         | 111/1070 [00:13<01:47,  8.89it/s] 10%|█         | 112/1070 [00:13<01:45,  9.05it/s] 11%|█         | 113/1070 [00:13<01:47,  8.92it/s] 11%|█         | 114/1070 [00:14<01:47,  8.90it/s] 11%|█         | 115/1070 [00:14<01:46,  8.97it/s] 11%|█         | 116/1070 [00:14<01:46,  8.92it/s] 11%|█         | 117/1070 [00:14<01:47,  8.85it/s] 11%|█         | 118/1070 [00:14<01:47,  8.87it/s] 11%|█         | 119/1070 [00:14<01:47,  8.84it/s] 11%|█         | 120/1070 [00:14<01:47,  8.84it/s] 11%|█▏        | 121/1070 [00:14<01:48,  8.79it/s] 11%|█▏        | 122/1070 [00:14<01:46,  8.89it/s] 11%|█▏        | 123/1070 [00:15<01:46,  8.90it/s] 12%|█▏        | 124/1070 [00:15<01:45,  8.96it/s] 12%|█▏        | 125/1070 [00:15<01:45,  8.95it/s] 12%|█▏        | 126/1070 [00:15<01:45,  8.91it/s] 12%|█▏        | 127/1070 [00:15<01:46,  8.82it/s] 12%|█▏        | 128/1070 [00:15<01:46,  8.82it/s] 12%|█▏        | 129/1070 [00:15<01:46,  8.83it/s] 12%|█▏        | 130/1070 [00:15<01:46,  8.85it/s] 12%|█▏        | 131/1070 [00:15<01:45,  8.86it/s] 12%|█▏        | 132/1070 [00:16<01:43,  9.04it/s] 12%|█▏        | 133/1070 [00:16<01:45,  8.89it/s] 13%|█▎        | 134/1070 [00:16<01:44,  8.95it/s] 13%|█▎        | 135/1070 [00:16<01:45,  8.88it/s] 13%|█▎        | 136/1070 [00:16<01:44,  8.93it/s] 13%|█▎        | 137/1070 [00:16<01:45,  8.87it/s] 13%|█▎        | 138/1070 [00:16<01:45,  8.84it/s] 13%|█▎        | 139/1070 [00:16<01:45,  8.86it/s] 13%|█▎        | 140/1070 [00:16<01:44,  8.90it/s] 13%|█▎        | 141/1070 [00:17<01:44,  8.90it/s] 13%|█▎        | 142/1070 [00:17<01:42,  9.03it/s] 13%|█▎        | 143/1070 [00:17<01:43,  8.97it/s] 13%|█▎        | 144/1070 [00:17<01:42,  9.00it/s] 14%|█▎        | 145/1070 [00:17<01:43,  8.97it/s] 14%|█▎        | 146/1070 [00:17<01:42,  9.00it/s] 14%|█▎        | 147/1070 [00:17<01:42,  8.97it/s] 14%|█▍        | 148/1070 [00:17<01:43,  8.90it/s] 14%|█▍        | 149/1070 [00:17<01:43,  8.91it/s] 14%|█▍        | 150/1070 [00:18<01:43,  8.90it/s] 14%|█▍        | 151/1070 [00:18<01:42,  8.92it/s] 14%|█▍        | 152/1070 [00:18<01:41,  9.01it/s] 14%|█▍        | 153/1070 [00:18<01:43,  8.84it/s] 14%|█▍        | 154/1070 [00:18<01:43,  8.85it/s] 14%|█▍        | 155/1070 [00:18<01:43,  8.86it/s] 15%|█▍        | 156/1070 [00:18<01:42,  8.92it/s] 15%|█▍        | 157/1070 [00:18<01:42,  8.88it/s] 15%|█▍        | 158/1070 [00:19<01:42,  8.87it/s] 15%|█▍        | 159/1070 [00:19<01:42,  8.85it/s] 15%|█▍        | 160/1070 [00:19<01:42,  8.84it/s] 15%|█▌        | 161/1070 [00:19<01:43,  8.82it/s] 15%|█▌        | 162/1070 [00:19<01:40,  9.00it/s] 15%|█▌        | 163/1070 [00:19<01:41,  8.95it/s] 15%|█▌        | 164/1070 [00:19<01:41,  8.95it/s] 15%|█▌        | 165/1070 [00:19<01:40,  8.97it/s] 16%|█▌        | 166/1070 [00:19<01:41,  8.93it/s] 16%|█▌        | 167/1070 [00:20<01:41,  8.89it/s] 16%|█▌        | 168/1070 [00:20<01:41,  8.93it/s] 16%|█▌        | 169/1070 [00:20<01:41,  8.87it/s] 16%|█▌        | 170/1070 [00:20<01:40,  8.94it/s] 16%|█▌        | 171/1070 [00:20<01:41,  8.87it/s] 16%|█▌        | 172/1070 [00:20<01:40,  8.92it/s] 16%|█▌        | 173/1070 [00:20<01:39,  8.97it/s] 16%|█▋        | 174/1070 [00:20<01:39,  8.98it/s] 16%|█▋        | 175/1070 [00:20<01:39,  9.00it/s] 16%|█▋        | 176/1070 [00:21<01:40,  8.93it/s] 17%|█▋        | 177/1070 [00:21<01:40,  8.91it/s] 17%|█▋        | 178/1070 [00:21<01:40,  8.90it/s] 17%|█▋        | 179/1070 [00:21<01:40,  8.91it/s] 17%|█▋        | 180/1070 [00:21<01:39,  8.95it/s] 17%|█▋        | 181/1070 [00:21<01:40,  8.83it/s] 17%|█▋        | 182/1070 [00:21<01:39,  8.89it/s] 17%|█▋        | 183/1070 [00:21<01:39,  8.91it/s] 17%|█▋        | 184/1070 [00:21<01:39,  8.91it/s] 17%|█▋        | 185/1070 [00:22<01:38,  9.02it/s] 17%|█▋        | 186/1070 [00:22<01:39,  8.90it/s] 17%|█▋        | 187/1070 [00:22<01:38,  8.94it/s] 18%|█▊        | 188/1070 [00:22<01:39,  8.87it/s] 18%|█▊        | 189/1070 [00:22<01:38,  8.92it/s] 18%|█▊        | 190/1070 [00:22<01:39,  8.87it/s] 18%|█▊        | 191/1070 [00:22<01:39,  8.86it/s] 18%|█▊        | 192/1070 [00:22<01:38,  8.90it/s] 18%|█▊        | 193/1070 [00:22<01:38,  8.94it/s] 18%|█▊        | 194/1070 [00:23<01:37,  8.96it/s] 18%|█▊        | 195/1070 [00:23<01:36,  9.10it/s] 18%|█▊        | 196/1070 [00:23<01:37,  8.97it/s] 18%|█▊        | 197/1070 [00:23<01:37,  8.96it/s] 19%|█▊        | 198/1070 [00:23<01:37,  8.96it/s] 19%|█▊        | 199/1070 [00:23<01:36,  9.03it/s] 19%|█▊        | 200/1070 [00:23<01:36,  8.99it/s] 19%|█▉        | 201/1070 [00:23<01:36,  8.98it/s] 19%|█▉        | 202/1070 [00:23<01:37,  8.93it/s] 19%|█▉        | 203/1070 [00:24<01:36,  8.95it/s] 19%|█▉        | 204/1070 [00:24<01:36,  8.95it/s] 19%|█▉        | 205/1070 [00:24<01:35,  9.08it/s] 19%|█▉        | 206/1070 [00:24<01:34,  9.10it/s] 19%|█▉        | 207/1070 [00:24<01:35,  9.07it/s] 19%|█▉        | 208/1070 [00:24<01:35,  9.06it/s] 20%|█▉        | 209/1070 [00:24<01:34,  9.09it/s] 20%|█▉        | 210/1070 [00:24<01:36,  8.92it/s] 20%|█▉        | 211/1070 [00:24<01:36,  8.93it/s] 20%|█▉        | 212/1070 [00:25<01:36,  8.92it/s] 20%|█▉        | 213/1070 [00:25<01:35,  9.00it/s]                                                   20%|██        | 214/1070 [00:25<01:35,  9.00it/s][INFO|trainer.py:755] 2023-11-15 19:42:39,061 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:42:39,063 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:42:39,063 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:42:39,064 >>   Batch size = 8
{'loss': 0.4657, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 84.12it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 77.96it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 73.19it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 74.12it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 72.97it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 73.57it/s][A
 61%|██████    | 58/95 [00:00<00:00, 73.85it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 73.52it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 71.41it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 71.65it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 71.49it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:26<01:35,  9.00it/s]
100%|██████████| 95/95 [00:01<00:00, 71.49it/s][A
                                               [A 20%|██        | 215/1070 [00:26<06:00,  2.37it/s] 20%|██        | 216/1070 [00:26<04:53,  2.91it/s] 20%|██        | 217/1070 [00:26<04:01,  3.53it/s] 20%|██        | 218/1070 [00:27<03:21,  4.23it/s] 20%|██        | 219/1070 [00:27<02:51,  4.97it/s] 21%|██        | 220/1070 [00:27<02:29,  5.70it/s] 21%|██        | 221/1070 [00:27<02:14,  6.33it/s] 21%|██        | 222/1070 [00:27<02:02,  6.93it/s] 21%|██        | 223/1070 [00:27<01:54,  7.42it/s] 21%|██        | 224/1070 [00:27<01:47,  7.85it/s] 21%|██        | 225/1070 [00:27<01:45,  8.04it/s] 21%|██        | 226/1070 [00:27<01:40,  8.36it/s] 21%|██        | 227/1070 [00:28<01:39,  8.48it/s] 21%|██▏       | 228/1070 [00:28<01:37,  8.62it/s] 21%|██▏       | 229/1070 [00:28<01:35,  8.84it/s] 21%|██▏       | 230/1070 [00:28<01:35,  8.82it/s] 22%|██▏       | 231/1070 [00:28<01:34,  8.85it/s] 22%|██▏       | 232/1070 [00:28<01:34,  8.86it/s] 22%|██▏       | 233/1070 [00:28<01:33,  8.92it/s] 22%|██▏       | 234/1070 [00:28<01:33,  8.92it/s] 22%|██▏       | 235/1070 [00:28<01:34,  8.87it/s] 22%|██▏       | 236/1070 [00:29<01:33,  8.90it/s] 22%|██▏       | 237/1070 [00:29<01:33,  8.87it/s] 22%|██▏       | 238/1070 [00:29<01:33,  8.94it/s] 22%|██▏       | 239/1070 [00:29<01:31,  9.08it/s] 22%|██▏       | 240/1070 [00:29<01:33,  8.91it/s] 23%|██▎       | 241/1070 [00:29<01:32,  8.93it/s] 23%|██▎       | 242/1070 [00:29<01:33,  8.90it/s] 23%|██▎       | 243/1070 [00:29<01:32,  8.94it/s] 23%|██▎       | 244/1070 [00:29<01:33,  8.82it/s] 23%|██▎       | 245/1070 [00:30<01:33,  8.84it/s] 23%|██▎       | 246/1070 [00:30<01:32,  8.89it/s] 23%|██▎       | 247/1070 [00:30<01:33,  8.84it/s] 23%|██▎       | 248/1070 [00:30<01:32,  8.85it/s] 23%|██▎       | 249/1070 [00:30<01:32,  8.91it/s] 23%|██▎       | 250/1070 [00:30<01:31,  8.97it/s] 23%|██▎       | 251/1070 [00:30<01:31,  8.95it/s] 24%|██▎       | 252/1070 [00:30<01:30,  9.08it/s] 24%|██▎       | 253/1070 [00:30<01:31,  8.95it/s] 24%|██▎       | 254/1070 [00:31<01:31,  8.92it/s] 24%|██▍       | 255/1070 [00:31<01:31,  8.87it/s] 24%|██▍       | 256/1070 [00:31<01:30,  8.98it/s] 24%|██▍       | 257/1070 [00:31<01:30,  8.94it/s] 24%|██▍       | 258/1070 [00:31<01:30,  8.96it/s] 24%|██▍       | 259/1070 [00:31<01:30,  8.95it/s] 24%|██▍       | 260/1070 [00:31<01:30,  8.94it/s] 24%|██▍       | 261/1070 [00:31<01:30,  8.92it/s] 24%|██▍       | 262/1070 [00:31<01:29,  8.99it/s] 25%|██▍       | 263/1070 [00:32<01:29,  9.00it/s] 25%|██▍       | 264/1070 [00:32<01:29,  8.97it/s] 25%|██▍       | 265/1070 [00:32<01:29,  9.00it/s] 25%|██▍       | 266/1070 [00:32<01:29,  8.94it/s] 25%|██▍       | 267/1070 [00:32<01:29,  8.94it/s] 25%|██▌       | 268/1070 [00:32<01:29,  8.96it/s] 25%|██▌       | 269/1070 [00:32<01:29,  8.97it/s] 25%|██▌       | 270/1070 [00:32<01:29,  8.96it/s] 25%|██▌       | 271/1070 [00:32<01:30,  8.87it/s] 25%|██▌       | 272/1070 [00:33<01:29,  8.89it/s] 26%|██▌       | 273/1070 [00:33<01:29,  8.91it/s] 26%|██▌       | 274/1070 [00:33<01:28,  8.99it/s] 26%|██▌       | 275/1070 [00:33<01:27,  9.08it/s] 26%|██▌       | 276/1070 [00:33<01:28,  8.96it/s] 26%|██▌       | 277/1070 [00:33<01:29,  8.91it/s] 26%|██▌       | 278/1070 [00:33<01:28,  8.98it/s] 26%|██▌       | 279/1070 [00:33<01:27,  9.01it/s] 26%|██▌       | 280/1070 [00:33<01:28,  8.94it/s] 26%|██▋       | 281/1070 [00:34<01:28,  8.92it/s] 26%|██▋       | 282/1070 [00:34<01:28,  8.91it/s] 26%|██▋       | 283/1070 [00:34<01:27,  8.96it/s] 27%|██▋       | 284/1070 [00:34<01:28,  8.86it/s] 27%|██▋       | 285/1070 [00:34<01:28,  8.91it/s] 27%|██▋       | 286/1070 [00:34<01:28,  8.89it/s] 27%|██▋       | 287/1070 [00:34<01:28,  8.87it/s] 27%|██▋       | 288/1070 [00:34<01:26,  8.99it/s] 27%|██▋       | 289/1070 [00:34<01:28,  8.86it/s] 27%|██▋       | 290/1070 [00:35<01:26,  8.97it/s] 27%|██▋       | 291/1070 [00:35<01:27,  8.95it/s] 27%|██▋       | 292/1070 [00:35<01:26,  9.01it/s] 27%|██▋       | 293/1070 [00:35<01:27,  8.91it/s] 27%|██▋       | 294/1070 [00:35<01:26,  8.96it/s] 28%|██▊       | 295/1070 [00:35<01:26,  8.91it/s] 28%|██▊       | 296/1070 [00:35<01:26,  8.94it/s] 28%|██▊       | 297/1070 [00:35<01:27,  8.81it/s] 28%|██▊       | 298/1070 [00:36<01:26,  8.88it/s] 28%|██▊       | 299/1070 [00:36<01:26,  8.90it/s] 28%|██▊       | 300/1070 [00:36<01:26,  8.95it/s] 28%|██▊       | 301/1070 [00:36<01:24,  9.05it/s] 28%|██▊       | 302/1070 [00:36<01:25,  8.94it/s] 28%|██▊       | 303/1070 [00:36<01:25,  9.01it/s] 28%|██▊       | 304/1070 [00:36<01:26,  8.91it/s] 29%|██▊       | 305/1070 [00:36<01:25,  8.97it/s] 29%|██▊       | 306/1070 [00:36<01:26,  8.88it/s] 29%|██▊       | 307/1070 [00:37<01:25,  8.96it/s] 29%|██▉       | 308/1070 [00:37<01:25,  8.93it/s] 29%|██▉       | 309/1070 [00:37<01:24,  8.99it/s] 29%|██▉       | 310/1070 [00:37<01:25,  8.94it/s] 29%|██▉       | 311/1070 [00:37<01:23,  9.07it/s] 29%|██▉       | 312/1070 [00:37<01:24,  8.97it/s] 29%|██▉       | 313/1070 [00:37<01:24,  8.99it/s] 29%|██▉       | 314/1070 [00:37<01:23,  9.03it/s] 29%|██▉       | 315/1070 [00:37<01:23,  9.03it/s] 30%|██▉       | 316/1070 [00:38<01:23,  9.00it/s] 30%|██▉       | 317/1070 [00:38<01:23,  9.01it/s] 30%|██▉       | 318/1070 [00:38<01:23,  8.99it/s] 30%|██▉       | 319/1070 [00:38<01:23,  8.96it/s] 30%|██▉       | 320/1070 [00:38<01:24,  8.93it/s] 30%|███       | 321/1070 [00:38<01:23,  9.00it/s] 30%|███       | 322/1070 [00:38<01:23,  8.96it/s] 30%|███       | 323/1070 [00:38<01:23,  8.96it/s] 30%|███       | 324/1070 [00:38<01:22,  9.09it/s] 30%|███       | 325/1070 [00:39<01:23,  8.92it/s] 30%|███       | 326/1070 [00:39<01:23,  8.92it/s] 31%|███       | 327/1070 [00:39<01:23,  8.91it/s] 31%|███       | 328/1070 [00:39<01:22,  8.97it/s] 31%|███       | 329/1070 [00:39<01:23,  8.89it/s] 31%|███       | 330/1070 [00:39<01:22,  8.95it/s] 31%|███       | 331/1070 [00:39<01:22,  8.91it/s] 31%|███       | 332/1070 [00:39<01:22,  8.94it/s] 31%|███       | 333/1070 [00:39<01:23,  8.86it/s] 31%|███       | 334/1070 [00:40<01:22,  8.94it/s] 31%|███▏      | 335/1070 [00:40<01:22,  8.92it/s] 31%|███▏      | 336/1070 [00:40<01:22,  8.90it/s] 31%|███▏      | 337/1070 [00:40<01:21,  9.00it/s] 32%|███▏      | 338/1070 [00:40<01:21,  8.93it/s] 32%|███▏      | 339/1070 [00:40<01:21,  8.93it/s] 32%|███▏      | 340/1070 [00:40<01:21,  8.93it/s] 32%|███▏      | 341/1070 [00:40<01:21,  8.97it/s] 32%|███▏      | 342/1070 [00:40<01:21,  8.95it/s] 32%|███▏      | 343/1070 [00:41<01:21,  8.93it/s] 32%|███▏      | 344/1070 [00:41<01:21,  8.93it/s] 32%|███▏      | 345/1070 [00:41<01:21,  8.90it/s] 32%|███▏      | 346/1070 [00:41<01:21,  8.93it/s] 32%|███▏      | 347/1070 [00:41<01:19,  9.07it/s] 33%|███▎      | 348/1070 [00:41<01:20,  8.95it/s] 33%|███▎      | 349/1070 [00:41<01:20,  8.96it/s] 33%|███▎      | 350/1070 [00:41<01:20,  8.95it/s] 33%|███▎      | 351/1070 [00:41<01:20,  8.93it/s] 33%|███▎      | 352/1070 [00:42<01:21,  8.86it/s] 33%|███▎      | 353/1070 [00:42<01:20,  8.87it/s] 33%|███▎      | 354/1070 [00:42<01:20,  8.87it/s] 33%|███▎      | 355/1070 [00:42<01:20,  8.86it/s] 33%|███▎      | 356/1070 [00:42<01:20,  8.84it/s] 33%|███▎      | 357/1070 [00:42<01:20,  8.89it/s] 33%|███▎      | 358/1070 [00:42<01:19,  8.91it/s] 34%|███▎      | 359/1070 [00:42<01:19,  8.96it/s] 34%|███▎      | 360/1070 [00:42<01:18,  9.06it/s] 34%|███▎      | 361/1070 [00:43<01:19,  8.92it/s] 34%|███▍      | 362/1070 [00:43<01:18,  8.98it/s] 34%|███▍      | 363/1070 [00:43<01:18,  8.96it/s] 34%|███▍      | 364/1070 [00:43<01:18,  8.98it/s] 34%|███▍      | 365/1070 [00:43<01:18,  8.97it/s] 34%|███▍      | 366/1070 [00:43<01:19,  8.91it/s] 34%|███▍      | 367/1070 [00:43<01:19,  8.89it/s] 34%|███▍      | 368/1070 [00:43<01:18,  8.97it/s] 34%|███▍      | 369/1070 [00:43<01:18,  8.98it/s] 35%|███▍      | 370/1070 [00:44<01:16,  9.10it/s] 35%|███▍      | 371/1070 [00:44<01:17,  8.99it/s] 35%|███▍      | 372/1070 [00:44<01:17,  8.97it/s] 35%|███▍      | 373/1070 [00:44<01:17,  8.95it/s] 35%|███▍      | 374/1070 [00:44<01:17,  8.98it/s] 35%|███▌      | 375/1070 [00:44<01:17,  8.94it/s] 35%|███▌      | 376/1070 [00:44<01:17,  8.93it/s] 35%|███▌      | 377/1070 [00:44<01:18,  8.88it/s] 35%|███▌      | 378/1070 [00:44<01:17,  8.94it/s] 35%|███▌      | 379/1070 [00:45<01:18,  8.82it/s] 36%|███▌      | 380/1070 [00:45<01:17,  8.94it/s] 36%|███▌      | 381/1070 [00:45<01:17,  8.86it/s] 36%|███▌      | 382/1070 [00:45<01:17,  8.91it/s] 36%|███▌      | 383/1070 [00:45<01:16,  8.99it/s] 36%|███▌      | 384/1070 [00:45<01:17,  8.88it/s] 36%|███▌      | 385/1070 [00:45<01:17,  8.85it/s] 36%|███▌      | 386/1070 [00:45<01:17,  8.85it/s] 36%|███▌      | 387/1070 [00:45<01:16,  8.91it/s] 36%|███▋      | 388/1070 [00:46<01:16,  8.90it/s] 36%|███▋      | 389/1070 [00:46<01:16,  8.86it/s] 36%|███▋      | 390/1070 [00:46<01:16,  8.87it/s] 37%|███▋      | 391/1070 [00:46<01:16,  8.91it/s] 37%|███▋      | 392/1070 [00:46<01:16,  8.89it/s] 37%|███▋      | 393/1070 [00:46<01:14,  9.07it/s] 37%|███▋      | 394/1070 [00:46<01:15,  8.92it/s] 37%|███▋      | 395/1070 [00:46<01:15,  8.91it/s] 37%|███▋      | 396/1070 [00:46<01:15,  8.92it/s] 37%|███▋      | 397/1070 [00:47<01:15,  8.96it/s] 37%|███▋      | 398/1070 [00:47<01:15,  8.86it/s] 37%|███▋      | 399/1070 [00:47<01:15,  8.91it/s] 37%|███▋      | 400/1070 [00:47<01:15,  8.87it/s] 37%|███▋      | 401/1070 [00:47<01:14,  8.94it/s] 38%|███▊      | 402/1070 [00:47<01:15,  8.85it/s] 38%|███▊      | 403/1070 [00:47<01:14,  8.90it/s] 38%|███▊      | 404/1070 [00:47<01:14,  8.93it/s] 38%|███▊      | 405/1070 [00:47<01:14,  8.89it/s] 38%|███▊      | 406/1070 [00:48<01:13,  9.01it/s] 38%|███▊      | 407/1070 [00:48<01:14,  8.90it/s] 38%|███▊      | 408/1070 [00:48<01:14,  8.94it/s] 38%|███▊      | 409/1070 [00:48<01:13,  8.96it/s] 38%|███▊      | 410/1070 [00:48<01:13,  8.96it/s] 38%|███▊      | 411/1070 [00:48<01:13,  8.97it/s] 39%|███▊      | 412/1070 [00:48<01:14,  8.87it/s] 39%|███▊      | 413/1070 [00:48<01:14,  8.87it/s] 39%|███▊      | 414/1070 [00:48<01:13,  8.87it/s] 39%|███▉      | 415/1070 [00:49<01:13,  8.89it/s] 39%|███▉      | 416/1070 [00:49<01:12,  8.97it/s] 39%|███▉      | 417/1070 [00:49<01:13,  8.90it/s] 39%|███▉      | 418/1070 [00:49<01:13,  8.88it/s] 39%|███▉      | 419/1070 [00:49<01:12,  8.93it/s] 39%|███▉      | 420/1070 [00:49<01:12,  8.95it/s] 39%|███▉      | 421/1070 [00:49<01:13,  8.88it/s] 39%|███▉      | 422/1070 [00:49<01:12,  8.89it/s] 40%|███▉      | 423/1070 [00:49<01:13,  8.86it/s] 40%|███▉      | 424/1070 [00:50<01:12,  8.91it/s] 40%|███▉      | 425/1070 [00:50<01:12,  8.85it/s] 40%|███▉      | 426/1070 [00:50<01:12,  8.88it/s] 40%|███▉      | 427/1070 [00:50<01:11,  8.94it/s]                                                   40%|████      | 428/1070 [00:50<01:11,  8.94it/s][INFO|trainer.py:755] 2023-11-15 19:43:04,355 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:43:04,357 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:43:04,358 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:43:04,358 >>   Batch size = 8
{'eval_loss': 0.29503726959228516, 'eval_accuracy': 0.8986842105263158, 'eval_micro_f1': 0.8986842105263158, 'eval_macro_f1': 0.89587661632091, 'eval_runtime': 1.3528, 'eval_samples_per_second': 561.778, 'eval_steps_per_second': 70.222, 'epoch': 1.0}
{'loss': 0.2342, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:00, 87.46it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 74.33it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 72.99it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 73.42it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 70.78it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 70.42it/s][A
 61%|██████    | 58/95 [00:00<00:00, 70.00it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 71.58it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 70.31it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 70.41it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 70.75it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:51<01:11,  8.94it/s]
100%|██████████| 95/95 [00:01<00:00, 70.75it/s][A
                                               [A 40%|████      | 429/1070 [00:52<04:34,  2.34it/s] 40%|████      | 430/1070 [00:52<03:43,  2.87it/s] 40%|████      | 431/1070 [00:52<03:04,  3.47it/s] 40%|████      | 432/1070 [00:52<02:33,  4.15it/s] 40%|████      | 433/1070 [00:52<02:10,  4.87it/s] 41%|████      | 434/1070 [00:52<01:53,  5.60it/s] 41%|████      | 435/1070 [00:52<01:41,  6.25it/s] 41%|████      | 436/1070 [00:52<01:32,  6.84it/s] 41%|████      | 437/1070 [00:52<01:27,  7.26it/s] 41%|████      | 438/1070 [00:53<01:21,  7.71it/s] 41%|████      | 439/1070 [00:53<01:18,  8.02it/s] 41%|████      | 440/1070 [00:53<01:15,  8.36it/s] 41%|████      | 441/1070 [00:53<01:14,  8.48it/s] 41%|████▏     | 442/1070 [00:53<01:13,  8.59it/s] 41%|████▏     | 443/1070 [00:53<01:12,  8.70it/s] 41%|████▏     | 444/1070 [00:53<01:11,  8.76it/s] 42%|████▏     | 445/1070 [00:53<01:11,  8.79it/s] 42%|████▏     | 446/1070 [00:53<01:11,  8.78it/s] 42%|████▏     | 447/1070 [00:54<01:10,  8.82it/s] 42%|████▏     | 448/1070 [00:54<01:10,  8.87it/s] 42%|████▏     | 449/1070 [00:54<01:10,  8.78it/s] 42%|████▏     | 450/1070 [00:54<01:10,  8.76it/s] 42%|████▏     | 451/1070 [00:54<01:10,  8.83it/s] 42%|████▏     | 452/1070 [00:54<01:09,  8.91it/s] 42%|████▏     | 453/1070 [00:54<01:08,  9.02it/s] 42%|████▏     | 454/1070 [00:54<01:09,  8.87it/s] 43%|████▎     | 455/1070 [00:54<01:09,  8.88it/s] 43%|████▎     | 456/1070 [00:55<01:08,  8.90it/s] 43%|████▎     | 457/1070 [00:55<01:08,  8.91it/s] 43%|████▎     | 458/1070 [00:55<01:09,  8.79it/s] 43%|████▎     | 459/1070 [00:55<01:09,  8.84it/s] 43%|████▎     | 460/1070 [00:55<01:09,  8.78it/s] 43%|████▎     | 461/1070 [00:55<01:08,  8.87it/s] 43%|████▎     | 462/1070 [00:55<01:09,  8.79it/s] 43%|████▎     | 463/1070 [00:55<01:08,  8.87it/s] 43%|████▎     | 464/1070 [00:55<01:08,  8.88it/s] 43%|████▎     | 465/1070 [00:56<01:07,  8.91it/s] 44%|████▎     | 466/1070 [00:56<01:06,  9.04it/s] 44%|████▎     | 467/1070 [00:56<01:07,  8.91it/s] 44%|████▎     | 468/1070 [00:56<01:07,  8.93it/s] 44%|████▍     | 469/1070 [00:56<01:07,  8.90it/s] 44%|████▍     | 470/1070 [00:56<01:06,  8.97it/s] 44%|████▍     | 471/1070 [00:56<01:07,  8.89it/s] 44%|████▍     | 472/1070 [00:56<01:07,  8.90it/s] 44%|████▍     | 473/1070 [00:56<01:07,  8.88it/s] 44%|████▍     | 474/1070 [00:57<01:06,  8.91it/s] 44%|████▍     | 475/1070 [00:57<01:06,  8.88it/s] 44%|████▍     | 476/1070 [00:57<01:06,  9.00it/s] 45%|████▍     | 477/1070 [00:57<01:06,  8.87it/s] 45%|████▍     | 478/1070 [00:57<01:06,  8.95it/s] 45%|████▍     | 479/1070 [00:57<01:05,  8.99it/s] 45%|████▍     | 480/1070 [00:57<01:06,  8.91it/s] 45%|████▍     | 481/1070 [00:57<01:06,  8.83it/s] 45%|████▌     | 482/1070 [00:58<01:06,  8.84it/s] 45%|████▌     | 483/1070 [00:58<01:06,  8.87it/s] 45%|████▌     | 484/1070 [00:58<01:06,  8.85it/s] 45%|████▌     | 485/1070 [00:58<01:06,  8.79it/s] 45%|████▌     | 486/1070 [00:58<01:06,  8.78it/s] 46%|████▌     | 487/1070 [00:58<01:06,  8.83it/s] 46%|████▌     | 488/1070 [00:58<01:06,  8.80it/s] 46%|████▌     | 489/1070 [00:58<01:05,  8.94it/s] 46%|████▌     | 490/1070 [00:58<01:05,  8.88it/s] 46%|████▌     | 491/1070 [00:59<01:04,  8.95it/s] 46%|████▌     | 492/1070 [00:59<01:04,  8.98it/s] 46%|████▌     | 493/1070 [00:59<01:04,  8.98it/s] 46%|████▌     | 494/1070 [00:59<01:04,  8.92it/s] 46%|████▋     | 495/1070 [00:59<01:04,  8.94it/s] 46%|████▋     | 496/1070 [00:59<01:04,  8.92it/s] 46%|████▋     | 497/1070 [00:59<01:03,  8.96it/s] 47%|████▋     | 498/1070 [00:59<01:04,  8.85it/s] 47%|████▋     | 499/1070 [00:59<01:04,  8.86it/s] 47%|████▋     | 500/1070 [01:00<01:04,  8.86it/s] 47%|████▋     | 501/1070 [01:00<01:04,  8.87it/s] 47%|████▋     | 502/1070 [01:00<01:02,  9.02it/s] 47%|████▋     | 503/1070 [01:00<01:03,  9.00it/s] 47%|████▋     | 504/1070 [01:00<01:02,  9.02it/s] 47%|████▋     | 505/1070 [01:00<01:02,  9.02it/s] 47%|████▋     | 506/1070 [01:00<01:02,  9.00it/s] 47%|████▋     | 507/1070 [01:00<01:03,  8.89it/s] 47%|████▋     | 508/1070 [01:00<01:03,  8.89it/s] 48%|████▊     | 509/1070 [01:01<01:03,  8.89it/s] 48%|████▊     | 510/1070 [01:01<01:02,  8.90it/s] 48%|████▊     | 511/1070 [01:01<01:03,  8.81it/s] 48%|████▊     | 512/1070 [01:01<01:02,  8.91it/s] 48%|████▊     | 513/1070 [01:01<01:02,  8.86it/s] 48%|████▊     | 514/1070 [01:01<01:02,  8.92it/s] 48%|████▊     | 515/1070 [01:01<01:01,  9.07it/s] 48%|████▊     | 516/1070 [01:01<01:02,  8.93it/s] 48%|████▊     | 517/1070 [01:01<01:01,  8.96it/s] 48%|████▊     | 518/1070 [01:02<01:01,  8.92it/s] 49%|████▊     | 519/1070 [01:02<01:01,  9.00it/s] 49%|████▊     | 520/1070 [01:02<01:02,  8.87it/s] 49%|████▊     | 521/1070 [01:02<01:01,  8.91it/s] 49%|████▉     | 522/1070 [01:02<01:02,  8.83it/s] 49%|████▉     | 523/1070 [01:02<01:01,  8.88it/s] 49%|████▉     | 524/1070 [01:02<01:02,  8.79it/s] 49%|████▉     | 525/1070 [01:02<01:01,  8.90it/s] 49%|████▉     | 526/1070 [01:02<01:01,  8.83it/s] 49%|████▉     | 527/1070 [01:03<01:01,  8.87it/s] 49%|████▉     | 528/1070 [01:03<01:00,  8.98it/s] 49%|████▉     | 529/1070 [01:03<01:00,  8.94it/s] 50%|████▉     | 530/1070 [01:03<01:00,  8.95it/s] 50%|████▉     | 531/1070 [01:03<01:00,  8.92it/s] 50%|████▉     | 532/1070 [01:03<01:00,  8.95it/s] 50%|████▉     | 533/1070 [01:03<01:00,  8.88it/s] 50%|████▉     | 534/1070 [01:03<01:00,  8.89it/s] 50%|█████     | 535/1070 [01:03<01:00,  8.85it/s] 50%|█████     | 536/1070 [01:04<00:59,  8.93it/s] 50%|█████     | 537/1070 [01:04<00:59,  8.89it/s] 50%|█████     | 538/1070 [01:04<00:59,  8.98it/s] 50%|█████     | 539/1070 [01:04<00:59,  8.96it/s] 50%|█████     | 540/1070 [01:04<00:59,  8.98it/s] 51%|█████     | 541/1070 [01:04<00:58,  9.02it/s] 51%|█████     | 542/1070 [01:04<00:59,  8.90it/s] 51%|█████     | 543/1070 [01:04<00:59,  8.90it/s] 51%|█████     | 544/1070 [01:04<00:59,  8.90it/s] 51%|█████     | 545/1070 [01:05<00:58,  8.95it/s] 51%|█████     | 546/1070 [01:05<00:59,  8.85it/s] 51%|█████     | 547/1070 [01:05<00:58,  8.88it/s] 51%|█████     | 548/1070 [01:05<00:59,  8.81it/s] 51%|█████▏    | 549/1070 [01:05<00:59,  8.78it/s] 51%|█████▏    | 550/1070 [01:05<00:59,  8.77it/s] 51%|█████▏    | 551/1070 [01:05<00:58,  8.81it/s] 52%|█████▏    | 552/1070 [01:05<00:58,  8.83it/s] 52%|█████▏    | 553/1070 [01:05<00:58,  8.82it/s] 52%|█████▏    | 554/1070 [01:06<00:58,  8.85it/s] 52%|█████▏    | 555/1070 [01:06<00:58,  8.74it/s] 52%|█████▏    | 556/1070 [01:06<00:58,  8.81it/s] 52%|█████▏    | 557/1070 [01:06<00:58,  8.81it/s] 52%|█████▏    | 558/1070 [01:06<00:57,  8.85it/s] 52%|█████▏    | 559/1070 [01:06<00:58,  8.76it/s] 52%|█████▏    | 560/1070 [01:06<00:58,  8.78it/s] 52%|█████▏    | 561/1070 [01:06<00:58,  8.77it/s] 53%|█████▎    | 562/1070 [01:07<00:57,  8.76it/s] 53%|█████▎    | 563/1070 [01:07<00:58,  8.72it/s] 53%|█████▎    | 564/1070 [01:07<00:58,  8.68it/s] 53%|█████▎    | 565/1070 [01:07<00:57,  8.72it/s] 53%|█████▎    | 566/1070 [01:07<00:57,  8.76it/s] 53%|█████▎    | 567/1070 [01:07<00:56,  8.88it/s] 53%|█████▎    | 568/1070 [01:07<00:56,  8.82it/s] 53%|█████▎    | 569/1070 [01:07<00:56,  8.84it/s] 53%|█████▎    | 570/1070 [01:07<00:55,  8.95it/s] 53%|█████▎    | 571/1070 [01:08<00:55,  8.92it/s] 53%|█████▎    | 572/1070 [01:08<00:56,  8.88it/s] 54%|█████▎    | 573/1070 [01:08<00:56,  8.87it/s] 54%|█████▎    | 574/1070 [01:08<00:55,  8.94it/s] 54%|█████▎    | 575/1070 [01:08<00:55,  8.87it/s] 54%|█████▍    | 576/1070 [01:08<00:55,  8.88it/s] 54%|█████▍    | 577/1070 [01:08<00:56,  8.78it/s] 54%|█████▍    | 578/1070 [01:08<00:55,  8.85it/s] 54%|█████▍    | 579/1070 [01:08<00:55,  8.77it/s] 54%|█████▍    | 580/1070 [01:09<00:55,  8.85it/s] 54%|█████▍    | 581/1070 [01:09<00:55,  8.86it/s] 54%|█████▍    | 582/1070 [01:09<00:54,  8.92it/s] 54%|█████▍    | 583/1070 [01:09<00:53,  9.02it/s] 55%|█████▍    | 584/1070 [01:09<00:54,  8.90it/s] 55%|█████▍    | 585/1070 [01:09<00:54,  8.90it/s] 55%|█████▍    | 586/1070 [01:09<00:54,  8.93it/s] 55%|█████▍    | 587/1070 [01:09<00:53,  8.97it/s] 55%|█████▍    | 588/1070 [01:09<00:54,  8.82it/s] 55%|█████▌    | 589/1070 [01:10<00:54,  8.85it/s] 55%|█████▌    | 590/1070 [01:10<00:54,  8.83it/s] 55%|█████▌    | 591/1070 [01:10<00:53,  8.90it/s] 55%|█████▌    | 592/1070 [01:10<00:54,  8.81it/s] 55%|█████▌    | 593/1070 [01:10<00:54,  8.82it/s] 56%|█████▌    | 594/1070 [01:10<00:54,  8.78it/s] 56%|█████▌    | 595/1070 [01:10<00:53,  8.87it/s] 56%|█████▌    | 596/1070 [01:10<00:52,  8.99it/s] 56%|█████▌    | 597/1070 [01:10<00:53,  8.90it/s] 56%|█████▌    | 598/1070 [01:11<00:52,  8.92it/s] 56%|█████▌    | 599/1070 [01:11<00:52,  8.93it/s] 56%|█████▌    | 600/1070 [01:11<00:52,  8.89it/s] 56%|█████▌    | 601/1070 [01:11<00:52,  8.89it/s] 56%|█████▋    | 602/1070 [01:11<00:52,  8.89it/s] 56%|█████▋    | 603/1070 [01:11<00:52,  8.90it/s] 56%|█████▋    | 604/1070 [01:11<00:53,  8.78it/s] 57%|█████▋    | 605/1070 [01:11<00:52,  8.79it/s] 57%|█████▋    | 606/1070 [01:11<00:52,  8.79it/s] 57%|█████▋    | 607/1070 [01:12<00:52,  8.85it/s] 57%|█████▋    | 608/1070 [01:12<00:52,  8.75it/s] 57%|█████▋    | 609/1070 [01:12<00:52,  8.82it/s] 57%|█████▋    | 610/1070 [01:12<00:52,  8.80it/s] 57%|█████▋    | 611/1070 [01:12<00:51,  8.87it/s] 57%|█████▋    | 612/1070 [01:12<00:50,  8.99it/s] 57%|█████▋    | 613/1070 [01:12<00:51,  8.88it/s] 57%|█████▋    | 614/1070 [01:12<00:51,  8.85it/s] 57%|█████▋    | 615/1070 [01:12<00:51,  8.86it/s] 58%|█████▊    | 616/1070 [01:13<00:50,  8.91it/s] 58%|█████▊    | 617/1070 [01:13<00:51,  8.87it/s] 58%|█████▊    | 618/1070 [01:13<00:51,  8.83it/s] 58%|█████▊    | 619/1070 [01:13<00:51,  8.79it/s] 58%|█████▊    | 620/1070 [01:13<00:50,  8.85it/s] 58%|█████▊    | 621/1070 [01:13<00:51,  8.79it/s] 58%|█████▊    | 622/1070 [01:13<00:50,  8.85it/s] 58%|█████▊    | 623/1070 [01:13<00:50,  8.89it/s] 58%|█████▊    | 624/1070 [01:14<00:50,  8.82it/s] 58%|█████▊    | 625/1070 [01:14<00:49,  8.93it/s] 59%|█████▊    | 626/1070 [01:14<00:50,  8.84it/s] 59%|█████▊    | 627/1070 [01:14<00:50,  8.83it/s] 59%|█████▊    | 628/1070 [01:14<00:50,  8.81it/s] 59%|█████▉    | 629/1070 [01:14<00:49,  8.88it/s] 59%|█████▉    | 630/1070 [01:14<00:49,  8.87it/s] 59%|█████▉    | 631/1070 [01:14<00:49,  8.88it/s] 59%|█████▉    | 632/1070 [01:14<00:49,  8.92it/s] 59%|█████▉    | 633/1070 [01:15<00:49,  8.86it/s] 59%|█████▉    | 634/1070 [01:15<00:48,  8.92it/s] 59%|█████▉    | 635/1070 [01:15<00:48,  8.98it/s] 59%|█████▉    | 636/1070 [01:15<00:49,  8.84it/s] 60%|█████▉    | 637/1070 [01:15<00:48,  8.89it/s] 60%|█████▉    | 638/1070 [01:15<00:48,  8.89it/s] 60%|█████▉    | 639/1070 [01:15<00:48,  8.91it/s] 60%|█████▉    | 640/1070 [01:15<00:48,  8.80it/s] 60%|█████▉    | 641/1070 [01:15<00:48,  8.85it/s]                                                   60%|██████    | 642/1070 [01:16<00:48,  8.85it/s][INFO|trainer.py:755] 2023-11-15 19:43:29,835 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:43:29,837 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:43:29,837 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:43:29,837 >>   Batch size = 8
{'eval_loss': 0.27156704664230347, 'eval_accuracy': 0.9131578947368421, 'eval_micro_f1': 0.9131578947368421, 'eval_macro_f1': 0.9106413817156589, 'eval_runtime': 1.3782, 'eval_samples_per_second': 551.427, 'eval_steps_per_second': 68.928, 'epoch': 2.0}
{'loss': 0.1671, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 79.59it/s][A
 18%|█▊        | 17/95 [00:00<00:01, 72.73it/s][A
 26%|██▋       | 25/95 [00:00<00:00, 72.05it/s][A
 35%|███▍      | 33/95 [00:00<00:00, 70.79it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 71.48it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 72.72it/s][A
 60%|██████    | 57/95 [00:00<00:00, 69.47it/s][A
 67%|██████▋   | 64/95 [00:00<00:00, 68.87it/s][A
 76%|███████▌  | 72/95 [00:01<00:00, 68.96it/s][A
 84%|████████▍ | 80/95 [00:01<00:00, 70.68it/s][A
 93%|█████████▎| 88/95 [00:01<00:00, 68.90it/s][A
100%|██████████| 95/95 [00:01<00:00, 69.16it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:17<00:48,  8.85it/s]
100%|██████████| 95/95 [00:01<00:00, 69.16it/s][A
                                               [A 60%|██████    | 643/1070 [01:17<03:07,  2.28it/s] 60%|██████    | 644/1070 [01:17<02:32,  2.78it/s] 60%|██████    | 645/1070 [01:17<02:05,  3.38it/s] 60%|██████    | 646/1070 [01:17<01:44,  4.05it/s] 60%|██████    | 647/1070 [01:18<01:28,  4.78it/s] 61%|██████    | 648/1070 [01:18<01:17,  5.47it/s] 61%|██████    | 649/1070 [01:18<01:08,  6.19it/s] 61%|██████    | 650/1070 [01:18<01:01,  6.78it/s] 61%|██████    | 651/1070 [01:18<00:57,  7.26it/s] 61%|██████    | 652/1070 [01:18<00:54,  7.73it/s] 61%|██████    | 653/1070 [01:18<00:52,  7.95it/s] 61%|██████    | 654/1070 [01:18<00:51,  8.15it/s] 61%|██████    | 655/1070 [01:18<00:49,  8.37it/s] 61%|██████▏   | 656/1070 [01:19<00:48,  8.51it/s] 61%|██████▏   | 657/1070 [01:19<00:48,  8.52it/s] 61%|██████▏   | 658/1070 [01:19<00:47,  8.62it/s] 62%|██████▏   | 659/1070 [01:19<00:47,  8.66it/s] 62%|██████▏   | 660/1070 [01:19<00:47,  8.70it/s] 62%|██████▏   | 661/1070 [01:19<00:46,  8.73it/s] 62%|██████▏   | 662/1070 [01:19<00:45,  8.93it/s] 62%|██████▏   | 663/1070 [01:19<00:46,  8.83it/s] 62%|██████▏   | 664/1070 [01:19<00:46,  8.81it/s] 62%|██████▏   | 665/1070 [01:20<00:46,  8.79it/s] 62%|██████▏   | 666/1070 [01:20<00:45,  8.86it/s] 62%|██████▏   | 667/1070 [01:20<00:45,  8.80it/s] 62%|██████▏   | 668/1070 [01:20<00:45,  8.79it/s] 63%|██████▎   | 669/1070 [01:20<00:45,  8.75it/s] 63%|██████▎   | 670/1070 [01:20<00:45,  8.80it/s] 63%|██████▎   | 671/1070 [01:20<00:45,  8.79it/s] 63%|██████▎   | 672/1070 [01:20<00:44,  8.89it/s] 63%|██████▎   | 673/1070 [01:20<00:44,  8.87it/s] 63%|██████▎   | 674/1070 [01:21<00:44,  8.85it/s] 63%|██████▎   | 675/1070 [01:21<00:44,  8.87it/s] 63%|██████▎   | 676/1070 [01:21<00:44,  8.87it/s] 63%|██████▎   | 677/1070 [01:21<00:44,  8.81it/s] 63%|██████▎   | 678/1070 [01:21<00:44,  8.83it/s] 63%|██████▎   | 679/1070 [01:21<00:44,  8.83it/s] 64%|██████▎   | 680/1070 [01:21<00:43,  8.89it/s] 64%|██████▎   | 681/1070 [01:21<00:44,  8.81it/s] 64%|██████▎   | 682/1070 [01:21<00:43,  8.92it/s] 64%|██████▍   | 683/1070 [01:22<00:43,  8.90it/s] 64%|██████▍   | 684/1070 [01:22<00:43,  8.98it/s] 64%|██████▍   | 685/1070 [01:22<00:42,  8.95it/s] 64%|██████▍   | 686/1070 [01:22<00:43,  8.92it/s] 64%|██████▍   | 687/1070 [01:22<00:43,  8.82it/s] 64%|██████▍   | 688/1070 [01:22<00:43,  8.82it/s] 64%|██████▍   | 689/1070 [01:22<00:43,  8.79it/s] 64%|██████▍   | 690/1070 [01:22<00:42,  8.85it/s] 65%|██████▍   | 691/1070 [01:23<00:43,  8.78it/s] 65%|██████▍   | 692/1070 [01:23<00:42,  8.83it/s] 65%|██████▍   | 693/1070 [01:23<00:42,  8.78it/s] 65%|██████▍   | 694/1070 [01:23<00:42,  8.78it/s] 65%|██████▍   | 695/1070 [01:23<00:42,  8.90it/s] 65%|██████▌   | 696/1070 [01:23<00:42,  8.81it/s] 65%|██████▌   | 697/1070 [01:23<00:42,  8.82it/s] 65%|██████▌   | 698/1070 [01:23<00:42,  8.82it/s] 65%|██████▌   | 699/1070 [01:23<00:42,  8.83it/s] 65%|██████▌   | 700/1070 [01:24<00:41,  8.81it/s] 66%|██████▌   | 701/1070 [01:24<00:41,  8.81it/s] 66%|██████▌   | 702/1070 [01:24<00:41,  8.83it/s] 66%|██████▌   | 703/1070 [01:24<00:41,  8.86it/s] 66%|██████▌   | 704/1070 [01:24<00:41,  8.86it/s] 66%|██████▌   | 705/1070 [01:24<00:40,  8.99it/s] 66%|██████▌   | 706/1070 [01:24<00:41,  8.86it/s] 66%|██████▌   | 707/1070 [01:24<00:40,  8.87it/s] 66%|██████▌   | 708/1070 [01:24<00:40,  8.87it/s] 66%|██████▋   | 709/1070 [01:25<00:40,  8.92it/s] 66%|██████▋   | 710/1070 [01:25<00:40,  8.82it/s] 66%|██████▋   | 711/1070 [01:25<00:40,  8.84it/s] 67%|██████▋   | 712/1070 [01:25<00:40,  8.83it/s] 67%|██████▋   | 713/1070 [01:25<00:39,  8.93it/s] 67%|██████▋   | 714/1070 [01:25<00:40,  8.81it/s] 67%|██████▋   | 715/1070 [01:25<00:40,  8.83it/s] 67%|██████▋   | 716/1070 [01:25<00:39,  8.88it/s] 67%|██████▋   | 717/1070 [01:25<00:39,  8.90it/s] 67%|██████▋   | 718/1070 [01:26<00:39,  8.94it/s] 67%|██████▋   | 719/1070 [01:26<00:39,  8.81it/s] 67%|██████▋   | 720/1070 [01:26<00:39,  8.86it/s] 67%|██████▋   | 721/1070 [01:26<00:39,  8.94it/s] 67%|██████▋   | 722/1070 [01:26<00:39,  8.91it/s] 68%|██████▊   | 723/1070 [01:26<00:39,  8.81it/s] 68%|██████▊   | 724/1070 [01:26<00:39,  8.86it/s] 68%|██████▊   | 725/1070 [01:26<00:39,  8.84it/s] 68%|██████▊   | 726/1070 [01:26<00:38,  8.85it/s] 68%|██████▊   | 727/1070 [01:27<00:38,  8.81it/s] 68%|██████▊   | 728/1070 [01:27<00:38,  8.83it/s] 68%|██████▊   | 729/1070 [01:27<00:38,  8.84it/s] 68%|██████▊   | 730/1070 [01:27<00:38,  8.84it/s] 68%|██████▊   | 731/1070 [01:27<00:38,  8.90it/s] 68%|██████▊   | 732/1070 [01:27<00:38,  8.84it/s] 69%|██████▊   | 733/1070 [01:27<00:37,  8.88it/s] 69%|██████▊   | 734/1070 [01:27<00:37,  8.92it/s] 69%|██████▊   | 735/1070 [01:27<00:37,  8.89it/s] 69%|██████▉   | 736/1070 [01:28<00:38,  8.78it/s] 69%|██████▉   | 737/1070 [01:28<00:37,  8.84it/s] 69%|██████▉   | 738/1070 [01:28<00:37,  8.83it/s] 69%|██████▉   | 739/1070 [01:28<00:37,  8.82it/s] 69%|██████▉   | 740/1070 [01:28<00:37,  8.73it/s] 69%|██████▉   | 741/1070 [01:28<00:37,  8.78it/s] 69%|██████▉   | 742/1070 [01:28<00:37,  8.76it/s] 69%|██████▉   | 743/1070 [01:28<00:37,  8.76it/s] 70%|██████▉   | 744/1070 [01:28<00:36,  8.83it/s] 70%|██████▉   | 745/1070 [01:29<00:36,  8.80it/s] 70%|██████▉   | 746/1070 [01:29<00:37,  8.71it/s] 70%|██████▉   | 747/1070 [01:29<00:36,  8.75it/s] 70%|██████▉   | 748/1070 [01:29<00:36,  8.76it/s] 70%|███████   | 749/1070 [01:29<00:36,  8.72it/s] 70%|███████   | 750/1070 [01:29<00:36,  8.70it/s] 70%|███████   | 751/1070 [01:29<00:36,  8.70it/s] 70%|███████   | 752/1070 [01:29<00:36,  8.73it/s] 70%|███████   | 753/1070 [01:30<00:36,  8.72it/s] 70%|███████   | 754/1070 [01:30<00:35,  8.83it/s] 71%|███████   | 755/1070 [01:30<00:35,  8.85it/s] 71%|███████   | 756/1070 [01:30<00:35,  8.81it/s] 71%|███████   | 757/1070 [01:30<00:35,  8.81it/s] 71%|███████   | 758/1070 [01:30<00:35,  8.73it/s] 71%|███████   | 759/1070 [01:30<00:35,  8.79it/s] 71%|███████   | 760/1070 [01:30<00:35,  8.67it/s] 71%|███████   | 761/1070 [01:30<00:35,  8.78it/s] 71%|███████   | 762/1070 [01:31<00:35,  8.67it/s] 71%|███████▏  | 763/1070 [01:31<00:35,  8.71it/s] 71%|███████▏  | 764/1070 [01:31<00:34,  8.76it/s] 71%|███████▏  | 765/1070 [01:31<00:34,  8.81it/s] 72%|███████▏  | 766/1070 [01:31<00:34,  8.71it/s] 72%|███████▏  | 767/1070 [01:31<00:34,  8.72it/s] 72%|███████▏  | 768/1070 [01:31<00:34,  8.70it/s] 72%|███████▏  | 769/1070 [01:31<00:34,  8.76it/s] 72%|███████▏  | 770/1070 [01:31<00:34,  8.77it/s] 72%|███████▏  | 771/1070 [01:32<00:33,  8.90it/s] 72%|███████▏  | 772/1070 [01:32<00:33,  8.86it/s] 72%|███████▏  | 773/1070 [01:32<00:33,  8.75it/s] 72%|███████▏  | 774/1070 [01:32<00:33,  8.78it/s] 72%|███████▏  | 775/1070 [01:32<00:33,  8.79it/s] 73%|███████▎  | 776/1070 [01:32<00:33,  8.79it/s] 73%|███████▎  | 777/1070 [01:32<00:33,  8.74it/s] 73%|███████▎  | 778/1070 [01:32<00:33,  8.77it/s] 73%|███████▎  | 779/1070 [01:32<00:33,  8.76it/s] 73%|███████▎  | 780/1070 [01:33<00:33,  8.70it/s] 73%|███████▎  | 781/1070 [01:33<00:32,  8.85it/s] 73%|███████▎  | 782/1070 [01:33<00:33,  8.69it/s] 73%|███████▎  | 783/1070 [01:33<00:33,  8.66it/s] 73%|███████▎  | 784/1070 [01:33<00:32,  8.71it/s] 73%|███████▎  | 785/1070 [01:33<00:32,  8.73it/s] 73%|███████▎  | 786/1070 [01:33<00:32,  8.76it/s] 74%|███████▎  | 787/1070 [01:33<00:32,  8.75it/s] 74%|███████▎  | 788/1070 [01:34<00:31,  8.85it/s] 74%|███████▎  | 789/1070 [01:34<00:32,  8.77it/s] 74%|███████▍  | 790/1070 [01:34<00:31,  8.80it/s] 74%|███████▍  | 791/1070 [01:34<00:31,  8.86it/s] 74%|███████▍  | 792/1070 [01:34<00:31,  8.85it/s] 74%|███████▍  | 793/1070 [01:34<00:31,  8.76it/s] 74%|███████▍  | 794/1070 [01:34<00:31,  8.76it/s] 74%|███████▍  | 795/1070 [01:34<00:31,  8.71it/s] 74%|███████▍  | 796/1070 [01:34<00:31,  8.75it/s] 74%|███████▍  | 797/1070 [01:35<00:31,  8.72it/s] 75%|███████▍  | 798/1070 [01:35<00:30,  8.84it/s] 75%|███████▍  | 799/1070 [01:35<00:30,  8.81it/s] 75%|███████▍  | 800/1070 [01:35<00:30,  8.87it/s] 75%|███████▍  | 801/1070 [01:35<00:30,  8.94it/s] 75%|███████▍  | 802/1070 [01:35<00:30,  8.87it/s] 75%|███████▌  | 803/1070 [01:35<00:30,  8.76it/s] 75%|███████▌  | 804/1070 [01:35<00:30,  8.78it/s] 75%|███████▌  | 805/1070 [01:35<00:30,  8.77it/s] 75%|███████▌  | 806/1070 [01:36<00:30,  8.79it/s] 75%|███████▌  | 807/1070 [01:36<00:30,  8.69it/s] 76%|███████▌  | 808/1070 [01:36<00:30,  8.73it/s] 76%|███████▌  | 809/1070 [01:36<00:29,  8.82it/s] 76%|███████▌  | 810/1070 [01:36<00:29,  8.80it/s] 76%|███████▌  | 811/1070 [01:36<00:29,  8.84it/s] 76%|███████▌  | 812/1070 [01:36<00:29,  8.77it/s] 76%|███████▌  | 813/1070 [01:36<00:29,  8.78it/s] 76%|███████▌  | 814/1070 [01:36<00:29,  8.76it/s] 76%|███████▌  | 815/1070 [01:37<00:28,  8.81it/s] 76%|███████▋  | 816/1070 [01:37<00:28,  8.84it/s] 76%|███████▋  | 817/1070 [01:37<00:28,  8.77it/s] 76%|███████▋  | 818/1070 [01:37<00:28,  8.80it/s] 77%|███████▋  | 819/1070 [01:37<00:28,  8.83it/s] 77%|███████▋  | 820/1070 [01:37<00:28,  8.88it/s] 77%|███████▋  | 821/1070 [01:37<00:27,  8.91it/s] 77%|███████▋  | 822/1070 [01:37<00:28,  8.79it/s] 77%|███████▋  | 823/1070 [01:37<00:27,  8.83it/s] 77%|███████▋  | 824/1070 [01:38<00:28,  8.78it/s] 77%|███████▋  | 825/1070 [01:38<00:27,  8.82it/s] 77%|███████▋  | 826/1070 [01:38<00:27,  8.84it/s] 77%|███████▋  | 827/1070 [01:38<00:27,  8.75it/s] 77%|███████▋  | 828/1070 [01:38<00:27,  8.87it/s] 77%|███████▋  | 829/1070 [01:38<00:27,  8.82it/s] 78%|███████▊  | 830/1070 [01:38<00:27,  8.87it/s] 78%|███████▊  | 831/1070 [01:38<00:26,  8.95it/s] 78%|███████▊  | 832/1070 [01:39<00:26,  8.83it/s] 78%|███████▊  | 833/1070 [01:39<00:26,  8.80it/s] 78%|███████▊  | 834/1070 [01:39<00:26,  8.80it/s] 78%|███████▊  | 835/1070 [01:39<00:26,  8.82it/s] 78%|███████▊  | 836/1070 [01:39<00:26,  8.87it/s] 78%|███████▊  | 837/1070 [01:39<00:26,  8.81it/s] 78%|███████▊  | 838/1070 [01:39<00:26,  8.82it/s] 78%|███████▊  | 839/1070 [01:39<00:26,  8.76it/s] 79%|███████▊  | 840/1070 [01:39<00:26,  8.79it/s] 79%|███████▊  | 841/1070 [01:40<00:25,  8.91it/s] 79%|███████▊  | 842/1070 [01:40<00:25,  8.84it/s] 79%|███████▉  | 843/1070 [01:40<00:25,  8.84it/s] 79%|███████▉  | 844/1070 [01:40<00:25,  8.90it/s] 79%|███████▉  | 845/1070 [01:40<00:25,  8.85it/s] 79%|███████▉  | 846/1070 [01:40<00:25,  8.90it/s] 79%|███████▉  | 847/1070 [01:40<00:25,  8.78it/s] 79%|███████▉  | 848/1070 [01:40<00:25,  8.81it/s] 79%|███████▉  | 849/1070 [01:40<00:25,  8.76it/s] 79%|███████▉  | 850/1070 [01:41<00:24,  8.82it/s] 80%|███████▉  | 851/1070 [01:41<00:24,  8.88it/s] 80%|███████▉  | 852/1070 [01:41<00:24,  8.81it/s] 80%|███████▉  | 853/1070 [01:41<00:24,  8.81it/s] 80%|███████▉  | 854/1070 [01:41<00:24,  8.79it/s] 80%|███████▉  | 855/1070 [01:41<00:24,  8.83it/s]                                                   80%|████████  | 856/1070 [01:41<00:24,  8.83it/s][INFO|trainer.py:755] 2023-11-15 19:43:55,533 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:43:55,535 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:43:55,536 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:43:55,536 >>   Batch size = 8
{'eval_loss': 0.30160102248191833, 'eval_accuracy': 0.9118421052631579, 'eval_micro_f1': 0.9118421052631579, 'eval_macro_f1': 0.9088849645601841, 'eval_runtime': 1.4011, 'eval_samples_per_second': 542.413, 'eval_steps_per_second': 67.802, 'epoch': 3.0}
{'loss': 0.1122, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 81.19it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 73.36it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 72.24it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 69.14it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 68.65it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 68.96it/s][A
 59%|█████▉    | 56/95 [00:00<00:00, 68.76it/s][A
 66%|██████▋   | 63/95 [00:00<00:00, 68.39it/s][A
 75%|███████▍  | 71/95 [00:01<00:00, 69.97it/s][A
 83%|████████▎ | 79/95 [00:01<00:00, 68.92it/s][A
 92%|█████████▏| 87/95 [00:01<00:00, 70.16it/s][A
100%|██████████| 95/95 [00:01<00:00, 69.82it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:43<00:24,  8.83it/s]
100%|██████████| 95/95 [00:01<00:00, 69.82it/s][A
                                               [A 80%|████████  | 857/1070 [01:43<01:33,  2.28it/s] 80%|████████  | 858/1070 [01:43<01:15,  2.79it/s] 80%|████████  | 859/1070 [01:43<01:02,  3.40it/s] 80%|████████  | 860/1070 [01:43<00:51,  4.07it/s] 80%|████████  | 861/1070 [01:43<00:43,  4.79it/s] 81%|████████  | 862/1070 [01:43<00:37,  5.53it/s] 81%|████████  | 863/1070 [01:43<00:33,  6.17it/s] 81%|████████  | 864/1070 [01:44<00:30,  6.73it/s] 81%|████████  | 865/1070 [01:44<00:28,  7.24it/s] 81%|████████  | 866/1070 [01:44<00:26,  7.68it/s] 81%|████████  | 867/1070 [01:44<00:25,  7.93it/s] 81%|████████  | 868/1070 [01:44<00:24,  8.15it/s] 81%|████████  | 869/1070 [01:44<00:24,  8.32it/s] 81%|████████▏ | 870/1070 [01:44<00:23,  8.42it/s] 81%|████████▏ | 871/1070 [01:44<00:23,  8.57it/s] 81%|████████▏ | 872/1070 [01:44<00:22,  8.73it/s] 82%|████████▏ | 873/1070 [01:45<00:22,  8.67it/s] 82%|████████▏ | 874/1070 [01:45<00:22,  8.67it/s] 82%|████████▏ | 875/1070 [01:45<00:22,  8.68it/s] 82%|████████▏ | 876/1070 [01:45<00:22,  8.76it/s] 82%|████████▏ | 877/1070 [01:45<00:22,  8.67it/s] 82%|████████▏ | 878/1070 [01:45<00:22,  8.64it/s] 82%|████████▏ | 879/1070 [01:45<00:22,  8.65it/s] 82%|████████▏ | 880/1070 [01:45<00:21,  8.74it/s] 82%|████████▏ | 881/1070 [01:45<00:21,  8.79it/s] 82%|████████▏ | 882/1070 [01:46<00:21,  8.90it/s] 83%|████████▎ | 883/1070 [01:46<00:21,  8.82it/s] 83%|████████▎ | 884/1070 [01:46<00:21,  8.72it/s] 83%|████████▎ | 885/1070 [01:46<00:21,  8.70it/s] 83%|████████▎ | 886/1070 [01:46<00:21,  8.75it/s] 83%|████████▎ | 887/1070 [01:46<00:21,  8.71it/s] 83%|████████▎ | 888/1070 [01:46<00:20,  8.69it/s] 83%|████████▎ | 889/1070 [01:46<00:20,  8.68it/s] 83%|████████▎ | 890/1070 [01:47<00:20,  8.77it/s] 83%|████████▎ | 891/1070 [01:47<00:20,  8.71it/s] 83%|████████▎ | 892/1070 [01:47<00:20,  8.76it/s] 83%|████████▎ | 893/1070 [01:47<00:20,  8.78it/s] 84%|████████▎ | 894/1070 [01:47<00:20,  8.75it/s] 84%|████████▎ | 895/1070 [01:47<00:19,  8.76it/s] 84%|████████▎ | 896/1070 [01:47<00:19,  8.74it/s] 84%|████████▍ | 897/1070 [01:47<00:19,  8.71it/s] 84%|████████▍ | 898/1070 [01:47<00:19,  8.70it/s] 84%|████████▍ | 899/1070 [01:48<00:19,  8.65it/s] 84%|████████▍ | 900/1070 [01:48<00:19,  8.71it/s] 84%|████████▍ | 901/1070 [01:48<00:19,  8.67it/s] 84%|████████▍ | 902/1070 [01:48<00:19,  8.74it/s] 84%|████████▍ | 903/1070 [01:48<00:19,  8.73it/s] 84%|████████▍ | 904/1070 [01:48<00:18,  8.78it/s] 85%|████████▍ | 905/1070 [01:48<00:18,  8.84it/s] 85%|████████▍ | 906/1070 [01:48<00:18,  8.85it/s] 85%|████████▍ | 907/1070 [01:48<00:18,  8.73it/s] 85%|████████▍ | 908/1070 [01:49<00:18,  8.79it/s] 85%|████████▍ | 909/1070 [01:49<00:18,  8.75it/s] 85%|████████▌ | 910/1070 [01:49<00:18,  8.80it/s] 85%|████████▌ | 911/1070 [01:49<00:18,  8.74it/s] 85%|████████▌ | 912/1070 [01:49<00:17,  8.84it/s] 85%|████████▌ | 913/1070 [01:49<00:17,  8.83it/s] 85%|████████▌ | 914/1070 [01:49<00:17,  8.86it/s] 86%|████████▌ | 915/1070 [01:49<00:17,  8.86it/s] 86%|████████▌ | 916/1070 [01:49<00:17,  8.85it/s] 86%|████████▌ | 917/1070 [01:50<00:17,  8.81it/s] 86%|████████▌ | 918/1070 [01:50<00:17,  8.79it/s] 86%|████████▌ | 919/1070 [01:50<00:17,  8.77it/s] 86%|████████▌ | 920/1070 [01:50<00:17,  8.81it/s] 86%|████████▌ | 921/1070 [01:50<00:16,  8.79it/s] 86%|████████▌ | 922/1070 [01:50<00:16,  8.89it/s] 86%|████████▋ | 923/1070 [01:50<00:16,  8.85it/s] 86%|████████▋ | 924/1070 [01:50<00:16,  8.84it/s] 86%|████████▋ | 925/1070 [01:51<00:16,  8.84it/s] 87%|████████▋ | 926/1070 [01:51<00:16,  8.87it/s] 87%|████████▋ | 927/1070 [01:51<00:16,  8.84it/s] 87%|████████▋ | 928/1070 [01:51<00:16,  8.85it/s] 87%|████████▋ | 929/1070 [01:51<00:15,  8.83it/s] 87%|████████▋ | 930/1070 [01:51<00:15,  8.79it/s] 87%|████████▋ | 931/1070 [01:51<00:15,  8.86it/s] 87%|████████▋ | 932/1070 [01:51<00:15,  8.94it/s] 87%|████████▋ | 933/1070 [01:51<00:15,  8.88it/s] 87%|████████▋ | 934/1070 [01:52<00:15,  8.87it/s] 87%|████████▋ | 935/1070 [01:52<00:15,  8.79it/s] 87%|████████▋ | 936/1070 [01:52<00:15,  8.84it/s] 88%|████████▊ | 937/1070 [01:52<00:15,  8.76it/s] 88%|████████▊ | 938/1070 [01:52<00:15,  8.75it/s] 88%|████████▊ | 939/1070 [01:52<00:14,  8.78it/s] 88%|████████▊ | 940/1070 [01:52<00:14,  8.79it/s] 88%|████████▊ | 941/1070 [01:52<00:14,  8.73it/s] 88%|████████▊ | 942/1070 [01:52<00:14,  8.93it/s] 88%|████████▊ | 943/1070 [01:53<00:14,  8.88it/s] 88%|████████▊ | 944/1070 [01:53<00:14,  8.86it/s] 88%|████████▊ | 945/1070 [01:53<00:14,  8.81it/s] 88%|████████▊ | 946/1070 [01:53<00:14,  8.85it/s] 89%|████████▊ | 947/1070 [01:53<00:14,  8.76it/s] 89%|████████▊ | 948/1070 [01:53<00:13,  8.74it/s] 89%|████████▊ | 949/1070 [01:53<00:13,  8.72it/s] 89%|████████▉ | 950/1070 [01:53<00:13,  8.77it/s] 89%|████████▉ | 951/1070 [01:53<00:13,  8.80it/s] 89%|████████▉ | 952/1070 [01:54<00:13,  8.91it/s] 89%|████████▉ | 953/1070 [01:54<00:13,  8.86it/s] 89%|████████▉ | 954/1070 [01:54<00:13,  8.86it/s] 89%|████████▉ | 955/1070 [01:54<00:13,  8.84it/s] 89%|████████▉ | 956/1070 [01:54<00:12,  8.88it/s] 89%|████████▉ | 957/1070 [01:54<00:12,  8.79it/s] 90%|████████▉ | 958/1070 [01:54<00:12,  8.81it/s] 90%|████████▉ | 959/1070 [01:54<00:12,  8.80it/s] 90%|████████▉ | 960/1070 [01:54<00:12,  8.88it/s] 90%|████████▉ | 961/1070 [01:55<00:12,  8.78it/s] 90%|████████▉ | 962/1070 [01:55<00:12,  8.97it/s] 90%|█████████ | 963/1070 [01:55<00:12,  8.83it/s] 90%|█████████ | 964/1070 [01:55<00:12,  8.75it/s] 90%|█████████ | 965/1070 [01:55<00:11,  8.82it/s] 90%|█████████ | 966/1070 [01:55<00:11,  8.86it/s] 90%|█████████ | 967/1070 [01:55<00:11,  8.77it/s] 90%|█████████ | 968/1070 [01:55<00:11,  8.78it/s] 91%|█████████ | 969/1070 [01:55<00:11,  8.80it/s] 91%|█████████ | 970/1070 [01:56<00:11,  8.84it/s] 91%|█████████ | 971/1070 [01:56<00:11,  8.82it/s] 91%|█████████ | 972/1070 [01:56<00:11,  8.86it/s] 91%|█████████ | 973/1070 [01:56<00:11,  8.79it/s] 91%|█████████ | 974/1070 [01:56<00:10,  8.86it/s] 91%|█████████ | 975/1070 [01:56<00:10,  8.91it/s] 91%|█████████ | 976/1070 [01:56<00:10,  8.90it/s] 91%|█████████▏| 977/1070 [01:56<00:10,  8.84it/s] 91%|█████████▏| 978/1070 [01:57<00:10,  8.81it/s] 91%|█████████▏| 979/1070 [01:57<00:10,  8.85it/s] 92%|█████████▏| 980/1070 [01:57<00:10,  8.72it/s] 92%|█████████▏| 981/1070 [01:57<00:10,  8.77it/s] 92%|█████████▏| 982/1070 [01:57<00:10,  8.75it/s] 92%|█████████▏| 983/1070 [01:57<00:09,  8.83it/s] 92%|█████████▏| 984/1070 [01:57<00:09,  8.78it/s] 92%|█████████▏| 985/1070 [01:57<00:09,  8.79it/s] 92%|█████████▏| 986/1070 [01:57<00:09,  8.74it/s] 92%|█████████▏| 987/1070 [01:58<00:09,  8.79it/s] 92%|█████████▏| 988/1070 [01:58<00:09,  8.86it/s] 92%|█████████▏| 989/1070 [01:58<00:09,  8.88it/s] 93%|█████████▎| 990/1070 [01:58<00:09,  8.79it/s] 93%|█████████▎| 991/1070 [01:58<00:08,  8.81it/s] 93%|█████████▎| 992/1070 [01:58<00:08,  8.88it/s] 93%|█████████▎| 993/1070 [01:58<00:08,  8.81it/s] 93%|█████████▎| 994/1070 [01:58<00:08,  8.79it/s] 93%|█████████▎| 995/1070 [01:58<00:08,  8.72it/s] 93%|█████████▎| 996/1070 [01:59<00:08,  8.78it/s] 93%|█████████▎| 997/1070 [01:59<00:08,  8.77it/s] 93%|█████████▎| 998/1070 [01:59<00:08,  8.83it/s] 93%|█████████▎| 999/1070 [01:59<00:08,  8.84it/s] 93%|█████████▎| 1000/1070 [01:59<00:07,  8.87it/s] 94%|█████████▎| 1001/1070 [01:59<00:07,  8.94it/s] 94%|█████████▎| 1002/1070 [01:59<00:07,  8.87it/s] 94%|█████████▎| 1003/1070 [01:59<00:07,  8.84it/s] 94%|█████████▍| 1004/1070 [01:59<00:07,  8.80it/s] 94%|█████████▍| 1005/1070 [02:00<00:07,  8.80it/s] 94%|█████████▍| 1006/1070 [02:00<00:07,  8.82it/s] 94%|█████████▍| 1007/1070 [02:00<00:07,  8.75it/s] 94%|█████████▍| 1008/1070 [02:00<00:07,  8.72it/s] 94%|█████████▍| 1009/1070 [02:00<00:06,  8.81it/s] 94%|█████████▍| 1010/1070 [02:00<00:06,  8.79it/s] 94%|█████████▍| 1011/1070 [02:00<00:06,  8.89it/s] 95%|█████████▍| 1012/1070 [02:00<00:06,  8.80it/s] 95%|█████████▍| 1013/1070 [02:00<00:06,  8.82it/s] 95%|█████████▍| 1014/1070 [02:01<00:06,  8.88it/s] 95%|█████████▍| 1015/1070 [02:01<00:06,  8.86it/s] 95%|█████████▍| 1016/1070 [02:01<00:06,  8.71it/s] 95%|█████████▌| 1017/1070 [02:01<00:06,  8.81it/s] 95%|█████████▌| 1018/1070 [02:01<00:05,  8.80it/s] 95%|█████████▌| 1019/1070 [02:01<00:05,  8.83it/s] 95%|█████████▌| 1020/1070 [02:01<00:05,  8.73it/s] 95%|█████████▌| 1021/1070 [02:01<00:05,  8.86it/s] 96%|█████████▌| 1022/1070 [02:02<00:05,  8.79it/s] 96%|█████████▌| 1023/1070 [02:02<00:05,  8.86it/s] 96%|█████████▌| 1024/1070 [02:02<00:05,  8.95it/s] 96%|█████████▌| 1025/1070 [02:02<00:05,  8.85it/s] 96%|█████████▌| 1026/1070 [02:02<00:04,  8.81it/s] 96%|█████████▌| 1027/1070 [02:02<00:04,  8.80it/s] 96%|█████████▌| 1028/1070 [02:02<00:04,  8.85it/s] 96%|█████████▌| 1029/1070 [02:02<00:04,  8.73it/s] 96%|█████████▋| 1030/1070 [02:02<00:04,  8.70it/s] 96%|█████████▋| 1031/1070 [02:03<00:04,  8.72it/s] 96%|█████████▋| 1032/1070 [02:03<00:04,  8.77it/s] 97%|█████████▋| 1033/1070 [02:03<00:04,  8.76it/s] 97%|█████████▋| 1034/1070 [02:03<00:04,  8.83it/s] 97%|█████████▋| 1035/1070 [02:03<00:03,  8.78it/s] 97%|█████████▋| 1036/1070 [02:03<00:03,  8.79it/s] 97%|█████████▋| 1037/1070 [02:03<00:03,  8.85it/s] 97%|█████████▋| 1038/1070 [02:03<00:03,  8.76it/s] 97%|█████████▋| 1039/1070 [02:03<00:03,  8.71it/s] 97%|█████████▋| 1040/1070 [02:04<00:03,  8.65it/s] 97%|█████████▋| 1041/1070 [02:04<00:03,  8.72it/s] 97%|█████████▋| 1042/1070 [02:04<00:03,  8.72it/s] 97%|█████████▋| 1043/1070 [02:04<00:03,  8.66it/s] 98%|█████████▊| 1044/1070 [02:04<00:03,  8.66it/s] 98%|█████████▊| 1045/1070 [02:04<00:02,  8.73it/s] 98%|█████████▊| 1046/1070 [02:04<00:02,  8.76it/s] 98%|█████████▊| 1047/1070 [02:04<00:02,  8.81it/s] 98%|█████████▊| 1048/1070 [02:04<00:02,  8.72it/s] 98%|█████████▊| 1049/1070 [02:05<00:02,  8.84it/s] 98%|█████████▊| 1050/1070 [02:05<00:02,  8.90it/s] 98%|█████████▊| 1051/1070 [02:05<00:02,  8.76it/s] 98%|█████████▊| 1052/1070 [02:05<00:02,  8.70it/s] 98%|█████████▊| 1053/1070 [02:05<00:01,  8.76it/s] 99%|█████████▊| 1054/1070 [02:05<00:01,  8.82it/s] 99%|█████████▊| 1055/1070 [02:05<00:01,  8.82it/s] 99%|█████████▊| 1056/1070 [02:05<00:01,  8.78it/s] 99%|█████████▉| 1057/1070 [02:05<00:01,  8.72it/s] 99%|█████████▉| 1058/1070 [02:06<00:01,  8.75it/s] 99%|█████████▉| 1059/1070 [02:06<00:01,  8.76it/s] 99%|█████████▉| 1060/1070 [02:06<00:01,  8.81it/s] 99%|█████████▉| 1061/1070 [02:06<00:01,  8.75it/s] 99%|█████████▉| 1062/1070 [02:06<00:00,  8.74it/s] 99%|█████████▉| 1063/1070 [02:06<00:00,  8.83it/s] 99%|█████████▉| 1064/1070 [02:06<00:00,  8.83it/s]100%|█████████▉| 1065/1070 [02:06<00:00,  8.78it/s]100%|█████████▉| 1066/1070 [02:07<00:00,  8.72it/s]100%|█████████▉| 1067/1070 [02:07<00:00,  8.71it/s]100%|█████████▉| 1068/1070 [02:07<00:00,  8.72it/s]100%|█████████▉| 1069/1070 [02:07<00:00,  8.61it/s]                                                   100%|██████████| 1070/1070 [02:07<00:00,  8.61it/s][INFO|trainer.py:755] 2023-11-15 19:44:21,285 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:44:21,287 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:44:21,287 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:44:21,287 >>   Batch size = 8
{'eval_loss': 0.3214026391506195, 'eval_accuracy': 0.9144736842105263, 'eval_micro_f1': 0.9144736842105263, 'eval_macro_f1': 0.912014075775827, 'eval_runtime': 1.4156, 'eval_samples_per_second': 536.886, 'eval_steps_per_second': 67.111, 'epoch': 4.0}
{'loss': 0.0831, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 78.48it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 72.74it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 71.80it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 71.02it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 68.87it/s][A
 49%|████▉     | 47/95 [00:00<00:00, 68.52it/s][A
 58%|█████▊    | 55/95 [00:00<00:00, 70.25it/s][A
 66%|██████▋   | 63/95 [00:00<00:00, 69.08it/s][A
 74%|███████▎  | 70/95 [00:01<00:00, 68.36it/s][A
 82%|████████▏ | 78/95 [00:01<00:00, 70.01it/s][A
 91%|█████████ | 86/95 [00:01<00:00, 68.60it/s][A
 98%|█████████▊| 93/95 [00:01<00:00, 67.75it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:08<00:00,  8.61it/s]
100%|██████████| 95/95 [00:01<00:00, 67.75it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 19:44:22,713 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:08<00:00,  8.61it/s]100%|██████████| 1070/1070 [02:08<00:00,  8.30it/s]
[INFO|trainer.py:2855] 2023-11-15 19:44:22,717 >> Saving model checkpoint to ./result/agnews_sup_roberta-base_adapter__seed0
[INFO|configuration_utils.py:460] 2023-11-15 19:44:22,720 >> Configuration saved in ./result/agnews_sup_roberta-base_adapter__seed0/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:44:24,272 >> Model weights saved in ./result/agnews_sup_roberta-base_adapter__seed0/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:44:24,274 >> tokenizer config file saved in ./result/agnews_sup_roberta-base_adapter__seed0/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:44:24,277 >> Special tokens file saved in ./result/agnews_sup_roberta-base_adapter__seed0/special_tokens_map.json
{'eval_loss': 0.33421194553375244, 'eval_accuracy': 0.9171052631578948, 'eval_micro_f1': 0.9171052631578948, 'eval_macro_f1': 0.9149316652215203, 'eval_runtime': 1.422, 'eval_samples_per_second': 534.465, 'eval_steps_per_second': 66.808, 'epoch': 5.0}
{'train_runtime': 128.9059, 'train_samples_per_second': 265.31, 'train_steps_per_second': 8.301, 'train_loss': 0.21246406697781287, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2125
  train_runtime            = 0:02:08.90
  train_samples            =       6840
  train_samples_per_second =     265.31
  train_steps_per_second   =      8.301
11/15/2023 19:44:24 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:44:24,377 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:44:24,378 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:44:24,379 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:44:24,379 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  8%|▊         | 8/95 [00:00<00:01, 68.76it/s] 16%|█▌        | 15/95 [00:00<00:01, 66.61it/s] 23%|██▎       | 22/95 [00:00<00:01, 65.59it/s] 31%|███       | 29/95 [00:00<00:00, 66.02it/s] 38%|███▊      | 36/95 [00:00<00:00, 66.49it/s] 45%|████▌     | 43/95 [00:00<00:00, 66.86it/s] 53%|█████▎    | 50/95 [00:00<00:00, 65.80it/s] 60%|██████    | 57/95 [00:00<00:00, 66.92it/s] 67%|██████▋   | 64/95 [00:00<00:00, 67.07it/s] 75%|███████▍  | 71/95 [00:01<00:00, 66.91it/s] 83%|████████▎ | 79/95 [00:01<00:00, 68.36it/s] 91%|█████████ | 86/95 [00:01<00:00, 67.07it/s] 98%|█████████▊| 93/95 [00:01<00:00, 66.62it/s]100%|██████████| 95/95 [00:01<00:00, 65.40it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9171
  eval_loss               =     0.3342
  eval_macro_f1           =     0.9149
  eval_micro_f1           =     0.9171
  eval_runtime            = 0:00:01.47
  eval_samples            =        760
  eval_samples_per_second =    516.958
  eval_steps_per_second   =      64.62
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▆▆▇██
wandb:                      eval/loss ▄▁▄▇██
wandb:                  eval/macro_f1 ▁▆▆▇██
wandb:                  eval/micro_f1 ▁▆▆▇██
wandb:                   eval/runtime ▁▃▄▅▅█
wandb:        eval/samples_per_second █▆▅▄▄▁
wandb:          eval/steps_per_second █▆▅▄▄▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.91711
wandb:                      eval/loss 0.33421
wandb:                  eval/macro_f1 0.91493
wandb:                  eval/micro_f1 0.91711
wandb:                   eval/runtime 1.4701
wandb:        eval/samples_per_second 516.958
wandb:          eval/steps_per_second 64.62
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0831
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.21246
wandb:            train/train_runtime 128.9059
wandb: train/train_samples_per_second 265.31
wandb:   train/train_steps_per_second 8.301
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_194055-g7jpmi5f
wandb: Find logs at: ./wandb/offline-run-20231115_194055-g7jpmi5f/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_bert-base-cased_adapter__seed0/runs/Nov15_19-44-38_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_bert-base-cased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_bert-base-cased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:44:38 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:44:38 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_bert-base-cased_adapter__seed0/runs/Nov15_19-44-37_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_bert-base-cased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_bert-base-cased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 19:44:54,951 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:44:54,963 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 19:45:04,981 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:45:04,981 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:45:04,984 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:45:04,985 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:45:04,985 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:45:04,986 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:45:04,986 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 19:45:04,987 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:45:04,988 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:45:25,140 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 19:45:25,838 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:45:25,839 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  44%|████▍     | 3000/6840 [00:00<00:00, 21704.74 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 22877.67 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 22499.88 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 25154.04 examples/s]
11/15/2023 19:45:26 - INFO - __main__ - Sample 6776 of the training set: {'text': 'Cup chase lands in Dover When the green flag drops for today #39;s MBNA America 400 at Dover International Speedway, 43 drivers will be lined up to cross the start/finish line.', 'label': 0, 'input_ids': [101, 1635, 9839, 4508, 1107, 14493, 1332, 1103, 2448, 5167, 8949, 1111, 2052, 108, 3614, 132, 188, 19443, 11185, 1738, 3434, 1120, 14493, 1570, 12081, 117, 3887, 7016, 1209, 1129, 7265, 1146, 1106, 2771, 1103, 1838, 120, 3146, 1413, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:45:26 - INFO - __main__ - Sample 1742 of the training set: {'text': 'Louisiana Tech Bulldogs RUSTON, Louisiana (Ticker) -- No. 17 Fresno State could not overcome a dominant performance by Ryan Moats or a poor one by Paul Pinegar.', 'label': 0, 'input_ids': [101, 5060, 7882, 16051, 155, 13329, 18082, 2249, 117, 5060, 113, 157, 23666, 114, 118, 118, 1302, 119, 1542, 22885, 1426, 1180, 1136, 9414, 170, 7065, 2099, 1118, 3730, 12556, 9971, 1137, 170, 2869, 1141, 1118, 1795, 11465, 5526, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:45:26 - INFO - __main__ - Sample 2588 of the training set: {'text': 'Rossi:  #39;I #39;m fairly happy #39; Valentino Rossi, who on Thursday pledged his future to Yamaha, entered the final qualifying session with the fastest time to date, but with the morning rain having washed the circuit clean, the Italian was unable to challenge Makoto Tamada for the pole.', 'label': 0, 'input_ids': [101, 20154, 131, 108, 3614, 132, 146, 108, 3614, 132, 182, 6751, 2816, 108, 3614, 132, 10532, 18618, 20154, 117, 1150, 1113, 9170, 18215, 1117, 2174, 1106, 27275, 117, 2242, 1103, 1509, 6045, 4912, 1114, 1103, 7901, 1159, 1106, 2236, 117, 1133, 1114, 1103, 2106, 4458, 1515, 8589, 1103, 6090, 4044, 117, 1103, 2169, 1108, 3372, 1106, 4506, 7085, 27710, 22876, 7971, 1111, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 19:45:26 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:45:27,726 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:45:27,734 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:45:27,734 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 19:45:27,735 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:45:27,735 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:45:27,735 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:45:27,735 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:45:27,736 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 19:45:27,736 >>   Number of trainable parameters = 108,313,348
[INFO|integration_utils.py:716] 2023-11-15 19:45:27,737 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<25:12,  1.42s/it]  0%|          | 2/1070 [00:01<11:30,  1.55it/s]  0%|          | 3/1070 [00:01<07:07,  2.49it/s]  0%|          | 4/1070 [00:01<05:06,  3.47it/s]  0%|          | 5/1070 [00:01<03:57,  4.48it/s]  1%|          | 6/1070 [00:01<03:17,  5.39it/s]  1%|          | 7/1070 [00:02<02:51,  6.21it/s]  1%|          | 8/1070 [00:02<02:34,  6.88it/s]  1%|          | 9/1070 [00:02<02:20,  7.53it/s]  1%|          | 10/1070 [00:02<02:15,  7.85it/s]  1%|          | 11/1070 [00:02<02:09,  8.21it/s]  1%|          | 12/1070 [00:02<02:05,  8.44it/s]  1%|          | 13/1070 [00:02<02:02,  8.66it/s]  1%|▏         | 14/1070 [00:02<02:00,  8.75it/s]  1%|▏         | 15/1070 [00:02<01:59,  8.85it/s]  1%|▏         | 16/1070 [00:03<01:57,  8.99it/s]  2%|▏         | 17/1070 [00:03<01:57,  8.96it/s]  2%|▏         | 18/1070 [00:03<01:56,  9.01it/s]  2%|▏         | 19/1070 [00:03<01:54,  9.15it/s]  2%|▏         | 20/1070 [00:03<01:56,  9.03it/s]  2%|▏         | 21/1070 [00:03<01:55,  9.07it/s]  2%|▏         | 22/1070 [00:03<01:56,  9.00it/s]  2%|▏         | 23/1070 [00:03<01:55,  9.06it/s]  2%|▏         | 24/1070 [00:03<01:55,  9.08it/s]  2%|▏         | 25/1070 [00:04<01:55,  9.04it/s]  2%|▏         | 26/1070 [00:04<01:54,  9.11it/s]  3%|▎         | 27/1070 [00:04<01:55,  9.06it/s]  3%|▎         | 28/1070 [00:04<01:54,  9.09it/s]  3%|▎         | 29/1070 [00:04<01:53,  9.16it/s]  3%|▎         | 30/1070 [00:04<01:53,  9.13it/s]  3%|▎         | 31/1070 [00:04<01:55,  9.03it/s]  3%|▎         | 32/1070 [00:04<01:54,  9.03it/s]  3%|▎         | 33/1070 [00:04<01:54,  9.05it/s]  3%|▎         | 34/1070 [00:05<01:54,  9.04it/s]  3%|▎         | 35/1070 [00:05<01:55,  8.97it/s]  3%|▎         | 36/1070 [00:05<01:54,  9.04it/s]  3%|▎         | 37/1070 [00:05<01:54,  9.01it/s]  4%|▎         | 38/1070 [00:05<01:54,  9.00it/s]  4%|▎         | 39/1070 [00:05<01:52,  9.15it/s]  4%|▎         | 40/1070 [00:05<01:53,  9.06it/s]  4%|▍         | 41/1070 [00:05<01:54,  8.97it/s]  4%|▍         | 42/1070 [00:05<01:54,  8.96it/s]  4%|▍         | 43/1070 [00:06<01:53,  9.02it/s]  4%|▍         | 44/1070 [00:06<01:54,  8.97it/s]  4%|▍         | 45/1070 [00:06<01:53,  9.00it/s]  4%|▍         | 46/1070 [00:06<01:52,  9.08it/s]  4%|▍         | 47/1070 [00:06<01:52,  9.08it/s]  4%|▍         | 48/1070 [00:06<01:52,  9.08it/s]  5%|▍         | 49/1070 [00:06<01:50,  9.21it/s]  5%|▍         | 50/1070 [00:06<01:52,  9.09it/s]  5%|▍         | 51/1070 [00:06<01:52,  9.07it/s]  5%|▍         | 52/1070 [00:07<01:52,  9.04it/s]  5%|▍         | 53/1070 [00:07<01:52,  9.08it/s]  5%|▌         | 54/1070 [00:07<01:52,  9.04it/s]  5%|▌         | 55/1070 [00:07<01:52,  9.05it/s]  5%|▌         | 56/1070 [00:07<01:51,  9.11it/s]  5%|▌         | 57/1070 [00:07<01:50,  9.17it/s]  5%|▌         | 58/1070 [00:07<01:50,  9.16it/s]  6%|▌         | 59/1070 [00:07<01:49,  9.26it/s]  6%|▌         | 60/1070 [00:07<01:50,  9.12it/s]  6%|▌         | 61/1070 [00:08<01:51,  9.06it/s]  6%|▌         | 62/1070 [00:08<01:51,  9.01it/s]  6%|▌         | 63/1070 [00:08<01:50,  9.10it/s]  6%|▌         | 64/1070 [00:08<01:50,  9.08it/s]  6%|▌         | 65/1070 [00:08<01:51,  9.05it/s]  6%|▌         | 66/1070 [00:08<01:50,  9.07it/s]  6%|▋         | 67/1070 [00:08<01:50,  9.06it/s]  6%|▋         | 68/1070 [00:08<01:50,  9.07it/s]  6%|▋         | 69/1070 [00:08<01:48,  9.19it/s]  7%|▋         | 70/1070 [00:09<01:49,  9.15it/s]  7%|▋         | 71/1070 [00:09<01:49,  9.11it/s]  7%|▋         | 72/1070 [00:09<01:50,  9.07it/s]  7%|▋         | 73/1070 [00:09<01:49,  9.14it/s]  7%|▋         | 74/1070 [00:09<01:49,  9.07it/s]  7%|▋         | 75/1070 [00:09<01:49,  9.07it/s]  7%|▋         | 76/1070 [00:09<01:49,  9.10it/s]  7%|▋         | 77/1070 [00:09<01:48,  9.11it/s]  7%|▋         | 78/1070 [00:09<01:48,  9.14it/s]  7%|▋         | 79/1070 [00:10<01:48,  9.17it/s]  7%|▋         | 80/1070 [00:10<01:48,  9.13it/s]  8%|▊         | 81/1070 [00:10<01:48,  9.08it/s]  8%|▊         | 82/1070 [00:10<01:48,  9.08it/s]  8%|▊         | 83/1070 [00:10<01:48,  9.11it/s]  8%|▊         | 84/1070 [00:10<01:49,  9.04it/s]  8%|▊         | 85/1070 [00:10<01:49,  9.02it/s]  8%|▊         | 86/1070 [00:10<01:49,  8.97it/s]  8%|▊         | 87/1070 [00:10<01:48,  9.06it/s]  8%|▊         | 88/1070 [00:11<01:49,  9.01it/s]  8%|▊         | 89/1070 [00:11<01:47,  9.09it/s]  8%|▊         | 90/1070 [00:11<01:48,  9.06it/s]  9%|▊         | 91/1070 [00:11<01:48,  9.06it/s]  9%|▊         | 92/1070 [00:11<01:46,  9.17it/s]  9%|▊         | 93/1070 [00:11<01:46,  9.15it/s]  9%|▉         | 94/1070 [00:11<01:48,  9.03it/s]  9%|▉         | 95/1070 [00:11<01:47,  9.11it/s]  9%|▉         | 96/1070 [00:11<01:47,  9.07it/s]  9%|▉         | 97/1070 [00:11<01:46,  9.13it/s]  9%|▉         | 98/1070 [00:12<01:47,  9.02it/s]  9%|▉         | 99/1070 [00:12<01:46,  9.08it/s]  9%|▉         | 100/1070 [00:12<01:47,  9.06it/s]  9%|▉         | 101/1070 [00:12<01:46,  9.08it/s] 10%|▉         | 102/1070 [00:12<01:45,  9.15it/s] 10%|▉         | 103/1070 [00:12<01:46,  9.08it/s] 10%|▉         | 104/1070 [00:12<01:47,  9.02it/s] 10%|▉         | 105/1070 [00:12<01:46,  9.03it/s] 10%|▉         | 106/1070 [00:12<01:46,  9.06it/s] 10%|█         | 107/1070 [00:13<01:45,  9.11it/s] 10%|█         | 108/1070 [00:13<01:46,  9.00it/s] 10%|█         | 109/1070 [00:13<01:45,  9.13it/s] 10%|█         | 110/1070 [00:13<01:45,  9.06it/s] 10%|█         | 111/1070 [00:13<01:45,  9.06it/s] 10%|█         | 112/1070 [00:13<01:44,  9.15it/s] 11%|█         | 113/1070 [00:13<01:45,  9.04it/s] 11%|█         | 114/1070 [00:13<01:45,  9.05it/s] 11%|█         | 115/1070 [00:13<01:45,  9.01it/s] 11%|█         | 116/1070 [00:14<01:45,  9.04it/s] 11%|█         | 117/1070 [00:14<01:45,  9.06it/s] 11%|█         | 118/1070 [00:14<01:45,  8.99it/s] 11%|█         | 119/1070 [00:14<01:45,  9.06it/s] 11%|█         | 120/1070 [00:14<01:45,  9.04it/s] 11%|█▏        | 121/1070 [00:14<01:44,  9.06it/s] 11%|█▏        | 122/1070 [00:14<01:43,  9.15it/s] 11%|█▏        | 123/1070 [00:14<01:44,  9.03it/s] 12%|█▏        | 124/1070 [00:14<01:44,  9.06it/s] 12%|█▏        | 125/1070 [00:15<01:44,  9.01it/s] 12%|█▏        | 126/1070 [00:15<01:44,  9.07it/s] 12%|█▏        | 127/1070 [00:15<01:43,  9.09it/s] 12%|█▏        | 128/1070 [00:15<01:45,  8.93it/s] 12%|█▏        | 129/1070 [00:15<01:44,  8.99it/s] 12%|█▏        | 130/1070 [00:15<01:43,  9.04it/s] 12%|█▏        | 131/1070 [00:15<01:43,  9.07it/s] 12%|█▏        | 132/1070 [00:15<01:41,  9.21it/s] 12%|█▏        | 133/1070 [00:15<01:42,  9.12it/s] 13%|█▎        | 134/1070 [00:16<01:43,  9.00it/s] 13%|█▎        | 135/1070 [00:16<01:44,  8.96it/s] 13%|█▎        | 136/1070 [00:16<01:43,  9.00it/s] 13%|█▎        | 137/1070 [00:16<01:43,  9.02it/s] 13%|█▎        | 138/1070 [00:16<01:43,  8.99it/s] 13%|█▎        | 139/1070 [00:16<01:43,  9.03it/s] 13%|█▎        | 140/1070 [00:16<01:43,  9.01it/s] 13%|█▎        | 141/1070 [00:16<01:42,  9.03it/s] 13%|█▎        | 142/1070 [00:16<01:41,  9.15it/s] 13%|█▎        | 143/1070 [00:17<01:42,  9.06it/s] 13%|█▎        | 144/1070 [00:17<01:43,  8.96it/s] 14%|█▎        | 145/1070 [00:17<01:42,  8.99it/s] 14%|█▎        | 146/1070 [00:17<01:42,  8.99it/s] 14%|█▎        | 147/1070 [00:17<01:43,  8.92it/s] 14%|█▍        | 148/1070 [00:17<01:43,  8.93it/s] 14%|█▍        | 149/1070 [00:17<01:41,  9.03it/s] 14%|█▍        | 150/1070 [00:17<01:41,  9.02it/s] 14%|█▍        | 151/1070 [00:17<01:41,  9.07it/s] 14%|█▍        | 152/1070 [00:18<01:40,  9.11it/s] 14%|█▍        | 153/1070 [00:18<01:41,  9.00it/s] 14%|█▍        | 154/1070 [00:18<01:41,  9.03it/s] 14%|█▍        | 155/1070 [00:18<01:41,  9.00it/s] 15%|█▍        | 156/1070 [00:18<01:41,  8.98it/s] 15%|█▍        | 157/1070 [00:18<01:41,  9.01it/s] 15%|█▍        | 158/1070 [00:18<01:41,  8.95it/s] 15%|█▍        | 159/1070 [00:18<01:41,  8.97it/s] 15%|█▍        | 160/1070 [00:18<01:41,  9.00it/s] 15%|█▌        | 161/1070 [00:19<01:40,  9.04it/s] 15%|█▌        | 162/1070 [00:19<01:39,  9.10it/s] 15%|█▌        | 163/1070 [00:19<01:40,  9.00it/s] 15%|█▌        | 164/1070 [00:19<01:41,  8.90it/s] 15%|█▌        | 165/1070 [00:19<01:41,  8.93it/s] 16%|█▌        | 166/1070 [00:19<01:40,  8.97it/s] 16%|█▌        | 167/1070 [00:19<01:40,  8.96it/s] 16%|█▌        | 168/1070 [00:19<01:41,  8.90it/s] 16%|█▌        | 169/1070 [00:19<01:40,  9.00it/s] 16%|█▌        | 170/1070 [00:20<01:40,  8.94it/s] 16%|█▌        | 171/1070 [00:20<01:39,  8.99it/s] 16%|█▌        | 172/1070 [00:20<01:38,  9.11it/s] 16%|█▌        | 173/1070 [00:20<01:39,  9.01it/s] 16%|█▋        | 174/1070 [00:20<01:40,  8.95it/s] 16%|█▋        | 175/1070 [00:20<01:40,  8.92it/s] 16%|█▋        | 176/1070 [00:20<01:39,  8.97it/s] 17%|█▋        | 177/1070 [00:20<01:39,  8.96it/s] 17%|█▋        | 178/1070 [00:20<01:39,  8.94it/s] 17%|█▋        | 179/1070 [00:21<01:39,  8.98it/s] 17%|█▋        | 180/1070 [00:21<01:38,  9.03it/s] 17%|█▋        | 181/1070 [00:21<01:37,  9.08it/s] 17%|█▋        | 182/1070 [00:21<01:37,  9.15it/s] 17%|█▋        | 183/1070 [00:21<01:37,  9.10it/s] 17%|█▋        | 184/1070 [00:21<01:37,  9.06it/s] 17%|█▋        | 185/1070 [00:21<01:38,  8.98it/s] 17%|█▋        | 186/1070 [00:21<01:37,  9.04it/s] 17%|█▋        | 187/1070 [00:21<01:38,  9.00it/s] 18%|█▊        | 188/1070 [00:22<01:38,  8.95it/s] 18%|█▊        | 189/1070 [00:22<01:38,  8.98it/s] 18%|█▊        | 190/1070 [00:22<01:37,  8.99it/s] 18%|█▊        | 191/1070 [00:22<01:37,  9.02it/s] 18%|█▊        | 192/1070 [00:22<01:36,  9.09it/s] 18%|█▊        | 193/1070 [00:22<01:37,  9.02it/s] 18%|█▊        | 194/1070 [00:22<01:37,  9.02it/s] 18%|█▊        | 195/1070 [00:22<01:37,  9.01it/s] 18%|█▊        | 196/1070 [00:22<01:36,  9.06it/s] 18%|█▊        | 197/1070 [00:23<01:37,  8.98it/s] 19%|█▊        | 198/1070 [00:23<01:36,  9.02it/s] 19%|█▊        | 199/1070 [00:23<01:36,  9.05it/s] 19%|█▊        | 200/1070 [00:23<01:36,  9.05it/s] 19%|█▉        | 201/1070 [00:23<01:36,  9.03it/s] 19%|█▉        | 202/1070 [00:23<01:35,  9.12it/s] 19%|█▉        | 203/1070 [00:23<01:35,  9.05it/s] 19%|█▉        | 204/1070 [00:23<01:35,  9.07it/s] 19%|█▉        | 205/1070 [00:23<01:35,  9.05it/s] 19%|█▉        | 206/1070 [00:24<01:34,  9.13it/s] 19%|█▉        | 207/1070 [00:24<01:35,  9.01it/s] 19%|█▉        | 208/1070 [00:24<01:35,  9.04it/s] 20%|█▉        | 209/1070 [00:24<01:35,  8.98it/s] 20%|█▉        | 210/1070 [00:24<01:34,  9.06it/s] 20%|█▉        | 211/1070 [00:24<01:35,  9.03it/s] 20%|█▉        | 212/1070 [00:24<01:34,  9.09it/s] 20%|█▉        | 213/1070 [00:24<01:34,  9.07it/s]                                                   20%|██        | 214/1070 [00:24<01:34,  9.07it/s][INFO|trainer.py:755] 2023-11-15 19:45:52,680 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:45:52,682 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:45:52,683 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:45:52,683 >>   Batch size = 8
{'loss': 0.4587, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:00, 86.18it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 76.36it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 74.14it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 73.14it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 72.80it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 70.98it/s][A
 61%|██████    | 58/95 [00:00<00:00, 70.36it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 71.30it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 71.58it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 70.38it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 72.09it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:26<01:34,  9.07it/s]
100%|██████████| 95/95 [00:01<00:00, 72.09it/s][A
                                               [A 20%|██        | 215/1070 [00:26<06:02,  2.36it/s] 20%|██        | 216/1070 [00:26<04:55,  2.89it/s] 20%|██        | 217/1070 [00:26<04:02,  3.52it/s] 20%|██        | 218/1070 [00:26<03:22,  4.20it/s] 20%|██        | 219/1070 [00:26<02:52,  4.93it/s] 21%|██        | 220/1070 [00:26<02:29,  5.68it/s] 21%|██        | 221/1070 [00:27<02:13,  6.38it/s] 21%|██        | 222/1070 [00:27<02:02,  6.92it/s] 21%|██        | 223/1070 [00:27<01:53,  7.46it/s] 21%|██        | 224/1070 [00:27<01:47,  7.84it/s] 21%|██        | 225/1070 [00:27<01:43,  8.19it/s] 21%|██        | 226/1070 [00:27<01:39,  8.48it/s] 21%|██        | 227/1070 [00:27<01:37,  8.64it/s] 21%|██▏       | 228/1070 [00:27<01:36,  8.76it/s] 21%|██▏       | 229/1070 [00:27<01:34,  8.85it/s] 21%|██▏       | 230/1070 [00:28<01:33,  8.95it/s] 22%|██▏       | 231/1070 [00:28<01:34,  8.91it/s] 22%|██▏       | 232/1070 [00:28<01:33,  8.95it/s] 22%|██▏       | 233/1070 [00:28<01:32,  9.03it/s] 22%|██▏       | 234/1070 [00:28<01:32,  9.05it/s] 22%|██▏       | 235/1070 [00:28<01:32,  9.07it/s] 22%|██▏       | 236/1070 [00:28<01:30,  9.23it/s] 22%|██▏       | 237/1070 [00:28<01:31,  9.07it/s] 22%|██▏       | 238/1070 [00:28<01:31,  9.08it/s] 22%|██▏       | 239/1070 [00:29<01:31,  9.07it/s] 22%|██▏       | 240/1070 [00:29<01:31,  9.10it/s] 23%|██▎       | 241/1070 [00:29<01:31,  9.04it/s] 23%|██▎       | 242/1070 [00:29<01:32,  9.00it/s] 23%|██▎       | 243/1070 [00:29<01:31,  9.01it/s] 23%|██▎       | 244/1070 [00:29<01:31,  9.05it/s] 23%|██▎       | 245/1070 [00:29<01:31,  9.04it/s] 23%|██▎       | 246/1070 [00:29<01:30,  9.12it/s] 23%|██▎       | 247/1070 [00:29<01:30,  9.11it/s] 23%|██▎       | 248/1070 [00:30<01:30,  9.10it/s] 23%|██▎       | 249/1070 [00:30<01:30,  9.09it/s] 23%|██▎       | 250/1070 [00:30<01:30,  9.08it/s] 23%|██▎       | 251/1070 [00:30<01:30,  9.04it/s] 24%|██▎       | 252/1070 [00:30<01:30,  9.05it/s] 24%|██▎       | 253/1070 [00:30<01:30,  9.04it/s] 24%|██▎       | 254/1070 [00:30<01:29,  9.10it/s] 24%|██▍       | 255/1070 [00:30<01:30,  8.99it/s] 24%|██▍       | 256/1070 [00:30<01:29,  9.09it/s] 24%|██▍       | 257/1070 [00:31<01:29,  9.04it/s] 24%|██▍       | 258/1070 [00:31<01:29,  9.07it/s] 24%|██▍       | 259/1070 [00:31<01:28,  9.16it/s] 24%|██▍       | 260/1070 [00:31<01:29,  9.04it/s] 24%|██▍       | 261/1070 [00:31<01:29,  9.05it/s] 24%|██▍       | 262/1070 [00:31<01:28,  9.08it/s] 25%|██▍       | 263/1070 [00:31<01:28,  9.07it/s] 25%|██▍       | 264/1070 [00:31<01:28,  9.12it/s] 25%|██▍       | 265/1070 [00:31<01:29,  9.03it/s] 25%|██▍       | 266/1070 [00:32<01:27,  9.15it/s] 25%|██▍       | 267/1070 [00:32<01:28,  9.10it/s] 25%|██▌       | 268/1070 [00:32<01:28,  9.09it/s] 25%|██▌       | 269/1070 [00:32<01:27,  9.12it/s] 25%|██▌       | 270/1070 [00:32<01:28,  9.03it/s] 25%|██▌       | 271/1070 [00:32<01:28,  8.99it/s] 25%|██▌       | 272/1070 [00:32<01:29,  8.91it/s] 26%|██▌       | 273/1070 [00:32<01:28,  9.00it/s] 26%|██▌       | 274/1070 [00:32<01:28,  9.01it/s] 26%|██▌       | 275/1070 [00:33<01:28,  9.03it/s] 26%|██▌       | 276/1070 [00:33<01:27,  9.05it/s] 26%|██▌       | 277/1070 [00:33<01:27,  9.06it/s] 26%|██▌       | 278/1070 [00:33<01:26,  9.11it/s] 26%|██▌       | 279/1070 [00:33<01:26,  9.11it/s] 26%|██▌       | 280/1070 [00:33<01:27,  9.03it/s] 26%|██▋       | 281/1070 [00:33<01:27,  9.04it/s] 26%|██▋       | 282/1070 [00:33<01:26,  9.07it/s] 26%|██▋       | 283/1070 [00:33<01:26,  9.11it/s] 27%|██▋       | 284/1070 [00:34<01:27,  8.97it/s] 27%|██▋       | 285/1070 [00:34<01:27,  8.96it/s] 27%|██▋       | 286/1070 [00:34<01:27,  8.95it/s] 27%|██▋       | 287/1070 [00:34<01:27,  8.99it/s] 27%|██▋       | 288/1070 [00:34<01:27,  8.94it/s] 27%|██▋       | 289/1070 [00:34<01:26,  9.08it/s] 27%|██▋       | 290/1070 [00:34<01:27,  8.95it/s] 27%|██▋       | 291/1070 [00:34<01:26,  8.98it/s] 27%|██▋       | 292/1070 [00:34<01:25,  9.07it/s] 27%|██▋       | 293/1070 [00:35<01:26,  8.98it/s] 27%|██▋       | 294/1070 [00:35<01:26,  8.94it/s] 28%|██▊       | 295/1070 [00:35<01:26,  8.93it/s] 28%|██▊       | 296/1070 [00:35<01:26,  8.98it/s] 28%|██▊       | 297/1070 [00:35<01:26,  8.97it/s] 28%|██▊       | 298/1070 [00:35<01:26,  8.96it/s] 28%|██▊       | 299/1070 [00:35<01:25,  9.06it/s] 28%|██▊       | 300/1070 [00:35<01:25,  8.96it/s] 28%|██▊       | 301/1070 [00:35<01:26,  8.92it/s] 28%|██▊       | 302/1070 [00:36<01:24,  9.08it/s] 28%|██▊       | 303/1070 [00:36<01:25,  8.95it/s] 28%|██▊       | 304/1070 [00:36<01:25,  8.98it/s] 29%|██▊       | 305/1070 [00:36<01:24,  9.01it/s] 29%|██▊       | 306/1070 [00:36<01:24,  9.01it/s] 29%|██▊       | 307/1070 [00:36<01:25,  8.90it/s] 29%|██▉       | 308/1070 [00:36<01:25,  8.95it/s] 29%|██▉       | 309/1070 [00:36<01:25,  8.94it/s] 29%|██▉       | 310/1070 [00:36<01:24,  8.99it/s] 29%|██▉       | 311/1070 [00:37<01:24,  8.97it/s] 29%|██▉       | 312/1070 [00:37<01:23,  9.06it/s] 29%|██▉       | 313/1070 [00:37<01:24,  8.99it/s] 29%|██▉       | 314/1070 [00:37<01:23,  9.00it/s] 29%|██▉       | 315/1070 [00:37<01:22,  9.10it/s] 30%|██▉       | 316/1070 [00:37<01:23,  8.99it/s] 30%|██▉       | 317/1070 [00:37<01:23,  9.03it/s] 30%|██▉       | 318/1070 [00:37<01:23,  8.98it/s] 30%|██▉       | 319/1070 [00:37<01:23,  9.04it/s] 30%|██▉       | 320/1070 [00:38<01:23,  9.03it/s] 30%|███       | 321/1070 [00:38<01:23,  9.01it/s] 30%|███       | 322/1070 [00:38<01:22,  9.06it/s] 30%|███       | 323/1070 [00:38<01:22,  9.04it/s] 30%|███       | 324/1070 [00:38<01:22,  9.01it/s] 30%|███       | 325/1070 [00:38<01:21,  9.13it/s] 30%|███       | 326/1070 [00:38<01:22,  9.03it/s] 31%|███       | 327/1070 [00:38<01:22,  8.97it/s] 31%|███       | 328/1070 [00:38<01:22,  8.96it/s] 31%|███       | 329/1070 [00:39<01:21,  9.05it/s] 31%|███       | 330/1070 [00:39<01:22,  9.00it/s] 31%|███       | 331/1070 [00:39<01:22,  8.90it/s] 31%|███       | 332/1070 [00:39<01:22,  8.91it/s] 31%|███       | 333/1070 [00:39<01:22,  8.98it/s] 31%|███       | 334/1070 [00:39<01:22,  8.94it/s] 31%|███▏      | 335/1070 [00:39<01:21,  9.01it/s] 31%|███▏      | 336/1070 [00:39<01:22,  8.93it/s] 31%|███▏      | 337/1070 [00:39<01:22,  8.94it/s] 32%|███▏      | 338/1070 [00:40<01:21,  9.03it/s] 32%|███▏      | 339/1070 [00:40<01:21,  9.00it/s] 32%|███▏      | 340/1070 [00:40<01:21,  8.97it/s] 32%|███▏      | 341/1070 [00:40<01:21,  8.99it/s] 32%|███▏      | 342/1070 [00:40<01:21,  8.98it/s] 32%|███▏      | 343/1070 [00:40<01:20,  9.02it/s] 32%|███▏      | 344/1070 [00:40<01:20,  8.99it/s] 32%|███▏      | 345/1070 [00:40<01:20,  8.98it/s] 32%|███▏      | 346/1070 [00:40<01:20,  8.99it/s] 32%|███▏      | 347/1070 [00:41<01:20,  9.00it/s] 33%|███▎      | 348/1070 [00:41<01:19,  9.09it/s] 33%|███▎      | 349/1070 [00:41<01:20,  8.98it/s] 33%|███▎      | 350/1070 [00:41<01:20,  8.96it/s] 33%|███▎      | 351/1070 [00:41<01:20,  8.93it/s] 33%|███▎      | 352/1070 [00:41<01:19,  8.99it/s] 33%|███▎      | 353/1070 [00:41<01:20,  8.88it/s] 33%|███▎      | 354/1070 [00:41<01:19,  8.96it/s] 33%|███▎      | 355/1070 [00:41<01:19,  8.96it/s] 33%|███▎      | 356/1070 [00:42<01:19,  9.02it/s] 33%|███▎      | 357/1070 [00:42<01:19,  8.99it/s] 33%|███▎      | 358/1070 [00:42<01:18,  9.06it/s] 34%|███▎      | 359/1070 [00:42<01:18,  9.02it/s] 34%|███▎      | 360/1070 [00:42<01:18,  9.04it/s] 34%|███▎      | 361/1070 [00:42<01:18,  9.03it/s] 34%|███▍      | 362/1070 [00:42<01:18,  9.02it/s] 34%|███▍      | 363/1070 [00:42<01:19,  8.94it/s] 34%|███▍      | 364/1070 [00:42<01:18,  8.97it/s] 34%|███▍      | 365/1070 [00:43<01:18,  8.95it/s] 34%|███▍      | 366/1070 [00:43<01:18,  8.95it/s] 34%|███▍      | 367/1070 [00:43<01:18,  8.91it/s] 34%|███▍      | 368/1070 [00:43<01:17,  9.02it/s] 34%|███▍      | 369/1070 [00:43<01:18,  8.96it/s] 35%|███▍      | 370/1070 [00:43<01:18,  8.96it/s] 35%|███▍      | 371/1070 [00:43<01:17,  9.04it/s] 35%|███▍      | 372/1070 [00:43<01:17,  9.03it/s] 35%|███▍      | 373/1070 [00:43<01:17,  8.97it/s] 35%|███▍      | 374/1070 [00:44<01:17,  8.97it/s] 35%|███▌      | 375/1070 [00:44<01:16,  9.03it/s] 35%|███▌      | 376/1070 [00:44<01:17,  8.98it/s] 35%|███▌      | 377/1070 [00:44<01:16,  9.03it/s] 35%|███▌      | 378/1070 [00:44<01:17,  8.92it/s] 35%|███▌      | 379/1070 [00:44<01:17,  8.96it/s] 36%|███▌      | 380/1070 [00:44<01:16,  8.98it/s] 36%|███▌      | 381/1070 [00:44<01:16,  9.02it/s] 36%|███▌      | 382/1070 [00:44<01:16,  9.00it/s] 36%|███▌      | 383/1070 [00:45<01:16,  8.98it/s] 36%|███▌      | 384/1070 [00:45<01:16,  9.00it/s] 36%|███▌      | 385/1070 [00:45<01:16,  8.96it/s] 36%|███▌      | 386/1070 [00:45<01:16,  8.90it/s] 36%|███▌      | 387/1070 [00:45<01:16,  8.93it/s] 36%|███▋      | 388/1070 [00:45<01:16,  8.93it/s] 36%|███▋      | 389/1070 [00:45<01:15,  8.97it/s] 36%|███▋      | 390/1070 [00:45<01:16,  8.86it/s] 37%|███▋      | 391/1070 [00:45<01:15,  8.98it/s] 37%|███▋      | 392/1070 [00:46<01:15,  9.00it/s] 37%|███▋      | 393/1070 [00:46<01:15,  8.97it/s] 37%|███▋      | 394/1070 [00:46<01:14,  9.07it/s] 37%|███▋      | 395/1070 [00:46<01:14,  9.00it/s] 37%|███▋      | 396/1070 [00:46<01:15,  8.94it/s] 37%|███▋      | 397/1070 [00:46<01:15,  8.93it/s] 37%|███▋      | 398/1070 [00:46<01:14,  8.97it/s] 37%|███▋      | 399/1070 [00:46<01:14,  8.95it/s] 37%|███▋      | 400/1070 [00:46<01:15,  8.87it/s] 37%|███▋      | 401/1070 [00:47<01:15,  8.86it/s] 38%|███▊      | 402/1070 [00:47<01:15,  8.85it/s] 38%|███▊      | 403/1070 [00:47<01:15,  8.87it/s] 38%|███▊      | 404/1070 [00:47<01:13,  9.02it/s] 38%|███▊      | 405/1070 [00:47<01:14,  8.94it/s] 38%|███▊      | 406/1070 [00:47<01:14,  8.90it/s] 38%|███▊      | 407/1070 [00:47<01:14,  8.92it/s] 38%|███▊      | 408/1070 [00:47<01:14,  8.92it/s] 38%|███▊      | 409/1070 [00:47<01:14,  8.87it/s] 38%|███▊      | 410/1070 [00:48<01:14,  8.85it/s] 38%|███▊      | 411/1070 [00:48<01:14,  8.86it/s] 39%|███▊      | 412/1070 [00:48<01:13,  8.94it/s] 39%|███▊      | 413/1070 [00:48<01:14,  8.82it/s] 39%|███▊      | 414/1070 [00:48<01:13,  8.88it/s] 39%|███▉      | 415/1070 [00:48<01:14,  8.83it/s] 39%|███▉      | 416/1070 [00:48<01:13,  8.87it/s] 39%|███▉      | 417/1070 [00:48<01:12,  8.98it/s] 39%|███▉      | 418/1070 [00:48<01:13,  8.90it/s] 39%|███▉      | 419/1070 [00:49<01:13,  8.86it/s] 39%|███▉      | 420/1070 [00:49<01:13,  8.87it/s] 39%|███▉      | 421/1070 [00:49<01:12,  8.92it/s] 39%|███▉      | 422/1070 [00:49<01:12,  8.97it/s] 40%|███▉      | 423/1070 [00:49<01:12,  8.93it/s] 40%|███▉      | 424/1070 [00:49<01:12,  8.92it/s] 40%|███▉      | 425/1070 [00:49<01:12,  8.87it/s] 40%|███▉      | 426/1070 [00:49<01:12,  8.92it/s] 40%|███▉      | 427/1070 [00:49<01:11,  9.03it/s]                                                   40%|████      | 428/1070 [00:50<01:11,  9.03it/s][INFO|trainer.py:755] 2023-11-15 19:46:17,824 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:46:17,826 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:46:17,826 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:46:17,827 >>   Batch size = 8
{'eval_loss': 0.3201710283756256, 'eval_accuracy': 0.9013157894736842, 'eval_micro_f1': 0.9013157894736842, 'eval_macro_f1': 0.8981957669809135, 'eval_runtime': 1.3667, 'eval_samples_per_second': 556.077, 'eval_steps_per_second': 69.51, 'epoch': 1.0}
{'loss': 0.2108, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 83.18it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 76.17it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 69.56it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 68.64it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 68.37it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 69.87it/s][A
 60%|██████    | 57/95 [00:00<00:00, 67.07it/s][A
 67%|██████▋   | 64/95 [00:00<00:00, 66.58it/s][A
 75%|███████▍  | 71/95 [00:01<00:00, 66.81it/s][A
 82%|████████▏ | 78/95 [00:01<00:00, 66.92it/s][A
 91%|█████████ | 86/95 [00:01<00:00, 68.44it/s][A
 99%|█████████▉| 94/95 [00:01<00:00, 67.80it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:51<01:11,  9.03it/s]
100%|██████████| 95/95 [00:01<00:00, 67.80it/s][A
                                               [A 40%|████      | 429/1070 [00:51<04:43,  2.26it/s] 40%|████      | 430/1070 [00:51<03:51,  2.77it/s] 40%|████      | 431/1070 [00:51<03:08,  3.38it/s] 40%|████      | 432/1070 [00:51<02:37,  4.05it/s] 40%|████      | 433/1070 [00:52<02:13,  4.79it/s] 41%|████      | 434/1070 [00:52<01:54,  5.54it/s] 41%|████      | 435/1070 [00:52<01:42,  6.22it/s] 41%|████      | 436/1070 [00:52<01:32,  6.82it/s] 41%|████      | 437/1070 [00:52<01:26,  7.34it/s] 41%|████      | 438/1070 [00:52<01:21,  7.74it/s] 41%|████      | 439/1070 [00:52<01:17,  8.11it/s] 41%|████      | 440/1070 [00:52<01:15,  8.30it/s] 41%|████      | 441/1070 [00:52<01:13,  8.55it/s] 41%|████▏     | 442/1070 [00:53<01:13,  8.53it/s] 41%|████▏     | 443/1070 [00:53<01:12,  8.63it/s] 41%|████▏     | 444/1070 [00:53<01:11,  8.73it/s] 42%|████▏     | 445/1070 [00:53<01:11,  8.68it/s] 42%|████▏     | 446/1070 [00:53<01:11,  8.71it/s] 42%|████▏     | 447/1070 [00:53<01:11,  8.68it/s] 42%|████▏     | 448/1070 [00:53<01:10,  8.76it/s] 42%|████▏     | 449/1070 [00:53<01:10,  8.82it/s] 42%|████▏     | 450/1070 [00:54<01:10,  8.79it/s] 42%|████▏     | 451/1070 [00:54<01:09,  8.85it/s] 42%|████▏     | 452/1070 [00:54<01:09,  8.86it/s] 42%|████▏     | 453/1070 [00:54<01:09,  8.88it/s] 42%|████▏     | 454/1070 [00:54<01:09,  8.92it/s] 43%|████▎     | 455/1070 [00:54<01:09,  8.86it/s] 43%|████▎     | 456/1070 [00:54<01:09,  8.80it/s] 43%|████▎     | 457/1070 [00:54<01:09,  8.80it/s] 43%|████▎     | 458/1070 [00:54<01:09,  8.77it/s] 43%|████▎     | 459/1070 [00:55<01:08,  8.86it/s] 43%|████▎     | 460/1070 [00:55<01:09,  8.79it/s] 43%|████▎     | 461/1070 [00:55<01:08,  8.89it/s] 43%|████▎     | 462/1070 [00:55<01:08,  8.86it/s] 43%|████▎     | 463/1070 [00:55<01:08,  8.87it/s] 43%|████▎     | 464/1070 [00:55<01:07,  8.94it/s] 43%|████▎     | 465/1070 [00:55<01:08,  8.88it/s] 44%|████▎     | 466/1070 [00:55<01:08,  8.85it/s] 44%|████▎     | 467/1070 [00:55<01:08,  8.83it/s] 44%|████▎     | 468/1070 [00:56<01:08,  8.82it/s] 44%|████▍     | 469/1070 [00:56<01:07,  8.91it/s] 44%|████▍     | 470/1070 [00:56<01:07,  8.85it/s] 44%|████▍     | 471/1070 [00:56<01:07,  8.91it/s] 44%|████▍     | 472/1070 [00:56<01:07,  8.86it/s] 44%|████▍     | 473/1070 [00:56<01:07,  8.86it/s] 44%|████▍     | 474/1070 [00:56<01:06,  8.98it/s] 44%|████▍     | 475/1070 [00:56<01:06,  8.89it/s] 44%|████▍     | 476/1070 [00:56<01:06,  8.92it/s] 45%|████▍     | 477/1070 [00:57<01:06,  8.92it/s] 45%|████▍     | 478/1070 [00:57<01:06,  8.93it/s] 45%|████▍     | 479/1070 [00:57<01:05,  9.00it/s] 45%|████▍     | 480/1070 [00:57<01:06,  8.90it/s] 45%|████▍     | 481/1070 [00:57<01:05,  8.98it/s] 45%|████▌     | 482/1070 [00:57<01:06,  8.85it/s] 45%|████▌     | 483/1070 [00:57<01:05,  8.99it/s] 45%|████▌     | 484/1070 [00:57<01:04,  9.03it/s] 45%|████▌     | 485/1070 [00:57<01:05,  8.95it/s] 45%|████▌     | 486/1070 [00:58<01:05,  8.89it/s] 46%|████▌     | 487/1070 [00:58<01:05,  8.86it/s] 46%|████▌     | 488/1070 [00:58<01:05,  8.88it/s] 46%|████▌     | 489/1070 [00:58<01:04,  8.97it/s] 46%|████▌     | 490/1070 [00:58<01:05,  8.86it/s] 46%|████▌     | 491/1070 [00:58<01:04,  8.92it/s] 46%|████▌     | 492/1070 [00:58<01:05,  8.89it/s] 46%|████▌     | 493/1070 [00:58<01:04,  8.92it/s] 46%|████▌     | 494/1070 [00:58<01:04,  8.97it/s] 46%|████▋     | 495/1070 [00:59<01:04,  8.97it/s] 46%|████▋     | 496/1070 [00:59<01:04,  8.90it/s] 46%|████▋     | 497/1070 [00:59<01:04,  8.84it/s] 47%|████▋     | 498/1070 [00:59<01:04,  8.87it/s] 47%|████▋     | 499/1070 [00:59<01:03,  8.96it/s] 47%|████▋     | 500/1070 [00:59<01:03,  8.94it/s] 47%|████▋     | 501/1070 [00:59<01:03,  8.95it/s] 47%|████▋     | 502/1070 [00:59<01:03,  8.88it/s] 47%|████▋     | 503/1070 [00:59<01:03,  8.95it/s] 47%|████▋     | 504/1070 [01:00<01:02,  8.99it/s] 47%|████▋     | 505/1070 [01:00<01:03,  8.94it/s] 47%|████▋     | 506/1070 [01:00<01:03,  8.91it/s] 47%|████▋     | 507/1070 [01:00<01:03,  8.89it/s] 47%|████▋     | 508/1070 [01:00<01:03,  8.89it/s] 48%|████▊     | 509/1070 [01:00<01:03,  8.87it/s] 48%|████▊     | 510/1070 [01:00<01:03,  8.75it/s] 48%|████▊     | 511/1070 [01:00<01:03,  8.84it/s] 48%|████▊     | 512/1070 [01:00<01:03,  8.80it/s] 48%|████▊     | 513/1070 [01:01<01:02,  8.85it/s] 48%|████▊     | 514/1070 [01:01<01:01,  8.97it/s] 48%|████▊     | 515/1070 [01:01<01:02,  8.90it/s] 48%|████▊     | 516/1070 [01:01<01:02,  8.90it/s] 48%|████▊     | 517/1070 [01:01<01:02,  8.91it/s] 48%|████▊     | 518/1070 [01:01<01:02,  8.90it/s] 49%|████▊     | 519/1070 [01:01<01:01,  8.93it/s] 49%|████▊     | 520/1070 [01:01<01:02,  8.84it/s] 49%|████▊     | 521/1070 [01:01<01:01,  8.93it/s] 49%|████▉     | 522/1070 [01:02<01:01,  8.88it/s] 49%|████▉     | 523/1070 [01:02<01:01,  8.90it/s] 49%|████▉     | 524/1070 [01:02<01:00,  8.99it/s] 49%|████▉     | 525/1070 [01:02<01:01,  8.90it/s] 49%|████▉     | 526/1070 [01:02<01:01,  8.88it/s] 49%|████▉     | 527/1070 [01:02<01:01,  8.89it/s] 49%|████▉     | 528/1070 [01:02<01:01,  8.87it/s] 49%|████▉     | 529/1070 [01:02<01:00,  8.96it/s] 50%|████▉     | 530/1070 [01:03<01:00,  8.88it/s] 50%|████▉     | 531/1070 [01:03<01:00,  8.92it/s] 50%|████▉     | 532/1070 [01:03<01:00,  8.89it/s] 50%|████▉     | 533/1070 [01:03<01:00,  8.92it/s] 50%|████▉     | 534/1070 [01:03<00:59,  8.97it/s] 50%|█████     | 535/1070 [01:03<01:00,  8.91it/s] 50%|█████     | 536/1070 [01:03<01:00,  8.78it/s] 50%|█████     | 537/1070 [01:03<01:00,  8.75it/s] 50%|█████     | 538/1070 [01:03<01:00,  8.81it/s] 50%|█████     | 539/1070 [01:04<00:59,  8.85it/s] 50%|█████     | 540/1070 [01:04<01:00,  8.77it/s] 51%|█████     | 541/1070 [01:04<00:59,  8.82it/s] 51%|█████     | 542/1070 [01:04<00:59,  8.81it/s] 51%|█████     | 543/1070 [01:04<00:59,  8.85it/s] 51%|█████     | 544/1070 [01:04<00:58,  8.92it/s] 51%|█████     | 545/1070 [01:04<00:59,  8.88it/s] 51%|█████     | 546/1070 [01:04<00:59,  8.83it/s] 51%|█████     | 547/1070 [01:04<00:59,  8.83it/s] 51%|█████     | 548/1070 [01:05<00:59,  8.83it/s] 51%|█████▏    | 549/1070 [01:05<00:58,  8.86it/s] 51%|█████▏    | 550/1070 [01:05<00:59,  8.76it/s] 51%|█████▏    | 551/1070 [01:05<00:58,  8.83it/s] 52%|█████▏    | 552/1070 [01:05<00:58,  8.84it/s] 52%|█████▏    | 553/1070 [01:05<00:58,  8.83it/s] 52%|█████▏    | 554/1070 [01:05<00:58,  8.88it/s] 52%|█████▏    | 555/1070 [01:05<00:58,  8.88it/s] 52%|█████▏    | 556/1070 [01:05<00:58,  8.84it/s] 52%|█████▏    | 557/1070 [01:06<00:58,  8.78it/s] 52%|█████▏    | 558/1070 [01:06<00:58,  8.74it/s] 52%|█████▏    | 559/1070 [01:06<00:57,  8.83it/s] 52%|█████▏    | 560/1070 [01:06<00:57,  8.80it/s] 52%|█████▏    | 561/1070 [01:06<00:57,  8.83it/s] 53%|█████▎    | 562/1070 [01:06<00:57,  8.86it/s] 53%|█████▎    | 563/1070 [01:06<00:57,  8.88it/s] 53%|█████▎    | 564/1070 [01:06<00:56,  8.91it/s] 53%|█████▎    | 565/1070 [01:06<00:57,  8.86it/s] 53%|█████▎    | 566/1070 [01:07<00:57,  8.81it/s] 53%|█████▎    | 567/1070 [01:07<00:57,  8.78it/s] 53%|█████▎    | 568/1070 [01:07<00:56,  8.81it/s] 53%|█████▎    | 569/1070 [01:07<00:56,  8.81it/s] 53%|█████▎    | 570/1070 [01:07<00:56,  8.82it/s] 53%|█████▎    | 571/1070 [01:07<00:56,  8.85it/s] 53%|█████▎    | 572/1070 [01:07<00:56,  8.81it/s] 54%|█████▎    | 573/1070 [01:07<00:56,  8.87it/s] 54%|█████▎    | 574/1070 [01:07<00:55,  8.92it/s] 54%|█████▎    | 575/1070 [01:08<00:55,  8.95it/s] 54%|█████▍    | 576/1070 [01:08<00:55,  8.92it/s] 54%|█████▍    | 577/1070 [01:08<00:55,  8.90it/s] 54%|█████▍    | 578/1070 [01:08<00:55,  8.87it/s] 54%|█████▍    | 579/1070 [01:08<00:54,  8.95it/s] 54%|█████▍    | 580/1070 [01:08<00:55,  8.91it/s] 54%|█████▍    | 581/1070 [01:08<00:54,  9.03it/s] 54%|█████▍    | 582/1070 [01:08<00:54,  8.93it/s] 54%|█████▍    | 583/1070 [01:08<00:54,  8.90it/s] 55%|█████▍    | 584/1070 [01:09<00:54,  8.87it/s] 55%|█████▍    | 585/1070 [01:09<00:54,  8.88it/s] 55%|█████▍    | 586/1070 [01:09<00:55,  8.79it/s] 55%|█████▍    | 587/1070 [01:09<00:54,  8.82it/s] 55%|█████▍    | 588/1070 [01:09<00:54,  8.84it/s] 55%|█████▌    | 589/1070 [01:09<00:54,  8.89it/s] 55%|█████▌    | 590/1070 [01:09<00:54,  8.88it/s] 55%|█████▌    | 591/1070 [01:09<00:53,  9.00it/s] 55%|█████▌    | 592/1070 [01:09<00:53,  8.91it/s] 55%|█████▌    | 593/1070 [01:10<00:54,  8.81it/s] 56%|█████▌    | 594/1070 [01:10<00:53,  8.85it/s] 56%|█████▌    | 595/1070 [01:10<00:53,  8.94it/s] 56%|█████▌    | 596/1070 [01:10<00:53,  8.92it/s] 56%|█████▌    | 597/1070 [01:10<00:53,  8.92it/s] 56%|█████▌    | 598/1070 [01:10<00:52,  8.97it/s] 56%|█████▌    | 599/1070 [01:10<00:52,  8.94it/s] 56%|█████▌    | 600/1070 [01:10<00:52,  8.94it/s] 56%|█████▌    | 601/1070 [01:11<00:51,  9.05it/s] 56%|█████▋    | 602/1070 [01:11<00:52,  8.92it/s] 56%|█████▋    | 603/1070 [01:11<00:52,  8.90it/s] 56%|█████▋    | 604/1070 [01:11<00:52,  8.85it/s] 57%|█████▋    | 605/1070 [01:11<00:52,  8.86it/s] 57%|█████▋    | 606/1070 [01:11<00:52,  8.86it/s] 57%|█████▋    | 607/1070 [01:11<00:52,  8.85it/s] 57%|█████▋    | 608/1070 [01:11<00:51,  8.92it/s] 57%|█████▋    | 609/1070 [01:11<00:52,  8.84it/s] 57%|█████▋    | 610/1070 [01:12<00:51,  8.89it/s] 57%|█████▋    | 611/1070 [01:12<00:50,  9.01it/s] 57%|█████▋    | 612/1070 [01:12<00:51,  8.86it/s] 57%|█████▋    | 613/1070 [01:12<00:51,  8.84it/s] 57%|█████▋    | 614/1070 [01:12<00:51,  8.83it/s] 57%|█████▋    | 615/1070 [01:12<00:51,  8.90it/s] 58%|█████▊    | 616/1070 [01:12<00:50,  8.92it/s] 58%|█████▊    | 617/1070 [01:12<00:51,  8.84it/s] 58%|█████▊    | 618/1070 [01:12<00:50,  8.92it/s] 58%|█████▊    | 619/1070 [01:13<00:50,  8.85it/s] 58%|█████▊    | 620/1070 [01:13<00:50,  8.88it/s] 58%|█████▊    | 621/1070 [01:13<00:49,  9.00it/s] 58%|█████▊    | 622/1070 [01:13<00:50,  8.90it/s] 58%|█████▊    | 623/1070 [01:13<00:50,  8.79it/s] 58%|█████▊    | 624/1070 [01:13<00:50,  8.83it/s] 58%|█████▊    | 625/1070 [01:13<00:50,  8.86it/s] 59%|█████▊    | 626/1070 [01:13<00:50,  8.84it/s] 59%|█████▊    | 627/1070 [01:13<00:50,  8.77it/s] 59%|█████▊    | 628/1070 [01:14<00:49,  8.85it/s] 59%|█████▉    | 629/1070 [01:14<00:50,  8.78it/s] 59%|█████▉    | 630/1070 [01:14<00:49,  8.84it/s] 59%|█████▉    | 631/1070 [01:14<00:49,  8.92it/s] 59%|█████▉    | 632/1070 [01:14<00:49,  8.79it/s] 59%|█████▉    | 633/1070 [01:14<00:49,  8.79it/s] 59%|█████▉    | 634/1070 [01:14<00:49,  8.78it/s] 59%|█████▉    | 635/1070 [01:14<00:49,  8.82it/s] 59%|█████▉    | 636/1070 [01:14<00:49,  8.82it/s] 60%|█████▉    | 637/1070 [01:15<00:48,  8.84it/s] 60%|█████▉    | 638/1070 [01:15<00:48,  8.84it/s] 60%|█████▉    | 639/1070 [01:15<00:48,  8.80it/s] 60%|█████▉    | 640/1070 [01:15<00:48,  8.83it/s] 60%|█████▉    | 641/1070 [01:15<00:48,  8.92it/s]                                                   60%|██████    | 642/1070 [01:15<00:47,  8.92it/s][INFO|trainer.py:755] 2023-11-15 19:46:43,365 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:46:43,367 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:46:43,368 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:46:43,368 >>   Batch size = 8
{'eval_loss': 0.3119429051876068, 'eval_accuracy': 0.9026315789473685, 'eval_micro_f1': 0.9026315789473685, 'eval_macro_f1': 0.9002756417721678, 'eval_runtime': 1.4406, 'eval_samples_per_second': 527.562, 'eval_steps_per_second': 65.945, 'epoch': 2.0}
{'loss': 0.137, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 78.13it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 70.57it/s][A
 25%|██▌       | 24/95 [00:00<00:01, 70.31it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 66.76it/s][A
 41%|████      | 39/95 [00:00<00:00, 66.28it/s][A
 49%|████▉     | 47/95 [00:00<00:00, 67.00it/s][A
 57%|█████▋    | 54/95 [00:00<00:00, 67.68it/s][A
 64%|██████▍   | 61/95 [00:00<00:00, 67.46it/s][A
 72%|███████▏  | 68/95 [00:01<00:00, 67.22it/s][A
 79%|███████▉  | 75/95 [00:01<00:00, 67.88it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 66.98it/s][A
 94%|█████████▎| 89/95 [00:01<00:00, 66.05it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:17<00:47,  8.92it/s]
100%|██████████| 95/95 [00:01<00:00, 66.05it/s][A
                                               [A 60%|██████    | 643/1070 [01:17<03:12,  2.22it/s] 60%|██████    | 644/1070 [01:17<02:36,  2.73it/s] 60%|██████    | 645/1070 [01:17<02:07,  3.34it/s] 60%|██████    | 646/1070 [01:17<01:45,  4.00it/s] 60%|██████    | 647/1070 [01:17<01:29,  4.72it/s] 61%|██████    | 648/1070 [01:17<01:17,  5.45it/s] 61%|██████    | 649/1070 [01:17<01:08,  6.18it/s] 61%|██████    | 650/1070 [01:17<01:01,  6.81it/s] 61%|██████    | 651/1070 [01:18<00:57,  7.27it/s] 61%|██████    | 652/1070 [01:18<00:53,  7.75it/s] 61%|██████    | 653/1070 [01:18<00:51,  8.09it/s] 61%|██████    | 654/1070 [01:18<00:49,  8.32it/s] 61%|██████    | 655/1070 [01:18<00:48,  8.55it/s] 61%|██████▏   | 656/1070 [01:18<00:48,  8.59it/s] 61%|██████▏   | 657/1070 [01:18<00:47,  8.73it/s] 61%|██████▏   | 658/1070 [01:18<00:46,  8.77it/s] 62%|██████▏   | 659/1070 [01:19<00:46,  8.81it/s] 62%|██████▏   | 660/1070 [01:19<00:46,  8.87it/s] 62%|██████▏   | 661/1070 [01:19<00:46,  8.76it/s] 62%|██████▏   | 662/1070 [01:19<00:45,  8.89it/s] 62%|██████▏   | 663/1070 [01:19<00:45,  8.91it/s] 62%|██████▏   | 664/1070 [01:19<00:45,  8.92it/s] 62%|██████▏   | 665/1070 [01:19<00:44,  9.01it/s] 62%|██████▏   | 666/1070 [01:19<00:45,  8.90it/s] 62%|██████▏   | 667/1070 [01:19<00:45,  8.94it/s] 62%|██████▏   | 668/1070 [01:20<00:45,  8.91it/s] 63%|██████▎   | 669/1070 [01:20<00:44,  8.93it/s] 63%|██████▎   | 670/1070 [01:20<00:44,  8.93it/s] 63%|██████▎   | 671/1070 [01:20<00:44,  8.87it/s] 63%|██████▎   | 672/1070 [01:20<00:44,  8.88it/s] 63%|██████▎   | 673/1070 [01:20<00:44,  8.90it/s] 63%|██████▎   | 674/1070 [01:20<00:44,  8.93it/s] 63%|██████▎   | 675/1070 [01:20<00:44,  8.95it/s] 63%|██████▎   | 676/1070 [01:20<00:44,  8.89it/s] 63%|██████▎   | 677/1070 [01:21<00:44,  8.87it/s] 63%|██████▎   | 678/1070 [01:21<00:44,  8.87it/s] 63%|██████▎   | 679/1070 [01:21<00:43,  8.96it/s] 64%|██████▎   | 680/1070 [01:21<00:43,  8.87it/s] 64%|██████▎   | 681/1070 [01:21<00:43,  8.94it/s] 64%|██████▎   | 682/1070 [01:21<00:43,  8.91it/s] 64%|██████▍   | 683/1070 [01:21<00:43,  8.91it/s] 64%|██████▍   | 684/1070 [01:21<00:43,  8.91it/s] 64%|██████▍   | 685/1070 [01:21<00:42,  9.04it/s] 64%|██████▍   | 686/1070 [01:22<00:43,  8.93it/s] 64%|██████▍   | 687/1070 [01:22<00:42,  8.93it/s] 64%|██████▍   | 688/1070 [01:22<00:42,  8.94it/s] 64%|██████▍   | 689/1070 [01:22<00:42,  8.98it/s] 64%|██████▍   | 690/1070 [01:22<00:42,  8.86it/s] 65%|██████▍   | 691/1070 [01:22<00:42,  8.84it/s] 65%|██████▍   | 692/1070 [01:22<00:42,  8.84it/s] 65%|██████▍   | 693/1070 [01:22<00:42,  8.90it/s] 65%|██████▍   | 694/1070 [01:22<00:42,  8.84it/s] 65%|██████▍   | 695/1070 [01:23<00:42,  8.88it/s] 65%|██████▌   | 696/1070 [01:23<00:42,  8.89it/s] 65%|██████▌   | 697/1070 [01:23<00:41,  8.88it/s] 65%|██████▌   | 698/1070 [01:23<00:41,  8.98it/s] 65%|██████▌   | 699/1070 [01:23<00:41,  8.96it/s] 65%|██████▌   | 700/1070 [01:23<00:41,  8.87it/s] 66%|██████▌   | 701/1070 [01:23<00:41,  8.88it/s] 66%|██████▌   | 702/1070 [01:23<00:41,  8.86it/s] 66%|██████▌   | 703/1070 [01:23<00:41,  8.89it/s] 66%|██████▌   | 704/1070 [01:24<00:41,  8.83it/s] 66%|██████▌   | 705/1070 [01:24<00:41,  8.87it/s] 66%|██████▌   | 706/1070 [01:24<00:41,  8.87it/s] 66%|██████▌   | 707/1070 [01:24<00:40,  8.92it/s] 66%|██████▌   | 708/1070 [01:24<00:40,  9.02it/s] 66%|██████▋   | 709/1070 [01:24<00:40,  8.89it/s] 66%|██████▋   | 710/1070 [01:24<00:40,  8.92it/s] 66%|██████▋   | 711/1070 [01:24<00:40,  8.90it/s] 67%|██████▋   | 712/1070 [01:24<00:40,  8.92it/s] 67%|██████▋   | 713/1070 [01:25<00:39,  8.93it/s] 67%|██████▋   | 714/1070 [01:25<00:39,  8.93it/s] 67%|██████▋   | 715/1070 [01:25<00:39,  8.93it/s] 67%|██████▋   | 716/1070 [01:25<00:39,  8.95it/s] 67%|██████▋   | 717/1070 [01:25<00:39,  8.97it/s] 67%|██████▋   | 718/1070 [01:25<00:39,  9.02it/s] 67%|██████▋   | 719/1070 [01:25<00:39,  8.97it/s] 67%|██████▋   | 720/1070 [01:25<00:39,  8.91it/s] 67%|██████▋   | 721/1070 [01:25<00:38,  8.97it/s] 67%|██████▋   | 722/1070 [01:26<00:38,  9.02it/s] 68%|██████▊   | 723/1070 [01:26<00:38,  8.93it/s] 68%|██████▊   | 724/1070 [01:26<00:38,  8.93it/s] 68%|██████▊   | 725/1070 [01:26<00:38,  8.93it/s] 68%|██████▊   | 726/1070 [01:26<00:38,  8.96it/s] 68%|██████▊   | 727/1070 [01:26<00:38,  8.91it/s] 68%|██████▊   | 728/1070 [01:26<00:37,  9.02it/s] 68%|██████▊   | 729/1070 [01:26<00:37,  8.98it/s] 68%|██████▊   | 730/1070 [01:26<00:37,  8.98it/s] 68%|██████▊   | 731/1070 [01:27<00:37,  9.02it/s] 68%|██████▊   | 732/1070 [01:27<00:37,  8.95it/s] 69%|██████▊   | 733/1070 [01:27<00:37,  8.95it/s] 69%|██████▊   | 734/1070 [01:27<00:37,  8.87it/s] 69%|██████▊   | 735/1070 [01:27<00:37,  8.87it/s] 69%|██████▉   | 736/1070 [01:27<00:37,  8.85it/s] 69%|██████▉   | 737/1070 [01:27<00:37,  8.81it/s] 69%|██████▉   | 738/1070 [01:27<00:37,  8.87it/s] 69%|██████▉   | 739/1070 [01:27<00:37,  8.84it/s] 69%|██████▉   | 740/1070 [01:28<00:37,  8.83it/s] 69%|██████▉   | 741/1070 [01:28<00:36,  8.97it/s] 69%|██████▉   | 742/1070 [01:28<00:37,  8.86it/s] 69%|██████▉   | 743/1070 [01:28<00:37,  8.81it/s] 70%|██████▉   | 744/1070 [01:28<00:37,  8.81it/s] 70%|██████▉   | 745/1070 [01:28<00:36,  8.83it/s] 70%|██████▉   | 746/1070 [01:28<00:36,  8.84it/s] 70%|██████▉   | 747/1070 [01:28<00:36,  8.86it/s] 70%|██████▉   | 748/1070 [01:28<00:36,  8.86it/s] 70%|███████   | 749/1070 [01:29<00:36,  8.89it/s] 70%|███████   | 750/1070 [01:29<00:35,  8.92it/s] 70%|███████   | 751/1070 [01:29<00:35,  9.04it/s] 70%|███████   | 752/1070 [01:29<00:35,  8.96it/s] 70%|███████   | 753/1070 [01:29<00:35,  8.96it/s] 70%|███████   | 754/1070 [01:29<00:35,  8.96it/s] 71%|███████   | 755/1070 [01:29<00:35,  8.98it/s] 71%|███████   | 756/1070 [01:29<00:35,  8.95it/s] 71%|███████   | 757/1070 [01:29<00:34,  9.01it/s] 71%|███████   | 758/1070 [01:30<00:34,  8.97it/s] 71%|███████   | 759/1070 [01:30<00:34,  8.97it/s] 71%|███████   | 760/1070 [01:30<00:34,  8.96it/s] 71%|███████   | 761/1070 [01:30<00:34,  9.00it/s] 71%|███████   | 762/1070 [01:30<00:34,  8.95it/s] 71%|███████▏  | 763/1070 [01:30<00:34,  8.94it/s] 71%|███████▏  | 764/1070 [01:30<00:34,  8.96it/s] 71%|███████▏  | 765/1070 [01:30<00:33,  8.97it/s] 72%|███████▏  | 766/1070 [01:31<00:34,  8.88it/s] 72%|███████▏  | 767/1070 [01:31<00:34,  8.88it/s] 72%|███████▏  | 768/1070 [01:31<00:34,  8.87it/s] 72%|███████▏  | 769/1070 [01:31<00:33,  8.88it/s] 72%|███████▏  | 770/1070 [01:31<00:33,  8.85it/s] 72%|███████▏  | 771/1070 [01:31<00:33,  8.94it/s] 72%|███████▏  | 772/1070 [01:31<00:33,  8.91it/s] 72%|███████▏  | 773/1070 [01:31<00:33,  8.92it/s] 72%|███████▏  | 774/1070 [01:31<00:32,  9.03it/s] 72%|███████▏  | 775/1070 [01:32<00:33,  8.92it/s] 73%|███████▎  | 776/1070 [01:32<00:32,  8.93it/s] 73%|███████▎  | 777/1070 [01:32<00:32,  8.90it/s] 73%|███████▎  | 778/1070 [01:32<00:32,  8.92it/s] 73%|███████▎  | 779/1070 [01:32<00:32,  8.94it/s] 73%|███████▎  | 780/1070 [01:32<00:32,  8.85it/s] 73%|███████▎  | 781/1070 [01:32<00:32,  8.92it/s] 73%|███████▎  | 782/1070 [01:32<00:32,  8.89it/s] 73%|███████▎  | 783/1070 [01:32<00:32,  8.94it/s] 73%|███████▎  | 784/1070 [01:33<00:31,  8.99it/s] 73%|███████▎  | 785/1070 [01:33<00:31,  8.92it/s] 73%|███████▎  | 786/1070 [01:33<00:31,  8.90it/s] 74%|███████▎  | 787/1070 [01:33<00:31,  8.90it/s] 74%|███████▎  | 788/1070 [01:33<00:31,  8.90it/s] 74%|███████▎  | 789/1070 [01:33<00:31,  8.90it/s] 74%|███████▍  | 790/1070 [01:33<00:31,  8.88it/s] 74%|███████▍  | 791/1070 [01:33<00:31,  8.90it/s] 74%|███████▍  | 792/1070 [01:33<00:31,  8.95it/s] 74%|███████▍  | 793/1070 [01:34<00:30,  8.95it/s] 74%|███████▍  | 794/1070 [01:34<00:30,  9.00it/s] 74%|███████▍  | 795/1070 [01:34<00:30,  9.01it/s] 74%|███████▍  | 796/1070 [01:34<00:30,  9.03it/s] 74%|███████▍  | 797/1070 [01:34<00:30,  9.07it/s] 75%|███████▍  | 798/1070 [01:34<00:30,  9.02it/s] 75%|███████▍  | 799/1070 [01:34<00:30,  8.95it/s] 75%|███████▍  | 800/1070 [01:34<00:30,  8.93it/s] 75%|███████▍  | 801/1070 [01:34<00:30,  8.93it/s] 75%|███████▍  | 802/1070 [01:35<00:29,  8.95it/s] 75%|███████▌  | 803/1070 [01:35<00:29,  8.96it/s] 75%|███████▌  | 804/1070 [01:35<00:29,  9.01it/s] 75%|███████▌  | 805/1070 [01:35<00:29,  8.95it/s] 75%|███████▌  | 806/1070 [01:35<00:29,  8.95it/s] 75%|███████▌  | 807/1070 [01:35<00:29,  8.97it/s] 76%|███████▌  | 808/1070 [01:35<00:29,  8.88it/s] 76%|███████▌  | 809/1070 [01:35<00:29,  8.85it/s] 76%|███████▌  | 810/1070 [01:35<00:29,  8.87it/s] 76%|███████▌  | 811/1070 [01:36<00:29,  8.86it/s] 76%|███████▌  | 812/1070 [01:36<00:28,  8.92it/s] 76%|███████▌  | 813/1070 [01:36<00:28,  8.88it/s] 76%|███████▌  | 814/1070 [01:36<00:28,  8.90it/s] 76%|███████▌  | 815/1070 [01:36<00:28,  8.97it/s] 76%|███████▋  | 816/1070 [01:36<00:28,  8.89it/s] 76%|███████▋  | 817/1070 [01:36<00:28,  9.01it/s] 76%|███████▋  | 818/1070 [01:36<00:28,  8.96it/s] 77%|███████▋  | 819/1070 [01:36<00:27,  8.98it/s] 77%|███████▋  | 820/1070 [01:37<00:27,  8.99it/s] 77%|███████▋  | 821/1070 [01:37<00:27,  8.96it/s] 77%|███████▋  | 822/1070 [01:37<00:27,  8.93it/s] 77%|███████▋  | 823/1070 [01:37<00:27,  8.88it/s] 77%|███████▋  | 824/1070 [01:37<00:27,  8.83it/s] 77%|███████▋  | 825/1070 [01:37<00:27,  8.96it/s] 77%|███████▋  | 826/1070 [01:37<00:27,  8.92it/s] 77%|███████▋  | 827/1070 [01:37<00:27,  8.99it/s] 77%|███████▋  | 828/1070 [01:37<00:27,  8.91it/s] 77%|███████▋  | 829/1070 [01:38<00:26,  8.98it/s] 78%|███████▊  | 830/1070 [01:38<00:26,  9.03it/s] 78%|███████▊  | 831/1070 [01:38<00:26,  8.97it/s] 78%|███████▊  | 832/1070 [01:38<00:26,  8.95it/s] 78%|███████▊  | 833/1070 [01:38<00:26,  8.94it/s] 78%|███████▊  | 834/1070 [01:38<00:26,  8.98it/s] 78%|███████▊  | 835/1070 [01:38<00:25,  9.05it/s] 78%|███████▊  | 836/1070 [01:38<00:26,  8.94it/s] 78%|███████▊  | 837/1070 [01:38<00:25,  9.04it/s] 78%|███████▊  | 838/1070 [01:39<00:25,  8.93it/s] 78%|███████▊  | 839/1070 [01:39<00:25,  8.99it/s] 79%|███████▊  | 840/1070 [01:39<00:25,  9.10it/s] 79%|███████▊  | 841/1070 [01:39<00:25,  9.01it/s] 79%|███████▊  | 842/1070 [01:39<00:25,  8.98it/s] 79%|███████▉  | 843/1070 [01:39<00:25,  8.96it/s] 79%|███████▉  | 844/1070 [01:39<00:25,  9.00it/s] 79%|███████▉  | 845/1070 [01:39<00:25,  8.93it/s] 79%|███████▉  | 846/1070 [01:39<00:25,  8.86it/s] 79%|███████▉  | 847/1070 [01:40<00:25,  8.82it/s] 79%|███████▉  | 848/1070 [01:40<00:24,  8.90it/s] 79%|███████▉  | 849/1070 [01:40<00:24,  8.87it/s] 79%|███████▉  | 850/1070 [01:40<00:24,  8.96it/s] 80%|███████▉  | 851/1070 [01:40<00:24,  8.91it/s] 80%|███████▉  | 852/1070 [01:40<00:24,  8.89it/s] 80%|███████▉  | 853/1070 [01:40<00:24,  9.01it/s] 80%|███████▉  | 854/1070 [01:40<00:24,  8.97it/s] 80%|███████▉  | 855/1070 [01:40<00:24,  8.94it/s]                                                   80%|████████  | 856/1070 [01:41<00:23,  8.94it/s][INFO|trainer.py:755] 2023-11-15 19:47:08,798 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:47:08,799 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:47:08,800 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:47:08,800 >>   Batch size = 8
{'eval_loss': 0.32605454325675964, 'eval_accuracy': 0.8973684210526316, 'eval_micro_f1': 0.8973684210526317, 'eval_macro_f1': 0.894580874431949, 'eval_runtime': 1.45, 'eval_samples_per_second': 524.129, 'eval_steps_per_second': 65.516, 'epoch': 3.0}
{'loss': 0.0726, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 84.18it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 74.01it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 71.36it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 72.23it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 72.43it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 70.43it/s][A
 61%|██████    | 58/95 [00:00<00:00, 70.91it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 70.81it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 70.57it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 71.46it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 70.05it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:42<00:23,  8.94it/s]
100%|██████████| 95/95 [00:01<00:00, 70.05it/s][A
                                               [A 80%|████████  | 857/1070 [01:42<01:31,  2.33it/s] 80%|████████  | 858/1070 [01:42<01:14,  2.85it/s] 80%|████████  | 859/1070 [01:42<01:01,  3.46it/s] 80%|████████  | 860/1070 [01:42<00:50,  4.14it/s] 80%|████████  | 861/1070 [01:43<00:42,  4.88it/s] 81%|████████  | 862/1070 [01:43<00:37,  5.60it/s] 81%|████████  | 863/1070 [01:43<00:32,  6.28it/s] 81%|████████  | 864/1070 [01:43<00:29,  6.90it/s] 81%|████████  | 865/1070 [01:43<00:27,  7.35it/s] 81%|████████  | 866/1070 [01:43<00:26,  7.78it/s] 81%|████████  | 867/1070 [01:43<00:24,  8.17it/s] 81%|████████  | 868/1070 [01:43<00:24,  8.34it/s] 81%|████████  | 869/1070 [01:43<00:23,  8.48it/s] 81%|████████▏ | 870/1070 [01:44<00:23,  8.61it/s] 81%|████████▏ | 871/1070 [01:44<00:22,  8.80it/s] 81%|████████▏ | 872/1070 [01:44<00:22,  8.75it/s] 82%|████████▏ | 873/1070 [01:44<00:22,  8.80it/s] 82%|████████▏ | 874/1070 [01:44<00:22,  8.78it/s] 82%|████████▏ | 875/1070 [01:44<00:21,  8.88it/s] 82%|████████▏ | 876/1070 [01:44<00:21,  8.88it/s] 82%|████████▏ | 877/1070 [01:44<00:21,  8.98it/s] 82%|████████▏ | 878/1070 [01:44<00:21,  8.91it/s] 82%|████████▏ | 879/1070 [01:45<00:21,  8.91it/s] 82%|████████▏ | 880/1070 [01:45<00:21,  8.99it/s] 82%|████████▏ | 881/1070 [01:45<00:21,  8.92it/s] 82%|████████▏ | 882/1070 [01:45<00:21,  8.90it/s] 83%|████████▎ | 883/1070 [01:45<00:20,  8.91it/s] 83%|████████▎ | 884/1070 [01:45<00:20,  8.94it/s] 83%|████████▎ | 885/1070 [01:45<00:20,  8.92it/s] 83%|████████▎ | 886/1070 [01:45<00:20,  8.91it/s] 83%|████████▎ | 887/1070 [01:45<00:20,  8.86it/s] 83%|████████▎ | 888/1070 [01:46<00:20,  8.90it/s] 83%|████████▎ | 889/1070 [01:46<00:20,  8.88it/s] 83%|████████▎ | 890/1070 [01:46<00:20,  8.95it/s] 83%|████████▎ | 891/1070 [01:46<00:20,  8.86it/s] 83%|████████▎ | 892/1070 [01:46<00:19,  8.92it/s] 83%|████████▎ | 893/1070 [01:46<00:19,  9.02it/s] 84%|████████▎ | 894/1070 [01:46<00:19,  8.94it/s] 84%|████████▎ | 895/1070 [01:46<00:19,  8.94it/s] 84%|████████▎ | 896/1070 [01:46<00:19,  8.89it/s] 84%|████████▍ | 897/1070 [01:47<00:19,  8.92it/s] 84%|████████▍ | 898/1070 [01:47<00:19,  8.93it/s] 84%|████████▍ | 899/1070 [01:47<00:19,  8.87it/s] 84%|████████▍ | 900/1070 [01:47<00:19,  8.93it/s] 84%|████████▍ | 901/1070 [01:47<00:18,  8.96it/s] 84%|████████▍ | 902/1070 [01:47<00:18,  8.97it/s] 84%|████████▍ | 903/1070 [01:47<00:18,  9.05it/s] 84%|████████▍ | 904/1070 [01:47<00:18,  9.01it/s] 85%|████████▍ | 905/1070 [01:47<00:18,  8.99it/s] 85%|████████▍ | 906/1070 [01:48<00:18,  9.00it/s] 85%|████████▍ | 907/1070 [01:48<00:18,  9.04it/s] 85%|████████▍ | 908/1070 [01:48<00:18,  8.99it/s] 85%|████████▍ | 909/1070 [01:48<00:18,  8.91it/s] 85%|████████▌ | 910/1070 [01:48<00:18,  8.87it/s] 85%|████████▌ | 911/1070 [01:48<00:17,  8.95it/s] 85%|████████▌ | 912/1070 [01:48<00:17,  8.86it/s] 85%|████████▌ | 913/1070 [01:48<00:17,  8.95it/s] 85%|████████▌ | 914/1070 [01:48<00:17,  8.93it/s] 86%|████████▌ | 915/1070 [01:49<00:17,  8.94it/s] 86%|████████▌ | 916/1070 [01:49<00:17,  9.02it/s] 86%|████████▌ | 917/1070 [01:49<00:17,  8.91it/s] 86%|████████▌ | 918/1070 [01:49<00:17,  8.93it/s] 86%|████████▌ | 919/1070 [01:49<00:17,  8.85it/s] 86%|████████▌ | 920/1070 [01:49<00:16,  8.92it/s] 86%|████████▌ | 921/1070 [01:49<00:16,  8.88it/s] 86%|████████▌ | 922/1070 [01:49<00:16,  8.87it/s] 86%|████████▋ | 923/1070 [01:49<00:16,  8.88it/s] 86%|████████▋ | 924/1070 [01:50<00:16,  8.92it/s] 86%|████████▋ | 925/1070 [01:50<00:16,  8.96it/s] 87%|████████▋ | 926/1070 [01:50<00:15,  9.08it/s] 87%|████████▋ | 927/1070 [01:50<00:15,  8.99it/s] 87%|████████▋ | 928/1070 [01:50<00:15,  8.94it/s] 87%|████████▋ | 929/1070 [01:50<00:15,  8.94it/s] 87%|████████▋ | 930/1070 [01:50<00:15,  8.95it/s] 87%|████████▋ | 931/1070 [01:50<00:15,  8.88it/s] 87%|████████▋ | 932/1070 [01:50<00:15,  8.90it/s] 87%|████████▋ | 933/1070 [01:51<00:15,  8.88it/s] 87%|████████▋ | 934/1070 [01:51<00:15,  8.95it/s] 87%|████████▋ | 935/1070 [01:51<00:15,  8.85it/s] 87%|████████▋ | 936/1070 [01:51<00:15,  8.93it/s] 88%|████████▊ | 937/1070 [01:51<00:14,  8.87it/s] 88%|████████▊ | 938/1070 [01:51<00:14,  8.91it/s] 88%|████████▊ | 939/1070 [01:51<00:14,  9.00it/s] 88%|████████▊ | 940/1070 [01:51<00:14,  8.93it/s] 88%|████████▊ | 941/1070 [01:51<00:14,  8.90it/s] 88%|████████▊ | 942/1070 [01:52<00:14,  8.89it/s] 88%|████████▊ | 943/1070 [01:52<00:14,  8.94it/s] 88%|████████▊ | 944/1070 [01:52<00:14,  8.93it/s] 88%|████████▊ | 945/1070 [01:52<00:14,  8.90it/s] 88%|████████▊ | 946/1070 [01:52<00:13,  8.97it/s] 89%|████████▊ | 947/1070 [01:52<00:13,  8.88it/s] 89%|████████▊ | 948/1070 [01:52<00:13,  8.93it/s] 89%|████████▊ | 949/1070 [01:52<00:13,  9.06it/s] 89%|████████▉ | 950/1070 [01:52<00:13,  8.92it/s] 89%|████████▉ | 951/1070 [01:53<00:13,  8.94it/s] 89%|████████▉ | 952/1070 [01:53<00:13,  8.89it/s] 89%|████████▉ | 953/1070 [01:53<00:13,  8.97it/s] 89%|████████▉ | 954/1070 [01:53<00:12,  8.95it/s] 89%|████████▉ | 955/1070 [01:53<00:12,  8.90it/s] 89%|████████▉ | 956/1070 [01:53<00:12,  8.87it/s] 89%|████████▉ | 957/1070 [01:53<00:12,  8.84it/s] 90%|████████▉ | 958/1070 [01:53<00:12,  8.85it/s] 90%|████████▉ | 959/1070 [01:53<00:12,  8.96it/s] 90%|████████▉ | 960/1070 [01:54<00:12,  8.93it/s] 90%|████████▉ | 961/1070 [01:54<00:12,  8.93it/s] 90%|████████▉ | 962/1070 [01:54<00:12,  8.92it/s] 90%|█████████ | 963/1070 [01:54<00:11,  8.95it/s] 90%|█████████ | 964/1070 [01:54<00:11,  8.90it/s] 90%|█████████ | 965/1070 [01:54<00:11,  8.83it/s] 90%|█████████ | 966/1070 [01:54<00:11,  8.85it/s] 90%|█████████ | 967/1070 [01:54<00:11,  8.88it/s] 90%|█████████ | 968/1070 [01:54<00:11,  8.89it/s] 91%|█████████ | 969/1070 [01:55<00:11,  9.00it/s] 91%|█████████ | 970/1070 [01:55<00:11,  8.88it/s] 91%|█████████ | 971/1070 [01:55<00:11,  8.84it/s] 91%|█████████ | 972/1070 [01:55<00:11,  8.91it/s] 91%|█████████ | 973/1070 [01:55<00:10,  8.91it/s] 91%|█████████ | 974/1070 [01:55<00:10,  8.87it/s] 91%|█████████ | 975/1070 [01:55<00:10,  8.84it/s] 91%|█████████ | 976/1070 [01:55<00:10,  8.80it/s] 91%|█████████▏| 977/1070 [01:56<00:10,  8.85it/s] 91%|█████████▏| 978/1070 [01:56<00:10,  8.77it/s] 91%|█████████▏| 979/1070 [01:56<00:10,  8.87it/s] 92%|█████████▏| 980/1070 [01:56<00:10,  8.81it/s] 92%|█████████▏| 981/1070 [01:56<00:10,  8.81it/s] 92%|█████████▏| 982/1070 [01:56<00:09,  8.87it/s] 92%|█████████▏| 983/1070 [01:56<00:09,  8.86it/s] 92%|█████████▏| 984/1070 [01:56<00:09,  8.86it/s] 92%|█████████▏| 985/1070 [01:56<00:09,  8.83it/s] 92%|█████████▏| 986/1070 [01:57<00:09,  8.85it/s] 92%|█████████▏| 987/1070 [01:57<00:09,  8.87it/s] 92%|█████████▏| 988/1070 [01:57<00:09,  8.84it/s] 92%|█████████▏| 989/1070 [01:57<00:09,  8.92it/s] 93%|█████████▎| 990/1070 [01:57<00:09,  8.87it/s] 93%|█████████▎| 991/1070 [01:57<00:08,  8.89it/s] 93%|█████████▎| 992/1070 [01:57<00:08,  8.95it/s] 93%|█████████▎| 993/1070 [01:57<00:08,  8.90it/s] 93%|█████████▎| 994/1070 [01:57<00:08,  8.87it/s] 93%|█████████▎| 995/1070 [01:58<00:08,  8.82it/s] 93%|█████████▎| 996/1070 [01:58<00:08,  8.84it/s] 93%|█████████▎| 997/1070 [01:58<00:08,  8.85it/s] 93%|█████████▎| 998/1070 [01:58<00:08,  8.83it/s] 93%|█████████▎| 999/1070 [01:58<00:07,  8.89it/s] 93%|█████████▎| 1000/1070 [01:58<00:07,  8.84it/s] 94%|█████████▎| 1001/1070 [01:58<00:07,  8.90it/s] 94%|█████████▎| 1002/1070 [01:58<00:07,  8.97it/s] 94%|█████████▎| 1003/1070 [01:58<00:07,  8.88it/s] 94%|█████████▍| 1004/1070 [01:59<00:07,  8.87it/s] 94%|█████████▍| 1005/1070 [01:59<00:07,  8.84it/s] 94%|█████████▍| 1006/1070 [01:59<00:07,  8.85it/s] 94%|█████████▍| 1007/1070 [01:59<00:07,  8.83it/s] 94%|█████████▍| 1008/1070 [01:59<00:07,  8.77it/s] 94%|█████████▍| 1009/1070 [01:59<00:06,  8.87it/s] 94%|█████████▍| 1010/1070 [01:59<00:06,  8.84it/s] 94%|█████████▍| 1011/1070 [01:59<00:06,  8.86it/s] 95%|█████████▍| 1012/1070 [01:59<00:06,  8.94it/s] 95%|█████████▍| 1013/1070 [02:00<00:06,  8.81it/s] 95%|█████████▍| 1014/1070 [02:00<00:06,  8.74it/s] 95%|█████████▍| 1015/1070 [02:00<00:06,  8.78it/s] 95%|█████████▍| 1016/1070 [02:00<00:06,  8.83it/s] 95%|█████████▌| 1017/1070 [02:00<00:06,  8.76it/s] 95%|█████████▌| 1018/1070 [02:00<00:05,  8.74it/s] 95%|█████████▌| 1019/1070 [02:00<00:05,  8.86it/s] 95%|█████████▌| 1020/1070 [02:00<00:05,  8.80it/s] 95%|█████████▌| 1021/1070 [02:00<00:05,  8.82it/s] 96%|█████████▌| 1022/1070 [02:01<00:05,  8.97it/s] 96%|█████████▌| 1023/1070 [02:01<00:05,  8.87it/s] 96%|█████████▌| 1024/1070 [02:01<00:05,  8.85it/s] 96%|█████████▌| 1025/1070 [02:01<00:05,  8.83it/s] 96%|█████████▌| 1026/1070 [02:01<00:04,  8.90it/s] 96%|█████████▌| 1027/1070 [02:01<00:04,  8.84it/s] 96%|█████████▌| 1028/1070 [02:01<00:04,  8.83it/s] 96%|█████████▌| 1029/1070 [02:01<00:04,  8.95it/s] 96%|█████████▋| 1030/1070 [02:01<00:04,  8.88it/s] 96%|█████████▋| 1031/1070 [02:02<00:04,  8.89it/s] 96%|█████████▋| 1032/1070 [02:02<00:04,  9.03it/s] 97%|█████████▋| 1033/1070 [02:02<00:04,  8.97it/s] 97%|█████████▋| 1034/1070 [02:02<00:04,  8.87it/s] 97%|█████████▋| 1035/1070 [02:02<00:03,  8.85it/s] 97%|█████████▋| 1036/1070 [02:02<00:03,  8.92it/s] 97%|█████████▋| 1037/1070 [02:02<00:03,  8.82it/s] 97%|█████████▋| 1038/1070 [02:02<00:03,  8.82it/s] 97%|█████████▋| 1039/1070 [02:03<00:03,  8.86it/s] 97%|█████████▋| 1040/1070 [02:03<00:03,  8.91it/s] 97%|█████████▋| 1041/1070 [02:03<00:03,  8.91it/s] 97%|█████████▋| 1042/1070 [02:03<00:03,  9.04it/s] 97%|█████████▋| 1043/1070 [02:03<00:03,  8.94it/s] 98%|█████████▊| 1044/1070 [02:03<00:02,  8.86it/s] 98%|█████████▊| 1045/1070 [02:03<00:02,  8.87it/s] 98%|█████████▊| 1046/1070 [02:03<00:02,  8.89it/s] 98%|█████████▊| 1047/1070 [02:03<00:02,  8.82it/s] 98%|█████████▊| 1048/1070 [02:04<00:02,  8.80it/s] 98%|█████████▊| 1049/1070 [02:04<00:02,  8.82it/s] 98%|█████████▊| 1050/1070 [02:04<00:02,  8.86it/s] 98%|█████████▊| 1051/1070 [02:04<00:02,  8.83it/s] 98%|█████████▊| 1052/1070 [02:04<00:02,  8.94it/s] 98%|█████████▊| 1053/1070 [02:04<00:01,  8.82it/s] 99%|█████████▊| 1054/1070 [02:04<00:01,  8.89it/s] 99%|█████████▊| 1055/1070 [02:04<00:01,  8.90it/s] 99%|█████████▊| 1056/1070 [02:04<00:01,  8.89it/s] 99%|█████████▉| 1057/1070 [02:05<00:01,  8.84it/s] 99%|█████████▉| 1058/1070 [02:05<00:01,  8.81it/s] 99%|█████████▉| 1059/1070 [02:05<00:01,  8.80it/s] 99%|█████████▉| 1060/1070 [02:05<00:01,  8.84it/s] 99%|█████████▉| 1061/1070 [02:05<00:01,  8.81it/s] 99%|█████████▉| 1062/1070 [02:05<00:00,  8.92it/s] 99%|█████████▉| 1063/1070 [02:05<00:00,  8.87it/s] 99%|█████████▉| 1064/1070 [02:05<00:00,  8.94it/s]100%|█████████▉| 1065/1070 [02:05<00:00,  9.06it/s]100%|█████████▉| 1066/1070 [02:06<00:00,  8.92it/s]100%|█████████▉| 1067/1070 [02:06<00:00,  8.92it/s]100%|█████████▉| 1068/1070 [02:06<00:00,  8.87it/s]100%|█████████▉| 1069/1070 [02:06<00:00,  8.93it/s]                                                   100%|██████████| 1070/1070 [02:06<00:00,  8.93it/s][INFO|trainer.py:755] 2023-11-15 19:47:34,224 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:47:34,226 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:47:34,226 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:47:34,227 >>   Batch size = 8
{'eval_loss': 0.39104023575782776, 'eval_accuracy': 0.8973684210526316, 'eval_micro_f1': 0.8973684210526317, 'eval_macro_f1': 0.8947304243082619, 'eval_runtime': 1.3867, 'eval_samples_per_second': 548.075, 'eval_steps_per_second': 68.509, 'epoch': 4.0}
{'loss': 0.0456, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 80.95it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 74.69it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 73.14it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 70.75it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 69.86it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 69.68it/s][A
 60%|██████    | 57/95 [00:00<00:00, 69.60it/s][A
 67%|██████▋   | 64/95 [00:00<00:00, 69.71it/s][A
 75%|███████▍  | 71/95 [00:01<00:00, 69.57it/s][A
 82%|████████▏ | 78/95 [00:01<00:00, 69.02it/s][A
 89%|████████▉ | 85/95 [00:01<00:00, 67.49it/s][A
 98%|█████████▊| 93/95 [00:01<00:00, 69.45it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:07<00:00,  8.93it/s]
100%|██████████| 95/95 [00:01<00:00, 69.45it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 19:47:35,644 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:07<00:00,  8.93it/s]100%|██████████| 1070/1070 [02:07<00:00,  8.37it/s]
[INFO|trainer.py:2855] 2023-11-15 19:47:35,648 >> Saving model checkpoint to ./result/agnews_sup_bert-base-cased_adapter__seed0
[INFO|configuration_utils.py:460] 2023-11-15 19:47:35,651 >> Configuration saved in ./result/agnews_sup_bert-base-cased_adapter__seed0/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:47:36,887 >> Model weights saved in ./result/agnews_sup_bert-base-cased_adapter__seed0/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:47:36,889 >> tokenizer config file saved in ./result/agnews_sup_bert-base-cased_adapter__seed0/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:47:36,892 >> Special tokens file saved in ./result/agnews_sup_bert-base-cased_adapter__seed0/special_tokens_map.json
{'eval_loss': 0.4139268100261688, 'eval_accuracy': 0.8947368421052632, 'eval_micro_f1': 0.8947368421052632, 'eval_macro_f1': 0.8919742018178907, 'eval_runtime': 1.4133, 'eval_samples_per_second': 537.748, 'eval_steps_per_second': 67.218, 'epoch': 5.0}
{'train_runtime': 127.908, 'train_samples_per_second': 267.38, 'train_steps_per_second': 8.365, 'train_loss': 0.18494656732149214, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.1849
  train_runtime            = 0:02:07.90
  train_samples            =       6840
  train_samples_per_second =     267.38
  train_steps_per_second   =      8.365
11/15/2023 19:47:36 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:47:36,939 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:47:36,940 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:47:36,940 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:47:36,941 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  9%|▉         | 9/95 [00:00<00:01, 83.31it/s] 19%|█▉        | 18/95 [00:00<00:01, 73.72it/s] 27%|██▋       | 26/95 [00:00<00:00, 70.54it/s] 36%|███▌      | 34/95 [00:00<00:00, 70.01it/s] 44%|████▍     | 42/95 [00:00<00:00, 69.97it/s] 53%|█████▎    | 50/95 [00:00<00:00, 68.93it/s] 60%|██████    | 57/95 [00:00<00:00, 68.40it/s] 67%|██████▋   | 64/95 [00:00<00:00, 68.53it/s] 75%|███████▍  | 71/95 [00:01<00:00, 68.83it/s] 83%|████████▎ | 79/95 [00:01<00:00, 69.73it/s] 91%|█████████ | 86/95 [00:01<00:00, 69.33it/s] 99%|█████████▉| 94/95 [00:01<00:00, 70.22it/s]100%|██████████| 95/95 [00:01<00:00, 68.33it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8947
  eval_loss               =     0.4139
  eval_macro_f1           =      0.892
  eval_micro_f1           =     0.8947
  eval_runtime            = 0:00:01.41
  eval_samples            =        760
  eval_samples_per_second =    538.799
  eval_steps_per_second   =      67.35
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▇█▃▃▁▁
wandb:                      eval/loss ▂▁▂▆██
wandb:                  eval/macro_f1 ▆█▃▃▁▁
wandb:                  eval/micro_f1 ▇█▃▃▁▁
wandb:                   eval/runtime ▁▇█▃▅▅
wandb:        eval/samples_per_second █▂▁▆▄▄
wandb:          eval/steps_per_second █▂▁▆▄▄
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▁▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.89474
wandb:                      eval/loss 0.41393
wandb:                  eval/macro_f1 0.89197
wandb:                  eval/micro_f1 0.89474
wandb:                   eval/runtime 1.4105
wandb:        eval/samples_per_second 538.799
wandb:          eval/steps_per_second 67.35
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0456
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.18495
wandb:            train/train_runtime 127.908
wandb: train/train_samples_per_second 267.38
wandb:   train/train_steps_per_second 8.365
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_194440-dbes7g9b
wandb: Find logs at: ./wandb/offline-run-20231115_194440-dbes7g9b/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0/runs/Nov15_19-47-50_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:47:50 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:47:50 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0/runs/Nov15_19-47-49_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=111,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 19:48:06,145 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:48:06,157 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 19:48:16,174 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 19:48:26,193 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:48:26,194 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:48:46,275 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:48:46,276 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:48:46,276 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:48:46,276 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:48:46,276 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 19:48:46,279 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:48:46,279 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 19:48:46,302 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:48:46,303 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:49:06,456 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 19:49:08,196 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:49:08,197 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  29%|██▉       | 2000/6840 [00:00<00:00, 16643.47 examples/s]Running tokenizer on dataset:  73%|███████▎  | 5000/6840 [00:00<00:00, 18705.11 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 18540.55 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 22539.18 examples/s]
11/15/2023 19:49:08 - INFO - __main__ - Sample 6776 of the training set: {'text': 'Cup chase lands in Dover When the green flag drops for today #39;s MBNA America 400 at Dover International Speedway, 43 drivers will be lined up to cross the start/finish line.', 'label': 0, 'input_ids': [102, 14009, 7683, 246, 24662, 121, 17681, 30114, 603, 111, 3755, 9721, 12976, 168, 7121, 3000, 4133, 1814, 112, 6369, 648, 7968, 5629, 235, 17681, 30114, 2565, 2747, 1758, 422, 4734, 12034, 650, 195, 972, 30118, 692, 147, 2057, 111, 3901, 1352, 19996, 972, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:49:08 - INFO - __main__ - Sample 1742 of the training set: {'text': 'Louisiana Tech Bulldogs RUSTON, Louisiana (Ticker) -- No. 17 Fresno State could not overcome a dominant performance by Ryan Moats or a poor one by Paul Pinegar.', 'label': 0, 'input_ids': [102, 10540, 14388, 14134, 11777, 2904, 3940, 7069, 1764, 422, 10540, 14388, 145, 15530, 114, 546, 579, 579, 425, 205, 1557, 28757, 2682, 1098, 968, 302, 7505, 106, 5521, 1150, 214, 20338, 533, 3257, 234, 106, 3228, 482, 214, 8374, 14990, 11142, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:49:08 - INFO - __main__ - Sample 2588 of the training set: {'text': 'Rossi:  #39;I #39;m fairly happy #39; Valentino Rossi, who on Thursday pledged his future to Yamaha, entered the final qualifying session with the fastest time to date, but with the morning rain having washed the circuit clean, the Italian was unable to challenge Makoto Tamada for the pole.', 'label': 0, 'input_ids': [102, 13657, 30109, 862, 3000, 4133, 1814, 259, 3000, 4133, 1814, 127, 10542, 20942, 3000, 4133, 1814, 491, 28590, 30112, 13657, 30109, 422, 975, 191, 149, 2669, 3113, 4641, 13465, 119, 1972, 2158, 147, 10863, 14503, 422, 11405, 111, 2531, 3885, 5780, 4205, 190, 111, 22675, 532, 147, 4282, 422, 563, 190, 111, 14522, 7112, 2773, 6069, 111, 4239, 7113, 422, 111, 14865, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 19:49:08 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:49:10,262 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:49:10,271 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:49:10,271 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 19:49:10,272 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:49:10,272 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:49:10,272 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:49:10,272 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:49:10,273 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 19:49:10,274 >>   Number of trainable parameters = 109,921,540
[INFO|integration_utils.py:716] 2023-11-15 19:49:10,275 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<27:43,  1.56s/it]  0%|          | 2/1070 [00:01<12:33,  1.42it/s]  0%|          | 3/1070 [00:01<07:44,  2.30it/s]  0%|          | 4/1070 [00:01<05:28,  3.25it/s]  0%|          | 5/1070 [00:02<04:12,  4.22it/s]  1%|          | 6/1070 [00:02<03:26,  5.16it/s]  1%|          | 7/1070 [00:02<02:57,  6.00it/s]  1%|          | 8/1070 [00:02<02:38,  6.70it/s]  1%|          | 9/1070 [00:02<02:25,  7.27it/s]  1%|          | 10/1070 [00:02<02:16,  7.75it/s]  1%|          | 11/1070 [00:02<02:12,  7.97it/s]  1%|          | 12/1070 [00:02<02:07,  8.28it/s]  1%|          | 13/1070 [00:02<02:04,  8.48it/s]  1%|▏         | 14/1070 [00:03<02:02,  8.62it/s]  1%|▏         | 15/1070 [00:03<02:01,  8.72it/s]  1%|▏         | 16/1070 [00:03<01:58,  8.90it/s]  2%|▏         | 17/1070 [00:03<01:58,  8.90it/s]  2%|▏         | 18/1070 [00:03<01:58,  8.86it/s]  2%|▏         | 19/1070 [00:03<01:59,  8.80it/s]  2%|▏         | 20/1070 [00:03<01:59,  8.82it/s]  2%|▏         | 21/1070 [00:03<01:58,  8.85it/s]  2%|▏         | 22/1070 [00:03<01:59,  8.80it/s]  2%|▏         | 23/1070 [00:04<01:57,  8.91it/s]  2%|▏         | 24/1070 [00:04<01:58,  8.86it/s]  2%|▏         | 25/1070 [00:04<01:58,  8.81it/s]  2%|▏         | 26/1070 [00:04<01:57,  8.89it/s]  3%|▎         | 27/1070 [00:04<01:57,  8.85it/s]  3%|▎         | 28/1070 [00:04<01:58,  8.81it/s]  3%|▎         | 29/1070 [00:04<01:57,  8.83it/s]  3%|▎         | 30/1070 [00:04<01:57,  8.85it/s]  3%|▎         | 31/1070 [00:04<01:58,  8.79it/s]  3%|▎         | 32/1070 [00:05<01:57,  8.81it/s]  3%|▎         | 33/1070 [00:05<01:55,  8.97it/s]  3%|▎         | 34/1070 [00:05<01:56,  8.88it/s]  3%|▎         | 35/1070 [00:05<01:57,  8.83it/s]  3%|▎         | 36/1070 [00:05<01:56,  8.87it/s]  3%|▎         | 37/1070 [00:05<01:56,  8.90it/s]  4%|▎         | 38/1070 [00:05<01:56,  8.85it/s]  4%|▎         | 39/1070 [00:05<01:57,  8.80it/s]  4%|▎         | 40/1070 [00:05<01:55,  8.89it/s]  4%|▍         | 41/1070 [00:06<01:56,  8.85it/s]  4%|▍         | 42/1070 [00:06<01:55,  8.89it/s]  4%|▍         | 43/1070 [00:06<01:54,  8.99it/s]  4%|▍         | 44/1070 [00:06<01:54,  8.96it/s]  4%|▍         | 45/1070 [00:06<01:55,  8.87it/s]  4%|▍         | 46/1070 [00:06<01:55,  8.90it/s]  4%|▍         | 47/1070 [00:06<01:54,  8.91it/s]  4%|▍         | 48/1070 [00:06<01:54,  8.92it/s]  5%|▍         | 49/1070 [00:06<01:53,  8.96it/s]  5%|▍         | 50/1070 [00:07<01:52,  9.04it/s]  5%|▍         | 51/1070 [00:07<01:53,  8.95it/s]  5%|▍         | 52/1070 [00:07<01:53,  8.95it/s]  5%|▍         | 53/1070 [00:07<01:52,  9.01it/s]  5%|▌         | 54/1070 [00:07<01:52,  9.01it/s]  5%|▌         | 55/1070 [00:07<01:53,  8.98it/s]  5%|▌         | 56/1070 [00:07<01:52,  9.00it/s]  5%|▌         | 57/1070 [00:07<01:53,  8.95it/s]  5%|▌         | 58/1070 [00:07<01:52,  8.98it/s]  6%|▌         | 59/1070 [00:08<01:53,  8.95it/s]  6%|▌         | 60/1070 [00:08<01:50,  9.12it/s]  6%|▌         | 61/1070 [00:08<01:51,  9.01it/s]  6%|▌         | 62/1070 [00:08<01:52,  8.94it/s]  6%|▌         | 63/1070 [00:08<01:53,  8.90it/s]  6%|▌         | 64/1070 [00:08<01:52,  8.93it/s]  6%|▌         | 65/1070 [00:08<01:52,  8.96it/s]  6%|▌         | 66/1070 [00:08<01:52,  8.94it/s]  6%|▋         | 67/1070 [00:08<01:49,  9.13it/s]  6%|▋         | 68/1070 [00:09<01:50,  9.03it/s]  6%|▋         | 69/1070 [00:09<01:50,  9.02it/s]  7%|▋         | 70/1070 [00:09<01:49,  9.10it/s]  7%|▋         | 71/1070 [00:09<01:50,  9.07it/s]  7%|▋         | 72/1070 [00:09<01:51,  8.98it/s]  7%|▋         | 73/1070 [00:09<01:51,  8.93it/s]  7%|▋         | 74/1070 [00:09<01:51,  8.96it/s]  7%|▋         | 75/1070 [00:09<01:50,  8.97it/s]  7%|▋         | 76/1070 [00:09<01:51,  8.94it/s]  7%|▋         | 77/1070 [00:10<01:49,  9.07it/s]  7%|▋         | 78/1070 [00:10<01:49,  9.10it/s]  7%|▋         | 79/1070 [00:10<01:50,  8.96it/s]  7%|▋         | 80/1070 [00:10<01:50,  8.97it/s]  8%|▊         | 81/1070 [00:10<01:49,  9.00it/s]  8%|▊         | 82/1070 [00:10<01:49,  8.99it/s]  8%|▊         | 83/1070 [00:10<01:50,  8.95it/s]  8%|▊         | 84/1070 [00:10<01:49,  9.02it/s]  8%|▊         | 85/1070 [00:10<01:49,  8.98it/s]  8%|▊         | 86/1070 [00:11<01:49,  8.96it/s]  8%|▊         | 87/1070 [00:11<01:48,  9.06it/s]  8%|▊         | 88/1070 [00:11<01:49,  8.99it/s]  8%|▊         | 89/1070 [00:11<01:49,  8.99it/s]  8%|▊         | 90/1070 [00:11<01:48,  9.00it/s]  9%|▊         | 91/1070 [00:11<01:49,  8.97it/s]  9%|▊         | 92/1070 [00:11<01:48,  8.99it/s]  9%|▊         | 93/1070 [00:11<01:49,  8.91it/s]  9%|▉         | 94/1070 [00:11<01:48,  9.02it/s]  9%|▉         | 95/1070 [00:12<01:48,  8.96it/s]  9%|▉         | 96/1070 [00:12<01:48,  8.97it/s]  9%|▉         | 97/1070 [00:12<01:48,  9.00it/s]  9%|▉         | 98/1070 [00:12<01:47,  9.04it/s]  9%|▉         | 99/1070 [00:12<01:48,  8.91it/s]  9%|▉         | 100/1070 [00:12<01:49,  8.85it/s]  9%|▉         | 101/1070 [00:12<01:49,  8.87it/s] 10%|▉         | 102/1070 [00:12<01:48,  8.90it/s] 10%|▉         | 103/1070 [00:12<01:49,  8.82it/s] 10%|▉         | 104/1070 [00:13<01:48,  8.91it/s] 10%|▉         | 105/1070 [00:13<01:47,  8.98it/s] 10%|▉         | 106/1070 [00:13<01:47,  8.97it/s] 10%|█         | 107/1070 [00:13<01:47,  8.96it/s] 10%|█         | 108/1070 [00:13<01:46,  9.02it/s] 10%|█         | 109/1070 [00:13<01:47,  8.97it/s] 10%|█         | 110/1070 [00:13<01:47,  8.94it/s] 10%|█         | 111/1070 [00:13<01:47,  8.94it/s] 10%|█         | 112/1070 [00:13<01:46,  8.95it/s] 11%|█         | 113/1070 [00:14<01:46,  9.00it/s] 11%|█         | 114/1070 [00:14<01:45,  9.07it/s] 11%|█         | 115/1070 [00:14<01:46,  8.98it/s] 11%|█         | 116/1070 [00:14<01:46,  8.95it/s] 11%|█         | 117/1070 [00:14<01:46,  8.96it/s] 11%|█         | 118/1070 [00:14<01:45,  8.99it/s] 11%|█         | 119/1070 [00:14<01:44,  9.06it/s] 11%|█         | 120/1070 [00:14<01:46,  8.92it/s] 11%|█▏        | 121/1070 [00:14<01:45,  9.00it/s] 11%|█▏        | 122/1070 [00:15<01:46,  8.94it/s] 11%|█▏        | 123/1070 [00:15<01:45,  8.98it/s] 12%|█▏        | 124/1070 [00:15<01:44,  9.01it/s] 12%|█▏        | 125/1070 [00:15<01:45,  8.99it/s] 12%|█▏        | 126/1070 [00:15<01:45,  8.91it/s] 12%|█▏        | 127/1070 [00:15<01:45,  8.92it/s] 12%|█▏        | 128/1070 [00:15<01:45,  8.90it/s] 12%|█▏        | 129/1070 [00:15<01:45,  8.96it/s] 12%|█▏        | 130/1070 [00:15<01:45,  8.89it/s] 12%|█▏        | 131/1070 [00:16<01:44,  8.96it/s] 12%|█▏        | 132/1070 [00:16<01:45,  8.89it/s] 12%|█▏        | 133/1070 [00:16<01:45,  8.90it/s] 13%|█▎        | 134/1070 [00:16<01:44,  8.94it/s] 13%|█▎        | 135/1070 [00:16<01:44,  8.97it/s] 13%|█▎        | 136/1070 [00:16<01:44,  8.93it/s] 13%|█▎        | 137/1070 [00:16<01:44,  8.93it/s] 13%|█▎        | 138/1070 [00:16<01:43,  8.96it/s] 13%|█▎        | 139/1070 [00:16<01:44,  8.91it/s] 13%|█▎        | 140/1070 [00:17<01:44,  8.86it/s] 13%|█▎        | 141/1070 [00:17<01:42,  9.03it/s] 13%|█▎        | 142/1070 [00:17<01:44,  8.91it/s] 13%|█▎        | 143/1070 [00:17<01:44,  8.91it/s] 13%|█▎        | 144/1070 [00:17<01:43,  8.91it/s] 14%|█▎        | 145/1070 [00:17<01:43,  8.97it/s] 14%|█▎        | 146/1070 [00:17<01:43,  8.90it/s] 14%|█▎        | 147/1070 [00:17<01:43,  8.88it/s] 14%|█▍        | 148/1070 [00:17<01:43,  8.90it/s] 14%|█▍        | 149/1070 [00:18<01:43,  8.93it/s] 14%|█▍        | 150/1070 [00:18<01:42,  8.98it/s] 14%|█▍        | 151/1070 [00:18<01:41,  9.03it/s] 14%|█▍        | 152/1070 [00:18<01:42,  8.96it/s] 14%|█▍        | 153/1070 [00:18<01:43,  8.90it/s] 14%|█▍        | 154/1070 [00:18<01:42,  8.93it/s] 14%|█▍        | 155/1070 [00:18<01:41,  8.98it/s] 15%|█▍        | 156/1070 [00:18<01:41,  8.96it/s] 15%|█▍        | 157/1070 [00:18<01:42,  8.95it/s] 15%|█▍        | 158/1070 [00:19<01:41,  8.99it/s] 15%|█▍        | 159/1070 [00:19<01:40,  9.03it/s] 15%|█▍        | 160/1070 [00:19<01:40,  9.05it/s] 15%|█▌        | 161/1070 [00:19<01:39,  9.10it/s] 15%|█▌        | 162/1070 [00:19<01:40,  8.99it/s] 15%|█▌        | 163/1070 [00:19<01:41,  8.96it/s] 15%|█▌        | 164/1070 [00:19<01:41,  8.95it/s] 15%|█▌        | 165/1070 [00:19<01:40,  8.98it/s] 16%|█▌        | 166/1070 [00:19<01:40,  9.01it/s] 16%|█▌        | 167/1070 [00:20<01:40,  8.96it/s] 16%|█▌        | 168/1070 [00:20<01:40,  8.97it/s] 16%|█▌        | 169/1070 [00:20<01:40,  8.99it/s] 16%|█▌        | 170/1070 [00:20<01:40,  8.97it/s] 16%|█▌        | 171/1070 [00:20<01:38,  9.09it/s] 16%|█▌        | 172/1070 [00:20<01:39,  9.02it/s] 16%|█▌        | 173/1070 [00:20<01:39,  8.98it/s] 16%|█▋        | 174/1070 [00:20<01:39,  9.01it/s] 16%|█▋        | 175/1070 [00:20<01:39,  8.99it/s] 16%|█▋        | 176/1070 [00:21<01:39,  8.97it/s] 17%|█▋        | 177/1070 [00:21<01:39,  8.95it/s] 17%|█▋        | 178/1070 [00:21<01:39,  8.98it/s] 17%|█▋        | 179/1070 [00:21<01:39,  8.96it/s] 17%|█▋        | 180/1070 [00:21<01:38,  9.00it/s] 17%|█▋        | 181/1070 [00:21<01:37,  9.09it/s] 17%|█▋        | 182/1070 [00:21<01:38,  9.02it/s] 17%|█▋        | 183/1070 [00:21<01:39,  8.92it/s] 17%|█▋        | 184/1070 [00:21<01:38,  8.96it/s] 17%|█▋        | 185/1070 [00:22<01:38,  8.96it/s] 17%|█▋        | 186/1070 [00:22<01:38,  8.94it/s] 17%|█▋        | 187/1070 [00:22<01:39,  8.91it/s] 18%|█▊        | 188/1070 [00:22<01:37,  9.04it/s] 18%|█▊        | 189/1070 [00:22<01:37,  9.00it/s] 18%|█▊        | 190/1070 [00:22<01:37,  9.02it/s] 18%|█▊        | 191/1070 [00:22<01:37,  9.04it/s] 18%|█▊        | 192/1070 [00:22<01:38,  8.92it/s] 18%|█▊        | 193/1070 [00:22<01:38,  8.92it/s] 18%|█▊        | 194/1070 [00:23<01:38,  8.92it/s] 18%|█▊        | 195/1070 [00:23<01:38,  8.91it/s] 18%|█▊        | 196/1070 [00:23<01:37,  8.94it/s] 18%|█▊        | 197/1070 [00:23<01:38,  8.85it/s] 19%|█▊        | 198/1070 [00:23<01:37,  8.98it/s] 19%|█▊        | 199/1070 [00:23<01:37,  8.96it/s] 19%|█▊        | 200/1070 [00:23<01:36,  8.98it/s] 19%|█▉        | 201/1070 [00:23<01:36,  9.03it/s] 19%|█▉        | 202/1070 [00:24<01:36,  8.98it/s] 19%|█▉        | 203/1070 [00:24<01:36,  8.95it/s] 19%|█▉        | 204/1070 [00:24<01:36,  9.02it/s] 19%|█▉        | 205/1070 [00:24<01:36,  8.95it/s] 19%|█▉        | 206/1070 [00:24<01:36,  8.97it/s] 19%|█▉        | 207/1070 [00:24<01:36,  8.95it/s] 19%|█▉        | 208/1070 [00:24<01:35,  9.01it/s] 20%|█▉        | 209/1070 [00:24<01:35,  8.98it/s] 20%|█▉        | 210/1070 [00:24<01:36,  8.95it/s] 20%|█▉        | 211/1070 [00:25<01:35,  8.97it/s] 20%|█▉        | 212/1070 [00:25<01:35,  9.01it/s] 20%|█▉        | 213/1070 [00:25<01:35,  9.01it/s]                                                   20%|██        | 214/1070 [00:25<01:35,  9.01it/s][INFO|trainer.py:755] 2023-11-15 19:49:35,603 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:49:35,605 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:49:35,606 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:49:35,606 >>   Batch size = 8
{'loss': 0.5143, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 81.38it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 77.54it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 71.36it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 73.07it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 71.56it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 71.38it/s][A
 61%|██████    | 58/95 [00:00<00:00, 72.63it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 70.70it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 69.81it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 70.61it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 70.88it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:26<01:35,  9.01it/s]
100%|██████████| 95/95 [00:01<00:00, 70.88it/s][A
                                               [A 20%|██        | 215/1070 [00:26<06:04,  2.34it/s] 20%|██        | 216/1070 [00:26<04:57,  2.87it/s] 20%|██        | 217/1070 [00:27<04:04,  3.49it/s] 20%|██        | 218/1070 [00:27<03:23,  4.18it/s] 20%|██        | 219/1070 [00:27<02:53,  4.91it/s] 21%|██        | 220/1070 [00:27<02:30,  5.65it/s] 21%|██        | 221/1070 [00:27<02:14,  6.31it/s] 21%|██        | 222/1070 [00:27<02:02,  6.91it/s] 21%|██        | 223/1070 [00:27<01:54,  7.40it/s] 21%|██        | 224/1070 [00:27<01:48,  7.79it/s] 21%|██        | 225/1070 [00:27<01:44,  8.10it/s] 21%|██        | 226/1070 [00:28<01:40,  8.44it/s] 21%|██        | 227/1070 [00:28<01:39,  8.51it/s] 21%|██▏       | 228/1070 [00:28<01:38,  8.57it/s] 21%|██▏       | 229/1070 [00:28<01:37,  8.62it/s] 21%|██▏       | 230/1070 [00:28<01:35,  8.77it/s] 22%|██▏       | 231/1070 [00:28<01:35,  8.76it/s] 22%|██▏       | 232/1070 [00:28<01:35,  8.79it/s] 22%|██▏       | 233/1070 [00:28<01:34,  8.86it/s] 22%|██▏       | 234/1070 [00:28<01:33,  8.90it/s] 22%|██▏       | 235/1070 [00:29<01:33,  8.95it/s] 22%|██▏       | 236/1070 [00:29<01:32,  9.04it/s] 22%|██▏       | 237/1070 [00:29<01:32,  8.96it/s] 22%|██▏       | 238/1070 [00:29<01:33,  8.93it/s] 22%|██▏       | 239/1070 [00:29<01:33,  8.89it/s] 22%|██▏       | 240/1070 [00:29<01:33,  8.84it/s] 23%|██▎       | 241/1070 [00:29<01:33,  8.84it/s] 23%|██▎       | 242/1070 [00:29<01:33,  8.83it/s] 23%|██▎       | 243/1070 [00:29<01:33,  8.88it/s] 23%|██▎       | 244/1070 [00:30<01:33,  8.84it/s] 23%|██▎       | 245/1070 [00:30<01:33,  8.82it/s] 23%|██▎       | 246/1070 [00:30<01:32,  8.95it/s] 23%|██▎       | 247/1070 [00:30<01:31,  8.95it/s] 23%|██▎       | 248/1070 [00:30<01:32,  8.92it/s] 23%|██▎       | 249/1070 [00:30<01:31,  8.93it/s] 23%|██▎       | 250/1070 [00:30<01:32,  8.87it/s] 23%|██▎       | 251/1070 [00:30<01:32,  8.86it/s] 24%|██▎       | 252/1070 [00:30<01:32,  8.85it/s] 24%|██▎       | 253/1070 [00:31<01:32,  8.86it/s] 24%|██▎       | 254/1070 [00:31<01:32,  8.80it/s] 24%|██▍       | 255/1070 [00:31<01:32,  8.79it/s] 24%|██▍       | 256/1070 [00:31<01:31,  8.88it/s] 24%|██▍       | 257/1070 [00:31<01:31,  8.86it/s] 24%|██▍       | 258/1070 [00:31<01:31,  8.84it/s] 24%|██▍       | 259/1070 [00:31<01:32,  8.81it/s] 24%|██▍       | 260/1070 [00:31<01:31,  8.82it/s] 24%|██▍       | 261/1070 [00:31<01:31,  8.83it/s] 24%|██▍       | 262/1070 [00:32<01:31,  8.83it/s] 25%|██▍       | 263/1070 [00:32<01:30,  8.90it/s] 25%|██▍       | 264/1070 [00:32<01:31,  8.83it/s] 25%|██▍       | 265/1070 [00:32<01:30,  8.88it/s] 25%|██▍       | 266/1070 [00:32<01:30,  8.87it/s] 25%|██▍       | 267/1070 [00:32<01:29,  8.93it/s] 25%|██▌       | 268/1070 [00:32<01:30,  8.87it/s] 25%|██▌       | 269/1070 [00:32<01:30,  8.87it/s] 25%|██▌       | 270/1070 [00:33<01:29,  8.91it/s] 25%|██▌       | 271/1070 [00:33<01:29,  8.89it/s] 25%|██▌       | 272/1070 [00:33<01:29,  8.90it/s] 26%|██▌       | 273/1070 [00:33<01:27,  9.12it/s] 26%|██▌       | 274/1070 [00:33<01:28,  8.97it/s] 26%|██▌       | 275/1070 [00:33<01:29,  8.90it/s] 26%|██▌       | 276/1070 [00:33<01:29,  8.90it/s] 26%|██▌       | 277/1070 [00:33<01:28,  9.00it/s] 26%|██▌       | 278/1070 [00:33<01:28,  8.97it/s] 26%|██▌       | 279/1070 [00:34<01:28,  8.96it/s] 26%|██▌       | 280/1070 [00:34<01:27,  9.05it/s] 26%|██▋       | 281/1070 [00:34<01:27,  8.97it/s] 26%|██▋       | 282/1070 [00:34<01:28,  8.91it/s] 26%|██▋       | 283/1070 [00:34<01:28,  8.85it/s] 27%|██▋       | 284/1070 [00:34<01:28,  8.90it/s] 27%|██▋       | 285/1070 [00:34<01:28,  8.88it/s] 27%|██▋       | 286/1070 [00:34<01:28,  8.85it/s] 27%|██▋       | 287/1070 [00:34<01:28,  8.86it/s] 27%|██▋       | 288/1070 [00:35<01:28,  8.83it/s] 27%|██▋       | 289/1070 [00:35<01:27,  8.89it/s] 27%|██▋       | 290/1070 [00:35<01:26,  8.99it/s] 27%|██▋       | 291/1070 [00:35<01:28,  8.83it/s] 27%|██▋       | 292/1070 [00:35<01:28,  8.82it/s] 27%|██▋       | 293/1070 [00:35<01:28,  8.80it/s] 27%|██▋       | 294/1070 [00:35<01:27,  8.90it/s] 28%|██▊       | 295/1070 [00:35<01:28,  8.79it/s] 28%|██▊       | 296/1070 [00:35<01:27,  8.85it/s] 28%|██▊       | 297/1070 [00:36<01:27,  8.86it/s] 28%|██▊       | 298/1070 [00:36<01:26,  8.88it/s] 28%|██▊       | 299/1070 [00:36<01:26,  8.87it/s] 28%|██▊       | 300/1070 [00:36<01:25,  9.05it/s] 28%|██▊       | 301/1070 [00:36<01:25,  8.96it/s] 28%|██▊       | 302/1070 [00:36<01:26,  8.88it/s] 28%|██▊       | 303/1070 [00:36<01:26,  8.90it/s] 28%|██▊       | 304/1070 [00:36<01:25,  8.94it/s] 29%|██▊       | 305/1070 [00:36<01:25,  8.92it/s] 29%|██▊       | 306/1070 [00:37<01:26,  8.86it/s] 29%|██▊       | 307/1070 [00:37<01:25,  8.87it/s] 29%|██▉       | 308/1070 [00:37<01:25,  8.86it/s] 29%|██▉       | 309/1070 [00:37<01:25,  8.87it/s] 29%|██▉       | 310/1070 [00:37<01:24,  9.00it/s] 29%|██▉       | 311/1070 [00:37<01:24,  8.97it/s] 29%|██▉       | 312/1070 [00:37<01:25,  8.88it/s] 29%|██▉       | 313/1070 [00:37<01:25,  8.84it/s] 29%|██▉       | 314/1070 [00:37<01:25,  8.87it/s] 29%|██▉       | 315/1070 [00:38<01:25,  8.87it/s] 30%|██▉       | 316/1070 [00:38<01:25,  8.84it/s] 30%|██▉       | 317/1070 [00:38<01:24,  8.94it/s] 30%|██▉       | 318/1070 [00:38<01:24,  8.91it/s] 30%|██▉       | 319/1070 [00:38<01:24,  8.93it/s] 30%|██▉       | 320/1070 [00:38<01:23,  9.02it/s] 30%|███       | 321/1070 [00:38<01:23,  8.94it/s] 30%|███       | 322/1070 [00:38<01:24,  8.83it/s] 30%|███       | 323/1070 [00:38<01:24,  8.88it/s] 30%|███       | 324/1070 [00:39<01:24,  8.84it/s] 30%|███       | 325/1070 [00:39<01:23,  8.90it/s] 30%|███       | 326/1070 [00:39<01:24,  8.78it/s] 31%|███       | 327/1070 [00:39<01:24,  8.84it/s] 31%|███       | 328/1070 [00:39<01:24,  8.82it/s] 31%|███       | 329/1070 [00:39<01:23,  8.88it/s] 31%|███       | 330/1070 [00:39<01:23,  8.89it/s] 31%|███       | 331/1070 [00:39<01:22,  8.91it/s] 31%|███       | 332/1070 [00:39<01:23,  8.87it/s] 31%|███       | 333/1070 [00:40<01:23,  8.81it/s] 31%|███       | 334/1070 [00:40<01:23,  8.79it/s] 31%|███▏      | 335/1070 [00:40<01:23,  8.83it/s] 31%|███▏      | 336/1070 [00:40<01:23,  8.83it/s] 31%|███▏      | 337/1070 [00:40<01:21,  8.95it/s] 32%|███▏      | 338/1070 [00:40<01:22,  8.91it/s] 32%|███▏      | 339/1070 [00:40<01:22,  8.81it/s] 32%|███▏      | 340/1070 [00:40<01:22,  8.82it/s] 32%|███▏      | 341/1070 [00:40<01:22,  8.87it/s] 32%|███▏      | 342/1070 [00:41<01:22,  8.80it/s] 32%|███▏      | 343/1070 [00:41<01:22,  8.82it/s] 32%|███▏      | 344/1070 [00:41<01:22,  8.81it/s] 32%|███▏      | 345/1070 [00:41<01:21,  8.85it/s] 32%|███▏      | 346/1070 [00:41<01:21,  8.84it/s] 32%|███▏      | 347/1070 [00:41<01:20,  8.96it/s] 33%|███▎      | 348/1070 [00:41<01:21,  8.83it/s] 33%|███▎      | 349/1070 [00:41<01:21,  8.81it/s] 33%|███▎      | 350/1070 [00:42<01:22,  8.74it/s] 33%|███▎      | 351/1070 [00:42<01:22,  8.75it/s] 33%|███▎      | 352/1070 [00:42<01:21,  8.83it/s] 33%|███▎      | 353/1070 [00:42<01:21,  8.79it/s] 33%|███▎      | 354/1070 [00:42<01:20,  8.90it/s] 33%|███▎      | 355/1070 [00:42<01:21,  8.78it/s] 33%|███▎      | 356/1070 [00:42<01:21,  8.77it/s] 33%|███▎      | 357/1070 [00:42<01:20,  8.82it/s] 33%|███▎      | 358/1070 [00:42<01:20,  8.86it/s] 34%|███▎      | 359/1070 [00:43<01:21,  8.76it/s] 34%|███▎      | 360/1070 [00:43<01:20,  8.77it/s] 34%|███▎      | 361/1070 [00:43<01:20,  8.85it/s] 34%|███▍      | 362/1070 [00:43<01:20,  8.78it/s] 34%|███▍      | 363/1070 [00:43<01:20,  8.81it/s] 34%|███▍      | 364/1070 [00:43<01:19,  8.88it/s] 34%|███▍      | 365/1070 [00:43<01:19,  8.85it/s] 34%|███▍      | 366/1070 [00:43<01:19,  8.83it/s] 34%|███▍      | 367/1070 [00:43<01:19,  8.84it/s] 34%|███▍      | 368/1070 [00:44<01:20,  8.77it/s] 34%|███▍      | 369/1070 [00:44<01:19,  8.81it/s] 35%|███▍      | 370/1070 [00:44<01:19,  8.78it/s] 35%|███▍      | 371/1070 [00:44<01:19,  8.84it/s] 35%|███▍      | 372/1070 [00:44<01:19,  8.79it/s] 35%|███▍      | 373/1070 [00:44<01:20,  8.71it/s] 35%|███▍      | 374/1070 [00:44<01:19,  8.77it/s] 35%|███▌      | 375/1070 [00:44<01:18,  8.82it/s] 35%|███▌      | 376/1070 [00:44<01:18,  8.82it/s] 35%|███▌      | 377/1070 [00:45<01:19,  8.76it/s] 35%|███▌      | 378/1070 [00:45<01:18,  8.84it/s] 35%|███▌      | 379/1070 [00:45<01:18,  8.82it/s] 36%|███▌      | 380/1070 [00:45<01:18,  8.80it/s] 36%|███▌      | 381/1070 [00:45<01:17,  8.88it/s] 36%|███▌      | 382/1070 [00:45<01:18,  8.80it/s] 36%|███▌      | 383/1070 [00:45<01:18,  8.81it/s] 36%|███▌      | 384/1070 [00:45<01:18,  8.71it/s] 36%|███▌      | 385/1070 [00:45<01:19,  8.66it/s] 36%|███▌      | 386/1070 [00:46<01:18,  8.71it/s] 36%|███▌      | 387/1070 [00:46<01:18,  8.74it/s] 36%|███▋      | 388/1070 [00:46<01:17,  8.75it/s] 36%|███▋      | 389/1070 [00:46<01:17,  8.75it/s] 36%|███▋      | 390/1070 [00:46<01:17,  8.76it/s] 37%|███▋      | 391/1070 [00:46<01:17,  8.71it/s] 37%|███▋      | 392/1070 [00:46<01:17,  8.78it/s] 37%|███▋      | 393/1070 [00:46<01:17,  8.76it/s] 37%|███▋      | 394/1070 [00:47<01:17,  8.74it/s] 37%|███▋      | 395/1070 [00:47<01:16,  8.82it/s] 37%|███▋      | 396/1070 [00:47<01:16,  8.81it/s] 37%|███▋      | 397/1070 [00:47<01:16,  8.84it/s] 37%|███▋      | 398/1070 [00:47<01:16,  8.84it/s] 37%|███▋      | 399/1070 [00:47<01:16,  8.75it/s] 37%|███▋      | 400/1070 [00:47<01:16,  8.75it/s] 37%|███▋      | 401/1070 [00:47<01:17,  8.68it/s] 38%|███▊      | 402/1070 [00:47<01:16,  8.69it/s] 38%|███▊      | 403/1070 [00:48<01:16,  8.76it/s] 38%|███▊      | 404/1070 [00:48<01:15,  8.79it/s] 38%|███▊      | 405/1070 [00:48<01:15,  8.83it/s] 38%|███▊      | 406/1070 [00:48<01:14,  8.93it/s] 38%|███▊      | 407/1070 [00:48<01:14,  8.92it/s] 38%|███▊      | 408/1070 [00:48<01:14,  8.94it/s] 38%|███▊      | 409/1070 [00:48<01:13,  9.00it/s] 38%|███▊      | 410/1070 [00:48<01:14,  8.90it/s] 38%|███▊      | 411/1070 [00:48<01:13,  8.91it/s] 39%|███▊      | 412/1070 [00:49<01:14,  8.86it/s] 39%|███▊      | 413/1070 [00:49<01:13,  8.90it/s] 39%|███▊      | 414/1070 [00:49<01:13,  8.94it/s] 39%|███▉      | 415/1070 [00:49<01:12,  9.00it/s] 39%|███▉      | 416/1070 [00:49<01:13,  8.95it/s] 39%|███▉      | 417/1070 [00:49<01:13,  8.90it/s] 39%|███▉      | 418/1070 [00:49<01:13,  8.92it/s] 39%|███▉      | 419/1070 [00:49<01:13,  8.89it/s] 39%|███▉      | 420/1070 [00:49<01:13,  8.87it/s] 39%|███▉      | 421/1070 [00:50<01:13,  8.89it/s] 39%|███▉      | 422/1070 [00:50<01:13,  8.81it/s] 40%|███▉      | 423/1070 [00:50<01:13,  8.83it/s] 40%|███▉      | 424/1070 [00:50<01:13,  8.81it/s] 40%|███▉      | 425/1070 [00:50<01:11,  9.01it/s] 40%|███▉      | 426/1070 [00:50<01:11,  8.97it/s] 40%|███▉      | 427/1070 [00:50<01:12,  8.88it/s]                                                   40%|████      | 428/1070 [00:50<01:12,  8.88it/s][INFO|trainer.py:755] 2023-11-15 19:50:01,110 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:50:01,113 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:50:01,113 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:50:01,113 >>   Batch size = 8
{'eval_loss': 0.32216885685920715, 'eval_accuracy': 0.8973684210526316, 'eval_micro_f1': 0.8973684210526317, 'eval_macro_f1': 0.8950567277093869, 'eval_runtime': 1.3785, 'eval_samples_per_second': 551.326, 'eval_steps_per_second': 68.916, 'epoch': 1.0}
{'loss': 0.2513, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 82.67it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 69.58it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 69.16it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 71.22it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 69.05it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 68.51it/s][A
 60%|██████    | 57/95 [00:00<00:00, 70.14it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 69.64it/s][A
 76%|███████▌  | 72/95 [00:01<00:00, 69.26it/s][A
 83%|████████▎ | 79/95 [00:01<00:00, 68.72it/s][A
 92%|█████████▏| 87/95 [00:01<00:00, 70.05it/s][A
100%|██████████| 95/95 [00:01<00:00, 69.48it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:52<01:12,  8.88it/s]
100%|██████████| 95/95 [00:01<00:00, 69.48it/s][A
                                               [A 40%|████      | 429/1070 [00:52<04:39,  2.30it/s] 40%|████      | 430/1070 [00:52<03:47,  2.81it/s] 40%|████      | 431/1070 [00:52<03:06,  3.42it/s] 40%|████      | 432/1070 [00:52<02:35,  4.11it/s] 40%|████      | 433/1070 [00:52<02:11,  4.83it/s] 41%|████      | 434/1070 [00:52<01:54,  5.55it/s] 41%|████      | 435/1070 [00:53<01:42,  6.22it/s] 41%|████      | 436/1070 [00:53<01:32,  6.85it/s] 41%|████      | 437/1070 [00:53<01:26,  7.31it/s] 41%|████      | 438/1070 [00:53<01:22,  7.68it/s] 41%|████      | 439/1070 [00:53<01:18,  8.00it/s] 41%|████      | 440/1070 [00:53<01:16,  8.26it/s] 41%|████      | 441/1070 [00:53<01:14,  8.47it/s] 41%|████▏     | 442/1070 [00:53<01:13,  8.50it/s] 41%|████▏     | 443/1070 [00:53<01:12,  8.66it/s] 41%|████▏     | 444/1070 [00:54<01:11,  8.74it/s] 42%|████▏     | 445/1070 [00:54<01:11,  8.80it/s] 42%|████▏     | 446/1070 [00:54<01:10,  8.89it/s] 42%|████▏     | 447/1070 [00:54<01:10,  8.87it/s] 42%|████▏     | 448/1070 [00:54<01:10,  8.85it/s] 42%|████▏     | 449/1070 [00:54<01:10,  8.83it/s] 42%|████▏     | 450/1070 [00:54<01:10,  8.77it/s] 42%|████▏     | 451/1070 [00:54<01:09,  8.84it/s] 42%|████▏     | 452/1070 [00:54<01:09,  8.85it/s] 42%|████▏     | 453/1070 [00:55<01:09,  8.91it/s] 42%|████▏     | 454/1070 [00:55<01:09,  8.88it/s] 43%|████▎     | 455/1070 [00:55<01:09,  8.85it/s] 43%|████▎     | 456/1070 [00:55<01:09,  8.87it/s] 43%|████▎     | 457/1070 [00:55<01:09,  8.79it/s] 43%|████▎     | 458/1070 [00:55<01:09,  8.82it/s] 43%|████▎     | 459/1070 [00:55<01:09,  8.85it/s] 43%|████▎     | 460/1070 [00:55<01:08,  8.92it/s] 43%|████▎     | 461/1070 [00:55<01:08,  8.89it/s] 43%|████▎     | 462/1070 [00:56<01:08,  8.92it/s] 43%|████▎     | 463/1070 [00:56<01:07,  9.05it/s] 43%|████▎     | 464/1070 [00:56<01:07,  8.96it/s] 43%|████▎     | 465/1070 [00:56<01:07,  8.90it/s] 44%|████▎     | 466/1070 [00:56<01:07,  8.90it/s] 44%|████▎     | 467/1070 [00:56<01:08,  8.86it/s] 44%|████▎     | 468/1070 [00:56<01:07,  8.92it/s] 44%|████▍     | 469/1070 [00:56<01:08,  8.78it/s] 44%|████▍     | 470/1070 [00:56<01:07,  8.94it/s] 44%|████▍     | 471/1070 [00:57<01:07,  8.86it/s] 44%|████▍     | 472/1070 [00:57<01:07,  8.86it/s] 44%|████▍     | 473/1070 [00:57<01:07,  8.90it/s] 44%|████▍     | 474/1070 [00:57<01:07,  8.89it/s] 44%|████▍     | 475/1070 [00:57<01:07,  8.82it/s] 44%|████▍     | 476/1070 [00:57<01:07,  8.85it/s] 45%|████▍     | 477/1070 [00:57<01:07,  8.78it/s] 45%|████▍     | 478/1070 [00:57<01:06,  8.84it/s] 45%|████▍     | 479/1070 [00:57<01:07,  8.80it/s] 45%|████▍     | 480/1070 [00:58<01:05,  8.98it/s] 45%|████▍     | 481/1070 [00:58<01:07,  8.78it/s] 45%|████▌     | 482/1070 [00:58<01:06,  8.85it/s] 45%|████▌     | 483/1070 [00:58<01:06,  8.82it/s] 45%|████▌     | 484/1070 [00:58<01:06,  8.87it/s] 45%|████▌     | 485/1070 [00:58<01:06,  8.83it/s] 45%|████▌     | 486/1070 [00:58<01:06,  8.81it/s] 46%|████▌     | 487/1070 [00:58<01:05,  8.84it/s] 46%|████▌     | 488/1070 [00:59<01:05,  8.83it/s] 46%|████▌     | 489/1070 [00:59<01:05,  8.87it/s] 46%|████▌     | 490/1070 [00:59<01:05,  8.90it/s] 46%|████▌     | 491/1070 [00:59<01:05,  8.86it/s] 46%|████▌     | 492/1070 [00:59<01:05,  8.77it/s] 46%|████▌     | 493/1070 [00:59<01:05,  8.83it/s] 46%|████▌     | 494/1070 [00:59<01:04,  8.88it/s] 46%|████▋     | 495/1070 [00:59<01:04,  8.86it/s] 46%|████▋     | 496/1070 [00:59<01:04,  8.87it/s] 46%|████▋     | 497/1070 [01:00<01:04,  8.90it/s] 47%|████▋     | 498/1070 [01:00<01:04,  8.81it/s] 47%|████▋     | 499/1070 [01:00<01:04,  8.80it/s] 47%|████▋     | 500/1070 [01:00<01:03,  8.91it/s] 47%|████▋     | 501/1070 [01:00<01:03,  8.91it/s] 47%|████▋     | 502/1070 [01:00<01:04,  8.80it/s] 47%|████▋     | 503/1070 [01:00<01:04,  8.85it/s] 47%|████▋     | 504/1070 [01:00<01:04,  8.79it/s] 47%|████▋     | 505/1070 [01:00<01:03,  8.85it/s] 47%|████▋     | 506/1070 [01:01<01:03,  8.87it/s] 47%|████▋     | 507/1070 [01:01<01:02,  8.96it/s] 47%|████▋     | 508/1070 [01:01<01:02,  8.93it/s] 48%|████▊     | 509/1070 [01:01<01:02,  8.92it/s] 48%|████▊     | 510/1070 [01:01<01:02,  8.92it/s] 48%|████▊     | 511/1070 [01:01<01:02,  8.96it/s] 48%|████▊     | 512/1070 [01:01<01:02,  8.92it/s] 48%|████▊     | 513/1070 [01:01<01:02,  8.90it/s] 48%|████▊     | 514/1070 [01:01<01:02,  8.94it/s] 48%|████▊     | 515/1070 [01:02<01:01,  8.99it/s] 48%|████▊     | 516/1070 [01:02<01:01,  9.02it/s] 48%|████▊     | 517/1070 [01:02<01:01,  9.04it/s] 48%|████▊     | 518/1070 [01:02<01:02,  8.90it/s] 49%|████▊     | 519/1070 [01:02<01:02,  8.84it/s] 49%|████▊     | 520/1070 [01:02<01:02,  8.84it/s] 49%|████▊     | 521/1070 [01:02<01:01,  8.89it/s] 49%|████▉     | 522/1070 [01:02<01:01,  8.93it/s] 49%|████▉     | 523/1070 [01:02<01:01,  8.88it/s] 49%|████▉     | 524/1070 [01:03<01:00,  8.96it/s] 49%|████▉     | 525/1070 [01:03<01:01,  8.88it/s] 49%|████▉     | 526/1070 [01:03<01:01,  8.90it/s] 49%|████▉     | 527/1070 [01:03<01:00,  8.97it/s] 49%|████▉     | 528/1070 [01:03<01:00,  8.99it/s] 49%|████▉     | 529/1070 [01:03<01:00,  8.90it/s] 50%|████▉     | 530/1070 [01:03<01:00,  8.85it/s] 50%|████▉     | 531/1070 [01:03<01:00,  8.88it/s] 50%|████▉     | 532/1070 [01:03<01:00,  8.88it/s] 50%|████▉     | 533/1070 [01:04<01:00,  8.84it/s] 50%|████▉     | 534/1070 [01:04<00:59,  8.95it/s] 50%|█████     | 535/1070 [01:04<01:00,  8.86it/s] 50%|█████     | 536/1070 [01:04<01:00,  8.84it/s] 50%|█████     | 537/1070 [01:04<01:00,  8.84it/s] 50%|█████     | 538/1070 [01:04<00:59,  8.88it/s] 50%|█████     | 539/1070 [01:04<01:00,  8.79it/s] 50%|█████     | 540/1070 [01:04<01:00,  8.80it/s] 51%|█████     | 541/1070 [01:04<00:59,  8.82it/s] 51%|█████     | 542/1070 [01:05<00:59,  8.86it/s] 51%|█████     | 543/1070 [01:05<00:59,  8.91it/s] 51%|█████     | 544/1070 [01:05<00:58,  9.00it/s] 51%|█████     | 545/1070 [01:05<00:59,  8.89it/s] 51%|█████     | 546/1070 [01:05<00:59,  8.81it/s] 51%|█████     | 547/1070 [01:05<00:59,  8.80it/s] 51%|█████     | 548/1070 [01:05<00:58,  8.85it/s] 51%|█████▏    | 549/1070 [01:05<00:59,  8.82it/s] 51%|█████▏    | 550/1070 [01:05<00:59,  8.77it/s] 51%|█████▏    | 551/1070 [01:06<00:58,  8.86it/s] 52%|█████▏    | 552/1070 [01:06<00:58,  8.84it/s] 52%|█████▏    | 553/1070 [01:06<00:58,  8.82it/s] 52%|█████▏    | 554/1070 [01:06<00:57,  8.93it/s] 52%|█████▏    | 555/1070 [01:06<00:57,  8.93it/s] 52%|█████▏    | 556/1070 [01:06<00:58,  8.77it/s] 52%|█████▏    | 557/1070 [01:06<00:57,  8.85it/s] 52%|█████▏    | 558/1070 [01:06<00:58,  8.82it/s] 52%|█████▏    | 559/1070 [01:07<00:57,  8.89it/s] 52%|█████▏    | 560/1070 [01:07<00:57,  8.84it/s] 52%|█████▏    | 561/1070 [01:07<00:57,  8.90it/s] 53%|█████▎    | 562/1070 [01:07<00:57,  8.88it/s] 53%|█████▎    | 563/1070 [01:07<00:56,  8.91it/s] 53%|█████▎    | 564/1070 [01:07<00:56,  8.91it/s] 53%|█████▎    | 565/1070 [01:07<00:56,  8.96it/s] 53%|█████▎    | 566/1070 [01:07<00:56,  8.85it/s] 53%|█████▎    | 567/1070 [01:07<00:56,  8.87it/s] 53%|█████▎    | 568/1070 [01:08<00:56,  8.87it/s] 53%|█████▎    | 569/1070 [01:08<00:56,  8.89it/s] 53%|█████▎    | 570/1070 [01:08<00:55,  8.94it/s] 53%|█████▎    | 571/1070 [01:08<00:55,  9.06it/s] 53%|█████▎    | 572/1070 [01:08<00:55,  8.97it/s] 54%|█████▎    | 573/1070 [01:08<00:55,  8.89it/s] 54%|█████▎    | 574/1070 [01:08<00:55,  8.92it/s] 54%|█████▎    | 575/1070 [01:08<00:55,  8.97it/s] 54%|█████▍    | 576/1070 [01:08<00:55,  8.85it/s] 54%|█████▍    | 577/1070 [01:09<00:56,  8.80it/s] 54%|█████▍    | 578/1070 [01:09<00:55,  8.92it/s] 54%|█████▍    | 579/1070 [01:09<00:55,  8.86it/s] 54%|█████▍    | 580/1070 [01:09<00:55,  8.90it/s] 54%|█████▍    | 581/1070 [01:09<00:54,  8.93it/s] 54%|█████▍    | 582/1070 [01:09<00:55,  8.85it/s] 54%|█████▍    | 583/1070 [01:09<00:55,  8.82it/s] 55%|█████▍    | 584/1070 [01:09<00:55,  8.80it/s] 55%|█████▍    | 585/1070 [01:09<00:54,  8.82it/s] 55%|█████▍    | 586/1070 [01:10<00:54,  8.83it/s] 55%|█████▍    | 587/1070 [01:10<00:54,  8.81it/s] 55%|█████▍    | 588/1070 [01:10<00:54,  8.87it/s] 55%|█████▌    | 589/1070 [01:10<00:54,  8.86it/s] 55%|█████▌    | 590/1070 [01:10<00:54,  8.81it/s] 55%|█████▌    | 591/1070 [01:10<00:54,  8.87it/s] 55%|█████▌    | 592/1070 [01:10<00:53,  8.89it/s] 55%|█████▌    | 593/1070 [01:10<00:54,  8.83it/s] 56%|█████▌    | 594/1070 [01:10<00:54,  8.81it/s] 56%|█████▌    | 595/1070 [01:11<00:53,  8.82it/s] 56%|█████▌    | 596/1070 [01:11<00:53,  8.82it/s] 56%|█████▌    | 597/1070 [01:11<00:53,  8.79it/s] 56%|█████▌    | 598/1070 [01:11<00:53,  8.88it/s] 56%|█████▌    | 599/1070 [01:11<00:53,  8.85it/s] 56%|█████▌    | 600/1070 [01:11<00:53,  8.84it/s] 56%|█████▌    | 601/1070 [01:11<00:53,  8.80it/s] 56%|█████▋    | 602/1070 [01:11<00:53,  8.81it/s] 56%|█████▋    | 603/1070 [01:11<00:52,  8.82it/s] 56%|█████▋    | 604/1070 [01:12<00:53,  8.78it/s] 57%|█████▋    | 605/1070 [01:12<00:52,  8.83it/s] 57%|█████▋    | 606/1070 [01:12<00:52,  8.90it/s] 57%|█████▋    | 607/1070 [01:12<00:52,  8.88it/s] 57%|█████▋    | 608/1070 [01:12<00:51,  8.93it/s] 57%|█████▋    | 609/1070 [01:12<00:51,  8.93it/s] 57%|█████▋    | 610/1070 [01:12<00:52,  8.77it/s] 57%|█████▋    | 611/1070 [01:12<00:52,  8.79it/s] 57%|█████▋    | 612/1070 [01:12<00:52,  8.77it/s] 57%|█████▋    | 613/1070 [01:13<00:51,  8.80it/s] 57%|█████▋    | 614/1070 [01:13<00:51,  8.78it/s] 57%|█████▋    | 615/1070 [01:13<00:50,  8.95it/s] 58%|█████▊    | 616/1070 [01:13<00:51,  8.85it/s] 58%|█████▊    | 617/1070 [01:13<00:51,  8.80it/s] 58%|█████▊    | 618/1070 [01:13<00:51,  8.75it/s] 58%|█████▊    | 619/1070 [01:13<00:51,  8.77it/s] 58%|█████▊    | 620/1070 [01:13<00:50,  8.84it/s] 58%|█████▊    | 621/1070 [01:14<00:51,  8.75it/s] 58%|█████▊    | 622/1070 [01:14<00:50,  8.84it/s] 58%|█████▊    | 623/1070 [01:14<00:50,  8.83it/s] 58%|█████▊    | 624/1070 [01:14<00:50,  8.80it/s] 58%|█████▊    | 625/1070 [01:14<00:50,  8.81it/s] 59%|█████▊    | 626/1070 [01:14<00:50,  8.86it/s] 59%|█████▊    | 627/1070 [01:14<00:50,  8.79it/s] 59%|█████▊    | 628/1070 [01:14<00:50,  8.77it/s] 59%|█████▉    | 629/1070 [01:14<00:50,  8.81it/s] 59%|█████▉    | 630/1070 [01:15<00:49,  8.81it/s] 59%|█████▉    | 631/1070 [01:15<00:49,  8.82it/s] 59%|█████▉    | 632/1070 [01:15<00:49,  8.89it/s] 59%|█████▉    | 633/1070 [01:15<00:49,  8.79it/s] 59%|█████▉    | 634/1070 [01:15<00:49,  8.78it/s] 59%|█████▉    | 635/1070 [01:15<00:49,  8.72it/s] 59%|█████▉    | 636/1070 [01:15<00:49,  8.68it/s] 60%|█████▉    | 637/1070 [01:15<00:49,  8.80it/s] 60%|█████▉    | 638/1070 [01:15<00:49,  8.75it/s] 60%|█████▉    | 640/1070 [01:16<00:45,  9.46it/s] 60%|██████    | 642/1070 [01:16<00:41, 10.42it/s]                                                   60%|██████    | 642/1070 [01:16<00:41, 10.42it/s][INFO|trainer.py:755] 2023-11-15 19:50:26,591 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:50:26,593 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:50:26,593 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:50:26,593 >>   Batch size = 8
{'eval_loss': 0.2979486882686615, 'eval_accuracy': 0.9092105263157895, 'eval_micro_f1': 0.9092105263157895, 'eval_macro_f1': 0.9066246220202558, 'eval_runtime': 1.4129, 'eval_samples_per_second': 537.882, 'eval_steps_per_second': 67.235, 'epoch': 2.0}
{'loss': 0.1614, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 120.01it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 113.77it/s][A
 40%|████      | 38/95 [00:00<00:00, 111.85it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 110.90it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 110.36it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 109.83it/s][A
 89%|████████▉ | 85/95 [00:00<00:00, 108.75it/s][A                                                  
                                                [A 60%|██████    | 642/1070 [01:17<00:41, 10.42it/s]
100%|██████████| 95/95 [00:00<00:00, 108.75it/s][A
                                                [A 60%|██████    | 644/1070 [01:17<01:51,  3.83it/s] 60%|██████    | 646/1070 [01:17<01:26,  4.92it/s] 61%|██████    | 648/1070 [01:17<01:10,  6.01it/s] 61%|██████    | 650/1070 [01:17<00:59,  7.05it/s] 61%|██████    | 652/1070 [01:18<00:52,  7.96it/s] 61%|██████    | 654/1070 [01:18<00:47,  8.71it/s] 61%|██████▏   | 656/1070 [01:18<00:44,  9.32it/s] 61%|██████▏   | 658/1070 [01:18<00:42,  9.79it/s] 62%|██████▏   | 660/1070 [01:18<00:40, 10.15it/s] 62%|██████▏   | 662/1070 [01:19<00:39, 10.42it/s] 62%|██████▏   | 664/1070 [01:19<00:38, 10.60it/s] 62%|██████▏   | 666/1070 [01:19<00:37, 10.66it/s] 62%|██████▏   | 668/1070 [01:19<00:37, 10.79it/s] 63%|██████▎   | 670/1070 [01:19<00:36, 10.88it/s] 63%|██████▎   | 672/1070 [01:19<00:36, 10.95it/s] 63%|██████▎   | 674/1070 [01:20<00:36, 10.97it/s] 63%|██████▎   | 676/1070 [01:20<00:35, 11.00it/s] 63%|██████▎   | 678/1070 [01:20<00:35, 11.02it/s] 64%|██████▎   | 680/1070 [01:20<00:35, 11.03it/s] 64%|██████▎   | 682/1070 [01:20<00:35, 11.03it/s] 64%|██████▍   | 684/1070 [01:21<00:34, 11.05it/s] 64%|██████▍   | 686/1070 [01:21<00:34, 11.06it/s] 64%|██████▍   | 688/1070 [01:21<00:34, 11.06it/s] 64%|██████▍   | 690/1070 [01:21<00:34, 11.06it/s] 65%|██████▍   | 692/1070 [01:21<00:34, 11.06it/s] 65%|██████▍   | 694/1070 [01:21<00:33, 11.07it/s] 65%|██████▌   | 696/1070 [01:22<00:33, 11.07it/s] 65%|██████▌   | 698/1070 [01:22<00:33, 11.07it/s] 65%|██████▌   | 700/1070 [01:22<00:33, 11.07it/s] 66%|██████▌   | 702/1070 [01:22<00:33, 11.07it/s] 66%|██████▌   | 704/1070 [01:22<00:33, 11.07it/s] 66%|██████▌   | 706/1070 [01:23<00:32, 11.07it/s] 66%|██████▌   | 708/1070 [01:23<00:32, 11.06it/s] 66%|██████▋   | 710/1070 [01:23<00:32, 11.06it/s] 67%|██████▋   | 712/1070 [01:23<00:32, 11.06it/s] 67%|██████▋   | 714/1070 [01:23<00:32, 11.06it/s] 67%|██████▋   | 716/1070 [01:23<00:32, 11.06it/s] 67%|██████▋   | 718/1070 [01:24<00:31, 11.05it/s] 67%|██████▋   | 720/1070 [01:24<00:31, 11.06it/s] 67%|██████▋   | 722/1070 [01:24<00:31, 11.07it/s] 68%|██████▊   | 724/1070 [01:24<00:31, 11.07it/s] 68%|██████▊   | 726/1070 [01:24<00:31, 11.06it/s] 68%|██████▊   | 728/1070 [01:25<00:30, 11.05it/s] 68%|██████▊   | 730/1070 [01:25<00:30, 11.06it/s] 68%|██████▊   | 732/1070 [01:25<00:30, 11.06it/s] 69%|██████▊   | 734/1070 [01:25<00:30, 11.05it/s] 69%|██████▉   | 736/1070 [01:25<00:30, 11.05it/s] 69%|██████▉   | 738/1070 [01:25<00:30, 11.05it/s] 69%|██████▉   | 740/1070 [01:26<00:29, 11.05it/s] 69%|██████▉   | 742/1070 [01:26<00:29, 11.01it/s] 70%|██████▉   | 744/1070 [01:26<00:29, 10.98it/s] 70%|██████▉   | 746/1070 [01:26<00:29, 10.95it/s] 70%|██████▉   | 748/1070 [01:26<00:29, 10.92it/s] 70%|███████   | 750/1070 [01:27<00:29, 10.96it/s] 70%|███████   | 752/1070 [01:27<00:28, 10.98it/s] 70%|███████   | 754/1070 [01:27<00:28, 11.00it/s] 71%|███████   | 756/1070 [01:27<00:28, 11.01it/s] 71%|███████   | 758/1070 [01:27<00:28, 11.01it/s] 71%|███████   | 760/1070 [01:27<00:28, 11.02it/s] 71%|███████   | 762/1070 [01:28<00:27, 11.02it/s] 71%|███████▏  | 764/1070 [01:28<00:27, 10.98it/s] 72%|███████▏  | 766/1070 [01:28<00:27, 11.00it/s] 72%|███████▏  | 768/1070 [01:28<00:27, 11.01it/s] 72%|███████▏  | 770/1070 [01:28<00:27, 11.01it/s] 72%|███████▏  | 772/1070 [01:29<00:27, 11.00it/s] 72%|███████▏  | 774/1070 [01:29<00:26, 11.01it/s] 73%|███████▎  | 776/1070 [01:29<00:26, 11.01it/s] 73%|███████▎  | 778/1070 [01:29<00:26, 11.00it/s] 73%|███████▎  | 780/1070 [01:29<00:26, 11.01it/s] 73%|███████▎  | 782/1070 [01:29<00:26, 11.01it/s] 73%|███████▎  | 784/1070 [01:30<00:26, 11.00it/s] 73%|███████▎  | 786/1070 [01:30<00:25, 10.97it/s] 74%|███████▎  | 788/1070 [01:30<00:25, 10.98it/s] 74%|███████▍  | 790/1070 [01:30<00:25, 10.99it/s] 74%|███████▍  | 792/1070 [01:30<00:25, 10.97it/s] 74%|███████▍  | 794/1070 [01:31<00:25, 10.97it/s] 74%|███████▍  | 796/1070 [01:31<00:25, 10.96it/s] 75%|███████▍  | 798/1070 [01:31<00:24, 10.97it/s] 75%|███████▍  | 800/1070 [01:31<00:24, 11.00it/s] 75%|███████▍  | 802/1070 [01:31<00:24, 11.00it/s] 75%|███████▌  | 804/1070 [01:31<00:24, 10.98it/s] 75%|███████▌  | 806/1070 [01:32<00:24, 10.99it/s] 76%|███████▌  | 808/1070 [01:32<00:23, 10.97it/s] 76%|███████▌  | 810/1070 [01:32<00:23, 10.97it/s] 76%|███████▌  | 812/1070 [01:32<00:23, 10.97it/s] 76%|███████▌  | 814/1070 [01:32<00:23, 10.98it/s] 76%|███████▋  | 816/1070 [01:33<00:23, 10.97it/s] 76%|███████▋  | 818/1070 [01:33<00:22, 10.97it/s] 77%|███████▋  | 820/1070 [01:33<00:22, 10.98it/s] 77%|███████▋  | 822/1070 [01:33<00:22, 10.97it/s] 77%|███████▋  | 824/1070 [01:33<00:22, 10.99it/s] 77%|███████▋  | 826/1070 [01:33<00:22, 11.01it/s] 77%|███████▋  | 828/1070 [01:34<00:21, 11.00it/s] 78%|███████▊  | 830/1070 [01:34<00:21, 10.99it/s] 78%|███████▊  | 832/1070 [01:34<00:21, 11.00it/s] 78%|███████▊  | 834/1070 [01:34<00:21, 11.00it/s] 78%|███████▊  | 836/1070 [01:34<00:21, 11.01it/s] 78%|███████▊  | 838/1070 [01:35<00:21, 10.98it/s] 79%|███████▊  | 840/1070 [01:35<00:20, 11.00it/s] 79%|███████▊  | 842/1070 [01:35<00:20, 10.98it/s] 79%|███████▉  | 844/1070 [01:35<00:20, 11.00it/s] 79%|███████▉  | 846/1070 [01:35<00:20, 11.02it/s] 79%|███████▉  | 848/1070 [01:35<00:20, 11.03it/s] 79%|███████▉  | 850/1070 [01:36<00:19, 11.01it/s] 80%|███████▉  | 852/1070 [01:36<00:19, 11.00it/s] 80%|███████▉  | 854/1070 [01:36<00:19, 11.00it/s] 80%|████████  | 856/1070 [01:36<00:18, 11.41it/s]                                                   80%|████████  | 856/1070 [01:36<00:18, 11.41it/s][INFO|trainer.py:755] 2023-11-15 19:50:46,910 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:50:46,911 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:50:46,911 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:50:46,912 >>   Batch size = 8
{'eval_loss': 0.3496883511543274, 'eval_accuracy': 0.8921052631578947, 'eval_micro_f1': 0.8921052631578947, 'eval_macro_f1': 0.8896464646464647, 'eval_runtime': 0.9084, 'eval_samples_per_second': 836.594, 'eval_steps_per_second': 104.574, 'epoch': 3.0}
{'loss': 0.0983, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 13%|█▎        | 12/95 [00:00<00:00, 119.74it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 113.28it/s][A
 38%|███▊      | 36/95 [00:00<00:00, 111.14it/s][A
 51%|█████     | 48/95 [00:00<00:00, 109.94it/s][A
 63%|██████▎   | 60/95 [00:00<00:00, 108.68it/s][A
 75%|███████▍  | 71/95 [00:00<00:00, 107.84it/s][A
 86%|████████▋ | 82/95 [00:00<00:00, 107.27it/s][A
 98%|█████████▊| 93/95 [00:00<00:00, 106.63it/s][A                                                  
                                                [A 80%|████████  | 856/1070 [01:37<00:18, 11.41it/s]
100%|██████████| 95/95 [00:00<00:00, 106.63it/s][A
                                                [A 80%|████████  | 858/1070 [01:37<00:48,  4.37it/s] 80%|████████  | 860/1070 [01:37<00:39,  5.32it/s] 81%|████████  | 862/1070 [01:38<00:33,  6.30it/s] 81%|████████  | 864/1070 [01:38<00:28,  7.22it/s] 81%|████████  | 866/1070 [01:38<00:25,  8.04it/s] 81%|████████  | 868/1070 [01:38<00:23,  8.73it/s] 81%|████████▏ | 870/1070 [01:38<00:21,  9.29it/s] 81%|████████▏ | 872/1070 [01:39<00:20,  9.73it/s] 82%|████████▏ | 874/1070 [01:39<00:19, 10.06it/s] 82%|████████▏ | 876/1070 [01:39<00:18, 10.32it/s] 82%|████████▏ | 878/1070 [01:39<00:18, 10.52it/s] 82%|████████▏ | 880/1070 [01:39<00:17, 10.66it/s] 82%|████████▏ | 882/1070 [01:39<00:17, 10.76it/s] 83%|████████▎ | 884/1070 [01:40<00:17, 10.83it/s] 83%|████████▎ | 886/1070 [01:40<00:16, 10.88it/s] 83%|████████▎ | 888/1070 [01:40<00:16, 10.95it/s] 83%|████████▎ | 890/1070 [01:40<00:16, 10.96it/s] 83%|████████▎ | 892/1070 [01:40<00:16, 10.97it/s] 84%|████████▎ | 894/1070 [01:41<00:16, 10.97it/s] 84%|████████▎ | 896/1070 [01:41<00:15, 10.99it/s] 84%|████████▍ | 898/1070 [01:41<00:15, 11.00it/s] 84%|████████▍ | 900/1070 [01:41<00:15, 10.99it/s] 84%|████████▍ | 902/1070 [01:41<00:15, 11.00it/s] 84%|████████▍ | 904/1070 [01:41<00:15, 11.00it/s] 85%|████████▍ | 906/1070 [01:42<00:14, 11.01it/s] 85%|████████▍ | 908/1070 [01:42<00:14, 11.00it/s] 85%|████████▌ | 910/1070 [01:42<00:14, 11.01it/s] 85%|████████▌ | 912/1070 [01:42<00:14, 11.02it/s] 85%|████████▌ | 914/1070 [01:42<00:14, 11.01it/s] 86%|████████▌ | 916/1070 [01:43<00:14, 10.99it/s] 86%|████████▌ | 918/1070 [01:43<00:13, 10.99it/s] 86%|████████▌ | 920/1070 [01:43<00:13, 11.01it/s] 86%|████████▌ | 922/1070 [01:43<00:13, 10.99it/s] 86%|████████▋ | 924/1070 [01:43<00:13, 11.00it/s] 87%|████████▋ | 926/1070 [01:43<00:13, 11.00it/s] 87%|████████▋ | 928/1070 [01:44<00:12, 11.00it/s] 87%|████████▋ | 930/1070 [01:44<00:12, 11.00it/s] 87%|████████▋ | 932/1070 [01:44<00:12, 10.99it/s] 87%|████████▋ | 934/1070 [01:44<00:12, 10.99it/s] 87%|████████▋ | 936/1070 [01:44<00:12, 10.98it/s] 88%|████████▊ | 938/1070 [01:45<00:12, 10.96it/s] 88%|████████▊ | 940/1070 [01:45<00:11, 10.98it/s] 88%|████████▊ | 942/1070 [01:45<00:11, 10.97it/s] 88%|████████▊ | 944/1070 [01:45<00:11, 10.99it/s] 88%|████████▊ | 946/1070 [01:45<00:11, 10.96it/s] 89%|████████▊ | 948/1070 [01:45<00:11, 10.97it/s] 89%|████████▉ | 950/1070 [01:46<00:10, 10.97it/s] 89%|████████▉ | 952/1070 [01:46<00:10, 10.97it/s] 89%|████████▉ | 954/1070 [01:46<00:10, 10.95it/s] 89%|████████▉ | 956/1070 [01:46<00:10, 10.96it/s] 90%|████████▉ | 958/1070 [01:46<00:10, 10.96it/s] 90%|████████▉ | 960/1070 [01:47<00:10, 10.94it/s] 90%|████████▉ | 962/1070 [01:47<00:09, 10.94it/s] 90%|█████████ | 964/1070 [01:47<00:09, 10.96it/s] 90%|█████████ | 966/1070 [01:47<00:09, 10.97it/s] 90%|█████████ | 968/1070 [01:47<00:09, 10.95it/s] 91%|█████████ | 970/1070 [01:47<00:09, 10.96it/s] 91%|█████████ | 972/1070 [01:48<00:08, 10.96it/s] 91%|█████████ | 974/1070 [01:48<00:08, 10.95it/s] 91%|█████████ | 976/1070 [01:48<00:08, 10.94it/s] 91%|█████████▏| 978/1070 [01:48<00:08, 10.95it/s] 92%|█████████▏| 980/1070 [01:48<00:08, 10.95it/s] 92%|█████████▏| 982/1070 [01:49<00:08, 10.94it/s] 92%|█████████▏| 984/1070 [01:49<00:07, 10.95it/s] 92%|█████████▏| 986/1070 [01:49<00:07, 10.96it/s] 92%|█████████▏| 988/1070 [01:49<00:07, 10.96it/s] 93%|█████████▎| 990/1070 [01:49<00:07, 10.96it/s] 93%|█████████▎| 992/1070 [01:49<00:07, 10.96it/s] 93%|█████████▎| 994/1070 [01:50<00:06, 10.95it/s] 93%|█████████▎| 996/1070 [01:50<00:06, 10.96it/s] 93%|█████████▎| 998/1070 [01:50<00:06, 10.96it/s] 93%|█████████▎| 1000/1070 [01:50<00:06, 10.95it/s] 94%|█████████▎| 1002/1070 [01:50<00:06, 10.98it/s] 94%|█████████▍| 1004/1070 [01:51<00:06, 10.97it/s] 94%|█████████▍| 1006/1070 [01:51<00:05, 11.00it/s] 94%|█████████▍| 1008/1070 [01:51<00:05, 11.00it/s] 94%|█████████▍| 1010/1070 [01:51<00:05, 11.00it/s] 95%|█████████▍| 1012/1070 [01:51<00:05, 11.01it/s] 95%|█████████▍| 1014/1070 [01:51<00:05, 11.02it/s] 95%|█████████▍| 1016/1070 [01:52<00:04, 11.01it/s] 95%|█████████▌| 1018/1070 [01:52<00:04, 11.01it/s] 95%|█████████▌| 1020/1070 [01:52<00:04, 11.00it/s] 96%|█████████▌| 1022/1070 [01:52<00:04, 11.00it/s] 96%|█████████▌| 1024/1070 [01:52<00:04, 11.02it/s] 96%|█████████▌| 1026/1070 [01:53<00:03, 11.01it/s] 96%|█████████▌| 1028/1070 [01:53<00:03, 11.00it/s] 96%|█████████▋| 1030/1070 [01:53<00:03, 10.99it/s] 96%|█████████▋| 1032/1070 [01:53<00:03, 10.99it/s] 97%|█████████▋| 1034/1070 [01:53<00:03, 11.00it/s] 97%|█████████▋| 1036/1070 [01:53<00:03, 11.01it/s] 97%|█████████▋| 1038/1070 [01:54<00:02, 11.02it/s] 97%|█████████▋| 1040/1070 [01:54<00:02, 11.00it/s] 97%|█████████▋| 1042/1070 [01:54<00:02, 10.98it/s] 98%|█████████▊| 1044/1070 [01:54<00:02, 11.00it/s] 98%|█████████▊| 1046/1070 [01:54<00:02, 11.03it/s] 98%|█████████▊| 1048/1070 [01:55<00:01, 11.02it/s] 98%|█████████▊| 1050/1070 [01:55<00:01, 11.01it/s] 98%|█████████▊| 1052/1070 [01:55<00:01, 11.01it/s] 99%|█████████▊| 1054/1070 [01:55<00:01, 11.01it/s] 99%|█████████▊| 1056/1070 [01:55<00:01, 11.01it/s] 99%|█████████▉| 1058/1070 [01:55<00:01, 11.02it/s] 99%|█████████▉| 1060/1070 [01:56<00:00, 11.00it/s] 99%|█████████▉| 1062/1070 [01:56<00:00, 10.99it/s] 99%|█████████▉| 1064/1070 [01:56<00:00, 10.96it/s]100%|█████████▉| 1066/1070 [01:56<00:00, 10.96it/s]100%|█████████▉| 1068/1070 [01:56<00:00, 10.97it/s]100%|██████████| 1070/1070 [01:57<00:00, 11.37it/s]                                                   100%|██████████| 1070/1070 [01:57<00:00, 11.37it/s][INFO|trainer.py:755] 2023-11-15 19:51:07,310 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:51:07,312 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:51:07,312 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:51:07,313 >>   Batch size = 8
{'eval_loss': 0.35815635323524475, 'eval_accuracy': 0.9078947368421053, 'eval_micro_f1': 0.9078947368421053, 'eval_macro_f1': 0.9055880355791155, 'eval_runtime': 0.9211, 'eval_samples_per_second': 825.113, 'eval_steps_per_second': 103.139, 'epoch': 4.0}
{'loss': 0.06, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 13%|█▎        | 12/95 [00:00<00:00, 118.02it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 111.69it/s][A
 38%|███▊      | 36/95 [00:00<00:00, 109.64it/s][A
 49%|████▉     | 47/95 [00:00<00:00, 108.15it/s][A
 61%|██████    | 58/95 [00:00<00:00, 107.10it/s][A
 73%|███████▎  | 69/95 [00:00<00:00, 106.33it/s][A
 84%|████████▍ | 80/95 [00:00<00:00, 105.69it/s][A
 96%|█████████▌| 91/95 [00:00<00:00, 105.20it/s][A                                                   
                                                [A100%|██████████| 1070/1070 [01:57<00:00, 11.37it/s]
100%|██████████| 95/95 [00:00<00:00, 105.20it/s][A
                                                [A[INFO|trainer.py:1963] 2023-11-15 19:51:08,252 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [01:57<00:00, 11.37it/s]100%|██████████| 1070/1070 [01:57<00:00,  9.07it/s]
[INFO|trainer.py:2855] 2023-11-15 19:51:08,257 >> Saving model checkpoint to ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0
[INFO|configuration_utils.py:460] 2023-11-15 19:51:08,261 >> Configuration saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:51:09,509 >> Model weights saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:51:09,513 >> tokenizer config file saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:51:09,516 >> Special tokens file saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed0/special_tokens_map.json
{'eval_loss': 0.38665711879730225, 'eval_accuracy': 0.9131578947368421, 'eval_micro_f1': 0.9131578947368421, 'eval_macro_f1': 0.9112788122991711, 'eval_runtime': 0.9353, 'eval_samples_per_second': 812.597, 'eval_steps_per_second': 101.575, 'epoch': 5.0}
{'train_runtime': 117.9784, 'train_samples_per_second': 289.884, 'train_steps_per_second': 9.069, 'train_loss': 0.21705836893242098, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2171
  train_runtime            = 0:01:57.97
  train_samples            =       6840
  train_samples_per_second =    289.884
  train_steps_per_second   =      9.069
11/15/2023 19:51:09 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:51:09,565 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:51:09,567 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:51:09,567 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 19:51:09,567 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s] 13%|█▎        | 12/95 [00:00<00:00, 116.88it/s] 25%|██▌       | 24/95 [00:00<00:00, 109.10it/s] 37%|███▋      | 35/95 [00:00<00:00, 106.34it/s] 48%|████▊     | 46/95 [00:00<00:00, 103.81it/s] 60%|██████    | 57/95 [00:00<00:00, 103.19it/s] 72%|███████▏  | 68/95 [00:00<00:00, 103.54it/s] 83%|████████▎ | 79/95 [00:00<00:00, 103.38it/s] 95%|█████████▍| 90/95 [00:00<00:00, 103.12it/s]100%|██████████| 95/95 [00:00<00:00, 100.39it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9132
  eval_loss               =     0.3867
  eval_macro_f1           =     0.9113
  eval_micro_f1           =     0.9132
  eval_runtime            = 0:00:00.95
  eval_samples            =        760
  eval_samples_per_second =    792.686
  eval_steps_per_second   =     99.086
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▃▇▁▆██
wandb:                      eval/loss ▃▁▅▆██
wandb:                  eval/macro_f1 ▃▆▁▆██
wandb:                  eval/micro_f1 ▃▇▁▆██
wandb:                   eval/runtime ██▁▁▁▂
wandb:        eval/samples_per_second ▁▁██▇▇
wandb:          eval/steps_per_second ▁▁██▇▇
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.91316
wandb:                      eval/loss 0.38666
wandb:                  eval/macro_f1 0.91128
wandb:                  eval/micro_f1 0.91316
wandb:                   eval/runtime 0.9588
wandb:        eval/samples_per_second 792.686
wandb:          eval/steps_per_second 99.086
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.06
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.21706
wandb:            train/train_runtime 117.9784
wandb: train/train_samples_per_second 289.884
wandb:   train/train_steps_per_second 9.069
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_194751-su3nt64a
wandb: Find logs at: ./wandb/offline-run-20231115_194751-su3nt64a/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_roberta-base_adapter__seed1/runs/Nov15_19-51-23_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_roberta-base_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_roberta-base_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:51:23 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:51:23 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_roberta-base_adapter__seed1/runs/Nov15_19-51-22_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_roberta-base_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_roberta-base_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  88%|████████▊ | 4135/4722 [00:00<00:00, 41043.17 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 40099.34 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 19:51:39,539 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:51:39,551 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 19:51:49,569 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 19:51:59,587 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:51:59,588 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:52:19,636 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:52:19,636 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:52:19,636 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:52:19,637 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:52:19,637 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:52:19,637 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 19:52:19,638 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:52:19,639 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:52:39,828 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 19:52:40,590 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:52:40,591 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 24923.95 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 24501.54 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 28402.24 examples/s]
11/15/2023 19:52:40 - INFO - __main__ - Sample 3190 of the training set: {'text': 'priced <SEP> The food is great and reasonably priced.', 'label': 0, 'input_ids': [0, 18288, 28696, 3388, 510, 15698, 20, 689, 16, 372, 8, 15646, 7663, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:52:40 - INFO - __main__ - Sample 441 of the training set: {'text': 'dhosas <SEP> I like the somosas, chai, and the chole, but the dhosas and dhal were kinda dissapointing.', 'label': 2, 'input_ids': [0, 16593, 366, 281, 28696, 3388, 510, 15698, 38, 101, 5, 16487, 366, 281, 6, 1855, 1439, 6, 8, 5, 14310, 459, 6, 53, 5, 19480, 366, 281, 8, 385, 11124, 58, 24282, 14863, 1115, 15494, 154, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:52:40 - INFO - __main__ - Sample 963 of the training set: {'text': 'beef carpaachio <SEP> Service was warm and attentive, beef carpaachio was exellent (huge portion) and pasta was fresh and well-prepared.', 'label': 0, 'input_ids': [0, 1610, 4550, 512, 6709, 1488, 1020, 28696, 3388, 510, 15698, 1841, 21, 3279, 8, 36670, 6, 6829, 512, 6709, 1488, 1020, 21, 1931, 1641, 1342, 36, 30214, 4745, 43, 8, 18236, 21, 2310, 8, 157, 12, 5234, 33160, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:52:40 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:52:41,979 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:52:41,986 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:52:41,987 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 19:52:41,987 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:52:41,987 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:52:41,987 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:52:41,988 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:52:41,988 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 19:52:41,989 >>   Number of trainable parameters = 124,647,939
[INFO|integration_utils.py:716] 2023-11-15 19:52:41,990 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<10:57,  1.11s/it]  1%|          | 3/595 [00:01<03:28,  2.83it/s]  1%|          | 5/595 [00:01<02:08,  4.59it/s]  1%|          | 7/595 [00:01<01:35,  6.13it/s]  2%|▏         | 9/595 [00:01<01:19,  7.40it/s]  2%|▏         | 11/595 [00:01<01:09,  8.41it/s]  2%|▏         | 13/595 [00:02<01:03,  9.18it/s]  3%|▎         | 15/595 [00:02<00:59,  9.74it/s]  3%|▎         | 17/595 [00:02<00:57, 10.13it/s]  3%|▎         | 19/595 [00:02<00:55, 10.44it/s]  4%|▎         | 21/595 [00:02<00:53, 10.68it/s]  4%|▍         | 23/595 [00:03<00:52, 10.85it/s]  4%|▍         | 25/595 [00:03<00:52, 10.96it/s]  5%|▍         | 27/595 [00:03<00:51, 10.99it/s]  5%|▍         | 29/595 [00:03<00:51, 11.06it/s]  5%|▌         | 31/595 [00:03<00:50, 11.11it/s]  6%|▌         | 33/595 [00:03<00:50, 11.14it/s]  6%|▌         | 35/595 [00:04<00:50, 11.16it/s]  6%|▌         | 37/595 [00:04<00:49, 11.16it/s]  7%|▋         | 39/595 [00:04<00:49, 11.18it/s]  7%|▋         | 41/595 [00:04<00:49, 11.17it/s]  7%|▋         | 43/595 [00:04<00:49, 11.18it/s]  8%|▊         | 45/595 [00:05<00:49, 11.18it/s]  8%|▊         | 47/595 [00:05<00:48, 11.20it/s]  8%|▊         | 49/595 [00:05<00:48, 11.22it/s]  9%|▊         | 51/595 [00:05<00:48, 11.25it/s]  9%|▉         | 53/595 [00:05<00:48, 11.25it/s]  9%|▉         | 55/595 [00:05<00:47, 11.26it/s] 10%|▉         | 57/595 [00:06<00:47, 11.28it/s] 10%|▉         | 59/595 [00:06<00:47, 11.28it/s] 10%|█         | 61/595 [00:06<00:47, 11.27it/s] 11%|█         | 63/595 [00:06<00:47, 11.28it/s] 11%|█         | 65/595 [00:06<00:46, 11.28it/s] 11%|█▏        | 67/595 [00:06<00:46, 11.28it/s] 12%|█▏        | 69/595 [00:07<00:46, 11.28it/s] 12%|█▏        | 71/595 [00:07<00:46, 11.29it/s] 12%|█▏        | 73/595 [00:07<00:46, 11.28it/s] 13%|█▎        | 75/595 [00:07<00:46, 11.27it/s] 13%|█▎        | 77/595 [00:07<00:45, 11.27it/s] 13%|█▎        | 79/595 [00:08<00:45, 11.27it/s] 14%|█▎        | 81/595 [00:08<00:45, 11.28it/s] 14%|█▍        | 83/595 [00:08<00:45, 11.29it/s] 14%|█▍        | 85/595 [00:08<00:45, 11.28it/s] 15%|█▍        | 87/595 [00:08<00:45, 11.27it/s] 15%|█▍        | 89/595 [00:08<00:44, 11.27it/s] 15%|█▌        | 91/595 [00:09<00:44, 11.27it/s] 16%|█▌        | 93/595 [00:09<00:44, 11.26it/s] 16%|█▌        | 95/595 [00:09<00:44, 11.27it/s] 16%|█▋        | 97/595 [00:09<00:44, 11.28it/s] 17%|█▋        | 99/595 [00:09<00:44, 11.26it/s] 17%|█▋        | 101/595 [00:10<00:43, 11.26it/s] 17%|█▋        | 103/595 [00:10<00:43, 11.26it/s] 18%|█▊        | 105/595 [00:10<00:43, 11.27it/s] 18%|█▊        | 107/595 [00:10<00:43, 11.27it/s] 18%|█▊        | 109/595 [00:10<00:43, 11.26it/s] 19%|█▊        | 111/595 [00:10<00:42, 11.27it/s] 19%|█▉        | 113/595 [00:11<00:42, 11.27it/s] 19%|█▉        | 115/595 [00:11<00:42, 11.27it/s] 20%|█▉        | 117/595 [00:11<00:42, 11.28it/s] 20%|██        | 119/595 [00:11<00:38, 12.36it/s]                                                  20%|██        | 119/595 [00:11<00:38, 12.36it/s][INFO|trainer.py:755] 2023-11-15 19:52:53,551 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:52:53,553 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:52:53,554 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:52:53,554 >>   Batch size = 8
{'loss': 0.7364, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 128.29it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 121.03it/s][A
 33%|███▎      | 39/119 [00:00<00:00, 118.46it/s][A
 43%|████▎     | 51/119 [00:00<00:00, 117.25it/s][A
 53%|█████▎    | 63/119 [00:00<00:00, 116.58it/s][A
 63%|██████▎   | 75/119 [00:00<00:00, 116.04it/s][A
 73%|███████▎  | 87/119 [00:00<00:00, 115.45it/s][A
 83%|████████▎ | 99/119 [00:00<00:00, 114.82it/s][A
 93%|█████████▎| 111/119 [00:00<00:00, 114.10it/s][A                                                 
                                                  [A 20%|██        | 119/595 [00:12<00:38, 12.36it/s]
100%|██████████| 119/119 [00:01<00:00, 114.10it/s][A
                                                  [A 20%|██        | 121/595 [00:12<01:56,  4.08it/s] 21%|██        | 123/595 [00:12<01:33,  5.05it/s] 21%|██        | 125/595 [00:13<01:17,  6.05it/s] 21%|██▏       | 127/595 [00:13<01:06,  7.03it/s] 22%|██▏       | 129/595 [00:13<00:58,  7.92it/s] 22%|██▏       | 131/595 [00:13<00:53,  8.66it/s] 22%|██▏       | 133/595 [00:13<00:49,  9.31it/s] 23%|██▎       | 135/595 [00:14<00:46,  9.81it/s] 23%|██▎       | 137/595 [00:14<00:44, 10.21it/s] 23%|██▎       | 139/595 [00:14<00:43, 10.50it/s] 24%|██▎       | 141/595 [00:14<00:42, 10.69it/s] 24%|██▍       | 143/595 [00:14<00:41, 10.84it/s] 24%|██▍       | 145/595 [00:14<00:41, 10.96it/s] 25%|██▍       | 147/595 [00:15<00:40, 11.06it/s] 25%|██▌       | 149/595 [00:15<00:40, 11.11it/s] 25%|██▌       | 151/595 [00:15<00:39, 11.14it/s] 26%|██▌       | 153/595 [00:15<00:39, 11.16it/s] 26%|██▌       | 155/595 [00:15<00:39, 11.18it/s] 26%|██▋       | 157/595 [00:16<00:39, 11.20it/s] 27%|██▋       | 159/595 [00:16<00:38, 11.22it/s] 27%|██▋       | 161/595 [00:16<00:38, 11.24it/s] 27%|██▋       | 163/595 [00:16<00:38, 11.23it/s] 28%|██▊       | 165/595 [00:16<00:38, 11.22it/s] 28%|██▊       | 167/595 [00:16<00:38, 11.24it/s] 28%|██▊       | 169/595 [00:17<00:37, 11.23it/s] 29%|██▊       | 171/595 [00:17<00:37, 11.23it/s] 29%|██▉       | 173/595 [00:17<00:37, 11.24it/s] 29%|██▉       | 175/595 [00:17<00:37, 11.22it/s] 30%|██▉       | 177/595 [00:17<00:37, 11.24it/s] 30%|███       | 179/595 [00:17<00:37, 11.23it/s] 30%|███       | 181/595 [00:18<00:36, 11.24it/s] 31%|███       | 183/595 [00:18<00:36, 11.24it/s] 31%|███       | 185/595 [00:18<00:36, 11.23it/s] 31%|███▏      | 187/595 [00:18<00:36, 11.24it/s] 32%|███▏      | 189/595 [00:18<00:36, 11.24it/s] 32%|███▏      | 191/595 [00:19<00:35, 11.22it/s] 32%|███▏      | 193/595 [00:19<00:35, 11.21it/s] 33%|███▎      | 195/595 [00:19<00:35, 11.21it/s] 33%|███▎      | 197/595 [00:19<00:35, 11.22it/s] 33%|███▎      | 199/595 [00:19<00:35, 11.23it/s] 34%|███▍      | 201/595 [00:19<00:35, 11.24it/s] 34%|███▍      | 203/595 [00:20<00:34, 11.23it/s] 34%|███▍      | 205/595 [00:20<00:34, 11.23it/s] 35%|███▍      | 207/595 [00:20<00:34, 11.24it/s] 35%|███▌      | 209/595 [00:20<00:34, 11.22it/s] 35%|███▌      | 211/595 [00:20<00:34, 11.23it/s] 36%|███▌      | 213/595 [00:20<00:34, 11.23it/s] 36%|███▌      | 215/595 [00:21<00:33, 11.22it/s] 36%|███▋      | 217/595 [00:21<00:33, 11.21it/s] 37%|███▋      | 219/595 [00:21<00:33, 11.22it/s] 37%|███▋      | 221/595 [00:21<00:33, 11.21it/s] 37%|███▋      | 223/595 [00:21<00:33, 11.22it/s] 38%|███▊      | 225/595 [00:22<00:32, 11.22it/s] 38%|███▊      | 227/595 [00:22<00:32, 11.21it/s] 38%|███▊      | 229/595 [00:22<00:32, 11.21it/s] 39%|███▉      | 231/595 [00:22<00:32, 11.18it/s] 39%|███▉      | 233/595 [00:22<00:32, 11.21it/s] 39%|███▉      | 235/595 [00:22<00:32, 11.22it/s] 40%|███▉      | 237/595 [00:23<00:31, 11.26it/s]                                                  40%|████      | 238/595 [00:23<00:31, 11.26it/s][INFO|trainer.py:755] 2023-11-15 19:53:05,169 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:53:05,171 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:53:05,171 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:53:05,171 >>   Batch size = 8
{'eval_loss': 0.46876609325408936, 'eval_accuracy': 0.817989417989418, 'eval_micro_f1': 0.8179894179894182, 'eval_macro_f1': 0.7046806203008943, 'eval_runtime': 1.0683, 'eval_samples_per_second': 884.6, 'eval_steps_per_second': 111.394, 'epoch': 1.0}
{'loss': 0.4445, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 127.31it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 120.01it/s][A
 33%|███▎      | 39/119 [00:00<00:00, 117.77it/s][A
 43%|████▎     | 51/119 [00:00<00:00, 116.39it/s][A
 53%|█████▎    | 63/119 [00:00<00:00, 115.39it/s][A
 63%|██████▎   | 75/119 [00:00<00:00, 114.70it/s][A
 73%|███████▎  | 87/119 [00:00<00:00, 114.15it/s][A
 83%|████████▎ | 99/119 [00:00<00:00, 113.92it/s][A
 93%|█████████▎| 111/119 [00:00<00:00, 113.15it/s][A                                                 
                                                  [A 40%|████      | 238/595 [00:24<00:31, 11.26it/s]
100%|██████████| 119/119 [00:01<00:00, 113.15it/s][A
                                                  [A 40%|████      | 239/595 [00:24<01:26,  4.11it/s] 41%|████      | 241/595 [00:24<01:09,  5.06it/s] 41%|████      | 243/595 [00:24<00:58,  6.06it/s] 41%|████      | 245/595 [00:24<00:49,  7.03it/s] 42%|████▏     | 247/595 [00:25<00:43,  7.93it/s] 42%|████▏     | 249/595 [00:25<00:39,  8.68it/s] 42%|████▏     | 251/595 [00:25<00:37,  9.28it/s] 43%|████▎     | 253/595 [00:25<00:34,  9.79it/s] 43%|████▎     | 255/595 [00:25<00:33, 10.18it/s] 43%|████▎     | 257/595 [00:25<00:32, 10.47it/s] 44%|████▎     | 259/595 [00:26<00:31, 10.68it/s] 44%|████▍     | 261/595 [00:26<00:30, 10.83it/s] 44%|████▍     | 263/595 [00:26<00:30, 10.93it/s] 45%|████▍     | 265/595 [00:26<00:29, 11.01it/s] 45%|████▍     | 267/595 [00:26<00:29, 11.07it/s] 45%|████▌     | 269/595 [00:27<00:29, 11.10it/s] 46%|████▌     | 271/595 [00:27<00:29, 11.14it/s] 46%|████▌     | 273/595 [00:27<00:28, 11.13it/s] 46%|████▌     | 275/595 [00:27<00:28, 11.14it/s] 47%|████▋     | 277/595 [00:27<00:28, 11.18it/s] 47%|████▋     | 279/595 [00:27<00:28, 11.19it/s] 47%|████▋     | 281/595 [00:28<00:28, 11.20it/s] 48%|████▊     | 283/595 [00:28<00:27, 11.21it/s] 48%|████▊     | 285/595 [00:28<00:27, 11.19it/s] 48%|████▊     | 287/595 [00:28<00:27, 11.17it/s] 49%|████▊     | 289/595 [00:28<00:27, 11.18it/s] 49%|████▉     | 291/595 [00:28<00:27, 11.19it/s] 49%|████▉     | 293/595 [00:29<00:26, 11.20it/s] 50%|████▉     | 295/595 [00:29<00:26, 11.20it/s] 50%|████▉     | 297/595 [00:29<00:26, 11.19it/s] 50%|█████     | 299/595 [00:29<00:26, 11.20it/s] 51%|█████     | 301/595 [00:29<00:26, 11.17it/s] 51%|█████     | 303/595 [00:30<00:26, 11.19it/s] 51%|█████▏    | 305/595 [00:30<00:25, 11.20it/s] 52%|█████▏    | 307/595 [00:30<00:25, 11.19it/s] 52%|█████▏    | 309/595 [00:30<00:25, 11.19it/s] 52%|█████▏    | 311/595 [00:30<00:25, 11.18it/s] 53%|█████▎    | 313/595 [00:30<00:25, 11.17it/s] 53%|█████▎    | 315/595 [00:31<00:25, 11.17it/s] 53%|█████▎    | 317/595 [00:31<00:24, 11.19it/s] 54%|█████▎    | 319/595 [00:31<00:24, 11.18it/s] 54%|█████▍    | 321/595 [00:31<00:24, 11.18it/s] 54%|█████▍    | 323/595 [00:31<00:24, 11.18it/s] 55%|█████▍    | 325/595 [00:32<00:24, 11.17it/s] 55%|█████▍    | 327/595 [00:32<00:23, 11.18it/s] 55%|█████▌    | 329/595 [00:32<00:23, 11.20it/s] 56%|█████▌    | 331/595 [00:32<00:23, 11.20it/s] 56%|█████▌    | 333/595 [00:32<00:23, 11.19it/s] 56%|█████▋    | 335/595 [00:32<00:23, 11.19it/s] 57%|█████▋    | 337/595 [00:33<00:23, 11.19it/s] 57%|█████▋    | 339/595 [00:33<00:22, 11.18it/s] 57%|█████▋    | 341/595 [00:33<00:22, 11.17it/s] 58%|█████▊    | 343/595 [00:33<00:22, 11.17it/s] 58%|█████▊    | 345/595 [00:33<00:22, 11.18it/s] 58%|█████▊    | 347/595 [00:33<00:22, 11.19it/s] 59%|█████▊    | 349/595 [00:34<00:22, 11.18it/s] 59%|█████▉    | 351/595 [00:34<00:21, 11.18it/s] 59%|█████▉    | 353/595 [00:34<00:21, 11.19it/s] 60%|█████▉    | 355/595 [00:34<00:21, 11.19it/s] 60%|██████    | 357/595 [00:34<00:19, 12.42it/s]                                                  60%|██████    | 357/595 [00:34<00:19, 12.42it/s][INFO|trainer.py:755] 2023-11-15 19:53:16,833 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:53:16,835 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:53:16,835 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:53:16,836 >>   Batch size = 8
{'eval_loss': 0.3979891836643219, 'eval_accuracy': 0.8380952380952381, 'eval_micro_f1': 0.8380952380952381, 'eval_macro_f1': 0.784396637445123, 'eval_runtime': 1.0782, 'eval_samples_per_second': 876.471, 'eval_steps_per_second': 110.37, 'epoch': 2.0}
{'loss': 0.2952, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 126.66it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 119.23it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 116.58it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 115.07it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 114.34it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 113.46it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 112.88it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 112.44it/s][A
 92%|█████████▏| 110/119 [00:00<00:00, 111.70it/s][A                                                 
                                                  [A 60%|██████    | 357/595 [00:35<00:19, 12.42it/s]
100%|██████████| 119/119 [00:01<00:00, 111.70it/s][A
                                                  [A 60%|██████    | 359/595 [00:36<00:58,  4.02it/s] 61%|██████    | 361/595 [00:36<00:47,  4.98it/s] 61%|██████    | 363/595 [00:36<00:38,  5.97it/s] 61%|██████▏   | 365/595 [00:36<00:33,  6.93it/s] 62%|██████▏   | 367/595 [00:36<00:29,  7.82it/s] 62%|██████▏   | 369/595 [00:37<00:26,  8.57it/s] 62%|██████▏   | 371/595 [00:37<00:24,  9.21it/s] 63%|██████▎   | 373/595 [00:37<00:22,  9.71it/s] 63%|██████▎   | 375/595 [00:37<00:21, 10.10it/s] 63%|██████▎   | 377/595 [00:37<00:20, 10.41it/s] 64%|██████▎   | 379/595 [00:37<00:20, 10.62it/s] 64%|██████▍   | 381/595 [00:38<00:19, 10.76it/s] 64%|██████▍   | 383/595 [00:38<00:19, 10.87it/s] 65%|██████▍   | 385/595 [00:38<00:19, 10.95it/s] 65%|██████▌   | 387/595 [00:38<00:18, 11.01it/s] 65%|██████▌   | 389/595 [00:38<00:18, 11.08it/s] 66%|██████▌   | 391/595 [00:38<00:18, 11.08it/s] 66%|██████▌   | 393/595 [00:39<00:18, 11.11it/s] 66%|██████▋   | 395/595 [00:39<00:17, 11.12it/s] 67%|██████▋   | 397/595 [00:39<00:17, 11.12it/s] 67%|██████▋   | 399/595 [00:39<00:17, 11.14it/s] 67%|██████▋   | 401/595 [00:39<00:17, 11.14it/s] 68%|██████▊   | 403/595 [00:40<00:17, 11.14it/s] 68%|██████▊   | 405/595 [00:40<00:17, 11.15it/s] 68%|██████▊   | 407/595 [00:40<00:16, 11.16it/s] 69%|██████▊   | 409/595 [00:40<00:16, 11.14it/s] 69%|██████▉   | 411/595 [00:40<00:16, 11.14it/s] 69%|██████▉   | 413/595 [00:40<00:16, 11.14it/s] 70%|██████▉   | 415/595 [00:41<00:16, 11.12it/s] 70%|███████   | 417/595 [00:41<00:15, 11.14it/s] 70%|███████   | 419/595 [00:41<00:15, 11.15it/s] 71%|███████   | 421/595 [00:41<00:15, 11.14it/s] 71%|███████   | 423/595 [00:41<00:15, 11.14it/s] 71%|███████▏  | 425/595 [00:42<00:15, 11.13it/s] 72%|███████▏  | 427/595 [00:42<00:15, 11.13it/s] 72%|███████▏  | 429/595 [00:42<00:14, 11.14it/s] 72%|███████▏  | 431/595 [00:42<00:14, 11.12it/s] 73%|███████▎  | 433/595 [00:42<00:14, 11.14it/s] 73%|███████▎  | 435/595 [00:42<00:14, 11.15it/s] 73%|███████▎  | 437/595 [00:43<00:14, 11.16it/s] 74%|███████▍  | 439/595 [00:43<00:14, 11.12it/s] 74%|███████▍  | 441/595 [00:43<00:13, 11.13it/s] 74%|███████▍  | 443/595 [00:43<00:13, 11.14it/s] 75%|███████▍  | 445/595 [00:43<00:13, 11.14it/s] 75%|███████▌  | 447/595 [00:44<00:13, 11.14it/s] 75%|███████▌  | 449/595 [00:44<00:13, 11.15it/s] 76%|███████▌  | 451/595 [00:44<00:12, 11.15it/s] 76%|███████▌  | 453/595 [00:44<00:12, 11.14it/s] 76%|███████▋  | 455/595 [00:44<00:12, 11.14it/s] 77%|███████▋  | 457/595 [00:44<00:12, 11.14it/s] 77%|███████▋  | 459/595 [00:45<00:12, 11.15it/s] 77%|███████▋  | 461/595 [00:45<00:12, 11.14it/s] 78%|███████▊  | 463/595 [00:45<00:11, 11.13it/s] 78%|███████▊  | 465/595 [00:45<00:11, 11.12it/s] 78%|███████▊  | 467/595 [00:45<00:11, 11.10it/s] 79%|███████▉  | 469/595 [00:45<00:11, 11.12it/s] 79%|███████▉  | 471/595 [00:46<00:11, 11.13it/s] 79%|███████▉  | 473/595 [00:46<00:10, 11.13it/s] 80%|███████▉  | 475/595 [00:46<00:10, 11.16it/s]                                                  80%|████████  | 476/595 [00:46<00:10, 11.16it/s][INFO|trainer.py:755] 2023-11-15 19:53:28,558 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:53:28,559 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:53:28,560 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:53:28,560 >>   Batch size = 8
{'eval_loss': 0.33024856448173523, 'eval_accuracy': 0.8656084656084656, 'eval_micro_f1': 0.8656084656084656, 'eval_macro_f1': 0.8024388011896592, 'eval_runtime': 1.091, 'eval_samples_per_second': 866.204, 'eval_steps_per_second': 109.078, 'epoch': 3.0}
{'loss': 0.2133, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 126.36it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 118.75it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 116.50it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 115.25it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 114.00it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 113.10it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 112.68it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 112.05it/s][A
 92%|█████████▏| 110/119 [00:00<00:00, 111.32it/s][A                                                 
                                                  [A 80%|████████  | 476/595 [00:47<00:10, 11.16it/s]
100%|██████████| 119/119 [00:01<00:00, 111.32it/s][A
                                                  [A 80%|████████  | 477/595 [00:47<00:29,  4.06it/s] 81%|████████  | 479/595 [00:47<00:23,  5.01it/s] 81%|████████  | 481/595 [00:48<00:18,  6.00it/s] 81%|████████  | 483/595 [00:48<00:16,  6.97it/s] 82%|████████▏ | 485/595 [00:48<00:14,  7.85it/s] 82%|████████▏ | 487/595 [00:48<00:12,  8.58it/s] 82%|████████▏ | 489/595 [00:48<00:11,  9.20it/s] 83%|████████▎ | 491/595 [00:49<00:10,  9.71it/s] 83%|████████▎ | 493/595 [00:49<00:10, 10.10it/s] 83%|████████▎ | 495/595 [00:49<00:09, 10.40it/s] 84%|████████▎ | 497/595 [00:49<00:09, 10.62it/s] 84%|████████▍ | 499/595 [00:49<00:08, 10.76it/s] 84%|████████▍ | 501/595 [00:49<00:08, 10.85it/s] 85%|████████▍ | 503/595 [00:50<00:08, 10.93it/s] 85%|████████▍ | 505/595 [00:50<00:08, 11.01it/s] 85%|████████▌ | 507/595 [00:50<00:07, 11.05it/s] 86%|████████▌ | 509/595 [00:50<00:07, 11.07it/s] 86%|████████▌ | 511/595 [00:50<00:07, 11.09it/s] 86%|████████▌ | 513/595 [00:50<00:07, 11.10it/s] 87%|████████▋ | 515/595 [00:51<00:07, 11.10it/s] 87%|████████▋ | 517/595 [00:51<00:07, 11.11it/s] 87%|████████▋ | 519/595 [00:51<00:06, 11.11it/s] 88%|████████▊ | 521/595 [00:51<00:06, 11.11it/s] 88%|████████▊ | 523/595 [00:51<00:06, 11.10it/s] 88%|████████▊ | 525/595 [00:52<00:06, 11.12it/s] 89%|████████▊ | 527/595 [00:52<00:06, 11.11it/s] 89%|████████▉ | 529/595 [00:52<00:05, 11.12it/s] 89%|████████▉ | 531/595 [00:52<00:05, 11.11it/s] 90%|████████▉ | 533/595 [00:52<00:05, 11.11it/s] 90%|████████▉ | 535/595 [00:52<00:05, 11.11it/s] 90%|█████████ | 537/595 [00:53<00:05, 11.10it/s] 91%|█████████ | 539/595 [00:53<00:05, 11.10it/s] 91%|█████████ | 541/595 [00:53<00:04, 11.11it/s] 91%|█████████▏| 543/595 [00:53<00:04, 11.12it/s] 92%|█████████▏| 545/595 [00:53<00:04, 11.12it/s] 92%|█████████▏| 547/595 [00:54<00:04, 11.12it/s] 92%|█████████▏| 549/595 [00:54<00:04, 11.10it/s] 93%|█████████▎| 551/595 [00:54<00:03, 11.10it/s] 93%|█████████▎| 553/595 [00:54<00:03, 11.10it/s] 93%|█████████▎| 555/595 [00:54<00:03, 11.10it/s] 94%|█████████▎| 557/595 [00:54<00:03, 11.11it/s] 94%|█████████▍| 559/595 [00:55<00:03, 11.11it/s] 94%|█████████▍| 561/595 [00:55<00:03, 11.10it/s] 95%|█████████▍| 563/595 [00:55<00:02, 11.10it/s] 95%|█████████▍| 565/595 [00:55<00:02, 11.09it/s] 95%|█████████▌| 567/595 [00:55<00:02, 11.09it/s] 96%|█████████▌| 569/595 [00:56<00:02, 11.09it/s] 96%|█████████▌| 571/595 [00:56<00:02, 11.10it/s] 96%|█████████▋| 573/595 [00:56<00:01, 11.09it/s] 97%|█████████▋| 575/595 [00:56<00:01, 11.10it/s] 97%|█████████▋| 577/595 [00:56<00:01, 11.07it/s] 97%|█████████▋| 579/595 [00:56<00:01, 11.08it/s] 98%|█████████▊| 581/595 [00:57<00:01, 11.09it/s] 98%|█████████▊| 583/595 [00:57<00:01, 11.07it/s] 98%|█████████▊| 585/595 [00:57<00:00, 11.08it/s] 99%|█████████▊| 587/595 [00:57<00:00, 11.07it/s] 99%|█████████▉| 589/595 [00:57<00:00, 11.08it/s] 99%|█████████▉| 591/595 [00:58<00:00, 11.09it/s]100%|█████████▉| 593/595 [00:58<00:00, 11.10it/s]100%|██████████| 595/595 [00:58<00:00, 12.32it/s]                                                 100%|██████████| 595/595 [00:58<00:00, 12.32it/s][INFO|trainer.py:755] 2023-11-15 19:53:40,316 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:53:40,317 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:53:40,317 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:53:40,317 >>   Batch size = 8
{'eval_loss': 0.3467077910900116, 'eval_accuracy': 0.8804232804232804, 'eval_micro_f1': 0.8804232804232806, 'eval_macro_f1': 0.8221679520565255, 'eval_runtime': 1.0929, 'eval_samples_per_second': 864.677, 'eval_steps_per_second': 108.885, 'epoch': 4.0}
{'loss': 0.1563, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 125.15it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 118.33it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 116.00it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 114.38it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 113.44it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 112.62it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 111.91it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 111.24it/s][A
 92%|█████████▏| 110/119 [00:00<00:00, 110.33it/s][A                                                 
                                                  [A100%|██████████| 595/595 [00:59<00:00, 12.32it/s]
100%|██████████| 119/119 [00:01<00:00, 110.33it/s][A
                                                  [A[INFO|trainer.py:1963] 2023-11-15 19:53:41,422 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [00:59<00:00, 12.32it/s]100%|██████████| 595/595 [00:59<00:00, 10.01it/s]
[INFO|trainer.py:2855] 2023-11-15 19:53:41,424 >> Saving model checkpoint to ./result/restaurant_roberta-base_adapter__seed1
[INFO|configuration_utils.py:460] 2023-11-15 19:53:41,427 >> Configuration saved in ./result/restaurant_roberta-base_adapter__seed1/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:53:42,941 >> Model weights saved in ./result/restaurant_roberta-base_adapter__seed1/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:53:42,944 >> tokenizer config file saved in ./result/restaurant_roberta-base_adapter__seed1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:53:42,947 >> Special tokens file saved in ./result/restaurant_roberta-base_adapter__seed1/special_tokens_map.json
{'eval_loss': 0.36614707112312317, 'eval_accuracy': 0.8835978835978836, 'eval_micro_f1': 0.8835978835978836, 'eval_macro_f1': 0.8308492762205355, 'eval_runtime': 1.1, 'eval_samples_per_second': 859.062, 'eval_steps_per_second': 108.178, 'epoch': 5.0}
{'train_runtime': 59.4329, 'train_samples_per_second': 317.753, 'train_steps_per_second': 10.011, 'train_loss': 0.3691521748775194, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3692
  train_runtime            = 0:00:59.43
  train_samples            =       3777
  train_samples_per_second =    317.753
  train_steps_per_second   =     10.011
11/15/2023 19:53:43 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:53:43,044 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:53:43,046 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:53:43,046 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:53:43,046 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s] 11%|█         | 13/119 [00:00<00:00, 123.87it/s] 22%|██▏       | 26/119 [00:00<00:00, 116.09it/s] 32%|███▏      | 38/119 [00:00<00:00, 113.65it/s] 42%|████▏     | 50/119 [00:00<00:00, 112.59it/s] 52%|█████▏    | 62/119 [00:00<00:00, 111.98it/s] 62%|██████▏   | 74/119 [00:00<00:00, 111.53it/s] 72%|███████▏  | 86/119 [00:00<00:00, 111.43it/s] 82%|████████▏ | 98/119 [00:00<00:00, 110.91it/s] 92%|█████████▏| 110/119 [00:00<00:00, 110.06it/s]100%|██████████| 119/119 [00:01<00:00, 108.95it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8836
  eval_loss               =     0.3661
  eval_macro_f1           =     0.8308
  eval_micro_f1           =     0.8836
  eval_runtime            = 0:00:01.10
  eval_samples            =        945
  eval_samples_per_second =    856.339
  eval_steps_per_second   =    107.835
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▃▆███
wandb:                      eval/loss █▄▁▂▃▃
wandb:                  eval/macro_f1 ▁▅▆███
wandb:                  eval/micro_f1 ▁▃▆███
wandb:                   eval/runtime ▁▃▆▆▇█
wandb:        eval/samples_per_second █▆▃▃▂▁
wandb:          eval/steps_per_second █▆▃▃▂▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.8836
wandb:                      eval/loss 0.36615
wandb:                  eval/macro_f1 0.83085
wandb:                  eval/micro_f1 0.8836
wandb:                   eval/runtime 1.1035
wandb:        eval/samples_per_second 856.339
wandb:          eval/steps_per_second 107.835
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1563
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.36915
wandb:            train/train_runtime 59.4329
wandb: train/train_samples_per_second 317.753
wandb:   train/train_steps_per_second 10.011
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_195124-yubvcu42
wandb: Find logs at: ./wandb/offline-run-20231115_195124-yubvcu42/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_bert-base-cased_adapter__seed1/runs/Nov15_19-53-55_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_bert-base-cased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_bert-base-cased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:53:55 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:53:55 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_bert-base-cased_adapter__seed1/runs/Nov15_19-53-54_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_bert-base-cased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_bert-base-cased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  88%|████████▊ | 4136/4722 [00:00<00:00, 40520.98 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 39903.26 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 19:54:11,459 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:54:11,471 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 19:54:21,490 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:54:21,491 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:54:21,494 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:54:21,495 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:54:21,495 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:54:21,495 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:54:21,496 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 19:54:21,497 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:54:21,497 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:54:41,659 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 19:54:42,294 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:54:42,295 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 23848.35 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 23508.36 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 27622.37 examples/s]
11/15/2023 19:54:42 - INFO - __main__ - Sample 3190 of the training set: {'text': 'priced <SEP> The food is great and reasonably priced.', 'label': 0, 'input_ids': [101, 23812, 133, 12342, 2101, 135, 1109, 2094, 1110, 1632, 1105, 17517, 23812, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:54:42 - INFO - __main__ - Sample 441 of the training set: {'text': 'dhosas <SEP> I like the somosas, chai, and the chole, but the dhosas and dhal were kinda dissapointing.', 'label': 2, 'input_ids': [101, 173, 15342, 2225, 133, 12342, 2101, 135, 146, 1176, 1103, 1177, 11828, 2225, 117, 22572, 3814, 117, 1105, 1103, 22572, 9016, 117, 1133, 1103, 173, 15342, 2225, 1105, 173, 7654, 1127, 21884, 4267, 11655, 7587, 1158, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:54:42 - INFO - __main__ - Sample 963 of the training set: {'text': 'beef carpaachio <SEP> Service was warm and attentive, beef carpaachio was exellent (huge portion) and pasta was fresh and well-prepared.', 'label': 0, 'input_ids': [101, 14413, 1610, 4163, 19226, 1186, 133, 12342, 2101, 135, 2516, 1108, 3258, 1105, 1120, 5208, 3946, 117, 14413, 1610, 4163, 19226, 1186, 1108, 4252, 11682, 2227, 113, 3321, 3849, 114, 1105, 1763, 1161, 1108, 4489, 1105, 1218, 118, 4029, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:54:42 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:54:43,569 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:54:43,577 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:54:43,578 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 19:54:43,578 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:54:43,579 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:54:43,579 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:54:43,579 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:54:43,580 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 19:54:43,580 >>   Number of trainable parameters = 108,312,579
[INFO|integration_utils.py:716] 2023-11-15 19:54:43,581 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<11:00,  1.11s/it]  1%|          | 3/595 [00:01<03:29,  2.83it/s]  1%|          | 5/595 [00:01<02:08,  4.60it/s]  1%|          | 7/595 [00:01<01:35,  6.15it/s]  2%|▏         | 9/595 [00:01<01:18,  7.44it/s]  2%|▏         | 11/595 [00:01<01:08,  8.47it/s]  2%|▏         | 13/595 [00:02<01:02,  9.26it/s]  3%|▎         | 15/595 [00:02<00:58,  9.85it/s]  3%|▎         | 17/595 [00:02<00:56, 10.29it/s]  3%|▎         | 19/595 [00:02<00:54, 10.60it/s]  4%|▎         | 21/595 [00:02<00:53, 10.83it/s]  4%|▍         | 23/595 [00:03<00:52, 10.99it/s]  4%|▍         | 25/595 [00:03<00:51, 11.10it/s]  5%|▍         | 27/595 [00:03<00:50, 11.17it/s]  5%|▍         | 29/595 [00:03<00:50, 11.23it/s]  5%|▌         | 31/595 [00:03<00:50, 11.28it/s]  6%|▌         | 33/595 [00:03<00:49, 11.31it/s]  6%|▌         | 35/595 [00:04<00:49, 11.32it/s]  6%|▌         | 37/595 [00:04<00:49, 11.34it/s]  7%|▋         | 39/595 [00:04<00:49, 11.34it/s]  7%|▋         | 41/595 [00:04<00:48, 11.34it/s]  7%|▋         | 43/595 [00:04<00:48, 11.34it/s]  8%|▊         | 45/595 [00:04<00:48, 11.35it/s]  8%|▊         | 47/595 [00:05<00:48, 11.37it/s]  8%|▊         | 49/595 [00:05<00:48, 11.34it/s]  9%|▊         | 51/595 [00:05<00:47, 11.36it/s]  9%|▉         | 53/595 [00:05<00:47, 11.37it/s]  9%|▉         | 55/595 [00:05<00:47, 11.37it/s] 10%|▉         | 57/595 [00:06<00:47, 11.34it/s] 10%|▉         | 59/595 [00:06<00:47, 11.35it/s] 10%|█         | 61/595 [00:06<00:47, 11.36it/s] 11%|█         | 63/595 [00:06<00:46, 11.36it/s] 11%|█         | 65/595 [00:06<00:46, 11.34it/s] 11%|█▏        | 67/595 [00:06<00:46, 11.35it/s] 12%|█▏        | 69/595 [00:07<00:46, 11.35it/s] 12%|█▏        | 71/595 [00:07<00:46, 11.34it/s] 12%|█▏        | 73/595 [00:07<00:46, 11.32it/s] 13%|█▎        | 75/595 [00:07<00:45, 11.33it/s] 13%|█▎        | 77/595 [00:07<00:45, 11.30it/s] 13%|█▎        | 79/595 [00:07<00:45, 11.30it/s] 14%|█▎        | 81/595 [00:08<00:45, 11.33it/s] 14%|█▍        | 83/595 [00:08<00:45, 11.34it/s] 14%|█▍        | 85/595 [00:08<00:45, 11.33it/s] 15%|█▍        | 87/595 [00:08<00:44, 11.33it/s] 15%|█▍        | 89/595 [00:08<00:44, 11.32it/s] 15%|█▌        | 91/595 [00:09<00:44, 11.33it/s] 16%|█▌        | 93/595 [00:09<00:44, 11.37it/s] 16%|█▌        | 95/595 [00:09<00:44, 11.35it/s] 16%|█▋        | 97/595 [00:09<00:43, 11.35it/s] 17%|█▋        | 99/595 [00:09<00:43, 11.32it/s] 17%|█▋        | 101/595 [00:09<00:43, 11.35it/s] 17%|█▋        | 103/595 [00:10<00:43, 11.35it/s] 18%|█▊        | 105/595 [00:10<00:43, 11.34it/s] 18%|█▊        | 107/595 [00:10<00:43, 11.34it/s] 18%|█▊        | 109/595 [00:10<00:42, 11.34it/s] 19%|█▊        | 111/595 [00:10<00:42, 11.34it/s] 19%|█▉        | 113/595 [00:10<00:42, 11.34it/s] 19%|█▉        | 115/595 [00:11<00:42, 11.35it/s] 20%|█▉        | 117/595 [00:11<00:42, 11.34it/s] 20%|██        | 119/595 [00:11<00:38, 12.51it/s]                                                  20%|██        | 119/595 [00:11<00:38, 12.51it/s][INFO|trainer.py:755] 2023-11-15 19:54:55,047 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:54:55,049 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:54:55,050 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:54:55,050 >>   Batch size = 8
{'loss': 0.7528, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 124.90it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 117.18it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 114.83it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 113.68it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 112.89it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 112.38it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 112.11it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 111.35it/s][A
 92%|█████████▏| 110/119 [00:00<00:00, 110.49it/s][A                                                 
                                                  [A 20%|██        | 119/595 [00:12<00:38, 12.51it/s]
100%|██████████| 119/119 [00:01<00:00, 110.49it/s][A
                                                  [A 20%|██        | 121/595 [00:12<01:58,  4.00it/s] 21%|██        | 123/595 [00:12<01:35,  4.96it/s] 21%|██        | 125/595 [00:13<01:18,  5.96it/s] 21%|██▏       | 127/595 [00:13<01:07,  6.95it/s] 22%|██▏       | 129/595 [00:13<00:59,  7.86it/s] 22%|██▏       | 131/595 [00:13<00:53,  8.65it/s] 22%|██▏       | 133/595 [00:13<00:49,  9.31it/s] 23%|██▎       | 135/595 [00:13<00:46,  9.87it/s] 23%|██▎       | 137/595 [00:14<00:44, 10.27it/s] 23%|██▎       | 139/595 [00:14<00:43, 10.56it/s] 24%|██▎       | 141/595 [00:14<00:42, 10.77it/s] 24%|██▍       | 143/595 [00:14<00:41, 10.93it/s] 24%|██▍       | 145/595 [00:14<00:40, 11.05it/s] 25%|██▍       | 147/595 [00:15<00:40, 11.13it/s] 25%|██▌       | 149/595 [00:15<00:39, 11.19it/s] 25%|██▌       | 151/595 [00:15<00:39, 11.21it/s] 26%|██▌       | 153/595 [00:15<00:39, 11.24it/s] 26%|██▌       | 155/595 [00:15<00:39, 11.26it/s] 26%|██▋       | 157/595 [00:15<00:38, 11.29it/s] 27%|██▋       | 159/595 [00:16<00:38, 11.29it/s] 27%|██▋       | 161/595 [00:16<00:38, 11.31it/s] 27%|██▋       | 163/595 [00:16<00:38, 11.32it/s] 28%|██▊       | 165/595 [00:16<00:37, 11.34it/s] 28%|██▊       | 167/595 [00:16<00:37, 11.33it/s] 28%|██▊       | 169/595 [00:16<00:37, 11.33it/s] 29%|██▊       | 171/595 [00:17<00:37, 11.34it/s] 29%|██▉       | 173/595 [00:17<00:37, 11.33it/s] 29%|██▉       | 175/595 [00:17<00:37, 11.34it/s] 30%|██▉       | 177/595 [00:17<00:36, 11.32it/s] 30%|███       | 179/595 [00:17<00:36, 11.32it/s] 30%|███       | 181/595 [00:18<00:36, 11.32it/s] 31%|███       | 183/595 [00:18<00:36, 11.33it/s] 31%|███       | 185/595 [00:18<00:36, 11.33it/s] 31%|███▏      | 187/595 [00:18<00:35, 11.35it/s] 32%|███▏      | 189/595 [00:18<00:35, 11.33it/s] 32%|███▏      | 191/595 [00:18<00:35, 11.33it/s] 32%|███▏      | 193/595 [00:19<00:35, 11.33it/s] 33%|███▎      | 195/595 [00:19<00:35, 11.33it/s] 33%|███▎      | 197/595 [00:19<00:35, 11.32it/s] 33%|███▎      | 199/595 [00:19<00:34, 11.33it/s] 34%|███▍      | 201/595 [00:19<00:34, 11.33it/s] 34%|███▍      | 203/595 [00:19<00:34, 11.30it/s] 34%|███▍      | 205/595 [00:20<00:34, 11.32it/s] 35%|███▍      | 207/595 [00:20<00:34, 11.33it/s] 35%|███▌      | 209/595 [00:20<00:34, 11.34it/s] 35%|███▌      | 211/595 [00:20<00:33, 11.35it/s] 36%|███▌      | 213/595 [00:20<00:33, 11.34it/s] 36%|███▌      | 215/595 [00:21<00:33, 11.34it/s] 36%|███▋      | 217/595 [00:21<00:33, 11.33it/s] 37%|███▋      | 219/595 [00:21<00:33, 11.32it/s] 37%|███▋      | 221/595 [00:21<00:32, 11.34it/s] 37%|███▋      | 223/595 [00:21<00:32, 11.35it/s] 38%|███▊      | 225/595 [00:21<00:32, 11.34it/s] 38%|███▊      | 227/595 [00:22<00:32, 11.33it/s] 38%|███▊      | 229/595 [00:22<00:32, 11.33it/s] 39%|███▉      | 231/595 [00:22<00:32, 11.32it/s] 39%|███▉      | 233/595 [00:22<00:31, 11.32it/s] 39%|███▉      | 235/595 [00:22<00:31, 11.32it/s] 40%|███▉      | 237/595 [00:22<00:31, 11.37it/s]                                                  40%|████      | 238/595 [00:23<00:31, 11.37it/s][INFO|trainer.py:755] 2023-11-15 19:55:06,609 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:55:06,610 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:55:06,611 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:55:06,612 >>   Batch size = 8
{'eval_loss': 0.5639967918395996, 'eval_accuracy': 0.7756613756613756, 'eval_micro_f1': 0.7756613756613756, 'eval_macro_f1': 0.6016884542597166, 'eval_runtime': 1.1026, 'eval_samples_per_second': 857.085, 'eval_steps_per_second': 107.929, 'epoch': 1.0}
{'loss': 0.5197, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 123.48it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 116.70it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 114.20it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 112.85it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 112.14it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 111.80it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 111.36it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 110.87it/s][A
 92%|█████████▏| 110/119 [00:00<00:00, 109.94it/s][A                                                 
                                                  [A 40%|████      | 238/595 [00:24<00:31, 11.37it/s]
100%|██████████| 119/119 [00:01<00:00, 109.94it/s][A
                                                  [A 40%|████      | 239/595 [00:24<01:28,  4.04it/s] 41%|████      | 241/595 [00:24<01:10,  5.00it/s] 41%|████      | 243/595 [00:24<00:58,  6.00it/s] 41%|████      | 245/595 [00:24<00:50,  6.97it/s] 42%|████▏     | 247/595 [00:24<00:44,  7.87it/s] 42%|████▏     | 249/595 [00:25<00:39,  8.66it/s] 42%|████▏     | 251/595 [00:25<00:36,  9.34it/s] 43%|████▎     | 253/595 [00:25<00:34,  9.85it/s] 43%|████▎     | 255/595 [00:25<00:33, 10.25it/s] 43%|████▎     | 257/595 [00:25<00:32, 10.53it/s] 44%|████▎     | 259/595 [00:25<00:31, 10.75it/s] 44%|████▍     | 261/595 [00:26<00:30, 10.90it/s] 44%|████▍     | 263/595 [00:26<00:30, 11.03it/s] 45%|████▍     | 265/595 [00:26<00:29, 11.11it/s] 45%|████▍     | 267/595 [00:26<00:29, 11.16it/s] 45%|████▌     | 269/595 [00:26<00:29, 11.21it/s] 46%|████▌     | 271/595 [00:27<00:28, 11.21it/s] 46%|████▌     | 273/595 [00:27<00:28, 11.22it/s] 46%|████▌     | 275/595 [00:27<00:28, 11.23it/s] 47%|████▋     | 277/595 [00:27<00:28, 11.25it/s] 47%|████▋     | 279/595 [00:27<00:28, 11.26it/s] 47%|████▋     | 281/595 [00:27<00:27, 11.27it/s] 48%|████▊     | 283/595 [00:28<00:27, 11.26it/s] 48%|████▊     | 285/595 [00:28<00:27, 11.26it/s] 48%|████▊     | 287/595 [00:28<00:27, 11.28it/s] 49%|████▊     | 289/595 [00:28<00:27, 11.28it/s] 49%|████▉     | 291/595 [00:28<00:26, 11.28it/s] 49%|████▉     | 293/595 [00:29<00:26, 11.28it/s] 50%|████▉     | 295/595 [00:29<00:26, 11.30it/s] 50%|████▉     | 297/595 [00:29<00:26, 11.28it/s] 50%|█████     | 299/595 [00:29<00:26, 11.29it/s] 51%|█████     | 301/595 [00:29<00:26, 11.29it/s] 51%|█████     | 303/595 [00:29<00:25, 11.29it/s] 51%|█████▏    | 305/595 [00:30<00:25, 11.28it/s] 52%|█████▏    | 307/595 [00:30<00:25, 11.29it/s] 52%|█████▏    | 309/595 [00:30<00:25, 11.30it/s] 52%|█████▏    | 311/595 [00:30<00:25, 11.29it/s] 53%|█████▎    | 313/595 [00:30<00:24, 11.29it/s] 53%|█████▎    | 315/595 [00:30<00:24, 11.28it/s] 53%|█████▎    | 317/595 [00:31<00:24, 11.27it/s] 54%|█████▎    | 319/595 [00:31<00:24, 11.26it/s] 54%|█████▍    | 321/595 [00:31<00:24, 11.25it/s] 54%|█████▍    | 323/595 [00:31<00:24, 11.27it/s] 55%|█████▍    | 325/595 [00:31<00:23, 11.27it/s] 55%|█████▍    | 327/595 [00:32<00:23, 11.26it/s] 55%|█████▌    | 329/595 [00:32<00:23, 11.25it/s] 56%|█████▌    | 331/595 [00:32<00:23, 11.26it/s] 56%|█████▌    | 333/595 [00:32<00:23, 11.27it/s] 56%|█████▋    | 335/595 [00:32<00:23, 11.25it/s] 57%|█████▋    | 337/595 [00:32<00:22, 11.24it/s] 57%|█████▋    | 339/595 [00:33<00:22, 11.26it/s] 57%|█████▋    | 341/595 [00:33<00:22, 11.26it/s] 58%|█████▊    | 343/595 [00:33<00:22, 11.27it/s] 58%|█████▊    | 345/595 [00:33<00:22, 11.27it/s] 58%|█████▊    | 347/595 [00:33<00:22, 11.27it/s] 59%|█████▊    | 349/595 [00:33<00:21, 11.28it/s] 59%|█████▉    | 351/595 [00:34<00:21, 11.26it/s] 59%|█████▉    | 353/595 [00:34<00:21, 11.25it/s] 60%|█████▉    | 355/595 [00:34<00:21, 11.27it/s] 60%|██████    | 357/595 [00:34<00:18, 12.58it/s]                                                  60%|██████    | 357/595 [00:34<00:18, 12.58it/s][INFO|trainer.py:755] 2023-11-15 19:55:18,221 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:55:18,223 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:55:18,224 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:55:18,224 >>   Batch size = 8
{'eval_loss': 0.4961102306842804, 'eval_accuracy': 0.8042328042328042, 'eval_micro_f1': 0.8042328042328042, 'eval_macro_f1': 0.7181173012515796, 'eval_runtime': 1.1103, 'eval_samples_per_second': 851.158, 'eval_steps_per_second': 107.183, 'epoch': 2.0}
{'loss': 0.3755, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 122.99it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 116.06it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 113.54it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 112.41it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 111.76it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 110.94it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 110.17it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 109.46it/s][A
 92%|█████████▏| 109/119 [00:00<00:00, 108.61it/s][A                                                 
                                                  [A 60%|██████    | 357/595 [00:35<00:18, 12.58it/s]
100%|██████████| 119/119 [00:01<00:00, 108.61it/s][A
                                                  [A 60%|██████    | 359/595 [00:35<00:59,  3.97it/s] 61%|██████    | 361/595 [00:36<00:47,  4.92it/s] 61%|██████    | 363/595 [00:36<00:39,  5.92it/s] 61%|██████▏   | 365/595 [00:36<00:33,  6.90it/s] 62%|██████▏   | 367/595 [00:36<00:29,  7.81it/s] 62%|██████▏   | 369/595 [00:36<00:26,  8.59it/s] 62%|██████▏   | 371/595 [00:37<00:24,  9.25it/s] 63%|██████▎   | 373/595 [00:37<00:22,  9.77it/s] 63%|██████▎   | 375/595 [00:37<00:21, 10.18it/s] 63%|██████▎   | 377/595 [00:37<00:20, 10.47it/s] 64%|██████▎   | 379/595 [00:37<00:20, 10.69it/s] 64%|██████▍   | 381/595 [00:37<00:19, 10.84it/s] 64%|██████▍   | 383/595 [00:38<00:19, 10.96it/s] 65%|██████▍   | 385/595 [00:38<00:19, 11.04it/s] 65%|██████▌   | 387/595 [00:38<00:18, 11.11it/s] 65%|██████▌   | 389/595 [00:38<00:18, 11.14it/s] 66%|██████▌   | 391/595 [00:38<00:18, 11.17it/s] 66%|██████▌   | 393/595 [00:38<00:18, 11.19it/s] 66%|██████▋   | 395/595 [00:39<00:17, 11.20it/s] 67%|██████▋   | 397/595 [00:39<00:17, 11.20it/s] 67%|██████▋   | 399/595 [00:39<00:17, 11.21it/s] 67%|██████▋   | 401/595 [00:39<00:17, 11.21it/s] 68%|██████▊   | 403/595 [00:39<00:17, 11.21it/s] 68%|██████▊   | 405/595 [00:40<00:16, 11.23it/s] 68%|██████▊   | 407/595 [00:40<00:16, 11.24it/s] 69%|██████▊   | 409/595 [00:40<00:16, 11.25it/s] 69%|██████▉   | 411/595 [00:40<00:16, 11.25it/s] 69%|██████▉   | 413/595 [00:40<00:16, 11.24it/s] 70%|██████▉   | 415/595 [00:40<00:16, 11.24it/s] 70%|███████   | 417/595 [00:41<00:15, 11.25it/s] 70%|███████   | 419/595 [00:41<00:15, 11.24it/s] 71%|███████   | 421/595 [00:41<00:15, 11.24it/s] 71%|███████   | 423/595 [00:41<00:15, 11.23it/s] 71%|███████▏  | 425/595 [00:41<00:15, 11.23it/s] 72%|███████▏  | 427/595 [00:41<00:14, 11.24it/s] 72%|███████▏  | 429/595 [00:42<00:14, 11.25it/s] 72%|███████▏  | 431/595 [00:42<00:14, 11.23it/s] 73%|███████▎  | 433/595 [00:42<00:14, 11.24it/s] 73%|███████▎  | 435/595 [00:42<00:14, 11.25it/s] 73%|███████▎  | 437/595 [00:42<00:14, 11.24it/s] 74%|███████▍  | 439/595 [00:43<00:13, 11.23it/s] 74%|███████▍  | 441/595 [00:43<00:13, 11.23it/s] 74%|███████▍  | 443/595 [00:43<00:13, 11.21it/s] 75%|███████▍  | 445/595 [00:43<00:13, 11.22it/s] 75%|███████▌  | 447/595 [00:43<00:13, 11.20it/s] 75%|███████▌  | 449/595 [00:43<00:13, 11.21it/s] 76%|███████▌  | 451/595 [00:44<00:12, 11.22it/s] 76%|███████▌  | 453/595 [00:44<00:12, 11.21it/s] 76%|███████▋  | 455/595 [00:44<00:12, 11.20it/s] 77%|███████▋  | 457/595 [00:44<00:12, 11.19it/s] 77%|███████▋  | 459/595 [00:44<00:12, 11.20it/s] 77%|███████▋  | 461/595 [00:45<00:11, 11.20it/s] 78%|███████▊  | 463/595 [00:45<00:11, 11.20it/s] 78%|███████▊  | 465/595 [00:45<00:11, 11.21it/s] 78%|███████▊  | 467/595 [00:45<00:11, 11.21it/s] 79%|███████▉  | 469/595 [00:45<00:11, 11.21it/s] 79%|███████▉  | 471/595 [00:45<00:11, 11.21it/s] 79%|███████▉  | 473/595 [00:46<00:10, 11.23it/s] 80%|███████▉  | 475/595 [00:46<00:10, 11.28it/s]                                                  80%|████████  | 476/595 [00:46<00:10, 11.28it/s][INFO|trainer.py:755] 2023-11-15 19:55:29,888 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:55:29,890 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:55:29,891 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:55:29,891 >>   Batch size = 8
{'eval_loss': 0.435137003660202, 'eval_accuracy': 0.8359788359788359, 'eval_micro_f1': 0.8359788359788359, 'eval_macro_f1': 0.7539814332190007, 'eval_runtime': 1.1167, 'eval_samples_per_second': 846.26, 'eval_steps_per_second': 106.566, 'epoch': 3.0}
{'loss': 0.2706, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 123.05it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 115.75it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 113.46it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 112.37it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 111.49it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 110.81it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 110.12it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 109.37it/s][A
 92%|█████████▏| 109/119 [00:00<00:00, 108.18it/s][A                                                 
                                                  [A 80%|████████  | 476/595 [00:47<00:10, 11.28it/s]
100%|██████████| 119/119 [00:01<00:00, 108.18it/s][A
                                                  [A 80%|████████  | 477/595 [00:47<00:29,  4.00it/s] 81%|████████  | 479/595 [00:47<00:23,  4.94it/s] 81%|████████  | 481/595 [00:47<00:19,  5.93it/s] 81%|████████  | 483/595 [00:48<00:16,  6.91it/s] 82%|████████▏ | 485/595 [00:48<00:14,  7.81it/s] 82%|████████▏ | 487/595 [00:48<00:12,  8.58it/s] 82%|████████▏ | 489/595 [00:48<00:11,  9.23it/s] 83%|████████▎ | 491/595 [00:48<00:10,  9.75it/s] 83%|████████▎ | 493/595 [00:48<00:10, 10.15it/s] 83%|████████▎ | 495/595 [00:49<00:09, 10.44it/s] 84%|████████▎ | 497/595 [00:49<00:09, 10.66it/s] 84%|████████▍ | 499/595 [00:49<00:08, 10.83it/s] 84%|████████▍ | 501/595 [00:49<00:08, 10.94it/s] 85%|████████▍ | 503/595 [00:49<00:08, 11.01it/s] 85%|████████▍ | 505/595 [00:50<00:08, 11.06it/s] 85%|████████▌ | 507/595 [00:50<00:07, 11.11it/s] 86%|████████▌ | 509/595 [00:50<00:07, 11.14it/s] 86%|████████▌ | 511/595 [00:50<00:07, 11.16it/s] 86%|████████▌ | 513/595 [00:50<00:07, 11.18it/s] 87%|████████▋ | 515/595 [00:50<00:07, 11.18it/s] 87%|████████▋ | 517/595 [00:51<00:06, 11.19it/s] 87%|████████▋ | 519/595 [00:51<00:06, 11.19it/s] 88%|████████▊ | 521/595 [00:51<00:06, 11.19it/s] 88%|████████▊ | 523/595 [00:51<00:06, 11.19it/s] 88%|████████▊ | 525/595 [00:51<00:06, 11.19it/s] 89%|████████▊ | 527/595 [00:51<00:06, 11.21it/s] 89%|████████▉ | 529/595 [00:52<00:05, 11.22it/s] 89%|████████▉ | 531/595 [00:52<00:05, 11.22it/s] 90%|████████▉ | 533/595 [00:52<00:05, 11.20it/s] 90%|████████▉ | 535/595 [00:52<00:05, 11.20it/s] 90%|█████████ | 537/595 [00:52<00:05, 11.19it/s] 91%|█████████ | 539/595 [00:53<00:05, 11.19it/s] 91%|█████████ | 541/595 [00:53<00:04, 11.19it/s] 91%|█████████▏| 543/595 [00:53<00:04, 11.20it/s] 92%|█████████▏| 545/595 [00:53<00:04, 11.19it/s] 92%|█████████▏| 547/595 [00:53<00:04, 11.19it/s] 92%|█████████▏| 549/595 [00:53<00:04, 11.19it/s] 93%|█████████▎| 551/595 [00:54<00:03, 11.20it/s] 93%|█████████▎| 553/595 [00:54<00:03, 11.21it/s] 93%|█████████▎| 555/595 [00:54<00:03, 11.21it/s] 94%|█████████▎| 557/595 [00:54<00:03, 11.22it/s] 94%|█████████▍| 559/595 [00:54<00:03, 11.20it/s] 94%|█████████▍| 561/595 [00:55<00:03, 11.20it/s] 95%|█████████▍| 563/595 [00:55<00:02, 11.19it/s] 95%|█████████▍| 565/595 [00:55<00:02, 11.19it/s] 95%|█████████▌| 567/595 [00:55<00:02, 11.19it/s] 96%|█████████▌| 569/595 [00:55<00:02, 11.20it/s] 96%|█████████▌| 571/595 [00:55<00:02, 11.19it/s] 96%|█████████▋| 573/595 [00:56<00:01, 11.18it/s] 97%|█████████▋| 575/595 [00:56<00:01, 11.19it/s] 97%|█████████▋| 577/595 [00:56<00:01, 11.19it/s] 97%|█████████▋| 579/595 [00:56<00:01, 11.18it/s] 98%|█████████▊| 581/595 [00:56<00:01, 11.18it/s] 98%|█████████▊| 583/595 [00:56<00:01, 11.19it/s] 98%|█████████▊| 585/595 [00:57<00:00, 11.20it/s] 99%|█████████▊| 587/595 [00:57<00:00, 11.21it/s] 99%|█████████▉| 589/595 [00:57<00:00, 11.20it/s] 99%|█████████▉| 591/595 [00:57<00:00, 11.19it/s]100%|█████████▉| 593/595 [00:57<00:00, 11.18it/s]100%|██████████| 595/595 [00:57<00:00, 12.46it/s]                                                 100%|██████████| 595/595 [00:58<00:00, 12.46it/s][INFO|trainer.py:755] 2023-11-15 19:55:41,590 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:55:41,591 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:55:41,592 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:55:41,592 >>   Batch size = 8
{'eval_loss': 0.4555298388004303, 'eval_accuracy': 0.8391534391534392, 'eval_micro_f1': 0.8391534391534392, 'eval_macro_f1': 0.7643997620790822, 'eval_runtime': 1.1206, 'eval_samples_per_second': 843.279, 'eval_steps_per_second': 106.191, 'epoch': 4.0}
{'loss': 0.2015, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 122.04it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 114.82it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 112.35it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 111.30it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 110.61it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 110.07it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 109.63it/s][A
 82%|████████▏ | 97/119 [00:00<00:00, 108.86it/s][A
 91%|█████████ | 108/119 [00:00<00:00, 107.57it/s][A
100%|██████████| 119/119 [00:01<00:00, 108.23it/s][A                                                 
                                                  [A100%|██████████| 595/595 [00:59<00:00, 12.46it/s]
100%|██████████| 119/119 [00:01<00:00, 108.23it/s][A
                                                  [A[INFO|trainer.py:1963] 2023-11-15 19:55:42,722 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [00:59<00:00, 12.46it/s]100%|██████████| 595/595 [00:59<00:00, 10.06it/s]
[INFO|trainer.py:2855] 2023-11-15 19:55:42,726 >> Saving model checkpoint to ./result/restaurant_bert-base-cased_adapter__seed1
[INFO|configuration_utils.py:460] 2023-11-15 19:55:42,729 >> Configuration saved in ./result/restaurant_bert-base-cased_adapter__seed1/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:55:43,910 >> Model weights saved in ./result/restaurant_bert-base-cased_adapter__seed1/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:55:43,912 >> tokenizer config file saved in ./result/restaurant_bert-base-cased_adapter__seed1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:55:43,915 >> Special tokens file saved in ./result/restaurant_bert-base-cased_adapter__seed1/special_tokens_map.json
{'eval_loss': 0.4557267129421234, 'eval_accuracy': 0.8412698412698413, 'eval_micro_f1': 0.8412698412698413, 'eval_macro_f1': 0.7690611279972982, 'eval_runtime': 1.1272, 'eval_samples_per_second': 838.398, 'eval_steps_per_second': 105.576, 'epoch': 5.0}
{'train_runtime': 59.1423, 'train_samples_per_second': 319.315, 'train_steps_per_second': 10.06, 'train_loss': 0.4240163306228253, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =      0.424
  train_runtime            = 0:00:59.14
  train_samples            =       3777
  train_samples_per_second =    319.315
  train_steps_per_second   =      10.06
11/15/2023 19:55:43 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:55:43,956 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:55:43,958 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:55:43,958 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:55:43,959 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s] 11%|█         | 13/119 [00:00<00:00, 120.68it/s] 22%|██▏       | 26/119 [00:00<00:00, 112.84it/s] 32%|███▏      | 38/119 [00:00<00:00, 110.53it/s] 42%|████▏     | 50/119 [00:00<00:00, 109.55it/s] 51%|█████▏    | 61/119 [00:00<00:00, 108.93it/s] 61%|██████    | 72/119 [00:00<00:00, 108.51it/s] 70%|██████▉   | 83/119 [00:00<00:00, 107.96it/s] 79%|███████▉  | 94/119 [00:00<00:00, 107.74it/s] 88%|████████▊ | 105/119 [00:00<00:00, 106.83it/s] 97%|█████████▋| 116/119 [00:01<00:00, 106.64it/s]100%|██████████| 119/119 [00:01<00:00, 105.84it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8413
  eval_loss               =     0.4557
  eval_macro_f1           =     0.7691
  eval_micro_f1           =     0.8413
  eval_runtime            = 0:00:01.13
  eval_samples            =        945
  eval_samples_per_second =    831.286
  eval_steps_per_second   =     104.68
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▄▇███
wandb:                      eval/loss █▄▁▂▂▂
wandb:                  eval/macro_f1 ▁▆▇███
wandb:                  eval/micro_f1 ▁▄▇███
wandb:                   eval/runtime ▁▃▄▅▆█
wandb:        eval/samples_per_second █▆▅▄▃▁
wandb:          eval/steps_per_second █▆▅▄▃▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.84127
wandb:                      eval/loss 0.45573
wandb:                  eval/macro_f1 0.76906
wandb:                  eval/micro_f1 0.84127
wandb:                   eval/runtime 1.1368
wandb:        eval/samples_per_second 831.286
wandb:          eval/steps_per_second 104.68
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.2015
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.42402
wandb:            train/train_runtime 59.1423
wandb: train/train_samples_per_second 319.315
wandb:   train/train_steps_per_second 10.06
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_195356-8z6jtujf
wandb: Find logs at: ./wandb/offline-run-20231115_195356-8z6jtujf/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1/runs/Nov15_19-55-56_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:55:56 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:55:56 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1/runs/Nov15_19-55-55_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  86%|████████▌ | 4041/4722 [00:00<00:00, 40192.04 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 39611.64 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 19:56:12,070 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:56:12,082 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 19:56:22,100 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 19:56:32,963 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:56:32,964 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:56:53,006 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:56:53,006 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:56:53,007 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:56:53,007 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:56:53,007 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 19:56:53,008 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:56:53,009 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 19:56:53,032 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:56:53,033 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:57:13,184 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 19:57:14,861 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:57:14,862 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset:  79%|███████▉  | 3000/3777 [00:00<00:00, 21652.08 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 21740.88 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 26206.08 examples/s]
11/15/2023 19:57:15 - INFO - __main__ - Sample 3190 of the training set: {'text': 'priced <SEP> The food is great and reasonably priced.', 'label': 0, 'input_ids': [102, 4048, 30118, 962, 9892, 1374, 111, 2599, 165, 2815, 137, 13520, 4048, 30118, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:57:15 - INFO - __main__ - Sample 441 of the training set: {'text': 'dhosas <SEP> I like the somosas, chai, and the chole, but the dhosas and dhal were kinda dissapointing.', 'label': 2, 'input_ids': [102, 8078, 4591, 30113, 962, 9892, 1374, 259, 1967, 111, 7856, 4591, 30113, 422, 7683, 30109, 422, 137, 111, 8104, 30107, 422, 563, 111, 8078, 4591, 30113, 137, 22236, 30115, 267, 3433, 30110, 2681, 230, 1944, 140, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:57:15 - INFO - __main__ - Sample 963 of the training set: {'text': 'beef carpaachio <SEP> Service was warm and attentive, beef carpaachio was exellent (huge portion) and pasta was fresh and well-prepared.', 'label': 0, 'input_ids': [102, 21721, 17328, 27273, 4481, 30112, 962, 9892, 1374, 2289, 241, 8591, 137, 2570, 345, 422, 21721, 17328, 27273, 4481, 30112, 241, 199, 7639, 30108, 145, 11812, 6492, 546, 137, 3648, 30110, 241, 5893, 137, 804, 579, 4092, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:57:15 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:57:16,192 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:57:16,201 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:57:16,201 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 19:57:16,201 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:57:16,202 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:57:16,202 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:57:16,202 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:57:16,203 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 19:57:16,203 >>   Number of trainable parameters = 109,920,771
[INFO|integration_utils.py:716] 2023-11-15 19:57:16,204 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<11:40,  1.18s/it]  1%|          | 3/595 [00:01<03:39,  2.70it/s]  1%|          | 5/595 [00:01<02:13,  4.43it/s]  1%|          | 7/595 [00:01<01:38,  5.95it/s]  2%|▏         | 9/595 [00:01<01:20,  7.24it/s]  2%|▏         | 11/595 [00:02<01:10,  8.28it/s]  2%|▏         | 13/595 [00:02<01:04,  9.08it/s]  3%|▎         | 15/595 [00:02<00:59,  9.69it/s]  3%|▎         | 17/595 [00:02<00:56, 10.15it/s]  3%|▎         | 19/595 [00:02<00:54, 10.48it/s]  4%|▎         | 21/595 [00:02<00:53, 10.69it/s]  4%|▍         | 23/595 [00:03<00:52, 10.88it/s]  4%|▍         | 25/595 [00:03<00:51, 11.01it/s]  5%|▍         | 27/595 [00:03<00:51, 11.09it/s]  5%|▍         | 29/595 [00:03<00:50, 11.14it/s]  5%|▌         | 31/595 [00:03<00:50, 11.19it/s]  6%|▌         | 33/595 [00:04<00:50, 11.23it/s]  6%|▌         | 35/595 [00:04<00:49, 11.24it/s]  6%|▌         | 37/595 [00:04<00:49, 11.25it/s]  7%|▋         | 39/595 [00:04<00:49, 11.26it/s]  7%|▋         | 41/595 [00:04<00:49, 11.27it/s]  7%|▋         | 43/595 [00:04<00:48, 11.27it/s]  8%|▊         | 45/595 [00:05<00:48, 11.27it/s]  8%|▊         | 47/595 [00:05<00:48, 11.27it/s]  8%|▊         | 49/595 [00:05<00:48, 11.29it/s]  9%|▊         | 51/595 [00:05<00:48, 11.30it/s]  9%|▉         | 53/595 [00:05<00:47, 11.32it/s]  9%|▉         | 55/595 [00:05<00:47, 11.32it/s] 10%|▉         | 57/595 [00:06<00:47, 11.31it/s] 10%|▉         | 59/595 [00:06<00:47, 11.34it/s] 10%|█         | 61/595 [00:06<00:47, 11.33it/s] 11%|█         | 63/595 [00:06<00:46, 11.33it/s] 11%|█         | 65/595 [00:06<00:46, 11.36it/s] 11%|█▏        | 67/595 [00:07<00:46, 11.35it/s] 12%|█▏        | 69/595 [00:07<00:46, 11.35it/s] 12%|█▏        | 71/595 [00:07<00:46, 11.34it/s] 12%|█▏        | 73/595 [00:07<00:45, 11.35it/s] 13%|█▎        | 75/595 [00:07<00:45, 11.36it/s] 13%|█▎        | 77/595 [00:07<00:45, 11.37it/s] 13%|█▎        | 79/595 [00:08<00:45, 11.36it/s] 14%|█▎        | 81/595 [00:08<00:45, 11.35it/s] 14%|█▍        | 83/595 [00:08<00:45, 11.33it/s] 14%|█▍        | 85/595 [00:08<00:44, 11.34it/s] 15%|█▍        | 87/595 [00:08<00:44, 11.36it/s] 15%|█▍        | 89/595 [00:08<00:44, 11.35it/s] 15%|█▌        | 91/595 [00:09<00:44, 11.35it/s] 16%|█▌        | 93/595 [00:09<00:44, 11.35it/s] 16%|█▌        | 95/595 [00:09<00:43, 11.37it/s] 16%|█▋        | 97/595 [00:09<00:43, 11.34it/s] 17%|█▋        | 99/595 [00:09<00:43, 11.34it/s] 17%|█▋        | 101/595 [00:10<00:43, 11.36it/s] 17%|█▋        | 103/595 [00:10<00:43, 11.36it/s] 18%|█▊        | 105/595 [00:10<00:43, 11.35it/s] 18%|█▊        | 107/595 [00:10<00:42, 11.37it/s] 18%|█▊        | 109/595 [00:10<00:42, 11.36it/s] 19%|█▊        | 111/595 [00:10<00:42, 11.36it/s] 19%|█▉        | 113/595 [00:11<00:42, 11.33it/s] 19%|█▉        | 115/595 [00:11<00:42, 11.33it/s] 20%|█▉        | 117/595 [00:11<00:42, 11.34it/s] 20%|██        | 119/595 [00:11<00:38, 12.48it/s]                                                  20%|██        | 119/595 [00:11<00:38, 12.48it/s][INFO|trainer.py:755] 2023-11-15 19:57:27,763 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:57:27,765 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:57:27,765 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:57:27,766 >>   Batch size = 8
{'loss': 0.724, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 124.57it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 117.70it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 115.31it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 114.19it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 113.21it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 112.85it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 112.56it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 112.01it/s][A
 92%|█████████▏| 110/119 [00:00<00:00, 111.06it/s][A                                                 
                                                  [A 20%|██        | 119/595 [00:12<00:38, 12.48it/s]
100%|██████████| 119/119 [00:01<00:00, 111.06it/s][A
                                                  [A 20%|██        | 121/595 [00:12<01:57,  4.02it/s] 21%|██        | 123/595 [00:13<01:34,  4.98it/s] 21%|██        | 125/595 [00:13<01:18,  5.99it/s] 21%|██▏       | 127/595 [00:13<01:07,  6.98it/s] 22%|██▏       | 129/595 [00:13<00:59,  7.89it/s] 22%|██▏       | 131/595 [00:13<00:53,  8.68it/s] 22%|██▏       | 133/595 [00:13<00:49,  9.33it/s] 23%|██▎       | 135/595 [00:14<00:46,  9.86it/s] 23%|██▎       | 137/595 [00:14<00:44, 10.26it/s] 23%|██▎       | 139/595 [00:14<00:43, 10.57it/s] 24%|██▎       | 141/595 [00:14<00:42, 10.79it/s] 24%|██▍       | 143/595 [00:14<00:41, 10.95it/s] 24%|██▍       | 145/595 [00:14<00:40, 11.06it/s] 25%|██▍       | 147/595 [00:15<00:40, 11.14it/s] 25%|██▌       | 149/595 [00:15<00:39, 11.21it/s] 25%|██▌       | 151/595 [00:15<00:39, 11.24it/s] 26%|██▌       | 153/595 [00:15<00:39, 11.28it/s] 26%|██▌       | 155/595 [00:15<00:38, 11.29it/s] 26%|██▋       | 157/595 [00:16<00:38, 11.31it/s] 27%|██▋       | 159/595 [00:16<00:38, 11.33it/s] 27%|██▋       | 161/595 [00:16<00:38, 11.34it/s] 27%|██▋       | 163/595 [00:16<00:38, 11.33it/s] 28%|██▊       | 165/595 [00:16<00:37, 11.32it/s] 28%|██▊       | 167/595 [00:16<00:37, 11.30it/s] 28%|██▊       | 169/595 [00:17<00:37, 11.30it/s] 29%|██▊       | 171/595 [00:17<00:37, 11.30it/s] 29%|██▉       | 173/595 [00:17<00:37, 11.32it/s] 29%|██▉       | 175/595 [00:17<00:37, 11.32it/s] 30%|██▉       | 177/595 [00:17<00:36, 11.31it/s] 30%|███       | 179/595 [00:17<00:36, 11.30it/s] 30%|███       | 181/595 [00:18<00:36, 11.32it/s] 31%|███       | 183/595 [00:18<00:36, 11.32it/s] 31%|███       | 185/595 [00:18<00:36, 11.34it/s] 31%|███▏      | 187/595 [00:18<00:36, 11.30it/s] 32%|███▏      | 189/595 [00:18<00:35, 11.31it/s] 32%|███▏      | 191/595 [00:19<00:35, 11.31it/s] 32%|███▏      | 193/595 [00:19<00:35, 11.31it/s] 33%|███▎      | 195/595 [00:19<00:35, 11.30it/s] 33%|███▎      | 197/595 [00:19<00:35, 11.31it/s] 33%|███▎      | 199/595 [00:19<00:35, 11.30it/s] 34%|███▍      | 201/595 [00:19<00:34, 11.29it/s] 34%|███▍      | 203/595 [00:20<00:34, 11.30it/s] 34%|███▍      | 205/595 [00:20<00:34, 11.31it/s] 35%|███▍      | 207/595 [00:20<00:34, 11.30it/s] 35%|███▌      | 209/595 [00:20<00:34, 11.31it/s] 35%|███▌      | 211/595 [00:20<00:33, 11.32it/s] 36%|███▌      | 213/595 [00:20<00:33, 11.32it/s] 36%|███▌      | 215/595 [00:21<00:33, 11.33it/s] 36%|███▋      | 217/595 [00:21<00:33, 11.33it/s] 37%|███▋      | 219/595 [00:21<00:33, 11.32it/s] 37%|███▋      | 221/595 [00:21<00:33, 11.32it/s] 37%|███▋      | 223/595 [00:21<00:32, 11.32it/s] 38%|███▊      | 225/595 [00:22<00:32, 11.32it/s] 38%|███▊      | 227/595 [00:22<00:32, 11.32it/s] 38%|███▊      | 229/595 [00:22<00:32, 11.32it/s] 39%|███▉      | 231/595 [00:22<00:32, 11.31it/s] 39%|███▉      | 233/595 [00:22<00:32, 11.30it/s] 39%|███▉      | 235/595 [00:22<00:31, 11.32it/s] 40%|███▉      | 237/595 [00:23<00:31, 11.37it/s]                                                  40%|████      | 238/595 [00:23<00:31, 11.37it/s][INFO|trainer.py:755] 2023-11-15 19:57:39,322 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:57:39,324 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:57:39,325 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:57:39,325 >>   Batch size = 8
{'eval_loss': 0.5346671938896179, 'eval_accuracy': 0.780952380952381, 'eval_micro_f1': 0.780952380952381, 'eval_macro_f1': 0.6797098088993331, 'eval_runtime': 1.0973, 'eval_samples_per_second': 861.213, 'eval_steps_per_second': 108.449, 'epoch': 1.0}
{'loss': 0.4279, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 124.19it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 116.81it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 114.89it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 113.81it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 113.09it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 112.61it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 112.37it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 111.76it/s][A
 92%|█████████▏| 110/119 [00:00<00:00, 110.61it/s][A                                                 
                                                  [A 40%|████      | 238/595 [00:24<00:31, 11.37it/s]
100%|██████████| 119/119 [00:01<00:00, 110.61it/s][A
                                                  [A 40%|████      | 239/595 [00:24<01:27,  4.06it/s] 41%|████      | 241/595 [00:24<01:10,  5.01it/s] 41%|████      | 243/595 [00:24<00:58,  6.02it/s] 41%|████      | 245/595 [00:24<00:49,  7.00it/s] 42%|████▏     | 247/595 [00:25<00:43,  7.91it/s] 42%|████▏     | 249/595 [00:25<00:39,  8.68it/s] 42%|████▏     | 251/595 [00:25<00:36,  9.34it/s] 43%|████▎     | 253/595 [00:25<00:34,  9.86it/s] 43%|████▎     | 255/595 [00:25<00:33, 10.26it/s] 43%|████▎     | 257/595 [00:25<00:31, 10.56it/s] 44%|████▎     | 259/595 [00:26<00:31, 10.80it/s] 44%|████▍     | 261/595 [00:26<00:30, 10.94it/s] 44%|████▍     | 263/595 [00:26<00:30, 11.05it/s] 45%|████▍     | 265/595 [00:26<00:29, 11.13it/s] 45%|████▍     | 267/595 [00:26<00:29, 11.19it/s] 45%|████▌     | 269/595 [00:26<00:29, 11.24it/s] 46%|████▌     | 271/595 [00:27<00:28, 11.27it/s] 46%|████▌     | 273/595 [00:27<00:28, 11.30it/s] 46%|████▌     | 275/595 [00:27<00:28, 11.30it/s] 47%|████▋     | 277/595 [00:27<00:28, 11.32it/s] 47%|████▋     | 279/595 [00:27<00:27, 11.31it/s] 47%|████▋     | 281/595 [00:28<00:27, 11.33it/s] 48%|████▊     | 283/595 [00:28<00:27, 11.33it/s] 48%|████▊     | 285/595 [00:28<00:27, 11.32it/s] 48%|████▊     | 287/595 [00:28<00:27, 11.31it/s] 49%|████▊     | 289/595 [00:28<00:27, 11.31it/s] 49%|████▉     | 291/595 [00:28<00:26, 11.30it/s] 49%|████▉     | 293/595 [00:29<00:26, 11.30it/s] 50%|████▉     | 295/595 [00:29<00:26, 11.29it/s] 50%|████▉     | 297/595 [00:29<00:26, 11.29it/s] 50%|█████     | 299/595 [00:29<00:26, 11.30it/s] 51%|█████     | 301/595 [00:29<00:26, 11.30it/s] 51%|█████     | 303/595 [00:29<00:25, 11.30it/s] 51%|█████▏    | 305/595 [00:30<00:25, 11.30it/s] 52%|█████▏    | 307/595 [00:30<00:25, 11.30it/s] 52%|█████▏    | 309/595 [00:30<00:25, 11.30it/s] 52%|█████▏    | 311/595 [00:30<00:25, 11.28it/s] 53%|█████▎    | 313/595 [00:30<00:24, 11.30it/s] 53%|█████▎    | 315/595 [00:31<00:24, 11.31it/s] 53%|█████▎    | 317/595 [00:31<00:24, 11.30it/s] 54%|█████▎    | 319/595 [00:31<00:24, 11.30it/s] 54%|█████▍    | 321/595 [00:31<00:24, 11.28it/s] 54%|█████▍    | 323/595 [00:31<00:24, 11.29it/s] 55%|█████▍    | 325/595 [00:31<00:23, 11.27it/s] 55%|█████▍    | 327/595 [00:32<00:23, 11.29it/s] 55%|█████▌    | 329/595 [00:32<00:23, 11.28it/s] 56%|█████▌    | 331/595 [00:32<00:23, 11.30it/s] 56%|█████▌    | 333/595 [00:32<00:23, 11.30it/s] 56%|█████▋    | 335/595 [00:32<00:22, 11.32it/s] 57%|█████▋    | 337/595 [00:32<00:22, 11.33it/s] 57%|█████▋    | 339/595 [00:33<00:22, 11.31it/s] 57%|█████▋    | 341/595 [00:33<00:22, 11.30it/s] 58%|█████▊    | 343/595 [00:33<00:22, 11.31it/s] 58%|█████▊    | 345/595 [00:33<00:22, 11.31it/s] 58%|█████▊    | 347/595 [00:33<00:21, 11.30it/s] 59%|█████▊    | 349/595 [00:34<00:21, 11.31it/s] 59%|█████▉    | 351/595 [00:34<00:21, 11.30it/s] 59%|█████▉    | 353/595 [00:34<00:21, 11.31it/s] 60%|█████▉    | 355/595 [00:34<00:21, 11.29it/s] 60%|██████    | 357/595 [00:34<00:18, 12.60it/s]                                                  60%|██████    | 357/595 [00:34<00:18, 12.60it/s][INFO|trainer.py:755] 2023-11-15 19:57:50,900 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:57:50,902 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:57:50,902 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:57:50,903 >>   Batch size = 8
{'eval_loss': 0.4912623465061188, 'eval_accuracy': 0.8052910052910053, 'eval_micro_f1': 0.8052910052910053, 'eval_macro_f1': 0.7363943765520653, 'eval_runtime': 1.1036, 'eval_samples_per_second': 856.308, 'eval_steps_per_second': 107.831, 'epoch': 2.0}
{'loss': 0.2855, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 124.26it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 116.99it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 114.77it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 113.37it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 112.52it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 111.67it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 111.14it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 110.61it/s][A
 92%|█████████▏| 110/119 [00:00<00:00, 109.61it/s][A                                                 
                                                  [A 60%|██████    | 357/595 [00:35<00:18, 12.60it/s]
100%|██████████| 119/119 [00:01<00:00, 109.61it/s][A
                                                  [A 60%|██████    | 359/595 [00:35<00:59,  3.99it/s] 61%|██████    | 361/595 [00:36<00:47,  4.94it/s] 61%|██████    | 363/595 [00:36<00:39,  5.94it/s] 61%|██████▏   | 365/595 [00:36<00:33,  6.92it/s] 62%|██████▏   | 367/595 [00:36<00:29,  7.83it/s] 62%|██████▏   | 369/595 [00:36<00:26,  8.63it/s] 62%|██████▏   | 371/595 [00:37<00:24,  9.28it/s] 63%|██████▎   | 373/595 [00:37<00:22,  9.79it/s] 63%|██████▎   | 375/595 [00:37<00:21, 10.19it/s] 63%|██████▎   | 377/595 [00:37<00:20, 10.49it/s] 64%|██████▎   | 379/595 [00:37<00:20, 10.71it/s] 64%|██████▍   | 381/595 [00:37<00:19, 10.87it/s] 64%|██████▍   | 383/595 [00:38<00:19, 11.00it/s] 65%|██████▍   | 385/595 [00:38<00:18, 11.09it/s] 65%|██████▌   | 387/595 [00:38<00:18, 11.14it/s] 65%|██████▌   | 389/595 [00:38<00:18, 11.17it/s] 66%|██████▌   | 391/595 [00:38<00:18, 11.21it/s] 66%|██████▌   | 393/595 [00:39<00:18, 11.22it/s] 66%|██████▋   | 395/595 [00:39<00:17, 11.22it/s] 67%|██████▋   | 397/595 [00:39<00:17, 11.24it/s] 67%|██████▋   | 399/595 [00:39<00:17, 11.25it/s] 67%|██████▋   | 401/595 [00:39<00:17, 11.26it/s] 68%|██████▊   | 403/595 [00:39<00:17, 11.26it/s] 68%|██████▊   | 405/595 [00:40<00:16, 11.25it/s] 68%|██████▊   | 407/595 [00:40<00:16, 11.25it/s] 69%|██████▊   | 409/595 [00:40<00:16, 11.26it/s] 69%|██████▉   | 411/595 [00:40<00:16, 11.26it/s] 69%|██████▉   | 413/595 [00:40<00:16, 11.25it/s] 70%|██████▉   | 415/595 [00:40<00:15, 11.26it/s] 70%|███████   | 417/595 [00:41<00:15, 11.26it/s] 70%|███████   | 419/595 [00:41<00:15, 11.26it/s] 71%|███████   | 421/595 [00:41<00:15, 11.26it/s] 71%|███████   | 423/595 [00:41<00:15, 11.25it/s] 71%|███████▏  | 425/595 [00:41<00:15, 11.25it/s] 72%|███████▏  | 427/595 [00:42<00:14, 11.25it/s] 72%|███████▏  | 429/595 [00:42<00:14, 11.25it/s] 72%|███████▏  | 431/595 [00:42<00:14, 11.25it/s] 73%|███████▎  | 433/595 [00:42<00:14, 11.26it/s] 73%|███████▎  | 435/595 [00:42<00:14, 11.25it/s] 73%|███████▎  | 437/595 [00:42<00:14, 11.27it/s] 74%|███████▍  | 439/595 [00:43<00:13, 11.26it/s] 74%|███████▍  | 441/595 [00:43<00:13, 11.25it/s] 74%|███████▍  | 443/595 [00:43<00:13, 11.25it/s] 75%|███████▍  | 445/595 [00:43<00:13, 11.26it/s] 75%|███████▌  | 447/595 [00:43<00:13, 11.24it/s] 75%|███████▌  | 449/595 [00:43<00:13, 11.20it/s] 76%|███████▌  | 451/595 [00:44<00:12, 11.21it/s] 76%|███████▌  | 453/595 [00:44<00:12, 11.22it/s] 76%|███████▋  | 455/595 [00:44<00:12, 11.20it/s] 77%|███████▋  | 457/595 [00:44<00:12, 11.22it/s] 77%|███████▋  | 459/595 [00:44<00:12, 11.23it/s] 77%|███████▋  | 461/595 [00:45<00:11, 11.23it/s] 78%|███████▊  | 463/595 [00:45<00:11, 11.22it/s] 78%|███████▊  | 465/595 [00:45<00:11, 11.22it/s] 78%|███████▊  | 467/595 [00:45<00:11, 11.23it/s] 79%|███████▉  | 469/595 [00:45<00:11, 11.24it/s] 79%|███████▉  | 471/595 [00:45<00:11, 11.23it/s] 79%|███████▉  | 473/595 [00:46<00:10, 11.23it/s] 80%|███████▉  | 475/595 [00:46<00:10, 11.28it/s]                                                  80%|████████  | 476/595 [00:46<00:10, 11.28it/s][INFO|trainer.py:755] 2023-11-15 19:58:02,540 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:58:02,542 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:58:02,542 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:58:02,542 >>   Batch size = 8
{'eval_loss': 0.4604700803756714, 'eval_accuracy': 0.8306878306878307, 'eval_micro_f1': 0.8306878306878307, 'eval_macro_f1': 0.7595655993903317, 'eval_runtime': 1.1087, 'eval_samples_per_second': 852.319, 'eval_steps_per_second': 107.329, 'epoch': 3.0}
{'loss': 0.1812, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 124.06it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 116.23it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 113.91it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 112.87it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 112.14it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 111.13it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 110.31it/s][A
 82%|████████▏ | 98/119 [00:00<00:00, 109.83it/s][A
 92%|█████████▏| 109/119 [00:00<00:00, 108.53it/s][A                                                 
                                                  [A 80%|████████  | 476/595 [00:47<00:10, 11.28it/s]
100%|██████████| 119/119 [00:01<00:00, 108.53it/s][A
                                                  [A 80%|████████  | 477/595 [00:47<00:29,  4.02it/s] 81%|████████  | 479/595 [00:47<00:23,  4.97it/s] 81%|████████  | 481/595 [00:47<00:19,  5.96it/s] 81%|████████  | 483/595 [00:48<00:16,  6.93it/s] 82%|████████▏ | 485/595 [00:48<00:14,  7.83it/s] 82%|████████▏ | 487/595 [00:48<00:12,  8.61it/s] 82%|████████▏ | 489/595 [00:48<00:11,  9.26it/s] 83%|████████▎ | 491/595 [00:48<00:10,  9.78it/s] 83%|████████▎ | 493/595 [00:48<00:10, 10.15it/s] 83%|████████▎ | 495/595 [00:49<00:09, 10.43it/s] 84%|████████▎ | 497/595 [00:49<00:09, 10.65it/s] 84%|████████▍ | 499/595 [00:49<00:08, 10.81it/s] 84%|████████▍ | 501/595 [00:49<00:08, 10.95it/s] 85%|████████▍ | 503/595 [00:49<00:08, 11.05it/s] 85%|████████▍ | 505/595 [00:50<00:08, 11.10it/s] 85%|████████▌ | 507/595 [00:50<00:07, 11.13it/s] 86%|████████▌ | 509/595 [00:50<00:07, 11.17it/s] 86%|████████▌ | 511/595 [00:50<00:07, 11.20it/s] 86%|████████▌ | 513/595 [00:50<00:07, 11.20it/s] 87%|████████▋ | 515/595 [00:50<00:07, 11.20it/s] 87%|████████▋ | 517/595 [00:51<00:06, 11.20it/s] 87%|████████▋ | 519/595 [00:51<00:06, 11.19it/s] 88%|████████▊ | 521/595 [00:51<00:06, 11.20it/s] 88%|████████▊ | 523/595 [00:51<00:06, 11.20it/s] 88%|████████▊ | 525/595 [00:51<00:06, 11.22it/s] 89%|████████▊ | 527/595 [00:51<00:06, 11.21it/s] 89%|████████▉ | 529/595 [00:52<00:05, 11.21it/s] 89%|████████▉ | 531/595 [00:52<00:05, 11.21it/s] 90%|████████▉ | 533/595 [00:52<00:05, 11.21it/s] 90%|████████▉ | 535/595 [00:52<00:05, 11.21it/s] 90%|█████████ | 537/595 [00:52<00:05, 11.21it/s] 91%|█████████ | 539/595 [00:53<00:04, 11.21it/s] 91%|█████████ | 541/595 [00:53<00:04, 11.22it/s] 91%|█████████▏| 543/595 [00:53<00:04, 11.21it/s] 92%|█████████▏| 545/595 [00:53<00:04, 11.22it/s] 92%|█████████▏| 547/595 [00:53<00:04, 11.23it/s] 92%|█████████▏| 549/595 [00:53<00:04, 11.21it/s] 93%|█████████▎| 551/595 [00:54<00:03, 11.22it/s] 93%|█████████▎| 553/595 [00:54<00:03, 11.23it/s] 93%|█████████▎| 555/595 [00:54<00:03, 11.21it/s] 94%|█████████▎| 557/595 [00:54<00:03, 11.18it/s] 94%|█████████▍| 559/595 [00:54<00:03, 11.18it/s] 94%|█████████▍| 561/595 [00:55<00:03, 11.19it/s] 95%|█████████▍| 563/595 [00:55<00:02, 11.17it/s] 95%|█████████▍| 565/595 [00:55<00:02, 11.18it/s] 95%|█████████▌| 567/595 [00:55<00:02, 11.19it/s] 96%|█████████▌| 569/595 [00:55<00:02, 11.21it/s] 96%|█████████▌| 571/595 [00:55<00:02, 11.20it/s] 96%|█████████▋| 573/595 [00:56<00:01, 11.19it/s] 97%|█████████▋| 575/595 [00:56<00:01, 11.20it/s] 97%|█████████▋| 577/595 [00:56<00:01, 11.20it/s] 97%|█████████▋| 579/595 [00:56<00:01, 11.20it/s] 98%|█████████▊| 581/595 [00:56<00:01, 11.20it/s] 98%|█████████▊| 583/595 [00:56<00:01, 11.20it/s] 98%|█████████▊| 585/595 [00:57<00:00, 11.20it/s] 99%|█████████▊| 587/595 [00:57<00:00, 11.18it/s] 99%|█████████▉| 589/595 [00:57<00:00, 11.18it/s] 99%|█████████▉| 591/595 [00:57<00:00, 11.19it/s]100%|█████████▉| 593/595 [00:57<00:00, 11.20it/s]100%|██████████| 595/595 [00:58<00:00, 12.50it/s]                                                 100%|██████████| 595/595 [00:58<00:00, 12.50it/s][INFO|trainer.py:755] 2023-11-15 19:58:14,225 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:58:14,226 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:58:14,226 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:58:14,227 >>   Batch size = 8
{'eval_loss': 0.5131469964981079, 'eval_accuracy': 0.8391534391534392, 'eval_micro_f1': 0.8391534391534392, 'eval_macro_f1': 0.7694046190479072, 'eval_runtime': 1.1138, 'eval_samples_per_second': 848.463, 'eval_steps_per_second': 106.843, 'epoch': 4.0}
{'loss': 0.1409, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
 11%|█         | 13/119 [00:00<00:00, 123.10it/s][A
 22%|██▏       | 26/119 [00:00<00:00, 115.48it/s][A
 32%|███▏      | 38/119 [00:00<00:00, 113.36it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 112.24it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 111.44it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 110.71it/s][A
 72%|███████▏  | 86/119 [00:00<00:00, 109.95it/s][A
 82%|████████▏ | 97/119 [00:00<00:00, 109.25it/s][A
 91%|█████████ | 108/119 [00:00<00:00, 108.18it/s][A                                                 
                                                  [A100%|██████████| 595/595 [00:59<00:00, 12.50it/s]
100%|██████████| 119/119 [00:01<00:00, 108.18it/s][A
                                                  [A[INFO|trainer.py:1963] 2023-11-15 19:58:15,349 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [00:59<00:00, 12.50it/s]100%|██████████| 595/595 [00:59<00:00, 10.06it/s]
[INFO|trainer.py:2855] 2023-11-15 19:58:15,353 >> Saving model checkpoint to ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1
[INFO|configuration_utils.py:460] 2023-11-15 19:58:15,356 >> Configuration saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 19:58:16,600 >> Model weights saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 19:58:16,602 >> tokenizer config file saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 19:58:16,605 >> Special tokens file saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed1/special_tokens_map.json
{'eval_loss': 0.5224369168281555, 'eval_accuracy': 0.8328042328042328, 'eval_micro_f1': 0.8328042328042328, 'eval_macro_f1': 0.7647080213483818, 'eval_runtime': 1.1195, 'eval_samples_per_second': 844.101, 'eval_steps_per_second': 106.294, 'epoch': 5.0}
{'train_runtime': 59.1462, 'train_samples_per_second': 319.293, 'train_steps_per_second': 10.06, 'train_loss': 0.3518873711594013, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3519
  train_runtime            = 0:00:59.14
  train_samples            =       3777
  train_samples_per_second =    319.293
  train_steps_per_second   =      10.06
11/15/2023 19:58:16 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 19:58:16,649 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 19:58:16,651 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 19:58:16,651 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 19:58:16,651 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s] 11%|█         | 13/119 [00:00<00:00, 120.69it/s] 22%|██▏       | 26/119 [00:00<00:00, 113.57it/s] 32%|███▏      | 38/119 [00:00<00:00, 111.58it/s] 42%|████▏     | 50/119 [00:00<00:00, 110.59it/s] 52%|█████▏    | 62/119 [00:00<00:00, 110.06it/s] 62%|██████▏   | 74/119 [00:00<00:00, 109.63it/s] 71%|███████▏  | 85/119 [00:00<00:00, 109.25it/s] 81%|████████  | 96/119 [00:00<00:00, 108.86it/s] 90%|████████▉ | 107/119 [00:00<00:00, 108.58it/s] 99%|█████████▉| 118/119 [00:01<00:00, 108.79it/s]100%|██████████| 119/119 [00:01<00:00, 107.13it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8328
  eval_loss               =     0.5224
  eval_macro_f1           =     0.7647
  eval_micro_f1           =     0.8328
  eval_runtime            = 0:00:01.12
  eval_samples            =        945
  eval_samples_per_second =    841.796
  eval_steps_per_second   =    106.004
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▄▇█▇▇
wandb:                      eval/loss █▄▁▆▇▇
wandb:                  eval/macro_f1 ▁▅▇███
wandb:                  eval/micro_f1 ▁▄▇█▇▇
wandb:                   eval/runtime ▁▃▄▆▇█
wandb:        eval/samples_per_second █▆▅▃▂▁
wandb:          eval/steps_per_second █▆▅▃▂▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▁▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.8328
wandb:                      eval/loss 0.52244
wandb:                  eval/macro_f1 0.76471
wandb:                  eval/micro_f1 0.8328
wandb:                   eval/runtime 1.1226
wandb:        eval/samples_per_second 841.796
wandb:          eval/steps_per_second 106.004
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1409
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.35189
wandb:            train/train_runtime 59.1462
wandb: train/train_samples_per_second 319.293
wandb:   train/train_steps_per_second 10.06
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_195557-ew7cz7jm
wandb: Find logs at: ./wandb/offline-run-20231115_195557-ew7cz7jm/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_roberta-base_adapter__seed1/runs/Nov15_19-58-29_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_roberta-base_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_roberta-base_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 19:58:29 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 19:58:29 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_roberta-base_adapter__seed1/runs/Nov15_19-58-28_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_roberta-base_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_roberta-base_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  38%|███▊      | 4136/11020 [00:00<00:00, 40842.97 examples/s]Map:  75%|███████▌  | 8311/11020 [00:00<00:00, 41366.90 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 40630.41 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 19:58:45,283 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:58:45,296 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 19:58:55,314 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 19:59:05,334 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:59:05,335 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:59:25,389 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:59:25,389 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:59:25,390 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:59:25,390 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:59:25,391 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 19:59:25,391 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 19:59:25,392 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 19:59:25,393 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 19:59:45,590 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 19:59:46,302 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 19:59:46,302 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  34%|███▍      | 3000/8816 [00:00<00:00, 19527.01 examples/s]Running tokenizer on dataset:  68%|██████▊   | 6000/8816 [00:00<00:00, 19822.50 examples/s]Running tokenizer on dataset:  91%|█████████ | 8000/8816 [00:00<00:00, 19844.21 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 19831.16 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 21852.25 examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 21519.97 examples/s]
11/15/2023 19:59:46 - INFO - __main__ - Sample 1767 of the training set: {'text': 'Second, HASM cells in culture, when observed between 3 and 6 h after plating, were not spindle shaped or aligned in parallel, as they are at the tissue level (5); instead, they were irregularly shaped (Fig.', 'label': 0, 'input_ids': [0, 32703, 6, 31963, 448, 4590, 11, 2040, 6, 77, 6373, 227, 155, 8, 231, 1368, 71, 2968, 1295, 6, 58, 45, 2292, 38969, 14216, 50, 14485, 11, 12980, 6, 25, 51, 32, 23, 5, 11576, 672, 36, 245, 4397, 1386, 6, 51, 58, 22937, 352, 14216, 36, 44105, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:59:46 - INFO - __main__ - Sample 3854 of the training set: {'text': 'Yet, allowing for interruptions might decrease classification accuracy [24] as well as making results vulnerable to variation in wear time if analyzed with different epoch lengths [37].', 'label': 0, 'input_ids': [0, 34995, 6, 2455, 13, 22749, 2485, 429, 7280, 20257, 8611, 646, 1978, 742, 25, 157, 25, 442, 775, 4478, 7, 21875, 11, 3568, 86, 114, 13773, 19, 430, 43660, 18915, 646, 3272, 8174, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:59:46 - INFO - __main__ - Sample 4652 of the training set: {'text': 'Examination of plaque formation and growth curves were performed by standard methods as previously described (10, 35).', 'label': 1, 'input_ids': [0, 9089, 41121, 9, 22054, 9285, 8, 434, 23739, 58, 3744, 30, 2526, 6448, 25, 1433, 1602, 36, 698, 6, 1718, 322, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 19:59:46 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 19:59:48,055 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 19:59:48,063 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 19:59:48,063 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 19:59:48,063 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 19:59:48,064 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 19:59:48,064 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 19:59:48,064 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 19:59:48,064 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 19:59:48,065 >>   Number of trainable parameters = 124,647,939
[INFO|integration_utils.py:716] 2023-11-15 19:59:48,066 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<24:59,  1.09s/it]  0%|          | 3/1380 [00:01<07:58,  2.88it/s]  0%|          | 5/1380 [00:01<04:55,  4.65it/s]  1%|          | 7/1380 [00:01<03:41,  6.19it/s]  1%|          | 9/1380 [00:01<03:04,  7.45it/s]  1%|          | 11/1380 [00:01<02:42,  8.42it/s]  1%|          | 13/1380 [00:02<02:29,  9.17it/s]  1%|          | 15/1380 [00:02<02:20,  9.73it/s]  1%|          | 17/1380 [00:02<02:14, 10.13it/s]  1%|▏         | 19/1380 [00:02<02:10, 10.42it/s]  2%|▏         | 21/1380 [00:02<02:07, 10.63it/s]  2%|▏         | 23/1380 [00:03<02:05, 10.78it/s]  2%|▏         | 25/1380 [00:03<02:04, 10.88it/s]  2%|▏         | 27/1380 [00:03<02:03, 10.95it/s]  2%|▏         | 29/1380 [00:03<02:02, 11.01it/s]  2%|▏         | 31/1380 [00:03<02:02, 11.04it/s]  2%|▏         | 33/1380 [00:03<02:02, 11.03it/s]  3%|▎         | 35/1380 [00:04<02:01, 11.05it/s]  3%|▎         | 37/1380 [00:04<02:01, 11.08it/s]  3%|▎         | 39/1380 [00:04<02:00, 11.09it/s]  3%|▎         | 41/1380 [00:04<02:00, 11.09it/s]  3%|▎         | 43/1380 [00:04<02:00, 11.10it/s]  3%|▎         | 45/1380 [00:05<02:00, 11.05it/s]  3%|▎         | 47/1380 [00:05<01:59, 11.13it/s]  4%|▎         | 49/1380 [00:05<01:59, 11.13it/s]  4%|▎         | 51/1380 [00:05<01:59, 11.14it/s]  4%|▍         | 53/1380 [00:05<01:59, 11.13it/s]  4%|▍         | 55/1380 [00:05<01:59, 11.11it/s]  4%|▍         | 57/1380 [00:06<01:58, 11.15it/s]  4%|▍         | 59/1380 [00:06<01:58, 11.14it/s]  4%|▍         | 61/1380 [00:06<01:58, 11.15it/s]  5%|▍         | 63/1380 [00:06<01:58, 11.13it/s]  5%|▍         | 65/1380 [00:06<01:58, 11.13it/s]  5%|▍         | 67/1380 [00:07<01:57, 11.14it/s]  5%|▌         | 69/1380 [00:07<01:57, 11.12it/s]  5%|▌         | 71/1380 [00:07<01:57, 11.12it/s]  5%|▌         | 73/1380 [00:07<01:57, 11.13it/s]  5%|▌         | 75/1380 [00:07<01:57, 11.14it/s]  6%|▌         | 77/1380 [00:07<01:57, 11.13it/s]  6%|▌         | 79/1380 [00:08<01:56, 11.13it/s]  6%|▌         | 81/1380 [00:08<01:56, 11.13it/s]  6%|▌         | 83/1380 [00:08<01:56, 11.12it/s]  6%|▌         | 85/1380 [00:08<01:56, 11.11it/s]  6%|▋         | 87/1380 [00:08<01:56, 11.12it/s]  6%|▋         | 89/1380 [00:08<01:55, 11.13it/s]  7%|▋         | 91/1380 [00:09<01:55, 11.12it/s]  7%|▋         | 93/1380 [00:09<01:55, 11.12it/s]  7%|▋         | 95/1380 [00:09<01:55, 11.11it/s]  7%|▋         | 97/1380 [00:09<01:55, 11.12it/s]  7%|▋         | 99/1380 [00:09<01:55, 11.12it/s]  7%|▋         | 101/1380 [00:10<01:55, 11.12it/s]  7%|▋         | 103/1380 [00:10<01:54, 11.11it/s]  8%|▊         | 105/1380 [00:10<01:54, 11.10it/s]  8%|▊         | 107/1380 [00:10<01:54, 11.10it/s]  8%|▊         | 109/1380 [00:10<01:54, 11.08it/s]  8%|▊         | 111/1380 [00:10<01:54, 11.10it/s]  8%|▊         | 113/1380 [00:11<01:54, 11.11it/s]  8%|▊         | 115/1380 [00:11<01:53, 11.10it/s]  8%|▊         | 117/1380 [00:11<01:53, 11.10it/s]  9%|▊         | 119/1380 [00:11<01:53, 11.11it/s]  9%|▉         | 121/1380 [00:11<01:53, 11.12it/s]  9%|▉         | 123/1380 [00:12<01:53, 11.07it/s]  9%|▉         | 125/1380 [00:12<01:53, 11.08it/s]  9%|▉         | 127/1380 [00:12<01:52, 11.10it/s]  9%|▉         | 129/1380 [00:12<01:53, 11.05it/s]  9%|▉         | 131/1380 [00:12<01:53, 11.05it/s] 10%|▉         | 133/1380 [00:12<01:52, 11.07it/s] 10%|▉         | 135/1380 [00:13<01:52, 11.07it/s] 10%|▉         | 137/1380 [00:13<01:51, 11.11it/s] 10%|█         | 139/1380 [00:13<01:51, 11.11it/s] 10%|█         | 141/1380 [00:13<01:51, 11.11it/s] 10%|█         | 143/1380 [00:13<01:51, 11.10it/s] 11%|█         | 145/1380 [00:14<01:51, 11.09it/s] 11%|█         | 147/1380 [00:14<01:51, 11.08it/s] 11%|█         | 149/1380 [00:14<01:51, 11.08it/s] 11%|█         | 151/1380 [00:14<01:50, 11.10it/s] 11%|█         | 153/1380 [00:14<01:50, 11.14it/s] 11%|█         | 155/1380 [00:14<01:49, 11.17it/s] 11%|█▏        | 157/1380 [00:15<01:49, 11.20it/s] 12%|█▏        | 159/1380 [00:15<01:48, 11.21it/s] 12%|█▏        | 161/1380 [00:15<01:49, 11.17it/s] 12%|█▏        | 163/1380 [00:15<01:48, 11.19it/s] 12%|█▏        | 165/1380 [00:15<01:48, 11.19it/s] 12%|█▏        | 167/1380 [00:16<01:48, 11.20it/s] 12%|█▏        | 169/1380 [00:16<01:48, 11.20it/s] 12%|█▏        | 171/1380 [00:16<01:48, 11.19it/s] 13%|█▎        | 173/1380 [00:16<01:47, 11.18it/s] 13%|█▎        | 175/1380 [00:16<01:47, 11.18it/s] 13%|█▎        | 177/1380 [00:16<01:47, 11.19it/s] 13%|█▎        | 179/1380 [00:17<01:47, 11.19it/s] 13%|█▎        | 181/1380 [00:17<01:47, 11.17it/s] 13%|█▎        | 183/1380 [00:17<01:47, 11.18it/s] 13%|█▎        | 185/1380 [00:17<01:46, 11.17it/s] 14%|█▎        | 187/1380 [00:17<01:47, 11.14it/s] 14%|█▎        | 189/1380 [00:17<01:46, 11.13it/s] 14%|█▍        | 191/1380 [00:18<01:46, 11.12it/s] 14%|█▍        | 193/1380 [00:18<01:46, 11.11it/s] 14%|█▍        | 195/1380 [00:18<01:46, 11.15it/s] 14%|█▍        | 197/1380 [00:18<01:46, 11.16it/s] 14%|█▍        | 199/1380 [00:18<01:45, 11.15it/s] 15%|█▍        | 201/1380 [00:19<01:45, 11.15it/s] 15%|█▍        | 203/1380 [00:19<01:45, 11.14it/s] 15%|█▍        | 205/1380 [00:19<01:45, 11.16it/s] 15%|█▌        | 207/1380 [00:19<01:44, 11.17it/s] 15%|█▌        | 209/1380 [00:19<01:44, 11.19it/s] 15%|█▌        | 211/1380 [00:19<01:44, 11.18it/s] 15%|█▌        | 213/1380 [00:20<01:44, 11.17it/s] 16%|█▌        | 215/1380 [00:20<01:44, 11.16it/s] 16%|█▌        | 217/1380 [00:20<01:44, 11.15it/s] 16%|█▌        | 219/1380 [00:20<01:44, 11.16it/s] 16%|█▌        | 221/1380 [00:20<01:43, 11.18it/s] 16%|█▌        | 223/1380 [00:21<01:43, 11.18it/s] 16%|█▋        | 225/1380 [00:21<01:43, 11.15it/s] 16%|█▋        | 227/1380 [00:21<01:43, 11.16it/s] 17%|█▋        | 229/1380 [00:21<01:43, 11.16it/s] 17%|█▋        | 231/1380 [00:21<01:42, 11.18it/s] 17%|█▋        | 233/1380 [00:21<01:42, 11.18it/s] 17%|█▋        | 235/1380 [00:22<01:42, 11.17it/s] 17%|█▋        | 237/1380 [00:22<01:42, 11.18it/s] 17%|█▋        | 239/1380 [00:22<01:42, 11.17it/s] 17%|█▋        | 241/1380 [00:22<01:42, 11.16it/s] 18%|█▊        | 243/1380 [00:22<01:41, 11.18it/s] 18%|█▊        | 245/1380 [00:22<01:41, 11.18it/s] 18%|█▊        | 247/1380 [00:23<01:41, 11.18it/s] 18%|█▊        | 249/1380 [00:23<01:41, 11.15it/s] 18%|█▊        | 251/1380 [00:23<01:41, 11.15it/s] 18%|█▊        | 253/1380 [00:23<01:40, 11.17it/s] 18%|█▊        | 255/1380 [00:23<01:40, 11.18it/s] 19%|█▊        | 257/1380 [00:24<01:40, 11.18it/s] 19%|█▉        | 259/1380 [00:24<01:40, 11.16it/s] 19%|█▉        | 261/1380 [00:24<01:40, 11.15it/s] 19%|█▉        | 263/1380 [00:24<01:40, 11.15it/s] 19%|█▉        | 265/1380 [00:24<01:39, 11.15it/s] 19%|█▉        | 267/1380 [00:24<01:39, 11.16it/s] 19%|█▉        | 269/1380 [00:25<01:39, 11.14it/s] 20%|█▉        | 271/1380 [00:25<01:39, 11.13it/s] 20%|█▉        | 273/1380 [00:25<01:39, 11.15it/s] 20%|█▉        | 275/1380 [00:25<01:38, 11.17it/s]                                                   20%|██        | 276/1380 [00:25<01:38, 11.17it/s][INFO|trainer.py:755] 2023-11-15 20:00:13,817 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:00:13,819 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:00:13,820 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:00:13,820 >>   Batch size = 8
{'loss': 0.5077, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 125.19it/s][A
  9%|▉         | 26/276 [00:00<00:02, 118.64it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 116.59it/s][A
 18%|█▊        | 50/276 [00:00<00:01, 115.36it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 114.50it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 113.65it/s][A
 31%|███       | 86/276 [00:00<00:01, 112.70it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 112.46it/s][A
 40%|███▉      | 110/276 [00:00<00:01, 111.86it/s][A
 44%|████▍     | 122/276 [00:01<00:01, 111.70it/s][A
 49%|████▊     | 134/276 [00:01<00:01, 111.94it/s][A
 53%|█████▎    | 146/276 [00:01<00:01, 112.24it/s][A
 57%|█████▋    | 158/276 [00:01<00:01, 112.30it/s][A
 62%|██████▏   | 170/276 [00:01<00:00, 112.17it/s][A
 66%|██████▌   | 182/276 [00:01<00:00, 111.95it/s][A
 70%|███████   | 194/276 [00:01<00:00, 111.63it/s][A
 75%|███████▍  | 206/276 [00:01<00:00, 111.42it/s][A
 79%|███████▉  | 218/276 [00:01<00:00, 111.23it/s][A
 83%|████████▎ | 230/276 [00:02<00:00, 111.16it/s][A
 88%|████████▊ | 242/276 [00:02<00:00, 111.19it/s][A
 92%|█████████▏| 254/276 [00:02<00:00, 111.52it/s][A
 96%|█████████▋| 266/276 [00:02<00:00, 111.67it/s][A                                                  
                                                  [A 20%|██        | 276/1380 [00:28<01:38, 11.17it/s]
100%|██████████| 276/276 [00:02<00:00, 111.67it/s][A
                                                  [A 20%|██        | 277/1380 [00:28<08:29,  2.16it/s] 20%|██        | 279/1380 [00:28<06:26,  2.85it/s] 20%|██        | 281/1380 [00:28<04:59,  3.67it/s] 21%|██        | 283/1380 [00:28<03:58,  4.59it/s] 21%|██        | 285/1380 [00:29<03:16,  5.58it/s] 21%|██        | 287/1380 [00:29<02:46,  6.55it/s] 21%|██        | 289/1380 [00:29<02:26,  7.47it/s] 21%|██        | 291/1380 [00:29<02:11,  8.29it/s] 21%|██        | 293/1380 [00:29<02:00,  8.99it/s] 21%|██▏       | 295/1380 [00:29<01:53,  9.54it/s] 22%|██▏       | 297/1380 [00:30<01:48,  9.98it/s] 22%|██▏       | 299/1380 [00:30<01:45, 10.28it/s] 22%|██▏       | 301/1380 [00:30<01:42, 10.52it/s] 22%|██▏       | 303/1380 [00:30<01:40, 10.69it/s] 22%|██▏       | 305/1380 [00:30<01:39, 10.83it/s] 22%|██▏       | 307/1380 [00:31<01:38, 10.92it/s] 22%|██▏       | 309/1380 [00:31<01:37, 10.98it/s] 23%|██▎       | 311/1380 [00:31<01:37, 11.01it/s] 23%|██▎       | 313/1380 [00:31<01:36, 11.04it/s] 23%|██▎       | 315/1380 [00:31<01:36, 11.07it/s] 23%|██▎       | 317/1380 [00:31<01:35, 11.08it/s] 23%|██▎       | 319/1380 [00:32<01:35, 11.09it/s] 23%|██▎       | 321/1380 [00:32<01:35, 11.10it/s] 23%|██▎       | 323/1380 [00:32<01:35, 11.10it/s] 24%|██▎       | 325/1380 [00:32<01:35, 11.10it/s] 24%|██▎       | 327/1380 [00:32<01:34, 11.10it/s] 24%|██▍       | 329/1380 [00:33<01:34, 11.09it/s] 24%|██▍       | 331/1380 [00:33<01:34, 11.09it/s] 24%|██▍       | 333/1380 [00:33<01:34, 11.11it/s] 24%|██▍       | 335/1380 [00:33<01:33, 11.12it/s] 24%|██▍       | 337/1380 [00:33<01:33, 11.12it/s] 25%|██▍       | 339/1380 [00:33<01:33, 11.11it/s] 25%|██▍       | 341/1380 [00:34<01:33, 11.12it/s] 25%|██▍       | 343/1380 [00:34<01:33, 11.10it/s] 25%|██▌       | 345/1380 [00:34<01:33, 11.11it/s] 25%|██▌       | 347/1380 [00:34<01:33, 11.10it/s] 25%|██▌       | 349/1380 [00:34<01:33, 11.08it/s] 25%|██▌       | 351/1380 [00:35<01:32, 11.10it/s] 26%|██▌       | 353/1380 [00:35<01:32, 11.12it/s] 26%|██▌       | 355/1380 [00:35<01:32, 11.11it/s] 26%|██▌       | 357/1380 [00:35<01:32, 11.10it/s] 26%|██▌       | 359/1380 [00:35<01:31, 11.10it/s] 26%|██▌       | 361/1380 [00:35<01:31, 11.10it/s] 26%|██▋       | 363/1380 [00:36<01:31, 11.11it/s] 26%|██▋       | 365/1380 [00:36<01:31, 11.11it/s] 27%|██▋       | 367/1380 [00:36<01:31, 11.11it/s] 27%|██▋       | 369/1380 [00:36<01:31, 11.11it/s] 27%|██▋       | 371/1380 [00:36<01:30, 11.10it/s] 27%|██▋       | 373/1380 [00:36<01:30, 11.10it/s] 27%|██▋       | 375/1380 [00:37<01:30, 11.12it/s] 27%|██▋       | 377/1380 [00:37<01:30, 11.11it/s] 27%|██▋       | 379/1380 [00:37<01:30, 11.12it/s] 28%|██▊       | 381/1380 [00:37<01:29, 11.13it/s] 28%|██▊       | 383/1380 [00:37<01:29, 11.12it/s] 28%|██▊       | 385/1380 [00:38<01:29, 11.11it/s] 28%|██▊       | 387/1380 [00:38<01:29, 11.12it/s] 28%|██▊       | 389/1380 [00:38<01:29, 11.12it/s] 28%|██▊       | 391/1380 [00:38<01:29, 11.10it/s] 28%|██▊       | 393/1380 [00:38<01:28, 11.11it/s] 29%|██▊       | 395/1380 [00:38<01:28, 11.11it/s] 29%|██▉       | 397/1380 [00:39<01:28, 11.12it/s] 29%|██▉       | 399/1380 [00:39<01:28, 11.10it/s] 29%|██▉       | 401/1380 [00:39<01:28, 11.11it/s] 29%|██▉       | 403/1380 [00:39<01:27, 11.11it/s] 29%|██▉       | 405/1380 [00:39<01:27, 11.10it/s] 29%|██▉       | 407/1380 [00:40<01:27, 11.11it/s] 30%|██▉       | 409/1380 [00:40<01:27, 11.10it/s] 30%|██▉       | 411/1380 [00:40<01:27, 11.10it/s] 30%|██▉       | 413/1380 [00:40<01:27, 11.10it/s] 30%|███       | 415/1380 [00:40<01:26, 11.10it/s] 30%|███       | 417/1380 [00:40<01:26, 11.09it/s] 30%|███       | 419/1380 [00:41<01:26, 11.06it/s] 31%|███       | 421/1380 [00:41<01:26, 11.07it/s] 31%|███       | 423/1380 [00:41<01:26, 11.05it/s] 31%|███       | 425/1380 [00:41<01:26, 11.06it/s] 31%|███       | 427/1380 [00:41<01:26, 11.08it/s] 31%|███       | 429/1380 [00:42<01:25, 11.08it/s] 31%|███       | 431/1380 [00:42<01:25, 11.07it/s] 31%|███▏      | 433/1380 [00:42<01:25, 11.08it/s] 32%|███▏      | 435/1380 [00:42<01:25, 11.08it/s] 32%|███▏      | 437/1380 [00:42<01:25, 11.09it/s] 32%|███▏      | 439/1380 [00:42<01:24, 11.08it/s] 32%|███▏      | 441/1380 [00:43<01:24, 11.09it/s] 32%|███▏      | 443/1380 [00:43<01:24, 11.10it/s] 32%|███▏      | 445/1380 [00:43<01:24, 11.09it/s] 32%|███▏      | 447/1380 [00:43<01:24, 11.08it/s] 33%|███▎      | 449/1380 [00:43<01:24, 11.08it/s] 33%|███▎      | 451/1380 [00:44<01:23, 11.09it/s] 33%|███▎      | 453/1380 [00:44<01:23, 11.09it/s] 33%|███▎      | 455/1380 [00:44<01:23, 11.09it/s] 33%|███▎      | 457/1380 [00:44<01:23, 11.09it/s] 33%|███▎      | 459/1380 [00:44<01:23, 11.09it/s] 33%|███▎      | 461/1380 [00:44<01:22, 11.08it/s] 34%|███▎      | 463/1380 [00:45<01:22, 11.09it/s] 34%|███▎      | 465/1380 [00:45<01:22, 11.09it/s] 34%|███▍      | 467/1380 [00:45<01:22, 11.09it/s] 34%|███▍      | 469/1380 [00:45<01:22, 11.08it/s] 34%|███▍      | 471/1380 [00:45<01:22, 11.08it/s] 34%|███▍      | 473/1380 [00:45<01:21, 11.09it/s] 34%|███▍      | 475/1380 [00:46<01:21, 11.09it/s] 35%|███▍      | 477/1380 [00:46<01:21, 11.09it/s] 35%|███▍      | 479/1380 [00:46<01:21, 11.09it/s] 35%|███▍      | 481/1380 [00:46<01:21, 11.09it/s] 35%|███▌      | 483/1380 [00:46<01:21, 11.07it/s] 35%|███▌      | 485/1380 [00:47<01:20, 11.08it/s] 35%|███▌      | 487/1380 [00:47<01:20, 11.10it/s] 35%|███▌      | 489/1380 [00:47<01:20, 11.08it/s] 36%|███▌      | 491/1380 [00:47<01:20, 11.09it/s] 36%|███▌      | 493/1380 [00:47<01:20, 11.08it/s] 36%|███▌      | 495/1380 [00:47<01:20, 11.06it/s] 36%|███▌      | 497/1380 [00:48<01:20, 11.03it/s] 36%|███▌      | 499/1380 [00:48<01:19, 11.04it/s] 36%|███▋      | 501/1380 [00:48<01:19, 11.05it/s] 36%|███▋      | 503/1380 [00:48<01:19, 11.07it/s] 37%|███▋      | 505/1380 [00:48<01:19, 11.05it/s] 37%|███▋      | 507/1380 [00:49<01:18, 11.06it/s] 37%|███▋      | 509/1380 [00:49<01:18, 11.06it/s] 37%|███▋      | 511/1380 [00:49<01:18, 11.05it/s] 37%|███▋      | 513/1380 [00:49<01:18, 11.07it/s] 37%|███▋      | 515/1380 [00:49<01:18, 11.07it/s] 37%|███▋      | 517/1380 [00:49<01:18, 11.06it/s] 38%|███▊      | 519/1380 [00:50<01:17, 11.05it/s] 38%|███▊      | 521/1380 [00:50<01:17, 11.05it/s] 38%|███▊      | 523/1380 [00:50<01:17, 11.07it/s] 38%|███▊      | 525/1380 [00:50<01:17, 11.08it/s] 38%|███▊      | 527/1380 [00:50<01:17, 11.06it/s] 38%|███▊      | 529/1380 [00:51<01:16, 11.07it/s] 38%|███▊      | 531/1380 [00:51<01:16, 11.08it/s] 39%|███▊      | 533/1380 [00:51<01:16, 11.08it/s] 39%|███▉      | 535/1380 [00:51<01:16, 11.10it/s] 39%|███▉      | 537/1380 [00:51<01:15, 11.09it/s] 39%|███▉      | 539/1380 [00:51<01:15, 11.08it/s] 39%|███▉      | 541/1380 [00:52<01:15, 11.07it/s] 39%|███▉      | 543/1380 [00:52<01:15, 11.06it/s] 39%|███▉      | 545/1380 [00:52<01:15, 11.06it/s] 40%|███▉      | 547/1380 [00:52<01:15, 11.08it/s] 40%|███▉      | 549/1380 [00:52<01:15, 11.08it/s] 40%|███▉      | 551/1380 [00:53<01:14, 11.09it/s]                                                   40%|████      | 552/1380 [00:53<01:14, 11.09it/s][INFO|trainer.py:755] 2023-11-15 20:00:41,180 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:00:41,181 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:00:41,182 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:00:41,183 >>   Batch size = 8
{'eval_loss': 0.391414076089859, 'eval_accuracy': 0.8598003629764065, 'eval_micro_f1': 0.8598003629764064, 'eval_macro_f1': 0.846509757595502, 'eval_runtime': 2.5088, 'eval_samples_per_second': 878.492, 'eval_steps_per_second': 110.011, 'epoch': 1.0}
{'loss': 0.334, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 124.26it/s][A
  9%|▉         | 26/276 [00:00<00:02, 117.39it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 115.14it/s][A
 18%|█▊        | 50/276 [00:00<00:01, 113.71it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 112.63it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 111.90it/s][A
 31%|███       | 86/276 [00:00<00:01, 111.49it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 110.93it/s][A
 40%|███▉      | 110/276 [00:00<00:01, 109.96it/s][A
 44%|████▍     | 121/276 [00:01<00:01, 109.53it/s][A
 48%|████▊     | 133/276 [00:01<00:01, 109.71it/s][A
 53%|█████▎    | 145/276 [00:01<00:01, 109.96it/s][A
 57%|█████▋    | 157/276 [00:01<00:01, 110.08it/s][A
 61%|██████    | 169/276 [00:01<00:00, 110.00it/s][A
 66%|██████▌   | 181/276 [00:01<00:00, 110.02it/s][A
 70%|██████▉   | 193/276 [00:01<00:00, 109.96it/s][A
 74%|███████▍  | 204/276 [00:01<00:00, 109.67it/s][A
 78%|███████▊  | 215/276 [00:01<00:00, 109.24it/s][A
 82%|████████▏ | 226/276 [00:02<00:00, 109.15it/s][A
 86%|████████▌ | 237/276 [00:02<00:00, 109.17it/s][A
 90%|████████▉ | 248/276 [00:02<00:00, 109.27it/s][A
 94%|█████████▍| 259/276 [00:02<00:00, 109.33it/s][A
 98%|█████████▊| 271/276 [00:02<00:00, 109.61it/s][A                                                  
                                                  [A 40%|████      | 552/1380 [00:55<01:14, 11.09it/s]
100%|██████████| 276/276 [00:02<00:00, 109.61it/s][A
                                                  [A 40%|████      | 553/1380 [00:55<06:27,  2.13it/s] 40%|████      | 555/1380 [00:55<04:53,  2.81it/s] 40%|████      | 557/1380 [00:56<03:47,  3.62it/s] 41%|████      | 559/1380 [00:56<03:00,  4.54it/s] 41%|████      | 561/1380 [00:56<02:28,  5.52it/s] 41%|████      | 563/1380 [00:56<02:06,  6.48it/s] 41%|████      | 565/1380 [00:56<01:50,  7.40it/s] 41%|████      | 567/1380 [00:57<01:38,  8.23it/s] 41%|████      | 569/1380 [00:57<01:30,  8.92it/s] 41%|████▏     | 571/1380 [00:57<01:25,  9.47it/s] 42%|████▏     | 573/1380 [00:57<01:21,  9.89it/s] 42%|████▏     | 575/1380 [00:57<01:18, 10.21it/s] 42%|████▏     | 577/1380 [00:57<01:16, 10.45it/s] 42%|████▏     | 579/1380 [00:58<01:15, 10.62it/s] 42%|████▏     | 581/1380 [00:58<01:14, 10.75it/s] 42%|████▏     | 583/1380 [00:58<01:13, 10.85it/s] 42%|████▏     | 585/1380 [00:58<01:12, 10.91it/s] 43%|████▎     | 587/1380 [00:58<01:12, 10.94it/s] 43%|████▎     | 589/1380 [00:59<01:11, 10.99it/s] 43%|████▎     | 591/1380 [00:59<01:11, 11.01it/s] 43%|████▎     | 593/1380 [00:59<01:11, 11.03it/s] 43%|████▎     | 595/1380 [00:59<01:11, 11.03it/s] 43%|████▎     | 597/1380 [00:59<01:10, 11.03it/s] 43%|████▎     | 599/1380 [00:59<01:10, 11.04it/s] 44%|████▎     | 601/1380 [01:00<01:10, 11.07it/s] 44%|████▎     | 603/1380 [01:00<01:10, 11.06it/s] 44%|████▍     | 605/1380 [01:00<01:10, 11.05it/s] 44%|████▍     | 607/1380 [01:00<01:09, 11.05it/s] 44%|████▍     | 609/1380 [01:00<01:09, 11.04it/s] 44%|████▍     | 611/1380 [01:00<01:09, 11.04it/s] 44%|████▍     | 613/1380 [01:01<01:09, 11.05it/s] 45%|████▍     | 615/1380 [01:01<01:09, 11.04it/s] 45%|████▍     | 617/1380 [01:01<01:09, 11.03it/s] 45%|████▍     | 619/1380 [01:01<01:08, 11.04it/s] 45%|████▌     | 621/1380 [01:01<01:08, 11.06it/s] 45%|████▌     | 623/1380 [01:02<01:08, 11.06it/s] 45%|████▌     | 625/1380 [01:02<01:08, 11.04it/s] 45%|████▌     | 627/1380 [01:02<01:08, 11.06it/s] 46%|████▌     | 629/1380 [01:02<01:07, 11.07it/s] 46%|████▌     | 631/1380 [01:02<01:07, 11.06it/s] 46%|████▌     | 633/1380 [01:02<01:07, 11.07it/s] 46%|████▌     | 635/1380 [01:03<01:07, 11.07it/s] 46%|████▌     | 637/1380 [01:03<01:07, 11.04it/s] 46%|████▋     | 639/1380 [01:03<01:07, 11.04it/s] 46%|████▋     | 641/1380 [01:03<01:06, 11.04it/s] 47%|████▋     | 643/1380 [01:03<01:06, 11.05it/s] 47%|████▋     | 645/1380 [01:04<01:06, 11.06it/s] 47%|████▋     | 647/1380 [01:04<01:06, 11.04it/s] 47%|████▋     | 649/1380 [01:04<01:06, 11.05it/s] 47%|████▋     | 651/1380 [01:04<01:06, 11.04it/s] 47%|████▋     | 653/1380 [01:04<01:05, 11.06it/s] 47%|████▋     | 655/1380 [01:04<01:05, 11.06it/s] 48%|████▊     | 657/1380 [01:05<01:05, 11.06it/s] 48%|████▊     | 659/1380 [01:05<01:05, 11.05it/s] 48%|████▊     | 661/1380 [01:05<01:05, 11.04it/s] 48%|████▊     | 663/1380 [01:05<01:04, 11.05it/s] 48%|████▊     | 665/1380 [01:05<01:04, 11.06it/s] 48%|████▊     | 667/1380 [01:06<01:04, 11.06it/s] 48%|████▊     | 669/1380 [01:06<01:04, 11.05it/s] 49%|████▊     | 671/1380 [01:06<01:04, 11.04it/s] 49%|████▉     | 673/1380 [01:06<01:03, 11.06it/s] 49%|████▉     | 675/1380 [01:06<01:03, 11.06it/s] 49%|████▉     | 677/1380 [01:06<01:03, 11.04it/s] 49%|████▉     | 679/1380 [01:07<01:03, 11.05it/s] 49%|████▉     | 681/1380 [01:07<01:03, 11.05it/s] 49%|████▉     | 683/1380 [01:07<01:03, 11.04it/s] 50%|████▉     | 685/1380 [01:07<01:02, 11.04it/s] 50%|████▉     | 687/1380 [01:07<01:02, 11.04it/s] 50%|████▉     | 689/1380 [01:08<01:02, 11.04it/s] 50%|█████     | 691/1380 [01:08<01:02, 11.05it/s] 50%|█████     | 693/1380 [01:08<01:02, 11.05it/s] 50%|█████     | 695/1380 [01:08<01:02, 11.04it/s] 51%|█████     | 697/1380 [01:08<01:01, 11.05it/s] 51%|█████     | 699/1380 [01:08<01:01, 11.04it/s] 51%|█████     | 701/1380 [01:09<01:01, 11.03it/s] 51%|█████     | 703/1380 [01:09<01:01, 11.05it/s] 51%|█████     | 705/1380 [01:09<01:01, 11.05it/s] 51%|█████     | 707/1380 [01:09<01:00, 11.05it/s] 51%|█████▏    | 709/1380 [01:09<01:00, 11.06it/s] 52%|█████▏    | 711/1380 [01:10<01:00, 11.05it/s] 52%|█████▏    | 713/1380 [01:10<01:00, 11.05it/s] 52%|█████▏    | 715/1380 [01:10<01:00, 11.04it/s] 52%|█████▏    | 717/1380 [01:10<00:59, 11.08it/s] 52%|█████▏    | 719/1380 [01:10<00:59, 11.05it/s] 52%|█████▏    | 721/1380 [01:10<00:59, 11.03it/s] 52%|█████▏    | 723/1380 [01:11<00:59, 11.03it/s] 53%|█████▎    | 725/1380 [01:11<00:59, 11.02it/s] 53%|█████▎    | 727/1380 [01:11<00:59, 11.02it/s] 53%|█████▎    | 729/1380 [01:11<00:59, 11.02it/s] 53%|█████▎    | 731/1380 [01:11<00:58, 11.02it/s] 53%|█████▎    | 733/1380 [01:12<00:58, 11.02it/s] 53%|█████▎    | 735/1380 [01:12<00:58, 11.03it/s] 53%|█████▎    | 737/1380 [01:12<00:58, 11.02it/s] 54%|█████▎    | 739/1380 [01:12<00:58, 11.03it/s] 54%|█████▎    | 741/1380 [01:12<00:57, 11.03it/s] 54%|█████▍    | 743/1380 [01:12<00:57, 11.00it/s] 54%|█████▍    | 745/1380 [01:13<00:57, 10.99it/s] 54%|█████▍    | 747/1380 [01:13<00:57, 11.00it/s] 54%|█████▍    | 749/1380 [01:13<00:57, 11.02it/s] 54%|█████▍    | 751/1380 [01:13<00:57, 11.03it/s] 55%|█████▍    | 753/1380 [01:13<00:56, 11.02it/s] 55%|█████▍    | 755/1380 [01:14<00:56, 11.01it/s] 55%|█████▍    | 757/1380 [01:14<00:56, 11.00it/s] 55%|█████▌    | 759/1380 [01:14<00:56, 11.04it/s] 55%|█████▌    | 761/1380 [01:14<00:56, 11.04it/s] 55%|█████▌    | 763/1380 [01:14<00:55, 11.05it/s] 55%|█████▌    | 765/1380 [01:14<00:55, 11.02it/s] 56%|█████▌    | 767/1380 [01:15<00:55, 11.01it/s] 56%|█████▌    | 769/1380 [01:15<00:55, 11.01it/s] 56%|█████▌    | 771/1380 [01:15<00:55, 10.99it/s] 56%|█████▌    | 773/1380 [01:15<00:55, 11.01it/s] 56%|█████▌    | 775/1380 [01:15<00:54, 11.01it/s] 56%|█████▋    | 777/1380 [01:16<00:54, 11.01it/s] 56%|█████▋    | 779/1380 [01:16<00:54, 10.99it/s] 57%|█████▋    | 781/1380 [01:16<00:54, 10.99it/s] 57%|█████▋    | 783/1380 [01:16<00:54, 11.01it/s] 57%|█████▋    | 785/1380 [01:16<00:53, 11.03it/s] 57%|█████▋    | 787/1380 [01:16<00:53, 11.02it/s] 57%|█████▋    | 789/1380 [01:17<00:53, 11.01it/s] 57%|█████▋    | 791/1380 [01:17<00:53, 11.00it/s] 57%|█████▋    | 793/1380 [01:17<00:53, 11.00it/s] 58%|█████▊    | 795/1380 [01:17<00:53, 11.01it/s] 58%|█████▊    | 797/1380 [01:17<00:52, 11.03it/s] 58%|█████▊    | 799/1380 [01:18<00:52, 11.03it/s] 58%|█████▊    | 801/1380 [01:18<00:52, 10.99it/s] 58%|█████▊    | 803/1380 [01:18<00:52, 10.98it/s] 58%|█████▊    | 805/1380 [01:18<00:52, 10.99it/s] 58%|█████▊    | 807/1380 [01:18<00:52, 11.01it/s] 59%|█████▊    | 809/1380 [01:18<00:51, 11.00it/s] 59%|█████▉    | 811/1380 [01:19<00:51, 10.99it/s] 59%|█████▉    | 813/1380 [01:19<00:51, 10.99it/s] 59%|█████▉    | 815/1380 [01:19<00:51, 10.99it/s] 59%|█████▉    | 817/1380 [01:19<00:51, 10.99it/s] 59%|█████▉    | 819/1380 [01:19<00:50, 11.01it/s] 59%|█████▉    | 821/1380 [01:20<00:50, 11.01it/s] 60%|█████▉    | 823/1380 [01:20<00:50, 11.00it/s] 60%|█████▉    | 825/1380 [01:20<00:50, 11.00it/s] 60%|█████▉    | 827/1380 [01:20<00:50, 11.02it/s]                                                   60%|██████    | 828/1380 [01:20<00:50, 11.02it/s][INFO|trainer.py:755] 2023-11-15 20:01:08,715 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:01:08,717 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:01:08,717 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:01:08,717 >>   Batch size = 8
{'eval_loss': 0.40808725357055664, 'eval_accuracy': 0.8525408348457351, 'eval_micro_f1': 0.8525408348457351, 'eval_macro_f1': 0.8361445716330808, 'eval_runtime': 2.5501, 'eval_samples_per_second': 864.288, 'eval_steps_per_second': 108.232, 'epoch': 2.0}
{'loss': 0.2641, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 123.47it/s][A
  9%|▉         | 26/276 [00:00<00:02, 116.91it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 114.76it/s][A
 18%|█▊        | 50/276 [00:00<00:01, 113.18it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 112.15it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 111.21it/s][A
 31%|███       | 86/276 [00:00<00:01, 110.53it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 110.09it/s][A
 40%|███▉      | 110/276 [00:00<00:01, 108.99it/s][A
 44%|████▍     | 121/276 [00:01<00:01, 108.72it/s][A
 48%|████▊     | 132/276 [00:01<00:01, 108.91it/s][A
 52%|█████▏    | 143/276 [00:01<00:01, 109.07it/s][A
 56%|█████▌    | 154/276 [00:01<00:01, 109.19it/s][A
 60%|█████▉    | 165/276 [00:01<00:01, 109.31it/s][A
 64%|██████▍   | 176/276 [00:01<00:00, 109.03it/s][A
 68%|██████▊   | 187/276 [00:01<00:00, 108.62it/s][A
 72%|███████▏  | 198/276 [00:01<00:00, 108.47it/s][A
 76%|███████▌  | 209/276 [00:01<00:00, 107.81it/s][A
 80%|███████▉  | 220/276 [00:02<00:00, 107.50it/s][A
 84%|████████▎ | 231/276 [00:02<00:00, 107.45it/s][A
 88%|████████▊ | 242/276 [00:02<00:00, 107.55it/s][A
 92%|█████████▏| 253/276 [00:02<00:00, 107.75it/s][A
 96%|█████████▌| 264/276 [00:02<00:00, 107.93it/s][A
100%|█████████▉| 275/276 [00:02<00:00, 108.26it/s][A                                                  
                                                  [A 60%|██████    | 828/1380 [01:23<00:50, 11.02it/s]
100%|██████████| 276/276 [00:02<00:00, 108.26it/s][A
                                                  [A 60%|██████    | 829/1380 [01:23<04:20,  2.11it/s] 60%|██████    | 831/1380 [01:23<03:17,  2.78it/s] 60%|██████    | 833/1380 [01:23<02:32,  3.59it/s] 61%|██████    | 835/1380 [01:23<02:01,  4.49it/s] 61%|██████    | 837/1380 [01:24<01:39,  5.46it/s] 61%|██████    | 839/1380 [01:24<01:24,  6.43it/s] 61%|██████    | 841/1380 [01:24<01:13,  7.34it/s] 61%|██████    | 843/1380 [01:24<01:05,  8.16it/s] 61%|██████    | 845/1380 [01:24<01:00,  8.85it/s] 61%|██████▏   | 847/1380 [01:24<00:56,  9.40it/s] 62%|██████▏   | 849/1380 [01:25<00:53,  9.85it/s] 62%|██████▏   | 851/1380 [01:25<00:52, 10.17it/s] 62%|██████▏   | 853/1380 [01:25<00:50, 10.41it/s] 62%|██████▏   | 855/1380 [01:25<00:49, 10.58it/s] 62%|██████▏   | 857/1380 [01:25<00:48, 10.69it/s] 62%|██████▏   | 859/1380 [01:26<00:48, 10.78it/s] 62%|██████▏   | 861/1380 [01:26<00:47, 10.85it/s] 63%|██████▎   | 863/1380 [01:26<00:47, 10.90it/s] 63%|██████▎   | 865/1380 [01:26<00:47, 10.93it/s] 63%|██████▎   | 867/1380 [01:26<00:46, 10.96it/s] 63%|██████▎   | 869/1380 [01:26<00:46, 10.95it/s] 63%|██████▎   | 871/1380 [01:27<00:46, 10.98it/s] 63%|██████▎   | 873/1380 [01:27<00:46, 10.98it/s] 63%|██████▎   | 875/1380 [01:27<00:45, 11.00it/s] 64%|██████▎   | 877/1380 [01:27<00:45, 11.01it/s] 64%|██████▎   | 879/1380 [01:27<00:45, 10.99it/s] 64%|██████▍   | 881/1380 [01:28<00:45, 10.99it/s] 64%|██████▍   | 883/1380 [01:28<00:45, 10.99it/s] 64%|██████▍   | 885/1380 [01:28<00:45, 10.98it/s] 64%|██████▍   | 887/1380 [01:28<00:44, 11.00it/s] 64%|██████▍   | 889/1380 [01:28<00:44, 11.00it/s] 65%|██████▍   | 891/1380 [01:28<00:44, 10.99it/s] 65%|██████▍   | 893/1380 [01:29<00:44, 10.99it/s] 65%|██████▍   | 895/1380 [01:29<00:44, 11.00it/s] 65%|██████▌   | 897/1380 [01:29<00:43, 11.02it/s] 65%|██████▌   | 899/1380 [01:29<00:43, 11.02it/s] 65%|██████▌   | 901/1380 [01:29<00:43, 11.01it/s] 65%|██████▌   | 903/1380 [01:30<00:43, 11.00it/s] 66%|██████▌   | 905/1380 [01:30<00:43, 10.99it/s] 66%|██████▌   | 907/1380 [01:30<00:43, 10.99it/s] 66%|██████▌   | 909/1380 [01:30<00:42, 11.01it/s] 66%|██████▌   | 911/1380 [01:30<00:42, 11.01it/s] 66%|██████▌   | 913/1380 [01:30<00:42, 11.00it/s] 66%|██████▋   | 915/1380 [01:31<00:42, 11.00it/s] 66%|██████▋   | 917/1380 [01:31<00:42, 11.00it/s] 67%|██████▋   | 919/1380 [01:31<00:41, 11.02it/s] 67%|██████▋   | 921/1380 [01:31<00:41, 11.01it/s] 67%|██████▋   | 923/1380 [01:31<00:41, 11.01it/s] 67%|██████▋   | 925/1380 [01:32<00:41, 11.00it/s] 67%|██████▋   | 927/1380 [01:32<00:41, 10.99it/s] 67%|██████▋   | 929/1380 [01:32<00:40, 11.00it/s] 67%|██████▋   | 931/1380 [01:32<00:40, 11.01it/s] 68%|██████▊   | 933/1380 [01:32<00:40, 11.00it/s] 68%|██████▊   | 935/1380 [01:32<00:40, 11.00it/s] 68%|██████▊   | 937/1380 [01:33<00:40, 10.99it/s] 68%|██████▊   | 939/1380 [01:33<00:40, 11.01it/s] 68%|██████▊   | 941/1380 [01:33<00:39, 11.01it/s] 68%|██████▊   | 943/1380 [01:33<00:39, 11.00it/s] 68%|██████▊   | 945/1380 [01:33<00:39, 11.00it/s] 69%|██████▊   | 947/1380 [01:34<00:39, 10.99it/s] 69%|██████▉   | 949/1380 [01:34<00:39, 10.99it/s] 69%|██████▉   | 951/1380 [01:34<00:38, 11.00it/s] 69%|██████▉   | 953/1380 [01:34<00:38, 11.00it/s] 69%|██████▉   | 955/1380 [01:34<00:38, 11.00it/s] 69%|██████▉   | 957/1380 [01:34<00:38, 10.97it/s] 69%|██████▉   | 959/1380 [01:35<00:38, 11.00it/s] 70%|██████▉   | 961/1380 [01:35<00:38, 11.01it/s] 70%|██████▉   | 963/1380 [01:35<00:37, 11.01it/s] 70%|██████▉   | 965/1380 [01:35<00:37, 11.01it/s] 70%|███████   | 967/1380 [01:35<00:37, 11.00it/s] 70%|███████   | 969/1380 [01:36<00:37, 11.00it/s] 70%|███████   | 971/1380 [01:36<00:37, 11.01it/s] 71%|███████   | 973/1380 [01:36<00:37, 10.99it/s] 71%|███████   | 975/1380 [01:36<00:36, 11.01it/s] 71%|███████   | 977/1380 [01:36<00:36, 11.00it/s] 71%|███████   | 979/1380 [01:36<00:36, 10.99it/s] 71%|███████   | 981/1380 [01:37<00:36, 11.00it/s] 71%|███████   | 983/1380 [01:37<00:36, 11.00it/s] 71%|███████▏  | 985/1380 [01:37<00:35, 11.02it/s] 72%|███████▏  | 987/1380 [01:37<00:35, 11.01it/s] 72%|███████▏  | 989/1380 [01:37<00:35, 11.01it/s] 72%|███████▏  | 991/1380 [01:38<00:35, 11.00it/s] 72%|███████▏  | 993/1380 [01:38<00:35, 11.01it/s] 72%|███████▏  | 995/1380 [01:38<00:34, 11.01it/s] 72%|███████▏  | 997/1380 [01:38<00:34, 11.01it/s] 72%|███████▏  | 999/1380 [01:38<00:34, 11.00it/s] 73%|███████▎  | 1001/1380 [01:38<00:34, 10.99it/s] 73%|███████▎  | 1003/1380 [01:39<00:34, 10.99it/s] 73%|███████▎  | 1005/1380 [01:39<00:34, 11.01it/s] 73%|███████▎  | 1007/1380 [01:39<00:33, 11.02it/s] 73%|███████▎  | 1009/1380 [01:39<00:33, 11.01it/s] 73%|███████▎  | 1011/1380 [01:39<00:33, 11.00it/s] 73%|███████▎  | 1013/1380 [01:40<00:33, 10.99it/s] 74%|███████▎  | 1015/1380 [01:40<00:33, 11.00it/s] 74%|███████▎  | 1017/1380 [01:40<00:33, 10.99it/s] 74%|███████▍  | 1019/1380 [01:40<00:32, 10.99it/s] 74%|███████▍  | 1021/1380 [01:40<00:32, 11.00it/s] 74%|███████▍  | 1023/1380 [01:40<00:32, 10.99it/s] 74%|███████▍  | 1025/1380 [01:41<00:32, 11.00it/s] 74%|███████▍  | 1027/1380 [01:41<00:32, 11.01it/s] 75%|███████▍  | 1029/1380 [01:41<00:31, 11.00it/s] 75%|███████▍  | 1031/1380 [01:41<00:31, 10.99it/s] 75%|███████▍  | 1033/1380 [01:41<00:31, 10.99it/s] 75%|███████▌  | 1035/1380 [01:42<00:31, 11.00it/s] 75%|███████▌  | 1037/1380 [01:42<00:31, 11.00it/s] 75%|███████▌  | 1039/1380 [01:42<00:31, 10.99it/s] 75%|███████▌  | 1041/1380 [01:42<00:30, 10.98it/s] 76%|███████▌  | 1043/1380 [01:42<00:30, 10.98it/s] 76%|███████▌  | 1045/1380 [01:42<00:30, 10.99it/s] 76%|███████▌  | 1047/1380 [01:43<00:30, 10.99it/s] 76%|███████▌  | 1049/1380 [01:43<00:30, 10.97it/s] 76%|███████▌  | 1051/1380 [01:43<00:29, 10.98it/s] 76%|███████▋  | 1053/1380 [01:43<00:29, 10.97it/s] 76%|███████▋  | 1055/1380 [01:43<00:29, 10.98it/s] 77%|███████▋  | 1057/1380 [01:44<00:29, 10.98it/s] 77%|███████▋  | 1059/1380 [01:44<00:29, 10.97it/s] 77%|███████▋  | 1061/1380 [01:44<00:29, 10.98it/s] 77%|███████▋  | 1063/1380 [01:44<00:28, 10.98it/s] 77%|███████▋  | 1065/1380 [01:44<00:28, 10.98it/s] 77%|███████▋  | 1067/1380 [01:44<00:28, 10.98it/s] 77%|███████▋  | 1069/1380 [01:45<00:28, 10.97it/s] 78%|███████▊  | 1071/1380 [01:45<00:28, 10.98it/s] 78%|███████▊  | 1073/1380 [01:45<00:27, 10.98it/s] 78%|███████▊  | 1075/1380 [01:45<00:27, 10.99it/s] 78%|███████▊  | 1077/1380 [01:45<00:27, 10.98it/s] 78%|███████▊  | 1079/1380 [01:46<00:27, 10.98it/s] 78%|███████▊  | 1081/1380 [01:46<00:27, 10.91it/s] 78%|███████▊  | 1083/1380 [01:46<00:27, 10.92it/s] 79%|███████▊  | 1085/1380 [01:46<00:26, 10.95it/s] 79%|███████▉  | 1087/1380 [01:46<00:26, 10.98it/s] 79%|███████▉  | 1089/1380 [01:46<00:26, 10.98it/s] 79%|███████▉  | 1091/1380 [01:47<00:26, 10.98it/s] 79%|███████▉  | 1093/1380 [01:47<00:26, 10.98it/s] 79%|███████▉  | 1095/1380 [01:47<00:25, 10.99it/s] 79%|███████▉  | 1097/1380 [01:47<00:25, 11.00it/s] 80%|███████▉  | 1099/1380 [01:47<00:25, 11.00it/s] 80%|███████▉  | 1101/1380 [01:48<00:25, 11.00it/s] 80%|███████▉  | 1103/1380 [01:48<00:25, 11.01it/s]                                                    80%|████████  | 1104/1380 [01:48<00:25, 11.01it/s][INFO|trainer.py:755] 2023-11-15 20:01:36,371 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:01:36,372 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:01:36,372 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:01:36,373 >>   Batch size = 8
{'eval_loss': 0.42625564336776733, 'eval_accuracy': 0.8557168784029038, 'eval_micro_f1': 0.8557168784029038, 'eval_macro_f1': 0.8406619380974024, 'eval_runtime': 2.5765, 'eval_samples_per_second': 855.422, 'eval_steps_per_second': 107.122, 'epoch': 3.0}
{'loss': 0.198, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 123.01it/s][A
  9%|▉         | 26/276 [00:00<00:02, 116.43it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 113.69it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 112.52it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.41it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.58it/s][A
 31%|███       | 86/276 [00:00<00:01, 110.10it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 109.56it/s][A
 39%|███▉      | 109/276 [00:00<00:01, 108.38it/s][A
 43%|████▎     | 120/276 [00:01<00:01, 108.37it/s][A
 47%|████▋     | 131/276 [00:01<00:01, 108.67it/s][A
 51%|█████▏    | 142/276 [00:01<00:01, 108.93it/s][A
 55%|█████▌    | 153/276 [00:01<00:01, 108.90it/s][A
 59%|█████▉    | 164/276 [00:01<00:01, 108.90it/s][A
 63%|██████▎   | 175/276 [00:01<00:00, 108.68it/s][A
 67%|██████▋   | 186/276 [00:01<00:00, 108.32it/s][A
 71%|███████▏  | 197/276 [00:01<00:00, 108.02it/s][A
 75%|███████▌  | 208/276 [00:01<00:00, 107.44it/s][A
 79%|███████▉  | 219/276 [00:02<00:00, 107.04it/s][A
 83%|████████▎ | 230/276 [00:02<00:00, 106.91it/s][A
 87%|████████▋ | 241/276 [00:02<00:00, 106.98it/s][A
 91%|█████████▏| 252/276 [00:02<00:00, 107.24it/s][A
 95%|█████████▌| 263/276 [00:02<00:00, 107.43it/s][A
 99%|█████████▉| 274/276 [00:02<00:00, 107.41it/s][A                                                   
                                                  [A 80%|████████  | 1104/1380 [01:50<00:25, 11.01it/s]
100%|██████████| 276/276 [00:02<00:00, 107.41it/s][A
                                                  [A 80%|████████  | 1105/1380 [01:50<02:10,  2.10it/s] 80%|████████  | 1107/1380 [01:51<01:38,  2.77it/s] 80%|████████  | 1109/1380 [01:51<01:15,  3.57it/s] 81%|████████  | 1111/1380 [01:51<01:00,  4.48it/s] 81%|████████  | 1113/1380 [01:51<00:49,  5.44it/s] 81%|████████  | 1115/1380 [01:51<00:41,  6.41it/s] 81%|████████  | 1117/1380 [01:52<00:35,  7.33it/s] 81%|████████  | 1119/1380 [01:52<00:32,  8.15it/s] 81%|████████  | 1121/1380 [01:52<00:29,  8.82it/s] 81%|████████▏ | 1123/1380 [01:52<00:27,  9.37it/s] 82%|████████▏ | 1125/1380 [01:52<00:25,  9.81it/s] 82%|████████▏ | 1127/1380 [01:52<00:24, 10.13it/s] 82%|████████▏ | 1129/1380 [01:53<00:24, 10.36it/s] 82%|████████▏ | 1131/1380 [01:53<00:23, 10.54it/s] 82%|████████▏ | 1133/1380 [01:53<00:23, 10.67it/s] 82%|████████▏ | 1135/1380 [01:53<00:22, 10.76it/s] 82%|████████▏ | 1137/1380 [01:53<00:22, 10.84it/s] 83%|████████▎ | 1139/1380 [01:54<00:22, 10.88it/s] 83%|████████▎ | 1141/1380 [01:54<00:21, 10.91it/s] 83%|████████▎ | 1143/1380 [01:54<00:21, 10.92it/s] 83%|████████▎ | 1145/1380 [01:54<00:21, 10.96it/s] 83%|████████▎ | 1147/1380 [01:54<00:21, 10.96it/s] 83%|████████▎ | 1149/1380 [01:54<00:21, 10.96it/s] 83%|████████▎ | 1151/1380 [01:55<00:20, 10.96it/s] 84%|████████▎ | 1153/1380 [01:55<00:20, 10.98it/s] 84%|████████▎ | 1155/1380 [01:55<00:20, 10.98it/s] 84%|████████▍ | 1157/1380 [01:55<00:20, 10.98it/s] 84%|████████▍ | 1159/1380 [01:55<00:20, 10.97it/s] 84%|████████▍ | 1161/1380 [01:56<00:19, 10.97it/s] 84%|████████▍ | 1163/1380 [01:56<00:19, 10.99it/s] 84%|████████▍ | 1165/1380 [01:56<00:19, 10.98it/s] 85%|████████▍ | 1167/1380 [01:56<00:19, 10.98it/s] 85%|████████▍ | 1169/1380 [01:56<00:19, 10.98it/s] 85%|████████▍ | 1171/1380 [01:56<00:19, 10.98it/s] 85%|████████▌ | 1173/1380 [01:57<00:18, 10.98it/s] 85%|████████▌ | 1175/1380 [01:57<00:18, 10.97it/s] 85%|████████▌ | 1177/1380 [01:57<00:18, 10.97it/s] 85%|████████▌ | 1179/1380 [01:57<00:18, 10.97it/s] 86%|████████▌ | 1181/1380 [01:57<00:18, 11.00it/s] 86%|████████▌ | 1183/1380 [01:58<00:17, 11.01it/s] 86%|████████▌ | 1185/1380 [01:58<00:17, 11.00it/s] 86%|████████▌ | 1187/1380 [01:58<00:17, 10.98it/s] 86%|████████▌ | 1189/1380 [01:58<00:17, 10.97it/s] 86%|████████▋ | 1191/1380 [01:58<00:17, 10.99it/s] 86%|████████▋ | 1193/1380 [01:59<00:17, 10.99it/s] 87%|████████▋ | 1195/1380 [01:59<00:16, 10.99it/s] 87%|████████▋ | 1197/1380 [01:59<00:16, 10.98it/s] 87%|████████▋ | 1199/1380 [01:59<00:16, 11.00it/s] 87%|████████▋ | 1201/1380 [01:59<00:16, 11.00it/s] 87%|████████▋ | 1203/1380 [01:59<00:16, 11.01it/s] 87%|████████▋ | 1205/1380 [02:00<00:15, 11.00it/s] 87%|████████▋ | 1207/1380 [02:00<00:15, 10.99it/s] 88%|████████▊ | 1209/1380 [02:00<00:15, 10.98it/s] 88%|████████▊ | 1211/1380 [02:00<00:15, 10.98it/s] 88%|████████▊ | 1213/1380 [02:00<00:15, 10.98it/s] 88%|████████▊ | 1215/1380 [02:01<00:15, 10.98it/s] 88%|████████▊ | 1217/1380 [02:01<00:14, 10.98it/s] 88%|████████▊ | 1219/1380 [02:01<00:14, 11.00it/s] 88%|████████▊ | 1221/1380 [02:01<00:14, 11.01it/s] 89%|████████▊ | 1223/1380 [02:01<00:14, 11.01it/s] 89%|████████▉ | 1225/1380 [02:01<00:14, 11.01it/s] 89%|████████▉ | 1227/1380 [02:02<00:13, 10.99it/s] 89%|████████▉ | 1229/1380 [02:02<00:13, 10.97it/s] 89%|████████▉ | 1231/1380 [02:02<00:13, 10.99it/s] 89%|████████▉ | 1233/1380 [02:02<00:13, 10.99it/s] 89%|████████▉ | 1235/1380 [02:02<00:13, 10.99it/s] 90%|████████▉ | 1237/1380 [02:03<00:13, 10.98it/s] 90%|████████▉ | 1239/1380 [02:03<00:12, 10.99it/s] 90%|████████▉ | 1241/1380 [02:03<00:12, 10.98it/s] 90%|█████████ | 1243/1380 [02:03<00:12, 10.98it/s] 90%|█████████ | 1245/1380 [02:03<00:12, 10.96it/s] 90%|█████████ | 1247/1380 [02:03<00:12, 10.98it/s] 91%|█████████ | 1249/1380 [02:04<00:11, 10.98it/s] 91%|█████████ | 1251/1380 [02:04<00:11, 10.98it/s] 91%|█████████ | 1253/1380 [02:04<00:11, 10.97it/s] 91%|█████████ | 1255/1380 [02:04<00:11, 10.97it/s] 91%|█████████ | 1257/1380 [02:04<00:11, 10.98it/s] 91%|█████████ | 1259/1380 [02:05<00:11, 10.98it/s] 91%|█████████▏| 1261/1380 [02:05<00:10, 10.97it/s] 92%|█████████▏| 1263/1380 [02:05<00:10, 10.97it/s] 92%|█████████▏| 1265/1380 [02:05<00:10, 10.98it/s] 92%|█████████▏| 1267/1380 [02:05<00:10, 10.97it/s] 92%|█████████▏| 1269/1380 [02:05<00:10, 10.97it/s] 92%|█████████▏| 1271/1380 [02:06<00:09, 10.95it/s] 92%|█████████▏| 1273/1380 [02:06<00:09, 10.97it/s] 92%|█████████▏| 1275/1380 [02:06<00:09, 10.98it/s] 93%|█████████▎| 1277/1380 [02:06<00:09, 10.97it/s] 93%|█████████▎| 1279/1380 [02:06<00:09, 10.96it/s] 93%|█████████▎| 1281/1380 [02:07<00:09, 10.96it/s] 93%|█████████▎| 1283/1380 [02:07<00:08, 10.98it/s] 93%|█████████▎| 1285/1380 [02:07<00:08, 10.98it/s] 93%|█████████▎| 1287/1380 [02:07<00:08, 10.97it/s] 93%|█████████▎| 1289/1380 [02:07<00:08, 10.97it/s] 94%|█████████▎| 1291/1380 [02:07<00:08, 10.97it/s] 94%|█████████▎| 1293/1380 [02:08<00:07, 10.96it/s] 94%|█████████▍| 1295/1380 [02:08<00:07, 10.97it/s] 94%|█████████▍| 1297/1380 [02:08<00:07, 10.96it/s] 94%|█████████▍| 1299/1380 [02:08<00:07, 10.97it/s] 94%|█████████▍| 1301/1380 [02:08<00:07, 10.97it/s] 94%|█████████▍| 1303/1380 [02:09<00:07, 10.97it/s] 95%|█████████▍| 1305/1380 [02:09<00:06, 10.96it/s] 95%|█████████▍| 1307/1380 [02:09<00:06, 10.97it/s] 95%|█████████▍| 1309/1380 [02:09<00:06, 10.98it/s] 95%|█████████▌| 1311/1380 [02:09<00:06, 10.98it/s] 95%|█████████▌| 1313/1380 [02:09<00:06, 10.97it/s] 95%|█████████▌| 1315/1380 [02:10<00:05, 10.97it/s] 95%|█████████▌| 1317/1380 [02:10<00:05, 10.98it/s] 96%|█████████▌| 1319/1380 [02:10<00:05, 10.98it/s] 96%|█████████▌| 1321/1380 [02:10<00:05, 10.97it/s] 96%|█████████▌| 1323/1380 [02:10<00:05, 10.97it/s] 96%|█████████▌| 1325/1380 [02:11<00:05, 10.98it/s] 96%|█████████▌| 1327/1380 [02:11<00:04, 10.97it/s] 96%|█████████▋| 1329/1380 [02:11<00:04, 10.96it/s] 96%|█████████▋| 1331/1380 [02:11<00:04, 10.97it/s] 97%|█████████▋| 1333/1380 [02:11<00:04, 10.97it/s] 97%|█████████▋| 1335/1380 [02:11<00:04, 10.97it/s] 97%|█████████▋| 1337/1380 [02:12<00:03, 10.92it/s] 97%|█████████▋| 1339/1380 [02:12<00:03, 10.94it/s] 97%|█████████▋| 1341/1380 [02:12<00:03, 10.92it/s] 97%|█████████▋| 1343/1380 [02:12<00:03, 10.91it/s] 97%|█████████▋| 1345/1380 [02:12<00:03, 10.93it/s] 98%|█████████▊| 1347/1380 [02:13<00:03, 10.92it/s] 98%|█████████▊| 1349/1380 [02:13<00:02, 10.92it/s] 98%|█████████▊| 1351/1380 [02:13<00:02, 10.95it/s] 98%|█████████▊| 1353/1380 [02:13<00:02, 10.95it/s] 98%|█████████▊| 1355/1380 [02:13<00:02, 10.96it/s] 98%|█████████▊| 1357/1380 [02:13<00:02, 10.95it/s] 98%|█████████▊| 1359/1380 [02:14<00:01, 10.94it/s] 99%|█████████▊| 1361/1380 [02:14<00:01, 10.95it/s] 99%|█████████▉| 1363/1380 [02:14<00:01, 10.94it/s] 99%|█████████▉| 1365/1380 [02:14<00:01, 10.95it/s] 99%|█████████▉| 1367/1380 [02:14<00:01, 10.96it/s] 99%|█████████▉| 1369/1380 [02:15<00:01, 10.98it/s] 99%|█████████▉| 1371/1380 [02:15<00:00, 10.95it/s] 99%|█████████▉| 1373/1380 [02:15<00:00, 10.95it/s]100%|█████████▉| 1375/1380 [02:15<00:00, 10.95it/s]100%|█████████▉| 1377/1380 [02:15<00:00, 10.96it/s]100%|█████████▉| 1379/1380 [02:15<00:00, 10.97it/s]                                                   100%|██████████| 1380/1380 [02:16<00:00, 10.97it/s][INFO|trainer.py:755] 2023-11-15 20:02:04,092 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:02:04,094 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:02:04,094 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:02:04,095 >>   Batch size = 8
{'eval_loss': 0.4283997416496277, 'eval_accuracy': 0.8579854809437386, 'eval_micro_f1': 0.8579854809437386, 'eval_macro_f1': 0.8484389977868155, 'eval_runtime': 2.5897, 'eval_samples_per_second': 851.07, 'eval_steps_per_second': 106.577, 'epoch': 4.0}
{'loss': 0.1534, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 121.84it/s][A
  9%|▉         | 26/276 [00:00<00:02, 115.35it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 113.09it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 112.36it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.68it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 111.01it/s][A
 31%|███       | 86/276 [00:00<00:01, 110.48it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 109.86it/s][A
 39%|███▉      | 109/276 [00:00<00:01, 108.64it/s][A
 43%|████▎     | 120/276 [00:01<00:01, 108.24it/s][A
 47%|████▋     | 131/276 [00:01<00:01, 108.19it/s][A
 51%|█████▏    | 142/276 [00:01<00:01, 108.53it/s][A
 55%|█████▌    | 153/276 [00:01<00:01, 108.46it/s][A
 59%|█████▉    | 164/276 [00:01<00:01, 108.50it/s][A
 63%|██████▎   | 175/276 [00:01<00:00, 108.27it/s][A
 67%|██████▋   | 186/276 [00:01<00:00, 108.14it/s][A
 71%|███████▏  | 197/276 [00:01<00:00, 107.69it/s][A
 75%|███████▌  | 208/276 [00:01<00:00, 107.24it/s][A
 79%|███████▉  | 219/276 [00:02<00:00, 106.71it/s][A
 83%|████████▎ | 230/276 [00:02<00:00, 106.41it/s][A
 87%|████████▋ | 241/276 [00:02<00:00, 106.42it/s][A
 91%|█████████▏| 252/276 [00:02<00:00, 106.71it/s][A
 95%|█████████▌| 263/276 [00:02<00:00, 107.06it/s][A
 99%|█████████▉| 274/276 [00:02<00:00, 106.98it/s][A                                                   
                                                  [A100%|██████████| 1380/1380 [02:18<00:00, 10.97it/s]
100%|██████████| 276/276 [00:02<00:00, 106.98it/s][A
                                                  [A[INFO|trainer.py:1963] 2023-11-15 20:02:06,693 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:18<00:00, 10.97it/s]100%|██████████| 1380/1380 [02:18<00:00,  9.95it/s]
[INFO|trainer.py:2855] 2023-11-15 20:02:06,698 >> Saving model checkpoint to ./result/acl_roberta-base_adapter__seed1
[INFO|configuration_utils.py:460] 2023-11-15 20:02:06,700 >> Configuration saved in ./result/acl_roberta-base_adapter__seed1/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:02:08,079 >> Model weights saved in ./result/acl_roberta-base_adapter__seed1/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:02:08,082 >> tokenizer config file saved in ./result/acl_roberta-base_adapter__seed1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:02:08,085 >> Special tokens file saved in ./result/acl_roberta-base_adapter__seed1/special_tokens_map.json
{'eval_loss': 0.4911593198776245, 'eval_accuracy': 0.8561705989110708, 'eval_micro_f1': 0.8561705989110708, 'eval_macro_f1': 0.845402321369025, 'eval_runtime': 2.5959, 'eval_samples_per_second': 849.028, 'eval_steps_per_second': 106.321, 'epoch': 5.0}
{'train_runtime': 138.6284, 'train_samples_per_second': 317.972, 'train_steps_per_second': 9.955, 'train_loss': 0.2914655491925668, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2915
  train_runtime            = 0:02:18.62
  train_samples            =       8816
  train_samples_per_second =    317.972
  train_steps_per_second   =      9.955
11/15/2023 20:02:08 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:02:08,179 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:02:08,181 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:02:08,181 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:02:08,182 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  5%|▍         | 13/276 [00:00<00:02, 120.77it/s]  9%|▉         | 26/276 [00:00<00:02, 112.80it/s] 14%|█▍        | 38/276 [00:00<00:02, 110.68it/s] 18%|█▊        | 50/276 [00:00<00:02, 109.40it/s] 22%|██▏       | 61/276 [00:00<00:01, 108.84it/s] 26%|██▌       | 72/276 [00:00<00:01, 108.43it/s] 30%|███       | 83/276 [00:00<00:01, 108.14it/s] 34%|███▍      | 94/276 [00:00<00:01, 107.85it/s] 38%|███▊      | 105/276 [00:00<00:01, 107.52it/s] 42%|████▏     | 116/276 [00:01<00:01, 107.27it/s] 46%|████▌     | 127/276 [00:01<00:01, 106.96it/s] 50%|█████     | 138/276 [00:01<00:01, 106.74it/s] 54%|█████▍    | 149/276 [00:01<00:01, 106.79it/s] 58%|█████▊    | 160/276 [00:01<00:01, 106.80it/s] 62%|██████▏   | 171/276 [00:01<00:00, 106.64it/s] 66%|██████▌   | 182/276 [00:01<00:00, 106.57it/s] 70%|██████▉   | 193/276 [00:01<00:00, 106.65it/s] 74%|███████▍  | 204/276 [00:01<00:00, 106.64it/s] 78%|███████▊  | 215/276 [00:01<00:00, 106.57it/s] 82%|████████▏ | 226/276 [00:02<00:00, 106.53it/s] 86%|████████▌ | 237/276 [00:02<00:00, 106.27it/s] 90%|████████▉ | 248/276 [00:02<00:00, 106.33it/s] 94%|█████████▍| 259/276 [00:02<00:00, 106.35it/s] 98%|█████████▊| 270/276 [00:02<00:00, 106.09it/s]100%|██████████| 276/276 [00:02<00:00, 105.65it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8562
  eval_loss               =     0.4912
  eval_macro_f1           =     0.8454
  eval_micro_f1           =     0.8562
  eval_runtime            = 0:00:02.62
  eval_samples            =       2204
  eval_samples_per_second =    839.695
  eval_steps_per_second   =    105.152
Traceback (most recent call last):
  File "/ceph/home/wangyifei/a3/train_combined.py", line 211, in <module>
    main()
  File "/ceph/home/wangyifei/a3/train_combined.py", line 207, in main
    trainer.save_metrics("eval",metrics)
  File "/ceph/home/wangyifei/anaconda3/envs/trans/lib/python3.11/site-packages/transformers/trainer_pt_utils.py", line 1010, in save_metrics
    with open(path, "w") as f:
         ^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './result/acl_roberta-base_adapter__seed1/eval_results.json'
wandb: Waiting for W&B process to finish... (failed 1).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy █▁▄▆▅▅
wandb:                      eval/loss ▁▂▃▄██
wandb:                  eval/macro_f1 ▇▁▄█▆▆
wandb:                  eval/micro_f1 █▁▄▆▅▅
wandb:                   eval/runtime ▁▃▅▆▆█
wandb:        eval/samples_per_second █▅▄▃▃▁
wandb:          eval/steps_per_second █▅▄▃▃▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.85617
wandb:                      eval/loss 0.49116
wandb:                  eval/macro_f1 0.8454
wandb:                  eval/micro_f1 0.85617
wandb:                   eval/runtime 2.6248
wandb:        eval/samples_per_second 839.695
wandb:          eval/steps_per_second 105.152
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1534
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.29147
wandb:            train/train_runtime 138.6284
wandb: train/train_samples_per_second 317.972
wandb:   train/train_steps_per_second 9.955
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_195830-8zps7uq0
wandb: Find logs at: ./wandb/offline-run-20231115_195830-8zps7uq0/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_bert-base-cased_adapter__seed1/runs/Nov15_20-02-21_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_bert-base-cased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_bert-base-cased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:02:21 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:02:21 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_bert-base-cased_adapter__seed1/runs/Nov15_20-02-20_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_bert-base-cased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_bert-base-cased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  36%|███▋      | 4014/11020 [00:00<00:00, 39302.23 examples/s]Map:  75%|███████▍  | 8244/11020 [00:00<00:00, 41048.59 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 40269.34 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:02:37,467 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:02:37,479 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 20:02:47,496 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:02:47,497 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:02:47,501 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:02:47,501 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:02:47,501 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:02:47,502 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:02:47,502 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 20:02:47,503 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:02:47,504 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:03:07,674 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:03:08,311 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:03:08,312 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  23%|██▎       | 2000/8816 [00:00<00:00, 18844.88 examples/s]Running tokenizer on dataset:  57%|█████▋    | 5000/8816 [00:00<00:00, 18993.44 examples/s]Running tokenizer on dataset:  79%|███████▉  | 7000/8816 [00:00<00:00, 18991.48 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 19220.51 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 21220.31 examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 20906.59 examples/s]
11/15/2023 20:03:08 - INFO - __main__ - Sample 1767 of the training set: {'text': 'Second, HASM cells in culture, when observed between 3 and 6 h after plating, were not spindle shaped or aligned in parallel, as they are at the tissue level (5); instead, they were irregularly shaped (Fig.', 'label': 0, 'input_ids': [101, 2307, 117, 145, 10719, 2107, 3652, 1107, 2754, 117, 1165, 4379, 1206, 124, 1105, 127, 177, 1170, 185, 18156, 117, 1127, 1136, 6898, 7916, 4283, 1137, 14006, 1107, 5504, 117, 1112, 1152, 1132, 1120, 1103, 7918, 1634, 113, 126, 114, 132, 1939, 117, 1152, 1127, 12692, 1193, 4283, 113, 17355, 1403, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:03:08 - INFO - __main__ - Sample 3854 of the training set: {'text': 'Yet, allowing for interruptions might decrease classification accuracy [24] as well as making results vulnerable to variation in wear time if analyzed with different epoch lengths [37].', 'label': 0, 'input_ids': [101, 6355, 117, 3525, 1111, 19717, 5266, 1547, 9711, 5393, 10893, 164, 1572, 166, 1112, 1218, 1112, 1543, 2686, 8018, 1106, 8516, 1107, 4330, 1159, 1191, 17689, 1114, 1472, 174, 5674, 1732, 10707, 164, 3413, 166, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:03:08 - INFO - __main__ - Sample 4652 of the training set: {'text': 'Examination of plaque formation and growth curves were performed by standard methods as previously described (10, 35).', 'label': 1, 'input_ids': [101, 26947, 1104, 12592, 3855, 1105, 3213, 10642, 1127, 1982, 1118, 2530, 4069, 1112, 2331, 1758, 113, 1275, 117, 2588, 114, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:03:08 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:03:10,012 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:03:10,020 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:03:10,020 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 20:03:10,021 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:03:10,021 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:03:10,021 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:03:10,021 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:03:10,022 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 20:03:10,022 >>   Number of trainable parameters = 108,312,579
[INFO|integration_utils.py:716] 2023-11-15 20:03:10,023 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<25:59,  1.13s/it]  0%|          | 3/1380 [00:01<08:15,  2.78it/s]  0%|          | 5/1380 [00:01<05:03,  4.53it/s]  1%|          | 7/1380 [00:01<03:46,  6.06it/s]  1%|          | 9/1380 [00:01<03:06,  7.34it/s]  1%|          | 11/1380 [00:02<02:43,  8.37it/s]  1%|          | 13/1380 [00:02<02:30,  9.11it/s]  1%|          | 15/1380 [00:02<02:20,  9.68it/s]  1%|          | 17/1380 [00:02<02:14, 10.12it/s]  1%|▏         | 19/1380 [00:02<02:10, 10.43it/s]  2%|▏         | 21/1380 [00:02<02:07, 10.65it/s]  2%|▏         | 23/1380 [00:03<02:05, 10.81it/s]  2%|▏         | 25/1380 [00:03<02:04, 10.92it/s]  2%|▏         | 27/1380 [00:03<02:02, 11.01it/s]  2%|▏         | 29/1380 [00:03<02:02, 11.07it/s]  2%|▏         | 31/1380 [00:03<02:01, 11.12it/s]  2%|▏         | 33/1380 [00:03<02:00, 11.16it/s]  3%|▎         | 35/1380 [00:04<02:00, 11.17it/s]  3%|▎         | 37/1380 [00:04<02:00, 11.18it/s]  3%|▎         | 39/1380 [00:04<01:59, 11.18it/s]  3%|▎         | 41/1380 [00:04<01:59, 11.19it/s]  3%|▎         | 43/1380 [00:04<01:59, 11.18it/s]  3%|▎         | 45/1380 [00:05<01:59, 11.19it/s]  3%|▎         | 47/1380 [00:05<01:58, 11.21it/s]  4%|▎         | 49/1380 [00:05<01:58, 11.22it/s]  4%|▎         | 51/1380 [00:05<01:58, 11.20it/s]  4%|▍         | 53/1380 [00:05<01:58, 11.21it/s]  4%|▍         | 55/1380 [00:05<01:58, 11.21it/s]  4%|▍         | 57/1380 [00:06<01:57, 11.22it/s]  4%|▍         | 59/1380 [00:06<01:58, 11.19it/s]  4%|▍         | 61/1380 [00:06<01:57, 11.20it/s]  5%|▍         | 63/1380 [00:06<01:57, 11.21it/s]  5%|▍         | 65/1380 [00:06<01:57, 11.20it/s]  5%|▍         | 67/1380 [00:07<01:56, 11.23it/s]  5%|▌         | 69/1380 [00:07<01:56, 11.22it/s]  5%|▌         | 71/1380 [00:07<01:56, 11.22it/s]  5%|▌         | 73/1380 [00:07<01:56, 11.22it/s]  5%|▌         | 75/1380 [00:07<01:56, 11.21it/s]  6%|▌         | 77/1380 [00:07<01:56, 11.21it/s]  6%|▌         | 79/1380 [00:08<01:56, 11.21it/s]  6%|▌         | 81/1380 [00:08<01:55, 11.20it/s]  6%|▌         | 83/1380 [00:08<01:55, 11.22it/s]  6%|▌         | 85/1380 [00:08<01:55, 11.21it/s]  6%|▋         | 87/1380 [00:08<01:55, 11.20it/s]  6%|▋         | 89/1380 [00:08<01:55, 11.20it/s]  7%|▋         | 91/1380 [00:09<01:55, 11.19it/s]  7%|▋         | 93/1380 [00:09<01:54, 11.20it/s]  7%|▋         | 95/1380 [00:09<01:54, 11.22it/s]  7%|▋         | 97/1380 [00:09<01:54, 11.20it/s]  7%|▋         | 99/1380 [00:09<01:54, 11.19it/s]  7%|▋         | 101/1380 [00:10<01:54, 11.18it/s]  7%|▋         | 103/1380 [00:10<01:54, 11.19it/s]  8%|▊         | 105/1380 [00:10<01:53, 11.20it/s]  8%|▊         | 107/1380 [00:10<01:53, 11.20it/s]  8%|▊         | 109/1380 [00:10<01:53, 11.20it/s]  8%|▊         | 111/1380 [00:10<01:53, 11.19it/s]  8%|▊         | 113/1380 [00:11<01:53, 11.20it/s]  8%|▊         | 115/1380 [00:11<01:53, 11.19it/s]  8%|▊         | 117/1380 [00:11<01:52, 11.19it/s]  9%|▊         | 119/1380 [00:11<01:52, 11.17it/s]  9%|▉         | 121/1380 [00:11<01:52, 11.19it/s]  9%|▉         | 123/1380 [00:12<01:52, 11.18it/s]  9%|▉         | 125/1380 [00:12<01:52, 11.17it/s]  9%|▉         | 127/1380 [00:12<01:52, 11.18it/s]  9%|▉         | 129/1380 [00:12<01:52, 11.15it/s]  9%|▉         | 131/1380 [00:12<01:51, 11.16it/s] 10%|▉         | 133/1380 [00:12<01:51, 11.17it/s] 10%|▉         | 135/1380 [00:13<01:51, 11.18it/s] 10%|▉         | 137/1380 [00:13<01:51, 11.17it/s] 10%|█         | 139/1380 [00:13<01:50, 11.18it/s] 10%|█         | 141/1380 [00:13<01:50, 11.18it/s] 10%|█         | 143/1380 [00:13<01:50, 11.19it/s] 11%|█         | 145/1380 [00:13<01:50, 11.18it/s] 11%|█         | 147/1380 [00:14<01:50, 11.19it/s] 11%|█         | 149/1380 [00:14<01:49, 11.20it/s] 11%|█         | 151/1380 [00:14<01:49, 11.21it/s] 11%|█         | 153/1380 [00:14<01:49, 11.20it/s] 11%|█         | 155/1380 [00:14<01:49, 11.21it/s] 11%|█▏        | 157/1380 [00:15<01:49, 11.20it/s] 12%|█▏        | 159/1380 [00:15<01:49, 11.16it/s] 12%|█▏        | 161/1380 [00:15<01:49, 11.17it/s] 12%|█▏        | 163/1380 [00:15<01:48, 11.17it/s] 12%|█▏        | 165/1380 [00:15<01:48, 11.18it/s] 12%|█▏        | 167/1380 [00:15<01:48, 11.15it/s] 12%|█▏        | 169/1380 [00:16<01:48, 11.14it/s] 12%|█▏        | 171/1380 [00:16<01:48, 11.14it/s] 13%|█▎        | 173/1380 [00:16<01:48, 11.15it/s] 13%|█▎        | 175/1380 [00:16<01:48, 11.14it/s] 13%|█▎        | 177/1380 [00:16<01:47, 11.15it/s] 13%|█▎        | 179/1380 [00:17<01:47, 11.13it/s] 13%|█▎        | 181/1380 [00:17<01:47, 11.16it/s] 13%|█▎        | 183/1380 [00:17<01:47, 11.15it/s] 13%|█▎        | 185/1380 [00:17<01:47, 11.15it/s] 14%|█▎        | 187/1380 [00:17<01:46, 11.17it/s] 14%|█▎        | 189/1380 [00:17<01:46, 11.18it/s] 14%|█▍        | 191/1380 [00:18<01:46, 11.16it/s] 14%|█▍        | 193/1380 [00:18<01:46, 11.18it/s] 14%|█▍        | 195/1380 [00:18<01:46, 11.18it/s] 14%|█▍        | 197/1380 [00:18<01:45, 11.17it/s] 14%|█▍        | 199/1380 [00:18<01:45, 11.18it/s] 15%|█▍        | 201/1380 [00:19<01:45, 11.18it/s] 15%|█▍        | 203/1380 [00:19<01:45, 11.20it/s] 15%|█▍        | 205/1380 [00:19<01:44, 11.20it/s] 15%|█▌        | 207/1380 [00:19<01:44, 11.18it/s] 15%|█▌        | 209/1380 [00:19<01:44, 11.18it/s] 15%|█▌        | 211/1380 [00:19<01:44, 11.19it/s] 15%|█▌        | 213/1380 [00:20<01:44, 11.18it/s] 16%|█▌        | 215/1380 [00:20<01:44, 11.17it/s] 16%|█▌        | 217/1380 [00:20<01:44, 11.16it/s] 16%|█▌        | 219/1380 [00:20<01:44, 11.16it/s] 16%|█▌        | 221/1380 [00:20<01:43, 11.16it/s] 16%|█▌        | 223/1380 [00:20<01:43, 11.18it/s] 16%|█▋        | 225/1380 [00:21<01:43, 11.18it/s] 16%|█▋        | 227/1380 [00:21<01:43, 11.18it/s] 17%|█▋        | 229/1380 [00:21<01:42, 11.18it/s] 17%|█▋        | 231/1380 [00:21<01:42, 11.19it/s] 17%|█▋        | 233/1380 [00:21<01:42, 11.18it/s] 17%|█▋        | 235/1380 [00:22<01:42, 11.20it/s] 17%|█▋        | 237/1380 [00:22<01:42, 11.20it/s] 17%|█▋        | 239/1380 [00:22<01:41, 11.20it/s] 17%|█▋        | 241/1380 [00:22<01:41, 11.18it/s] 18%|█▊        | 243/1380 [00:22<01:41, 11.18it/s] 18%|█▊        | 245/1380 [00:22<01:41, 11.19it/s] 18%|█▊        | 247/1380 [00:23<01:41, 11.19it/s] 18%|█▊        | 249/1380 [00:23<01:41, 11.19it/s] 18%|█▊        | 251/1380 [00:23<01:40, 11.19it/s] 18%|█▊        | 253/1380 [00:23<01:40, 11.18it/s] 18%|█▊        | 255/1380 [00:23<01:40, 11.20it/s] 19%|█▊        | 257/1380 [00:24<01:40, 11.20it/s] 19%|█▉        | 259/1380 [00:24<01:40, 11.19it/s] 19%|█▉        | 261/1380 [00:24<01:40, 11.17it/s] 19%|█▉        | 263/1380 [00:24<01:40, 11.16it/s] 19%|█▉        | 265/1380 [00:24<01:39, 11.16it/s] 19%|█▉        | 267/1380 [00:24<01:39, 11.17it/s] 19%|█▉        | 269/1380 [00:25<01:39, 11.17it/s] 20%|█▉        | 271/1380 [00:25<01:39, 11.17it/s] 20%|█▉        | 273/1380 [00:25<01:39, 11.17it/s] 20%|█▉        | 275/1380 [00:25<01:38, 11.19it/s]                                                   20%|██        | 276/1380 [00:25<01:38, 11.19it/s][INFO|trainer.py:755] 2023-11-15 20:03:35,713 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:03:35,715 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:03:35,715 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:03:35,716 >>   Batch size = 8
{'loss': 0.4899, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 121.57it/s][A
  9%|▉         | 26/276 [00:00<00:02, 115.07it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 112.96it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 111.88it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.03it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.24it/s][A
 31%|███       | 86/276 [00:00<00:01, 110.01it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 109.32it/s][A
 39%|███▉      | 109/276 [00:00<00:01, 108.74it/s][A
 43%|████▎     | 120/276 [00:01<00:01, 108.29it/s][A
 47%|████▋     | 131/276 [00:01<00:01, 108.31it/s][A
 51%|█████▏    | 142/276 [00:01<00:01, 108.49it/s][A
 55%|█████▌    | 153/276 [00:01<00:01, 108.42it/s][A
 59%|█████▉    | 164/276 [00:01<00:01, 108.56it/s][A
 63%|██████▎   | 175/276 [00:01<00:00, 108.55it/s][A
 67%|██████▋   | 186/276 [00:01<00:00, 108.48it/s][A
 71%|███████▏  | 197/276 [00:01<00:00, 108.32it/s][A
 75%|███████▌  | 208/276 [00:01<00:00, 108.26it/s][A
 79%|███████▉  | 219/276 [00:02<00:00, 107.81it/s][A
 83%|████████▎ | 230/276 [00:02<00:00, 107.70it/s][A
 87%|████████▋ | 241/276 [00:02<00:00, 107.76it/s][A
 91%|█████████▏| 252/276 [00:02<00:00, 107.88it/s][A
 95%|█████████▌| 263/276 [00:02<00:00, 107.78it/s][A
 99%|█████████▉| 274/276 [00:02<00:00, 107.92it/s][A                                                  
                                                  [A 20%|██        | 276/1380 [00:28<01:38, 11.19it/s]
100%|██████████| 276/276 [00:02<00:00, 107.92it/s][A
                                                  [A 20%|██        | 277/1380 [00:28<08:42,  2.11it/s] 20%|██        | 279/1380 [00:28<06:35,  2.78it/s] 20%|██        | 281/1380 [00:28<05:06,  3.59it/s] 21%|██        | 283/1380 [00:28<04:03,  4.50it/s] 21%|██        | 285/1380 [00:29<03:19,  5.48it/s] 21%|██        | 287/1380 [00:29<02:48,  6.47it/s] 21%|██        | 289/1380 [00:29<02:27,  7.41it/s] 21%|██        | 291/1380 [00:29<02:12,  8.23it/s] 21%|██        | 293/1380 [00:29<02:01,  8.93it/s] 21%|██▏       | 295/1380 [00:29<01:54,  9.49it/s] 22%|██▏       | 297/1380 [00:30<01:48,  9.95it/s] 22%|██▏       | 299/1380 [00:30<01:45, 10.28it/s] 22%|██▏       | 301/1380 [00:30<01:42, 10.53it/s] 22%|██▏       | 303/1380 [00:30<01:40, 10.69it/s] 22%|██▏       | 305/1380 [00:30<01:39, 10.83it/s] 22%|██▏       | 307/1380 [00:31<01:38, 10.91it/s] 22%|██▏       | 309/1380 [00:31<01:37, 10.97it/s] 23%|██▎       | 311/1380 [00:31<01:37, 11.02it/s] 23%|██▎       | 313/1380 [00:31<01:36, 11.06it/s] 23%|██▎       | 315/1380 [00:31<01:36, 11.09it/s] 23%|██▎       | 317/1380 [00:31<01:35, 11.11it/s] 23%|██▎       | 319/1380 [00:32<01:35, 11.12it/s] 23%|██▎       | 321/1380 [00:32<01:35, 11.12it/s] 23%|██▎       | 323/1380 [00:32<01:35, 11.12it/s] 24%|██▎       | 325/1380 [00:32<01:34, 11.13it/s] 24%|██▎       | 327/1380 [00:32<01:34, 11.13it/s] 24%|██▍       | 329/1380 [00:33<01:34, 11.12it/s] 24%|██▍       | 331/1380 [00:33<01:34, 11.13it/s] 24%|██▍       | 333/1380 [00:33<01:34, 11.12it/s] 24%|██▍       | 335/1380 [00:33<01:33, 11.12it/s] 24%|██▍       | 337/1380 [00:33<01:33, 11.14it/s] 25%|██▍       | 339/1380 [00:33<01:33, 11.13it/s] 25%|██▍       | 341/1380 [00:34<01:33, 11.13it/s] 25%|██▍       | 343/1380 [00:34<01:33, 11.12it/s] 25%|██▌       | 345/1380 [00:34<01:33, 11.11it/s] 25%|██▌       | 347/1380 [00:34<01:32, 11.13it/s] 25%|██▌       | 349/1380 [00:34<01:32, 11.12it/s] 25%|██▌       | 351/1380 [00:35<01:32, 11.12it/s] 26%|██▌       | 353/1380 [00:35<01:32, 11.12it/s] 26%|██▌       | 355/1380 [00:35<01:32, 11.12it/s] 26%|██▌       | 357/1380 [00:35<01:32, 11.10it/s] 26%|██▌       | 359/1380 [00:35<01:31, 11.11it/s] 26%|██▌       | 361/1380 [00:35<01:31, 11.13it/s] 26%|██▋       | 363/1380 [00:36<01:31, 11.13it/s] 26%|██▋       | 365/1380 [00:36<01:31, 11.10it/s] 27%|██▋       | 367/1380 [00:36<01:31, 11.11it/s] 27%|██▋       | 369/1380 [00:36<01:31, 11.10it/s] 27%|██▋       | 371/1380 [00:36<01:30, 11.09it/s] 27%|██▋       | 373/1380 [00:36<01:30, 11.08it/s] 27%|██▋       | 375/1380 [00:37<01:30, 11.12it/s] 27%|██▋       | 377/1380 [00:37<01:30, 11.11it/s] 27%|██▋       | 379/1380 [00:37<01:30, 11.11it/s] 28%|██▊       | 381/1380 [00:37<01:29, 11.10it/s] 28%|██▊       | 383/1380 [00:37<01:29, 11.12it/s] 28%|██▊       | 385/1380 [00:38<01:29, 11.11it/s] 28%|██▊       | 387/1380 [00:38<01:29, 11.09it/s] 28%|██▊       | 389/1380 [00:38<01:29, 11.09it/s] 28%|██▊       | 391/1380 [00:38<01:28, 11.11it/s] 28%|██▊       | 393/1380 [00:38<01:28, 11.13it/s] 29%|██▊       | 395/1380 [00:38<01:28, 11.10it/s] 29%|██▉       | 397/1380 [00:39<01:28, 11.10it/s] 29%|██▉       | 399/1380 [00:39<01:28, 11.12it/s] 29%|██▉       | 401/1380 [00:39<01:27, 11.13it/s] 29%|██▉       | 403/1380 [00:39<01:27, 11.11it/s] 29%|██▉       | 405/1380 [00:39<01:27, 11.12it/s] 29%|██▉       | 407/1380 [00:40<01:27, 11.11it/s] 30%|██▉       | 409/1380 [00:40<01:27, 11.11it/s] 30%|██▉       | 411/1380 [00:40<01:27, 11.11it/s] 30%|██▉       | 413/1380 [00:40<01:26, 11.12it/s] 30%|███       | 415/1380 [00:40<01:26, 11.12it/s] 30%|███       | 417/1380 [00:40<01:26, 11.11it/s] 30%|███       | 419/1380 [00:41<01:26, 11.11it/s] 31%|███       | 421/1380 [00:41<01:26, 11.11it/s] 31%|███       | 423/1380 [00:41<01:26, 11.12it/s] 31%|███       | 425/1380 [00:41<01:25, 11.12it/s] 31%|███       | 427/1380 [00:41<01:25, 11.13it/s] 31%|███       | 429/1380 [00:42<01:25, 11.11it/s] 31%|███       | 431/1380 [00:42<01:25, 11.09it/s] 31%|███▏      | 433/1380 [00:42<01:25, 11.08it/s] 32%|███▏      | 435/1380 [00:42<01:25, 11.08it/s] 32%|███▏      | 437/1380 [00:42<01:25, 11.09it/s] 32%|███▏      | 439/1380 [00:42<01:25, 11.07it/s] 32%|███▏      | 441/1380 [00:43<01:24, 11.06it/s] 32%|███▏      | 443/1380 [00:43<01:24, 11.05it/s] 32%|███▏      | 445/1380 [00:43<01:24, 11.06it/s] 32%|███▏      | 447/1380 [00:43<01:24, 11.06it/s] 33%|███▎      | 449/1380 [00:43<01:24, 11.06it/s] 33%|███▎      | 451/1380 [00:44<01:24, 11.06it/s] 33%|███▎      | 453/1380 [00:44<01:23, 11.05it/s] 33%|███▎      | 455/1380 [00:44<01:23, 11.06it/s] 33%|███▎      | 457/1380 [00:44<01:23, 11.04it/s] 33%|███▎      | 459/1380 [00:44<01:23, 11.05it/s] 33%|███▎      | 461/1380 [00:44<01:23, 11.05it/s] 34%|███▎      | 463/1380 [00:45<01:22, 11.06it/s] 34%|███▎      | 465/1380 [00:45<01:22, 11.05it/s] 34%|███▍      | 467/1380 [00:45<01:22, 11.06it/s] 34%|███▍      | 469/1380 [00:45<01:22, 11.06it/s] 34%|███▍      | 471/1380 [00:45<01:22, 11.05it/s] 34%|███▍      | 473/1380 [00:46<01:22, 11.06it/s] 34%|███▍      | 475/1380 [00:46<01:21, 11.08it/s] 35%|███▍      | 477/1380 [00:46<01:21, 11.10it/s] 35%|███▍      | 479/1380 [00:46<01:21, 11.09it/s] 35%|███▍      | 481/1380 [00:46<01:21, 11.09it/s] 35%|███▌      | 483/1380 [00:46<01:20, 11.09it/s] 35%|███▌      | 485/1380 [00:47<01:20, 11.10it/s] 35%|███▌      | 487/1380 [00:47<01:20, 11.10it/s] 35%|███▌      | 489/1380 [00:47<01:20, 11.09it/s] 36%|███▌      | 491/1380 [00:47<01:20, 11.09it/s] 36%|███▌      | 493/1380 [00:47<01:20, 11.09it/s] 36%|███▌      | 495/1380 [00:48<01:19, 11.07it/s] 36%|███▌      | 497/1380 [00:48<01:19, 11.06it/s] 36%|███▌      | 499/1380 [00:48<01:19, 11.07it/s] 36%|███▋      | 501/1380 [00:48<01:19, 11.07it/s] 36%|███▋      | 503/1380 [00:48<01:19, 11.05it/s] 37%|███▋      | 505/1380 [00:48<01:19, 11.06it/s] 37%|███▋      | 507/1380 [00:49<01:18, 11.08it/s] 37%|███▋      | 509/1380 [00:49<01:18, 11.08it/s] 37%|███▋      | 511/1380 [00:49<01:18, 11.07it/s] 37%|███▋      | 513/1380 [00:49<01:18, 11.08it/s] 37%|███▋      | 515/1380 [00:49<01:18, 11.08it/s] 37%|███▋      | 517/1380 [00:49<01:17, 11.07it/s] 38%|███▊      | 519/1380 [00:50<01:17, 11.04it/s] 38%|███▊      | 521/1380 [00:50<01:17, 11.04it/s] 38%|███▊      | 523/1380 [00:50<01:17, 11.00it/s] 38%|███▊      | 525/1380 [00:50<01:17, 11.02it/s] 38%|███▊      | 527/1380 [00:50<01:17, 11.04it/s] 38%|███▊      | 529/1380 [00:51<01:17, 11.04it/s] 38%|███▊      | 531/1380 [00:51<01:16, 11.07it/s] 39%|███▊      | 533/1380 [00:51<01:16, 11.07it/s] 39%|███▉      | 535/1380 [00:51<01:16, 11.07it/s] 39%|███▉      | 537/1380 [00:51<01:16, 11.06it/s] 39%|███▉      | 539/1380 [00:51<01:15, 11.07it/s] 39%|███▉      | 541/1380 [00:52<01:15, 11.05it/s] 39%|███▉      | 543/1380 [00:52<01:15, 11.06it/s] 39%|███▉      | 545/1380 [00:52<01:15, 11.07it/s] 40%|███▉      | 547/1380 [00:52<01:15, 11.07it/s] 40%|███▉      | 549/1380 [00:52<01:15, 11.06it/s] 40%|███▉      | 551/1380 [00:53<01:14, 11.09it/s]                                                   40%|████      | 552/1380 [00:53<01:14, 11.09it/s][INFO|trainer.py:755] 2023-11-15 20:04:03,153 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:04:03,155 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:04:03,155 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:04:03,156 >>   Batch size = 8
{'eval_loss': 0.3888576030731201, 'eval_accuracy': 0.8570780399274047, 'eval_micro_f1': 0.8570780399274048, 'eval_macro_f1': 0.8356521795295458, 'eval_runtime': 2.5884, 'eval_samples_per_second': 851.495, 'eval_steps_per_second': 106.63, 'epoch': 1.0}
{'loss': 0.3013, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 120.80it/s][A
  9%|▉         | 26/276 [00:00<00:02, 114.58it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 112.14it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 110.75it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 110.00it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 109.17it/s][A
 31%|███       | 85/276 [00:00<00:01, 108.28it/s][A
 35%|███▍      | 96/276 [00:00<00:01, 107.73it/s][A
 39%|███▉      | 107/276 [00:00<00:01, 106.93it/s][A
 43%|████▎     | 118/276 [00:01<00:01, 106.33it/s][A
 47%|████▋     | 129/276 [00:01<00:01, 106.46it/s][A
 51%|█████     | 140/276 [00:01<00:01, 106.59it/s][A
 55%|█████▍    | 151/276 [00:01<00:01, 106.86it/s][A
 59%|█████▊    | 162/276 [00:01<00:01, 106.86it/s][A
 63%|██████▎   | 173/276 [00:01<00:00, 106.87it/s][A
 67%|██████▋   | 184/276 [00:01<00:00, 106.71it/s][A
 71%|███████   | 195/276 [00:01<00:00, 106.24it/s][A
 75%|███████▍  | 206/276 [00:01<00:00, 105.64it/s][A
 79%|███████▊  | 217/276 [00:02<00:00, 105.30it/s][A
 83%|████████▎ | 228/276 [00:02<00:00, 105.28it/s][A
 87%|████████▋ | 239/276 [00:02<00:00, 105.65it/s][A
 91%|█████████ | 250/276 [00:02<00:00, 105.79it/s][A
 95%|█████████▍| 261/276 [00:02<00:00, 105.61it/s][A
 99%|█████████▊| 272/276 [00:02<00:00, 105.71it/s][A                                                  
                                                  [A 40%|████      | 552/1380 [00:55<01:14, 11.09it/s]
100%|██████████| 276/276 [00:02<00:00, 105.71it/s][A
                                                  [A 40%|████      | 553/1380 [00:55<06:38,  2.08it/s] 40%|████      | 555/1380 [00:56<05:00,  2.74it/s] 40%|████      | 557/1380 [00:56<03:52,  3.54it/s] 41%|████      | 559/1380 [00:56<03:04,  4.45it/s] 41%|████      | 561/1380 [00:56<02:31,  5.42it/s] 41%|████      | 563/1380 [00:56<02:07,  6.40it/s] 41%|████      | 565/1380 [00:56<01:51,  7.33it/s] 41%|████      | 567/1380 [00:57<01:39,  8.15it/s] 41%|████      | 569/1380 [00:57<01:31,  8.85it/s] 41%|████▏     | 571/1380 [00:57<01:25,  9.42it/s] 42%|████▏     | 573/1380 [00:57<01:21,  9.85it/s] 42%|████▏     | 575/1380 [00:57<01:18, 10.20it/s] 42%|████▏     | 577/1380 [00:58<01:16, 10.44it/s] 42%|████▏     | 579/1380 [00:58<01:15, 10.63it/s] 42%|████▏     | 581/1380 [00:58<01:14, 10.74it/s] 42%|████▏     | 583/1380 [00:58<01:13, 10.83it/s] 42%|████▏     | 585/1380 [00:58<01:13, 10.89it/s] 43%|████▎     | 587/1380 [00:58<01:12, 10.95it/s] 43%|████▎     | 589/1380 [00:59<01:12, 10.98it/s] 43%|████▎     | 591/1380 [00:59<01:11, 11.00it/s] 43%|████▎     | 593/1380 [00:59<01:11, 11.02it/s] 43%|████▎     | 595/1380 [00:59<01:11, 11.03it/s] 43%|████▎     | 597/1380 [00:59<01:10, 11.05it/s] 43%|████▎     | 599/1380 [01:00<01:10, 11.07it/s] 44%|████▎     | 601/1380 [01:00<01:10, 11.08it/s] 44%|████▎     | 603/1380 [01:00<01:10, 11.08it/s] 44%|████▍     | 605/1380 [01:00<01:10, 11.06it/s] 44%|████▍     | 607/1380 [01:00<01:09, 11.06it/s] 44%|████▍     | 609/1380 [01:00<01:09, 11.06it/s] 44%|████▍     | 611/1380 [01:01<01:09, 11.08it/s] 44%|████▍     | 613/1380 [01:01<01:09, 11.07it/s] 45%|████▍     | 615/1380 [01:01<01:09, 11.06it/s] 45%|████▍     | 617/1380 [01:01<01:08, 11.06it/s] 45%|████▍     | 619/1380 [01:01<01:08, 11.05it/s] 45%|████▌     | 621/1380 [01:02<01:08, 11.06it/s] 45%|████▌     | 623/1380 [01:02<01:08, 11.06it/s] 45%|████▌     | 625/1380 [01:02<01:08, 11.07it/s] 45%|████▌     | 627/1380 [01:02<01:08, 11.07it/s] 46%|████▌     | 629/1380 [01:02<01:07, 11.06it/s] 46%|████▌     | 631/1380 [01:02<01:07, 11.07it/s] 46%|████▌     | 633/1380 [01:03<01:07, 11.07it/s] 46%|████▌     | 635/1380 [01:03<01:07, 11.08it/s] 46%|████▌     | 637/1380 [01:03<01:07, 11.05it/s] 46%|████▋     | 639/1380 [01:03<01:06, 11.06it/s] 46%|████▋     | 641/1380 [01:03<01:06, 11.07it/s] 47%|████▋     | 643/1380 [01:03<01:06, 11.06it/s] 47%|████▋     | 645/1380 [01:04<01:06, 11.06it/s] 47%|████▋     | 647/1380 [01:04<01:06, 11.07it/s] 47%|████▋     | 649/1380 [01:04<01:06, 11.06it/s] 47%|████▋     | 651/1380 [01:04<01:05, 11.05it/s] 47%|████▋     | 653/1380 [01:04<01:05, 11.07it/s] 47%|████▋     | 655/1380 [01:05<01:05, 11.08it/s] 48%|████▊     | 657/1380 [01:05<01:05, 11.06it/s] 48%|████▊     | 659/1380 [01:05<01:05, 11.03it/s] 48%|████▊     | 661/1380 [01:05<01:05, 11.05it/s] 48%|████▊     | 663/1380 [01:05<01:04, 11.06it/s] 48%|████▊     | 665/1380 [01:05<01:04, 11.08it/s] 48%|████▊     | 667/1380 [01:06<01:04, 11.08it/s] 48%|████▊     | 669/1380 [01:06<01:04, 11.07it/s] 49%|████▊     | 671/1380 [01:06<01:03, 11.08it/s] 49%|████▉     | 673/1380 [01:06<01:03, 11.08it/s] 49%|████▉     | 675/1380 [01:06<01:03, 11.08it/s] 49%|████▉     | 677/1380 [01:07<01:03, 11.07it/s] 49%|████▉     | 679/1380 [01:07<01:03, 11.07it/s] 49%|████▉     | 681/1380 [01:07<01:03, 11.05it/s] 49%|████▉     | 683/1380 [01:07<01:03, 11.02it/s] 50%|████▉     | 685/1380 [01:07<01:03, 11.02it/s] 50%|████▉     | 687/1380 [01:07<01:02, 11.02it/s] 50%|████▉     | 689/1380 [01:08<01:02, 11.05it/s] 50%|█████     | 691/1380 [01:08<01:02, 11.06it/s] 50%|█████     | 693/1380 [01:08<01:02, 11.07it/s] 50%|█████     | 695/1380 [01:08<01:01, 11.08it/s] 51%|█████     | 697/1380 [01:08<01:01, 11.07it/s] 51%|█████     | 699/1380 [01:09<01:01, 11.08it/s] 51%|█████     | 701/1380 [01:09<01:01, 11.07it/s] 51%|█████     | 703/1380 [01:09<01:01, 11.06it/s] 51%|█████     | 705/1380 [01:09<01:01, 11.05it/s] 51%|█████     | 707/1380 [01:09<01:00, 11.06it/s] 51%|█████▏    | 709/1380 [01:09<01:00, 11.07it/s] 52%|█████▏    | 711/1380 [01:10<01:00, 11.07it/s] 52%|█████▏    | 713/1380 [01:10<01:00, 11.06it/s] 52%|█████▏    | 715/1380 [01:10<01:00, 11.06it/s] 52%|█████▏    | 717/1380 [01:10<00:59, 11.06it/s] 52%|█████▏    | 719/1380 [01:10<00:59, 11.06it/s] 52%|█████▏    | 721/1380 [01:11<00:59, 11.05it/s] 52%|█████▏    | 723/1380 [01:11<00:59, 11.06it/s] 53%|█████▎    | 725/1380 [01:11<00:59, 11.06it/s] 53%|█████▎    | 727/1380 [01:11<00:59, 11.06it/s] 53%|█████▎    | 729/1380 [01:11<00:58, 11.06it/s] 53%|█████▎    | 731/1380 [01:11<00:58, 11.06it/s] 53%|█████▎    | 733/1380 [01:12<00:58, 11.07it/s] 53%|█████▎    | 735/1380 [01:12<00:58, 11.06it/s] 53%|█████▎    | 737/1380 [01:12<00:58, 11.06it/s] 54%|█████▎    | 739/1380 [01:12<00:58, 11.04it/s] 54%|█████▎    | 741/1380 [01:12<00:57, 11.05it/s] 54%|█████▍    | 743/1380 [01:13<00:57, 11.03it/s] 54%|█████▍    | 745/1380 [01:13<00:57, 11.06it/s] 54%|█████▍    | 747/1380 [01:13<00:57, 11.06it/s] 54%|█████▍    | 749/1380 [01:13<00:57, 11.05it/s] 54%|█████▍    | 751/1380 [01:13<00:56, 11.04it/s] 55%|█████▍    | 753/1380 [01:13<00:56, 11.04it/s] 55%|█████▍    | 755/1380 [01:14<00:56, 11.04it/s] 55%|█████▍    | 757/1380 [01:14<00:56, 11.05it/s] 55%|█████▌    | 759/1380 [01:14<00:56, 11.07it/s] 55%|█████▌    | 761/1380 [01:14<00:55, 11.07it/s] 55%|█████▌    | 763/1380 [01:14<00:55, 11.07it/s] 55%|█████▌    | 765/1380 [01:15<00:55, 11.05it/s] 56%|█████▌    | 767/1380 [01:15<00:55, 11.04it/s] 56%|█████▌    | 769/1380 [01:15<00:55, 11.05it/s] 56%|█████▌    | 771/1380 [01:15<00:55, 11.04it/s] 56%|█████▌    | 773/1380 [01:15<00:55, 11.01it/s] 56%|█████▌    | 775/1380 [01:15<00:54, 11.03it/s] 56%|█████▋    | 777/1380 [01:16<00:54, 11.06it/s] 56%|█████▋    | 779/1380 [01:16<00:54, 11.05it/s] 57%|█████▋    | 781/1380 [01:16<00:54, 11.02it/s] 57%|█████▋    | 783/1380 [01:16<00:54, 11.03it/s] 57%|█████▋    | 785/1380 [01:16<00:53, 11.04it/s] 57%|█████▋    | 787/1380 [01:17<00:53, 11.03it/s] 57%|█████▋    | 789/1380 [01:17<00:53, 11.03it/s] 57%|█████▋    | 791/1380 [01:17<00:53, 11.03it/s] 57%|█████▋    | 793/1380 [01:17<00:53, 11.05it/s] 58%|█████▊    | 795/1380 [01:17<00:52, 11.04it/s] 58%|█████▊    | 797/1380 [01:17<00:52, 11.04it/s] 58%|█████▊    | 799/1380 [01:18<00:52, 11.04it/s] 58%|█████▊    | 801/1380 [01:18<00:52, 11.05it/s] 58%|█████▊    | 803/1380 [01:18<00:52, 11.02it/s] 58%|█████▊    | 805/1380 [01:18<00:52, 11.04it/s] 58%|█████▊    | 807/1380 [01:18<00:51, 11.05it/s] 59%|█████▊    | 809/1380 [01:19<00:51, 11.05it/s] 59%|█████▉    | 811/1380 [01:19<00:51, 11.02it/s] 59%|█████▉    | 813/1380 [01:19<00:51, 11.03it/s] 59%|█████▉    | 815/1380 [01:19<00:51, 11.04it/s] 59%|█████▉    | 817/1380 [01:19<00:50, 11.06it/s] 59%|█████▉    | 819/1380 [01:19<00:50, 11.03it/s] 59%|█████▉    | 821/1380 [01:20<00:50, 11.04it/s] 60%|█████▉    | 823/1380 [01:20<00:50, 11.06it/s] 60%|█████▉    | 825/1380 [01:20<00:50, 11.06it/s] 60%|█████▉    | 827/1380 [01:20<00:50, 11.06it/s]                                                   60%|██████    | 828/1380 [01:20<00:49, 11.06it/s][INFO|trainer.py:755] 2023-11-15 20:04:30,727 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:04:30,729 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:04:30,729 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:04:30,729 >>   Batch size = 8
{'eval_loss': 0.4104430079460144, 'eval_accuracy': 0.8548094373865699, 'eval_micro_f1': 0.8548094373865699, 'eval_macro_f1': 0.8374705582782185, 'eval_runtime': 2.6333, 'eval_samples_per_second': 836.971, 'eval_steps_per_second': 104.811, 'epoch': 2.0}
{'loss': 0.204, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  4%|▍         | 12/276 [00:00<00:02, 119.85it/s][A
  9%|▊         | 24/276 [00:00<00:02, 113.30it/s][A
 13%|█▎        | 36/276 [00:00<00:02, 110.97it/s][A
 17%|█▋        | 48/276 [00:00<00:02, 109.76it/s][A
 21%|██▏       | 59/276 [00:00<00:01, 108.57it/s][A
 25%|██▌       | 70/276 [00:00<00:01, 107.41it/s][A
 29%|██▉       | 81/276 [00:00<00:01, 107.05it/s][A
 33%|███▎      | 92/276 [00:00<00:01, 106.47it/s][A
 37%|███▋      | 103/276 [00:00<00:01, 105.97it/s][A
 41%|████▏     | 114/276 [00:01<00:01, 105.54it/s][A
 45%|████▌     | 125/276 [00:01<00:01, 105.37it/s][A
 49%|████▉     | 136/276 [00:01<00:01, 105.34it/s][A
 53%|█████▎    | 147/276 [00:01<00:01, 105.53it/s][A
 57%|█████▋    | 158/276 [00:01<00:01, 105.39it/s][A
 61%|██████    | 169/276 [00:01<00:01, 105.26it/s][A
 65%|██████▌   | 180/276 [00:01<00:00, 104.99it/s][A
 69%|██████▉   | 191/276 [00:01<00:00, 104.72it/s][A
 73%|███████▎  | 202/276 [00:01<00:00, 104.12it/s][A
 77%|███████▋  | 213/276 [00:02<00:00, 102.92it/s][A
 81%|████████  | 224/276 [00:02<00:00, 101.91it/s][A
 85%|████████▌ | 235/276 [00:02<00:00, 101.66it/s][A
 89%|████████▉ | 246/276 [00:02<00:00, 102.26it/s][A
 93%|█████████▎| 257/276 [00:02<00:00, 102.74it/s][A
 97%|█████████▋| 268/276 [00:02<00:00, 102.88it/s][A                                                  
                                                  [A 60%|██████    | 828/1380 [01:23<00:49, 11.06it/s]
100%|██████████| 276/276 [00:02<00:00, 102.88it/s][A
                                                  [A 60%|██████    | 829/1380 [01:23<04:29,  2.04it/s] 60%|██████    | 831/1380 [01:23<03:23,  2.70it/s] 60%|██████    | 833/1380 [01:23<02:37,  3.47it/s] 61%|██████    | 835/1380 [01:24<02:05,  4.35it/s] 61%|██████    | 836/1380 [01:24<01:53,  4.81it/s] 61%|██████    | 837/1380 [01:24<01:41,  5.34it/s] 61%|██████    | 838/1380 [01:24<01:31,  5.90it/s] 61%|██████    | 839/1380 [01:24<01:23,  6.50it/s] 61%|██████    | 840/1380 [01:24<01:16,  7.07it/s] 61%|██████    | 842/1380 [01:24<01:07,  7.99it/s] 61%|██████    | 843/1380 [01:24<01:05,  8.25it/s] 61%|██████    | 844/1380 [01:24<01:02,  8.52it/s] 61%|██████    | 845/1380 [01:25<01:01,  8.69it/s] 61%|██████▏   | 846/1380 [01:25<01:00,  8.86it/s] 61%|██████▏   | 847/1380 [01:25<00:59,  8.93it/s] 61%|██████▏   | 848/1380 [01:25<00:58,  9.13it/s] 62%|██████▏   | 849/1380 [01:25<00:57,  9.18it/s] 62%|██████▏   | 850/1380 [01:25<00:57,  9.18it/s] 62%|██████▏   | 851/1380 [01:25<00:57,  9.21it/s] 62%|██████▏   | 852/1380 [01:25<00:56,  9.33it/s] 62%|██████▏   | 853/1380 [01:25<00:56,  9.27it/s] 62%|██████▏   | 854/1380 [01:26<00:56,  9.24it/s] 62%|██████▏   | 855/1380 [01:26<00:56,  9.23it/s] 62%|██████▏   | 856/1380 [01:26<00:56,  9.19it/s] 62%|██████▏   | 857/1380 [01:26<00:56,  9.23it/s] 62%|██████▏   | 858/1380 [01:26<00:57,  9.12it/s] 62%|██████▏   | 859/1380 [01:26<00:56,  9.19it/s] 62%|██████▏   | 860/1380 [01:26<00:56,  9.13it/s] 62%|██████▏   | 861/1380 [01:26<00:57,  9.09it/s] 62%|██████▏   | 862/1380 [01:26<00:57,  9.03it/s] 63%|██████▎   | 863/1380 [01:27<00:56,  9.20it/s] 63%|██████▎   | 864/1380 [01:27<00:56,  9.06it/s] 63%|██████▎   | 865/1380 [01:27<00:57,  9.03it/s] 63%|██████▎   | 866/1380 [01:27<00:56,  9.04it/s] 63%|██████▎   | 867/1380 [01:27<00:56,  9.03it/s] 63%|██████▎   | 868/1380 [01:27<00:56,  8.99it/s] 63%|██████▎   | 869/1380 [01:27<00:56,  8.97it/s] 63%|██████▎   | 870/1380 [01:27<00:56,  8.98it/s] 63%|██████▎   | 871/1380 [01:27<00:56,  8.96it/s] 63%|██████▎   | 872/1380 [01:28<00:56,  8.96it/s] 63%|██████▎   | 873/1380 [01:28<00:56,  8.93it/s] 63%|██████▎   | 874/1380 [01:28<00:56,  9.02it/s] 63%|██████▎   | 875/1380 [01:28<00:56,  8.95it/s] 63%|██████▎   | 876/1380 [01:28<00:56,  8.91it/s] 64%|██████▎   | 877/1380 [01:28<00:56,  8.94it/s] 64%|██████▎   | 878/1380 [01:28<00:54,  9.15it/s] 64%|██████▎   | 879/1380 [01:28<00:55,  9.07it/s] 64%|██████▍   | 880/1380 [01:28<00:56,  8.92it/s] 64%|██████▍   | 881/1380 [01:29<00:55,  8.92it/s] 64%|██████▍   | 882/1380 [01:29<00:54,  9.06it/s] 64%|██████▍   | 883/1380 [01:29<00:54,  9.08it/s] 64%|██████▍   | 884/1380 [01:29<00:55,  8.97it/s] 64%|██████▍   | 885/1380 [01:29<00:55,  8.88it/s] 64%|██████▍   | 886/1380 [01:29<00:55,  8.93it/s] 64%|██████▍   | 887/1380 [01:29<00:55,  8.85it/s] 64%|██████▍   | 888/1380 [01:29<00:55,  8.90it/s] 64%|██████▍   | 889/1380 [01:29<00:54,  8.94it/s] 64%|██████▍   | 890/1380 [01:30<00:54,  8.95it/s] 65%|██████▍   | 891/1380 [01:30<00:54,  8.95it/s] 65%|██████▍   | 892/1380 [01:30<00:54,  8.95it/s] 65%|██████▍   | 893/1380 [01:30<00:54,  8.98it/s] 65%|██████▍   | 894/1380 [01:30<00:54,  8.96it/s] 65%|██████▍   | 895/1380 [01:30<00:54,  8.86it/s] 65%|██████▍   | 896/1380 [01:30<00:54,  8.85it/s] 65%|██████▌   | 897/1380 [01:30<00:53,  9.04it/s] 65%|██████▌   | 898/1380 [01:30<00:53,  8.94it/s] 65%|██████▌   | 899/1380 [01:31<00:53,  8.94it/s] 65%|██████▌   | 900/1380 [01:31<00:53,  8.91it/s] 65%|██████▌   | 901/1380 [01:31<00:52,  9.21it/s] 65%|██████▌   | 902/1380 [01:31<00:52,  9.05it/s] 65%|██████▌   | 903/1380 [01:31<00:53,  8.96it/s] 66%|██████▌   | 904/1380 [01:31<00:53,  8.85it/s] 66%|██████▌   | 905/1380 [01:31<00:53,  8.91it/s] 66%|██████▌   | 906/1380 [01:31<00:53,  8.94it/s] 66%|██████▌   | 907/1380 [01:31<00:52,  8.99it/s] 66%|██████▌   | 908/1380 [01:32<00:52,  9.02it/s] 66%|██████▌   | 909/1380 [01:32<00:52,  8.97it/s] 66%|██████▌   | 910/1380 [01:32<00:52,  8.97it/s] 66%|██████▌   | 911/1380 [01:32<00:52,  8.94it/s] 66%|██████▌   | 912/1380 [01:32<00:51,  9.14it/s] 66%|██████▌   | 913/1380 [01:32<00:51,  9.10it/s] 66%|██████▌   | 914/1380 [01:32<00:51,  8.98it/s] 66%|██████▋   | 915/1380 [01:32<00:52,  8.94it/s] 66%|██████▋   | 916/1380 [01:32<00:51,  9.07it/s] 66%|██████▋   | 917/1380 [01:33<00:50,  9.09it/s] 67%|██████▋   | 918/1380 [01:33<00:50,  9.13it/s] 67%|██████▋   | 919/1380 [01:33<00:50,  9.09it/s] 67%|██████▋   | 920/1380 [01:33<00:50,  9.14it/s] 67%|██████▋   | 921/1380 [01:33<00:50,  9.14it/s] 67%|██████▋   | 922/1380 [01:33<00:49,  9.19it/s] 67%|██████▋   | 923/1380 [01:33<00:49,  9.22it/s] 67%|██████▋   | 924/1380 [01:33<00:49,  9.20it/s] 67%|██████▋   | 925/1380 [01:33<00:49,  9.17it/s] 67%|██████▋   | 926/1380 [01:34<00:49,  9.20it/s] 67%|██████▋   | 927/1380 [01:34<00:48,  9.34it/s] 67%|██████▋   | 928/1380 [01:34<00:48,  9.25it/s] 67%|██████▋   | 929/1380 [01:34<00:49,  9.20it/s] 67%|██████▋   | 930/1380 [01:34<00:49,  9.13it/s] 67%|██████▋   | 931/1380 [01:34<00:48,  9.23it/s] 68%|██████▊   | 932/1380 [01:34<00:48,  9.25it/s] 68%|██████▊   | 933/1380 [01:34<00:48,  9.23it/s] 68%|██████▊   | 934/1380 [01:34<00:48,  9.13it/s] 68%|██████▊   | 935/1380 [01:35<00:48,  9.11it/s] 68%|██████▊   | 936/1380 [01:35<00:49,  9.05it/s] 68%|██████▊   | 937/1380 [01:35<00:48,  9.13it/s] 68%|██████▊   | 938/1380 [01:35<00:48,  9.16it/s] 68%|██████▊   | 939/1380 [01:35<00:48,  9.15it/s] 68%|██████▊   | 940/1380 [01:35<00:47,  9.18it/s] 68%|██████▊   | 941/1380 [01:35<00:48,  9.10it/s] 68%|██████▊   | 942/1380 [01:35<00:47,  9.29it/s] 68%|██████▊   | 943/1380 [01:35<00:47,  9.23it/s] 68%|██████▊   | 944/1380 [01:36<00:47,  9.19it/s] 68%|██████▊   | 945/1380 [01:36<00:47,  9.14it/s] 69%|██████▊   | 946/1380 [01:36<00:47,  9.22it/s] 69%|██████▊   | 947/1380 [01:36<00:47,  9.21it/s] 69%|██████▊   | 948/1380 [01:36<00:46,  9.24it/s] 69%|██████▉   | 949/1380 [01:36<00:46,  9.17it/s] 69%|██████▉   | 950/1380 [01:36<00:47,  9.12it/s] 69%|██████▉   | 951/1380 [01:36<00:46,  9.14it/s] 69%|██████▉   | 952/1380 [01:36<00:47,  9.05it/s] 69%|██████▉   | 953/1380 [01:36<00:47,  8.99it/s] 69%|██████▉   | 954/1380 [01:37<00:47,  9.04it/s] 69%|██████▉   | 955/1380 [01:37<00:47,  9.00it/s] 69%|██████▉   | 956/1380 [01:37<00:46,  9.06it/s] 69%|██████▉   | 957/1380 [01:37<00:45,  9.24it/s] 69%|██████▉   | 958/1380 [01:37<00:45,  9.19it/s] 69%|██████▉   | 959/1380 [01:37<00:45,  9.25it/s] 70%|██████▉   | 960/1380 [01:37<00:45,  9.20it/s] 70%|██████▉   | 961/1380 [01:37<00:45,  9.13it/s] 70%|██████▉   | 962/1380 [01:37<00:45,  9.11it/s] 70%|██████▉   | 963/1380 [01:38<00:45,  9.13it/s] 70%|██████▉   | 964/1380 [01:38<00:44,  9.25it/s] 70%|██████▉   | 965/1380 [01:38<00:44,  9.23it/s] 70%|███████   | 966/1380 [01:38<00:45,  9.13it/s] 70%|███████   | 967/1380 [01:38<00:45,  9.08it/s] 70%|███████   | 968/1380 [01:38<00:44,  9.26it/s] 70%|███████   | 969/1380 [01:38<00:44,  9.26it/s] 70%|███████   | 970/1380 [01:38<00:44,  9.27it/s] 70%|███████   | 971/1380 [01:38<00:44,  9.19it/s] 70%|███████   | 972/1380 [01:39<00:44,  9.12it/s] 71%|███████   | 973/1380 [01:39<00:44,  9.11it/s] 71%|███████   | 974/1380 [01:39<00:44,  9.13it/s] 71%|███████   | 975/1380 [01:39<00:43,  9.21it/s] 71%|███████   | 976/1380 [01:39<00:43,  9.18it/s] 71%|███████   | 977/1380 [01:39<00:43,  9.22it/s] 71%|███████   | 978/1380 [01:39<00:44,  9.12it/s] 71%|███████   | 979/1380 [01:39<00:43,  9.32it/s] 71%|███████   | 980/1380 [01:39<00:43,  9.25it/s] 71%|███████   | 981/1380 [01:40<00:42,  9.29it/s] 71%|███████   | 982/1380 [01:40<00:43,  9.19it/s] 71%|███████   | 983/1380 [01:40<00:43,  9.12it/s] 71%|███████▏  | 984/1380 [01:40<00:43,  9.15it/s] 71%|███████▏  | 985/1380 [01:40<00:43,  9.15it/s] 71%|███████▏  | 986/1380 [01:40<00:42,  9.26it/s] 72%|███████▏  | 987/1380 [01:40<00:42,  9.26it/s] 72%|███████▏  | 988/1380 [01:40<00:42,  9.19it/s] 72%|███████▏  | 989/1380 [01:40<00:42,  9.17it/s] 72%|███████▏  | 990/1380 [01:41<00:41,  9.34it/s] 72%|███████▏  | 991/1380 [01:41<00:41,  9.28it/s] 72%|███████▏  | 992/1380 [01:41<00:41,  9.25it/s] 72%|███████▏  | 993/1380 [01:41<00:42,  9.16it/s] 72%|███████▏  | 994/1380 [01:41<00:42,  9.17it/s] 72%|███████▏  | 995/1380 [01:41<00:41,  9.20it/s] 72%|███████▏  | 996/1380 [01:41<00:41,  9.21it/s] 72%|███████▏  | 997/1380 [01:41<00:40,  9.34it/s] 72%|███████▏  | 998/1380 [01:41<00:41,  9.31it/s] 72%|███████▏  | 999/1380 [01:41<00:41,  9.28it/s] 72%|███████▏  | 1000/1380 [01:42<00:40,  9.32it/s] 73%|███████▎  | 1001/1380 [01:42<00:40,  9.37it/s] 73%|███████▎  | 1002/1380 [01:42<00:40,  9.35it/s] 73%|███████▎  | 1003/1380 [01:42<00:40,  9.26it/s] 73%|███████▎  | 1004/1380 [01:42<00:41,  9.16it/s] 73%|███████▎  | 1005/1380 [01:42<00:41,  9.13it/s] 73%|███████▎  | 1006/1380 [01:42<00:41,  9.11it/s] 73%|███████▎  | 1007/1380 [01:42<00:41,  9.07it/s] 73%|███████▎  | 1008/1380 [01:42<00:40,  9.18it/s] 73%|███████▎  | 1009/1380 [01:43<00:40,  9.07it/s] 73%|███████▎  | 1010/1380 [01:43<00:40,  9.07it/s] 73%|███████▎  | 1011/1380 [01:43<00:40,  9.04it/s] 73%|███████▎  | 1013/1380 [01:43<00:39,  9.28it/s] 73%|███████▎  | 1014/1380 [01:43<00:39,  9.26it/s] 74%|███████▎  | 1015/1380 [01:43<00:39,  9.18it/s] 74%|███████▎  | 1016/1380 [01:43<00:39,  9.29it/s] 74%|███████▎  | 1017/1380 [01:43<00:39,  9.24it/s] 74%|███████▍  | 1018/1380 [01:44<00:39,  9.18it/s] 74%|███████▍  | 1019/1380 [01:44<00:38,  9.27it/s] 74%|███████▍  | 1020/1380 [01:44<00:39,  9.23it/s] 74%|███████▍  | 1021/1380 [01:44<00:38,  9.21it/s] 74%|███████▍  | 1022/1380 [01:44<00:38,  9.21it/s] 74%|███████▍  | 1023/1380 [01:44<00:38,  9.33it/s] 74%|███████▍  | 1024/1380 [01:44<00:38,  9.22it/s] 74%|███████▍  | 1025/1380 [01:44<00:38,  9.17it/s] 74%|███████▍  | 1026/1380 [01:44<00:38,  9.17it/s] 74%|███████▍  | 1027/1380 [01:45<00:37,  9.37it/s] 74%|███████▍  | 1028/1380 [01:45<00:37,  9.32it/s] 75%|███████▍  | 1029/1380 [01:45<00:37,  9.27it/s] 75%|███████▍  | 1030/1380 [01:45<00:37,  9.22it/s] 75%|███████▍  | 1031/1380 [01:45<00:37,  9.25it/s] 75%|███████▍  | 1032/1380 [01:45<00:37,  9.23it/s] 75%|███████▍  | 1033/1380 [01:45<00:37,  9.24it/s] 75%|███████▍  | 1034/1380 [01:45<00:36,  9.35it/s] 75%|███████▌  | 1035/1380 [01:45<00:37,  9.30it/s] 75%|███████▌  | 1036/1380 [01:46<00:37,  9.27it/s] 75%|███████▌  | 1037/1380 [01:46<00:37,  9.25it/s] 75%|███████▌  | 1038/1380 [01:46<00:36,  9.33it/s] 75%|███████▌  | 1039/1380 [01:46<00:37,  9.21it/s] 75%|███████▌  | 1040/1380 [01:46<00:36,  9.19it/s] 75%|███████▌  | 1041/1380 [01:46<00:36,  9.23it/s] 76%|███████▌  | 1042/1380 [01:46<00:36,  9.24it/s] 76%|███████▌  | 1043/1380 [01:46<00:36,  9.24it/s] 76%|███████▌  | 1044/1380 [01:46<00:36,  9.29it/s] 76%|███████▌  | 1045/1380 [01:46<00:35,  9.46it/s] 76%|███████▌  | 1046/1380 [01:47<00:35,  9.36it/s] 76%|███████▌  | 1047/1380 [01:47<00:35,  9.39it/s] 76%|███████▌  | 1048/1380 [01:47<00:35,  9.29it/s] 76%|███████▌  | 1049/1380 [01:47<00:35,  9.28it/s] 76%|███████▌  | 1050/1380 [01:47<00:35,  9.24it/s] 76%|███████▌  | 1051/1380 [01:47<00:35,  9.24it/s] 76%|███████▌  | 1052/1380 [01:47<00:34,  9.39it/s] 76%|███████▋  | 1053/1380 [01:47<00:35,  9.33it/s] 76%|███████▋  | 1054/1380 [01:47<00:34,  9.32it/s] 76%|███████▋  | 1055/1380 [01:48<00:35,  9.27it/s] 77%|███████▋  | 1056/1380 [01:48<00:34,  9.32it/s] 77%|███████▋  | 1057/1380 [01:48<00:34,  9.25it/s] 77%|███████▋  | 1058/1380 [01:48<00:34,  9.23it/s] 77%|███████▋  | 1059/1380 [01:48<00:34,  9.27it/s] 77%|███████▋  | 1060/1380 [01:48<00:34,  9.26it/s] 77%|███████▋  | 1061/1380 [01:48<00:34,  9.23it/s] 77%|███████▋  | 1062/1380 [01:48<00:34,  9.24it/s] 77%|███████▋  | 1063/1380 [01:48<00:33,  9.34it/s] 77%|███████▋  | 1064/1380 [01:49<00:33,  9.29it/s] 77%|███████▋  | 1065/1380 [01:49<00:34,  9.24it/s] 77%|███████▋  | 1066/1380 [01:49<00:34,  9.16it/s] 77%|███████▋  | 1067/1380 [01:49<00:34,  9.17it/s] 77%|███████▋  | 1068/1380 [01:49<00:34,  9.07it/s] 77%|███████▋  | 1069/1380 [01:49<00:34,  9.05it/s] 78%|███████▊  | 1070/1380 [01:49<00:33,  9.20it/s] 78%|███████▊  | 1071/1380 [01:49<00:33,  9.12it/s] 78%|███████▊  | 1072/1380 [01:49<00:33,  9.10it/s] 78%|███████▊  | 1073/1380 [01:50<00:33,  9.09it/s] 78%|███████▊  | 1074/1380 [01:50<00:33,  9.15it/s] 78%|███████▊  | 1075/1380 [01:50<00:33,  9.16it/s] 78%|███████▊  | 1076/1380 [01:50<00:33,  9.15it/s] 78%|███████▊  | 1077/1380 [01:50<00:32,  9.19it/s] 78%|███████▊  | 1078/1380 [01:50<00:32,  9.20it/s] 78%|███████▊  | 1079/1380 [01:50<00:32,  9.20it/s] 78%|███████▊  | 1080/1380 [01:50<00:32,  9.21it/s] 78%|███████▊  | 1081/1380 [01:50<00:32,  9.27it/s] 78%|███████▊  | 1082/1380 [01:50<00:32,  9.20it/s] 78%|███████▊  | 1083/1380 [01:51<00:32,  9.17it/s] 79%|███████▊  | 1084/1380 [01:51<00:32,  9.18it/s] 79%|███████▊  | 1085/1380 [01:51<00:32,  9.20it/s] 79%|███████▊  | 1086/1380 [01:51<00:32,  9.18it/s] 79%|███████▉  | 1087/1380 [01:51<00:31,  9.20it/s] 79%|███████▉  | 1088/1380 [01:51<00:31,  9.33it/s] 79%|███████▉  | 1089/1380 [01:51<00:31,  9.29it/s] 79%|███████▉  | 1090/1380 [01:51<00:31,  9.23it/s] 79%|███████▉  | 1091/1380 [01:51<00:31,  9.23it/s] 79%|███████▉  | 1092/1380 [01:52<00:31,  9.18it/s] 79%|███████▉  | 1093/1380 [01:52<00:31,  9.05it/s] 79%|███████▉  | 1094/1380 [01:52<00:31,  9.05it/s] 79%|███████▉  | 1095/1380 [01:52<00:31,  9.04it/s] 79%|███████▉  | 1096/1380 [01:52<00:31,  9.05it/s] 79%|███████▉  | 1097/1380 [01:52<00:31,  9.01it/s] 80%|███████▉  | 1098/1380 [01:52<00:31,  9.02it/s] 80%|███████▉  | 1099/1380 [01:52<00:30,  9.22it/s] 80%|███████▉  | 1100/1380 [01:52<00:30,  9.20it/s] 80%|███████▉  | 1101/1380 [01:53<00:30,  9.20it/s] 80%|███████▉  | 1102/1380 [01:53<00:30,  9.20it/s] 80%|███████▉  | 1103/1380 [01:53<00:30,  9.23it/s]                                                    80%|████████  | 1104/1380 [01:53<00:29,  9.23it/s][INFO|trainer.py:755] 2023-11-15 20:05:03,383 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:05:03,384 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:05:03,385 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:05:03,385 >>   Batch size = 8
{'eval_loss': 0.45065146684646606, 'eval_accuracy': 0.8489110707803993, 'eval_micro_f1': 0.8489110707803994, 'eval_macro_f1': 0.8315163805283646, 'eval_runtime': 2.6814, 'eval_samples_per_second': 821.95, 'eval_steps_per_second': 102.93, 'epoch': 3.0}
{'loss': 0.1324, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 84.52it/s][A
  7%|▋         | 18/276 [00:00<00:03, 83.13it/s][A
 10%|▉         | 27/276 [00:00<00:03, 80.36it/s][A
 13%|█▎        | 36/276 [00:00<00:03, 78.33it/s][A
 16%|█▌        | 44/276 [00:00<00:03, 77.05it/s][A
 19%|█▉        | 53/276 [00:00<00:02, 79.03it/s][A
 22%|██▏       | 61/276 [00:00<00:02, 78.50it/s][A
 25%|██▌       | 69/276 [00:00<00:02, 76.37it/s][A
 28%|██▊       | 78/276 [00:00<00:02, 78.63it/s][A
 31%|███       | 86/276 [00:01<00:02, 77.14it/s][A
 34%|███▍      | 94/276 [00:01<00:02, 76.53it/s][A
 37%|███▋      | 102/276 [00:01<00:02, 75.70it/s][A
 40%|████      | 111/276 [00:01<00:02, 77.28it/s][A
 43%|████▎     | 119/276 [00:01<00:02, 76.02it/s][A
 46%|████▌     | 127/276 [00:01<00:01, 74.85it/s][A
 49%|████▉     | 135/276 [00:01<00:01, 75.91it/s][A
 52%|█████▏    | 143/276 [00:01<00:01, 76.63it/s][A
 55%|█████▍    | 151/276 [00:01<00:01, 75.40it/s][A
 58%|█████▊    | 159/276 [00:02<00:01, 75.83it/s][A
 61%|██████    | 168/276 [00:02<00:01, 78.63it/s][A
 64%|██████▍   | 176/276 [00:02<00:01, 75.56it/s][A
 67%|██████▋   | 184/276 [00:02<00:01, 74.84it/s][A
 70%|██████▉   | 192/276 [00:02<00:01, 73.99it/s][A
 73%|███████▎  | 201/276 [00:02<00:00, 75.38it/s][A
 76%|███████▌  | 209/276 [00:02<00:00, 76.10it/s][A
 79%|███████▊  | 217/276 [00:02<00:00, 75.20it/s][A
 82%|████████▏ | 226/276 [00:02<00:00, 77.77it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 75.88it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 74.43it/s][A
 91%|█████████ | 250/276 [00:03<00:00, 73.76it/s][A
 94%|█████████▍| 259/276 [00:03<00:00, 75.79it/s][A
 97%|█████████▋| 267/276 [00:03<00:00, 74.95it/s][A
100%|█████████▉| 275/276 [00:03<00:00, 74.84it/s][A                                                   
                                                 [A 80%|████████  | 1104/1380 [01:57<00:29,  9.23it/s]
100%|██████████| 276/276 [00:03<00:00, 74.84it/s][A
                                                 [A 80%|████████  | 1105/1380 [01:57<04:21,  1.05it/s] 80%|████████  | 1106/1380 [01:57<03:23,  1.35it/s] 80%|████████  | 1107/1380 [01:57<02:37,  1.73it/s] 80%|████████  | 1108/1380 [01:57<02:02,  2.23it/s] 80%|████████  | 1109/1380 [01:57<01:35,  2.83it/s] 80%|████████  | 1110/1380 [01:57<01:16,  3.51it/s] 81%|████████  | 1111/1380 [01:57<01:02,  4.27it/s] 81%|████████  | 1112/1380 [01:57<00:52,  5.10it/s] 81%|████████  | 1113/1380 [01:58<00:45,  5.83it/s] 81%|████████  | 1114/1380 [01:58<00:40,  6.55it/s] 81%|████████  | 1115/1380 [01:58<00:37,  7.12it/s] 81%|████████  | 1116/1380 [01:58<00:34,  7.60it/s] 81%|████████  | 1117/1380 [01:58<00:33,  7.97it/s] 81%|████████  | 1118/1380 [01:58<00:31,  8.21it/s] 81%|████████  | 1119/1380 [01:58<00:30,  8.59it/s] 81%|████████  | 1120/1380 [01:58<00:30,  8.67it/s] 81%|████████  | 1121/1380 [01:58<00:29,  8.76it/s] 81%|████████▏ | 1122/1380 [01:59<00:29,  8.79it/s] 81%|████████▏ | 1123/1380 [01:59<00:29,  8.81it/s] 81%|████████▏ | 1124/1380 [01:59<00:28,  8.95it/s] 82%|████████▏ | 1125/1380 [01:59<00:28,  8.90it/s] 82%|████████▏ | 1126/1380 [01:59<00:27,  9.15it/s] 82%|████████▏ | 1127/1380 [01:59<00:27,  9.08it/s] 82%|████████▏ | 1128/1380 [01:59<00:27,  9.03it/s] 82%|████████▏ | 1129/1380 [01:59<00:27,  8.97it/s] 82%|████████▏ | 1130/1380 [01:59<00:27,  9.10it/s] 82%|████████▏ | 1131/1380 [02:00<00:27,  9.03it/s] 82%|████████▏ | 1132/1380 [02:00<00:27,  9.04it/s] 82%|████████▏ | 1133/1380 [02:00<00:27,  9.09it/s] 82%|████████▏ | 1134/1380 [02:00<00:27,  9.09it/s] 82%|████████▏ | 1135/1380 [02:00<00:27,  9.02it/s] 82%|████████▏ | 1136/1380 [02:00<00:27,  9.01it/s] 82%|████████▏ | 1137/1380 [02:00<00:26,  9.27it/s] 82%|████████▏ | 1138/1380 [02:00<00:26,  9.17it/s] 83%|████████▎ | 1139/1380 [02:00<00:26,  9.18it/s] 83%|████████▎ | 1140/1380 [02:00<00:26,  9.09it/s] 83%|████████▎ | 1141/1380 [02:01<00:26,  9.03it/s] 83%|████████▎ | 1142/1380 [02:01<00:26,  9.07it/s] 83%|████████▎ | 1143/1380 [02:01<00:26,  9.06it/s] 83%|████████▎ | 1144/1380 [02:01<00:25,  9.22it/s] 83%|████████▎ | 1145/1380 [02:01<00:25,  9.17it/s] 83%|████████▎ | 1146/1380 [02:01<00:25,  9.13it/s] 83%|████████▎ | 1147/1380 [02:01<00:25,  9.08it/s] 83%|████████▎ | 1148/1380 [02:01<00:25,  9.21it/s] 83%|████████▎ | 1149/1380 [02:01<00:25,  9.14it/s] 83%|████████▎ | 1150/1380 [02:02<00:25,  9.12it/s] 83%|████████▎ | 1151/1380 [02:02<00:25,  9.11it/s] 83%|████████▎ | 1152/1380 [02:02<00:25,  9.08it/s] 84%|████████▎ | 1153/1380 [02:02<00:25,  9.02it/s] 84%|████████▎ | 1154/1380 [02:02<00:25,  9.01it/s] 84%|████████▎ | 1155/1380 [02:02<00:24,  9.25it/s] 84%|████████▍ | 1156/1380 [02:02<00:24,  9.15it/s] 84%|████████▍ | 1157/1380 [02:02<00:24,  9.12it/s] 84%|████████▍ | 1158/1380 [02:02<00:24,  9.09it/s] 84%|████████▍ | 1159/1380 [02:03<00:24,  9.20it/s] 84%|████████▍ | 1160/1380 [02:03<00:23,  9.19it/s] 84%|████████▍ | 1161/1380 [02:03<00:23,  9.22it/s] 84%|████████▍ | 1162/1380 [02:03<00:23,  9.20it/s] 84%|████████▍ | 1163/1380 [02:03<00:23,  9.18it/s] 84%|████████▍ | 1164/1380 [02:03<00:23,  9.06it/s] 84%|████████▍ | 1165/1380 [02:03<00:23,  9.01it/s] 84%|████████▍ | 1166/1380 [02:03<00:23,  9.15it/s] 85%|████████▍ | 1167/1380 [02:03<00:23,  9.14it/s] 85%|████████▍ | 1168/1380 [02:04<00:23,  9.17it/s] 85%|████████▍ | 1169/1380 [02:04<00:23,  9.11it/s] 85%|████████▍ | 1170/1380 [02:04<00:22,  9.13it/s] 85%|████████▍ | 1171/1380 [02:04<00:23,  9.08it/s] 85%|████████▍ | 1172/1380 [02:04<00:23,  9.00it/s] 85%|████████▌ | 1173/1380 [02:04<00:22,  9.17it/s] 85%|████████▌ | 1174/1380 [02:04<00:22,  9.11it/s] 85%|████████▌ | 1175/1380 [02:04<00:22,  9.10it/s] 85%|████████▌ | 1176/1380 [02:04<00:22,  9.01it/s] 85%|████████▌ | 1177/1380 [02:05<00:22,  9.11it/s] 85%|████████▌ | 1178/1380 [02:05<00:22,  9.14it/s] 85%|████████▌ | 1179/1380 [02:05<00:22,  9.09it/s] 86%|████████▌ | 1180/1380 [02:05<00:21,  9.28it/s] 86%|████████▌ | 1181/1380 [02:05<00:21,  9.17it/s] 86%|████████▌ | 1182/1380 [02:05<00:21,  9.13it/s] 86%|████████▌ | 1183/1380 [02:05<00:21,  9.13it/s] 86%|████████▌ | 1184/1380 [02:05<00:21,  9.17it/s] 86%|████████▌ | 1185/1380 [02:05<00:21,  9.16it/s] 86%|████████▌ | 1186/1380 [02:06<00:21,  9.07it/s] 86%|████████▌ | 1187/1380 [02:06<00:21,  9.12it/s] 86%|████████▌ | 1188/1380 [02:06<00:21,  9.11it/s] 86%|████████▌ | 1189/1380 [02:06<00:21,  8.99it/s] 86%|████████▌ | 1190/1380 [02:06<00:21,  9.03it/s] 86%|████████▋ | 1191/1380 [02:06<00:20,  9.13it/s] 86%|████████▋ | 1192/1380 [02:06<00:20,  9.09it/s] 86%|████████▋ | 1193/1380 [02:06<00:20,  9.04it/s] 87%|████████▋ | 1194/1380 [02:06<00:20,  9.02it/s] 87%|████████▋ | 1195/1380 [02:07<00:20,  9.08it/s] 87%|████████▋ | 1196/1380 [02:07<00:20,  9.12it/s] 87%|████████▋ | 1197/1380 [02:07<00:20,  9.09it/s] 87%|████████▋ | 1198/1380 [02:07<00:19,  9.16it/s] 87%|████████▋ | 1199/1380 [02:07<00:19,  9.12it/s] 87%|████████▋ | 1200/1380 [02:07<00:19,  9.01it/s] 87%|████████▋ | 1201/1380 [02:07<00:19,  9.05it/s] 87%|████████▋ | 1202/1380 [02:07<00:19,  9.14it/s] 87%|████████▋ | 1203/1380 [02:07<00:19,  9.14it/s] 87%|████████▋ | 1204/1380 [02:08<00:19,  9.12it/s] 87%|████████▋ | 1205/1380 [02:08<00:19,  9.04it/s] 87%|████████▋ | 1206/1380 [02:08<00:19,  9.08it/s] 87%|████████▋ | 1207/1380 [02:08<00:19,  9.10it/s] 88%|████████▊ | 1208/1380 [02:08<00:19,  8.98it/s] 88%|████████▊ | 1209/1380 [02:08<00:18,  9.17it/s] 88%|████████▊ | 1210/1380 [02:08<00:18,  9.12it/s] 88%|████████▊ | 1211/1380 [02:08<00:18,  9.11it/s] 88%|████████▊ | 1212/1380 [02:08<00:18,  9.10it/s] 88%|████████▊ | 1213/1380 [02:08<00:17,  9.28it/s] 88%|████████▊ | 1214/1380 [02:09<00:18,  9.14it/s] 88%|████████▊ | 1215/1380 [02:09<00:18,  9.07it/s] 88%|████████▊ | 1216/1380 [02:09<00:18,  9.01it/s] 88%|████████▊ | 1217/1380 [02:09<00:18,  9.01it/s] 88%|████████▊ | 1218/1380 [02:09<00:18,  8.99it/s] 88%|████████▊ | 1219/1380 [02:09<00:18,  8.86it/s] 88%|████████▊ | 1220/1380 [02:09<00:17,  9.11it/s] 88%|████████▊ | 1221/1380 [02:09<00:17,  8.98it/s] 89%|████████▊ | 1222/1380 [02:10<00:17,  8.98it/s] 89%|████████▊ | 1223/1380 [02:10<00:17,  9.02it/s] 89%|████████▊ | 1224/1380 [02:10<00:17,  9.07it/s] 89%|████████▉ | 1225/1380 [02:10<00:17,  9.04it/s] 89%|████████▉ | 1226/1380 [02:10<00:16,  9.06it/s] 89%|████████▉ | 1227/1380 [02:10<00:16,  9.04it/s] 89%|████████▉ | 1228/1380 [02:10<00:16,  9.01it/s] 89%|████████▉ | 1229/1380 [02:10<00:16,  9.00it/s] 89%|████████▉ | 1230/1380 [02:10<00:16,  8.90it/s] 89%|████████▉ | 1231/1380 [02:10<00:16,  9.15it/s] 89%|████████▉ | 1232/1380 [02:11<00:16,  9.01it/s] 89%|████████▉ | 1233/1380 [02:11<00:16,  9.01it/s] 89%|████████▉ | 1234/1380 [02:11<00:16,  8.91it/s] 89%|████████▉ | 1235/1380 [02:11<00:16,  8.97it/s] 90%|████████▉ | 1236/1380 [02:11<00:16,  8.97it/s] 90%|████████▉ | 1237/1380 [02:11<00:16,  8.92it/s] 90%|████████▉ | 1238/1380 [02:11<00:15,  8.99it/s] 90%|████████▉ | 1239/1380 [02:11<00:15,  8.99it/s] 90%|████████▉ | 1240/1380 [02:12<00:15,  8.85it/s] 90%|████████▉ | 1241/1380 [02:12<00:15,  8.87it/s] 90%|█████████ | 1242/1380 [02:12<00:15,  8.93it/s] 90%|█████████ | 1243/1380 [02:12<00:15,  8.88it/s] 90%|█████████ | 1244/1380 [02:12<00:15,  8.90it/s] 90%|█████████ | 1245/1380 [02:12<00:15,  8.84it/s] 90%|█████████ | 1246/1380 [02:12<00:15,  8.90it/s] 90%|█████████ | 1247/1380 [02:12<00:14,  8.90it/s] 90%|█████████ | 1248/1380 [02:12<00:14,  8.84it/s] 91%|█████████ | 1249/1380 [02:13<00:14,  9.03it/s] 91%|█████████ | 1250/1380 [02:13<00:14,  8.90it/s] 91%|█████████ | 1251/1380 [02:13<00:14,  8.87it/s] 91%|█████████ | 1252/1380 [02:13<00:14,  8.87it/s] 91%|█████████ | 1253/1380 [02:13<00:14,  9.01it/s] 91%|█████████ | 1254/1380 [02:13<00:14,  8.97it/s] 91%|█████████ | 1255/1380 [02:13<00:14,  8.92it/s] 91%|█████████ | 1256/1380 [02:13<00:13,  8.91it/s] 91%|█████████ | 1257/1380 [02:13<00:13,  8.86it/s] 91%|█████████ | 1258/1380 [02:14<00:13,  8.86it/s] 91%|█████████ | 1259/1380 [02:14<00:13,  8.75it/s] 91%|█████████▏| 1260/1380 [02:14<00:13,  9.04it/s] 91%|█████████▏| 1261/1380 [02:14<00:13,  8.98it/s] 91%|█████████▏| 1262/1380 [02:14<00:13,  8.89it/s] 92%|█████████▏| 1263/1380 [02:14<00:13,  8.85it/s] 92%|█████████▏| 1264/1380 [02:14<00:12,  8.97it/s] 92%|█████████▏| 1265/1380 [02:14<00:12,  8.94it/s] 92%|█████████▏| 1266/1380 [02:14<00:12,  8.86it/s] 92%|█████████▏| 1267/1380 [02:15<00:12,  8.79it/s] 92%|█████████▏| 1268/1380 [02:15<00:12,  8.86it/s] 92%|█████████▏| 1269/1380 [02:15<00:12,  8.84it/s] 92%|█████████▏| 1270/1380 [02:15<00:12,  8.79it/s] 92%|█████████▏| 1271/1380 [02:15<00:12,  8.98it/s] 92%|█████████▏| 1272/1380 [02:15<00:12,  8.93it/s] 92%|█████████▏| 1273/1380 [02:15<00:12,  8.84it/s] 92%|█████████▏| 1274/1380 [02:15<00:12,  8.79it/s] 92%|█████████▏| 1275/1380 [02:15<00:11,  9.02it/s] 92%|█████████▏| 1276/1380 [02:16<00:11,  8.94it/s] 93%|█████████▎| 1277/1380 [02:16<00:11,  8.79it/s] 93%|█████████▎| 1278/1380 [02:16<00:11,  8.81it/s] 93%|█████████▎| 1279/1380 [02:16<00:11,  8.89it/s] 93%|█████████▎| 1280/1380 [02:16<00:11,  8.89it/s] 93%|█████████▎| 1281/1380 [02:16<00:11,  8.88it/s] 93%|█████████▎| 1282/1380 [02:16<00:10,  8.95it/s] 93%|█████████▎| 1283/1380 [02:16<00:10,  8.91it/s] 93%|█████████▎| 1284/1380 [02:16<00:10,  8.85it/s] 93%|█████████▎| 1285/1380 [02:17<00:10,  8.84it/s] 93%|█████████▎| 1286/1380 [02:17<00:10,  9.08it/s] 93%|█████████▎| 1287/1380 [02:17<00:10,  8.87it/s] 93%|█████████▎| 1288/1380 [02:17<00:10,  8.86it/s] 93%|█████████▎| 1289/1380 [02:17<00:10,  8.85it/s] 93%|█████████▎| 1290/1380 [02:17<00:09,  9.02it/s] 94%|█████████▎| 1291/1380 [02:17<00:09,  8.94it/s] 94%|█████████▎| 1292/1380 [02:17<00:09,  8.93it/s] 94%|█████████▎| 1293/1380 [02:17<00:09,  8.84it/s] 94%|█████████▍| 1294/1380 [02:18<00:09,  8.84it/s] 94%|█████████▍| 1295/1380 [02:18<00:09,  8.80it/s] 94%|█████████▍| 1296/1380 [02:18<00:09,  8.80it/s] 94%|█████████▍| 1297/1380 [02:18<00:09,  8.93it/s] 94%|█████████▍| 1298/1380 [02:18<00:09,  8.88it/s] 94%|█████████▍| 1299/1380 [02:18<00:09,  8.67it/s] 94%|█████████▍| 1300/1380 [02:18<00:09,  8.71it/s] 94%|█████████▍| 1301/1380 [02:18<00:08,  8.81it/s] 94%|█████████▍| 1302/1380 [02:18<00:08,  8.86it/s] 94%|█████████▍| 1303/1380 [02:19<00:08,  8.79it/s] 94%|█████████▍| 1304/1380 [02:19<00:08,  8.74it/s] 95%|█████████▍| 1305/1380 [02:19<00:08,  8.81it/s] 95%|█████████▍| 1306/1380 [02:19<00:08,  8.72it/s] 95%|█████████▍| 1307/1380 [02:19<00:08,  8.71it/s] 95%|█████████▍| 1308/1380 [02:19<00:08,  8.88it/s] 95%|█████████▍| 1309/1380 [02:19<00:08,  8.84it/s] 95%|█████████▍| 1310/1380 [02:19<00:07,  8.79it/s] 95%|█████████▌| 1311/1380 [02:20<00:07,  8.68it/s] 95%|█████████▌| 1312/1380 [02:20<00:07,  8.92it/s] 95%|█████████▌| 1313/1380 [02:20<00:07,  8.77it/s] 95%|█████████▌| 1314/1380 [02:20<00:07,  8.77it/s] 95%|█████████▌| 1315/1380 [02:20<00:07,  8.75it/s] 95%|█████████▌| 1316/1380 [02:20<00:07,  8.79it/s] 95%|█████████▌| 1317/1380 [02:20<00:07,  8.75it/s] 96%|█████████▌| 1318/1380 [02:20<00:07,  8.75it/s] 96%|█████████▌| 1319/1380 [02:20<00:06,  8.87it/s] 96%|█████████▌| 1320/1380 [02:21<00:06,  8.73it/s] 96%|█████████▌| 1321/1380 [02:21<00:06,  8.75it/s] 96%|█████████▌| 1322/1380 [02:21<00:06,  8.72it/s] 96%|█████████▌| 1323/1380 [02:21<00:06,  8.93it/s] 96%|█████████▌| 1324/1380 [02:21<00:06,  8.84it/s] 96%|█████████▌| 1325/1380 [02:21<00:06,  8.84it/s] 96%|█████████▌| 1326/1380 [02:21<00:06,  8.78it/s] 96%|█████████▌| 1327/1380 [02:21<00:06,  8.71it/s] 96%|█████████▌| 1328/1380 [02:21<00:05,  8.76it/s] 96%|█████████▋| 1329/1380 [02:22<00:05,  8.74it/s] 96%|█████████▋| 1330/1380 [02:22<00:05,  8.94it/s] 96%|█████████▋| 1331/1380 [02:22<00:05,  8.85it/s] 97%|█████████▋| 1332/1380 [02:22<00:05,  8.83it/s] 97%|█████████▋| 1333/1380 [02:22<00:05,  8.78it/s] 97%|█████████▋| 1334/1380 [02:22<00:05,  8.89it/s] 97%|█████████▋| 1335/1380 [02:22<00:05,  8.94it/s] 97%|█████████▋| 1336/1380 [02:22<00:04,  8.93it/s] 97%|█████████▋| 1337/1380 [02:22<00:04,  8.86it/s] 97%|█████████▋| 1338/1380 [02:23<00:04,  8.82it/s] 97%|█████████▋| 1339/1380 [02:23<00:04,  8.80it/s] 97%|█████████▋| 1340/1380 [02:23<00:04,  8.81it/s] 97%|█████████▋| 1341/1380 [02:23<00:04,  8.97it/s] 97%|█████████▋| 1342/1380 [02:23<00:04,  8.87it/s] 97%|█████████▋| 1343/1380 [02:23<00:04,  8.86it/s] 97%|█████████▋| 1344/1380 [02:23<00:04,  8.77it/s] 97%|█████████▋| 1345/1380 [02:23<00:03,  8.99it/s] 98%|█████████▊| 1346/1380 [02:23<00:03,  8.94it/s] 98%|█████████▊| 1347/1380 [02:24<00:03,  8.92it/s] 98%|█████████▊| 1348/1380 [02:24<00:03,  8.96it/s] 98%|█████████▊| 1349/1380 [02:24<00:03,  8.94it/s] 98%|█████████▊| 1350/1380 [02:24<00:03,  8.98it/s] 98%|█████████▊| 1351/1380 [02:24<00:03,  8.90it/s] 98%|█████████▊| 1352/1380 [02:24<00:03,  8.98it/s] 98%|█████████▊| 1353/1380 [02:24<00:03,  8.96it/s] 98%|█████████▊| 1354/1380 [02:24<00:02,  8.84it/s] 98%|█████████▊| 1355/1380 [02:24<00:02,  8.78it/s] 98%|█████████▊| 1356/1380 [02:25<00:02,  8.98it/s] 98%|█████████▊| 1357/1380 [02:25<00:02,  8.86it/s] 98%|█████████▊| 1358/1380 [02:25<00:02,  8.83it/s] 98%|█████████▊| 1359/1380 [02:25<00:02,  8.80it/s] 99%|█████████▊| 1360/1380 [02:25<00:02,  8.78it/s] 99%|█████████▊| 1361/1380 [02:25<00:02,  8.81it/s] 99%|█████████▊| 1362/1380 [02:25<00:02,  8.74it/s] 99%|█████████▉| 1363/1380 [02:25<00:01,  8.95it/s] 99%|█████████▉| 1364/1380 [02:26<00:01,  8.86it/s] 99%|█████████▉| 1365/1380 [02:26<00:01,  8.88it/s] 99%|█████████▉| 1366/1380 [02:26<00:01,  8.88it/s] 99%|█████████▉| 1367/1380 [02:26<00:01,  8.91it/s] 99%|█████████▉| 1368/1380 [02:26<00:01,  8.93it/s] 99%|█████████▉| 1369/1380 [02:26<00:01,  8.87it/s] 99%|█████████▉| 1370/1380 [02:26<00:01,  8.98it/s] 99%|█████████▉| 1371/1380 [02:26<00:01,  8.92it/s] 99%|█████████▉| 1372/1380 [02:26<00:00,  8.88it/s] 99%|█████████▉| 1373/1380 [02:27<00:00,  8.87it/s]100%|█████████▉| 1374/1380 [02:27<00:00,  8.98it/s]100%|█████████▉| 1375/1380 [02:27<00:00,  8.95it/s]100%|█████████▉| 1376/1380 [02:27<00:00,  8.97it/s]100%|█████████▉| 1377/1380 [02:27<00:00,  8.92it/s]100%|█████████▉| 1378/1380 [02:27<00:00,  8.91it/s]100%|█████████▉| 1379/1380 [02:27<00:00,  8.91it/s]                                                   100%|██████████| 1380/1380 [02:27<00:00,  8.91it/s][INFO|trainer.py:755] 2023-11-15 20:05:37,793 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:05:37,795 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:05:37,795 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:05:37,796 >>   Batch size = 8
{'eval_loss': 0.5205936431884766, 'eval_accuracy': 0.8525408348457351, 'eval_micro_f1': 0.8525408348457351, 'eval_macro_f1': 0.8369020836462241, 'eval_runtime': 3.6731, 'eval_samples_per_second': 600.046, 'eval_steps_per_second': 75.142, 'epoch': 4.0}
{'loss': 0.09, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:02, 89.00it/s][A
  7%|▋         | 18/276 [00:00<00:03, 76.57it/s][A
  9%|▉         | 26/276 [00:00<00:03, 71.89it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 71.27it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 71.46it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 71.08it/s][A
 21%|██        | 58/276 [00:00<00:03, 70.46it/s][A
 24%|██▍       | 66/276 [00:00<00:02, 71.42it/s][A
 27%|██▋       | 74/276 [00:01<00:02, 71.06it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 69.33it/s][A
 32%|███▏      | 89/276 [00:01<00:02, 68.52it/s][A
 35%|███▌      | 97/276 [00:01<00:02, 70.46it/s][A
 38%|███▊      | 105/276 [00:01<00:02, 68.92it/s][A
 41%|████      | 112/276 [00:01<00:02, 68.91it/s][A
 43%|████▎     | 119/276 [00:01<00:02, 68.15it/s][A
 46%|████▌     | 127/276 [00:01<00:02, 69.61it/s][A
 49%|████▊     | 134/276 [00:01<00:02, 69.41it/s][A
 51%|█████▏    | 142/276 [00:02<00:01, 69.07it/s][A
 54%|█████▍    | 150/276 [00:02<00:01, 70.31it/s][A
 57%|█████▋    | 158/276 [00:02<00:01, 67.77it/s][A
 60%|█████▉    | 165/276 [00:02<00:01, 68.15it/s][A
 62%|██████▏   | 172/276 [00:02<00:01, 68.32it/s][A
 65%|██████▌   | 180/276 [00:02<00:01, 68.77it/s][A
 68%|██████▊   | 188/276 [00:02<00:01, 69.43it/s][A
 71%|███████   | 195/276 [00:02<00:01, 69.38it/s][A
 74%|███████▎  | 203/276 [00:02<00:01, 70.33it/s][A
 76%|███████▋  | 211/276 [00:03<00:00, 68.97it/s][A
 79%|███████▉  | 218/276 [00:03<00:00, 69.07it/s][A
 82%|████████▏ | 225/276 [00:03<00:00, 68.08it/s][A
 84%|████████▍ | 233/276 [00:03<00:00, 69.40it/s][A
 87%|████████▋ | 240/276 [00:03<00:00, 69.23it/s][A
 89%|████████▉ | 247/276 [00:03<00:00, 68.70it/s][A
 92%|█████████▏| 254/276 [00:03<00:00, 68.39it/s][A
 95%|█████████▍| 261/276 [00:03<00:00, 68.46it/s][A
 97%|█████████▋| 268/276 [00:03<00:00, 68.25it/s][A
100%|█████████▉| 275/276 [00:03<00:00, 68.39it/s][A                                                   
                                                 [A100%|██████████| 1380/1380 [02:31<00:00,  8.91it/s]
100%|██████████| 276/276 [00:04<00:00, 68.39it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 20:05:41,828 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:31<00:00,  8.91it/s]100%|██████████| 1380/1380 [02:31<00:00,  9.09it/s]
[INFO|trainer.py:2855] 2023-11-15 20:05:41,832 >> Saving model checkpoint to ./result/acl_bert-base-cased_adapter__seed1
[INFO|configuration_utils.py:460] 2023-11-15 20:05:41,835 >> Configuration saved in ./result/acl_bert-base-cased_adapter__seed1/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:05:43,047 >> Model weights saved in ./result/acl_bert-base-cased_adapter__seed1/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:05:43,050 >> tokenizer config file saved in ./result/acl_bert-base-cased_adapter__seed1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:05:43,052 >> Special tokens file saved in ./result/acl_bert-base-cased_adapter__seed1/special_tokens_map.json
{'eval_loss': 0.5685838460922241, 'eval_accuracy': 0.8493647912885662, 'eval_micro_f1': 0.8493647912885661, 'eval_macro_f1': 0.8346218704151475, 'eval_runtime': 4.0292, 'eval_samples_per_second': 547.006, 'eval_steps_per_second': 68.5, 'epoch': 5.0}
{'train_runtime': 151.8063, 'train_samples_per_second': 290.37, 'train_steps_per_second': 9.091, 'train_loss': 0.24351205272950988, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2435
  train_runtime            = 0:02:31.80
  train_samples            =       8816
  train_samples_per_second =     290.37
  train_steps_per_second   =      9.091
11/15/2023 20:05:43 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:05:43,097 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:05:43,098 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:05:43,099 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:05:43,099 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  3%|▎         | 9/276 [00:00<00:03, 83.45it/s]  7%|▋         | 18/276 [00:00<00:03, 75.98it/s]  9%|▉         | 26/276 [00:00<00:03, 76.68it/s] 12%|█▏        | 34/276 [00:00<00:03, 76.03it/s] 15%|█▌        | 42/276 [00:00<00:03, 73.02it/s] 18%|█▊        | 50/276 [00:00<00:03, 72.72it/s] 21%|██        | 58/276 [00:00<00:02, 73.04it/s] 24%|██▍       | 66/276 [00:00<00:02, 72.77it/s] 27%|██▋       | 74/276 [00:01<00:02, 72.26it/s] 30%|██▉       | 82/276 [00:01<00:02, 74.46it/s] 33%|███▎      | 90/276 [00:01<00:02, 72.67it/s] 36%|███▌      | 98/276 [00:01<00:02, 71.61it/s] 38%|███▊      | 106/276 [00:01<00:02, 72.23it/s] 41%|████▏     | 114/276 [00:01<00:02, 72.40it/s] 44%|████▍     | 122/276 [00:01<00:02, 72.01it/s] 47%|████▋     | 130/276 [00:01<00:02, 71.55it/s] 50%|█████     | 138/276 [00:01<00:01, 73.80it/s] 53%|█████▎    | 146/276 [00:01<00:01, 71.64it/s] 56%|█████▌    | 154/276 [00:02<00:01, 71.95it/s] 59%|█████▊    | 162/276 [00:02<00:01, 71.66it/s] 62%|██████▏   | 170/276 [00:02<00:01, 72.56it/s] 64%|██████▍   | 178/276 [00:02<00:01, 72.31it/s] 67%|██████▋   | 186/276 [00:02<00:01, 71.90it/s] 70%|███████   | 194/276 [00:02<00:01, 73.58it/s] 73%|███████▎  | 202/276 [00:02<00:01, 73.76it/s] 76%|███████▌  | 210/276 [00:02<00:00, 73.60it/s] 79%|███████▉  | 218/276 [00:02<00:00, 73.71it/s] 82%|████████▏ | 226/276 [00:03<00:00, 74.60it/s] 85%|████████▍ | 234/276 [00:03<00:00, 74.42it/s] 88%|████████▊ | 242/276 [00:03<00:00, 74.17it/s] 91%|█████████ | 250/276 [00:03<00:00, 75.65it/s] 93%|█████████▎| 258/276 [00:03<00:00, 74.29it/s] 96%|█████████▋| 266/276 [00:03<00:00, 73.33it/s] 99%|█████████▉| 274/276 [00:03<00:00, 73.25it/s]100%|██████████| 276/276 [00:03<00:00, 72.61it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8494
  eval_loss               =     0.5686
  eval_macro_f1           =     0.8346
  eval_micro_f1           =     0.8494
  eval_runtime            = 0:00:03.82
  eval_samples            =       2204
  eval_samples_per_second =     576.94
  eval_steps_per_second   =     72.248
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy █▆▁▄▁▁
wandb:                      eval/loss ▁▂▃▆██
wandb:                  eval/macro_f1 ▆█▁▇▅▅
wandb:                  eval/micro_f1 █▆▁▄▁▁
wandb:                   eval/runtime ▁▁▁▆█▇
wandb:        eval/samples_per_second ██▇▂▁▂
wandb:          eval/steps_per_second ██▇▂▁▂
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.84936
wandb:                      eval/loss 0.56858
wandb:                  eval/macro_f1 0.83462
wandb:                  eval/micro_f1 0.84936
wandb:                   eval/runtime 3.8202
wandb:        eval/samples_per_second 576.94
wandb:          eval/steps_per_second 72.248
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.09
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.24351
wandb:            train/train_runtime 151.8063
wandb: train/train_samples_per_second 290.37
wandb:   train/train_steps_per_second 9.091
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_200222-1pchz968
wandb: Find logs at: ./wandb/offline-run-20231115_200222-1pchz968/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1/runs/Nov15_20-05-58_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:05:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:05:58 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1/runs/Nov15_20-05-57_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  37%|███▋      | 4128/11020 [00:00<00:00, 41062.21 examples/s]Map:  76%|███████▌  | 8352/11020 [00:00<00:00, 41748.17 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 41257.09 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:06:15,203 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:06:15,214 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:06:25,227 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:06:35,247 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:06:35,248 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:06:55,291 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:06:55,291 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:06:55,291 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:06:55,292 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:06:55,292 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:06:55,294 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:06:55,295 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 20:06:55,315 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:06:55,316 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:07:15,456 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 20:07:17,034 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:07:17,035 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  23%|██▎       | 2000/8816 [00:00<00:00, 14533.25 examples/s]Running tokenizer on dataset:  45%|████▌     | 4000/8816 [00:00<00:00, 15063.25 examples/s]Running tokenizer on dataset:  68%|██████▊   | 6000/8816 [00:00<00:00, 16789.26 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 18124.08 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 17135.96 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 20106.28 examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 19777.09 examples/s]
11/15/2023 20:07:17 - INFO - __main__ - Sample 1767 of the training set: {'text': 'Second, HASM cells in culture, when observed between 3 and 6 h after plating, were not spindle shaped or aligned in parallel, as they are at the tissue level (5); instead, they were irregularly shaped (Fig.', 'label': 0, 'input_ids': [102, 971, 422, 434, 30119, 576, 121, 2343, 422, 603, 1058, 467, 239, 137, 370, 151, 647, 26037, 422, 267, 302, 16043, 14792, 234, 10016, 121, 3098, 422, 188, 698, 220, 235, 111, 2003, 615, 145, 305, 546, 1814, 3222, 422, 698, 267, 11147, 179, 14792, 145, 522, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:07:17 - INFO - __main__ - Sample 3854 of the training set: {'text': 'Yet, allowing for interruptions might decrease classification accuracy [24] as well as making results vulnerable to variation in wear time if analyzed with different epoch lengths [37].', 'label': 0, 'input_ids': [102, 3481, 422, 5644, 168, 22904, 30113, 1799, 2640, 2998, 2683, 260, 1540, 1901, 188, 804, 188, 3469, 545, 12144, 147, 2835, 121, 12045, 532, 543, 2549, 190, 643, 14415, 8546, 260, 2659, 1901, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:07:17 - INFO - __main__ - Sample 4652 of the training set: {'text': 'Examination of plaque formation and growth curves were performed by standard methods as previously described (10, 35).', 'label': 1, 'input_ids': [102, 4373, 131, 12547, 2256, 137, 1503, 4483, 267, 1260, 214, 1235, 1045, 188, 2049, 1356, 145, 566, 422, 2638, 546, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:07:17 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:07:19,193 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:07:19,200 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:07:19,201 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 20:07:19,201 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:07:19,201 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:07:19,202 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:07:19,202 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:07:19,202 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 20:07:19,203 >>   Number of trainable parameters = 109,920,771
[INFO|integration_utils.py:716] 2023-11-15 20:07:19,204 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<31:54,  1.39s/it]  0%|          | 2/1380 [00:01<14:33,  1.58it/s]  0%|          | 3/1380 [00:01<09:00,  2.55it/s]  0%|          | 4/1380 [00:01<06:26,  3.56it/s]  0%|          | 5/1380 [00:01<05:01,  4.56it/s]  0%|          | 6/1380 [00:01<04:09,  5.51it/s]  1%|          | 7/1380 [00:02<03:36,  6.35it/s]  1%|          | 8/1380 [00:02<03:15,  7.02it/s]  1%|          | 9/1380 [00:02<02:59,  7.64it/s]  1%|          | 10/1380 [00:02<02:48,  8.11it/s]  1%|          | 11/1380 [00:02<02:43,  8.39it/s]  1%|          | 12/1380 [00:02<02:38,  8.65it/s]  1%|          | 13/1380 [00:02<02:34,  8.85it/s]  1%|          | 14/1380 [00:02<02:31,  8.99it/s]  1%|          | 15/1380 [00:02<02:29,  9.10it/s]  1%|          | 16/1380 [00:03<02:30,  9.08it/s]  1%|          | 17/1380 [00:03<02:30,  9.06it/s]  1%|▏         | 18/1380 [00:03<02:28,  9.19it/s]  1%|▏         | 19/1380 [00:03<02:27,  9.21it/s]  1%|▏         | 20/1380 [00:03<02:26,  9.25it/s]  2%|▏         | 21/1380 [00:03<02:25,  9.32it/s]  2%|▏         | 22/1380 [00:03<02:26,  9.30it/s]  2%|▏         | 23/1380 [00:03<02:23,  9.43it/s]  2%|▏         | 24/1380 [00:03<02:24,  9.35it/s]  2%|▏         | 25/1380 [00:03<02:25,  9.32it/s]  2%|▏         | 26/1380 [00:04<02:26,  9.22it/s]  2%|▏         | 27/1380 [00:04<02:25,  9.27it/s]  2%|▏         | 28/1380 [00:04<02:25,  9.29it/s]  2%|▏         | 29/1380 [00:04<02:26,  9.24it/s]  2%|▏         | 30/1380 [00:04<02:23,  9.43it/s]  2%|▏         | 31/1380 [00:04<02:23,  9.40it/s]  2%|▏         | 32/1380 [00:04<02:23,  9.40it/s]  2%|▏         | 33/1380 [00:04<02:23,  9.42it/s]  2%|▏         | 34/1380 [00:04<02:23,  9.40it/s]  3%|▎         | 35/1380 [00:05<02:23,  9.40it/s]  3%|▎         | 36/1380 [00:05<02:25,  9.25it/s]  3%|▎         | 37/1380 [00:05<02:23,  9.39it/s]  3%|▎         | 38/1380 [00:05<02:23,  9.34it/s]  3%|▎         | 39/1380 [00:05<02:23,  9.36it/s]  3%|▎         | 40/1380 [00:05<02:22,  9.44it/s]  3%|▎         | 41/1380 [00:05<02:22,  9.42it/s]  3%|▎         | 42/1380 [00:05<02:22,  9.41it/s]  3%|▎         | 43/1380 [00:05<02:23,  9.32it/s]  3%|▎         | 44/1380 [00:05<02:20,  9.48it/s]  3%|▎         | 45/1380 [00:06<02:21,  9.41it/s]  3%|▎         | 46/1380 [00:06<02:22,  9.39it/s]  3%|▎         | 47/1380 [00:06<02:20,  9.49it/s]  3%|▎         | 48/1380 [00:06<02:20,  9.47it/s]  4%|▎         | 49/1380 [00:06<02:21,  9.44it/s]  4%|▎         | 50/1380 [00:06<02:23,  9.29it/s]  4%|▎         | 51/1380 [00:06<02:21,  9.38it/s]  4%|▍         | 52/1380 [00:06<02:21,  9.40it/s]  4%|▍         | 53/1380 [00:06<02:21,  9.38it/s]  4%|▍         | 54/1380 [00:07<02:19,  9.49it/s]  4%|▍         | 55/1380 [00:07<02:21,  9.40it/s]  4%|▍         | 56/1380 [00:07<02:20,  9.42it/s]  4%|▍         | 57/1380 [00:07<02:21,  9.36it/s]  4%|▍         | 58/1380 [00:07<02:21,  9.34it/s]  4%|▍         | 59/1380 [00:07<02:20,  9.40it/s]  4%|▍         | 60/1380 [00:07<02:22,  9.25it/s]  4%|▍         | 61/1380 [00:07<02:20,  9.36it/s]  4%|▍         | 62/1380 [00:07<02:21,  9.32it/s]  5%|▍         | 63/1380 [00:08<02:20,  9.35it/s]  5%|▍         | 64/1380 [00:08<02:21,  9.32it/s]  5%|▍         | 65/1380 [00:08<02:19,  9.42it/s]  5%|▍         | 66/1380 [00:08<02:19,  9.43it/s]  5%|▍         | 67/1380 [00:08<02:19,  9.40it/s]  5%|▍         | 68/1380 [00:08<02:18,  9.48it/s]  5%|▌         | 69/1380 [00:08<02:19,  9.41it/s]  5%|▌         | 70/1380 [00:08<02:19,  9.40it/s]  5%|▌         | 71/1380 [00:08<02:19,  9.37it/s]  5%|▌         | 72/1380 [00:08<02:19,  9.38it/s]  5%|▌         | 73/1380 [00:09<02:20,  9.30it/s]  5%|▌         | 74/1380 [00:09<02:20,  9.33it/s]  5%|▌         | 75/1380 [00:09<02:18,  9.43it/s]  6%|▌         | 76/1380 [00:09<02:18,  9.39it/s]  6%|▌         | 77/1380 [00:09<02:19,  9.35it/s]  6%|▌         | 78/1380 [00:09<02:19,  9.35it/s]  6%|▌         | 79/1380 [00:09<02:20,  9.28it/s]  6%|▌         | 80/1380 [00:09<02:19,  9.31it/s]  6%|▌         | 81/1380 [00:09<02:19,  9.32it/s]  6%|▌         | 82/1380 [00:10<02:17,  9.42it/s]  6%|▌         | 83/1380 [00:10<02:18,  9.38it/s]  6%|▌         | 84/1380 [00:10<02:19,  9.26it/s]  6%|▌         | 85/1380 [00:10<02:19,  9.27it/s]  6%|▌         | 86/1380 [00:10<02:19,  9.26it/s]  6%|▋         | 87/1380 [00:10<02:18,  9.31it/s]  6%|▋         | 88/1380 [00:10<02:18,  9.33it/s]  6%|▋         | 89/1380 [00:10<02:17,  9.38it/s]  7%|▋         | 90/1380 [00:10<02:18,  9.31it/s]  7%|▋         | 91/1380 [00:11<02:19,  9.21it/s]  7%|▋         | 92/1380 [00:11<02:19,  9.21it/s]  7%|▋         | 93/1380 [00:11<02:19,  9.23it/s]  7%|▋         | 94/1380 [00:11<02:18,  9.28it/s]  7%|▋         | 95/1380 [00:11<02:19,  9.21it/s]  7%|▋         | 96/1380 [00:11<02:17,  9.34it/s]  7%|▋         | 97/1380 [00:11<02:17,  9.33it/s]  7%|▋         | 98/1380 [00:11<02:17,  9.34it/s]  7%|▋         | 99/1380 [00:11<02:18,  9.27it/s]  7%|▋         | 100/1380 [00:11<02:17,  9.32it/s]  7%|▋         | 101/1380 [00:12<02:16,  9.34it/s]  7%|▋         | 102/1380 [00:12<02:17,  9.32it/s]  7%|▋         | 103/1380 [00:12<02:16,  9.37it/s]  8%|▊         | 104/1380 [00:12<02:15,  9.41it/s]  8%|▊         | 105/1380 [00:12<02:16,  9.33it/s]  8%|▊         | 106/1380 [00:12<02:15,  9.38it/s]  8%|▊         | 107/1380 [00:12<02:15,  9.37it/s]  8%|▊         | 108/1380 [00:12<02:16,  9.34it/s]  8%|▊         | 109/1380 [00:12<02:16,  9.34it/s]  8%|▊         | 110/1380 [00:13<02:16,  9.29it/s]  8%|▊         | 111/1380 [00:13<02:17,  9.26it/s]  8%|▊         | 112/1380 [00:13<02:16,  9.30it/s]  8%|▊         | 113/1380 [00:13<02:15,  9.33it/s]  8%|▊         | 114/1380 [00:13<02:15,  9.32it/s]  8%|▊         | 115/1380 [00:13<02:16,  9.25it/s]  8%|▊         | 116/1380 [00:13<02:15,  9.32it/s]  8%|▊         | 117/1380 [00:13<02:15,  9.31it/s]  9%|▊         | 118/1380 [00:13<02:15,  9.31it/s]  9%|▊         | 119/1380 [00:14<02:15,  9.33it/s]  9%|▊         | 120/1380 [00:14<02:15,  9.33it/s]  9%|▉         | 121/1380 [00:14<02:14,  9.34it/s]  9%|▉         | 122/1380 [00:14<02:16,  9.25it/s]  9%|▉         | 123/1380 [00:14<02:15,  9.28it/s]  9%|▉         | 124/1380 [00:14<02:14,  9.33it/s]  9%|▉         | 125/1380 [00:14<02:14,  9.33it/s]  9%|▉         | 126/1380 [00:14<02:15,  9.27it/s]  9%|▉         | 127/1380 [00:14<02:13,  9.39it/s]  9%|▉         | 128/1380 [00:14<02:14,  9.32it/s]  9%|▉         | 129/1380 [00:15<02:14,  9.30it/s]  9%|▉         | 130/1380 [00:15<02:13,  9.38it/s]  9%|▉         | 131/1380 [00:15<02:13,  9.33it/s] 10%|▉         | 132/1380 [00:15<02:14,  9.31it/s] 10%|▉         | 133/1380 [00:15<02:15,  9.23it/s] 10%|▉         | 134/1380 [00:15<02:15,  9.23it/s] 10%|▉         | 135/1380 [00:15<02:14,  9.22it/s] 10%|▉         | 136/1380 [00:15<02:14,  9.23it/s] 10%|▉         | 137/1380 [00:15<02:14,  9.27it/s] 10%|█         | 138/1380 [00:16<02:13,  9.31it/s] 10%|█         | 139/1380 [00:16<02:14,  9.26it/s] 10%|█         | 140/1380 [00:16<02:13,  9.27it/s] 10%|█         | 141/1380 [00:16<02:12,  9.32it/s] 10%|█         | 142/1380 [00:16<02:12,  9.32it/s] 10%|█         | 143/1380 [00:16<02:13,  9.26it/s] 10%|█         | 144/1380 [00:16<02:11,  9.40it/s] 11%|█         | 145/1380 [00:16<02:13,  9.26it/s] 11%|█         | 146/1380 [00:16<02:12,  9.28it/s] 11%|█         | 147/1380 [00:17<02:11,  9.34it/s] 11%|█         | 148/1380 [00:17<02:12,  9.29it/s] 11%|█         | 149/1380 [00:17<02:12,  9.27it/s] 11%|█         | 150/1380 [00:17<02:14,  9.18it/s] 11%|█         | 151/1380 [00:17<02:13,  9.18it/s] 11%|█         | 152/1380 [00:17<02:12,  9.24it/s] 11%|█         | 153/1380 [00:17<02:13,  9.22it/s] 11%|█         | 154/1380 [00:17<02:11,  9.32it/s] 11%|█         | 155/1380 [00:17<02:13,  9.16it/s] 11%|█▏        | 156/1380 [00:18<02:12,  9.21it/s] 11%|█▏        | 157/1380 [00:18<02:11,  9.27it/s] 11%|█▏        | 158/1380 [00:18<02:11,  9.29it/s] 12%|█▏        | 159/1380 [00:18<02:12,  9.24it/s] 12%|█▏        | 160/1380 [00:18<02:11,  9.27it/s] 12%|█▏        | 161/1380 [00:18<02:11,  9.27it/s] 12%|█▏        | 162/1380 [00:18<02:11,  9.26it/s] 12%|█▏        | 163/1380 [00:18<02:11,  9.27it/s] 12%|█▏        | 164/1380 [00:18<02:10,  9.35it/s] 12%|█▏        | 165/1380 [00:18<02:10,  9.29it/s] 12%|█▏        | 166/1380 [00:19<02:12,  9.13it/s] 12%|█▏        | 167/1380 [00:19<02:12,  9.13it/s] 12%|█▏        | 168/1380 [00:19<02:12,  9.15it/s] 12%|█▏        | 169/1380 [00:19<02:11,  9.19it/s] 12%|█▏        | 170/1380 [00:19<02:12,  9.12it/s] 12%|█▏        | 171/1380 [00:19<02:10,  9.29it/s] 12%|█▏        | 172/1380 [00:19<02:12,  9.10it/s] 13%|█▎        | 173/1380 [00:19<02:12,  9.14it/s] 13%|█▎        | 174/1380 [00:19<02:10,  9.24it/s] 13%|█▎        | 175/1380 [00:20<02:10,  9.24it/s] 13%|█▎        | 176/1380 [00:20<02:09,  9.26it/s] 13%|█▎        | 177/1380 [00:20<02:11,  9.12it/s] 13%|█▎        | 178/1380 [00:20<02:12,  9.09it/s] 13%|█▎        | 179/1380 [00:20<02:11,  9.14it/s] 13%|█▎        | 180/1380 [00:20<02:11,  9.13it/s] 13%|█▎        | 181/1380 [00:20<02:10,  9.19it/s] 13%|█▎        | 182/1380 [00:20<02:10,  9.18it/s] 13%|█▎        | 183/1380 [00:20<02:11,  9.11it/s] 13%|█▎        | 184/1380 [00:21<02:11,  9.11it/s] 13%|█▎        | 185/1380 [00:21<02:11,  9.12it/s] 13%|█▎        | 186/1380 [00:21<02:10,  9.14it/s] 14%|█▎        | 187/1380 [00:21<02:10,  9.14it/s] 14%|█▎        | 188/1380 [00:21<02:07,  9.36it/s] 14%|█▎        | 189/1380 [00:21<02:08,  9.26it/s] 14%|█▍        | 190/1380 [00:21<02:09,  9.19it/s] 14%|█▍        | 191/1380 [00:21<02:10,  9.12it/s] 14%|█▍        | 192/1380 [00:21<02:09,  9.18it/s] 14%|█▍        | 193/1380 [00:22<02:08,  9.22it/s] 14%|█▍        | 194/1380 [00:22<02:09,  9.14it/s] 14%|█▍        | 195/1380 [00:22<02:08,  9.25it/s] 14%|█▍        | 196/1380 [00:22<02:08,  9.22it/s] 14%|█▍        | 197/1380 [00:22<02:08,  9.21it/s] 14%|█▍        | 198/1380 [00:22<02:07,  9.27it/s] 14%|█▍        | 199/1380 [00:22<02:07,  9.25it/s] 14%|█▍        | 200/1380 [00:22<02:08,  9.19it/s] 15%|█▍        | 201/1380 [00:22<02:07,  9.26it/s] 15%|█▍        | 202/1380 [00:23<02:07,  9.26it/s] 15%|█▍        | 203/1380 [00:23<02:06,  9.33it/s] 15%|█▍        | 204/1380 [00:23<02:06,  9.32it/s] 15%|█▍        | 205/1380 [00:23<02:05,  9.38it/s] 15%|█▍        | 206/1380 [00:23<02:06,  9.25it/s] 15%|█▌        | 207/1380 [00:23<02:06,  9.26it/s] 15%|█▌        | 208/1380 [00:23<02:05,  9.35it/s] 15%|█▌        | 209/1380 [00:23<02:05,  9.33it/s] 15%|█▌        | 210/1380 [00:23<02:05,  9.30it/s] 15%|█▌        | 211/1380 [00:23<02:07,  9.20it/s] 15%|█▌        | 212/1380 [00:24<02:06,  9.25it/s] 15%|█▌        | 213/1380 [00:24<02:05,  9.28it/s] 16%|█▌        | 214/1380 [00:24<02:05,  9.29it/s] 16%|█▌        | 215/1380 [00:24<02:04,  9.34it/s] 16%|█▌        | 216/1380 [00:24<02:05,  9.25it/s] 16%|█▌        | 217/1380 [00:24<02:06,  9.21it/s] 16%|█▌        | 218/1380 [00:24<02:04,  9.32it/s] 16%|█▌        | 219/1380 [00:24<02:04,  9.35it/s] 16%|█▌        | 220/1380 [00:24<02:05,  9.25it/s] 16%|█▌        | 221/1380 [00:25<02:05,  9.22it/s] 16%|█▌        | 222/1380 [00:25<02:05,  9.26it/s] 16%|█▌        | 223/1380 [00:25<02:04,  9.30it/s] 16%|█▌        | 224/1380 [00:25<02:04,  9.32it/s] 16%|█▋        | 225/1380 [00:25<02:03,  9.37it/s] 16%|█▋        | 226/1380 [00:25<02:03,  9.32it/s] 16%|█▋        | 227/1380 [00:25<02:03,  9.37it/s] 17%|█▋        | 228/1380 [00:25<02:02,  9.43it/s] 17%|█▋        | 229/1380 [00:25<02:01,  9.44it/s] 17%|█▋        | 230/1380 [00:26<02:01,  9.44it/s] 17%|█▋        | 231/1380 [00:26<02:03,  9.34it/s] 17%|█▋        | 232/1380 [00:26<02:03,  9.33it/s] 17%|█▋        | 233/1380 [00:26<02:02,  9.33it/s] 17%|█▋        | 234/1380 [00:26<02:02,  9.39it/s] 17%|█▋        | 235/1380 [00:26<02:01,  9.45it/s] 17%|█▋        | 236/1380 [00:26<02:01,  9.40it/s] 17%|█▋        | 237/1380 [00:26<02:02,  9.37it/s] 17%|█▋        | 238/1380 [00:26<02:00,  9.49it/s] 17%|█▋        | 239/1380 [00:26<02:01,  9.41it/s] 17%|█▋        | 240/1380 [00:27<02:01,  9.36it/s] 17%|█▋        | 241/1380 [00:27<02:02,  9.32it/s] 18%|█▊        | 242/1380 [00:27<02:01,  9.34it/s] 18%|█▊        | 243/1380 [00:27<02:01,  9.35it/s] 18%|█▊        | 244/1380 [00:27<02:02,  9.29it/s] 18%|█▊        | 245/1380 [00:27<02:00,  9.41it/s] 18%|█▊        | 246/1380 [00:27<02:00,  9.40it/s] 18%|█▊        | 247/1380 [00:27<02:00,  9.44it/s] 18%|█▊        | 248/1380 [00:27<01:59,  9.45it/s] 18%|█▊        | 249/1380 [00:28<02:00,  9.40it/s] 18%|█▊        | 250/1380 [00:28<02:01,  9.32it/s] 18%|█▊        | 251/1380 [00:28<02:00,  9.39it/s] 18%|█▊        | 252/1380 [00:28<01:59,  9.41it/s] 18%|█▊        | 253/1380 [00:28<02:00,  9.39it/s] 18%|█▊        | 254/1380 [00:28<02:00,  9.38it/s] 18%|█▊        | 255/1380 [00:28<01:59,  9.41it/s] 19%|█▊        | 256/1380 [00:28<01:59,  9.37it/s] 19%|█▊        | 257/1380 [00:28<01:58,  9.46it/s] 19%|█▊        | 258/1380 [00:28<01:58,  9.45it/s] 19%|█▉        | 259/1380 [00:29<01:59,  9.36it/s] 19%|█▉        | 260/1380 [00:29<02:00,  9.27it/s] 19%|█▉        | 261/1380 [00:29<02:01,  9.24it/s] 19%|█▉        | 262/1380 [00:29<02:00,  9.30it/s] 19%|█▉        | 263/1380 [00:29<02:00,  9.30it/s] 19%|█▉        | 264/1380 [00:29<02:00,  9.28it/s] 19%|█▉        | 266/1380 [00:29<01:57,  9.45it/s] 19%|█▉        | 267/1380 [00:29<01:58,  9.36it/s] 19%|█▉        | 268/1380 [00:30<01:59,  9.29it/s] 19%|█▉        | 269/1380 [00:30<01:59,  9.28it/s] 20%|█▉        | 270/1380 [00:30<01:59,  9.28it/s] 20%|█▉        | 271/1380 [00:30<01:59,  9.31it/s] 20%|█▉        | 272/1380 [00:30<01:57,  9.43it/s] 20%|█▉        | 273/1380 [00:30<01:58,  9.31it/s] 20%|█▉        | 274/1380 [00:30<01:58,  9.33it/s] 20%|█▉        | 275/1380 [00:30<01:58,  9.35it/s]                                                   20%|██        | 276/1380 [00:30<01:58,  9.35it/s][INFO|trainer.py:755] 2023-11-15 20:07:50,107 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:07:50,109 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:07:50,109 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:07:50,109 >>   Batch size = 8
{'loss': 0.4353, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 83.87it/s][A
  7%|▋         | 18/276 [00:00<00:03, 72.76it/s][A
  9%|▉         | 26/276 [00:00<00:03, 75.56it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 73.36it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 73.92it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 75.23it/s][A
 21%|██        | 58/276 [00:00<00:02, 75.01it/s][A
 24%|██▍       | 66/276 [00:00<00:02, 74.07it/s][A
 27%|██▋       | 74/276 [00:00<00:02, 73.52it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 74.75it/s][A
 33%|███▎      | 90/276 [00:01<00:02, 73.36it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 73.49it/s][A
 38%|███▊      | 106/276 [00:01<00:02, 75.21it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 73.42it/s][A
 44%|████▍     | 122/276 [00:01<00:02, 72.40it/s][A
 47%|████▋     | 130/276 [00:01<00:02, 72.91it/s][A
 50%|█████     | 138/276 [00:01<00:01, 74.18it/s][A
 53%|█████▎    | 146/276 [00:01<00:01, 74.46it/s][A
 56%|█████▌    | 154/276 [00:02<00:01, 74.26it/s][A
 59%|█████▊    | 162/276 [00:02<00:01, 74.66it/s][A
 62%|██████▏   | 170/276 [00:02<00:01, 73.19it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 72.14it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 73.01it/s][A
 70%|███████   | 194/276 [00:02<00:01, 73.97it/s][A
 73%|███████▎  | 202/276 [00:02<00:00, 74.70it/s][A
 76%|███████▌  | 210/276 [00:02<00:00, 73.13it/s][A
 79%|███████▉  | 219/276 [00:02<00:00, 75.08it/s][A
 82%|████████▏ | 227/276 [00:03<00:00, 73.23it/s][A
 85%|████████▌ | 235/276 [00:03<00:00, 72.72it/s][A
 88%|████████▊ | 243/276 [00:03<00:00, 73.48it/s][A
 91%|█████████ | 251/276 [00:03<00:00, 73.80it/s][A
 94%|█████████▍| 259/276 [00:03<00:00, 74.31it/s][A
 97%|█████████▋| 267/276 [00:03<00:00, 72.42it/s][A
100%|██████████| 276/276 [00:03<00:00, 75.66it/s][A                                                  
                                                 [A 20%|██        | 276/1380 [00:34<01:58,  9.35it/s]
100%|██████████| 276/276 [00:03<00:00, 75.66it/s][A
                                                 [A 20%|██        | 277/1380 [00:34<17:50,  1.03it/s] 20%|██        | 278/1380 [00:34<13:56,  1.32it/s] 20%|██        | 279/1380 [00:35<10:48,  1.70it/s] 20%|██        | 280/1380 [00:35<08:25,  2.18it/s] 20%|██        | 281/1380 [00:35<06:37,  2.77it/s] 20%|██        | 282/1380 [00:35<05:16,  3.46it/s] 21%|██        | 283/1380 [00:35<04:20,  4.21it/s] 21%|██        | 284/1380 [00:35<03:40,  4.98it/s] 21%|██        | 285/1380 [00:35<03:10,  5.75it/s] 21%|██        | 286/1380 [00:35<02:47,  6.53it/s] 21%|██        | 287/1380 [00:35<02:33,  7.14it/s] 21%|██        | 288/1380 [00:36<02:21,  7.71it/s] 21%|██        | 289/1380 [00:36<02:13,  8.16it/s] 21%|██        | 290/1380 [00:36<02:08,  8.47it/s] 21%|██        | 291/1380 [00:36<02:05,  8.70it/s] 21%|██        | 292/1380 [00:36<02:03,  8.81it/s] 21%|██        | 293/1380 [00:36<02:00,  8.99it/s] 21%|██▏       | 294/1380 [00:36<01:59,  9.10it/s] 21%|██▏       | 295/1380 [00:36<01:58,  9.18it/s] 21%|██▏       | 296/1380 [00:36<01:56,  9.31it/s] 22%|██▏       | 297/1380 [00:36<01:57,  9.25it/s] 22%|██▏       | 298/1380 [00:37<01:57,  9.23it/s] 22%|██▏       | 299/1380 [00:37<01:57,  9.23it/s] 22%|██▏       | 300/1380 [00:37<01:56,  9.23it/s] 22%|██▏       | 301/1380 [00:37<01:56,  9.26it/s] 22%|██▏       | 302/1380 [00:37<01:57,  9.17it/s] 22%|██▏       | 303/1380 [00:37<01:55,  9.35it/s] 22%|██▏       | 304/1380 [00:37<01:55,  9.31it/s] 22%|██▏       | 305/1380 [00:37<01:56,  9.25it/s] 22%|██▏       | 306/1380 [00:37<01:56,  9.25it/s] 22%|██▏       | 307/1380 [00:38<01:55,  9.30it/s] 22%|██▏       | 308/1380 [00:38<01:55,  9.32it/s] 22%|██▏       | 309/1380 [00:38<01:55,  9.26it/s] 22%|██▏       | 310/1380 [00:38<01:54,  9.36it/s] 23%|██▎       | 311/1380 [00:38<01:55,  9.28it/s] 23%|██▎       | 312/1380 [00:38<01:55,  9.24it/s] 23%|██▎       | 313/1380 [00:38<01:54,  9.29it/s] 23%|██▎       | 314/1380 [00:38<01:54,  9.28it/s] 23%|██▎       | 315/1380 [00:38<01:54,  9.28it/s] 23%|██▎       | 316/1380 [00:39<01:55,  9.20it/s] 23%|██▎       | 317/1380 [00:39<01:54,  9.27it/s] 23%|██▎       | 318/1380 [00:39<01:54,  9.25it/s] 23%|██▎       | 319/1380 [00:39<01:54,  9.26it/s] 23%|██▎       | 320/1380 [00:39<01:53,  9.35it/s] 23%|██▎       | 321/1380 [00:39<01:53,  9.34it/s] 23%|██▎       | 322/1380 [00:39<01:54,  9.23it/s] 23%|██▎       | 323/1380 [00:39<01:55,  9.17it/s] 23%|██▎       | 324/1380 [00:39<01:54,  9.19it/s] 24%|██▎       | 325/1380 [00:39<01:54,  9.23it/s] 24%|██▎       | 326/1380 [00:40<01:54,  9.21it/s] 24%|██▎       | 327/1380 [00:40<01:51,  9.42it/s] 24%|██▍       | 328/1380 [00:40<01:53,  9.30it/s] 24%|██▍       | 329/1380 [00:40<01:53,  9.25it/s] 24%|██▍       | 330/1380 [00:40<01:53,  9.23it/s] 24%|██▍       | 331/1380 [00:40<01:52,  9.30it/s] 24%|██▍       | 332/1380 [00:40<01:52,  9.29it/s] 24%|██▍       | 333/1380 [00:40<01:53,  9.19it/s] 24%|██▍       | 334/1380 [00:40<01:52,  9.34it/s] 24%|██▍       | 335/1380 [00:41<01:53,  9.24it/s] 24%|██▍       | 336/1380 [00:41<01:52,  9.24it/s] 24%|██▍       | 337/1380 [00:41<01:51,  9.32it/s] 24%|██▍       | 338/1380 [00:41<01:52,  9.29it/s] 25%|██▍       | 339/1380 [00:41<01:53,  9.21it/s] 25%|██▍       | 340/1380 [00:41<01:53,  9.20it/s] 25%|██▍       | 341/1380 [00:41<01:53,  9.18it/s] 25%|██▍       | 342/1380 [00:41<01:52,  9.21it/s] 25%|██▍       | 343/1380 [00:41<01:53,  9.17it/s] 25%|██▍       | 344/1380 [00:42<01:50,  9.35it/s] 25%|██▌       | 345/1380 [00:42<01:50,  9.33it/s] 25%|██▌       | 346/1380 [00:42<01:51,  9.24it/s] 25%|██▌       | 347/1380 [00:42<01:51,  9.24it/s] 25%|██▌       | 348/1380 [00:42<01:51,  9.21it/s] 25%|██▌       | 349/1380 [00:42<01:51,  9.25it/s] 25%|██▌       | 350/1380 [00:42<01:51,  9.21it/s] 25%|██▌       | 351/1380 [00:42<01:50,  9.29it/s] 26%|██▌       | 352/1380 [00:42<01:51,  9.18it/s] 26%|██▌       | 353/1380 [00:43<01:52,  9.13it/s] 26%|██▌       | 354/1380 [00:43<01:51,  9.19it/s] 26%|██▌       | 355/1380 [00:43<01:51,  9.20it/s] 26%|██▌       | 356/1380 [00:43<01:52,  9.13it/s] 26%|██▌       | 357/1380 [00:43<01:53,  9.01it/s] 26%|██▌       | 358/1380 [00:43<01:51,  9.16it/s] 26%|██▌       | 359/1380 [00:43<01:52,  9.09it/s] 26%|██▌       | 360/1380 [00:43<01:51,  9.13it/s] 26%|██▌       | 361/1380 [00:43<01:50,  9.23it/s] 26%|██▌       | 362/1380 [00:44<01:51,  9.15it/s] 26%|██▋       | 363/1380 [00:44<01:51,  9.09it/s] 26%|██▋       | 364/1380 [00:44<01:51,  9.11it/s] 26%|██▋       | 365/1380 [00:44<01:50,  9.20it/s] 27%|██▋       | 366/1380 [00:44<01:50,  9.17it/s] 27%|██▋       | 367/1380 [00:44<01:50,  9.13it/s] 27%|██▋       | 368/1380 [00:44<01:49,  9.27it/s] 27%|██▋       | 369/1380 [00:44<01:49,  9.27it/s] 27%|██▋       | 370/1380 [00:44<01:50,  9.16it/s] 27%|██▋       | 371/1380 [00:44<01:49,  9.22it/s] 27%|██▋       | 372/1380 [00:45<01:49,  9.21it/s] 27%|██▋       | 373/1380 [00:45<01:49,  9.23it/s] 27%|██▋       | 374/1380 [00:45<01:49,  9.19it/s] 27%|██▋       | 375/1380 [00:45<01:48,  9.27it/s] 27%|██▋       | 376/1380 [00:45<01:48,  9.23it/s] 27%|██▋       | 377/1380 [00:45<01:49,  9.15it/s] 27%|██▋       | 378/1380 [00:45<01:48,  9.22it/s] 27%|██▋       | 379/1380 [00:45<01:48,  9.22it/s] 28%|██▊       | 380/1380 [00:45<01:49,  9.16it/s] 28%|██▊       | 381/1380 [00:46<01:49,  9.11it/s] 28%|██▊       | 382/1380 [00:46<01:48,  9.24it/s] 28%|██▊       | 383/1380 [00:46<01:48,  9.20it/s] 28%|██▊       | 384/1380 [00:46<01:48,  9.19it/s] 28%|██▊       | 385/1380 [00:46<01:47,  9.23it/s] 28%|██▊       | 386/1380 [00:46<01:47,  9.26it/s] 28%|██▊       | 387/1380 [00:46<01:47,  9.25it/s] 28%|██▊       | 388/1380 [00:46<01:48,  9.16it/s] 28%|██▊       | 389/1380 [00:46<01:47,  9.25it/s] 28%|██▊       | 390/1380 [00:47<01:47,  9.23it/s] 28%|██▊       | 391/1380 [00:47<01:47,  9.19it/s] 28%|██▊       | 392/1380 [00:47<01:47,  9.21it/s] 28%|██▊       | 393/1380 [00:47<01:47,  9.14it/s] 29%|██▊       | 394/1380 [00:47<01:47,  9.16it/s] 29%|██▊       | 395/1380 [00:47<01:47,  9.19it/s] 29%|██▊       | 396/1380 [00:47<01:47,  9.19it/s] 29%|██▉       | 397/1380 [00:47<01:47,  9.16it/s] 29%|██▉       | 398/1380 [00:47<01:47,  9.17it/s] 29%|██▉       | 399/1380 [00:48<01:46,  9.17it/s] 29%|██▉       | 400/1380 [00:48<01:47,  9.11it/s] 29%|██▉       | 401/1380 [00:48<01:46,  9.17it/s] 29%|██▉       | 402/1380 [00:48<01:46,  9.19it/s] 29%|██▉       | 403/1380 [00:48<01:46,  9.14it/s] 29%|██▉       | 404/1380 [00:48<01:47,  9.06it/s] 29%|██▉       | 405/1380 [00:48<01:46,  9.12it/s] 29%|██▉       | 406/1380 [00:48<01:46,  9.17it/s] 29%|██▉       | 407/1380 [00:48<01:46,  9.16it/s] 30%|██▉       | 408/1380 [00:49<01:45,  9.20it/s] 30%|██▉       | 409/1380 [00:49<01:44,  9.33it/s] 30%|██▉       | 410/1380 [00:49<01:45,  9.16it/s] 30%|██▉       | 411/1380 [00:49<01:46,  9.12it/s] 30%|██▉       | 412/1380 [00:49<01:45,  9.17it/s] 30%|██▉       | 413/1380 [00:49<01:45,  9.16it/s] 30%|███       | 414/1380 [00:49<01:45,  9.13it/s] 30%|███       | 415/1380 [00:49<01:45,  9.17it/s] 30%|███       | 416/1380 [00:49<01:43,  9.28it/s] 30%|███       | 417/1380 [00:49<01:44,  9.21it/s] 30%|███       | 418/1380 [00:50<01:44,  9.22it/s] 30%|███       | 419/1380 [00:50<01:43,  9.27it/s] 30%|███       | 420/1380 [00:50<01:43,  9.29it/s] 31%|███       | 421/1380 [00:50<01:43,  9.22it/s] 31%|███       | 422/1380 [00:50<01:43,  9.24it/s] 31%|███       | 423/1380 [00:50<01:43,  9.22it/s] 31%|███       | 424/1380 [00:50<01:43,  9.28it/s] 31%|███       | 425/1380 [00:50<01:43,  9.23it/s] 31%|███       | 426/1380 [00:50<01:42,  9.28it/s] 31%|███       | 427/1380 [00:51<01:42,  9.29it/s] 31%|███       | 428/1380 [00:51<01:42,  9.25it/s] 31%|███       | 429/1380 [00:51<01:42,  9.25it/s] 31%|███       | 430/1380 [00:51<01:43,  9.22it/s] 31%|███       | 431/1380 [00:51<01:43,  9.20it/s] 31%|███▏      | 432/1380 [00:51<01:44,  9.06it/s] 31%|███▏      | 433/1380 [00:51<01:43,  9.16it/s] 31%|███▏      | 434/1380 [00:51<01:44,  9.05it/s] 32%|███▏      | 435/1380 [00:51<01:44,  9.05it/s] 32%|███▏      | 436/1380 [00:52<01:43,  9.11it/s] 32%|███▏      | 437/1380 [00:52<01:45,  8.95it/s] 32%|███▏      | 438/1380 [00:52<01:45,  8.97it/s] 32%|███▏      | 439/1380 [00:52<01:44,  8.97it/s] 32%|███▏      | 440/1380 [00:52<01:44,  9.00it/s] 32%|███▏      | 441/1380 [00:52<01:44,  9.00it/s] 32%|███▏      | 442/1380 [00:52<01:44,  8.99it/s] 32%|███▏      | 443/1380 [00:52<01:43,  9.07it/s] 32%|███▏      | 444/1380 [00:52<01:43,  9.04it/s] 32%|███▏      | 445/1380 [00:53<01:43,  9.04it/s] 32%|███▏      | 446/1380 [00:53<01:44,  8.93it/s] 32%|███▏      | 447/1380 [00:53<01:43,  8.98it/s] 32%|███▏      | 448/1380 [00:53<01:44,  8.93it/s] 33%|███▎      | 449/1380 [00:53<01:43,  8.99it/s] 33%|███▎      | 450/1380 [00:53<01:42,  9.05it/s] 33%|███▎      | 451/1380 [00:53<01:42,  9.04it/s] 33%|███▎      | 452/1380 [00:53<01:43,  8.99it/s] 33%|███▎      | 453/1380 [00:53<01:43,  8.98it/s] 33%|███▎      | 454/1380 [00:54<01:42,  9.00it/s] 33%|███▎      | 455/1380 [00:54<01:42,  9.00it/s] 33%|███▎      | 456/1380 [00:54<01:43,  8.95it/s] 33%|███▎      | 457/1380 [00:54<01:42,  8.97it/s] 33%|███▎      | 458/1380 [00:54<01:43,  8.93it/s] 33%|███▎      | 459/1380 [00:54<01:43,  8.92it/s] 33%|███▎      | 460/1380 [00:54<01:43,  8.85it/s] 33%|███▎      | 461/1380 [00:54<01:43,  8.88it/s] 33%|███▎      | 462/1380 [00:54<01:43,  8.86it/s] 34%|███▎      | 463/1380 [00:55<01:43,  8.84it/s] 34%|███▎      | 464/1380 [00:55<01:42,  8.94it/s] 34%|███▎      | 465/1380 [00:55<01:42,  8.95it/s] 34%|███▍      | 466/1380 [00:55<01:42,  8.92it/s] 34%|███▍      | 467/1380 [00:55<01:42,  8.95it/s] 34%|███▍      | 468/1380 [00:55<01:40,  9.04it/s] 34%|███▍      | 469/1380 [00:55<01:41,  8.99it/s] 34%|███▍      | 470/1380 [00:55<01:41,  8.95it/s] 34%|███▍      | 471/1380 [00:55<01:40,  9.00it/s] 34%|███▍      | 472/1380 [00:56<01:41,  8.96it/s] 34%|███▍      | 473/1380 [00:56<01:41,  8.96it/s] 34%|███▍      | 474/1380 [00:56<01:41,  8.95it/s] 34%|███▍      | 475/1380 [00:56<01:40,  8.97it/s] 34%|███▍      | 476/1380 [00:56<01:41,  8.94it/s] 35%|███▍      | 477/1380 [00:56<01:40,  8.95it/s] 35%|███▍      | 478/1380 [00:56<01:40,  8.94it/s] 35%|███▍      | 479/1380 [00:56<01:40,  8.94it/s] 35%|███▍      | 480/1380 [00:56<01:41,  8.91it/s] 35%|███▍      | 481/1380 [00:57<01:40,  8.93it/s] 35%|███▍      | 482/1380 [00:57<01:40,  8.92it/s] 35%|███▌      | 483/1380 [00:57<01:41,  8.84it/s] 35%|███▌      | 484/1380 [00:57<01:40,  8.89it/s] 35%|███▌      | 485/1380 [00:57<01:40,  8.92it/s] 35%|███▌      | 486/1380 [00:57<01:40,  8.93it/s] 35%|███▌      | 487/1380 [00:57<01:39,  8.99it/s] 35%|███▌      | 488/1380 [00:57<01:39,  8.93it/s] 35%|███▌      | 489/1380 [00:57<01:38,  9.05it/s] 36%|███▌      | 490/1380 [00:58<01:39,  8.95it/s] 36%|███▌      | 491/1380 [00:58<01:39,  8.97it/s] 36%|███▌      | 492/1380 [00:58<01:39,  8.92it/s] 36%|███▌      | 493/1380 [00:58<01:39,  8.93it/s] 36%|███▌      | 494/1380 [00:58<01:38,  8.96it/s] 36%|███▌      | 495/1380 [00:58<01:38,  8.98it/s] 36%|███▌      | 496/1380 [00:58<01:38,  9.01it/s] 36%|███▌      | 497/1380 [00:58<01:38,  8.95it/s] 36%|███▌      | 498/1380 [00:58<01:38,  8.93it/s] 36%|███▌      | 499/1380 [00:59<01:38,  8.94it/s] 36%|███▌      | 500/1380 [00:59<01:38,  8.90it/s] 36%|███▋      | 501/1380 [00:59<01:39,  8.88it/s] 36%|███▋      | 502/1380 [00:59<01:39,  8.86it/s] 36%|███▋      | 503/1380 [00:59<01:38,  8.90it/s] 37%|███▋      | 504/1380 [00:59<01:38,  8.89it/s] 37%|███▋      | 505/1380 [00:59<01:38,  8.85it/s] 37%|███▋      | 506/1380 [00:59<01:38,  8.90it/s] 37%|███▋      | 507/1380 [00:59<01:38,  8.90it/s] 37%|███▋      | 508/1380 [01:00<01:38,  8.90it/s] 37%|███▋      | 509/1380 [01:00<01:37,  8.92it/s] 37%|███▋      | 510/1380 [01:00<01:37,  8.94it/s] 37%|███▋      | 511/1380 [01:00<01:36,  8.98it/s] 37%|███▋      | 512/1380 [01:00<01:36,  8.98it/s] 37%|███▋      | 513/1380 [01:00<01:37,  8.93it/s] 37%|███▋      | 514/1380 [01:00<01:37,  8.89it/s] 37%|███▋      | 515/1380 [01:00<01:37,  8.92it/s] 37%|███▋      | 516/1380 [01:01<01:36,  8.91it/s] 37%|███▋      | 517/1380 [01:01<01:37,  8.85it/s] 38%|███▊      | 518/1380 [01:01<01:37,  8.88it/s] 38%|███▊      | 519/1380 [01:01<01:36,  8.91it/s] 38%|███▊      | 520/1380 [01:01<01:35,  8.98it/s] 38%|███▊      | 521/1380 [01:01<01:35,  9.00it/s] 38%|███▊      | 522/1380 [01:01<01:35,  9.01it/s] 38%|███▊      | 523/1380 [01:01<01:35,  8.97it/s] 38%|███▊      | 524/1380 [01:01<01:33,  9.14it/s] 38%|███▊      | 525/1380 [01:02<01:34,  9.01it/s] 38%|███▊      | 526/1380 [01:02<01:35,  8.92it/s] 38%|███▊      | 527/1380 [01:02<01:35,  8.90it/s] 38%|███▊      | 528/1380 [01:02<01:36,  8.86it/s] 38%|███▊      | 529/1380 [01:02<01:35,  8.87it/s] 38%|███▊      | 530/1380 [01:02<01:35,  8.86it/s] 38%|███▊      | 531/1380 [01:02<01:34,  9.01it/s] 39%|███▊      | 532/1380 [01:02<01:34,  8.98it/s] 39%|███▊      | 533/1380 [01:02<01:35,  8.91it/s] 39%|███▊      | 534/1380 [01:03<01:34,  8.91it/s] 39%|███▉      | 535/1380 [01:03<01:34,  8.90it/s] 39%|███▉      | 536/1380 [01:03<01:34,  8.91it/s] 39%|███▉      | 537/1380 [01:03<01:33,  8.98it/s] 39%|███▉      | 538/1380 [01:03<01:33,  9.03it/s] 39%|███▉      | 539/1380 [01:03<01:33,  8.96it/s] 39%|███▉      | 540/1380 [01:03<01:34,  8.92it/s] 39%|███▉      | 541/1380 [01:03<01:33,  8.93it/s] 39%|███▉      | 542/1380 [01:03<01:34,  8.91it/s] 39%|███▉      | 543/1380 [01:04<01:33,  8.93it/s] 39%|███▉      | 544/1380 [01:04<01:33,  8.97it/s] 39%|███▉      | 545/1380 [01:04<01:32,  9.07it/s] 40%|███▉      | 546/1380 [01:04<01:32,  9.05it/s] 40%|███▉      | 547/1380 [01:04<01:32,  8.98it/s] 40%|███▉      | 548/1380 [01:04<01:33,  8.94it/s] 40%|███▉      | 549/1380 [01:04<01:33,  8.88it/s] 40%|███▉      | 550/1380 [01:04<01:33,  8.86it/s] 40%|███▉      | 551/1380 [01:04<01:31,  9.03it/s]                                                   40%|████      | 552/1380 [01:04<01:31,  9.03it/s][INFO|trainer.py:755] 2023-11-15 20:08:24,204 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:08:24,206 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:08:24,207 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:08:24,207 >>   Batch size = 8
{'eval_loss': 0.3659806251525879, 'eval_accuracy': 0.8602540834845736, 'eval_micro_f1': 0.8602540834845736, 'eval_macro_f1': 0.8430169869799107, 'eval_runtime': 3.7966, 'eval_samples_per_second': 580.514, 'eval_steps_per_second': 72.696, 'epoch': 1.0}
{'loss': 0.2885, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 81.59it/s][A
  7%|▋         | 18/276 [00:00<00:03, 72.60it/s][A
  9%|▉         | 26/276 [00:00<00:03, 72.41it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 72.35it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 72.11it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 71.10it/s][A
 21%|██        | 58/276 [00:00<00:02, 73.30it/s][A
 24%|██▍       | 66/276 [00:00<00:02, 70.84it/s][A
 27%|██▋       | 74/276 [00:01<00:02, 71.20it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 71.44it/s][A
 33%|███▎      | 90/276 [00:01<00:02, 71.14it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 72.12it/s][A
 38%|███▊      | 106/276 [00:01<00:02, 71.53it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 72.14it/s][A
 44%|████▍     | 122/276 [00:01<00:02, 71.20it/s][A
 47%|████▋     | 130/276 [00:01<00:02, 71.05it/s][A
 50%|█████     | 138/276 [00:01<00:01, 72.16it/s][A
 53%|█████▎    | 146/276 [00:02<00:01, 72.24it/s][A
 56%|█████▌    | 154/276 [00:02<00:01, 72.77it/s][A
 59%|█████▊    | 162/276 [00:02<00:01, 72.31it/s][A
 62%|██████▏   | 170/276 [00:02<00:01, 73.21it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 72.66it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 72.94it/s][A
 70%|███████   | 194/276 [00:02<00:01, 72.85it/s][A
 73%|███████▎  | 202/276 [00:02<00:01, 72.76it/s][A
 76%|███████▌  | 210/276 [00:02<00:00, 71.63it/s][A
 79%|███████▉  | 218/276 [00:03<00:00, 71.18it/s][A
 82%|████████▏ | 226/276 [00:03<00:00, 72.13it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 71.88it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 72.02it/s][A
 91%|█████████ | 250/276 [00:03<00:00, 72.46it/s][A
 93%|█████████▎| 258/276 [00:03<00:00, 71.15it/s][A
 96%|█████████▋| 266/276 [00:03<00:00, 70.77it/s][A
 99%|█████████▉| 274/276 [00:03<00:00, 70.78it/s][A                                                  
                                                 [A 40%|████      | 552/1380 [01:08<01:31,  9.03it/s]
100%|██████████| 276/276 [00:03<00:00, 70.78it/s][A
                                                 [A 40%|████      | 553/1380 [01:08<13:49,  1.00s/it] 40%|████      | 554/1380 [01:09<10:45,  1.28it/s] 40%|████      | 555/1380 [01:09<08:19,  1.65it/s] 40%|████      | 556/1380 [01:09<06:27,  2.12it/s] 40%|████      | 557/1380 [01:09<05:04,  2.70it/s] 40%|████      | 558/1380 [01:09<04:03,  3.38it/s] 41%|████      | 559/1380 [01:09<03:18,  4.13it/s] 41%|████      | 560/1380 [01:09<02:46,  4.92it/s] 41%|████      | 561/1380 [01:09<02:24,  5.69it/s] 41%|████      | 562/1380 [01:09<02:08,  6.39it/s] 41%|████      | 563/1380 [01:10<01:56,  7.01it/s] 41%|████      | 564/1380 [01:10<01:48,  7.54it/s] 41%|████      | 565/1380 [01:10<01:42,  7.92it/s] 41%|████      | 566/1380 [01:10<01:38,  8.27it/s] 41%|████      | 567/1380 [01:10<01:35,  8.48it/s] 41%|████      | 568/1380 [01:10<01:33,  8.69it/s] 41%|████      | 569/1380 [01:10<01:31,  8.82it/s] 41%|████▏     | 570/1380 [01:10<01:30,  8.90it/s] 41%|████▏     | 571/1380 [01:10<01:30,  8.90it/s] 41%|████▏     | 572/1380 [01:11<01:30,  8.94it/s] 42%|████▏     | 573/1380 [01:11<01:29,  8.97it/s] 42%|████▏     | 574/1380 [01:11<01:29,  9.03it/s] 42%|████▏     | 575/1380 [01:11<01:28,  9.10it/s] 42%|████▏     | 576/1380 [01:11<01:28,  9.10it/s] 42%|████▏     | 577/1380 [01:11<01:28,  9.04it/s] 42%|████▏     | 578/1380 [01:11<01:28,  9.02it/s] 42%|████▏     | 579/1380 [01:11<01:28,  9.08it/s] 42%|████▏     | 580/1380 [01:11<01:28,  9.04it/s] 42%|████▏     | 581/1380 [01:12<01:28,  9.07it/s] 42%|████▏     | 582/1380 [01:12<01:27,  9.11it/s] 42%|████▏     | 583/1380 [01:12<01:27,  9.13it/s] 42%|████▏     | 584/1380 [01:12<01:27,  9.11it/s] 42%|████▏     | 585/1380 [01:12<01:26,  9.16it/s] 42%|████▏     | 586/1380 [01:12<01:26,  9.13it/s] 43%|████▎     | 587/1380 [01:12<01:26,  9.16it/s] 43%|████▎     | 588/1380 [01:12<01:26,  9.19it/s] 43%|████▎     | 589/1380 [01:12<01:26,  9.17it/s] 43%|████▎     | 590/1380 [01:13<01:25,  9.23it/s] 43%|████▎     | 591/1380 [01:13<01:25,  9.18it/s] 43%|████▎     | 592/1380 [01:13<01:26,  9.15it/s] 43%|████▎     | 593/1380 [01:13<01:25,  9.19it/s] 43%|████▎     | 594/1380 [01:13<01:25,  9.22it/s] 43%|████▎     | 595/1380 [01:13<01:25,  9.18it/s] 43%|████▎     | 596/1380 [01:13<01:26,  9.09it/s] 43%|████▎     | 597/1380 [01:13<01:25,  9.19it/s] 43%|████▎     | 598/1380 [01:13<01:25,  9.18it/s] 43%|████▎     | 599/1380 [01:14<01:24,  9.21it/s] 43%|████▎     | 600/1380 [01:14<01:24,  9.23it/s] 44%|████▎     | 601/1380 [01:14<01:24,  9.19it/s] 44%|████▎     | 602/1380 [01:14<01:25,  9.11it/s] 44%|████▎     | 603/1380 [01:14<01:26,  9.02it/s] 44%|████▍     | 604/1380 [01:14<01:25,  9.09it/s] 44%|████▍     | 605/1380 [01:14<01:25,  9.09it/s] 44%|████▍     | 606/1380 [01:14<01:24,  9.14it/s] 44%|████▍     | 607/1380 [01:14<01:24,  9.15it/s] 44%|████▍     | 608/1380 [01:15<01:24,  9.14it/s] 44%|████▍     | 609/1380 [01:15<01:25,  9.06it/s] 44%|████▍     | 610/1380 [01:15<01:25,  9.05it/s] 44%|████▍     | 611/1380 [01:15<01:24,  9.12it/s] 44%|████▍     | 612/1380 [01:15<01:23,  9.18it/s] 44%|████▍     | 613/1380 [01:15<01:23,  9.18it/s] 44%|████▍     | 614/1380 [01:15<01:23,  9.20it/s] 45%|████▍     | 615/1380 [01:15<01:23,  9.15it/s] 45%|████▍     | 616/1380 [01:15<01:23,  9.12it/s] 45%|████▍     | 617/1380 [01:16<01:23,  9.08it/s] 45%|████▍     | 618/1380 [01:16<01:23,  9.12it/s] 45%|████▍     | 619/1380 [01:16<01:23,  9.13it/s] 45%|████▍     | 620/1380 [01:16<01:23,  9.15it/s] 45%|████▌     | 621/1380 [01:16<01:22,  9.25it/s] 45%|████▌     | 622/1380 [01:16<01:21,  9.26it/s] 45%|████▌     | 623/1380 [01:16<01:22,  9.15it/s] 45%|████▌     | 624/1380 [01:16<01:22,  9.11it/s] 45%|████▌     | 625/1380 [01:16<01:22,  9.11it/s] 45%|████▌     | 626/1380 [01:16<01:22,  9.16it/s] 45%|████▌     | 627/1380 [01:17<01:22,  9.14it/s] 46%|████▌     | 628/1380 [01:17<01:20,  9.29it/s] 46%|████▌     | 629/1380 [01:17<01:21,  9.17it/s] 46%|████▌     | 630/1380 [01:17<01:21,  9.15it/s] 46%|████▌     | 631/1380 [01:17<01:21,  9.18it/s] 46%|████▌     | 632/1380 [01:17<01:21,  9.19it/s] 46%|████▌     | 633/1380 [01:17<01:21,  9.22it/s] 46%|████▌     | 634/1380 [01:17<01:21,  9.20it/s] 46%|████▌     | 635/1380 [01:17<01:20,  9.24it/s] 46%|████▌     | 636/1380 [01:18<01:21,  9.14it/s] 46%|████▌     | 637/1380 [01:18<01:21,  9.13it/s] 46%|████▌     | 638/1380 [01:18<01:20,  9.18it/s] 46%|████▋     | 639/1380 [01:18<01:21,  9.14it/s] 46%|████▋     | 640/1380 [01:18<01:20,  9.16it/s] 46%|████▋     | 641/1380 [01:18<01:20,  9.12it/s] 47%|████▋     | 642/1380 [01:18<01:20,  9.11it/s] 47%|████▋     | 643/1380 [01:18<01:20,  9.13it/s] 47%|████▋     | 644/1380 [01:18<01:20,  9.13it/s] 47%|████▋     | 645/1380 [01:19<01:20,  9.09it/s] 47%|████▋     | 646/1380 [01:19<01:20,  9.15it/s] 47%|████▋     | 647/1380 [01:19<01:20,  9.14it/s] 47%|████▋     | 648/1380 [01:19<01:20,  9.12it/s] 47%|████▋     | 649/1380 [01:19<01:19,  9.21it/s] 47%|████▋     | 650/1380 [01:19<01:19,  9.14it/s] 47%|████▋     | 651/1380 [01:19<01:19,  9.21it/s] 47%|████▋     | 652/1380 [01:19<01:19,  9.21it/s] 47%|████▋     | 653/1380 [01:19<01:19,  9.19it/s] 47%|████▋     | 654/1380 [01:20<01:19,  9.11it/s] 47%|████▋     | 655/1380 [01:20<01:19,  9.08it/s] 48%|████▊     | 656/1380 [01:20<01:19,  9.16it/s] 48%|████▊     | 657/1380 [01:20<01:18,  9.21it/s] 48%|████▊     | 658/1380 [01:20<01:17,  9.26it/s] 48%|████▊     | 659/1380 [01:20<01:17,  9.30it/s] 48%|████▊     | 660/1380 [01:20<01:17,  9.26it/s] 48%|████▊     | 661/1380 [01:20<01:17,  9.24it/s] 48%|████▊     | 662/1380 [01:20<01:18,  9.20it/s] 48%|████▊     | 663/1380 [01:21<01:17,  9.20it/s] 48%|████▊     | 664/1380 [01:21<01:18,  9.17it/s] 48%|████▊     | 665/1380 [01:21<01:17,  9.17it/s] 48%|████▊     | 666/1380 [01:21<01:17,  9.25it/s] 48%|████▊     | 667/1380 [01:21<01:17,  9.20it/s] 48%|████▊     | 668/1380 [01:21<01:17,  9.17it/s] 48%|████▊     | 669/1380 [01:21<01:17,  9.13it/s] 49%|████▊     | 670/1380 [01:21<01:17,  9.14it/s] 49%|████▊     | 671/1380 [01:21<01:17,  9.11it/s] 49%|████▊     | 672/1380 [01:22<01:17,  9.19it/s] 49%|████▉     | 673/1380 [01:22<01:16,  9.20it/s] 49%|████▉     | 674/1380 [01:22<01:16,  9.17it/s] 49%|████▉     | 675/1380 [01:22<01:17,  9.09it/s] 49%|████▉     | 676/1380 [01:22<01:17,  9.09it/s] 49%|████▉     | 677/1380 [01:22<01:17,  9.11it/s] 49%|████▉     | 678/1380 [01:22<01:16,  9.13it/s] 49%|████▉     | 679/1380 [01:22<01:16,  9.15it/s] 49%|████▉     | 680/1380 [01:22<01:16,  9.15it/s] 49%|████▉     | 681/1380 [01:22<01:16,  9.14it/s] 49%|████▉     | 682/1380 [01:23<01:16,  9.08it/s] 49%|████▉     | 683/1380 [01:23<01:17,  9.00it/s] 50%|████▉     | 684/1380 [01:23<01:16,  9.15it/s] 50%|████▉     | 685/1380 [01:23<01:16,  9.11it/s] 50%|████▉     | 686/1380 [01:23<01:15,  9.14it/s] 50%|████▉     | 687/1380 [01:23<01:15,  9.12it/s] 50%|████▉     | 688/1380 [01:23<01:15,  9.12it/s] 50%|████▉     | 689/1380 [01:23<01:16,  9.00it/s] 50%|█████     | 690/1380 [01:23<01:16,  8.96it/s] 50%|█████     | 691/1380 [01:24<01:15,  9.11it/s] 50%|█████     | 692/1380 [01:24<01:15,  9.12it/s] 50%|█████     | 693/1380 [01:24<01:15,  9.13it/s] 50%|█████     | 694/1380 [01:24<01:15,  9.09it/s] 50%|█████     | 695/1380 [01:24<01:15,  9.06it/s] 50%|█████     | 696/1380 [01:24<01:15,  9.06it/s] 51%|█████     | 697/1380 [01:24<01:15,  9.04it/s] 51%|█████     | 698/1380 [01:24<01:14,  9.13it/s] 51%|█████     | 699/1380 [01:24<01:15,  9.07it/s] 51%|█████     | 700/1380 [01:25<01:15,  9.06it/s] 51%|█████     | 701/1380 [01:25<01:14,  9.08it/s] 51%|█████     | 702/1380 [01:25<01:14,  9.07it/s] 51%|█████     | 703/1380 [01:25<01:15,  8.98it/s] 51%|█████     | 704/1380 [01:25<01:14,  9.03it/s] 51%|█████     | 705/1380 [01:25<01:14,  9.10it/s] 51%|█████     | 706/1380 [01:25<01:13,  9.12it/s] 51%|█████     | 707/1380 [01:25<01:13,  9.19it/s] 51%|█████▏    | 708/1380 [01:25<01:12,  9.23it/s] 51%|█████▏    | 709/1380 [01:26<01:12,  9.21it/s] 51%|█████▏    | 710/1380 [01:26<01:13,  9.13it/s] 52%|█████▏    | 711/1380 [01:26<01:13,  9.05it/s] 52%|█████▏    | 712/1380 [01:26<01:13,  9.13it/s] 52%|█████▏    | 713/1380 [01:26<01:13,  9.13it/s] 52%|█████▏    | 714/1380 [01:26<01:12,  9.20it/s] 52%|█████▏    | 715/1380 [01:26<01:12,  9.22it/s] 52%|█████▏    | 716/1380 [01:26<01:12,  9.20it/s] 52%|█████▏    | 717/1380 [01:26<01:11,  9.23it/s] 52%|█████▏    | 718/1380 [01:27<01:11,  9.27it/s] 52%|█████▏    | 719/1380 [01:27<01:11,  9.28it/s] 52%|█████▏    | 720/1380 [01:27<01:11,  9.23it/s] 52%|█████▏    | 721/1380 [01:27<01:11,  9.25it/s] 52%|█████▏    | 722/1380 [01:27<01:10,  9.31it/s] 52%|█████▏    | 723/1380 [01:27<01:10,  9.25it/s] 52%|█████▏    | 724/1380 [01:27<01:11,  9.18it/s] 53%|█████▎    | 725/1380 [01:27<01:11,  9.15it/s] 53%|█████▎    | 726/1380 [01:27<01:11,  9.15it/s] 53%|█████▎    | 727/1380 [01:28<01:11,  9.16it/s] 53%|█████▎    | 728/1380 [01:28<01:11,  9.11it/s] 53%|█████▎    | 729/1380 [01:28<01:10,  9.29it/s] 53%|█████▎    | 730/1380 [01:28<01:10,  9.21it/s] 53%|█████▎    | 731/1380 [01:28<01:10,  9.14it/s] 53%|█████▎    | 732/1380 [01:28<01:10,  9.23it/s] 53%|█████▎    | 733/1380 [01:28<01:10,  9.19it/s] 53%|█████▎    | 734/1380 [01:28<01:10,  9.16it/s] 53%|█████▎    | 735/1380 [01:28<01:10,  9.16it/s] 53%|█████▎    | 736/1380 [01:29<01:10,  9.20it/s] 53%|█████▎    | 737/1380 [01:29<01:10,  9.16it/s] 53%|█████▎    | 738/1380 [01:29<01:09,  9.18it/s] 54%|█████▎    | 739/1380 [01:29<01:10,  9.14it/s] 54%|█████▎    | 740/1380 [01:29<01:09,  9.18it/s] 54%|█████▎    | 741/1380 [01:29<01:10,  9.10it/s] 54%|█████▍    | 742/1380 [01:29<01:10,  9.09it/s] 54%|█████▍    | 743/1380 [01:29<01:09,  9.14it/s] 54%|█████▍    | 744/1380 [01:29<01:09,  9.17it/s] 54%|█████▍    | 745/1380 [01:29<01:08,  9.22it/s] 54%|█████▍    | 746/1380 [01:30<01:08,  9.24it/s] 54%|█████▍    | 747/1380 [01:30<01:08,  9.18it/s] 54%|█████▍    | 748/1380 [01:30<01:09,  9.09it/s] 54%|█████▍    | 749/1380 [01:30<01:09,  9.13it/s] 54%|█████▍    | 750/1380 [01:30<01:08,  9.14it/s] 54%|█████▍    | 751/1380 [01:30<01:08,  9.13it/s] 54%|█████▍    | 752/1380 [01:30<01:08,  9.11it/s] 55%|█████▍    | 753/1380 [01:30<01:07,  9.29it/s] 55%|█████▍    | 754/1380 [01:30<01:07,  9.25it/s] 55%|█████▍    | 755/1380 [01:31<01:08,  9.18it/s] 55%|█████▍    | 756/1380 [01:31<01:07,  9.26it/s] 55%|█████▍    | 757/1380 [01:31<01:07,  9.21it/s] 55%|█████▍    | 758/1380 [01:31<01:07,  9.18it/s] 55%|█████▌    | 759/1380 [01:31<01:07,  9.14it/s] 55%|█████▌    | 760/1380 [01:31<01:06,  9.26it/s] 55%|█████▌    | 761/1380 [01:31<01:07,  9.15it/s] 55%|█████▌    | 762/1380 [01:31<01:07,  9.14it/s] 55%|█████▌    | 763/1380 [01:31<01:07,  9.16it/s] 55%|█████▌    | 764/1380 [01:32<01:06,  9.22it/s] 55%|█████▌    | 765/1380 [01:32<01:07,  9.13it/s] 56%|█████▌    | 766/1380 [01:32<01:07,  9.12it/s] 56%|█████▌    | 767/1380 [01:32<01:06,  9.17it/s] 56%|█████▌    | 768/1380 [01:32<01:06,  9.15it/s] 56%|█████▌    | 769/1380 [01:32<01:06,  9.15it/s] 56%|█████▌    | 770/1380 [01:32<01:06,  9.15it/s] 56%|█████▌    | 771/1380 [01:32<01:06,  9.17it/s] 56%|█████▌    | 772/1380 [01:32<01:06,  9.09it/s] 56%|█████▌    | 773/1380 [01:33<01:07,  9.03it/s] 56%|█████▌    | 774/1380 [01:33<01:06,  9.14it/s] 56%|█████▌    | 775/1380 [01:33<01:06,  9.14it/s] 56%|█████▌    | 776/1380 [01:33<01:06,  9.14it/s] 56%|█████▋    | 777/1380 [01:33<01:05,  9.16it/s] 56%|█████▋    | 778/1380 [01:33<01:05,  9.13it/s] 56%|█████▋    | 779/1380 [01:33<01:06,  9.03it/s] 57%|█████▋    | 780/1380 [01:33<01:06,  9.04it/s] 57%|█████▋    | 781/1380 [01:33<01:06,  9.04it/s] 57%|█████▋    | 782/1380 [01:34<01:05,  9.09it/s] 57%|█████▋    | 783/1380 [01:34<01:05,  9.12it/s] 57%|█████▋    | 784/1380 [01:34<01:04,  9.18it/s] 57%|█████▋    | 785/1380 [01:34<01:04,  9.19it/s] 57%|█████▋    | 786/1380 [01:34<01:05,  9.07it/s] 57%|█████▋    | 787/1380 [01:34<01:05,  9.12it/s] 57%|█████▋    | 788/1380 [01:34<01:04,  9.16it/s] 57%|█████▋    | 789/1380 [01:34<01:04,  9.17it/s] 57%|█████▋    | 790/1380 [01:34<01:04,  9.16it/s] 57%|█████▋    | 791/1380 [01:35<01:04,  9.20it/s] 57%|█████▋    | 792/1380 [01:35<01:04,  9.12it/s] 57%|█████▋    | 793/1380 [01:35<01:04,  9.09it/s] 58%|█████▊    | 794/1380 [01:35<01:04,  9.10it/s] 58%|█████▊    | 795/1380 [01:35<01:04,  9.06it/s] 58%|█████▊    | 796/1380 [01:35<01:04,  9.09it/s] 58%|█████▊    | 797/1380 [01:35<01:04,  9.06it/s] 58%|█████▊    | 798/1380 [01:35<01:03,  9.19it/s] 58%|█████▊    | 799/1380 [01:35<01:04,  9.04it/s] 58%|█████▊    | 800/1380 [01:36<01:04,  9.01it/s] 58%|█████▊    | 801/1380 [01:36<01:03,  9.09it/s] 58%|█████▊    | 802/1380 [01:36<01:03,  9.10it/s] 58%|█████▊    | 803/1380 [01:36<01:02,  9.20it/s] 58%|█████▊    | 804/1380 [01:36<01:03,  9.11it/s] 58%|█████▊    | 805/1380 [01:36<01:02,  9.25it/s] 58%|█████▊    | 806/1380 [01:36<01:02,  9.14it/s] 58%|█████▊    | 807/1380 [01:36<01:02,  9.13it/s] 59%|█████▊    | 808/1380 [01:36<01:02,  9.17it/s] 59%|█████▊    | 809/1380 [01:37<01:02,  9.10it/s] 59%|█████▊    | 810/1380 [01:37<01:02,  9.08it/s] 59%|█████▉    | 811/1380 [01:37<01:02,  9.16it/s] 59%|█████▉    | 812/1380 [01:37<01:01,  9.23it/s] 59%|█████▉    | 813/1380 [01:37<01:01,  9.23it/s] 59%|█████▉    | 814/1380 [01:37<01:01,  9.23it/s] 59%|█████▉    | 815/1380 [01:37<01:01,  9.24it/s] 59%|█████▉    | 816/1380 [01:37<01:01,  9.22it/s] 59%|█████▉    | 817/1380 [01:37<01:01,  9.18it/s] 59%|█████▉    | 818/1380 [01:37<01:01,  9.17it/s] 59%|█████▉    | 819/1380 [01:38<01:01,  9.16it/s] 59%|█████▉    | 820/1380 [01:38<01:01,  9.17it/s] 59%|█████▉    | 821/1380 [01:38<01:00,  9.19it/s] 60%|█████▉    | 822/1380 [01:38<01:01,  9.11it/s] 60%|█████▉    | 823/1380 [01:38<01:01,  9.10it/s] 60%|█████▉    | 824/1380 [01:38<01:00,  9.12it/s] 60%|█████▉    | 825/1380 [01:38<01:00,  9.12it/s] 60%|█████▉    | 826/1380 [01:38<01:00,  9.17it/s] 60%|█████▉    | 827/1380 [01:38<01:00,  9.19it/s]                                                   60%|██████    | 828/1380 [01:39<01:00,  9.19it/s][INFO|trainer.py:755] 2023-11-15 20:08:58,259 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:08:58,260 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:08:58,261 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:08:58,261 >>   Batch size = 8
{'eval_loss': 0.37384283542633057, 'eval_accuracy': 0.8643375680580763, 'eval_micro_f1': 0.8643375680580763, 'eval_macro_f1': 0.8516481031286111, 'eval_runtime': 3.8902, 'eval_samples_per_second': 566.558, 'eval_steps_per_second': 70.948, 'epoch': 2.0}
{'loss': 0.1988, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 82.08it/s][A
  7%|▋         | 18/276 [00:00<00:03, 76.08it/s][A
  9%|▉         | 26/276 [00:00<00:03, 73.14it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 72.94it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 73.31it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 72.36it/s][A
 21%|██        | 58/276 [00:00<00:03, 71.32it/s][A
 24%|██▍       | 66/276 [00:00<00:02, 72.27it/s][A
 27%|██▋       | 74/276 [00:01<00:02, 71.73it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 71.18it/s][A
 33%|███▎      | 90/276 [00:01<00:02, 71.00it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 71.64it/s][A
 38%|███▊      | 106/276 [00:01<00:02, 70.62it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 70.82it/s][A
 44%|████▍     | 122/276 [00:01<00:02, 71.51it/s][A
 47%|████▋     | 130/276 [00:01<00:02, 71.81it/s][A
 50%|█████     | 138/276 [00:01<00:01, 71.11it/s][A
 53%|█████▎    | 146/276 [00:02<00:01, 72.63it/s][A
 56%|█████▌    | 154/276 [00:02<00:01, 70.89it/s][A
 59%|█████▊    | 162/276 [00:02<00:01, 70.83it/s][A
 62%|██████▏   | 170/276 [00:02<00:01, 71.97it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 71.36it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 72.71it/s][A
 70%|███████   | 194/276 [00:02<00:01, 70.85it/s][A
 73%|███████▎  | 202/276 [00:02<00:01, 72.47it/s][A
 76%|███████▌  | 210/276 [00:02<00:00, 72.14it/s][A
 79%|███████▉  | 218/276 [00:03<00:00, 71.31it/s][A
 82%|████████▏ | 226/276 [00:03<00:00, 71.45it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 71.35it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 70.01it/s][A
 91%|█████████ | 250/276 [00:03<00:00, 70.52it/s][A
 93%|█████████▎| 258/276 [00:03<00:00, 71.88it/s][A
 96%|█████████▋| 266/276 [00:03<00:00, 71.97it/s][A
 99%|█████████▉| 274/276 [00:03<00:00, 71.66it/s][A                                                  
                                                 [A 60%|██████    | 828/1380 [01:42<01:00,  9.19it/s]
100%|██████████| 276/276 [00:03<00:00, 71.66it/s][A
                                                 [A 60%|██████    | 829/1380 [01:43<09:13,  1.01s/it] 60%|██████    | 830/1380 [01:43<07:10,  1.28it/s] 60%|██████    | 831/1380 [01:43<05:33,  1.65it/s] 60%|██████    | 832/1380 [01:43<04:18,  2.12it/s] 60%|██████    | 833/1380 [01:43<03:22,  2.70it/s] 60%|██████    | 834/1380 [01:43<02:41,  3.39it/s] 61%|██████    | 835/1380 [01:43<02:11,  4.14it/s] 61%|██████    | 836/1380 [01:43<01:50,  4.92it/s] 61%|██████    | 837/1380 [01:43<01:35,  5.67it/s] 61%|██████    | 838/1380 [01:44<01:24,  6.39it/s] 61%|██████    | 839/1380 [01:44<01:16,  7.04it/s] 61%|██████    | 840/1380 [01:44<01:11,  7.55it/s] 61%|██████    | 841/1380 [01:44<01:07,  7.94it/s] 61%|██████    | 842/1380 [01:44<01:04,  8.34it/s] 61%|██████    | 843/1380 [01:44<01:02,  8.53it/s] 61%|██████    | 844/1380 [01:44<01:01,  8.72it/s] 61%|██████    | 845/1380 [01:44<01:00,  8.86it/s] 61%|██████▏   | 846/1380 [01:44<00:59,  8.93it/s] 61%|██████▏   | 847/1380 [01:45<00:59,  8.95it/s] 61%|██████▏   | 848/1380 [01:45<00:59,  8.97it/s] 62%|██████▏   | 849/1380 [01:45<00:58,  9.10it/s] 62%|██████▏   | 850/1380 [01:45<00:58,  9.10it/s] 62%|██████▏   | 851/1380 [01:45<00:58,  9.10it/s] 62%|██████▏   | 852/1380 [01:45<00:57,  9.11it/s] 62%|██████▏   | 853/1380 [01:45<00:57,  9.16it/s] 62%|██████▏   | 854/1380 [01:45<00:57,  9.08it/s] 62%|██████▏   | 855/1380 [01:45<00:57,  9.11it/s] 62%|██████▏   | 856/1380 [01:46<00:56,  9.19it/s] 62%|██████▏   | 857/1380 [01:46<00:56,  9.24it/s] 62%|██████▏   | 858/1380 [01:46<00:56,  9.22it/s] 62%|██████▏   | 859/1380 [01:46<00:56,  9.29it/s] 62%|██████▏   | 860/1380 [01:46<00:56,  9.19it/s] 62%|██████▏   | 861/1380 [01:46<00:56,  9.20it/s] 62%|██████▏   | 862/1380 [01:46<00:56,  9.16it/s] 63%|██████▎   | 863/1380 [01:46<00:56,  9.11it/s] 63%|██████▎   | 864/1380 [01:46<00:56,  9.14it/s] 63%|██████▎   | 865/1380 [01:47<00:56,  9.19it/s] 63%|██████▎   | 866/1380 [01:47<00:55,  9.25it/s] 63%|██████▎   | 867/1380 [01:47<00:55,  9.17it/s] 63%|██████▎   | 868/1380 [01:47<00:55,  9.17it/s] 63%|██████▎   | 869/1380 [01:47<00:55,  9.17it/s] 63%|██████▎   | 870/1380 [01:47<00:55,  9.22it/s] 63%|██████▎   | 871/1380 [01:47<00:55,  9.14it/s] 63%|██████▎   | 872/1380 [01:47<00:55,  9.19it/s] 63%|██████▎   | 873/1380 [01:47<00:55,  9.22it/s] 63%|██████▎   | 874/1380 [01:47<00:54,  9.22it/s] 63%|██████▎   | 875/1380 [01:48<00:54,  9.28it/s] 63%|██████▎   | 876/1380 [01:48<00:53,  9.33it/s] 64%|██████▎   | 877/1380 [01:48<00:54,  9.26it/s] 64%|██████▎   | 878/1380 [01:48<00:54,  9.20it/s] 64%|██████▎   | 879/1380 [01:48<00:54,  9.20it/s] 64%|██████▍   | 880/1380 [01:48<00:54,  9.14it/s] 64%|██████▍   | 881/1380 [01:48<00:54,  9.14it/s] 64%|██████▍   | 882/1380 [01:48<00:54,  9.18it/s] 64%|██████▍   | 883/1380 [01:48<00:53,  9.31it/s] 64%|██████▍   | 884/1380 [01:49<00:53,  9.26it/s] 64%|██████▍   | 885/1380 [01:49<00:53,  9.30it/s] 64%|██████▍   | 886/1380 [01:49<00:53,  9.27it/s] 64%|██████▍   | 887/1380 [01:49<00:53,  9.27it/s] 64%|██████▍   | 888/1380 [01:49<00:53,  9.23it/s] 64%|██████▍   | 889/1380 [01:49<00:53,  9.25it/s] 64%|██████▍   | 890/1380 [01:49<00:52,  9.40it/s] 65%|██████▍   | 891/1380 [01:49<00:52,  9.37it/s] 65%|██████▍   | 892/1380 [01:49<00:52,  9.36it/s] 65%|██████▍   | 893/1380 [01:50<00:52,  9.30it/s] 65%|██████▍   | 894/1380 [01:50<00:52,  9.31it/s] 65%|██████▍   | 895/1380 [01:50<00:52,  9.30it/s] 65%|██████▍   | 896/1380 [01:50<00:52,  9.25it/s] 65%|██████▌   | 897/1380 [01:50<00:52,  9.25it/s] 65%|██████▌   | 898/1380 [01:50<00:52,  9.22it/s] 65%|██████▌   | 899/1380 [01:50<00:52,  9.21it/s] 65%|██████▌   | 900/1380 [01:50<00:51,  9.31it/s] 65%|██████▌   | 901/1380 [01:50<00:51,  9.24it/s] 65%|██████▌   | 902/1380 [01:51<00:51,  9.21it/s] 65%|██████▌   | 903/1380 [01:51<00:51,  9.24it/s] 66%|██████▌   | 904/1380 [01:51<00:51,  9.22it/s] 66%|██████▌   | 905/1380 [01:51<00:51,  9.16it/s] 66%|██████▌   | 906/1380 [01:51<00:51,  9.18it/s] 66%|██████▌   | 907/1380 [01:51<00:50,  9.31it/s] 66%|██████▌   | 908/1380 [01:51<00:50,  9.29it/s] 66%|██████▌   | 909/1380 [01:51<00:50,  9.27it/s] 66%|██████▌   | 910/1380 [01:51<00:50,  9.35it/s] 66%|██████▌   | 911/1380 [01:51<00:50,  9.23it/s] 66%|██████▌   | 912/1380 [01:52<00:50,  9.24it/s] 66%|██████▌   | 913/1380 [01:52<00:50,  9.23it/s] 66%|██████▌   | 914/1380 [01:52<00:50,  9.30it/s] 66%|██████▋   | 915/1380 [01:52<00:49,  9.32it/s] 66%|██████▋   | 916/1380 [01:52<00:49,  9.28it/s] 66%|██████▋   | 917/1380 [01:52<00:49,  9.43it/s] 67%|██████▋   | 918/1380 [01:52<00:49,  9.36it/s] 67%|██████▋   | 919/1380 [01:52<00:49,  9.37it/s] 67%|██████▋   | 920/1380 [01:52<00:49,  9.32it/s] 67%|██████▋   | 921/1380 [01:53<00:49,  9.30it/s] 67%|██████▋   | 922/1380 [01:53<00:49,  9.24it/s] 67%|██████▋   | 923/1380 [01:53<00:48,  9.34it/s] 67%|██████▋   | 924/1380 [01:53<00:48,  9.36it/s] 67%|██████▋   | 925/1380 [01:53<00:48,  9.38it/s] 67%|██████▋   | 926/1380 [01:53<00:48,  9.28it/s] 67%|██████▋   | 927/1380 [01:53<00:48,  9.40it/s] 67%|██████▋   | 928/1380 [01:53<00:48,  9.33it/s] 67%|██████▋   | 929/1380 [01:53<00:48,  9.31it/s] 67%|██████▋   | 930/1380 [01:54<00:48,  9.30it/s] 67%|██████▋   | 931/1380 [01:54<00:48,  9.32it/s] 68%|██████▊   | 932/1380 [01:54<00:48,  9.19it/s] 68%|██████▊   | 933/1380 [01:54<00:48,  9.24it/s] 68%|██████▊   | 934/1380 [01:54<00:48,  9.19it/s] 68%|██████▊   | 935/1380 [01:54<00:47,  9.27it/s] 68%|██████▊   | 936/1380 [01:54<00:48,  9.25it/s] 68%|██████▊   | 937/1380 [01:54<00:47,  9.42it/s] 68%|██████▊   | 938/1380 [01:54<00:47,  9.33it/s] 68%|██████▊   | 939/1380 [01:54<00:47,  9.36it/s] 68%|██████▊   | 940/1380 [01:55<00:47,  9.33it/s] 68%|██████▊   | 941/1380 [01:55<00:47,  9.30it/s] 68%|██████▊   | 942/1380 [01:55<00:47,  9.19it/s] 68%|██████▊   | 943/1380 [01:55<00:47,  9.20it/s] 68%|██████▊   | 944/1380 [01:55<00:46,  9.29it/s] 68%|██████▊   | 945/1380 [01:55<00:46,  9.29it/s] 69%|██████▊   | 946/1380 [01:55<00:47,  9.22it/s] 69%|██████▊   | 947/1380 [01:55<00:46,  9.33it/s] 69%|██████▊   | 948/1380 [01:55<00:46,  9.22it/s] 69%|██████▉   | 949/1380 [01:56<00:46,  9.26it/s] 69%|██████▉   | 950/1380 [01:56<00:46,  9.19it/s] 69%|██████▉   | 951/1380 [01:56<00:46,  9.24it/s] 69%|██████▉   | 952/1380 [01:56<00:46,  9.22it/s] 69%|██████▉   | 953/1380 [01:56<00:46,  9.21it/s] 69%|██████▉   | 954/1380 [01:56<00:45,  9.33it/s] 69%|██████▉   | 955/1380 [01:56<00:45,  9.31it/s] 69%|██████▉   | 956/1380 [01:56<00:45,  9.35it/s] 69%|██████▉   | 957/1380 [01:56<00:45,  9.34it/s] 69%|██████▉   | 958/1380 [01:57<00:45,  9.30it/s] 69%|██████▉   | 959/1380 [01:57<00:45,  9.26it/s] 70%|██████▉   | 960/1380 [01:57<00:45,  9.24it/s] 70%|██████▉   | 961/1380 [01:57<00:45,  9.19it/s] 70%|██████▉   | 962/1380 [01:57<00:45,  9.27it/s] 70%|██████▉   | 963/1380 [01:57<00:45,  9.20it/s] 70%|██████▉   | 964/1380 [01:57<00:44,  9.33it/s] 70%|██████▉   | 965/1380 [01:57<00:44,  9.33it/s] 70%|███████   | 966/1380 [01:57<00:44,  9.35it/s] 70%|███████   | 967/1380 [01:58<00:44,  9.33it/s] 70%|███████   | 968/1380 [01:58<00:44,  9.35it/s] 70%|███████   | 969/1380 [01:58<00:44,  9.31it/s] 70%|███████   | 970/1380 [01:58<00:43,  9.35it/s] 70%|███████   | 971/1380 [01:58<00:43,  9.37it/s] 70%|███████   | 972/1380 [01:58<00:43,  9.39it/s] 71%|███████   | 973/1380 [01:58<00:43,  9.33it/s] 71%|███████   | 974/1380 [01:58<00:43,  9.41it/s] 71%|███████   | 975/1380 [01:58<00:43,  9.29it/s] 71%|███████   | 976/1380 [01:58<00:43,  9.32it/s] 71%|███████   | 977/1380 [01:59<00:43,  9.32it/s] 71%|███████   | 978/1380 [01:59<00:43,  9.33it/s] 71%|███████   | 979/1380 [01:59<00:42,  9.35it/s] 71%|███████   | 980/1380 [01:59<00:43,  9.29it/s] 71%|███████   | 981/1380 [01:59<00:42,  9.36it/s] 71%|███████   | 982/1380 [01:59<00:42,  9.41it/s] 71%|███████   | 983/1380 [01:59<00:42,  9.41it/s] 71%|███████▏  | 984/1380 [01:59<00:42,  9.39it/s] 71%|███████▏  | 985/1380 [01:59<00:42,  9.36it/s] 71%|███████▏  | 986/1380 [02:00<00:42,  9.33it/s] 72%|███████▏  | 987/1380 [02:00<00:42,  9.32it/s] 72%|███████▏  | 988/1380 [02:00<00:41,  9.36it/s] 72%|███████▏  | 989/1380 [02:00<00:41,  9.35it/s] 72%|███████▏  | 990/1380 [02:00<00:41,  9.37it/s] 72%|███████▏  | 991/1380 [02:00<00:41,  9.40it/s] 72%|███████▏  | 992/1380 [02:00<00:41,  9.34it/s] 72%|███████▏  | 993/1380 [02:00<00:41,  9.29it/s] 72%|███████▏  | 994/1380 [02:00<00:41,  9.31it/s] 72%|███████▏  | 995/1380 [02:00<00:41,  9.32it/s] 72%|███████▏  | 996/1380 [02:01<00:41,  9.34it/s] 72%|███████▏  | 997/1380 [02:01<00:41,  9.29it/s] 72%|███████▏  | 998/1380 [02:01<00:40,  9.37it/s] 72%|███████▏  | 999/1380 [02:01<00:40,  9.34it/s] 72%|███████▏  | 1000/1380 [02:01<00:40,  9.41it/s] 73%|███████▎  | 1001/1380 [02:01<00:40,  9.35it/s] 73%|███████▎  | 1002/1380 [02:01<00:40,  9.34it/s] 73%|███████▎  | 1003/1380 [02:01<00:40,  9.30it/s] 73%|███████▎  | 1004/1380 [02:01<00:40,  9.28it/s] 73%|███████▎  | 1005/1380 [02:02<00:40,  9.23it/s] 73%|███████▎  | 1006/1380 [02:02<00:40,  9.30it/s] 73%|███████▎  | 1007/1380 [02:02<00:40,  9.24it/s] 73%|███████▎  | 1008/1380 [02:02<00:39,  9.31it/s] 73%|███████▎  | 1009/1380 [02:02<00:39,  9.30it/s] 73%|███████▎  | 1010/1380 [02:02<00:39,  9.29it/s] 73%|███████▎  | 1011/1380 [02:02<00:39,  9.30it/s] 73%|███████▎  | 1012/1380 [02:02<00:39,  9.27it/s] 73%|███████▎  | 1013/1380 [02:02<00:39,  9.23it/s] 73%|███████▎  | 1014/1380 [02:03<00:39,  9.23it/s] 74%|███████▎  | 1015/1380 [02:03<00:39,  9.24it/s] 74%|███████▎  | 1016/1380 [02:03<00:39,  9.24it/s] 74%|███████▎  | 1017/1380 [02:03<00:39,  9.22it/s] 74%|███████▍  | 1018/1380 [02:03<00:39,  9.27it/s] 74%|███████▍  | 1019/1380 [02:03<00:38,  9.30it/s] 74%|███████▍  | 1020/1380 [02:03<00:38,  9.33it/s] 74%|███████▍  | 1021/1380 [02:03<00:38,  9.32it/s] 74%|███████▍  | 1022/1380 [02:03<00:38,  9.35it/s] 74%|███████▍  | 1023/1380 [02:04<00:38,  9.27it/s] 74%|███████▍  | 1024/1380 [02:04<00:38,  9.28it/s] 74%|███████▍  | 1025/1380 [02:04<00:38,  9.28it/s] 74%|███████▍  | 1026/1380 [02:04<00:38,  9.29it/s] 74%|███████▍  | 1027/1380 [02:04<00:38,  9.26it/s] 74%|███████▍  | 1028/1380 [02:04<00:37,  9.29it/s] 75%|███████▍  | 1029/1380 [02:04<00:37,  9.31it/s] 75%|███████▍  | 1030/1380 [02:04<00:37,  9.33it/s] 75%|███████▍  | 1031/1380 [02:04<00:37,  9.30it/s] 75%|███████▍  | 1032/1380 [02:04<00:37,  9.33it/s] 75%|███████▍  | 1033/1380 [02:05<00:37,  9.27it/s] 75%|███████▍  | 1034/1380 [02:05<00:37,  9.25it/s] 75%|███████▌  | 1035/1380 [02:05<00:37,  9.32it/s] 75%|███████▌  | 1036/1380 [02:05<00:36,  9.30it/s] 75%|███████▌  | 1037/1380 [02:05<00:37,  9.25it/s] 75%|███████▌  | 1038/1380 [02:05<00:36,  9.35it/s] 75%|███████▌  | 1039/1380 [02:05<00:36,  9.26it/s] 75%|███████▌  | 1040/1380 [02:05<00:36,  9.26it/s] 75%|███████▌  | 1041/1380 [02:05<00:36,  9.33it/s] 76%|███████▌  | 1042/1380 [02:06<00:36,  9.34it/s] 76%|███████▌  | 1043/1380 [02:06<00:36,  9.32it/s] 76%|███████▌  | 1044/1380 [02:06<00:36,  9.26it/s] 76%|███████▌  | 1045/1380 [02:06<00:36,  9.29it/s] 76%|███████▌  | 1046/1380 [02:06<00:36,  9.28it/s] 76%|███████▌  | 1047/1380 [02:06<00:35,  9.32it/s] 76%|███████▌  | 1048/1380 [02:06<00:35,  9.33it/s] 76%|███████▌  | 1049/1380 [02:06<00:35,  9.28it/s] 76%|███████▌  | 1050/1380 [02:06<00:35,  9.26it/s] 76%|███████▌  | 1051/1380 [02:07<00:35,  9.27it/s] 76%|███████▌  | 1052/1380 [02:07<00:35,  9.26it/s] 76%|███████▋  | 1053/1380 [02:07<00:34,  9.35it/s] 76%|███████▋  | 1054/1380 [02:07<00:35,  9.30it/s] 76%|███████▋  | 1055/1380 [02:07<00:34,  9.40it/s] 77%|███████▋  | 1056/1380 [02:07<00:34,  9.31it/s] 77%|███████▋  | 1057/1380 [02:07<00:34,  9.28it/s] 77%|███████▋  | 1058/1380 [02:07<00:34,  9.34it/s] 77%|███████▋  | 1059/1380 [02:07<00:34,  9.32it/s] 77%|███████▋  | 1060/1380 [02:07<00:34,  9.24it/s] 77%|███████▋  | 1061/1380 [02:08<00:34,  9.18it/s] 77%|███████▋  | 1062/1380 [02:08<00:34,  9.22it/s] 77%|███████▋  | 1063/1380 [02:08<00:34,  9.28it/s] 77%|███████▋  | 1064/1380 [02:08<00:34,  9.25it/s] 77%|███████▋  | 1065/1380 [02:08<00:34,  9.21it/s] 77%|███████▋  | 1066/1380 [02:08<00:34,  9.18it/s] 77%|███████▋  | 1067/1380 [02:08<00:34,  9.14it/s] 77%|███████▋  | 1068/1380 [02:08<00:34,  9.15it/s] 77%|███████▋  | 1069/1380 [02:08<00:33,  9.17it/s] 78%|███████▊  | 1070/1380 [02:09<00:33,  9.24it/s] 78%|███████▊  | 1071/1380 [02:09<00:33,  9.30it/s] 78%|███████▊  | 1072/1380 [02:09<00:32,  9.39it/s] 78%|███████▊  | 1073/1380 [02:09<00:33,  9.30it/s] 78%|███████▊  | 1074/1380 [02:09<00:32,  9.28it/s] 78%|███████▊  | 1075/1380 [02:09<00:32,  9.33it/s] 78%|███████▊  | 1076/1380 [02:09<00:32,  9.33it/s] 78%|███████▊  | 1077/1380 [02:09<00:32,  9.27it/s] 78%|███████▊  | 1078/1380 [02:09<00:32,  9.22it/s] 78%|███████▊  | 1079/1380 [02:10<00:32,  9.31it/s] 78%|███████▊  | 1080/1380 [02:10<00:32,  9.28it/s] 78%|███████▊  | 1081/1380 [02:10<00:32,  9.28it/s] 78%|███████▊  | 1082/1380 [02:10<00:32,  9.29it/s] 78%|███████▊  | 1083/1380 [02:10<00:32,  9.28it/s] 79%|███████▊  | 1084/1380 [02:10<00:32,  9.20it/s] 79%|███████▊  | 1085/1380 [02:10<00:32,  9.18it/s] 79%|███████▊  | 1086/1380 [02:10<00:31,  9.21it/s] 79%|███████▉  | 1087/1380 [02:10<00:31,  9.26it/s] 79%|███████▉  | 1088/1380 [02:11<00:31,  9.26it/s] 79%|███████▉  | 1089/1380 [02:11<00:31,  9.30it/s] 79%|███████▉  | 1090/1380 [02:11<00:31,  9.18it/s] 79%|███████▉  | 1091/1380 [02:11<00:31,  9.15it/s] 79%|███████▉  | 1092/1380 [02:11<00:31,  9.22it/s] 79%|███████▉  | 1093/1380 [02:11<00:31,  9.21it/s] 79%|███████▉  | 1094/1380 [02:11<00:30,  9.25it/s] 79%|███████▉  | 1095/1380 [02:11<00:30,  9.20it/s] 79%|███████▉  | 1096/1380 [02:11<00:30,  9.23it/s] 79%|███████▉  | 1097/1380 [02:11<00:30,  9.27it/s] 80%|███████▉  | 1098/1380 [02:12<00:30,  9.26it/s] 80%|███████▉  | 1099/1380 [02:12<00:30,  9.28it/s] 80%|███████▉  | 1100/1380 [02:12<00:30,  9.18it/s] 80%|███████▉  | 1101/1380 [02:12<00:30,  9.09it/s] 80%|███████▉  | 1102/1380 [02:12<00:30,  9.18it/s] 80%|███████▉  | 1103/1380 [02:12<00:30,  9.21it/s]                                                    80%|████████  | 1104/1380 [02:12<00:29,  9.21it/s][INFO|trainer.py:755] 2023-11-15 20:09:31,935 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:09:31,937 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:09:31,937 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:09:31,937 >>   Batch size = 8
{'eval_loss': 0.42553162574768066, 'eval_accuracy': 0.8643375680580763, 'eval_micro_f1': 0.8643375680580763, 'eval_macro_f1': 0.8493931441516377, 'eval_runtime': 3.9047, 'eval_samples_per_second': 564.453, 'eval_steps_per_second': 70.685, 'epoch': 3.0}
{'loss': 0.1303, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 82.41it/s][A
  7%|▋         | 18/276 [00:00<00:03, 82.44it/s][A
 10%|▉         | 27/276 [00:00<00:03, 77.84it/s][A
 13%|█▎        | 35/276 [00:00<00:03, 76.30it/s][A
 16%|█▌        | 43/276 [00:00<00:03, 75.46it/s][A
 18%|█▊        | 51/276 [00:00<00:02, 75.89it/s][A
 21%|██▏       | 59/276 [00:00<00:02, 73.88it/s][A
 24%|██▍       | 67/276 [00:00<00:02, 74.10it/s][A
 27%|██▋       | 75/276 [00:00<00:02, 75.18it/s][A
 30%|███       | 83/276 [00:01<00:02, 75.74it/s][A
 33%|███▎      | 91/276 [00:01<00:02, 74.78it/s][A
 36%|███▌      | 100/276 [00:01<00:02, 76.45it/s][A
 39%|███▉      | 108/276 [00:01<00:02, 74.88it/s][A
 42%|████▏     | 116/276 [00:01<00:02, 75.35it/s][A
 45%|████▍     | 124/276 [00:01<00:02, 75.23it/s][A
 48%|████▊     | 132/276 [00:01<00:01, 76.02it/s][A
 51%|█████     | 140/276 [00:01<00:01, 75.15it/s][A
 54%|█████▎    | 148/276 [00:01<00:01, 74.62it/s][A
 57%|█████▋    | 156/276 [00:02<00:01, 75.20it/s][A
 59%|█████▉    | 164/276 [00:02<00:01, 75.70it/s][A
 62%|██████▏   | 172/276 [00:02<00:01, 74.53it/s][A
 65%|██████▌   | 180/276 [00:02<00:01, 75.53it/s][A
 68%|██████▊   | 188/276 [00:02<00:01, 75.38it/s][A
 71%|███████   | 196/276 [00:02<00:01, 75.28it/s][A
 74%|███████▍  | 204/276 [00:02<00:00, 75.81it/s][A
 77%|███████▋  | 212/276 [00:02<00:00, 73.72it/s][A
 80%|███████▉  | 220/276 [00:02<00:00, 74.01it/s][A
 83%|████████▎ | 228/276 [00:03<00:00, 73.69it/s][A
 86%|████████▌ | 236/276 [00:03<00:00, 74.90it/s][A
 88%|████████▊ | 244/276 [00:03<00:00, 72.82it/s][A
 91%|█████████▏| 252/276 [00:03<00:00, 73.43it/s][A
 94%|█████████▍| 260/276 [00:03<00:00, 74.23it/s][A
 97%|█████████▋| 268/276 [00:03<00:00, 74.19it/s][A
100%|██████████| 276/276 [00:03<00:00, 74.95it/s][A                                                   
                                                 [A 80%|████████  | 1104/1380 [02:16<00:29,  9.21it/s]
100%|██████████| 276/276 [00:03<00:00, 74.95it/s][A
                                                 [A 80%|████████  | 1105/1380 [02:16<04:25,  1.04it/s] 80%|████████  | 1106/1380 [02:16<03:26,  1.33it/s] 80%|████████  | 1107/1380 [02:16<02:39,  1.71it/s] 80%|████████  | 1108/1380 [02:16<02:03,  2.20it/s] 80%|████████  | 1109/1380 [02:17<01:36,  2.80it/s] 80%|████████  | 1110/1380 [02:17<01:17,  3.48it/s] 81%|████████  | 1111/1380 [02:17<01:02,  4.27it/s] 81%|████████  | 1112/1380 [02:17<00:52,  5.07it/s] 81%|████████  | 1113/1380 [02:17<00:45,  5.84it/s] 81%|████████  | 1114/1380 [02:17<00:40,  6.59it/s] 81%|████████  | 1115/1380 [02:17<00:36,  7.20it/s] 81%|████████  | 1116/1380 [02:17<00:34,  7.71it/s] 81%|████████  | 1117/1380 [02:17<00:32,  8.09it/s] 81%|████████  | 1118/1380 [02:17<00:31,  8.41it/s] 81%|████████  | 1119/1380 [02:18<00:30,  8.60it/s] 81%|████████  | 1120/1380 [02:18<00:29,  8.78it/s] 81%|████████  | 1121/1380 [02:18<00:29,  8.88it/s] 81%|████████▏ | 1122/1380 [02:18<00:28,  9.03it/s] 81%|████████▏ | 1123/1380 [02:18<00:28,  8.98it/s] 81%|████████▏ | 1124/1380 [02:18<00:28,  9.12it/s] 82%|████████▏ | 1125/1380 [02:18<00:27,  9.21it/s] 82%|████████▏ | 1126/1380 [02:18<00:27,  9.28it/s] 82%|████████▏ | 1127/1380 [02:18<00:26,  9.40it/s] 82%|████████▏ | 1128/1380 [02:19<00:27,  9.33it/s] 82%|████████▏ | 1129/1380 [02:19<00:26,  9.34it/s] 82%|████████▏ | 1130/1380 [02:19<00:26,  9.35it/s] 82%|████████▏ | 1131/1380 [02:19<00:26,  9.33it/s] 82%|████████▏ | 1132/1380 [02:19<00:26,  9.28it/s] 82%|████████▏ | 1133/1380 [02:19<00:26,  9.28it/s] 82%|████████▏ | 1134/1380 [02:19<00:26,  9.30it/s] 82%|████████▏ | 1135/1380 [02:19<00:26,  9.22it/s] 82%|████████▏ | 1136/1380 [02:19<00:26,  9.23it/s] 82%|████████▏ | 1137/1380 [02:20<00:26,  9.27it/s] 82%|████████▏ | 1138/1380 [02:20<00:26,  9.29it/s] 83%|████████▎ | 1139/1380 [02:20<00:25,  9.28it/s] 83%|████████▎ | 1140/1380 [02:20<00:25,  9.38it/s] 83%|████████▎ | 1141/1380 [02:20<00:25,  9.32it/s] 83%|████████▎ | 1142/1380 [02:20<00:25,  9.33it/s] 83%|████████▎ | 1143/1380 [02:20<00:25,  9.25it/s] 83%|████████▎ | 1144/1380 [02:20<00:25,  9.27it/s] 83%|████████▎ | 1145/1380 [02:20<00:25,  9.16it/s] 83%|████████▎ | 1146/1380 [02:20<00:25,  9.22it/s] 83%|████████▎ | 1147/1380 [02:21<00:25,  9.23it/s] 83%|████████▎ | 1148/1380 [02:21<00:25,  9.20it/s] 83%|████████▎ | 1149/1380 [02:21<00:25,  9.23it/s] 83%|████████▎ | 1150/1380 [02:21<00:24,  9.26it/s] 83%|████████▎ | 1151/1380 [02:21<00:24,  9.16it/s] 83%|████████▎ | 1152/1380 [02:21<00:24,  9.17it/s] 84%|████████▎ | 1153/1380 [02:21<00:24,  9.20it/s] 84%|████████▎ | 1154/1380 [02:21<00:24,  9.14it/s] 84%|████████▎ | 1155/1380 [02:21<00:24,  9.21it/s] 84%|████████▍ | 1156/1380 [02:22<00:24,  9.25it/s] 84%|████████▍ | 1157/1380 [02:22<00:23,  9.38it/s] 84%|████████▍ | 1158/1380 [02:22<00:23,  9.27it/s] 84%|████████▍ | 1159/1380 [02:22<00:23,  9.23it/s] 84%|████████▍ | 1160/1380 [02:22<00:23,  9.27it/s] 84%|████████▍ | 1161/1380 [02:22<00:23,  9.20it/s] 84%|████████▍ | 1162/1380 [02:22<00:23,  9.20it/s] 84%|████████▍ | 1163/1380 [02:22<00:23,  9.10it/s] 84%|████████▍ | 1164/1380 [02:22<00:23,  9.20it/s] 84%|████████▍ | 1165/1380 [02:23<00:23,  9.22it/s] 84%|████████▍ | 1166/1380 [02:23<00:23,  9.23it/s] 85%|████████▍ | 1167/1380 [02:23<00:23,  9.22it/s] 85%|████████▍ | 1168/1380 [02:23<00:23,  9.20it/s] 85%|████████▍ | 1169/1380 [02:23<00:22,  9.21it/s] 85%|████████▍ | 1170/1380 [02:23<00:22,  9.17it/s] 85%|████████▍ | 1171/1380 [02:23<00:22,  9.20it/s] 85%|████████▍ | 1172/1380 [02:23<00:22,  9.20it/s] 85%|████████▌ | 1173/1380 [02:23<00:22,  9.25it/s] 85%|████████▌ | 1174/1380 [02:24<00:22,  9.29it/s] 85%|████████▌ | 1175/1380 [02:24<00:22,  9.20it/s] 85%|████████▌ | 1176/1380 [02:24<00:22,  9.22it/s] 85%|████████▌ | 1177/1380 [02:24<00:22,  9.20it/s] 85%|████████▌ | 1178/1380 [02:24<00:21,  9.20it/s] 85%|████████▌ | 1179/1380 [02:24<00:21,  9.16it/s] 86%|████████▌ | 1180/1380 [02:24<00:21,  9.22it/s] 86%|████████▌ | 1181/1380 [02:24<00:21,  9.28it/s] 86%|████████▌ | 1182/1380 [02:24<00:21,  9.19it/s] 86%|████████▌ | 1183/1380 [02:25<00:21,  9.17it/s] 86%|████████▌ | 1184/1380 [02:25<00:21,  9.20it/s] 86%|████████▌ | 1185/1380 [02:25<00:21,  9.23it/s] 86%|████████▌ | 1186/1380 [02:25<00:20,  9.24it/s] 86%|████████▌ | 1187/1380 [02:25<00:21,  9.14it/s] 86%|████████▌ | 1188/1380 [02:25<00:20,  9.19it/s] 86%|████████▌ | 1189/1380 [02:25<00:20,  9.23it/s] 86%|████████▌ | 1190/1380 [02:25<00:20,  9.21it/s] 86%|████████▋ | 1191/1380 [02:25<00:20,  9.18it/s] 86%|████████▋ | 1192/1380 [02:25<00:20,  9.23it/s] 86%|████████▋ | 1193/1380 [02:26<00:20,  9.17it/s] 87%|████████▋ | 1194/1380 [02:26<00:20,  9.18it/s] 87%|████████▋ | 1195/1380 [02:26<00:20,  9.23it/s] 87%|████████▋ | 1196/1380 [02:26<00:19,  9.22it/s] 87%|████████▋ | 1197/1380 [02:26<00:19,  9.26it/s] 87%|████████▋ | 1198/1380 [02:26<00:19,  9.26it/s] 87%|████████▋ | 1199/1380 [02:26<00:19,  9.19it/s] 87%|████████▋ | 1200/1380 [02:26<00:19,  9.13it/s] 87%|████████▋ | 1201/1380 [02:26<00:19,  9.14it/s] 87%|████████▋ | 1202/1380 [02:27<00:19,  9.14it/s] 87%|████████▋ | 1203/1380 [02:27<00:19,  9.20it/s] 87%|████████▋ | 1204/1380 [02:27<00:19,  9.23it/s] 87%|████████▋ | 1205/1380 [02:27<00:18,  9.30it/s] 87%|████████▋ | 1206/1380 [02:27<00:18,  9.27it/s] 87%|████████▋ | 1207/1380 [02:27<00:18,  9.20it/s] 88%|████████▊ | 1208/1380 [02:27<00:18,  9.18it/s] 88%|████████▊ | 1209/1380 [02:27<00:18,  9.16it/s] 88%|████████▊ | 1210/1380 [02:27<00:18,  9.20it/s] 88%|████████▊ | 1211/1380 [02:28<00:18,  9.21it/s] 88%|████████▊ | 1212/1380 [02:28<00:18,  9.30it/s] 88%|████████▊ | 1213/1380 [02:28<00:18,  9.16it/s] 88%|████████▊ | 1214/1380 [02:28<00:18,  9.20it/s] 88%|████████▊ | 1215/1380 [02:28<00:17,  9.19it/s] 88%|████████▊ | 1216/1380 [02:28<00:17,  9.16it/s] 88%|████████▊ | 1217/1380 [02:28<00:17,  9.14it/s] 88%|████████▊ | 1218/1380 [02:28<00:17,  9.12it/s] 88%|████████▊ | 1219/1380 [02:28<00:17,  9.13it/s] 88%|████████▊ | 1220/1380 [02:29<00:17,  9.15it/s] 88%|████████▊ | 1221/1380 [02:29<00:17,  9.19it/s] 89%|████████▊ | 1222/1380 [02:29<00:17,  9.22it/s] 89%|████████▊ | 1223/1380 [02:29<00:17,  9.20it/s] 89%|████████▊ | 1224/1380 [02:29<00:16,  9.18it/s] 89%|████████▉ | 1225/1380 [02:29<00:17,  9.10it/s] 89%|████████▉ | 1226/1380 [02:29<00:16,  9.12it/s] 89%|████████▉ | 1227/1380 [02:29<00:16,  9.15it/s] 89%|████████▉ | 1228/1380 [02:29<00:16,  9.23it/s] 89%|████████▉ | 1229/1380 [02:30<00:16,  9.17it/s] 89%|████████▉ | 1230/1380 [02:30<00:16,  9.22it/s] 89%|████████▉ | 1231/1380 [02:30<00:16,  9.10it/s] 89%|████████▉ | 1232/1380 [02:30<00:16,  9.12it/s] 89%|████████▉ | 1233/1380 [02:30<00:16,  9.19it/s] 89%|████████▉ | 1234/1380 [02:30<00:15,  9.16it/s] 89%|████████▉ | 1235/1380 [02:30<00:15,  9.19it/s] 90%|████████▉ | 1236/1380 [02:30<00:15,  9.15it/s] 90%|████████▉ | 1237/1380 [02:30<00:15,  9.15it/s] 90%|████████▉ | 1238/1380 [02:31<00:15,  9.12it/s] 90%|████████▉ | 1239/1380 [02:31<00:15,  9.02it/s] 90%|████████▉ | 1240/1380 [02:31<00:15,  9.14it/s] 90%|████████▉ | 1241/1380 [02:31<00:15,  9.16it/s] 90%|█████████ | 1242/1380 [02:31<00:15,  9.20it/s] 90%|█████████ | 1243/1380 [02:31<00:14,  9.19it/s] 90%|█████████ | 1244/1380 [02:31<00:15,  8.93it/s] 90%|█████████ | 1245/1380 [02:31<00:15,  8.96it/s] 90%|█████████ | 1246/1380 [02:31<00:14,  8.98it/s] 90%|█████████ | 1247/1380 [02:32<00:14,  9.04it/s] 90%|█████████ | 1248/1380 [02:32<00:14,  9.11it/s] 91%|█████████ | 1249/1380 [02:32<00:14,  9.06it/s] 91%|█████████ | 1250/1380 [02:32<00:14,  9.24it/s] 91%|█████████ | 1251/1380 [02:32<00:14,  9.14it/s] 91%|█████████ | 1252/1380 [02:32<00:14,  9.11it/s] 91%|█████████ | 1253/1380 [02:32<00:13,  9.14it/s] 91%|█████████ | 1254/1380 [02:32<00:13,  9.10it/s] 91%|█████████ | 1255/1380 [02:32<00:13,  9.13it/s] 91%|█████████ | 1256/1380 [02:32<00:13,  9.11it/s] 91%|█████████ | 1257/1380 [02:33<00:13,  9.21it/s] 91%|█████████ | 1258/1380 [02:33<00:13,  9.15it/s] 91%|█████████ | 1259/1380 [02:33<00:13,  9.12it/s] 91%|█████████▏| 1260/1380 [02:33<00:13,  9.19it/s] 91%|█████████▏| 1261/1380 [02:33<00:12,  9.16it/s] 91%|█████████▏| 1262/1380 [02:33<00:12,  9.10it/s] 92%|█████████▏| 1263/1380 [02:33<00:12,  9.06it/s] 92%|█████████▏| 1264/1380 [02:33<00:12,  9.12it/s] 92%|█████████▏| 1265/1380 [02:33<00:12,  9.09it/s] 92%|█████████▏| 1266/1380 [02:34<00:12,  9.06it/s] 92%|█████████▏| 1267/1380 [02:34<00:12,  9.10it/s] 92%|█████████▏| 1268/1380 [02:34<00:12,  9.12it/s] 92%|█████████▏| 1269/1380 [02:34<00:12,  9.08it/s] 92%|█████████▏| 1270/1380 [02:34<00:12,  8.98it/s] 92%|█████████▏| 1271/1380 [02:34<00:12,  9.07it/s] 92%|█████████▏| 1272/1380 [02:34<00:11,  9.11it/s] 92%|█████████▏| 1273/1380 [02:34<00:11,  9.13it/s] 92%|█████████▏| 1274/1380 [02:34<00:11,  9.10it/s] 92%|█████████▏| 1275/1380 [02:35<00:11,  9.05it/s] 92%|█████████▏| 1276/1380 [02:35<00:11,  9.00it/s] 93%|█████████▎| 1277/1380 [02:35<00:11,  9.01it/s] 93%|█████████▎| 1278/1380 [02:35<00:11,  9.09it/s] 93%|█████████▎| 1279/1380 [02:35<00:11,  9.07it/s] 93%|█████████▎| 1280/1380 [02:35<00:11,  9.08it/s] 93%|█████████▎| 1281/1380 [02:35<00:10,  9.15it/s] 93%|█████████▎| 1282/1380 [02:35<00:10,  9.12it/s] 93%|█████████▎| 1283/1380 [02:35<00:10,  9.06it/s] 93%|█████████▎| 1284/1380 [02:36<00:10,  9.01it/s] 93%|█████████▎| 1285/1380 [02:36<00:10,  9.03it/s] 93%|█████████▎| 1286/1380 [02:36<00:10,  9.06it/s] 93%|█████████▎| 1287/1380 [02:36<00:10,  9.13it/s] 93%|█████████▎| 1288/1380 [02:36<00:10,  9.16it/s] 93%|█████████▎| 1289/1380 [02:36<00:10,  9.07it/s] 93%|█████████▎| 1290/1380 [02:36<00:09,  9.02it/s] 94%|█████████▎| 1291/1380 [02:36<00:09,  9.05it/s] 94%|█████████▎| 1292/1380 [02:36<00:09,  9.11it/s] 94%|█████████▎| 1293/1380 [02:37<00:09,  9.11it/s] 94%|█████████▍| 1294/1380 [02:37<00:09,  9.10it/s] 94%|█████████▍| 1295/1380 [02:37<00:09,  9.15it/s] 94%|█████████▍| 1296/1380 [02:37<00:09,  9.07it/s] 94%|█████████▍| 1297/1380 [02:37<00:09,  9.03it/s] 94%|█████████▍| 1298/1380 [02:37<00:09,  9.03it/s] 94%|█████████▍| 1299/1380 [02:37<00:08,  9.05it/s] 94%|█████████▍| 1300/1380 [02:37<00:08,  9.11it/s] 94%|█████████▍| 1301/1380 [02:37<00:08,  9.06it/s] 94%|█████████▍| 1302/1380 [02:38<00:08,  9.12it/s] 94%|█████████▍| 1303/1380 [02:38<00:08,  8.99it/s] 94%|█████████▍| 1304/1380 [02:38<00:08,  9.05it/s] 95%|█████████▍| 1305/1380 [02:38<00:08,  9.07it/s] 95%|█████████▍| 1306/1380 [02:38<00:08,  9.03it/s] 95%|█████████▍| 1307/1380 [02:38<00:08,  9.02it/s] 95%|█████████▍| 1308/1380 [02:38<00:07,  9.04it/s] 95%|█████████▍| 1309/1380 [02:38<00:07,  9.16it/s] 95%|█████████▍| 1310/1380 [02:38<00:07,  9.00it/s] 95%|█████████▌| 1311/1380 [02:39<00:07,  8.94it/s] 95%|█████████▌| 1312/1380 [02:39<00:07,  8.91it/s] 95%|█████████▌| 1313/1380 [02:39<00:07,  8.84it/s] 95%|█████████▌| 1314/1380 [02:39<00:07,  8.85it/s] 95%|█████████▌| 1315/1380 [02:39<00:07,  8.90it/s] 95%|█████████▌| 1316/1380 [02:39<00:07,  9.00it/s] 95%|█████████▌| 1317/1380 [02:39<00:07,  8.93it/s] 96%|█████████▌| 1318/1380 [02:39<00:06,  8.89it/s] 96%|█████████▌| 1319/1380 [02:39<00:06,  8.87it/s] 96%|█████████▌| 1320/1380 [02:40<00:06,  8.92it/s] 96%|█████████▌| 1321/1380 [02:40<00:06,  8.99it/s] 96%|█████████▌| 1322/1380 [02:40<00:06,  9.00it/s] 96%|█████████▌| 1323/1380 [02:40<00:06,  9.16it/s] 96%|█████████▌| 1324/1380 [02:40<00:06,  9.09it/s] 96%|█████████▌| 1325/1380 [02:40<00:06,  9.05it/s] 96%|█████████▌| 1326/1380 [02:40<00:05,  9.05it/s] 96%|█████████▌| 1327/1380 [02:40<00:05,  9.10it/s] 96%|█████████▌| 1328/1380 [02:40<00:05,  9.17it/s] 96%|█████████▋| 1329/1380 [02:41<00:05,  9.09it/s] 96%|█████████▋| 1330/1380 [02:41<00:05,  9.21it/s] 96%|█████████▋| 1331/1380 [02:41<00:05,  9.11it/s] 97%|█████████▋| 1332/1380 [02:41<00:05,  9.10it/s] 97%|█████████▋| 1333/1380 [02:41<00:05,  9.10it/s] 97%|█████████▋| 1334/1380 [02:41<00:05,  9.09it/s] 97%|█████████▋| 1335/1380 [02:41<00:04,  9.08it/s] 97%|█████████▋| 1336/1380 [02:41<00:04,  9.12it/s] 97%|█████████▋| 1337/1380 [02:41<00:04,  9.23it/s] 97%|█████████▋| 1338/1380 [02:42<00:04,  9.15it/s] 97%|█████████▋| 1339/1380 [02:42<00:04,  9.09it/s] 97%|█████████▋| 1340/1380 [02:42<00:04,  9.10it/s] 97%|█████████▋| 1341/1380 [02:42<00:04,  9.07it/s] 97%|█████████▋| 1342/1380 [02:42<00:04,  9.06it/s] 97%|█████████▋| 1343/1380 [02:42<00:04,  9.03it/s] 97%|█████████▋| 1344/1380 [02:42<00:03,  9.09it/s] 97%|█████████▋| 1345/1380 [02:42<00:03,  9.13it/s] 98%|█████████▊| 1346/1380 [02:42<00:03,  9.16it/s] 98%|█████████▊| 1347/1380 [02:43<00:03,  9.14it/s] 98%|█████████▊| 1348/1380 [02:43<00:03,  9.14it/s] 98%|█████████▊| 1349/1380 [02:43<00:03,  9.13it/s] 98%|█████████▊| 1350/1380 [02:43<00:03,  9.14it/s] 98%|█████████▊| 1351/1380 [02:43<00:03,  9.22it/s] 98%|█████████▊| 1352/1380 [02:43<00:03,  9.16it/s] 98%|█████████▊| 1353/1380 [02:43<00:02,  9.20it/s] 98%|█████████▊| 1354/1380 [02:43<00:02,  9.13it/s] 98%|█████████▊| 1355/1380 [02:43<00:02,  9.18it/s] 98%|█████████▊| 1356/1380 [02:44<00:02,  9.12it/s] 98%|█████████▊| 1357/1380 [02:44<00:02,  9.15it/s] 98%|█████████▊| 1358/1380 [02:44<00:02,  9.22it/s] 98%|█████████▊| 1359/1380 [02:44<00:02,  9.23it/s] 99%|█████████▊| 1360/1380 [02:44<00:02,  9.19it/s] 99%|█████████▊| 1361/1380 [02:44<00:02,  9.22it/s] 99%|█████████▊| 1362/1380 [02:44<00:01,  9.22it/s] 99%|█████████▉| 1363/1380 [02:44<00:01,  9.14it/s] 99%|█████████▉| 1364/1380 [02:44<00:01,  9.17it/s] 99%|█████████▉| 1365/1380 [02:44<00:01,  9.15it/s] 99%|█████████▉| 1366/1380 [02:45<00:01,  9.14it/s] 99%|█████████▉| 1367/1380 [02:45<00:01,  9.14it/s] 99%|█████████▉| 1368/1380 [02:45<00:01,  9.27it/s] 99%|█████████▉| 1369/1380 [02:45<00:01,  9.14it/s] 99%|█████████▉| 1370/1380 [02:45<00:01,  9.12it/s] 99%|█████████▉| 1371/1380 [02:45<00:00,  9.12it/s] 99%|█████████▉| 1372/1380 [02:45<00:00,  9.17it/s] 99%|█████████▉| 1373/1380 [02:45<00:00,  9.21it/s]100%|█████████▉| 1374/1380 [02:45<00:00,  9.21it/s]100%|█████████▉| 1375/1380 [02:46<00:00,  9.31it/s]100%|█████████▉| 1376/1380 [02:46<00:00,  9.23it/s]100%|█████████▉| 1377/1380 [02:46<00:00,  9.20it/s]100%|█████████▉| 1378/1380 [02:46<00:00,  9.21it/s]100%|█████████▉| 1379/1380 [02:46<00:00,  9.25it/s]                                                   100%|██████████| 1380/1380 [02:46<00:00,  9.25it/s][INFO|trainer.py:755] 2023-11-15 20:10:05,791 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:10:05,793 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:10:05,793 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:10:05,794 >>   Batch size = 8
{'eval_loss': 0.49997761845588684, 'eval_accuracy': 0.867059891107078, 'eval_micro_f1': 0.867059891107078, 'eval_macro_f1': 0.8530555478579873, 'eval_runtime': 3.7366, 'eval_samples_per_second': 589.84, 'eval_steps_per_second': 73.864, 'epoch': 4.0}
{'loss': 0.0855, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 83.71it/s][A
  7%|▋         | 18/276 [00:00<00:03, 77.49it/s][A
  9%|▉         | 26/276 [00:00<00:03, 74.77it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 73.63it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 73.01it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 73.09it/s][A
 21%|██        | 58/276 [00:00<00:03, 72.19it/s][A
 24%|██▍       | 66/276 [00:00<00:02, 71.90it/s][A
 27%|██▋       | 74/276 [00:01<00:02, 72.41it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 72.56it/s][A
 33%|███▎      | 90/276 [00:01<00:02, 71.70it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 73.25it/s][A
 38%|███▊      | 106/276 [00:01<00:02, 71.21it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 71.60it/s][A
 44%|████▍     | 122/276 [00:01<00:02, 71.45it/s][A
 47%|████▋     | 130/276 [00:01<00:02, 71.84it/s][A
 50%|█████     | 138/276 [00:01<00:01, 72.72it/s][A
 53%|█████▎    | 146/276 [00:02<00:01, 72.09it/s][A
 56%|█████▌    | 154/276 [00:02<00:01, 72.50it/s][A
 59%|█████▊    | 162/276 [00:02<00:01, 72.53it/s][A
 62%|██████▏   | 170/276 [00:02<00:01, 72.50it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 71.93it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 72.16it/s][A
 70%|███████   | 194/276 [00:02<00:01, 71.40it/s][A
 73%|███████▎  | 202/276 [00:02<00:01, 71.46it/s][A
 76%|███████▌  | 210/276 [00:02<00:00, 72.30it/s][A
 79%|███████▉  | 218/276 [00:03<00:00, 72.66it/s][A
 82%|████████▏ | 226/276 [00:03<00:00, 71.73it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 72.86it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 70.79it/s][A
 91%|█████████ | 250/276 [00:03<00:00, 70.60it/s][A
 93%|█████████▎| 258/276 [00:03<00:00, 70.74it/s][A
 96%|█████████▋| 266/276 [00:03<00:00, 71.55it/s][A
 99%|█████████▉| 274/276 [00:03<00:00, 70.39it/s][A                                                   
                                                 [A100%|██████████| 1380/1380 [02:50<00:00,  9.25it/s]
100%|██████████| 276/276 [00:03<00:00, 70.39it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 20:10:09,683 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:50<00:00,  9.25it/s]100%|██████████| 1380/1380 [02:50<00:00,  8.09it/s]
[INFO|trainer.py:2855] 2023-11-15 20:10:09,690 >> Saving model checkpoint to ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1
[INFO|configuration_utils.py:460] 2023-11-15 20:10:09,693 >> Configuration saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:10:10,911 >> Model weights saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:10:10,914 >> tokenizer config file saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:10:10,916 >> Special tokens file saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed1/special_tokens_map.json
{'eval_loss': 0.5481438040733337, 'eval_accuracy': 0.8652450090744102, 'eval_micro_f1': 0.8652450090744102, 'eval_macro_f1': 0.852404726496809, 'eval_runtime': 3.8857, 'eval_samples_per_second': 567.213, 'eval_steps_per_second': 71.03, 'epoch': 5.0}
{'train_runtime': 170.4802, 'train_samples_per_second': 258.564, 'train_steps_per_second': 8.095, 'train_loss': 0.22768193949823795, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2277
  train_runtime            = 0:02:50.48
  train_samples            =       8816
  train_samples_per_second =    258.564
  train_steps_per_second   =      8.095
11/15/2023 20:10:10 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:10:10,965 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:10:10,966 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:10:10,966 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:10:10,967 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  3%|▎         | 9/276 [00:00<00:03, 84.78it/s]  7%|▋         | 18/276 [00:00<00:03, 77.49it/s]  9%|▉         | 26/276 [00:00<00:03, 76.32it/s] 12%|█▏        | 34/276 [00:00<00:03, 75.14it/s] 15%|█▌        | 42/276 [00:00<00:03, 73.70it/s] 18%|█▊        | 50/276 [00:00<00:03, 73.92it/s] 21%|██        | 58/276 [00:00<00:02, 74.53it/s] 24%|██▍       | 66/276 [00:00<00:02, 73.62it/s] 27%|██▋       | 74/276 [00:00<00:02, 73.07it/s] 30%|███       | 83/276 [00:01<00:02, 74.24it/s] 33%|███▎      | 91/276 [00:01<00:02, 74.55it/s] 36%|███▌      | 99/276 [00:01<00:02, 73.73it/s] 39%|███▉      | 107/276 [00:01<00:02, 73.09it/s] 42%|████▏     | 115/276 [00:01<00:02, 73.87it/s] 45%|████▍     | 123/276 [00:01<00:02, 73.37it/s] 47%|████▋     | 131/276 [00:01<00:01, 73.48it/s] 50%|█████     | 139/276 [00:01<00:01, 74.24it/s] 53%|█████▎    | 147/276 [00:01<00:01, 74.89it/s] 56%|█████▌    | 155/276 [00:02<00:01, 74.36it/s] 59%|█████▉    | 163/276 [00:02<00:01, 73.46it/s] 62%|██████▏   | 171/276 [00:02<00:01, 74.66it/s] 65%|██████▍   | 179/276 [00:02<00:01, 73.73it/s] 68%|██████▊   | 187/276 [00:02<00:01, 72.96it/s] 71%|███████   | 195/276 [00:02<00:01, 74.09it/s] 74%|███████▎  | 203/276 [00:02<00:00, 74.15it/s] 76%|███████▋  | 211/276 [00:02<00:00, 74.43it/s] 79%|███████▉  | 219/276 [00:02<00:00, 73.56it/s] 82%|████████▏ | 227/276 [00:03<00:00, 74.48it/s] 85%|████████▌ | 235/276 [00:03<00:00, 73.31it/s] 88%|████████▊ | 243/276 [00:03<00:00, 72.99it/s] 91%|█████████ | 251/276 [00:03<00:00, 74.71it/s] 94%|█████████▍| 259/276 [00:03<00:00, 74.28it/s] 97%|█████████▋| 267/276 [00:03<00:00, 74.04it/s]100%|█████████▉| 275/276 [00:03<00:00, 73.33it/s]100%|██████████| 276/276 [00:03<00:00, 73.30it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8652
  eval_loss               =     0.5481
  eval_macro_f1           =     0.8524
  eval_micro_f1           =     0.8652
  eval_runtime            = 0:00:03.78
  eval_samples            =       2204
  eval_samples_per_second =    582.348
  eval_steps_per_second   =     72.926
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▅▅█▆▆
wandb:                      eval/loss ▁▁▃▆██
wandb:                  eval/macro_f1 ▁▇▅███
wandb:                  eval/micro_f1 ▁▅▅█▆▆
wandb:                   eval/runtime ▃▇█▁▇▃
wandb:        eval/samples_per_second ▅▂▁█▂▆
wandb:          eval/steps_per_second ▅▂▁█▂▆
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.86525
wandb:                      eval/loss 0.54814
wandb:                  eval/macro_f1 0.8524
wandb:                  eval/micro_f1 0.86525
wandb:                   eval/runtime 3.7847
wandb:        eval/samples_per_second 582.348
wandb:          eval/steps_per_second 72.926
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0855
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.22768
wandb:            train/train_runtime 170.4802
wandb: train/train_samples_per_second 258.564
wandb:   train/train_steps_per_second 8.095
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_200600-jqfolhmj
wandb: Find logs at: ./wandb/offline-run-20231115_200600-jqfolhmj/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_roberta-base_adapter__seed1/runs/Nov15_20-10-26_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_roberta-base_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_roberta-base_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:10:26 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:10:26 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_roberta-base_adapter__seed1/runs/Nov15_20-10-25_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_roberta-base_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_roberta-base_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 20:10:42,945 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:10:42,959 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:10:52,969 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:11:02,988 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:11:02,989 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:11:23,050 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:11:23,050 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:11:23,051 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:11:23,051 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:11:23,051 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:11:23,052 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:11:23,053 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:11:23,054 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:11:43,241 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:11:44,044 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:11:44,045 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  29%|██▉       | 2000/6840 [00:00<00:00, 15574.03 examples/s]Running tokenizer on dataset:  58%|█████▊    | 4000/6840 [00:00<00:00, 16477.74 examples/s]Running tokenizer on dataset:  88%|████████▊ | 6000/6840 [00:00<00:00, 16765.73 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 16566.41 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 18180.98 examples/s]
11/15/2023 20:11:44 - INFO - __main__ - Sample 6380 of the training set: {'text': 'Mich. Elephant Gets Therapy for Arthritis ROYAL OAK, Mich. - Like any patient, Wanda needs positive reinforcement to wrestle through her physical therapy...', 'label': 3, 'input_ids': [0, 40648, 4, 36516, 32810, 25889, 13, 1586, 44491, 10033, 975, 2118, 384, 7140, 6, 9605, 4, 111, 2011, 143, 3186, 6, 305, 5219, 782, 1313, 37700, 7, 27881, 149, 69, 2166, 5804, 734, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:11:44 - INFO - __main__ - Sample 883 of the training set: {'text': "Chicago to Hold EBay Auction to Raise Money for Cultural Programs City officials hope there are people willing to pay plenty of money to own a vintage Playboy Bunny costume, toss green dye into the Chicago River or throw a dinner party prepared by Oprah Winfrey's chef.", 'label': 2, 'input_ids': [0, 21897, 7, 10357, 381, 20861, 26342, 7, 39208, 8028, 13, 15309, 25740, 412, 503, 1034, 89, 32, 82, 2882, 7, 582, 2710, 9, 418, 7, 308, 10, 12669, 24526, 33470, 12111, 6, 13027, 2272, 31800, 88, 5, 1568, 1995, 50, 3211, 10, 3630, 537, 2460, 30, 20015, 5711, 16127, 18, 8172, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:11:44 - INFO - __main__ - Sample 1927 of the training set: {'text': 'Astros 10, Pirates 5 HOUSTON Mike Lamb went four-for-five with a homer and four RB-Is to lead the Houston Astros to their ninth straight win with a 10-to-five victory over the Pittsburgh Pirates today.', 'label': 0, 'input_ids': [0, 39021, 3985, 158, 6, 11114, 195, 30392, 12917, 1483, 13132, 439, 237, 12, 1990, 12, 9579, 19, 10, 8646, 8, 237, 11191, 12, 6209, 7, 483, 5, 2499, 10938, 7, 49, 5127, 1359, 339, 19, 10, 158, 12, 560, 12, 9579, 1124, 81, 5, 4386, 11114, 452, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:11:44 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:11:46,080 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:11:46,088 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:11:46,089 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 20:11:46,089 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:11:46,089 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:11:46,090 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:11:46,090 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:11:46,090 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 20:11:46,091 >>   Number of trainable parameters = 124,648,708
[INFO|integration_utils.py:716] 2023-11-15 20:11:46,092 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<24:36,  1.38s/it]  0%|          | 2/1070 [00:01<11:13,  1.59it/s]  0%|          | 3/1070 [00:01<06:59,  2.54it/s]  0%|          | 4/1070 [00:01<04:58,  3.57it/s]  0%|          | 5/1070 [00:01<03:50,  4.62it/s]  1%|          | 6/1070 [00:01<03:11,  5.56it/s]  1%|          | 7/1070 [00:02<02:45,  6.42it/s]  1%|          | 8/1070 [00:02<02:28,  7.13it/s]  1%|          | 9/1070 [00:02<02:18,  7.66it/s]  1%|          | 10/1070 [00:02<02:10,  8.11it/s]  1%|          | 11/1070 [00:02<02:05,  8.42it/s]  1%|          | 12/1070 [00:02<02:00,  8.78it/s]  1%|          | 13/1070 [00:02<01:58,  8.89it/s]  1%|▏         | 14/1070 [00:02<01:57,  8.95it/s]  1%|▏         | 15/1070 [00:02<01:57,  9.01it/s]  1%|▏         | 16/1070 [00:02<01:57,  8.98it/s]  2%|▏         | 17/1070 [00:03<01:55,  9.08it/s]  2%|▏         | 18/1070 [00:03<01:55,  9.14it/s]  2%|▏         | 19/1070 [00:03<01:52,  9.33it/s]  2%|▏         | 20/1070 [00:03<01:53,  9.25it/s]  2%|▏         | 21/1070 [00:03<01:53,  9.26it/s]  2%|▏         | 22/1070 [00:03<01:53,  9.25it/s]  2%|▏         | 23/1070 [00:03<01:53,  9.20it/s]  2%|▏         | 24/1070 [00:03<01:53,  9.24it/s]  2%|▏         | 25/1070 [00:03<01:53,  9.19it/s]  2%|▏         | 26/1070 [00:04<01:52,  9.24it/s]  3%|▎         | 27/1070 [00:04<01:53,  9.16it/s]  3%|▎         | 28/1070 [00:04<01:53,  9.17it/s]  3%|▎         | 29/1070 [00:04<01:54,  9.13it/s]  3%|▎         | 30/1070 [00:04<01:52,  9.23it/s]  3%|▎         | 31/1070 [00:04<01:52,  9.24it/s]  3%|▎         | 32/1070 [00:04<01:53,  9.13it/s]  3%|▎         | 33/1070 [00:04<01:53,  9.16it/s]  3%|▎         | 34/1070 [00:04<01:53,  9.15it/s]  3%|▎         | 35/1070 [00:05<01:52,  9.17it/s]  3%|▎         | 36/1070 [00:05<01:52,  9.18it/s]  3%|▎         | 37/1070 [00:05<01:51,  9.26it/s]  4%|▎         | 38/1070 [00:05<01:51,  9.24it/s]  4%|▎         | 39/1070 [00:05<01:51,  9.22it/s]  4%|▎         | 40/1070 [00:05<01:51,  9.20it/s]  4%|▍         | 41/1070 [00:05<01:52,  9.14it/s]  4%|▍         | 42/1070 [00:05<01:52,  9.18it/s]  4%|▍         | 43/1070 [00:05<01:51,  9.21it/s]  4%|▍         | 44/1070 [00:06<01:49,  9.35it/s]  4%|▍         | 45/1070 [00:06<01:50,  9.24it/s]  4%|▍         | 46/1070 [00:06<01:51,  9.20it/s]  4%|▍         | 47/1070 [00:06<01:52,  9.11it/s]  4%|▍         | 48/1070 [00:06<01:51,  9.14it/s]  5%|▍         | 49/1070 [00:06<01:50,  9.21it/s]  5%|▍         | 50/1070 [00:06<01:50,  9.19it/s]  5%|▍         | 51/1070 [00:06<01:50,  9.23it/s]  5%|▍         | 52/1070 [00:06<01:50,  9.17it/s]  5%|▍         | 53/1070 [00:07<01:51,  9.14it/s]  5%|▌         | 54/1070 [00:07<01:50,  9.16it/s]  5%|▌         | 55/1070 [00:07<01:49,  9.30it/s]  5%|▌         | 56/1070 [00:07<01:49,  9.25it/s]  5%|▌         | 57/1070 [00:07<01:50,  9.21it/s]  5%|▌         | 58/1070 [00:07<01:50,  9.17it/s]  6%|▌         | 59/1070 [00:07<01:50,  9.18it/s]  6%|▌         | 60/1070 [00:07<01:51,  9.04it/s]  6%|▌         | 61/1070 [00:07<01:51,  9.06it/s]  6%|▌         | 62/1070 [00:07<01:49,  9.20it/s]  6%|▌         | 63/1070 [00:08<01:49,  9.23it/s]  6%|▌         | 64/1070 [00:08<01:49,  9.18it/s]  6%|▌         | 65/1070 [00:08<01:50,  9.14it/s]  6%|▌         | 66/1070 [00:08<01:49,  9.16it/s]  6%|▋         | 67/1070 [00:08<01:49,  9.17it/s]  6%|▋         | 68/1070 [00:08<01:49,  9.12it/s]  6%|▋         | 69/1070 [00:08<01:48,  9.19it/s]  7%|▋         | 70/1070 [00:08<01:48,  9.22it/s]  7%|▋         | 71/1070 [00:08<01:48,  9.18it/s]  7%|▋         | 72/1070 [00:09<01:48,  9.17it/s]  7%|▋         | 73/1070 [00:09<01:48,  9.15it/s]  7%|▋         | 74/1070 [00:09<01:48,  9.15it/s]  7%|▋         | 75/1070 [00:09<01:49,  9.13it/s]  7%|▋         | 76/1070 [00:09<01:47,  9.24it/s]  7%|▋         | 77/1070 [00:09<01:47,  9.20it/s]  7%|▋         | 78/1070 [00:09<01:48,  9.18it/s]  7%|▋         | 79/1070 [00:09<01:47,  9.19it/s]  7%|▋         | 80/1070 [00:09<01:47,  9.20it/s]  8%|▊         | 81/1070 [00:10<01:46,  9.28it/s]  8%|▊         | 82/1070 [00:10<01:46,  9.31it/s]  8%|▊         | 83/1070 [00:10<01:45,  9.38it/s]  8%|▊         | 84/1070 [00:10<01:46,  9.28it/s]  8%|▊         | 85/1070 [00:10<01:46,  9.25it/s]  8%|▊         | 86/1070 [00:10<01:46,  9.23it/s]  8%|▊         | 87/1070 [00:10<01:46,  9.27it/s]  8%|▊         | 88/1070 [00:10<01:45,  9.31it/s]  8%|▊         | 89/1070 [00:10<01:45,  9.27it/s]  8%|▊         | 90/1070 [00:11<01:44,  9.34it/s]  9%|▊         | 91/1070 [00:11<01:45,  9.25it/s]  9%|▊         | 92/1070 [00:11<01:45,  9.26it/s]  9%|▊         | 93/1070 [00:11<01:46,  9.18it/s]  9%|▉         | 94/1070 [00:11<01:45,  9.24it/s]  9%|▉         | 95/1070 [00:11<01:45,  9.23it/s]  9%|▉         | 96/1070 [00:11<01:46,  9.18it/s]  9%|▉         | 97/1070 [00:11<01:45,  9.19it/s]  9%|▉         | 98/1070 [00:11<01:46,  9.15it/s]  9%|▉         | 99/1070 [00:12<01:46,  9.16it/s]  9%|▉         | 100/1070 [00:12<01:46,  9.14it/s]  9%|▉         | 101/1070 [00:12<01:44,  9.24it/s] 10%|▉         | 102/1070 [00:12<01:45,  9.20it/s] 10%|▉         | 103/1070 [00:12<01:45,  9.16it/s] 10%|▉         | 104/1070 [00:12<01:44,  9.21it/s] 10%|▉         | 105/1070 [00:12<01:46,  9.10it/s] 10%|▉         | 106/1070 [00:12<01:46,  9.08it/s] 10%|█         | 107/1070 [00:12<01:45,  9.13it/s] 10%|█         | 108/1070 [00:12<01:43,  9.26it/s] 10%|█         | 109/1070 [00:13<01:43,  9.30it/s] 10%|█         | 110/1070 [00:13<01:43,  9.26it/s] 10%|█         | 111/1070 [00:13<01:43,  9.26it/s] 10%|█         | 112/1070 [00:13<01:44,  9.21it/s] 11%|█         | 113/1070 [00:13<01:43,  9.22it/s] 11%|█         | 114/1070 [00:13<01:43,  9.28it/s] 11%|█         | 115/1070 [00:13<01:41,  9.40it/s] 11%|█         | 116/1070 [00:13<01:41,  9.41it/s] 11%|█         | 117/1070 [00:13<01:43,  9.24it/s] 11%|█         | 118/1070 [00:14<01:42,  9.24it/s] 11%|█         | 119/1070 [00:14<01:42,  9.25it/s] 11%|█         | 120/1070 [00:14<01:42,  9.23it/s] 11%|█▏        | 121/1070 [00:14<01:43,  9.16it/s] 11%|█▏        | 122/1070 [00:14<01:42,  9.28it/s] 11%|█▏        | 123/1070 [00:14<01:42,  9.26it/s] 12%|█▏        | 124/1070 [00:14<01:42,  9.22it/s] 12%|█▏        | 125/1070 [00:14<01:42,  9.19it/s] 12%|█▏        | 126/1070 [00:14<01:42,  9.20it/s] 12%|█▏        | 127/1070 [00:15<01:42,  9.18it/s] 12%|█▏        | 128/1070 [00:15<01:41,  9.25it/s] 12%|█▏        | 129/1070 [00:15<01:40,  9.32it/s] 12%|█▏        | 130/1070 [00:15<01:41,  9.30it/s] 12%|█▏        | 131/1070 [00:15<01:41,  9.27it/s] 12%|█▏        | 132/1070 [00:15<01:41,  9.26it/s] 12%|█▏        | 133/1070 [00:15<01:40,  9.28it/s] 13%|█▎        | 134/1070 [00:15<01:41,  9.25it/s] 13%|█▎        | 135/1070 [00:15<01:41,  9.21it/s] 13%|█▎        | 136/1070 [00:16<01:39,  9.36it/s] 13%|█▎        | 137/1070 [00:16<01:40,  9.33it/s] 13%|█▎        | 138/1070 [00:16<01:39,  9.34it/s] 13%|█▎        | 139/1070 [00:16<01:40,  9.28it/s] 13%|█▎        | 140/1070 [00:16<01:40,  9.25it/s] 13%|█▎        | 141/1070 [00:16<01:40,  9.25it/s] 13%|█▎        | 142/1070 [00:16<01:39,  9.29it/s] 13%|█▎        | 143/1070 [00:16<01:39,  9.32it/s] 13%|█▎        | 144/1070 [00:16<01:40,  9.22it/s] 14%|█▎        | 145/1070 [00:16<01:40,  9.19it/s] 14%|█▎        | 146/1070 [00:17<01:40,  9.19it/s] 14%|█▎        | 147/1070 [00:17<01:39,  9.26it/s] 14%|█▍        | 148/1070 [00:17<01:38,  9.32it/s] 14%|█▍        | 149/1070 [00:17<01:38,  9.36it/s] 14%|█▍        | 150/1070 [00:17<01:37,  9.45it/s] 14%|█▍        | 151/1070 [00:17<01:37,  9.38it/s] 14%|█▍        | 152/1070 [00:17<01:39,  9.25it/s] 14%|█▍        | 153/1070 [00:17<01:39,  9.22it/s] 14%|█▍        | 154/1070 [00:17<01:39,  9.19it/s] 14%|█▍        | 155/1070 [00:18<01:38,  9.26it/s] 15%|█▍        | 156/1070 [00:18<01:38,  9.29it/s] 15%|█▍        | 157/1070 [00:18<01:37,  9.39it/s] 15%|█▍        | 158/1070 [00:18<01:38,  9.28it/s] 15%|█▍        | 159/1070 [00:18<01:38,  9.29it/s] 15%|█▍        | 160/1070 [00:18<01:37,  9.30it/s] 15%|█▌        | 161/1070 [00:18<01:37,  9.35it/s] 15%|█▌        | 162/1070 [00:18<01:36,  9.37it/s] 15%|█▌        | 163/1070 [00:18<01:36,  9.37it/s] 15%|█▌        | 164/1070 [00:19<01:36,  9.37it/s] 15%|█▌        | 165/1070 [00:19<01:37,  9.30it/s] 16%|█▌        | 166/1070 [00:19<01:37,  9.25it/s] 16%|█▌        | 167/1070 [00:19<01:37,  9.28it/s] 16%|█▌        | 168/1070 [00:19<01:35,  9.40it/s] 16%|█▌        | 169/1070 [00:19<01:36,  9.38it/s] 16%|█▌        | 170/1070 [00:19<01:37,  9.28it/s] 16%|█▌        | 171/1070 [00:19<01:37,  9.24it/s] 16%|█▌        | 172/1070 [00:19<01:37,  9.23it/s] 16%|█▌        | 173/1070 [00:19<01:36,  9.25it/s] 16%|█▋        | 174/1070 [00:20<01:36,  9.25it/s] 16%|█▋        | 175/1070 [00:20<01:36,  9.31it/s] 16%|█▋        | 176/1070 [00:20<01:35,  9.33it/s] 17%|█▋        | 177/1070 [00:20<01:36,  9.29it/s] 17%|█▋        | 178/1070 [00:20<01:36,  9.29it/s] 17%|█▋        | 179/1070 [00:20<01:36,  9.28it/s] 17%|█▋        | 180/1070 [00:20<01:36,  9.26it/s] 17%|█▋        | 181/1070 [00:20<01:36,  9.23it/s] 17%|█▋        | 182/1070 [00:20<01:35,  9.31it/s] 17%|█▋        | 183/1070 [00:21<01:35,  9.33it/s] 17%|█▋        | 184/1070 [00:21<01:34,  9.34it/s] 17%|█▋        | 185/1070 [00:21<01:35,  9.30it/s] 17%|█▋        | 186/1070 [00:21<01:35,  9.26it/s] 17%|█▋        | 187/1070 [00:21<01:36,  9.18it/s] 18%|█▊        | 188/1070 [00:21<01:36,  9.13it/s] 18%|█▊        | 189/1070 [00:21<01:35,  9.27it/s] 18%|█▊        | 190/1070 [00:21<01:36,  9.14it/s] 18%|█▊        | 191/1070 [00:21<01:35,  9.19it/s] 18%|█▊        | 192/1070 [00:22<01:35,  9.16it/s] 18%|█▊        | 193/1070 [00:22<01:34,  9.25it/s] 18%|█▊        | 194/1070 [00:22<01:35,  9.18it/s] 18%|█▊        | 195/1070 [00:22<01:35,  9.15it/s] 18%|█▊        | 196/1070 [00:22<01:36,  9.08it/s] 18%|█▊        | 197/1070 [00:22<01:34,  9.21it/s] 19%|█▊        | 198/1070 [00:22<01:34,  9.19it/s] 19%|█▊        | 199/1070 [00:22<01:35,  9.17it/s] 19%|█▊        | 200/1070 [00:22<01:34,  9.20it/s] 19%|█▉        | 201/1070 [00:23<01:35,  9.13it/s] 19%|█▉        | 202/1070 [00:23<01:35,  9.10it/s] 19%|█▉        | 203/1070 [00:23<01:35,  9.12it/s] 19%|█▉        | 204/1070 [00:23<01:33,  9.31it/s] 19%|█▉        | 205/1070 [00:23<01:33,  9.23it/s] 19%|█▉        | 206/1070 [00:23<01:34,  9.17it/s] 19%|█▉        | 207/1070 [00:23<01:34,  9.16it/s] 19%|█▉        | 208/1070 [00:23<01:33,  9.23it/s] 20%|█▉        | 209/1070 [00:23<01:33,  9.21it/s] 20%|█▉        | 210/1070 [00:24<01:33,  9.23it/s] 20%|█▉        | 211/1070 [00:24<01:33,  9.16it/s] 20%|█▉        | 212/1070 [00:24<01:34,  9.10it/s] 20%|█▉        | 213/1070 [00:24<01:34,  9.12it/s]                                                   20%|██        | 214/1070 [00:24<01:33,  9.12it/s][INFO|trainer.py:755] 2023-11-15 20:12:10,531 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:12:10,533 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:12:10,533 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:12:10,534 >>   Batch size = 8
{'loss': 0.4464, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 11%|█         | 10/95 [00:00<00:00, 93.02it/s][A
 21%|██        | 20/95 [00:00<00:00, 81.23it/s][A
 31%|███       | 29/95 [00:00<00:00, 77.19it/s][A
 40%|████      | 38/95 [00:00<00:00, 79.20it/s][A
 48%|████▊     | 46/95 [00:00<00:00, 76.43it/s][A
 57%|█████▋    | 54/95 [00:00<00:00, 76.43it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 75.16it/s][A
 75%|███████▍  | 71/95 [00:00<00:00, 76.70it/s][A
 83%|████████▎ | 79/95 [00:01<00:00, 76.32it/s][A
 92%|█████████▏| 87/95 [00:01<00:00, 76.05it/s][A
100%|██████████| 95/95 [00:01<00:00, 75.63it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:25<01:33,  9.12it/s]
100%|██████████| 95/95 [00:01<00:00, 75.63it/s][A
                                               [A 20%|██        | 215/1070 [00:25<05:44,  2.48it/s] 20%|██        | 216/1070 [00:25<04:42,  3.03it/s] 20%|██        | 217/1070 [00:26<03:52,  3.67it/s] 20%|██        | 218/1070 [00:26<03:13,  4.40it/s] 20%|██        | 219/1070 [00:26<02:45,  5.14it/s] 21%|██        | 220/1070 [00:26<02:24,  5.89it/s] 21%|██        | 221/1070 [00:26<02:08,  6.61it/s] 21%|██        | 222/1070 [00:26<01:58,  7.19it/s] 21%|██        | 223/1070 [00:26<01:50,  7.68it/s] 21%|██        | 224/1070 [00:26<01:45,  8.03it/s] 21%|██        | 225/1070 [00:26<01:39,  8.46it/s] 21%|██        | 226/1070 [00:27<01:37,  8.67it/s] 21%|██        | 227/1070 [00:27<01:35,  8.82it/s] 21%|██▏       | 228/1070 [00:27<01:34,  8.94it/s] 21%|██▏       | 229/1070 [00:27<01:32,  9.04it/s] 21%|██▏       | 230/1070 [00:27<01:32,  9.09it/s] 22%|██▏       | 231/1070 [00:27<01:31,  9.19it/s] 22%|██▏       | 232/1070 [00:27<01:30,  9.30it/s] 22%|██▏       | 233/1070 [00:27<01:29,  9.31it/s] 22%|██▏       | 234/1070 [00:27<01:30,  9.23it/s] 22%|██▏       | 235/1070 [00:27<01:30,  9.23it/s] 22%|██▏       | 236/1070 [00:28<01:30,  9.24it/s] 22%|██▏       | 237/1070 [00:28<01:30,  9.20it/s] 22%|██▏       | 238/1070 [00:28<01:30,  9.20it/s] 22%|██▏       | 239/1070 [00:28<01:29,  9.24it/s] 22%|██▏       | 240/1070 [00:28<01:30,  9.21it/s] 23%|██▎       | 241/1070 [00:28<01:29,  9.22it/s] 23%|██▎       | 242/1070 [00:28<01:29,  9.23it/s] 23%|██▎       | 243/1070 [00:28<01:29,  9.22it/s] 23%|██▎       | 244/1070 [00:28<01:29,  9.23it/s] 23%|██▎       | 245/1070 [00:29<01:29,  9.25it/s] 23%|██▎       | 246/1070 [00:29<01:27,  9.37it/s] 23%|██▎       | 247/1070 [00:29<01:28,  9.27it/s] 23%|██▎       | 248/1070 [00:29<01:28,  9.26it/s] 23%|██▎       | 249/1070 [00:29<01:29,  9.21it/s] 23%|██▎       | 250/1070 [00:29<01:28,  9.25it/s] 23%|██▎       | 251/1070 [00:29<01:29,  9.18it/s] 24%|██▎       | 252/1070 [00:29<01:28,  9.25it/s] 24%|██▎       | 253/1070 [00:29<01:27,  9.32it/s] 24%|██▎       | 254/1070 [00:30<01:27,  9.29it/s] 24%|██▍       | 255/1070 [00:30<01:27,  9.28it/s] 24%|██▍       | 256/1070 [00:30<01:27,  9.27it/s] 24%|██▍       | 257/1070 [00:30<01:27,  9.29it/s] 24%|██▍       | 258/1070 [00:30<01:26,  9.34it/s] 24%|██▍       | 259/1070 [00:30<01:27,  9.24it/s] 24%|██▍       | 260/1070 [00:30<01:26,  9.33it/s] 24%|██▍       | 261/1070 [00:30<01:27,  9.24it/s] 24%|██▍       | 262/1070 [00:30<01:27,  9.23it/s] 25%|██▍       | 263/1070 [00:31<01:27,  9.26it/s] 25%|██▍       | 264/1070 [00:31<01:26,  9.30it/s] 25%|██▍       | 265/1070 [00:31<01:26,  9.32it/s] 25%|██▍       | 266/1070 [00:31<01:26,  9.31it/s] 25%|██▍       | 267/1070 [00:31<01:26,  9.30it/s] 25%|██▌       | 268/1070 [00:31<01:26,  9.31it/s] 25%|██▌       | 269/1070 [00:31<01:26,  9.31it/s] 25%|██▌       | 270/1070 [00:31<01:25,  9.32it/s] 25%|██▌       | 271/1070 [00:31<01:24,  9.44it/s] 25%|██▌       | 272/1070 [00:31<01:25,  9.36it/s] 26%|██▌       | 273/1070 [00:32<01:25,  9.30it/s] 26%|██▌       | 274/1070 [00:32<01:24,  9.43it/s] 26%|██▌       | 276/1070 [00:32<01:19, 10.05it/s] 26%|██▌       | 278/1070 [00:32<01:16, 10.39it/s] 26%|██▌       | 280/1070 [00:32<01:14, 10.64it/s] 26%|██▋       | 282/1070 [00:32<01:18, 10.09it/s] 27%|██▋       | 284/1070 [00:33<01:19,  9.85it/s] 27%|██▋       | 285/1070 [00:33<01:20,  9.74it/s] 27%|██▋       | 286/1070 [00:33<01:20,  9.71it/s] 27%|██▋       | 287/1070 [00:33<01:21,  9.58it/s] 27%|██▋       | 288/1070 [00:33<01:22,  9.47it/s] 27%|██▋       | 289/1070 [00:33<01:23,  9.39it/s] 27%|██▋       | 290/1070 [00:33<01:23,  9.37it/s] 27%|██▋       | 291/1070 [00:33<01:22,  9.43it/s] 27%|██▋       | 292/1070 [00:34<01:22,  9.43it/s] 27%|██▋       | 293/1070 [00:34<01:23,  9.30it/s] 27%|██▋       | 294/1070 [00:34<01:23,  9.31it/s] 28%|██▊       | 295/1070 [00:34<01:23,  9.30it/s] 28%|██▊       | 296/1070 [00:34<01:23,  9.24it/s] 28%|██▊       | 297/1070 [00:34<01:23,  9.30it/s] 28%|██▊       | 298/1070 [00:34<01:23,  9.27it/s] 28%|██▊       | 299/1070 [00:34<01:23,  9.29it/s] 28%|██▊       | 300/1070 [00:34<01:23,  9.24it/s] 28%|██▊       | 301/1070 [00:34<01:22,  9.31it/s] 28%|██▊       | 302/1070 [00:35<01:23,  9.22it/s] 28%|██▊       | 303/1070 [00:35<01:23,  9.22it/s] 28%|██▊       | 304/1070 [00:35<01:23,  9.19it/s] 29%|██▊       | 305/1070 [00:35<01:21,  9.33it/s] 29%|██▊       | 306/1070 [00:35<01:21,  9.34it/s] 29%|██▊       | 307/1070 [00:35<01:22,  9.27it/s] 29%|██▉       | 308/1070 [00:35<01:21,  9.39it/s] 29%|██▉       | 309/1070 [00:35<01:21,  9.32it/s] 29%|██▉       | 310/1070 [00:35<01:21,  9.30it/s] 29%|██▉       | 311/1070 [00:36<01:21,  9.31it/s] 29%|██▉       | 312/1070 [00:36<01:22,  9.22it/s] 29%|██▉       | 313/1070 [00:36<01:21,  9.23it/s] 29%|██▉       | 314/1070 [00:36<01:22,  9.21it/s] 29%|██▉       | 315/1070 [00:36<01:20,  9.37it/s] 30%|██▉       | 316/1070 [00:36<01:20,  9.36it/s] 30%|██▉       | 317/1070 [00:36<01:20,  9.39it/s] 30%|██▉       | 318/1070 [00:36<01:20,  9.36it/s] 30%|██▉       | 319/1070 [00:36<01:20,  9.34it/s] 30%|██▉       | 320/1070 [00:37<01:19,  9.39it/s] 30%|███       | 321/1070 [00:37<01:19,  9.42it/s] 30%|███       | 322/1070 [00:37<01:19,  9.44it/s] 30%|███       | 323/1070 [00:37<01:18,  9.46it/s] 30%|███       | 324/1070 [00:37<01:18,  9.47it/s] 30%|███       | 325/1070 [00:37<01:19,  9.38it/s] 30%|███       | 326/1070 [00:37<01:19,  9.40it/s] 31%|███       | 327/1070 [00:37<01:19,  9.40it/s] 31%|███       | 328/1070 [00:37<01:19,  9.38it/s] 31%|███       | 329/1070 [00:37<01:18,  9.38it/s] 31%|███       | 330/1070 [00:38<01:19,  9.36it/s] 31%|███       | 331/1070 [00:38<01:18,  9.38it/s] 31%|███       | 332/1070 [00:38<01:20,  9.21it/s] 31%|███       | 333/1070 [00:38<01:19,  9.23it/s] 31%|███       | 334/1070 [00:38<01:19,  9.21it/s] 31%|███▏      | 335/1070 [00:38<01:19,  9.21it/s] 31%|███▏      | 336/1070 [00:38<01:18,  9.31it/s] 31%|███▏      | 337/1070 [00:38<01:18,  9.33it/s] 32%|███▏      | 338/1070 [00:38<01:18,  9.33it/s] 32%|███▏      | 339/1070 [00:39<01:18,  9.28it/s] 32%|███▏      | 340/1070 [00:39<01:18,  9.24it/s] 32%|███▏      | 341/1070 [00:39<01:18,  9.27it/s] 32%|███▏      | 342/1070 [00:39<01:18,  9.26it/s] 32%|███▏      | 343/1070 [00:39<01:18,  9.31it/s] 32%|███▏      | 344/1070 [00:39<01:17,  9.35it/s] 32%|███▏      | 345/1070 [00:39<01:18,  9.27it/s] 32%|███▏      | 346/1070 [00:39<01:16,  9.42it/s] 32%|███▏      | 347/1070 [00:39<01:17,  9.38it/s] 33%|███▎      | 348/1070 [00:40<01:17,  9.32it/s] 33%|███▎      | 349/1070 [00:40<01:17,  9.32it/s] 33%|███▎      | 350/1070 [00:40<01:17,  9.32it/s] 33%|███▎      | 351/1070 [00:40<01:16,  9.35it/s] 33%|███▎      | 352/1070 [00:40<01:16,  9.36it/s] 33%|███▎      | 353/1070 [00:40<01:15,  9.50it/s] 33%|███▎      | 354/1070 [00:40<01:15,  9.43it/s] 33%|███▎      | 355/1070 [00:40<01:16,  9.37it/s] 33%|███▎      | 356/1070 [00:40<01:16,  9.34it/s] 33%|███▎      | 357/1070 [00:40<01:16,  9.35it/s] 33%|███▎      | 358/1070 [00:41<01:16,  9.35it/s] 34%|███▎      | 359/1070 [00:41<01:16,  9.34it/s] 34%|███▎      | 360/1070 [00:41<01:15,  9.42it/s] 34%|███▎      | 361/1070 [00:41<01:15,  9.39it/s] 34%|███▍      | 362/1070 [00:41<01:15,  9.35it/s] 34%|███▍      | 363/1070 [00:41<01:15,  9.37it/s] 34%|███▍      | 364/1070 [00:41<01:16,  9.27it/s] 34%|███▍      | 365/1070 [00:41<01:16,  9.22it/s] 34%|███▍      | 366/1070 [00:41<01:16,  9.16it/s] 34%|███▍      | 367/1070 [00:42<01:17,  9.11it/s] 34%|███▍      | 368/1070 [00:42<01:16,  9.20it/s] 34%|███▍      | 369/1070 [00:42<01:16,  9.13it/s] 35%|███▍      | 370/1070 [00:42<01:15,  9.22it/s] 35%|███▍      | 371/1070 [00:42<01:16,  9.19it/s] 35%|███▍      | 372/1070 [00:42<01:16,  9.18it/s] 35%|███▍      | 373/1070 [00:42<01:15,  9.27it/s] 35%|███▍      | 374/1070 [00:42<01:15,  9.22it/s] 35%|███▌      | 375/1070 [00:42<01:15,  9.19it/s] 35%|███▌      | 376/1070 [00:43<01:15,  9.22it/s] 35%|███▌      | 377/1070 [00:43<01:15,  9.18it/s] 35%|███▌      | 378/1070 [00:43<01:14,  9.28it/s] 35%|███▌      | 379/1070 [00:43<01:14,  9.28it/s] 36%|███▌      | 380/1070 [00:43<01:13,  9.36it/s] 36%|███▌      | 381/1070 [00:43<01:14,  9.30it/s] 36%|███▌      | 382/1070 [00:43<01:14,  9.30it/s] 36%|███▌      | 383/1070 [00:43<01:13,  9.30it/s] 36%|███▌      | 384/1070 [00:43<01:13,  9.28it/s] 36%|███▌      | 385/1070 [00:44<01:14,  9.23it/s] 36%|███▌      | 386/1070 [00:44<01:14,  9.23it/s] 36%|███▌      | 387/1070 [00:44<01:13,  9.28it/s] 36%|███▋      | 388/1070 [00:44<01:13,  9.29it/s] 36%|███▋      | 389/1070 [00:44<01:13,  9.22it/s] 36%|███▋      | 390/1070 [00:44<01:12,  9.39it/s] 37%|███▋      | 391/1070 [00:44<01:13,  9.27it/s] 37%|███▋      | 392/1070 [00:44<01:13,  9.21it/s] 37%|███▋      | 393/1070 [00:44<01:13,  9.24it/s] 37%|███▋      | 394/1070 [00:44<01:13,  9.24it/s] 37%|███▋      | 395/1070 [00:45<01:13,  9.19it/s] 37%|███▋      | 396/1070 [00:45<01:12,  9.25it/s] 37%|███▋      | 397/1070 [00:45<01:12,  9.33it/s] 37%|███▋      | 398/1070 [00:45<01:12,  9.28it/s] 37%|███▋      | 399/1070 [00:45<01:12,  9.19it/s] 37%|███▋      | 400/1070 [00:45<01:12,  9.20it/s] 37%|███▋      | 401/1070 [00:45<01:12,  9.23it/s] 38%|███▊      | 402/1070 [00:45<01:12,  9.22it/s] 38%|███▊      | 403/1070 [00:45<01:12,  9.25it/s] 38%|███▊      | 404/1070 [00:46<01:11,  9.33it/s] 38%|███▊      | 405/1070 [00:46<01:11,  9.30it/s] 38%|███▊      | 406/1070 [00:46<01:11,  9.28it/s] 38%|███▊      | 407/1070 [00:46<01:11,  9.25it/s] 38%|███▊      | 408/1070 [00:46<01:11,  9.25it/s] 38%|███▊      | 409/1070 [00:46<01:11,  9.25it/s] 38%|███▊      | 410/1070 [00:46<01:11,  9.21it/s] 38%|███▊      | 411/1070 [00:46<01:10,  9.30it/s] 39%|███▊      | 412/1070 [00:46<01:11,  9.22it/s] 39%|███▊      | 413/1070 [00:47<01:11,  9.22it/s] 39%|███▊      | 414/1070 [00:47<01:11,  9.19it/s] 39%|███▉      | 415/1070 [00:47<01:11,  9.20it/s] 39%|███▉      | 416/1070 [00:47<01:11,  9.14it/s] 39%|███▉      | 417/1070 [00:47<01:11,  9.11it/s] 39%|███▉      | 418/1070 [00:47<01:10,  9.21it/s] 39%|███▉      | 419/1070 [00:47<01:10,  9.21it/s] 39%|███▉      | 420/1070 [00:47<01:10,  9.23it/s] 39%|███▉      | 421/1070 [00:47<01:10,  9.19it/s] 39%|███▉      | 422/1070 [00:48<01:10,  9.17it/s] 40%|███▉      | 423/1070 [00:48<01:11,  9.10it/s] 40%|███▉      | 424/1070 [00:48<01:10,  9.11it/s] 40%|███▉      | 425/1070 [00:48<01:10,  9.19it/s] 40%|███▉      | 426/1070 [00:48<01:10,  9.18it/s] 40%|███▉      | 427/1070 [00:48<01:09,  9.19it/s]                                                   40%|████      | 428/1070 [00:48<01:09,  9.19it/s][INFO|trainer.py:755] 2023-11-15 20:12:34,773 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:12:34,775 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:12:34,776 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:12:34,776 >>   Batch size = 8
{'eval_loss': 0.3049186170101166, 'eval_accuracy': 0.906578947368421, 'eval_micro_f1': 0.906578947368421, 'eval_macro_f1': 0.9034025297324961, 'eval_runtime': 1.2891, 'eval_samples_per_second': 589.548, 'eval_steps_per_second': 73.694, 'epoch': 1.0}
{'loss': 0.2292, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 78.58it/s][A
 18%|█▊        | 17/95 [00:00<00:01, 74.39it/s][A
 26%|██▋       | 25/95 [00:00<00:00, 72.91it/s][A
 35%|███▍      | 33/95 [00:00<00:00, 74.10it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 75.80it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 74.13it/s][A
 60%|██████    | 57/95 [00:00<00:00, 74.91it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 72.67it/s][A
 77%|███████▋  | 73/95 [00:00<00:00, 71.77it/s][A
 85%|████████▌ | 81/95 [00:01<00:00, 71.96it/s][A
 94%|█████████▎| 89/95 [00:01<00:00, 72.74it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:50<01:09,  9.19it/s]
100%|██████████| 95/95 [00:01<00:00, 72.74it/s][A
                                               [A 40%|████      | 429/1070 [00:50<04:27,  2.40it/s] 40%|████      | 430/1070 [00:50<03:37,  2.94it/s] 40%|████      | 431/1070 [00:50<02:59,  3.56it/s] 40%|████      | 432/1070 [00:50<02:30,  4.24it/s] 40%|████      | 433/1070 [00:50<02:08,  4.97it/s] 41%|████      | 434/1070 [00:50<01:51,  5.69it/s] 41%|████      | 435/1070 [00:50<01:39,  6.38it/s] 41%|████      | 436/1070 [00:50<01:30,  6.99it/s] 41%|████      | 437/1070 [00:51<01:23,  7.57it/s] 41%|████      | 438/1070 [00:51<01:19,  7.97it/s] 41%|████      | 439/1070 [00:51<01:16,  8.21it/s] 41%|████      | 440/1070 [00:51<01:14,  8.43it/s] 41%|████      | 441/1070 [00:51<01:12,  8.65it/s] 41%|████▏     | 442/1070 [00:51<01:11,  8.80it/s] 41%|████▏     | 443/1070 [00:51<01:10,  8.86it/s] 41%|████▏     | 444/1070 [00:51<01:09,  9.06it/s] 42%|████▏     | 445/1070 [00:51<01:08,  9.06it/s] 42%|████▏     | 446/1070 [00:52<01:09,  9.04it/s] 42%|████▏     | 447/1070 [00:52<01:09,  8.99it/s] 42%|████▏     | 448/1070 [00:52<01:08,  9.06it/s] 42%|████▏     | 449/1070 [00:52<01:08,  9.11it/s] 42%|████▏     | 450/1070 [00:52<01:07,  9.12it/s] 42%|████▏     | 451/1070 [00:52<01:06,  9.30it/s] 42%|████▏     | 452/1070 [00:52<01:06,  9.24it/s] 42%|████▏     | 453/1070 [00:52<01:06,  9.24it/s] 42%|████▏     | 454/1070 [00:52<01:06,  9.20it/s] 43%|████▎     | 455/1070 [00:52<01:06,  9.25it/s] 43%|████▎     | 456/1070 [00:53<01:06,  9.27it/s] 43%|████▎     | 457/1070 [00:53<01:06,  9.19it/s] 43%|████▎     | 458/1070 [00:53<01:05,  9.31it/s] 43%|████▎     | 459/1070 [00:53<01:06,  9.16it/s] 43%|████▎     | 460/1070 [00:53<01:06,  9.20it/s] 43%|████▎     | 461/1070 [00:53<01:06,  9.16it/s] 43%|████▎     | 462/1070 [00:53<01:06,  9.20it/s] 43%|████▎     | 463/1070 [00:53<01:05,  9.20it/s] 43%|████▎     | 464/1070 [00:53<01:05,  9.25it/s] 43%|████▎     | 465/1070 [00:54<01:04,  9.36it/s] 44%|████▎     | 466/1070 [00:54<01:05,  9.25it/s] 44%|████▎     | 467/1070 [00:54<01:05,  9.20it/s] 44%|████▎     | 468/1070 [00:54<01:05,  9.22it/s] 44%|████▍     | 469/1070 [00:54<01:05,  9.22it/s] 44%|████▍     | 470/1070 [00:54<01:04,  9.25it/s] 44%|████▍     | 471/1070 [00:54<01:05,  9.14it/s] 44%|████▍     | 472/1070 [00:54<01:04,  9.25it/s] 44%|████▍     | 473/1070 [00:54<01:04,  9.25it/s] 44%|████▍     | 474/1070 [00:55<01:05,  9.13it/s] 44%|████▍     | 475/1070 [00:55<01:05,  9.15it/s] 44%|████▍     | 476/1070 [00:55<01:04,  9.26it/s] 45%|████▍     | 477/1070 [00:55<01:04,  9.23it/s] 45%|████▍     | 478/1070 [00:55<01:04,  9.17it/s] 45%|████▍     | 479/1070 [00:55<01:04,  9.15it/s] 45%|████▍     | 480/1070 [00:55<01:04,  9.08it/s] 45%|████▍     | 481/1070 [00:55<01:04,  9.14it/s] 45%|████▌     | 482/1070 [00:55<01:04,  9.10it/s] 45%|████▌     | 483/1070 [00:56<01:04,  9.17it/s] 45%|████▌     | 484/1070 [00:56<01:04,  9.11it/s] 45%|████▌     | 485/1070 [00:56<01:04,  9.12it/s] 45%|████▌     | 486/1070 [00:56<01:04,  9.09it/s] 46%|████▌     | 487/1070 [00:56<01:03,  9.19it/s] 46%|████▌     | 488/1070 [00:56<01:03,  9.17it/s] 46%|████▌     | 489/1070 [00:56<01:03,  9.10it/s] 46%|████▌     | 490/1070 [00:56<01:03,  9.07it/s] 46%|████▌     | 491/1070 [00:56<01:04,  9.03it/s] 46%|████▌     | 492/1070 [00:57<01:03,  9.08it/s] 46%|████▌     | 493/1070 [00:57<01:04,  8.95it/s] 46%|████▌     | 494/1070 [00:57<01:03,  9.10it/s] 46%|████▋     | 495/1070 [00:57<01:03,  9.08it/s] 46%|████▋     | 496/1070 [00:57<01:03,  9.01it/s] 46%|████▋     | 497/1070 [00:57<01:03,  8.98it/s] 47%|████▋     | 498/1070 [00:57<01:02,  9.10it/s] 47%|████▋     | 499/1070 [00:57<01:03,  9.05it/s] 47%|████▋     | 500/1070 [00:57<01:03,  9.04it/s] 47%|████▋     | 501/1070 [00:58<01:02,  9.05it/s] 47%|████▋     | 502/1070 [00:58<01:03,  9.02it/s] 47%|████▋     | 503/1070 [00:58<01:03,  8.99it/s] 47%|████▋     | 504/1070 [00:58<01:03,  8.98it/s] 47%|████▋     | 505/1070 [00:58<01:01,  9.15it/s] 47%|████▋     | 506/1070 [00:58<01:02,  9.08it/s] 47%|████▋     | 507/1070 [00:58<01:02,  9.06it/s] 47%|████▋     | 508/1070 [00:58<01:02,  8.93it/s] 48%|████▊     | 509/1070 [00:58<01:02,  8.98it/s] 48%|████▊     | 510/1070 [00:59<01:02,  9.03it/s] 48%|████▊     | 511/1070 [00:59<01:02,  8.99it/s] 48%|████▊     | 512/1070 [00:59<01:01,  9.05it/s] 48%|████▊     | 513/1070 [00:59<01:01,  9.06it/s] 48%|████▊     | 514/1070 [00:59<01:01,  9.00it/s] 48%|████▊     | 515/1070 [00:59<01:01,  8.96it/s] 48%|████▊     | 516/1070 [00:59<01:01,  9.01it/s] 48%|████▊     | 517/1070 [00:59<01:01,  9.03it/s] 48%|████▊     | 518/1070 [00:59<01:01,  8.95it/s] 49%|████▊     | 519/1070 [01:00<01:01,  8.97it/s] 49%|████▊     | 520/1070 [01:00<01:01,  9.00it/s] 49%|████▊     | 521/1070 [01:00<01:00,  9.00it/s] 49%|████▉     | 522/1070 [01:00<01:01,  8.93it/s] 49%|████▉     | 523/1070 [01:00<01:00,  9.05it/s] 49%|████▉     | 524/1070 [01:00<01:00,  9.02it/s] 49%|████▉     | 525/1070 [01:00<01:00,  9.08it/s] 49%|████▉     | 526/1070 [01:00<01:00,  9.05it/s] 49%|████▉     | 527/1070 [01:00<00:59,  9.14it/s] 49%|████▉     | 528/1070 [01:01<00:59,  9.11it/s] 49%|████▉     | 529/1070 [01:01<00:59,  9.07it/s] 50%|████▉     | 530/1070 [01:01<00:59,  9.05it/s] 50%|████▉     | 531/1070 [01:01<00:58,  9.23it/s] 50%|████▉     | 532/1070 [01:01<00:59,  9.10it/s] 50%|████▉     | 533/1070 [01:01<00:59,  8.99it/s] 50%|████▉     | 534/1070 [01:01<01:00,  8.91it/s] 50%|█████     | 535/1070 [01:01<00:59,  8.97it/s] 50%|█████     | 536/1070 [01:01<00:59,  9.01it/s] 50%|█████     | 537/1070 [01:02<00:59,  8.95it/s] 50%|█████     | 538/1070 [01:02<00:59,  9.02it/s] 50%|█████     | 539/1070 [01:02<00:58,  9.01it/s] 50%|█████     | 540/1070 [01:02<00:59,  8.97it/s] 51%|█████     | 541/1070 [01:02<00:59,  8.93it/s] 51%|█████     | 542/1070 [01:02<00:58,  9.03it/s] 51%|█████     | 543/1070 [01:02<00:58,  9.02it/s] 51%|█████     | 544/1070 [01:02<00:58,  9.06it/s] 51%|█████     | 545/1070 [01:02<00:58,  8.96it/s] 51%|█████     | 546/1070 [01:03<00:58,  8.94it/s] 51%|█████     | 547/1070 [01:03<00:58,  8.95it/s] 51%|█████     | 548/1070 [01:03<00:58,  8.97it/s] 51%|█████▏    | 549/1070 [01:03<00:57,  9.05it/s] 51%|█████▏    | 550/1070 [01:03<00:57,  9.05it/s] 51%|█████▏    | 551/1070 [01:03<00:57,  9.06it/s] 52%|█████▏    | 552/1070 [01:03<00:57,  8.98it/s] 52%|█████▏    | 553/1070 [01:03<00:57,  8.96it/s] 52%|█████▏    | 554/1070 [01:03<00:57,  8.96it/s] 52%|█████▏    | 555/1070 [01:04<00:57,  8.94it/s] 52%|█████▏    | 556/1070 [01:04<00:56,  9.16it/s] 52%|█████▏    | 557/1070 [01:04<00:56,  9.06it/s] 52%|█████▏    | 558/1070 [01:04<00:56,  9.00it/s] 52%|█████▏    | 559/1070 [01:04<00:57,  8.95it/s] 52%|█████▏    | 560/1070 [01:04<00:57,  8.90it/s] 52%|█████▏    | 561/1070 [01:04<00:57,  8.92it/s] 53%|█████▎    | 562/1070 [01:04<00:57,  8.86it/s] 53%|█████▎    | 563/1070 [01:04<00:55,  9.07it/s] 53%|█████▎    | 564/1070 [01:05<00:56,  8.97it/s] 53%|█████▎    | 565/1070 [01:05<00:56,  8.96it/s] 53%|█████▎    | 566/1070 [01:05<00:56,  8.93it/s] 53%|█████▎    | 567/1070 [01:05<00:56,  8.94it/s] 53%|█████▎    | 568/1070 [01:05<00:56,  8.96it/s] 53%|█████▎    | 569/1070 [01:05<00:56,  8.92it/s] 53%|█████▎    | 570/1070 [01:05<00:55,  9.03it/s] 53%|█████▎    | 571/1070 [01:05<00:55,  8.99it/s] 53%|█████▎    | 572/1070 [01:05<00:55,  8.91it/s] 54%|█████▎    | 573/1070 [01:06<00:56,  8.86it/s] 54%|█████▎    | 574/1070 [01:06<00:55,  8.94it/s] 54%|█████▎    | 575/1070 [01:06<00:54,  9.02it/s] 54%|█████▍    | 576/1070 [01:06<00:54,  9.02it/s] 54%|█████▍    | 577/1070 [01:06<00:54,  9.01it/s] 54%|█████▍    | 578/1070 [01:06<00:54,  8.97it/s] 54%|█████▍    | 579/1070 [01:06<00:54,  8.97it/s] 54%|█████▍    | 580/1070 [01:06<00:55,  8.91it/s] 54%|█████▍    | 581/1070 [01:06<00:54,  9.04it/s] 54%|█████▍    | 582/1070 [01:07<00:54,  9.01it/s] 54%|█████▍    | 583/1070 [01:07<00:53,  9.02it/s] 55%|█████▍    | 584/1070 [01:07<00:54,  8.95it/s] 55%|█████▍    | 585/1070 [01:07<00:54,  8.89it/s] 55%|█████▍    | 586/1070 [01:07<00:54,  8.92it/s] 55%|█████▍    | 587/1070 [01:07<00:54,  8.82it/s] 55%|█████▍    | 588/1070 [01:07<00:53,  9.02it/s] 55%|█████▌    | 589/1070 [01:07<00:54,  8.90it/s] 55%|█████▌    | 590/1070 [01:07<00:53,  8.93it/s] 55%|█████▌    | 591/1070 [01:08<00:53,  8.94it/s] 55%|█████▌    | 592/1070 [01:08<00:53,  8.91it/s] 55%|█████▌    | 593/1070 [01:08<00:53,  8.87it/s] 56%|█████▌    | 594/1070 [01:08<00:53,  8.89it/s] 56%|█████▌    | 595/1070 [01:08<00:52,  9.07it/s] 56%|█████▌    | 596/1070 [01:08<00:53,  8.94it/s] 56%|█████▌    | 597/1070 [01:08<00:52,  8.93it/s] 56%|█████▌    | 598/1070 [01:08<00:53,  8.87it/s] 56%|█████▌    | 599/1070 [01:08<00:53,  8.87it/s] 56%|█████▌    | 600/1070 [01:09<00:52,  8.93it/s] 56%|█████▌    | 601/1070 [01:09<00:52,  8.94it/s] 56%|█████▋    | 602/1070 [01:09<00:51,  9.07it/s] 56%|█████▋    | 603/1070 [01:09<00:51,  9.05it/s] 56%|█████▋    | 604/1070 [01:09<00:51,  9.01it/s] 57%|█████▋    | 605/1070 [01:09<00:51,  9.00it/s] 57%|█████▋    | 606/1070 [01:09<00:51,  9.04it/s] 57%|█████▋    | 607/1070 [01:09<00:51,  9.01it/s] 57%|█████▋    | 608/1070 [01:09<00:51,  9.03it/s] 57%|█████▋    | 609/1070 [01:10<00:50,  9.06it/s] 57%|█████▋    | 610/1070 [01:10<00:50,  9.02it/s] 57%|█████▋    | 611/1070 [01:10<00:51,  8.99it/s] 57%|█████▋    | 612/1070 [01:10<00:50,  9.02it/s] 57%|█████▋    | 613/1070 [01:10<00:50,  9.02it/s] 57%|█████▋    | 614/1070 [01:10<00:50,  8.99it/s] 57%|█████▋    | 615/1070 [01:10<00:50,  9.01it/s] 58%|█████▊    | 616/1070 [01:10<00:50,  9.03it/s] 58%|█████▊    | 617/1070 [01:10<00:50,  8.94it/s] 58%|█████▊    | 618/1070 [01:11<00:50,  8.92it/s] 58%|█████▊    | 619/1070 [01:11<00:50,  8.90it/s] 58%|█████▊    | 620/1070 [01:11<00:50,  8.95it/s] 58%|█████▊    | 621/1070 [01:11<00:50,  8.96it/s] 58%|█████▊    | 622/1070 [01:11<00:49,  9.00it/s] 58%|█████▊    | 623/1070 [01:11<00:49,  8.99it/s] 58%|█████▊    | 624/1070 [01:11<00:49,  8.99it/s] 58%|█████▊    | 625/1070 [01:11<00:49,  8.95it/s] 59%|█████▊    | 626/1070 [01:11<00:50,  8.88it/s] 59%|█████▊    | 627/1070 [01:12<00:49,  9.01it/s] 59%|█████▊    | 628/1070 [01:12<00:49,  9.00it/s] 59%|█████▉    | 629/1070 [01:12<00:48,  9.00it/s] 59%|█████▉    | 630/1070 [01:12<00:49,  8.96it/s] 59%|█████▉    | 631/1070 [01:12<00:49,  8.95it/s] 59%|█████▉    | 632/1070 [01:12<00:49,  8.91it/s] 59%|█████▉    | 633/1070 [01:12<00:48,  8.94it/s] 59%|█████▉    | 634/1070 [01:12<00:48,  9.00it/s] 59%|█████▉    | 635/1070 [01:12<00:48,  8.97it/s] 59%|█████▉    | 636/1070 [01:13<00:47,  9.05it/s] 60%|█████▉    | 637/1070 [01:13<00:48,  9.01it/s] 60%|█████▉    | 638/1070 [01:13<00:47,  9.02it/s] 60%|█████▉    | 639/1070 [01:13<00:48,  8.91it/s] 60%|█████▉    | 640/1070 [01:13<00:47,  8.98it/s] 60%|█████▉    | 641/1070 [01:13<00:47,  9.04it/s]                                                   60%|██████    | 642/1070 [01:13<00:47,  9.04it/s][INFO|trainer.py:755] 2023-11-15 20:12:59,793 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:12:59,795 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:12:59,796 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:12:59,796 >>   Batch size = 8
{'eval_loss': 0.3214140832424164, 'eval_accuracy': 0.9171052631578948, 'eval_micro_f1': 0.9171052631578948, 'eval_macro_f1': 0.9147650607207014, 'eval_runtime': 1.3471, 'eval_samples_per_second': 564.185, 'eval_steps_per_second': 70.523, 'epoch': 2.0}
{'loss': 0.1646, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 81.87it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 79.85it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 74.32it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 72.20it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 70.80it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 70.92it/s][A
 61%|██████    | 58/95 [00:00<00:00, 71.20it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 70.42it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 72.49it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 70.58it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 70.16it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:15<00:47,  9.04it/s]
100%|██████████| 95/95 [00:01<00:00, 70.16it/s][A
                                               [A 60%|██████    | 643/1070 [01:15<03:02,  2.33it/s] 60%|██████    | 644/1070 [01:15<02:29,  2.85it/s] 60%|██████    | 645/1070 [01:15<02:02,  3.46it/s] 60%|██████    | 646/1070 [01:15<01:41,  4.16it/s] 60%|██████    | 647/1070 [01:15<01:26,  4.89it/s] 61%|██████    | 648/1070 [01:15<01:15,  5.61it/s] 61%|██████    | 649/1070 [01:15<01:06,  6.29it/s] 61%|██████    | 650/1070 [01:15<01:01,  6.86it/s] 61%|██████    | 651/1070 [01:16<00:56,  7.37it/s] 61%|██████    | 652/1070 [01:16<00:54,  7.71it/s] 61%|██████    | 653/1070 [01:16<00:51,  8.06it/s] 61%|██████    | 654/1070 [01:16<00:50,  8.27it/s] 61%|██████    | 655/1070 [01:16<00:48,  8.50it/s] 61%|██████▏   | 656/1070 [01:16<00:47,  8.69it/s] 61%|██████▏   | 657/1070 [01:16<00:47,  8.75it/s] 61%|██████▏   | 658/1070 [01:16<00:46,  8.77it/s] 62%|██████▏   | 659/1070 [01:16<00:46,  8.79it/s] 62%|██████▏   | 660/1070 [01:17<00:46,  8.86it/s] 62%|██████▏   | 661/1070 [01:17<00:45,  8.94it/s] 62%|██████▏   | 662/1070 [01:17<00:45,  8.92it/s] 62%|██████▏   | 663/1070 [01:17<00:44,  9.06it/s] 62%|██████▏   | 664/1070 [01:17<00:44,  9.06it/s] 62%|██████▏   | 665/1070 [01:17<00:45,  9.00it/s] 62%|██████▏   | 666/1070 [01:17<00:45,  8.98it/s] 62%|██████▏   | 667/1070 [01:17<00:44,  8.99it/s] 62%|██████▏   | 668/1070 [01:17<00:44,  9.03it/s] 63%|██████▎   | 669/1070 [01:18<00:44,  8.96it/s] 63%|██████▎   | 670/1070 [01:18<00:44,  9.07it/s] 63%|██████▎   | 671/1070 [01:18<00:44,  8.96it/s] 63%|██████▎   | 672/1070 [01:18<00:44,  8.92it/s] 63%|██████▎   | 673/1070 [01:18<00:44,  8.90it/s] 63%|██████▎   | 674/1070 [01:18<00:44,  8.92it/s] 63%|██████▎   | 675/1070 [01:18<00:44,  8.96it/s] 63%|██████▎   | 676/1070 [01:18<00:43,  9.00it/s] 63%|██████▎   | 677/1070 [01:18<00:43,  9.07it/s] 63%|██████▎   | 678/1070 [01:19<00:43,  8.99it/s] 63%|██████▎   | 679/1070 [01:19<00:43,  8.91it/s] 64%|██████▎   | 680/1070 [01:19<00:44,  8.82it/s] 64%|██████▎   | 681/1070 [01:19<00:43,  8.89it/s] 64%|██████▎   | 682/1070 [01:19<00:43,  8.92it/s] 64%|██████▍   | 683/1070 [01:19<00:43,  8.81it/s] 64%|██████▍   | 684/1070 [01:19<00:43,  8.93it/s] 64%|██████▍   | 685/1070 [01:19<00:43,  8.92it/s] 64%|██████▍   | 686/1070 [01:20<00:43,  8.92it/s] 64%|██████▍   | 687/1070 [01:20<00:43,  8.89it/s] 64%|██████▍   | 688/1070 [01:20<00:42,  8.89it/s] 64%|██████▍   | 689/1070 [01:20<00:42,  8.92it/s] 64%|██████▍   | 690/1070 [01:20<00:42,  8.92it/s] 65%|██████▍   | 691/1070 [01:20<00:42,  9.01it/s] 65%|██████▍   | 692/1070 [01:20<00:42,  8.99it/s] 65%|██████▍   | 693/1070 [01:20<00:42,  8.96it/s] 65%|██████▍   | 694/1070 [01:20<00:42,  8.92it/s] 65%|██████▍   | 695/1070 [01:21<00:42,  8.91it/s] 65%|██████▌   | 696/1070 [01:21<00:42,  8.89it/s] 65%|██████▌   | 697/1070 [01:21<00:42,  8.85it/s] 65%|██████▌   | 698/1070 [01:21<00:41,  8.95it/s] 65%|██████▌   | 699/1070 [01:21<00:41,  8.94it/s] 65%|██████▌   | 700/1070 [01:21<00:41,  8.98it/s] 66%|██████▌   | 701/1070 [01:21<00:41,  8.99it/s] 66%|██████▌   | 702/1070 [01:21<00:41,  8.96it/s] 66%|██████▌   | 703/1070 [01:21<00:41,  8.89it/s] 66%|██████▌   | 704/1070 [01:22<00:41,  8.92it/s] 66%|██████▌   | 705/1070 [01:22<00:40,  9.00it/s] 66%|██████▌   | 706/1070 [01:22<00:40,  9.01it/s] 66%|██████▌   | 707/1070 [01:22<00:40,  8.99it/s] 66%|██████▌   | 708/1070 [01:22<00:40,  8.99it/s] 66%|██████▋   | 709/1070 [01:22<00:40,  8.99it/s] 66%|██████▋   | 710/1070 [01:22<00:40,  8.91it/s] 66%|██████▋   | 711/1070 [01:22<00:40,  8.90it/s] 67%|██████▋   | 712/1070 [01:22<00:40,  8.85it/s] 67%|██████▋   | 713/1070 [01:23<00:39,  8.94it/s] 67%|██████▋   | 714/1070 [01:23<00:39,  8.99it/s] 67%|██████▋   | 715/1070 [01:23<00:39,  9.01it/s] 67%|██████▋   | 716/1070 [01:23<00:39,  8.93it/s] 67%|██████▋   | 717/1070 [01:23<00:39,  8.96it/s] 67%|██████▋   | 718/1070 [01:23<00:39,  8.88it/s] 67%|██████▋   | 719/1070 [01:23<00:39,  8.89it/s] 67%|██████▋   | 720/1070 [01:23<00:39,  8.94it/s] 67%|██████▋   | 721/1070 [01:23<00:39,  8.91it/s] 67%|██████▋   | 722/1070 [01:24<00:38,  9.08it/s] 68%|██████▊   | 723/1070 [01:24<00:38,  9.00it/s] 68%|██████▊   | 724/1070 [01:24<00:38,  9.02it/s] 68%|██████▊   | 725/1070 [01:24<00:38,  8.97it/s] 68%|██████▊   | 726/1070 [01:24<00:38,  8.86it/s] 68%|██████▊   | 727/1070 [01:24<00:38,  8.87it/s] 68%|██████▊   | 728/1070 [01:24<00:38,  8.83it/s] 68%|██████▊   | 729/1070 [01:24<00:38,  8.97it/s] 68%|██████▊   | 730/1070 [01:24<00:37,  9.01it/s] 68%|██████▊   | 731/1070 [01:25<00:37,  8.93it/s] 68%|██████▊   | 732/1070 [01:25<00:37,  8.92it/s] 69%|██████▊   | 733/1070 [01:25<00:37,  8.96it/s] 69%|██████▊   | 734/1070 [01:25<00:37,  8.88it/s] 69%|██████▊   | 735/1070 [01:25<00:37,  8.90it/s] 69%|██████▉   | 736/1070 [01:25<00:37,  8.97it/s] 69%|██████▉   | 737/1070 [01:25<00:37,  8.96it/s] 69%|██████▉   | 738/1070 [01:25<00:36,  8.99it/s] 69%|██████▉   | 739/1070 [01:25<00:36,  9.03it/s] 69%|██████▉   | 740/1070 [01:26<00:36,  9.04it/s] 69%|██████▉   | 741/1070 [01:26<00:36,  8.95it/s] 69%|██████▉   | 742/1070 [01:26<00:36,  9.00it/s] 69%|██████▉   | 743/1070 [01:26<00:36,  9.04it/s] 70%|██████▉   | 744/1070 [01:26<00:35,  9.06it/s] 70%|██████▉   | 745/1070 [01:26<00:36,  9.01it/s] 70%|██████▉   | 746/1070 [01:26<00:35,  9.09it/s] 70%|██████▉   | 747/1070 [01:26<00:35,  9.03it/s] 70%|██████▉   | 748/1070 [01:26<00:35,  8.98it/s] 70%|███████   | 749/1070 [01:27<00:35,  9.02it/s] 70%|███████   | 750/1070 [01:27<00:35,  9.00it/s] 70%|███████   | 751/1070 [01:27<00:35,  9.03it/s] 70%|███████   | 752/1070 [01:27<00:34,  9.09it/s] 70%|███████   | 753/1070 [01:27<00:34,  9.17it/s] 70%|███████   | 754/1070 [01:27<00:34,  9.06it/s] 71%|███████   | 755/1070 [01:27<00:34,  9.01it/s] 71%|███████   | 756/1070 [01:27<00:35,  8.93it/s] 71%|███████   | 757/1070 [01:27<00:35,  8.91it/s] 71%|███████   | 758/1070 [01:28<00:35,  8.90it/s] 71%|███████   | 759/1070 [01:28<00:35,  8.88it/s] 71%|███████   | 760/1070 [01:28<00:34,  9.06it/s] 71%|███████   | 761/1070 [01:28<00:34,  8.94it/s] 71%|███████   | 762/1070 [01:28<00:34,  8.92it/s] 71%|███████▏  | 763/1070 [01:28<00:34,  8.90it/s] 71%|███████▏  | 764/1070 [01:28<00:34,  8.92it/s] 71%|███████▏  | 765/1070 [01:28<00:34,  8.92it/s] 72%|███████▏  | 766/1070 [01:28<00:34,  8.86it/s] 72%|███████▏  | 767/1070 [01:29<00:33,  9.03it/s] 72%|███████▏  | 768/1070 [01:29<00:33,  9.05it/s] 72%|███████▏  | 769/1070 [01:29<00:33,  9.03it/s] 72%|███████▏  | 770/1070 [01:29<00:33,  9.02it/s] 72%|███████▏  | 771/1070 [01:29<00:33,  9.01it/s] 72%|███████▏  | 772/1070 [01:29<00:33,  8.93it/s] 72%|███████▏  | 773/1070 [01:29<00:32,  9.01it/s] 72%|███████▏  | 774/1070 [01:29<00:32,  9.03it/s] 72%|███████▏  | 775/1070 [01:29<00:32,  9.01it/s] 73%|███████▎  | 776/1070 [01:30<00:32,  9.04it/s] 73%|███████▎  | 777/1070 [01:30<00:32,  9.11it/s] 73%|███████▎  | 778/1070 [01:30<00:32,  9.03it/s] 73%|███████▎  | 779/1070 [01:30<00:32,  8.97it/s] 73%|███████▎  | 780/1070 [01:30<00:32,  8.96it/s] 73%|███████▎  | 781/1070 [01:30<00:32,  8.93it/s] 73%|███████▎  | 782/1070 [01:30<00:32,  9.00it/s] 73%|███████▎  | 783/1070 [01:30<00:32,  8.87it/s] 73%|███████▎  | 784/1070 [01:30<00:31,  9.12it/s] 73%|███████▎  | 785/1070 [01:31<00:31,  9.04it/s] 73%|███████▎  | 786/1070 [01:31<00:31,  9.02it/s] 74%|███████▎  | 787/1070 [01:31<00:31,  9.02it/s] 74%|███████▎  | 788/1070 [01:31<00:31,  8.99it/s] 74%|███████▎  | 789/1070 [01:31<00:31,  8.96it/s] 74%|███████▍  | 790/1070 [01:31<00:31,  8.94it/s] 74%|███████▍  | 791/1070 [01:31<00:30,  9.05it/s] 74%|███████▍  | 792/1070 [01:31<00:30,  9.00it/s] 74%|███████▍  | 793/1070 [01:31<00:30,  8.99it/s] 74%|███████▍  | 794/1070 [01:32<00:30,  9.02it/s] 74%|███████▍  | 795/1070 [01:32<00:30,  9.02it/s] 74%|███████▍  | 796/1070 [01:32<00:30,  8.91it/s] 74%|███████▍  | 797/1070 [01:32<00:30,  8.95it/s] 75%|███████▍  | 798/1070 [01:32<00:30,  9.03it/s] 75%|███████▍  | 799/1070 [01:32<00:29,  9.05it/s] 75%|███████▍  | 800/1070 [01:32<00:29,  9.08it/s] 75%|███████▍  | 801/1070 [01:32<00:29,  9.17it/s] 75%|███████▍  | 802/1070 [01:32<00:29,  9.01it/s] 75%|███████▌  | 803/1070 [01:33<00:29,  9.03it/s] 75%|███████▌  | 804/1070 [01:33<00:29,  8.99it/s] 75%|███████▌  | 805/1070 [01:33<00:29,  8.99it/s] 75%|███████▌  | 806/1070 [01:33<00:29,  9.01it/s] 75%|███████▌  | 807/1070 [01:33<00:29,  8.90it/s] 76%|███████▌  | 808/1070 [01:33<00:28,  9.05it/s] 76%|███████▌  | 809/1070 [01:33<00:28,  9.00it/s] 76%|███████▌  | 810/1070 [01:33<00:28,  9.00it/s] 76%|███████▌  | 811/1070 [01:33<00:28,  8.99it/s] 76%|███████▌  | 812/1070 [01:34<00:28,  9.01it/s] 76%|███████▌  | 813/1070 [01:34<00:28,  8.93it/s] 76%|███████▌  | 814/1070 [01:34<00:28,  8.98it/s] 76%|███████▌  | 815/1070 [01:34<00:28,  9.04it/s] 76%|███████▋  | 816/1070 [01:34<00:28,  9.01it/s] 76%|███████▋  | 817/1070 [01:34<00:27,  9.07it/s] 76%|███████▋  | 818/1070 [01:34<00:27,  9.15it/s] 77%|███████▋  | 819/1070 [01:34<00:27,  9.00it/s] 77%|███████▋  | 820/1070 [01:34<00:27,  8.98it/s] 77%|███████▋  | 821/1070 [01:35<00:27,  9.00it/s] 77%|███████▋  | 822/1070 [01:35<00:27,  8.93it/s] 77%|███████▋  | 823/1070 [01:35<00:27,  8.95it/s] 77%|███████▋  | 824/1070 [01:35<00:27,  8.94it/s] 77%|███████▋  | 825/1070 [01:35<00:26,  9.13it/s] 77%|███████▋  | 826/1070 [01:35<00:26,  9.08it/s] 77%|███████▋  | 827/1070 [01:35<00:26,  9.05it/s] 77%|███████▋  | 828/1070 [01:35<00:26,  9.02it/s] 77%|███████▋  | 829/1070 [01:35<00:26,  9.03it/s] 78%|███████▊  | 830/1070 [01:36<00:26,  8.94it/s] 78%|███████▊  | 831/1070 [01:36<00:26,  8.97it/s] 78%|███████▊  | 832/1070 [01:36<00:26,  9.07it/s] 78%|███████▊  | 833/1070 [01:36<00:26,  9.06it/s] 78%|███████▊  | 834/1070 [01:36<00:25,  9.08it/s] 78%|███████▊  | 835/1070 [01:36<00:25,  9.13it/s] 78%|███████▊  | 836/1070 [01:36<00:25,  9.08it/s] 78%|███████▊  | 837/1070 [01:36<00:25,  9.05it/s] 78%|███████▊  | 838/1070 [01:36<00:25,  9.08it/s] 78%|███████▊  | 839/1070 [01:37<00:25,  9.05it/s] 79%|███████▊  | 840/1070 [01:37<00:25,  9.07it/s] 79%|███████▊  | 841/1070 [01:37<00:25,  9.09it/s] 79%|███████▊  | 842/1070 [01:37<00:24,  9.27it/s] 79%|███████▉  | 843/1070 [01:37<00:24,  9.22it/s] 79%|███████▉  | 844/1070 [01:37<00:24,  9.21it/s] 79%|███████▉  | 845/1070 [01:37<00:24,  9.19it/s] 79%|███████▉  | 846/1070 [01:37<00:24,  9.16it/s] 79%|███████▉  | 847/1070 [01:37<00:24,  9.06it/s] 79%|███████▉  | 848/1070 [01:38<00:24,  9.03it/s] 79%|███████▉  | 849/1070 [01:38<00:24,  9.03it/s] 79%|███████▉  | 850/1070 [01:38<00:24,  9.05it/s] 80%|███████▉  | 851/1070 [01:38<00:24,  9.02it/s] 80%|███████▉  | 852/1070 [01:38<00:23,  9.12it/s] 80%|███████▉  | 853/1070 [01:38<00:23,  9.08it/s] 80%|███████▉  | 854/1070 [01:38<00:23,  9.13it/s] 80%|███████▉  | 855/1070 [01:38<00:23,  9.18it/s]                                                   80%|████████  | 856/1070 [01:38<00:23,  9.18it/s][INFO|trainer.py:755] 2023-11-15 20:13:24,977 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:13:24,979 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:13:24,980 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:13:24,980 >>   Batch size = 8
{'eval_loss': 0.33392032980918884, 'eval_accuracy': 0.906578947368421, 'eval_micro_f1': 0.906578947368421, 'eval_macro_f1': 0.9040971058316825, 'eval_runtime': 1.3825, 'eval_samples_per_second': 549.736, 'eval_steps_per_second': 68.717, 'epoch': 3.0}
{'loss': 0.1097, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:00, 86.13it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 78.53it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 78.22it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 74.81it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 74.37it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 75.18it/s][A
 61%|██████    | 58/95 [00:00<00:00, 75.02it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 75.30it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 76.02it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 74.47it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 74.33it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:40<00:23,  9.18it/s]
100%|██████████| 95/95 [00:01<00:00, 74.33it/s][A
                                               [A 80%|████████  | 857/1070 [01:40<01:27,  2.43it/s] 80%|████████  | 858/1070 [01:40<01:11,  2.97it/s] 80%|████████  | 859/1070 [01:40<00:58,  3.60it/s] 80%|████████  | 860/1070 [01:40<00:48,  4.30it/s] 80%|████████  | 861/1070 [01:40<00:41,  5.06it/s] 81%|████████  | 862/1070 [01:40<00:35,  5.81it/s] 81%|████████  | 863/1070 [01:40<00:31,  6.54it/s] 81%|████████  | 864/1070 [01:41<00:28,  7.12it/s] 81%|████████  | 865/1070 [01:41<00:26,  7.62it/s] 81%|████████  | 866/1070 [01:41<00:25,  8.01it/s] 81%|████████  | 867/1070 [01:41<00:24,  8.34it/s] 81%|████████  | 868/1070 [01:41<00:23,  8.56it/s] 81%|████████  | 869/1070 [01:41<00:23,  8.72it/s] 81%|████████▏ | 870/1070 [01:41<00:22,  8.90it/s] 81%|████████▏ | 871/1070 [01:41<00:22,  9.03it/s] 81%|████████▏ | 872/1070 [01:41<00:21,  9.09it/s] 82%|████████▏ | 873/1070 [01:42<00:21,  9.23it/s] 82%|████████▏ | 874/1070 [01:42<00:21,  9.12it/s] 82%|████████▏ | 875/1070 [01:42<00:21,  9.10it/s] 82%|████████▏ | 876/1070 [01:42<00:21,  9.06it/s] 82%|████████▏ | 877/1070 [01:42<00:21,  9.11it/s] 82%|████████▏ | 878/1070 [01:42<00:21,  9.07it/s] 82%|████████▏ | 879/1070 [01:42<00:21,  8.93it/s] 82%|████████▏ | 880/1070 [01:42<00:21,  9.02it/s] 82%|████████▏ | 881/1070 [01:42<00:20,  9.04it/s] 82%|████████▏ | 882/1070 [01:43<00:20,  9.04it/s] 83%|████████▎ | 883/1070 [01:43<00:20,  9.15it/s] 83%|████████▎ | 884/1070 [01:43<00:20,  9.13it/s] 83%|████████▎ | 885/1070 [01:43<00:20,  9.08it/s] 83%|████████▎ | 886/1070 [01:43<00:20,  9.08it/s] 83%|████████▎ | 887/1070 [01:43<00:20,  9.10it/s] 83%|████████▎ | 888/1070 [01:43<00:20,  9.09it/s] 83%|████████▎ | 889/1070 [01:43<00:19,  9.07it/s] 83%|████████▎ | 890/1070 [01:43<00:19,  9.11it/s] 83%|████████▎ | 891/1070 [01:44<00:19,  9.12it/s] 83%|████████▎ | 892/1070 [01:44<00:19,  9.06it/s] 83%|████████▎ | 893/1070 [01:44<00:19,  8.96it/s] 84%|████████▎ | 894/1070 [01:44<00:19,  9.00it/s] 84%|████████▎ | 895/1070 [01:44<00:19,  8.99it/s] 84%|████████▎ | 896/1070 [01:44<00:19,  8.98it/s] 84%|████████▍ | 897/1070 [01:44<00:19,  9.08it/s] 84%|████████▍ | 898/1070 [01:44<00:19,  9.03it/s] 84%|████████▍ | 899/1070 [01:44<00:18,  9.06it/s] 84%|████████▍ | 900/1070 [01:45<00:18,  9.02it/s] 84%|████████▍ | 901/1070 [01:45<00:18,  9.03it/s] 84%|████████▍ | 902/1070 [01:45<00:18,  8.93it/s] 84%|████████▍ | 903/1070 [01:45<00:18,  8.95it/s] 84%|████████▍ | 904/1070 [01:45<00:18,  9.04it/s] 85%|████████▍ | 905/1070 [01:45<00:18,  9.00it/s] 85%|████████▍ | 906/1070 [01:45<00:18,  8.98it/s] 85%|████████▍ | 907/1070 [01:45<00:18,  9.00it/s] 85%|████████▍ | 908/1070 [01:45<00:17,  9.04it/s] 85%|████████▍ | 909/1070 [01:46<00:18,  8.91it/s] 85%|████████▌ | 910/1070 [01:46<00:17,  8.96it/s] 85%|████████▌ | 911/1070 [01:46<00:17,  8.93it/s] 85%|████████▌ | 912/1070 [01:46<00:17,  8.95it/s] 85%|████████▌ | 913/1070 [01:46<00:17,  8.97it/s] 85%|████████▌ | 914/1070 [01:46<00:17,  9.03it/s] 86%|████████▌ | 915/1070 [01:46<00:17,  9.03it/s] 86%|████████▌ | 916/1070 [01:46<00:17,  8.96it/s] 86%|████████▌ | 917/1070 [01:46<00:17,  8.92it/s] 86%|████████▌ | 918/1070 [01:47<00:16,  9.00it/s] 86%|████████▌ | 919/1070 [01:47<00:16,  9.03it/s] 86%|████████▌ | 920/1070 [01:47<00:16,  9.03it/s] 86%|████████▌ | 921/1070 [01:47<00:16,  9.07it/s] 86%|████████▌ | 922/1070 [01:47<00:16,  9.00it/s] 86%|████████▋ | 923/1070 [01:47<00:16,  8.96it/s] 86%|████████▋ | 924/1070 [01:47<00:16,  8.93it/s] 86%|████████▋ | 925/1070 [01:47<00:16,  8.97it/s] 87%|████████▋ | 926/1070 [01:47<00:16,  8.99it/s] 87%|████████▋ | 927/1070 [01:48<00:15,  8.96it/s] 87%|████████▋ | 928/1070 [01:48<00:15,  9.09it/s] 87%|████████▋ | 929/1070 [01:48<00:15,  8.96it/s] 87%|████████▋ | 930/1070 [01:48<00:15,  8.91it/s] 87%|████████▋ | 931/1070 [01:48<00:15,  8.92it/s] 87%|████████▋ | 932/1070 [01:48<00:15,  8.91it/s] 87%|████████▋ | 933/1070 [01:48<00:15,  8.94it/s] 87%|████████▋ | 934/1070 [01:48<00:15,  9.00it/s] 87%|████████▋ | 935/1070 [01:48<00:14,  9.12it/s] 87%|████████▋ | 936/1070 [01:49<00:14,  9.02it/s] 88%|████████▊ | 937/1070 [01:49<00:14,  9.03it/s] 88%|████████▊ | 938/1070 [01:49<00:14,  8.87it/s] 88%|████████▊ | 939/1070 [01:49<00:14,  8.89it/s] 88%|████████▊ | 940/1070 [01:49<00:14,  8.91it/s] 88%|████████▊ | 941/1070 [01:49<00:14,  8.91it/s] 88%|████████▊ | 942/1070 [01:49<00:14,  9.11it/s] 88%|████████▊ | 943/1070 [01:49<00:14,  8.96it/s] 88%|████████▊ | 944/1070 [01:49<00:14,  8.94it/s] 88%|████████▊ | 945/1070 [01:50<00:13,  8.95it/s] 88%|████████▊ | 946/1070 [01:50<00:13,  8.94it/s] 89%|████████▊ | 947/1070 [01:50<00:13,  8.90it/s] 89%|████████▊ | 948/1070 [01:50<00:13,  8.91it/s] 89%|████████▊ | 949/1070 [01:50<00:13,  9.03it/s] 89%|████████▉ | 950/1070 [01:50<00:13,  9.03it/s] 89%|████████▉ | 951/1070 [01:50<00:13,  9.02it/s] 89%|████████▉ | 952/1070 [01:50<00:13,  9.03it/s] 89%|████████▉ | 953/1070 [01:50<00:12,  9.02it/s] 89%|████████▉ | 954/1070 [01:51<00:12,  8.96it/s] 89%|████████▉ | 955/1070 [01:51<00:12,  8.90it/s] 89%|████████▉ | 956/1070 [01:51<00:12,  8.98it/s] 89%|████████▉ | 957/1070 [01:51<00:12,  9.02it/s] 90%|████████▉ | 958/1070 [01:51<00:12,  9.00it/s] 90%|████████▉ | 959/1070 [01:51<00:12,  9.02it/s] 90%|████████▉ | 960/1070 [01:51<00:12,  9.04it/s] 90%|████████▉ | 961/1070 [01:51<00:12,  8.94it/s] 90%|████████▉ | 962/1070 [01:51<00:12,  8.98it/s] 90%|█████████ | 963/1070 [01:52<00:11,  9.02it/s] 90%|█████████ | 964/1070 [01:52<00:11,  9.01it/s] 90%|█████████ | 965/1070 [01:52<00:11,  8.94it/s] 90%|█████████ | 966/1070 [01:52<00:11,  9.09it/s] 90%|█████████ | 967/1070 [01:52<00:11,  9.05it/s] 90%|█████████ | 968/1070 [01:52<00:11,  9.02it/s] 91%|█████████ | 969/1070 [01:52<00:11,  9.03it/s] 91%|█████████ | 970/1070 [01:52<00:11,  8.97it/s] 91%|█████████ | 971/1070 [01:52<00:10,  9.05it/s] 91%|█████████ | 972/1070 [01:53<00:10,  9.01it/s] 91%|█████████ | 973/1070 [01:53<00:10,  9.19it/s] 91%|█████████ | 974/1070 [01:53<00:10,  9.09it/s] 91%|█████████ | 975/1070 [01:53<00:10,  9.10it/s] 91%|█████████ | 976/1070 [01:53<00:10,  9.07it/s] 91%|█████████▏| 977/1070 [01:53<00:10,  9.11it/s] 91%|█████████▏| 978/1070 [01:53<00:10,  9.03it/s] 91%|█████████▏| 979/1070 [01:53<00:10,  9.06it/s] 92%|█████████▏| 980/1070 [01:53<00:09,  9.13it/s] 92%|█████████▏| 981/1070 [01:54<00:09,  9.15it/s] 92%|█████████▏| 982/1070 [01:54<00:09,  9.22it/s] 92%|█████████▏| 983/1070 [01:54<00:09,  9.30it/s] 92%|█████████▏| 984/1070 [01:54<00:09,  9.13it/s] 92%|█████████▏| 985/1070 [01:54<00:09,  9.14it/s] 92%|█████████▏| 986/1070 [01:54<00:09,  9.10it/s] 92%|█████████▏| 987/1070 [01:54<00:09,  9.10it/s] 92%|█████████▏| 988/1070 [01:54<00:09,  9.07it/s] 92%|█████████▏| 989/1070 [01:54<00:08,  9.06it/s] 93%|█████████▎| 990/1070 [01:55<00:08,  9.11it/s] 93%|█████████▎| 991/1070 [01:55<00:08,  9.12it/s] 93%|█████████▎| 992/1070 [01:55<00:08,  9.13it/s] 93%|█████████▎| 993/1070 [01:55<00:08,  9.28it/s] 93%|█████████▎| 994/1070 [01:55<00:08,  9.12it/s] 93%|█████████▎| 995/1070 [01:55<00:08,  9.16it/s] 93%|█████████▎| 996/1070 [01:55<00:08,  9.12it/s] 93%|█████████▎| 997/1070 [01:55<00:08,  9.11it/s] 93%|█████████▎| 998/1070 [01:55<00:07,  9.11it/s] 93%|█████████▎| 999/1070 [01:56<00:07,  9.08it/s] 93%|█████████▎| 1000/1070 [01:56<00:07,  9.15it/s] 94%|█████████▎| 1001/1070 [01:56<00:07,  9.17it/s] 94%|█████████▎| 1002/1070 [01:56<00:07,  9.14it/s] 94%|█████████▎| 1003/1070 [01:56<00:07,  9.23it/s] 94%|█████████▍| 1004/1070 [01:56<00:07,  9.14it/s] 94%|█████████▍| 1005/1070 [01:56<00:07,  9.01it/s] 94%|█████████▍| 1006/1070 [01:56<00:07,  9.02it/s] 94%|█████████▍| 1007/1070 [01:56<00:06,  9.03it/s] 94%|█████████▍| 1008/1070 [01:56<00:06,  9.06it/s] 94%|█████████▍| 1009/1070 [01:57<00:06,  9.04it/s] 94%|█████████▍| 1010/1070 [01:57<00:06,  9.13it/s] 94%|█████████▍| 1011/1070 [01:57<00:06,  9.12it/s] 95%|█████████▍| 1012/1070 [01:57<00:06,  9.15it/s] 95%|█████████▍| 1013/1070 [01:57<00:06,  9.19it/s] 95%|█████████▍| 1014/1070 [01:57<00:06,  9.12it/s] 95%|█████████▍| 1015/1070 [01:57<00:06,  9.08it/s] 95%|█████████▍| 1016/1070 [01:57<00:05,  9.07it/s] 95%|█████████▌| 1017/1070 [01:57<00:05,  9.04it/s] 95%|█████████▌| 1018/1070 [01:58<00:05,  9.08it/s] 95%|█████████▌| 1019/1070 [01:58<00:05,  9.03it/s] 95%|█████████▌| 1020/1070 [01:58<00:05,  9.20it/s] 95%|█████████▌| 1021/1070 [01:58<00:05,  9.16it/s] 96%|█████████▌| 1022/1070 [01:58<00:05,  9.12it/s] 96%|█████████▌| 1023/1070 [01:58<00:05,  9.12it/s] 96%|█████████▌| 1024/1070 [01:58<00:05,  9.11it/s] 96%|█████████▌| 1025/1070 [01:58<00:04,  9.03it/s] 96%|█████████▌| 1026/1070 [01:58<00:04,  9.05it/s] 96%|█████████▌| 1027/1070 [01:59<00:04,  9.03it/s] 96%|█████████▌| 1028/1070 [01:59<00:04,  9.04it/s] 96%|█████████▌| 1029/1070 [01:59<00:04,  9.04it/s] 96%|█████████▋| 1030/1070 [01:59<00:04,  9.18it/s] 96%|█████████▋| 1031/1070 [01:59<00:04,  9.07it/s] 96%|█████████▋| 1032/1070 [01:59<00:04,  9.13it/s] 97%|█████████▋| 1033/1070 [01:59<00:04,  9.08it/s] 97%|█████████▋| 1034/1070 [01:59<00:03,  9.12it/s] 97%|█████████▋| 1035/1070 [01:59<00:03,  9.04it/s] 97%|█████████▋| 1036/1070 [02:00<00:03,  9.04it/s] 97%|█████████▋| 1037/1070 [02:00<00:03,  9.05it/s] 97%|█████████▋| 1038/1070 [02:00<00:03,  9.08it/s] 97%|█████████▋| 1039/1070 [02:00<00:03,  9.16it/s] 97%|█████████▋| 1040/1070 [02:00<00:03,  9.28it/s] 97%|█████████▋| 1041/1070 [02:00<00:03,  9.15it/s] 97%|█████████▋| 1042/1070 [02:00<00:03,  9.14it/s] 97%|█████████▋| 1043/1070 [02:00<00:02,  9.10it/s] 98%|█████████▊| 1044/1070 [02:00<00:02,  9.12it/s] 98%|█████████▊| 1045/1070 [02:01<00:02,  9.06it/s] 98%|█████████▊| 1046/1070 [02:01<00:02,  9.06it/s] 98%|█████████▊| 1047/1070 [02:01<00:02,  9.11it/s] 98%|█████████▊| 1048/1070 [02:01<00:02,  9.16it/s] 98%|█████████▊| 1049/1070 [02:01<00:02,  9.13it/s] 98%|█████████▊| 1050/1070 [02:01<00:02,  9.19it/s] 98%|█████████▊| 1051/1070 [02:01<00:02,  9.06it/s] 98%|█████████▊| 1052/1070 [02:01<00:01,  9.09it/s] 98%|█████████▊| 1053/1070 [02:01<00:01,  9.09it/s] 99%|█████████▊| 1054/1070 [02:02<00:01,  9.10it/s] 99%|█████████▊| 1055/1070 [02:02<00:01,  9.10it/s] 99%|█████████▊| 1056/1070 [02:02<00:01,  9.05it/s] 99%|█████████▉| 1057/1070 [02:02<00:01,  9.08it/s] 99%|█████████▉| 1058/1070 [02:02<00:01,  9.10it/s] 99%|█████████▉| 1059/1070 [02:02<00:01,  9.11it/s] 99%|█████████▉| 1060/1070 [02:02<00:01,  9.19it/s] 99%|█████████▉| 1061/1070 [02:02<00:00,  9.15it/s] 99%|█████████▉| 1062/1070 [02:02<00:00,  9.11it/s] 99%|█████████▉| 1063/1070 [02:03<00:00,  9.09it/s] 99%|█████████▉| 1064/1070 [02:03<00:00,  9.11it/s]100%|█████████▉| 1065/1070 [02:03<00:00,  9.15it/s]100%|█████████▉| 1066/1070 [02:03<00:00,  9.07it/s]100%|█████████▉| 1067/1070 [02:03<00:00,  9.18it/s]100%|█████████▉| 1068/1070 [02:03<00:00,  9.16it/s]100%|█████████▉| 1069/1070 [02:03<00:00,  9.18it/s]                                                   100%|██████████| 1070/1070 [02:03<00:00,  9.18it/s][INFO|trainer.py:755] 2023-11-15 20:13:49,885 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:13:49,887 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:13:49,888 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:13:49,888 >>   Batch size = 8
{'eval_loss': 0.3680191934108734, 'eval_accuracy': 0.9039473684210526, 'eval_micro_f1': 0.9039473684210526, 'eval_macro_f1': 0.9014715611278126, 'eval_runtime': 1.3183, 'eval_samples_per_second': 576.489, 'eval_steps_per_second': 72.061, 'epoch': 4.0}
{'loss': 0.077, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 76.57it/s][A
 18%|█▊        | 17/95 [00:00<00:01, 76.28it/s][A
 26%|██▋       | 25/95 [00:00<00:00, 76.20it/s][A
 35%|███▍      | 33/95 [00:00<00:00, 74.99it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 74.81it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 73.31it/s][A
 61%|██████    | 58/95 [00:00<00:00, 74.90it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 74.65it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 74.61it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 74.91it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 73.97it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:05<00:00,  9.18it/s]
100%|██████████| 95/95 [00:01<00:00, 73.97it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 20:13:51,208 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:05<00:00,  9.18it/s]100%|██████████| 1070/1070 [02:05<00:00,  8.55it/s]
[INFO|trainer.py:2855] 2023-11-15 20:13:51,211 >> Saving model checkpoint to ./result/agnews_sup_roberta-base_adapter__seed1
[INFO|configuration_utils.py:460] 2023-11-15 20:13:51,214 >> Configuration saved in ./result/agnews_sup_roberta-base_adapter__seed1/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:13:52,665 >> Model weights saved in ./result/agnews_sup_roberta-base_adapter__seed1/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:13:52,668 >> tokenizer config file saved in ./result/agnews_sup_roberta-base_adapter__seed1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:13:52,670 >> Special tokens file saved in ./result/agnews_sup_roberta-base_adapter__seed1/special_tokens_map.json
{'eval_loss': 0.37937164306640625, 'eval_accuracy': 0.906578947368421, 'eval_micro_f1': 0.906578947368421, 'eval_macro_f1': 0.9041437658360563, 'eval_runtime': 1.3154, 'eval_samples_per_second': 577.778, 'eval_steps_per_second': 72.222, 'epoch': 5.0}
{'train_runtime': 125.1168, 'train_samples_per_second': 273.345, 'train_steps_per_second': 8.552, 'train_loss': 0.20538091035646813, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2054
  train_runtime            = 0:02:05.11
  train_samples            =       6840
  train_samples_per_second =    273.345
  train_steps_per_second   =      8.552
11/15/2023 20:13:52 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:13:52,786 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:13:52,788 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:13:52,788 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:13:52,788 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  9%|▉         | 9/95 [00:00<00:00, 86.50it/s] 19%|█▉        | 18/95 [00:00<00:00, 79.30it/s] 27%|██▋       | 26/95 [00:00<00:00, 77.38it/s] 36%|███▌      | 34/95 [00:00<00:00, 77.16it/s] 44%|████▍     | 42/95 [00:00<00:00, 75.34it/s] 53%|█████▎    | 50/95 [00:00<00:00, 73.73it/s] 61%|██████    | 58/95 [00:00<00:00, 73.09it/s] 69%|██████▉   | 66/95 [00:00<00:00, 73.26it/s] 78%|███████▊  | 74/95 [00:00<00:00, 74.54it/s] 86%|████████▋ | 82/95 [00:01<00:00, 73.98it/s] 95%|█████████▍| 90/95 [00:01<00:00, 75.52it/s]100%|██████████| 95/95 [00:01<00:00, 73.13it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9066
  eval_loss               =     0.3794
  eval_macro_f1           =     0.9041
  eval_micro_f1           =     0.9066
  eval_runtime            = 0:00:01.31
  eval_samples            =        760
  eval_samples_per_second =    575.845
  eval_steps_per_second   =     71.981
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▂█▂▁▂▂
wandb:                      eval/loss ▁▃▄▇██
wandb:                  eval/macro_f1 ▂█▂▁▂▂
wandb:                  eval/micro_f1 ▂█▂▁▂▂
wandb:                   eval/runtime ▁▅█▃▃▃
wandb:        eval/samples_per_second █▄▁▆▆▆
wandb:          eval/steps_per_second █▄▁▆▆▆
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.90658
wandb:                      eval/loss 0.37937
wandb:                  eval/macro_f1 0.90414
wandb:                  eval/micro_f1 0.90658
wandb:                   eval/runtime 1.3198
wandb:        eval/samples_per_second 575.845
wandb:          eval/steps_per_second 71.981
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.077
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.20538
wandb:            train/train_runtime 125.1168
wandb: train/train_samples_per_second 273.345
wandb:   train/train_steps_per_second 8.552
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_201027-4j1w1ngk
wandb: Find logs at: ./wandb/offline-run-20231115_201027-4j1w1ngk/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_bert-base-cased_adapter__seed1/runs/Nov15_20-14-06_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_bert-base-cased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_bert-base-cased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:14:06 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:14:06 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_bert-base-cased_adapter__seed1/runs/Nov15_20-14-05_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_bert-base-cased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_bert-base-cased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 20:14:22,386 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:14:22,399 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 20:14:32,417 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:14:32,418 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:14:32,421 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:14:32,422 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:14:32,422 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:14:32,422 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:14:32,423 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 20:14:32,424 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:14:32,424 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:14:52,585 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:14:53,237 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:14:53,238 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  44%|████▍     | 3000/6840 [00:00<00:00, 21483.47 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 22270.95 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 21981.14 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 24742.28 examples/s]
11/15/2023 20:14:53 - INFO - __main__ - Sample 6380 of the training set: {'text': 'Mich. Elephant Gets Therapy for Arthritis ROYAL OAK, Mich. - Like any patient, Wanda needs positive reinforcement to wrestle through her physical therapy...', 'label': 3, 'input_ids': [101, 12107, 1732, 119, 21071, 3949, 1116, 23789, 1111, 2051, 8167, 10721, 155, 2346, 3663, 12507, 152, 1592, 2428, 117, 12107, 1732, 119, 118, 2409, 1251, 5351, 117, 23008, 2993, 3112, 21293, 1880, 1106, 192, 22713, 1194, 1123, 2952, 7606, 119, 119, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:14:53 - INFO - __main__ - Sample 883 of the training set: {'text': "Chicago to Hold EBay Auction to Raise Money for Cultural Programs City officials hope there are people willing to pay plenty of money to own a vintage Playboy Bunny costume, toss green dye into the Chicago River or throw a dinner party prepared by Oprah Winfrey's chef.", 'label': 2, 'input_ids': [101, 2290, 1106, 10860, 142, 2064, 4164, 27758, 5796, 1106, 20089, 2217, 8948, 1111, 6651, 18555, 1392, 3878, 2810, 1175, 1132, 1234, 4988, 1106, 2653, 7722, 1104, 1948, 1106, 1319, 170, 17787, 24071, 21198, 10220, 117, 10234, 2448, 23966, 1154, 1103, 2290, 1595, 1137, 4932, 170, 4014, 1710, 4029, 1118, 9126, 10659, 16387, 24740, 112, 188, 13628, 119, 102, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]}.
11/15/2023 20:14:53 - INFO - __main__ - Sample 1927 of the training set: {'text': 'Astros 10, Pirates 5 HOUSTON Mike Lamb went four-for-five with a homer and four RB-Is to lead the Houston Astros to their ninth straight win with a 10-to-five victory over the Pittsburgh Pirates today.', 'label': 0, 'input_ids': [101, 24462, 1275, 117, 11286, 126, 145, 2346, 13329, 18082, 2249, 2639, 16978, 1355, 1300, 118, 1111, 118, 1421, 1114, 170, 1313, 1197, 1105, 1300, 24718, 118, 2181, 1106, 1730, 1103, 4666, 24462, 1106, 1147, 6948, 2632, 1782, 1114, 170, 1275, 118, 1106, 118, 1421, 2681, 1166, 1103, 5610, 11286, 2052, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:14:53 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:14:55,214 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:14:55,222 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:14:55,222 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 20:14:55,223 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:14:55,223 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:14:55,223 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:14:55,224 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:14:55,224 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 20:14:55,225 >>   Number of trainable parameters = 108,313,348
[INFO|integration_utils.py:716] 2023-11-15 20:14:55,226 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<23:34,  1.32s/it]  0%|          | 2/1070 [00:01<10:49,  1.64it/s]  0%|          | 3/1070 [00:01<06:45,  2.63it/s]  0%|          | 4/1070 [00:01<04:51,  3.66it/s]  0%|          | 5/1070 [00:01<03:48,  4.66it/s]  1%|          | 6/1070 [00:01<03:08,  5.63it/s]  1%|          | 7/1070 [00:01<02:44,  6.46it/s]  1%|          | 8/1070 [00:02<02:28,  7.13it/s]  1%|          | 9/1070 [00:02<02:17,  7.71it/s]  1%|          | 10/1070 [00:02<02:10,  8.14it/s]  1%|          | 11/1070 [00:02<02:06,  8.40it/s]  1%|          | 12/1070 [00:02<02:03,  8.57it/s]  1%|          | 13/1070 [00:02<02:00,  8.77it/s]  1%|▏         | 14/1070 [00:02<01:58,  8.94it/s]  1%|▏         | 15/1070 [00:02<01:57,  9.00it/s]  1%|▏         | 16/1070 [00:02<01:54,  9.22it/s]  2%|▏         | 17/1070 [00:03<01:54,  9.21it/s]  2%|▏         | 18/1070 [00:03<01:55,  9.12it/s]  2%|▏         | 19/1070 [00:03<01:55,  9.10it/s]  2%|▏         | 20/1070 [00:03<01:55,  9.11it/s]  2%|▏         | 21/1070 [00:03<01:54,  9.18it/s]  2%|▏         | 22/1070 [00:03<01:54,  9.18it/s]  2%|▏         | 23/1070 [00:03<01:52,  9.34it/s]  2%|▏         | 24/1070 [00:03<01:54,  9.10it/s]  2%|▏         | 25/1070 [00:03<01:55,  9.08it/s]  2%|▏         | 26/1070 [00:04<01:54,  9.10it/s]  3%|▎         | 27/1070 [00:04<01:53,  9.18it/s]  3%|▎         | 28/1070 [00:04<01:54,  9.07it/s]  3%|▎         | 29/1070 [00:04<01:54,  9.06it/s]  3%|▎         | 30/1070 [00:04<01:54,  9.08it/s]  3%|▎         | 31/1070 [00:04<01:53,  9.16it/s]  3%|▎         | 32/1070 [00:04<01:52,  9.19it/s]  3%|▎         | 33/1070 [00:04<01:51,  9.27it/s]  3%|▎         | 34/1070 [00:04<01:52,  9.21it/s]  3%|▎         | 35/1070 [00:05<01:53,  9.11it/s]  3%|▎         | 36/1070 [00:05<01:53,  9.13it/s]  3%|▎         | 37/1070 [00:05<01:53,  9.11it/s]  4%|▎         | 38/1070 [00:05<01:53,  9.13it/s]  4%|▎         | 39/1070 [00:05<01:53,  9.11it/s]  4%|▎         | 40/1070 [00:05<01:51,  9.27it/s]  4%|▍         | 41/1070 [00:05<01:52,  9.13it/s]  4%|▍         | 42/1070 [00:05<01:53,  9.10it/s]  4%|▍         | 43/1070 [00:05<01:53,  9.06it/s]  4%|▍         | 44/1070 [00:06<01:52,  9.09it/s]  4%|▍         | 45/1070 [00:06<01:53,  9.05it/s]  4%|▍         | 46/1070 [00:06<01:54,  8.92it/s]  4%|▍         | 47/1070 [00:06<01:51,  9.17it/s]  4%|▍         | 48/1070 [00:06<01:51,  9.14it/s]  5%|▍         | 49/1070 [00:06<01:51,  9.12it/s]  5%|▍         | 50/1070 [00:06<01:52,  9.10it/s]  5%|▍         | 51/1070 [00:06<01:52,  9.06it/s]  5%|▍         | 52/1070 [00:06<01:51,  9.10it/s]  5%|▍         | 53/1070 [00:07<01:53,  9.00it/s]  5%|▌         | 54/1070 [00:07<01:51,  9.12it/s]  5%|▌         | 55/1070 [00:07<01:52,  9.04it/s]  5%|▌         | 56/1070 [00:07<01:51,  9.08it/s]  5%|▌         | 57/1070 [00:07<01:51,  9.05it/s]  5%|▌         | 58/1070 [00:07<01:52,  9.01it/s]  6%|▌         | 59/1070 [00:07<01:51,  9.07it/s]  6%|▌         | 60/1070 [00:07<01:51,  9.04it/s]  6%|▌         | 61/1070 [00:07<01:49,  9.22it/s]  6%|▌         | 62/1070 [00:07<01:50,  9.13it/s]  6%|▌         | 63/1070 [00:08<01:50,  9.08it/s]  6%|▌         | 64/1070 [00:08<01:50,  9.11it/s]  6%|▌         | 65/1070 [00:08<01:50,  9.05it/s]  6%|▌         | 66/1070 [00:08<01:50,  9.09it/s]  6%|▋         | 67/1070 [00:08<01:51,  9.01it/s]  6%|▋         | 68/1070 [00:08<01:48,  9.21it/s]  6%|▋         | 69/1070 [00:08<01:49,  9.14it/s]  7%|▋         | 70/1070 [00:08<01:49,  9.13it/s]  7%|▋         | 71/1070 [00:08<01:50,  9.06it/s]  7%|▋         | 72/1070 [00:09<01:49,  9.14it/s]  7%|▋         | 73/1070 [00:09<01:48,  9.15it/s]  7%|▋         | 74/1070 [00:09<01:48,  9.16it/s]  7%|▋         | 75/1070 [00:09<01:46,  9.31it/s]  7%|▋         | 76/1070 [00:09<01:49,  9.10it/s]  7%|▋         | 77/1070 [00:09<01:48,  9.12it/s]  7%|▋         | 78/1070 [00:09<01:48,  9.12it/s]  7%|▋         | 79/1070 [00:09<01:49,  9.07it/s]  7%|▋         | 80/1070 [00:09<01:48,  9.11it/s]  8%|▊         | 81/1070 [00:10<01:48,  9.11it/s]  8%|▊         | 82/1070 [00:10<01:46,  9.26it/s]  8%|▊         | 83/1070 [00:10<01:48,  9.12it/s]  8%|▊         | 84/1070 [00:10<01:48,  9.05it/s]  8%|▊         | 85/1070 [00:10<01:48,  9.08it/s]  8%|▊         | 86/1070 [00:10<01:48,  9.11it/s]  8%|▊         | 87/1070 [00:10<01:47,  9.18it/s]  8%|▊         | 88/1070 [00:10<01:47,  9.15it/s]  8%|▊         | 89/1070 [00:10<01:45,  9.32it/s]  8%|▊         | 90/1070 [00:11<01:46,  9.20it/s]  9%|▊         | 91/1070 [00:11<01:46,  9.19it/s]  9%|▊         | 92/1070 [00:11<01:46,  9.15it/s]  9%|▊         | 93/1070 [00:11<01:45,  9.25it/s]  9%|▉         | 94/1070 [00:11<01:45,  9.25it/s]  9%|▉         | 95/1070 [00:11<01:45,  9.21it/s]  9%|▉         | 96/1070 [00:11<01:45,  9.24it/s]  9%|▉         | 97/1070 [00:11<01:45,  9.24it/s]  9%|▉         | 98/1070 [00:11<01:46,  9.13it/s]  9%|▉         | 99/1070 [00:12<01:46,  9.15it/s]  9%|▉         | 100/1070 [00:12<01:45,  9.15it/s]  9%|▉         | 101/1070 [00:12<01:45,  9.22it/s] 10%|▉         | 102/1070 [00:12<01:44,  9.24it/s] 10%|▉         | 103/1070 [00:12<01:44,  9.24it/s] 10%|▉         | 104/1070 [00:12<01:45,  9.15it/s] 10%|▉         | 105/1070 [00:12<01:46,  9.09it/s] 10%|▉         | 106/1070 [00:12<01:46,  9.08it/s] 10%|█         | 107/1070 [00:12<01:45,  9.11it/s] 10%|█         | 108/1070 [00:13<01:45,  9.13it/s] 10%|█         | 109/1070 [00:13<01:44,  9.21it/s] 10%|█         | 110/1070 [00:13<01:44,  9.19it/s] 10%|█         | 111/1070 [00:13<01:44,  9.18it/s] 10%|█         | 112/1070 [00:13<01:45,  9.10it/s] 11%|█         | 113/1070 [00:13<01:45,  9.11it/s] 11%|█         | 114/1070 [00:13<01:44,  9.15it/s] 11%|█         | 115/1070 [00:13<01:43,  9.22it/s] 11%|█         | 116/1070 [00:13<01:42,  9.27it/s] 11%|█         | 117/1070 [00:13<01:42,  9.25it/s] 11%|█         | 118/1070 [00:14<01:42,  9.29it/s] 11%|█         | 119/1070 [00:14<01:43,  9.16it/s] 11%|█         | 120/1070 [00:14<01:43,  9.18it/s] 11%|█▏        | 121/1070 [00:14<01:43,  9.20it/s] 11%|█▏        | 122/1070 [00:14<01:43,  9.20it/s] 11%|█▏        | 123/1070 [00:14<01:41,  9.30it/s] 12%|█▏        | 124/1070 [00:14<01:41,  9.31it/s] 12%|█▏        | 125/1070 [00:14<01:43,  9.15it/s] 12%|█▏        | 126/1070 [00:14<01:42,  9.21it/s] 12%|█▏        | 127/1070 [00:15<01:42,  9.17it/s] 12%|█▏        | 128/1070 [00:15<01:43,  9.12it/s] 12%|█▏        | 129/1070 [00:15<01:42,  9.16it/s] 12%|█▏        | 130/1070 [00:15<01:44,  9.04it/s] 12%|█▏        | 131/1070 [00:15<01:41,  9.25it/s] 12%|█▏        | 132/1070 [00:15<01:41,  9.24it/s] 12%|█▏        | 133/1070 [00:15<01:41,  9.24it/s] 13%|█▎        | 134/1070 [00:15<01:41,  9.24it/s] 13%|█▎        | 135/1070 [00:15<01:41,  9.21it/s] 13%|█▎        | 136/1070 [00:16<01:42,  9.09it/s] 13%|█▎        | 137/1070 [00:16<01:42,  9.07it/s] 13%|█▎        | 138/1070 [00:16<01:42,  9.12it/s] 13%|█▎        | 139/1070 [00:16<01:41,  9.16it/s] 13%|█▎        | 140/1070 [00:16<01:42,  9.10it/s] 13%|█▎        | 141/1070 [00:16<01:40,  9.25it/s] 13%|█▎        | 142/1070 [00:16<01:41,  9.15it/s] 13%|█▎        | 143/1070 [00:16<01:41,  9.15it/s] 13%|█▎        | 144/1070 [00:16<01:42,  9.05it/s] 14%|█▎        | 145/1070 [00:17<01:41,  9.09it/s] 14%|█▎        | 146/1070 [00:17<01:41,  9.14it/s] 14%|█▎        | 147/1070 [00:17<01:41,  9.07it/s] 14%|█▍        | 148/1070 [00:17<01:39,  9.23it/s] 14%|█▍        | 149/1070 [00:17<01:39,  9.23it/s] 14%|█▍        | 150/1070 [00:17<01:39,  9.22it/s] 14%|█▍        | 151/1070 [00:17<01:40,  9.14it/s] 14%|█▍        | 152/1070 [00:17<01:40,  9.13it/s] 14%|█▍        | 153/1070 [00:17<01:40,  9.09it/s] 14%|█▍        | 154/1070 [00:18<01:41,  9.05it/s] 14%|█▍        | 155/1070 [00:18<01:40,  9.11it/s] 15%|█▍        | 156/1070 [00:18<01:40,  9.14it/s] 15%|█▍        | 157/1070 [00:18<01:39,  9.13it/s] 15%|█▍        | 158/1070 [00:18<01:39,  9.16it/s] 15%|█▍        | 159/1070 [00:18<01:39,  9.13it/s] 15%|█▍        | 160/1070 [00:18<01:41,  8.97it/s] 15%|█▌        | 161/1070 [00:18<01:40,  9.01it/s] 15%|█▌        | 162/1070 [00:18<01:40,  9.05it/s] 15%|█▌        | 163/1070 [00:19<01:40,  9.00it/s] 15%|█▌        | 164/1070 [00:19<01:39,  9.07it/s] 15%|█▌        | 165/1070 [00:19<01:40,  9.03it/s] 16%|█▌        | 166/1070 [00:19<01:40,  9.03it/s] 16%|█▌        | 167/1070 [00:19<01:40,  8.94it/s] 16%|█▌        | 168/1070 [00:19<01:40,  8.94it/s] 16%|█▌        | 169/1070 [00:19<01:40,  9.01it/s] 16%|█▌        | 170/1070 [00:19<01:39,  9.01it/s] 16%|█▌        | 171/1070 [00:19<01:40,  8.98it/s] 16%|█▌        | 172/1070 [00:20<01:39,  8.99it/s] 16%|█▌        | 173/1070 [00:20<01:39,  9.04it/s] 16%|█▋        | 174/1070 [00:20<01:39,  9.03it/s] 16%|█▋        | 175/1070 [00:20<01:39,  9.03it/s] 16%|█▋        | 176/1070 [00:20<01:37,  9.16it/s] 17%|█▋        | 177/1070 [00:20<01:37,  9.17it/s] 17%|█▋        | 178/1070 [00:20<01:37,  9.12it/s] 17%|█▋        | 179/1070 [00:20<01:38,  9.06it/s] 17%|█▋        | 180/1070 [00:20<01:38,  9.05it/s] 17%|█▋        | 181/1070 [00:21<01:38,  9.05it/s] 17%|█▋        | 182/1070 [00:21<01:38,  8.98it/s] 17%|█▋        | 183/1070 [00:21<01:36,  9.16it/s] 17%|█▋        | 184/1070 [00:21<01:36,  9.15it/s] 17%|█▋        | 185/1070 [00:21<01:37,  9.09it/s] 17%|█▋        | 186/1070 [00:21<01:38,  9.00it/s] 17%|█▋        | 187/1070 [00:21<01:37,  9.02it/s] 18%|█▊        | 188/1070 [00:21<01:37,  9.04it/s] 18%|█▊        | 189/1070 [00:21<01:37,  9.00it/s] 18%|█▊        | 190/1070 [00:22<01:36,  9.17it/s] 18%|█▊        | 191/1070 [00:22<01:36,  9.12it/s] 18%|█▊        | 192/1070 [00:22<01:36,  9.09it/s] 18%|█▊        | 193/1070 [00:22<01:37,  9.04it/s] 18%|█▊        | 194/1070 [00:22<01:36,  9.06it/s] 18%|█▊        | 195/1070 [00:22<01:36,  9.02it/s] 18%|█▊        | 196/1070 [00:22<01:37,  9.00it/s] 18%|█▊        | 197/1070 [00:22<01:35,  9.13it/s] 19%|█▊        | 198/1070 [00:22<01:35,  9.16it/s] 19%|█▊        | 199/1070 [00:23<01:34,  9.17it/s] 19%|█▊        | 200/1070 [00:23<01:35,  9.08it/s] 19%|█▉        | 201/1070 [00:23<01:35,  9.11it/s] 19%|█▉        | 202/1070 [00:23<01:35,  9.10it/s] 19%|█▉        | 203/1070 [00:23<01:36,  8.96it/s] 19%|█▉        | 204/1070 [00:23<01:34,  9.12it/s] 19%|█▉        | 205/1070 [00:23<01:35,  9.05it/s] 19%|█▉        | 206/1070 [00:23<01:34,  9.10it/s] 19%|█▉        | 207/1070 [00:23<01:36,  8.97it/s] 19%|█▉        | 208/1070 [00:23<01:35,  9.02it/s] 20%|█▉        | 209/1070 [00:24<01:35,  9.06it/s] 20%|█▉        | 210/1070 [00:24<01:35,  9.03it/s] 20%|█▉        | 211/1070 [00:24<01:34,  9.14it/s] 20%|█▉        | 212/1070 [00:24<01:34,  9.10it/s] 20%|█▉        | 213/1070 [00:24<01:34,  9.11it/s]                                                   20%|██        | 214/1070 [00:24<01:33,  9.11it/s][INFO|trainer.py:755] 2023-11-15 20:15:19,876 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:15:19,878 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:15:19,878 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:15:19,879 >>   Batch size = 8
{'loss': 0.4846, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 82.12it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 72.72it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 72.56it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 73.83it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 73.72it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 73.29it/s][A
 61%|██████    | 58/95 [00:00<00:00, 73.38it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 73.10it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 70.47it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 70.59it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 70.93it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:26<01:33,  9.11it/s]
100%|██████████| 95/95 [00:01<00:00, 70.93it/s][A
                                               [A 20%|██        | 215/1070 [00:26<06:01,  2.37it/s] 20%|██        | 216/1070 [00:26<04:54,  2.90it/s] 20%|██        | 217/1070 [00:26<04:02,  3.52it/s] 20%|██        | 218/1070 [00:26<03:23,  4.20it/s] 20%|██        | 219/1070 [00:26<02:52,  4.93it/s] 21%|██        | 220/1070 [00:26<02:29,  5.69it/s] 21%|██        | 221/1070 [00:26<02:12,  6.40it/s] 21%|██        | 222/1070 [00:26<02:00,  7.01it/s] 21%|██        | 223/1070 [00:27<01:52,  7.53it/s] 21%|██        | 224/1070 [00:27<01:47,  7.88it/s] 21%|██        | 225/1070 [00:27<01:44,  8.12it/s] 21%|██        | 226/1070 [00:27<01:40,  8.38it/s] 21%|██        | 227/1070 [00:27<01:37,  8.61it/s] 21%|██▏       | 228/1070 [00:27<01:35,  8.79it/s] 21%|██▏       | 229/1070 [00:27<01:34,  8.89it/s] 21%|██▏       | 230/1070 [00:27<01:33,  8.94it/s] 22%|██▏       | 231/1070 [00:27<01:34,  8.91it/s] 22%|██▏       | 232/1070 [00:28<01:34,  8.86it/s] 22%|██▏       | 233/1070 [00:28<01:34,  8.90it/s] 22%|██▏       | 234/1070 [00:28<01:33,  8.96it/s] 22%|██▏       | 235/1070 [00:28<01:32,  9.04it/s] 22%|██▏       | 236/1070 [00:28<01:32,  9.05it/s] 22%|██▏       | 237/1070 [00:28<01:31,  9.07it/s] 22%|██▏       | 238/1070 [00:28<01:31,  9.09it/s] 22%|██▏       | 239/1070 [00:28<01:32,  9.00it/s] 22%|██▏       | 240/1070 [00:28<01:32,  8.98it/s] 23%|██▎       | 241/1070 [00:29<01:31,  9.07it/s] 23%|██▎       | 242/1070 [00:29<01:31,  9.08it/s] 23%|██▎       | 243/1070 [00:29<01:31,  9.08it/s] 23%|██▎       | 244/1070 [00:29<01:31,  8.98it/s] 23%|██▎       | 245/1070 [00:29<01:32,  8.96it/s] 23%|██▎       | 246/1070 [00:29<01:32,  8.94it/s] 23%|██▎       | 247/1070 [00:29<01:31,  8.98it/s] 23%|██▎       | 248/1070 [00:29<01:30,  9.09it/s] 23%|██▎       | 249/1070 [00:29<01:31,  9.00it/s] 23%|██▎       | 250/1070 [00:29<01:30,  9.04it/s] 23%|██▎       | 251/1070 [00:30<01:31,  8.99it/s] 24%|██▎       | 252/1070 [00:30<01:30,  9.05it/s] 24%|██▎       | 253/1070 [00:30<01:30,  9.04it/s] 24%|██▎       | 254/1070 [00:30<01:30,  9.00it/s] 24%|██▍       | 255/1070 [00:30<01:29,  9.09it/s] 24%|██▍       | 256/1070 [00:30<01:29,  9.10it/s] 24%|██▍       | 257/1070 [00:30<01:29,  9.04it/s] 24%|██▍       | 258/1070 [00:30<01:30,  8.96it/s] 24%|██▍       | 259/1070 [00:30<01:30,  8.95it/s] 24%|██▍       | 260/1070 [00:31<01:30,  9.00it/s] 24%|██▍       | 261/1070 [00:31<01:30,  8.94it/s] 24%|██▍       | 262/1070 [00:31<01:29,  9.04it/s] 25%|██▍       | 263/1070 [00:31<01:29,  8.99it/s] 25%|██▍       | 264/1070 [00:31<01:29,  8.98it/s] 25%|██▍       | 265/1070 [00:31<01:29,  8.97it/s] 25%|██▍       | 266/1070 [00:31<01:29,  8.96it/s] 25%|██▍       | 267/1070 [00:31<01:29,  8.96it/s] 25%|██▌       | 268/1070 [00:32<01:29,  8.98it/s] 25%|██▌       | 269/1070 [00:32<01:27,  9.16it/s] 25%|██▌       | 270/1070 [00:32<01:28,  9.03it/s] 25%|██▌       | 271/1070 [00:32<01:28,  9.01it/s] 25%|██▌       | 272/1070 [00:32<01:28,  8.97it/s] 26%|██▌       | 273/1070 [00:32<01:29,  8.93it/s] 26%|██▌       | 274/1070 [00:32<01:28,  9.03it/s] 26%|██▌       | 275/1070 [00:32<01:29,  8.90it/s] 26%|██▌       | 276/1070 [00:32<01:27,  9.06it/s] 26%|██▌       | 277/1070 [00:33<01:28,  8.98it/s] 26%|██▌       | 278/1070 [00:33<01:27,  9.02it/s] 26%|██▌       | 279/1070 [00:33<01:27,  9.05it/s] 26%|██▌       | 280/1070 [00:33<01:27,  8.99it/s] 26%|██▋       | 281/1070 [00:33<01:27,  9.04it/s] 26%|██▋       | 282/1070 [00:33<01:27,  9.03it/s] 26%|██▋       | 283/1070 [00:33<01:25,  9.19it/s] 27%|██▋       | 284/1070 [00:33<01:26,  9.08it/s] 27%|██▋       | 285/1070 [00:33<01:27,  8.97it/s] 27%|██▋       | 286/1070 [00:33<01:27,  8.95it/s] 27%|██▋       | 287/1070 [00:34<01:27,  8.93it/s] 27%|██▋       | 288/1070 [00:34<01:27,  8.98it/s] 27%|██▋       | 289/1070 [00:34<01:26,  9.03it/s] 27%|██▋       | 290/1070 [00:34<01:25,  9.09it/s] 27%|██▋       | 291/1070 [00:34<01:26,  9.03it/s] 27%|██▋       | 292/1070 [00:34<01:27,  8.93it/s] 27%|██▋       | 293/1070 [00:34<01:27,  8.89it/s] 27%|██▋       | 294/1070 [00:34<01:26,  8.93it/s] 28%|██▊       | 295/1070 [00:34<01:25,  9.03it/s] 28%|██▊       | 296/1070 [00:35<01:25,  9.06it/s] 28%|██▊       | 297/1070 [00:35<01:24,  9.13it/s] 28%|██▊       | 298/1070 [00:35<01:24,  9.09it/s] 28%|██▊       | 299/1070 [00:35<01:25,  8.97it/s] 28%|██▊       | 300/1070 [00:35<01:25,  9.00it/s] 28%|██▊       | 301/1070 [00:35<01:25,  9.00it/s] 28%|██▊       | 302/1070 [00:35<01:25,  9.03it/s] 28%|██▊       | 303/1070 [00:35<01:24,  9.07it/s] 28%|██▊       | 304/1070 [00:35<01:24,  9.07it/s] 29%|██▊       | 305/1070 [00:36<01:24,  9.04it/s] 29%|██▊       | 306/1070 [00:36<01:25,  8.89it/s] 29%|██▊       | 307/1070 [00:36<01:25,  8.94it/s] 29%|██▉       | 308/1070 [00:36<01:25,  8.87it/s] 29%|██▉       | 309/1070 [00:36<01:25,  8.94it/s] 29%|██▉       | 310/1070 [00:36<01:24,  8.99it/s] 29%|██▉       | 311/1070 [00:36<01:23,  9.06it/s] 29%|██▉       | 312/1070 [00:36<01:24,  8.98it/s] 29%|██▉       | 313/1070 [00:37<01:24,  8.91it/s] 29%|██▉       | 314/1070 [00:37<01:24,  8.90it/s] 29%|██▉       | 315/1070 [00:37<01:24,  8.96it/s] 30%|██▉       | 316/1070 [00:37<01:23,  9.04it/s] 30%|██▉       | 317/1070 [00:37<01:23,  9.00it/s] 30%|██▉       | 318/1070 [00:37<01:22,  9.13it/s] 30%|██▉       | 319/1070 [00:37<01:22,  9.07it/s] 30%|██▉       | 320/1070 [00:37<01:23,  9.02it/s] 30%|███       | 321/1070 [00:37<01:22,  9.02it/s] 30%|███       | 322/1070 [00:37<01:22,  9.04it/s] 30%|███       | 323/1070 [00:38<01:21,  9.13it/s] 30%|███       | 324/1070 [00:38<01:21,  9.15it/s] 30%|███       | 325/1070 [00:38<01:20,  9.23it/s] 30%|███       | 326/1070 [00:38<01:21,  9.11it/s] 31%|███       | 327/1070 [00:38<01:21,  9.07it/s] 31%|███       | 328/1070 [00:38<01:22,  9.02it/s] 31%|███       | 329/1070 [00:38<01:21,  9.06it/s] 31%|███       | 330/1070 [00:38<01:21,  9.03it/s] 31%|███       | 331/1070 [00:38<01:21,  9.08it/s] 31%|███       | 332/1070 [00:39<01:20,  9.18it/s] 31%|███       | 333/1070 [00:39<01:21,  9.00it/s] 31%|███       | 334/1070 [00:39<01:21,  9.01it/s] 31%|███▏      | 335/1070 [00:39<01:21,  9.04it/s] 31%|███▏      | 336/1070 [00:39<01:21,  9.00it/s] 31%|███▏      | 337/1070 [00:39<01:21,  9.04it/s] 32%|███▏      | 338/1070 [00:39<01:21,  9.01it/s] 32%|███▏      | 339/1070 [00:39<01:20,  9.09it/s] 32%|███▏      | 340/1070 [00:39<01:20,  9.06it/s] 32%|███▏      | 341/1070 [00:40<01:20,  9.04it/s] 32%|███▏      | 342/1070 [00:40<01:20,  9.02it/s] 32%|███▏      | 343/1070 [00:40<01:20,  8.98it/s] 32%|███▏      | 344/1070 [00:40<01:20,  9.04it/s] 32%|███▏      | 345/1070 [00:40<01:20,  8.95it/s] 32%|███▏      | 346/1070 [00:40<01:18,  9.18it/s] 32%|███▏      | 347/1070 [00:40<01:19,  9.07it/s] 33%|███▎      | 348/1070 [00:40<01:19,  9.07it/s] 33%|███▎      | 349/1070 [00:40<01:19,  9.08it/s] 33%|███▎      | 350/1070 [00:41<01:19,  9.05it/s] 33%|███▎      | 351/1070 [00:41<01:19,  9.05it/s] 33%|███▎      | 352/1070 [00:41<01:19,  9.01it/s] 33%|███▎      | 353/1070 [00:41<01:18,  9.14it/s] 33%|███▎      | 354/1070 [00:41<01:18,  9.09it/s] 33%|███▎      | 355/1070 [00:41<01:18,  9.08it/s] 33%|███▎      | 356/1070 [00:41<01:19,  9.00it/s] 33%|███▎      | 357/1070 [00:41<01:19,  9.02it/s] 33%|███▎      | 358/1070 [00:41<01:19,  9.00it/s] 34%|███▎      | 359/1070 [00:42<01:19,  8.92it/s] 34%|███▎      | 360/1070 [00:42<01:18,  9.03it/s] 34%|███▎      | 361/1070 [00:42<01:18,  9.01it/s] 34%|███▍      | 362/1070 [00:42<01:18,  9.04it/s] 34%|███▍      | 363/1070 [00:42<01:19,  8.94it/s] 34%|███▍      | 364/1070 [00:42<01:18,  9.01it/s] 34%|███▍      | 365/1070 [00:42<01:19,  8.92it/s] 34%|███▍      | 366/1070 [00:42<01:18,  8.94it/s] 34%|███▍      | 367/1070 [00:42<01:18,  8.99it/s] 34%|███▍      | 368/1070 [00:43<01:17,  9.02it/s] 34%|███▍      | 369/1070 [00:43<01:17,  9.06it/s] 35%|███▍      | 370/1070 [00:43<01:17,  9.08it/s] 35%|███▍      | 371/1070 [00:43<01:17,  9.05it/s] 35%|███▍      | 372/1070 [00:43<01:17,  8.99it/s] 35%|███▍      | 373/1070 [00:43<01:17,  8.98it/s] 35%|███▍      | 374/1070 [00:43<01:16,  9.05it/s] 35%|███▌      | 375/1070 [00:43<01:16,  9.14it/s] 35%|███▌      | 376/1070 [00:43<01:15,  9.19it/s] 35%|███▌      | 377/1070 [00:44<01:15,  9.21it/s] 35%|███▌      | 378/1070 [00:44<01:15,  9.16it/s] 35%|███▌      | 379/1070 [00:44<01:16,  9.03it/s] 36%|███▌      | 380/1070 [00:44<01:16,  9.00it/s] 36%|███▌      | 381/1070 [00:44<01:15,  9.10it/s] 36%|███▌      | 382/1070 [00:44<01:14,  9.18it/s] 36%|███▌      | 383/1070 [00:44<01:14,  9.23it/s] 36%|███▌      | 384/1070 [00:44<01:14,  9.25it/s] 36%|███▌      | 385/1070 [00:44<01:14,  9.14it/s] 36%|███▌      | 386/1070 [00:45<01:15,  9.05it/s] 36%|███▌      | 387/1070 [00:45<01:15,  9.06it/s] 36%|███▋      | 388/1070 [00:45<01:15,  9.06it/s] 36%|███▋      | 389/1070 [00:45<01:15,  9.07it/s] 36%|███▋      | 390/1070 [00:45<01:15,  9.06it/s] 37%|███▋      | 391/1070 [00:45<01:13,  9.18it/s] 37%|███▋      | 392/1070 [00:45<01:14,  9.08it/s] 37%|███▋      | 393/1070 [00:45<01:14,  9.06it/s] 37%|███▋      | 394/1070 [00:45<01:14,  9.07it/s] 37%|███▋      | 395/1070 [00:46<01:14,  9.02it/s] 37%|███▋      | 396/1070 [00:46<01:13,  9.14it/s] 37%|███▋      | 397/1070 [00:46<01:14,  9.06it/s] 37%|███▋      | 398/1070 [00:46<01:12,  9.23it/s] 37%|███▋      | 399/1070 [00:46<01:14,  9.07it/s] 37%|███▋      | 400/1070 [00:46<01:13,  9.09it/s] 37%|███▋      | 401/1070 [00:46<01:13,  9.11it/s] 38%|███▊      | 402/1070 [00:46<01:13,  9.14it/s] 38%|███▊      | 403/1070 [00:46<01:12,  9.14it/s] 38%|███▊      | 404/1070 [00:47<01:12,  9.18it/s] 38%|███▊      | 405/1070 [00:47<01:11,  9.27it/s] 38%|███▊      | 406/1070 [00:47<01:12,  9.10it/s] 38%|███▊      | 407/1070 [00:47<01:12,  9.09it/s] 38%|███▊      | 408/1070 [00:47<01:12,  9.10it/s] 38%|███▊      | 409/1070 [00:47<01:12,  9.07it/s] 38%|███▊      | 410/1070 [00:47<01:12,  9.09it/s] 38%|███▊      | 411/1070 [00:47<01:11,  9.16it/s] 39%|███▊      | 412/1070 [00:47<01:11,  9.23it/s] 39%|███▊      | 413/1070 [00:48<01:12,  9.04it/s] 39%|███▊      | 414/1070 [00:48<01:12,  9.07it/s] 39%|███▉      | 415/1070 [00:48<01:11,  9.10it/s] 39%|███▉      | 416/1070 [00:48<01:12,  9.00it/s] 39%|███▉      | 417/1070 [00:48<01:12,  9.04it/s] 39%|███▉      | 418/1070 [00:48<01:12,  9.03it/s] 39%|███▉      | 419/1070 [00:48<01:11,  9.17it/s] 39%|███▉      | 420/1070 [00:48<01:11,  9.09it/s] 39%|███▉      | 421/1070 [00:48<01:11,  9.08it/s] 39%|███▉      | 422/1070 [00:49<01:11,  9.05it/s] 40%|███▉      | 423/1070 [00:49<01:11,  9.03it/s] 40%|███▉      | 424/1070 [00:49<01:11,  9.07it/s] 40%|███▉      | 425/1070 [00:49<01:11,  9.02it/s] 40%|███▉      | 426/1070 [00:49<01:10,  9.10it/s] 40%|███▉      | 427/1070 [00:49<01:10,  9.11it/s]                                                   40%|████      | 428/1070 [00:49<01:10,  9.11it/s][INFO|trainer.py:755] 2023-11-15 20:15:44,895 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:15:44,898 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:15:44,899 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:15:44,899 >>   Batch size = 8
{'eval_loss': 0.29802343249320984, 'eval_accuracy': 0.9026315789473685, 'eval_micro_f1': 0.9026315789473685, 'eval_macro_f1': 0.8991378210232692, 'eval_runtime': 1.3646, 'eval_samples_per_second': 556.938, 'eval_steps_per_second': 69.617, 'epoch': 1.0}
{'loss': 0.2118, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 79.82it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 76.89it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 71.23it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 71.26it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 71.32it/s][A
 51%|█████     | 48/95 [00:00<00:00, 72.33it/s][A
 59%|█████▉    | 56/95 [00:00<00:00, 71.69it/s][A
 67%|██████▋   | 64/95 [00:00<00:00, 71.72it/s][A
 76%|███████▌  | 72/95 [00:01<00:00, 69.30it/s][A
 83%|████████▎ | 79/95 [00:01<00:00, 68.59it/s][A
 91%|█████████ | 86/95 [00:01<00:00, 68.76it/s][A
 99%|█████████▉| 94/95 [00:01<00:00, 70.55it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:51<01:10,  9.11it/s]
100%|██████████| 95/95 [00:01<00:00, 70.55it/s][A
                                               [A 40%|████      | 429/1070 [00:51<04:37,  2.31it/s] 40%|████      | 430/1070 [00:51<03:45,  2.84it/s] 40%|████      | 431/1070 [00:51<03:04,  3.46it/s] 40%|████      | 432/1070 [00:51<02:32,  4.17it/s] 40%|████      | 433/1070 [00:51<02:09,  4.92it/s] 41%|████      | 434/1070 [00:51<01:52,  5.68it/s] 41%|████      | 435/1070 [00:51<01:40,  6.33it/s] 41%|████      | 436/1070 [00:51<01:31,  6.91it/s] 41%|████      | 437/1070 [00:52<01:25,  7.41it/s] 41%|████      | 438/1070 [00:52<01:20,  7.83it/s] 41%|████      | 439/1070 [00:52<01:16,  8.21it/s] 41%|████      | 440/1070 [00:52<01:14,  8.47it/s] 41%|████      | 441/1070 [00:52<01:12,  8.72it/s] 41%|████▏     | 442/1070 [00:52<01:11,  8.74it/s] 41%|████▏     | 443/1070 [00:52<01:11,  8.77it/s] 41%|████▏     | 444/1070 [00:52<01:10,  8.83it/s] 42%|████▏     | 445/1070 [00:52<01:10,  8.85it/s] 42%|████▏     | 446/1070 [00:53<01:09,  9.00it/s] 42%|████▏     | 447/1070 [00:53<01:09,  8.97it/s] 42%|████▏     | 448/1070 [00:53<01:08,  9.13it/s] 42%|████▏     | 449/1070 [00:53<01:08,  9.00it/s] 42%|████▏     | 450/1070 [00:53<01:08,  9.00it/s] 42%|████▏     | 451/1070 [00:53<01:08,  9.02it/s] 42%|████▏     | 452/1070 [00:53<01:08,  8.98it/s] 42%|████▏     | 453/1070 [00:53<01:08,  9.03it/s] 42%|████▏     | 454/1070 [00:53<01:08,  9.01it/s] 43%|████▎     | 455/1070 [00:54<01:07,  9.15it/s] 43%|████▎     | 456/1070 [00:54<01:07,  9.05it/s] 43%|████▎     | 457/1070 [00:54<01:07,  9.06it/s] 43%|████▎     | 458/1070 [00:54<01:07,  9.05it/s] 43%|████▎     | 459/1070 [00:54<01:07,  9.06it/s] 43%|████▎     | 460/1070 [00:54<01:07,  9.06it/s] 43%|████▎     | 461/1070 [00:54<01:07,  8.99it/s] 43%|████▎     | 462/1070 [00:54<01:06,  9.09it/s] 43%|████▎     | 463/1070 [00:54<01:06,  9.09it/s] 43%|████▎     | 464/1070 [00:55<01:06,  9.11it/s] 43%|████▎     | 465/1070 [00:55<01:06,  9.08it/s] 44%|████▎     | 466/1070 [00:55<01:06,  9.06it/s] 44%|████▎     | 467/1070 [00:55<01:06,  9.05it/s] 44%|████▎     | 468/1070 [00:55<01:06,  9.02it/s] 44%|████▍     | 469/1070 [00:55<01:05,  9.13it/s] 44%|████▍     | 470/1070 [00:55<01:06,  9.08it/s] 44%|████▍     | 471/1070 [00:55<01:05,  9.09it/s] 44%|████▍     | 472/1070 [00:55<01:06,  8.96it/s] 44%|████▍     | 473/1070 [00:56<01:06,  8.98it/s] 44%|████▍     | 474/1070 [00:56<01:06,  8.99it/s] 44%|████▍     | 475/1070 [00:56<01:06,  8.88it/s] 44%|████▍     | 476/1070 [00:56<01:05,  9.12it/s] 45%|████▍     | 477/1070 [00:56<01:05,  9.07it/s] 45%|████▍     | 478/1070 [00:56<01:05,  9.02it/s] 45%|████▍     | 479/1070 [00:56<01:05,  9.05it/s] 45%|████▍     | 480/1070 [00:56<01:05,  9.04it/s] 45%|████▍     | 481/1070 [00:56<01:05,  9.05it/s] 45%|████▌     | 482/1070 [00:57<01:06,  8.91it/s] 45%|████▌     | 483/1070 [00:57<01:04,  9.10it/s] 45%|████▌     | 484/1070 [00:57<01:05,  9.01it/s] 45%|████▌     | 485/1070 [00:57<01:04,  9.06it/s] 45%|████▌     | 486/1070 [00:57<01:04,  8.99it/s] 46%|████▌     | 487/1070 [00:57<01:05,  8.97it/s] 46%|████▌     | 488/1070 [00:57<01:04,  8.98it/s] 46%|████▌     | 489/1070 [00:57<01:05,  8.93it/s] 46%|████▌     | 490/1070 [00:57<01:03,  9.10it/s] 46%|████▌     | 491/1070 [00:58<01:03,  9.05it/s] 46%|████▌     | 492/1070 [00:58<01:04,  9.01it/s] 46%|████▌     | 493/1070 [00:58<01:03,  9.04it/s] 46%|████▌     | 494/1070 [00:58<01:03,  9.03it/s] 46%|████▋     | 495/1070 [00:58<01:03,  9.00it/s] 46%|████▋     | 496/1070 [00:58<01:03,  9.00it/s] 46%|████▋     | 497/1070 [00:58<01:02,  9.12it/s] 47%|████▋     | 498/1070 [00:58<01:02,  9.08it/s] 47%|████▋     | 499/1070 [00:58<01:02,  9.09it/s] 47%|████▋     | 500/1070 [00:59<01:03,  9.01it/s] 47%|████▋     | 501/1070 [00:59<01:03,  9.03it/s] 47%|████▋     | 502/1070 [00:59<01:03,  8.95it/s] 47%|████▋     | 503/1070 [00:59<01:03,  8.98it/s] 47%|████▋     | 504/1070 [00:59<01:02,  9.09it/s] 47%|████▋     | 505/1070 [00:59<01:02,  9.02it/s] 47%|████▋     | 506/1070 [00:59<01:02,  9.03it/s] 47%|████▋     | 507/1070 [00:59<01:02,  9.08it/s] 47%|████▋     | 508/1070 [00:59<01:02,  9.05it/s] 48%|████▊     | 509/1070 [01:00<01:02,  8.99it/s] 48%|████▊     | 510/1070 [01:00<01:02,  8.95it/s] 48%|████▊     | 511/1070 [01:00<01:01,  9.12it/s] 48%|████▊     | 512/1070 [01:00<01:01,  9.09it/s] 48%|████▊     | 513/1070 [01:00<01:01,  9.11it/s] 48%|████▊     | 514/1070 [01:00<01:01,  9.07it/s] 48%|████▊     | 515/1070 [01:00<01:01,  9.02it/s] 48%|████▊     | 516/1070 [01:00<01:01,  9.03it/s] 48%|████▊     | 517/1070 [01:00<01:01,  8.98it/s] 48%|████▊     | 518/1070 [01:01<01:00,  9.17it/s] 49%|████▊     | 519/1070 [01:01<01:00,  9.05it/s] 49%|████▊     | 520/1070 [01:01<01:00,  9.02it/s] 49%|████▊     | 521/1070 [01:01<01:01,  8.97it/s] 49%|████▉     | 522/1070 [01:01<01:01,  8.95it/s] 49%|████▉     | 523/1070 [01:01<01:01,  8.95it/s] 49%|████▉     | 524/1070 [01:01<01:00,  8.97it/s] 49%|████▉     | 525/1070 [01:01<00:59,  9.12it/s] 49%|████▉     | 526/1070 [01:01<01:00,  9.03it/s] 49%|████▉     | 527/1070 [01:02<01:00,  9.03it/s] 49%|████▉     | 528/1070 [01:02<01:00,  8.94it/s] 49%|████▉     | 529/1070 [01:02<01:00,  8.95it/s] 50%|████▉     | 530/1070 [01:02<01:00,  8.94it/s] 50%|████▉     | 531/1070 [01:02<00:59,  9.03it/s] 50%|████▉     | 532/1070 [01:02<00:59,  9.07it/s] 50%|████▉     | 533/1070 [01:02<00:59,  9.04it/s] 50%|████▉     | 534/1070 [01:02<00:59,  9.04it/s] 50%|█████     | 535/1070 [01:02<00:59,  8.99it/s] 50%|█████     | 536/1070 [01:03<00:59,  9.01it/s] 50%|█████     | 537/1070 [01:03<00:59,  8.96it/s] 50%|█████     | 538/1070 [01:03<00:59,  8.93it/s] 50%|█████     | 539/1070 [01:03<00:58,  9.10it/s] 50%|█████     | 540/1070 [01:03<00:58,  9.09it/s] 51%|█████     | 541/1070 [01:03<00:58,  9.07it/s] 51%|█████     | 542/1070 [01:03<00:58,  9.09it/s] 51%|█████     | 543/1070 [01:03<00:57,  9.12it/s] 51%|█████     | 544/1070 [01:03<00:57,  9.09it/s] 51%|█████     | 545/1070 [01:04<00:58,  9.04it/s] 51%|█████     | 546/1070 [01:04<00:57,  9.10it/s] 51%|█████     | 547/1070 [01:04<00:57,  9.08it/s] 51%|█████     | 548/1070 [01:04<00:57,  9.06it/s] 51%|█████▏    | 549/1070 [01:04<00:57,  9.04it/s] 51%|█████▏    | 550/1070 [01:04<00:57,  9.05it/s] 51%|█████▏    | 551/1070 [01:04<00:57,  8.97it/s] 52%|█████▏    | 552/1070 [01:04<00:57,  8.98it/s] 52%|█████▏    | 553/1070 [01:04<00:57,  8.98it/s] 52%|█████▏    | 554/1070 [01:05<00:57,  9.02it/s] 52%|█████▏    | 555/1070 [01:05<00:57,  9.00it/s] 52%|█████▏    | 556/1070 [01:05<00:57,  8.99it/s] 52%|█████▏    | 557/1070 [01:05<00:57,  8.96it/s] 52%|█████▏    | 558/1070 [01:05<00:57,  8.88it/s] 52%|█████▏    | 559/1070 [01:05<00:56,  8.98it/s] 52%|█████▏    | 560/1070 [01:05<00:56,  9.03it/s] 52%|█████▏    | 561/1070 [01:05<00:55,  9.09it/s] 53%|█████▎    | 562/1070 [01:05<00:55,  9.11it/s] 53%|█████▎    | 563/1070 [01:06<00:55,  9.14it/s] 53%|█████▎    | 564/1070 [01:06<00:55,  9.07it/s] 53%|█████▎    | 565/1070 [01:06<00:56,  8.99it/s] 53%|█████▎    | 566/1070 [01:06<00:55,  9.03it/s] 53%|█████▎    | 567/1070 [01:06<00:55,  9.05it/s] 53%|█████▎    | 568/1070 [01:06<00:55,  9.11it/s] 53%|█████▎    | 569/1070 [01:06<00:55,  9.11it/s] 53%|█████▎    | 570/1070 [01:06<00:54,  9.17it/s] 53%|█████▎    | 571/1070 [01:06<00:55,  9.06it/s] 53%|█████▎    | 572/1070 [01:07<00:55,  9.02it/s] 54%|█████▎    | 573/1070 [01:07<00:55,  9.02it/s] 54%|█████▎    | 574/1070 [01:07<00:54,  9.04it/s] 54%|█████▎    | 575/1070 [01:07<00:54,  9.00it/s] 54%|█████▍    | 576/1070 [01:07<00:54,  9.06it/s] 54%|█████▍    | 577/1070 [01:07<00:53,  9.18it/s] 54%|█████▍    | 578/1070 [01:07<00:54,  9.11it/s] 54%|█████▍    | 579/1070 [01:07<00:54,  9.05it/s] 54%|█████▍    | 580/1070 [01:07<00:54,  9.05it/s] 54%|█████▍    | 581/1070 [01:07<00:54,  9.01it/s] 54%|█████▍    | 582/1070 [01:08<00:53,  9.10it/s] 54%|█████▍    | 583/1070 [01:08<00:53,  9.11it/s] 55%|█████▍    | 584/1070 [01:08<00:52,  9.25it/s] 55%|█████▍    | 585/1070 [01:08<00:53,  9.15it/s] 55%|█████▍    | 586/1070 [01:08<00:52,  9.17it/s] 55%|█████▍    | 587/1070 [01:08<00:52,  9.17it/s] 55%|█████▍    | 588/1070 [01:08<00:52,  9.17it/s] 55%|█████▌    | 589/1070 [01:08<00:52,  9.12it/s] 55%|█████▌    | 590/1070 [01:08<00:53,  9.03it/s] 55%|█████▌    | 591/1070 [01:09<00:52,  9.17it/s] 55%|█████▌    | 592/1070 [01:09<00:52,  9.14it/s] 55%|█████▌    | 593/1070 [01:09<00:52,  9.10it/s] 56%|█████▌    | 594/1070 [01:09<00:52,  9.02it/s] 56%|█████▌    | 595/1070 [01:09<00:52,  9.06it/s] 56%|█████▌    | 596/1070 [01:09<00:52,  9.01it/s] 56%|█████▌    | 597/1070 [01:09<00:52,  9.03it/s] 56%|█████▌    | 598/1070 [01:09<00:51,  9.11it/s] 56%|█████▌    | 599/1070 [01:09<00:51,  9.15it/s] 56%|█████▌    | 600/1070 [01:10<00:51,  9.14it/s] 56%|█████▌    | 601/1070 [01:10<00:51,  9.13it/s] 56%|█████▋    | 602/1070 [01:10<00:51,  9.13it/s] 56%|█████▋    | 603/1070 [01:10<00:51,  9.02it/s] 56%|█████▋    | 604/1070 [01:10<00:51,  9.06it/s] 57%|█████▋    | 605/1070 [01:10<00:50,  9.13it/s] 57%|█████▋    | 606/1070 [01:10<00:50,  9.16it/s] 57%|█████▋    | 607/1070 [01:10<00:50,  9.14it/s] 57%|█████▋    | 608/1070 [01:10<00:50,  9.18it/s] 57%|█████▋    | 609/1070 [01:11<00:50,  9.16it/s] 57%|█████▋    | 610/1070 [01:11<00:50,  9.03it/s] 57%|█████▋    | 611/1070 [01:11<00:50,  9.08it/s] 57%|█████▋    | 612/1070 [01:11<00:50,  9.03it/s] 57%|█████▋    | 613/1070 [01:11<00:50,  9.09it/s] 57%|█████▋    | 614/1070 [01:11<00:50,  9.07it/s] 57%|█████▋    | 615/1070 [01:11<00:49,  9.20it/s] 58%|█████▊    | 616/1070 [01:11<00:50,  9.07it/s] 58%|█████▊    | 617/1070 [01:11<00:49,  9.07it/s] 58%|█████▊    | 618/1070 [01:12<00:49,  9.05it/s] 58%|█████▊    | 619/1070 [01:12<00:49,  9.05it/s] 58%|█████▊    | 620/1070 [01:12<00:49,  9.05it/s] 58%|█████▊    | 621/1070 [01:12<00:49,  9.04it/s] 58%|█████▊    | 622/1070 [01:12<00:49,  9.12it/s] 58%|█████▊    | 623/1070 [01:12<00:49,  9.09it/s] 58%|█████▊    | 624/1070 [01:12<00:49,  9.09it/s] 58%|█████▊    | 625/1070 [01:12<00:48,  9.09it/s] 59%|█████▊    | 626/1070 [01:12<00:48,  9.12it/s] 59%|█████▊    | 627/1070 [01:13<00:49,  9.01it/s] 59%|█████▊    | 628/1070 [01:13<00:49,  9.00it/s] 59%|█████▉    | 629/1070 [01:13<00:48,  9.06it/s] 59%|█████▉    | 630/1070 [01:13<00:48,  9.10it/s] 59%|█████▉    | 631/1070 [01:13<00:47,  9.17it/s] 59%|█████▉    | 632/1070 [01:13<00:48,  9.10it/s] 59%|█████▉    | 633/1070 [01:13<00:48,  9.09it/s] 59%|█████▉    | 634/1070 [01:13<00:48,  8.97it/s] 59%|█████▉    | 635/1070 [01:13<00:48,  9.02it/s] 59%|█████▉    | 636/1070 [01:14<00:48,  8.93it/s] 60%|█████▉    | 637/1070 [01:14<00:48,  8.98it/s] 60%|█████▉    | 638/1070 [01:14<00:48,  8.89it/s] 60%|█████▉    | 639/1070 [01:14<00:47,  9.05it/s] 60%|█████▉    | 640/1070 [01:14<00:47,  9.02it/s] 60%|█████▉    | 641/1070 [01:14<00:47,  9.06it/s]                                                   60%|██████    | 642/1070 [01:14<00:47,  9.06it/s][INFO|trainer.py:755] 2023-11-15 20:16:09,928 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:16:09,930 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:16:09,930 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:16:09,930 >>   Batch size = 8
{'eval_loss': 0.31820154190063477, 'eval_accuracy': 0.9052631578947369, 'eval_micro_f1': 0.9052631578947369, 'eval_macro_f1': 0.9028200079439144, 'eval_runtime': 1.3977, 'eval_samples_per_second': 543.749, 'eval_steps_per_second': 67.969, 'epoch': 2.0}
{'loss': 0.1335, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 83.24it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 73.63it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 71.83it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 71.70it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 72.05it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 69.87it/s][A
 61%|██████    | 58/95 [00:00<00:00, 70.64it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 70.41it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 70.48it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 70.81it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 68.73it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:16<00:47,  9.06it/s]
100%|██████████| 95/95 [00:01<00:00, 68.73it/s][A
                                               [A 60%|██████    | 643/1070 [01:16<03:03,  2.33it/s] 60%|██████    | 644/1070 [01:16<02:29,  2.85it/s] 60%|██████    | 645/1070 [01:16<02:02,  3.47it/s] 60%|██████    | 646/1070 [01:16<01:43,  4.11it/s] 60%|██████    | 647/1070 [01:16<01:26,  4.86it/s] 61%|██████    | 648/1070 [01:16<01:15,  5.62it/s] 61%|██████    | 649/1070 [01:16<01:06,  6.32it/s] 61%|██████    | 650/1070 [01:16<01:00,  6.93it/s] 61%|██████    | 651/1070 [01:17<00:56,  7.46it/s] 61%|██████    | 652/1070 [01:17<00:53,  7.81it/s] 61%|██████    | 653/1070 [01:17<00:50,  8.19it/s] 61%|██████    | 654/1070 [01:17<00:49,  8.44it/s] 61%|██████    | 655/1070 [01:17<00:47,  8.67it/s] 61%|██████▏   | 656/1070 [01:17<00:46,  8.82it/s] 61%|██████▏   | 657/1070 [01:17<00:46,  8.96it/s] 61%|██████▏   | 658/1070 [01:17<00:46,  8.92it/s] 62%|██████▏   | 659/1070 [01:17<00:45,  8.98it/s] 62%|██████▏   | 660/1070 [01:18<00:45,  9.03it/s] 62%|██████▏   | 661/1070 [01:18<00:45,  9.01it/s] 62%|██████▏   | 662/1070 [01:18<00:44,  9.10it/s] 62%|██████▏   | 663/1070 [01:18<00:44,  9.15it/s] 62%|██████▏   | 664/1070 [01:18<00:44,  9.21it/s] 62%|██████▏   | 665/1070 [01:18<00:44,  9.11it/s] 62%|██████▏   | 666/1070 [01:18<00:44,  9.13it/s] 62%|██████▏   | 667/1070 [01:18<00:44,  9.04it/s] 62%|██████▏   | 668/1070 [01:18<00:44,  9.08it/s] 63%|██████▎   | 669/1070 [01:19<00:44,  9.00it/s] 63%|██████▎   | 670/1070 [01:19<00:44,  8.98it/s] 63%|██████▎   | 671/1070 [01:19<00:43,  9.08it/s] 63%|██████▎   | 672/1070 [01:19<00:43,  9.10it/s] 63%|██████▎   | 673/1070 [01:19<00:43,  9.13it/s] 63%|██████▎   | 674/1070 [01:19<00:43,  9.10it/s] 63%|██████▎   | 675/1070 [01:19<00:43,  9.08it/s] 63%|██████▎   | 676/1070 [01:19<00:43,  9.04it/s] 63%|██████▎   | 677/1070 [01:19<00:43,  9.03it/s] 63%|██████▎   | 678/1070 [01:20<00:43,  9.07it/s] 63%|██████▎   | 679/1070 [01:20<00:42,  9.11it/s] 64%|██████▎   | 680/1070 [01:20<00:42,  9.12it/s] 64%|██████▎   | 681/1070 [01:20<00:42,  9.17it/s] 64%|██████▎   | 682/1070 [01:20<00:42,  9.12it/s] 64%|██████▍   | 683/1070 [01:20<00:42,  9.02it/s] 64%|██████▍   | 684/1070 [01:20<00:42,  9.06it/s] 64%|██████▍   | 685/1070 [01:20<00:42,  8.98it/s] 64%|██████▍   | 686/1070 [01:20<00:42,  9.11it/s] 64%|██████▍   | 687/1070 [01:21<00:42,  9.09it/s] 64%|██████▍   | 688/1070 [01:21<00:41,  9.22it/s] 64%|██████▍   | 689/1070 [01:21<00:41,  9.09it/s] 64%|██████▍   | 690/1070 [01:21<00:41,  9.11it/s] 65%|██████▍   | 691/1070 [01:21<00:41,  9.06it/s] 65%|██████▍   | 692/1070 [01:21<00:41,  9.04it/s] 65%|██████▍   | 693/1070 [01:21<00:41,  9.08it/s] 65%|██████▍   | 694/1070 [01:21<00:41,  9.08it/s] 65%|██████▍   | 695/1070 [01:21<00:40,  9.18it/s] 65%|██████▌   | 696/1070 [01:22<00:41,  9.11it/s] 65%|██████▌   | 697/1070 [01:22<00:40,  9.11it/s] 65%|██████▌   | 698/1070 [01:22<00:40,  9.11it/s] 65%|██████▌   | 699/1070 [01:22<00:40,  9.08it/s] 65%|██████▌   | 700/1070 [01:22<00:40,  9.13it/s] 66%|██████▌   | 701/1070 [01:22<00:40,  9.02it/s] 66%|██████▌   | 702/1070 [01:22<00:40,  9.19it/s] 66%|██████▌   | 703/1070 [01:22<00:40,  9.15it/s] 66%|██████▌   | 704/1070 [01:22<00:40,  9.10it/s] 66%|██████▌   | 705/1070 [01:23<00:40,  9.00it/s] 66%|██████▌   | 706/1070 [01:23<00:40,  9.04it/s] 66%|██████▌   | 707/1070 [01:23<00:40,  9.01it/s] 66%|██████▌   | 708/1070 [01:23<00:40,  9.01it/s] 66%|██████▋   | 709/1070 [01:23<00:39,  9.10it/s] 66%|██████▋   | 710/1070 [01:23<00:39,  9.09it/s] 66%|██████▋   | 711/1070 [01:23<00:39,  9.16it/s] 67%|██████▋   | 712/1070 [01:23<00:39,  9.10it/s] 67%|██████▋   | 713/1070 [01:23<00:39,  9.09it/s] 67%|██████▋   | 714/1070 [01:24<00:39,  8.98it/s] 67%|██████▋   | 715/1070 [01:24<00:39,  9.05it/s] 67%|██████▋   | 716/1070 [01:24<00:39,  9.05it/s] 67%|██████▋   | 717/1070 [01:24<00:38,  9.13it/s] 67%|██████▋   | 718/1070 [01:24<00:38,  9.17it/s] 67%|██████▋   | 719/1070 [01:24<00:38,  9.20it/s] 67%|██████▋   | 720/1070 [01:24<00:38,  9.12it/s] 67%|██████▋   | 721/1070 [01:24<00:38,  9.04it/s] 67%|██████▋   | 722/1070 [01:24<00:38,  9.04it/s] 68%|██████▊   | 723/1070 [01:25<00:38,  9.05it/s] 68%|██████▊   | 724/1070 [01:25<00:37,  9.11it/s] 68%|██████▊   | 725/1070 [01:25<00:38,  9.05it/s] 68%|██████▊   | 726/1070 [01:25<00:37,  9.18it/s] 68%|██████▊   | 727/1070 [01:25<00:37,  9.11it/s] 68%|██████▊   | 728/1070 [01:25<00:37,  9.09it/s] 68%|██████▊   | 729/1070 [01:25<00:37,  9.11it/s] 68%|██████▊   | 730/1070 [01:25<00:37,  9.09it/s] 68%|██████▊   | 731/1070 [01:25<00:36,  9.16it/s] 68%|██████▊   | 732/1070 [01:26<00:36,  9.15it/s] 69%|██████▊   | 733/1070 [01:26<00:36,  9.24it/s] 69%|██████▊   | 734/1070 [01:26<00:36,  9.11it/s] 69%|██████▊   | 735/1070 [01:26<00:36,  9.11it/s] 69%|██████▉   | 736/1070 [01:26<00:36,  9.09it/s] 69%|██████▉   | 737/1070 [01:26<00:36,  9.03it/s] 69%|██████▉   | 738/1070 [01:26<00:36,  9.02it/s] 69%|██████▉   | 739/1070 [01:26<00:36,  9.01it/s] 69%|██████▉   | 740/1070 [01:26<00:35,  9.17it/s] 69%|██████▉   | 741/1070 [01:26<00:36,  9.10it/s] 69%|██████▉   | 742/1070 [01:27<00:36,  9.11it/s] 69%|██████▉   | 743/1070 [01:27<00:35,  9.14it/s] 70%|██████▉   | 744/1070 [01:27<00:35,  9.13it/s] 70%|██████▉   | 745/1070 [01:27<00:35,  9.10it/s] 70%|██████▉   | 746/1070 [01:27<00:35,  9.13it/s] 70%|██████▉   | 747/1070 [01:27<00:34,  9.25it/s] 70%|██████▉   | 748/1070 [01:27<00:34,  9.20it/s] 70%|███████   | 749/1070 [01:27<00:35,  9.17it/s] 70%|███████   | 750/1070 [01:27<00:35,  9.10it/s] 70%|███████   | 751/1070 [01:28<00:35,  9.10it/s] 70%|███████   | 752/1070 [01:28<00:34,  9.12it/s] 70%|███████   | 753/1070 [01:28<00:34,  9.14it/s] 70%|███████   | 754/1070 [01:28<00:34,  9.20it/s] 71%|███████   | 755/1070 [01:28<00:34,  9.15it/s] 71%|███████   | 756/1070 [01:28<00:34,  9.16it/s] 71%|███████   | 757/1070 [01:28<00:34,  9.05it/s] 71%|███████   | 758/1070 [01:28<00:34,  9.09it/s] 71%|███████   | 759/1070 [01:28<00:34,  9.07it/s] 71%|███████   | 760/1070 [01:29<00:34,  9.00it/s] 71%|███████   | 761/1070 [01:29<00:33,  9.12it/s] 71%|███████   | 762/1070 [01:29<00:33,  9.09it/s] 71%|███████▏  | 763/1070 [01:29<00:33,  9.13it/s] 71%|███████▏  | 764/1070 [01:29<00:33,  9.06it/s] 71%|███████▏  | 765/1070 [01:29<00:33,  9.08it/s] 72%|███████▏  | 766/1070 [01:29<00:33,  9.03it/s] 72%|███████▏  | 767/1070 [01:29<00:33,  9.00it/s] 72%|███████▏  | 768/1070 [01:29<00:33,  9.04it/s] 72%|███████▏  | 769/1070 [01:30<00:33,  9.08it/s] 72%|███████▏  | 770/1070 [01:30<00:32,  9.16it/s] 72%|███████▏  | 771/1070 [01:30<00:32,  9.12it/s] 72%|███████▏  | 772/1070 [01:30<00:32,  9.07it/s] 72%|███████▏  | 773/1070 [01:30<00:33,  8.93it/s] 72%|███████▏  | 774/1070 [01:30<00:32,  8.98it/s] 72%|███████▏  | 775/1070 [01:30<00:32,  9.09it/s] 73%|███████▎  | 776/1070 [01:30<00:32,  9.15it/s] 73%|███████▎  | 777/1070 [01:30<00:31,  9.16it/s] 73%|███████▎  | 778/1070 [01:31<00:31,  9.17it/s] 73%|███████▎  | 779/1070 [01:31<00:31,  9.10it/s] 73%|███████▎  | 780/1070 [01:31<00:31,  9.07it/s] 73%|███████▎  | 781/1070 [01:31<00:32,  9.02it/s] 73%|███████▎  | 782/1070 [01:31<00:31,  9.12it/s] 73%|███████▎  | 783/1070 [01:31<00:31,  9.17it/s] 73%|███████▎  | 784/1070 [01:31<00:31,  9.12it/s] 73%|███████▎  | 785/1070 [01:31<00:31,  9.16it/s] 73%|███████▎  | 786/1070 [01:31<00:31,  9.07it/s] 74%|███████▎  | 787/1070 [01:32<00:31,  9.04it/s] 74%|███████▎  | 788/1070 [01:32<00:31,  9.04it/s] 74%|███████▎  | 789/1070 [01:32<00:31,  9.05it/s] 74%|███████▍  | 790/1070 [01:32<00:30,  9.10it/s] 74%|███████▍  | 791/1070 [01:32<00:30,  9.09it/s] 74%|███████▍  | 792/1070 [01:32<00:30,  9.25it/s] 74%|███████▍  | 793/1070 [01:32<00:30,  9.11it/s] 74%|███████▍  | 794/1070 [01:32<00:30,  9.08it/s] 74%|███████▍  | 795/1070 [01:32<00:30,  8.99it/s] 74%|███████▍  | 796/1070 [01:33<00:30,  9.07it/s] 74%|███████▍  | 797/1070 [01:33<00:30,  9.08it/s] 75%|███████▍  | 798/1070 [01:33<00:30,  9.04it/s] 75%|███████▍  | 799/1070 [01:33<00:29,  9.11it/s] 75%|███████▍  | 800/1070 [01:33<00:29,  9.10it/s] 75%|███████▍  | 801/1070 [01:33<00:29,  9.07it/s] 75%|███████▍  | 802/1070 [01:33<00:29,  9.05it/s] 75%|███████▌  | 803/1070 [01:33<00:29,  9.02it/s] 75%|███████▌  | 804/1070 [01:33<00:29,  9.13it/s] 75%|███████▌  | 805/1070 [01:34<00:29,  9.02it/s] 75%|███████▌  | 806/1070 [01:34<00:28,  9.20it/s] 75%|███████▌  | 807/1070 [01:34<00:28,  9.14it/s] 76%|███████▌  | 808/1070 [01:34<00:28,  9.12it/s] 76%|███████▌  | 809/1070 [01:34<00:29,  8.99it/s] 76%|███████▌  | 810/1070 [01:34<00:28,  9.03it/s] 76%|███████▌  | 811/1070 [01:34<00:28,  9.06it/s] 76%|███████▌  | 812/1070 [01:34<00:28,  9.01it/s] 76%|███████▌  | 813/1070 [01:34<00:28,  9.09it/s] 76%|███████▌  | 814/1070 [01:35<00:28,  9.02it/s] 76%|███████▌  | 815/1070 [01:35<00:28,  9.05it/s] 76%|███████▋  | 816/1070 [01:35<00:28,  9.01it/s] 76%|███████▋  | 817/1070 [01:35<00:27,  9.04it/s] 76%|███████▋  | 818/1070 [01:35<00:28,  8.91it/s] 77%|███████▋  | 819/1070 [01:35<00:27,  8.97it/s] 77%|███████▋  | 820/1070 [01:35<00:27,  9.03it/s] 77%|███████▋  | 821/1070 [01:35<00:27,  9.08it/s] 77%|███████▋  | 822/1070 [01:35<00:27,  9.06it/s] 77%|███████▋  | 823/1070 [01:36<00:27,  9.09it/s] 77%|███████▋  | 824/1070 [01:36<00:27,  9.06it/s] 77%|███████▋  | 825/1070 [01:36<00:27,  9.01it/s] 77%|███████▋  | 826/1070 [01:36<00:27,  8.98it/s] 77%|███████▋  | 827/1070 [01:36<00:27,  8.95it/s] 77%|███████▋  | 828/1070 [01:36<00:26,  9.07it/s] 77%|███████▋  | 829/1070 [01:36<00:26,  9.03it/s] 78%|███████▊  | 830/1070 [01:36<00:26,  9.13it/s] 78%|███████▊  | 831/1070 [01:36<00:26,  9.04it/s] 78%|███████▊  | 832/1070 [01:37<00:26,  9.03it/s] 78%|███████▊  | 833/1070 [01:37<00:26,  8.99it/s] 78%|███████▊  | 834/1070 [01:37<00:26,  9.00it/s] 78%|███████▊  | 835/1070 [01:37<00:25,  9.04it/s] 78%|███████▊  | 836/1070 [01:37<00:25,  9.02it/s] 78%|███████▊  | 837/1070 [01:37<00:25,  9.08it/s] 78%|███████▊  | 838/1070 [01:37<00:25,  9.05it/s] 78%|███████▊  | 839/1070 [01:37<00:25,  9.04it/s] 79%|███████▊  | 840/1070 [01:37<00:25,  8.99it/s] 79%|███████▊  | 841/1070 [01:38<00:25,  9.04it/s] 79%|███████▊  | 842/1070 [01:38<00:25,  9.02it/s] 79%|███████▉  | 843/1070 [01:38<00:25,  9.01it/s] 79%|███████▉  | 844/1070 [01:38<00:24,  9.11it/s] 79%|███████▉  | 845/1070 [01:38<00:24,  9.14it/s] 79%|███████▉  | 846/1070 [01:38<00:24,  9.13it/s] 79%|███████▉  | 847/1070 [01:38<00:24,  9.04it/s] 79%|███████▉  | 848/1070 [01:38<00:24,  9.05it/s] 79%|███████▉  | 849/1070 [01:38<00:24,  9.01it/s] 79%|███████▉  | 850/1070 [01:39<00:24,  9.01it/s] 80%|███████▉  | 851/1070 [01:39<00:24,  9.10it/s] 80%|███████▉  | 852/1070 [01:39<00:23,  9.09it/s] 80%|███████▉  | 853/1070 [01:39<00:24,  9.03it/s] 80%|███████▉  | 854/1070 [01:39<00:24,  9.00it/s] 80%|███████▉  | 855/1070 [01:39<00:23,  9.01it/s]                                                   80%|████████  | 856/1070 [01:39<00:23,  9.01it/s][INFO|trainer.py:755] 2023-11-15 20:16:34,891 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:16:34,893 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:16:34,893 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:16:34,894 >>   Batch size = 8
{'eval_loss': 0.32788050174713135, 'eval_accuracy': 0.9105263157894737, 'eval_micro_f1': 0.9105263157894739, 'eval_macro_f1': 0.9077817189811566, 'eval_runtime': 1.3916, 'eval_samples_per_second': 546.142, 'eval_steps_per_second': 68.268, 'epoch': 3.0}
{'loss': 0.0775, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 81.90it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 75.18it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 73.80it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 71.42it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 72.92it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 72.48it/s][A
 61%|██████    | 58/95 [00:00<00:00, 72.50it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 71.49it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 71.69it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 69.48it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 71.09it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:41<00:23,  9.01it/s]
100%|██████████| 95/95 [00:01<00:00, 71.09it/s][A
                                               [A 80%|████████  | 857/1070 [01:41<01:29,  2.37it/s] 80%|████████  | 858/1070 [01:41<01:13,  2.90it/s] 80%|████████  | 859/1070 [01:41<00:59,  3.52it/s] 80%|████████  | 860/1070 [01:41<00:49,  4.22it/s] 80%|████████  | 861/1070 [01:41<00:42,  4.94it/s] 81%|████████  | 862/1070 [01:41<00:36,  5.67it/s] 81%|████████  | 863/1070 [01:41<00:32,  6.40it/s] 81%|████████  | 864/1070 [01:41<00:29,  7.01it/s] 81%|████████  | 865/1070 [01:42<00:27,  7.50it/s] 81%|████████  | 866/1070 [01:42<00:25,  7.88it/s] 81%|████████  | 867/1070 [01:42<00:24,  8.21it/s] 81%|████████  | 868/1070 [01:42<00:24,  8.39it/s] 81%|████████  | 869/1070 [01:42<00:23,  8.58it/s] 81%|████████▏ | 870/1070 [01:42<00:22,  8.80it/s] 81%|████████▏ | 871/1070 [01:42<00:22,  8.87it/s] 81%|████████▏ | 872/1070 [01:42<00:22,  8.94it/s] 82%|████████▏ | 873/1070 [01:42<00:22,  8.90it/s] 82%|████████▏ | 874/1070 [01:43<00:21,  8.96it/s] 82%|████████▏ | 875/1070 [01:43<00:21,  8.88it/s] 82%|████████▏ | 876/1070 [01:43<00:21,  8.91it/s] 82%|████████▏ | 877/1070 [01:43<00:21,  9.05it/s] 82%|████████▏ | 878/1070 [01:43<00:21,  9.01it/s] 82%|████████▏ | 879/1070 [01:43<00:21,  8.96it/s] 82%|████████▏ | 880/1070 [01:43<00:21,  8.95it/s] 82%|████████▏ | 881/1070 [01:43<00:21,  8.94it/s] 82%|████████▏ | 882/1070 [01:43<00:21,  8.93it/s] 83%|████████▎ | 883/1070 [01:44<00:20,  8.95it/s] 83%|████████▎ | 884/1070 [01:44<00:20,  9.02it/s] 83%|████████▎ | 885/1070 [01:44<00:20,  9.07it/s] 83%|████████▎ | 886/1070 [01:44<00:20,  8.97it/s] 83%|████████▎ | 887/1070 [01:44<00:20,  8.99it/s] 83%|████████▎ | 888/1070 [01:44<00:20,  8.95it/s] 83%|████████▎ | 889/1070 [01:44<00:20,  8.94it/s] 83%|████████▎ | 890/1070 [01:44<00:20,  8.89it/s] 83%|████████▎ | 891/1070 [01:44<00:20,  8.94it/s] 83%|████████▎ | 892/1070 [01:45<00:19,  8.99it/s] 83%|████████▎ | 893/1070 [01:45<00:19,  8.96it/s] 84%|████████▎ | 894/1070 [01:45<00:19,  8.93it/s] 84%|████████▎ | 895/1070 [01:45<00:19,  8.94it/s] 84%|████████▎ | 896/1070 [01:45<00:19,  8.94it/s] 84%|████████▍ | 897/1070 [01:45<00:19,  8.93it/s] 84%|████████▍ | 898/1070 [01:45<00:19,  8.99it/s] 84%|████████▍ | 899/1070 [01:45<00:19,  8.97it/s] 84%|████████▍ | 900/1070 [01:45<00:18,  9.00it/s] 84%|████████▍ | 901/1070 [01:46<00:19,  8.88it/s] 84%|████████▍ | 902/1070 [01:46<00:18,  8.93it/s] 84%|████████▍ | 903/1070 [01:46<00:18,  8.86it/s] 84%|████████▍ | 904/1070 [01:46<00:18,  8.88it/s] 85%|████████▍ | 905/1070 [01:46<00:18,  9.06it/s] 85%|████████▍ | 906/1070 [01:46<00:18,  9.04it/s] 85%|████████▍ | 907/1070 [01:46<00:18,  9.02it/s] 85%|████████▍ | 908/1070 [01:46<00:18,  8.98it/s] 85%|████████▍ | 909/1070 [01:46<00:17,  9.03it/s] 85%|████████▌ | 910/1070 [01:47<00:17,  8.95it/s] 85%|████████▌ | 911/1070 [01:47<00:17,  8.89it/s] 85%|████████▌ | 912/1070 [01:47<00:17,  8.98it/s] 85%|████████▌ | 913/1070 [01:47<00:17,  9.01it/s] 85%|████████▌ | 914/1070 [01:47<00:17,  9.04it/s] 86%|████████▌ | 915/1070 [01:47<00:17,  8.96it/s] 86%|████████▌ | 916/1070 [01:47<00:17,  8.99it/s] 86%|████████▌ | 917/1070 [01:47<00:17,  8.92it/s] 86%|████████▌ | 918/1070 [01:47<00:16,  8.97it/s] 86%|████████▌ | 919/1070 [01:48<00:16,  9.10it/s] 86%|████████▌ | 920/1070 [01:48<00:16,  9.06it/s] 86%|████████▌ | 921/1070 [01:48<00:16,  9.08it/s] 86%|████████▌ | 922/1070 [01:48<00:16,  9.04it/s] 86%|████████▋ | 923/1070 [01:48<00:16,  9.01it/s] 86%|████████▋ | 924/1070 [01:48<00:16,  8.91it/s] 86%|████████▋ | 925/1070 [01:48<00:16,  8.94it/s] 87%|████████▋ | 926/1070 [01:48<00:16,  8.96it/s] 87%|████████▋ | 927/1070 [01:48<00:15,  8.98it/s] 87%|████████▋ | 928/1070 [01:49<00:15,  9.02it/s] 87%|████████▋ | 929/1070 [01:49<00:15,  9.08it/s] 87%|████████▋ | 930/1070 [01:49<00:15,  9.04it/s] 87%|████████▋ | 931/1070 [01:49<00:15,  8.97it/s] 87%|████████▋ | 932/1070 [01:49<00:15,  8.97it/s] 87%|████████▋ | 933/1070 [01:49<00:15,  9.03it/s] 87%|████████▋ | 934/1070 [01:49<00:14,  9.09it/s] 87%|████████▋ | 935/1070 [01:49<00:14,  9.00it/s] 87%|████████▋ | 936/1070 [01:49<00:14,  9.13it/s] 88%|████████▊ | 937/1070 [01:50<00:14,  9.04it/s] 88%|████████▊ | 938/1070 [01:50<00:14,  9.02it/s] 88%|████████▊ | 939/1070 [01:50<00:14,  9.05it/s] 88%|████████▊ | 940/1070 [01:50<00:14,  9.00it/s] 88%|████████▊ | 941/1070 [01:50<00:14,  9.01it/s] 88%|████████▊ | 942/1070 [01:50<00:14,  9.07it/s] 88%|████████▊ | 943/1070 [01:50<00:13,  9.09it/s] 88%|████████▊ | 944/1070 [01:50<00:13,  9.07it/s] 88%|████████▊ | 945/1070 [01:50<00:13,  9.01it/s] 88%|████████▊ | 946/1070 [01:51<00:13,  9.01it/s] 89%|████████▊ | 947/1070 [01:51<00:13,  9.02it/s] 89%|████████▊ | 948/1070 [01:51<00:13,  9.04it/s] 89%|████████▊ | 949/1070 [01:51<00:13,  9.07it/s] 89%|████████▉ | 950/1070 [01:51<00:13,  9.10it/s] 89%|████████▉ | 951/1070 [01:51<00:13,  8.99it/s] 89%|████████▉ | 952/1070 [01:51<00:13,  8.98it/s] 89%|████████▉ | 953/1070 [01:51<00:13,  9.00it/s] 89%|████████▉ | 954/1070 [01:51<00:12,  8.95it/s] 89%|████████▉ | 955/1070 [01:52<00:12,  8.95it/s] 89%|████████▉ | 956/1070 [01:52<00:12,  8.99it/s] 89%|████████▉ | 957/1070 [01:52<00:12,  9.18it/s] 90%|████████▉ | 958/1070 [01:52<00:12,  9.08it/s] 90%|████████▉ | 959/1070 [01:52<00:12,  9.05it/s] 90%|████████▉ | 960/1070 [01:52<00:12,  9.07it/s] 90%|████████▉ | 961/1070 [01:52<00:12,  9.04it/s] 90%|████████▉ | 962/1070 [01:52<00:11,  9.05it/s] 90%|█████████ | 963/1070 [01:52<00:11,  8.97it/s] 90%|█████████ | 964/1070 [01:53<00:11,  9.06it/s] 90%|█████████ | 965/1070 [01:53<00:11,  9.06it/s] 90%|█████████ | 966/1070 [01:53<00:11,  9.08it/s] 90%|█████████ | 967/1070 [01:53<00:11,  9.02it/s] 90%|█████████ | 968/1070 [01:53<00:11,  9.05it/s] 91%|█████████ | 969/1070 [01:53<00:11,  9.05it/s] 91%|█████████ | 970/1070 [01:53<00:11,  9.02it/s] 91%|█████████ | 971/1070 [01:53<00:10,  9.09it/s] 91%|█████████ | 972/1070 [01:53<00:10,  9.11it/s] 91%|█████████ | 973/1070 [01:54<00:10,  9.12it/s] 91%|█████████ | 974/1070 [01:54<00:10,  9.06it/s] 91%|█████████ | 975/1070 [01:54<00:10,  9.01it/s] 91%|█████████ | 976/1070 [01:54<00:10,  8.97it/s] 91%|█████████▏| 977/1070 [01:54<00:10,  9.01it/s] 91%|█████████▏| 978/1070 [01:54<00:10,  9.08it/s] 91%|█████████▏| 979/1070 [01:54<00:09,  9.11it/s] 92%|█████████▏| 980/1070 [01:54<00:09,  9.18it/s] 92%|█████████▏| 981/1070 [01:54<00:09,  9.16it/s] 92%|█████████▏| 982/1070 [01:54<00:09,  9.11it/s] 92%|█████████▏| 983/1070 [01:55<00:09,  8.99it/s] 92%|█████████▏| 984/1070 [01:55<00:09,  8.98it/s] 92%|█████████▏| 985/1070 [01:55<00:09,  8.97it/s] 92%|█████████▏| 986/1070 [01:55<00:09,  9.00it/s] 92%|█████████▏| 987/1070 [01:55<00:09,  9.06it/s] 92%|█████████▏| 988/1070 [01:55<00:08,  9.15it/s] 92%|█████████▏| 989/1070 [01:55<00:09,  8.99it/s] 93%|█████████▎| 990/1070 [01:55<00:08,  8.95it/s] 93%|█████████▎| 991/1070 [01:55<00:08,  9.01it/s] 93%|█████████▎| 992/1070 [01:56<00:08,  9.04it/s] 93%|█████████▎| 993/1070 [01:56<00:08,  9.06it/s] 93%|█████████▎| 994/1070 [01:56<00:08,  9.10it/s] 93%|█████████▎| 995/1070 [01:56<00:08,  9.19it/s] 93%|█████████▎| 996/1070 [01:56<00:08,  9.04it/s] 93%|█████████▎| 997/1070 [01:56<00:08,  9.02it/s] 93%|█████████▎| 998/1070 [01:56<00:07,  9.03it/s] 93%|█████████▎| 999/1070 [01:56<00:07,  9.03it/s] 93%|█████████▎| 1000/1070 [01:56<00:07,  8.97it/s] 94%|█████████▎| 1001/1070 [01:57<00:07,  9.01it/s] 94%|█████████▎| 1002/1070 [01:57<00:07,  9.13it/s] 94%|█████████▎| 1003/1070 [01:57<00:07,  9.09it/s] 94%|█████████▍| 1004/1070 [01:57<00:07,  9.09it/s] 94%|█████████▍| 1005/1070 [01:57<00:07,  9.01it/s] 94%|█████████▍| 1006/1070 [01:57<00:07,  9.02it/s] 94%|█████████▍| 1007/1070 [01:57<00:06,  9.03it/s] 94%|█████████▍| 1008/1070 [01:57<00:06,  8.98it/s] 94%|█████████▍| 1009/1070 [01:57<00:06,  9.09it/s] 94%|█████████▍| 1010/1070 [01:58<00:06,  9.10it/s] 94%|█████████▍| 1011/1070 [01:58<00:06,  9.05it/s] 95%|█████████▍| 1012/1070 [01:58<00:06,  8.98it/s] 95%|█████████▍| 1013/1070 [01:58<00:06,  9.04it/s] 95%|█████████▍| 1014/1070 [01:58<00:06,  8.99it/s] 95%|█████████▍| 1015/1070 [01:58<00:06,  8.96it/s] 95%|█████████▍| 1016/1070 [01:58<00:05,  9.04it/s] 95%|█████████▌| 1017/1070 [01:58<00:05,  9.03it/s] 95%|█████████▌| 1018/1070 [01:58<00:05,  9.09it/s] 95%|█████████▌| 1019/1070 [01:59<00:05,  9.13it/s] 95%|█████████▌| 1020/1070 [01:59<00:05,  9.06it/s] 95%|█████████▌| 1021/1070 [01:59<00:05,  9.00it/s] 96%|█████████▌| 1022/1070 [01:59<00:05,  9.00it/s] 96%|█████████▌| 1023/1070 [01:59<00:05,  9.06it/s] 96%|█████████▌| 1024/1070 [01:59<00:05,  9.02it/s] 96%|█████████▌| 1025/1070 [01:59<00:05,  8.97it/s] 96%|█████████▌| 1026/1070 [01:59<00:04,  9.00it/s] 96%|█████████▌| 1027/1070 [01:59<00:04,  9.01it/s] 96%|█████████▌| 1028/1070 [02:00<00:04,  8.95it/s] 96%|█████████▌| 1029/1070 [02:00<00:04,  8.98it/s] 96%|█████████▋| 1030/1070 [02:00<00:04,  8.97it/s] 96%|█████████▋| 1031/1070 [02:00<00:04,  9.00it/s] 96%|█████████▋| 1032/1070 [02:00<00:04,  9.06it/s] 97%|█████████▋| 1033/1070 [02:00<00:04,  9.18it/s] 97%|█████████▋| 1034/1070 [02:00<00:03,  9.01it/s] 97%|█████████▋| 1035/1070 [02:00<00:03,  9.03it/s] 97%|█████████▋| 1036/1070 [02:00<00:03,  8.97it/s] 97%|█████████▋| 1037/1070 [02:01<00:03,  9.01it/s] 97%|█████████▋| 1038/1070 [02:01<00:03,  9.06it/s] 97%|█████████▋| 1039/1070 [02:01<00:03,  9.06it/s] 97%|█████████▋| 1040/1070 [02:01<00:03,  9.12it/s] 97%|█████████▋| 1041/1070 [02:01<00:03,  9.06it/s] 97%|█████████▋| 1042/1070 [02:01<00:03,  9.10it/s] 97%|█████████▋| 1043/1070 [02:01<00:03,  8.98it/s] 98%|█████████▊| 1044/1070 [02:01<00:02,  8.98it/s] 98%|█████████▊| 1045/1070 [02:01<00:02,  9.00it/s] 98%|█████████▊| 1046/1070 [02:02<00:02,  8.97it/s] 98%|█████████▊| 1047/1070 [02:02<00:02,  9.07it/s] 98%|█████████▊| 1048/1070 [02:02<00:02,  9.06it/s] 98%|█████████▊| 1049/1070 [02:02<00:02,  9.05it/s] 98%|█████████▊| 1050/1070 [02:02<00:02,  9.02it/s] 98%|█████████▊| 1051/1070 [02:02<00:02,  9.06it/s] 98%|█████████▊| 1052/1070 [02:02<00:02,  8.94it/s] 98%|█████████▊| 1053/1070 [02:02<00:01,  8.99it/s] 99%|█████████▊| 1054/1070 [02:02<00:01,  9.00it/s] 99%|█████████▊| 1055/1070 [02:03<00:01,  9.01it/s] 99%|█████████▊| 1056/1070 [02:03<00:01,  9.05it/s] 99%|█████████▉| 1057/1070 [02:03<00:01,  9.13it/s] 99%|█████████▉| 1058/1070 [02:03<00:01,  9.06it/s] 99%|█████████▉| 1059/1070 [02:03<00:01,  8.99it/s] 99%|█████████▉| 1060/1070 [02:03<00:01,  8.98it/s] 99%|█████████▉| 1061/1070 [02:03<00:01,  9.00it/s] 99%|█████████▉| 1062/1070 [02:03<00:00,  9.07it/s] 99%|█████████▉| 1063/1070 [02:03<00:00,  9.01it/s] 99%|█████████▉| 1064/1070 [02:04<00:00,  9.14it/s]100%|█████████▉| 1065/1070 [02:04<00:00,  9.04it/s]100%|█████████▉| 1066/1070 [02:04<00:00,  9.05it/s]100%|█████████▉| 1067/1070 [02:04<00:00,  9.00it/s]100%|█████████▉| 1068/1070 [02:04<00:00,  8.96it/s]100%|█████████▉| 1069/1070 [02:04<00:00,  9.07it/s]                                                   100%|██████████| 1070/1070 [02:04<00:00,  9.07it/s][INFO|trainer.py:755] 2023-11-15 20:16:59,957 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:16:59,959 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:16:59,959 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:16:59,960 >>   Batch size = 8
{'eval_loss': 0.3675995171070099, 'eval_accuracy': 0.8986842105263158, 'eval_micro_f1': 0.8986842105263158, 'eval_macro_f1': 0.8958450543073867, 'eval_runtime': 1.356, 'eval_samples_per_second': 560.482, 'eval_steps_per_second': 70.06, 'epoch': 4.0}
{'loss': 0.0499, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 85.14it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 77.17it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 73.80it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 72.70it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 69.85it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 71.55it/s][A
 61%|██████    | 58/95 [00:00<00:00, 71.33it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 71.40it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 71.23it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 71.59it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 72.95it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:06<00:00,  9.07it/s]
100%|██████████| 95/95 [00:01<00:00, 72.95it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 20:17:01,325 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:06<00:00,  9.07it/s]100%|██████████| 1070/1070 [02:06<00:00,  8.49it/s]
[INFO|trainer.py:2855] 2023-11-15 20:17:01,329 >> Saving model checkpoint to ./result/agnews_sup_bert-base-cased_adapter__seed1
[INFO|configuration_utils.py:460] 2023-11-15 20:17:01,333 >> Configuration saved in ./result/agnews_sup_bert-base-cased_adapter__seed1/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:17:02,550 >> Model weights saved in ./result/agnews_sup_bert-base-cased_adapter__seed1/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:17:02,553 >> tokenizer config file saved in ./result/agnews_sup_bert-base-cased_adapter__seed1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:17:02,556 >> Special tokens file saved in ./result/agnews_sup_bert-base-cased_adapter__seed1/special_tokens_map.json
{'eval_loss': 0.38627487421035767, 'eval_accuracy': 0.9026315789473685, 'eval_micro_f1': 0.9026315789473685, 'eval_macro_f1': 0.900040513144057, 'eval_runtime': 1.3614, 'eval_samples_per_second': 558.258, 'eval_steps_per_second': 69.782, 'epoch': 5.0}
{'train_runtime': 126.1, 'train_samples_per_second': 271.213, 'train_steps_per_second': 8.485, 'train_loss': 0.19143234235103998, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.1914
  train_runtime            = 0:02:06.09
  train_samples            =       6840
  train_samples_per_second =    271.213
  train_steps_per_second   =      8.485
11/15/2023 20:17:02 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:17:02,602 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:17:02,605 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:17:02,605 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:17:02,606 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  9%|▉         | 9/95 [00:00<00:01, 85.60it/s] 19%|█▉        | 18/95 [00:00<00:01, 74.62it/s] 27%|██▋       | 26/95 [00:00<00:00, 71.49it/s] 36%|███▌      | 34/95 [00:00<00:00, 71.79it/s] 44%|████▍     | 42/95 [00:00<00:00, 72.84it/s] 53%|█████▎    | 50/95 [00:00<00:00, 71.40it/s] 61%|██████    | 58/95 [00:00<00:00, 71.38it/s] 69%|██████▉   | 66/95 [00:00<00:00, 72.32it/s] 78%|███████▊  | 74/95 [00:01<00:00, 71.44it/s] 86%|████████▋ | 82/95 [00:01<00:00, 70.62it/s] 95%|█████████▍| 90/95 [00:01<00:00, 71.56it/s]100%|██████████| 95/95 [00:01<00:00, 69.99it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9026
  eval_loss               =     0.3863
  eval_macro_f1           =        0.9
  eval_micro_f1           =     0.9026
  eval_runtime            = 0:00:01.37
  eval_samples            =        760
  eval_samples_per_second =    551.935
  eval_steps_per_second   =     68.992
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▃▅█▁▃▃
wandb:                      eval/loss ▁▃▃▇██
wandb:                  eval/macro_f1 ▃▅█▁▃▃
wandb:                  eval/micro_f1 ▃▅█▁▃▃
wandb:                   eval/runtime ▂█▇▁▂▅
wandb:        eval/samples_per_second ▇▁▂█▇▄
wandb:          eval/steps_per_second ▇▁▂█▇▄
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▂▁▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.90263
wandb:                      eval/loss 0.38627
wandb:                  eval/macro_f1 0.90004
wandb:                  eval/micro_f1 0.90263
wandb:                   eval/runtime 1.377
wandb:        eval/samples_per_second 551.935
wandb:          eval/steps_per_second 68.992
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0499
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.19143
wandb:            train/train_runtime 126.1
wandb: train/train_samples_per_second 271.213
wandb:   train/train_steps_per_second 8.485
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_201407-8h0zcd2g
wandb: Find logs at: ./wandb/offline-run-20231115_201407-8h0zcd2g/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1/runs/Nov15_20-17-14_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:17:14 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:17:14 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1/runs/Nov15_20-17-14_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=222,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 20:17:31,484 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:17:31,497 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:17:41,513 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:17:51,533 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:17:51,534 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:18:11,574 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:18:11,575 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:18:11,575 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:18:11,576 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:18:11,576 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:18:11,577 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:18:11,578 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 20:18:11,604 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:18:11,605 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:18:31,758 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 20:18:33,586 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:18:33,587 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  44%|████▍     | 3000/6840 [00:00<00:00, 19831.88 examples/s]Running tokenizer on dataset:  88%|████████▊ | 6000/6840 [00:00<00:00, 19788.82 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 19665.34 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 15497.90 examples/s]
11/15/2023 20:18:34 - INFO - __main__ - Sample 6380 of the training set: {'text': 'Mich. Elephant Gets Therapy for Arthritis ROYAL OAK, Mich. - Like any patient, Wanda needs positive reinforcement to wrestle through her physical therapy...', 'label': 3, 'input_ids': [102, 6842, 205, 1147, 19091, 30108, 10650, 2223, 168, 9767, 10305, 18090, 422, 6842, 205, 579, 1967, 843, 1454, 422, 23458, 30110, 3097, 1532, 14440, 147, 1800, 327, 143, 833, 1750, 2121, 2223, 205, 205, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:18:34 - INFO - __main__ - Sample 883 of the training set: {'text': "Chicago to Hold EBay Auction to Raise Money for Cultural Programs City officials hope there are people willing to pay plenty of money to own a vintage Playboy Bunny costume, toss green dye into the Chicago River or throw a dinner party prepared by Oprah Winfrey's chef.", 'label': 2, 'input_ids': [102, 11393, 147, 2837, 7147, 240, 16648, 147, 12517, 9668, 168, 6656, 3996, 5523, 21959, 9859, 461, 220, 2325, 10279, 147, 3982, 4641, 3372, 30126, 131, 9668, 147, 2910, 106, 14279, 14647, 2250, 2209, 30126, 19586, 9560, 1729, 1668, 422, 147, 2085, 3755, 9812, 690, 111, 11393, 7050, 234, 20805, 106, 11764, 1347, 9408, 4092, 214, 561, 1942, 30117, 8168, 15550, 30126, 2505, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 20:18:34 - INFO - __main__ - Sample 1927 of the training set: {'text': 'Astros 10, Pirates 5 HOUSTON Mike Lamb went four-for-five with a homer and four RB-Is to lead the Houston Astros to their ninth straight win with a 10-to-five victory over the Pittsburgh Pirates today.', 'label': 0, 'input_ids': [102, 28648, 30113, 566, 422, 15185, 457, 305, 22525, 13924, 30107, 16282, 14606, 1379, 579, 168, 579, 2539, 190, 106, 3417, 30114, 137, 1379, 6897, 579, 165, 147, 1269, 111, 22525, 28648, 30113, 147, 547, 12640, 266, 5772, 8168, 190, 106, 566, 579, 147, 579, 2539, 16309, 30126, 573, 111, 20256, 15185, 457, 7121, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:18:34 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:18:35,514 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:18:35,522 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:18:35,522 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 20:18:35,522 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:18:35,523 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:18:35,523 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:18:35,523 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:18:35,523 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 20:18:35,524 >>   Number of trainable parameters = 109,921,540
[INFO|integration_utils.py:716] 2023-11-15 20:18:35,525 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<24:27,  1.37s/it]  0%|          | 2/1070 [00:01<11:08,  1.60it/s]  0%|          | 3/1070 [00:01<06:54,  2.57it/s]  0%|          | 4/1070 [00:01<04:55,  3.61it/s]  0%|          | 5/1070 [00:01<03:49,  4.63it/s]  1%|          | 6/1070 [00:01<03:08,  5.64it/s]  1%|          | 7/1070 [00:02<02:46,  6.40it/s]  1%|          | 8/1070 [00:02<02:29,  7.09it/s]  1%|          | 9/1070 [00:02<02:18,  7.65it/s]  1%|          | 10/1070 [00:02<02:11,  8.07it/s]  1%|          | 11/1070 [00:02<02:05,  8.42it/s]  1%|          | 12/1070 [00:02<02:02,  8.66it/s]  1%|          | 13/1070 [00:02<01:59,  8.88it/s]  1%|▏         | 14/1070 [00:02<01:56,  9.03it/s]  1%|▏         | 15/1070 [00:02<01:55,  9.15it/s]  1%|▏         | 16/1070 [00:02<01:53,  9.25it/s]  2%|▏         | 17/1070 [00:03<01:54,  9.16it/s]  2%|▏         | 18/1070 [00:03<01:54,  9.22it/s]  2%|▏         | 19/1070 [00:03<01:53,  9.23it/s]  2%|▏         | 20/1070 [00:03<01:54,  9.19it/s]  2%|▏         | 21/1070 [00:03<01:53,  9.24it/s]  2%|▏         | 22/1070 [00:03<01:54,  9.17it/s]  2%|▏         | 23/1070 [00:03<01:51,  9.38it/s]  2%|▏         | 24/1070 [00:03<01:52,  9.30it/s]  2%|▏         | 25/1070 [00:03<01:52,  9.27it/s]  2%|▏         | 26/1070 [00:04<01:53,  9.22it/s]  3%|▎         | 27/1070 [00:04<01:52,  9.25it/s]  3%|▎         | 28/1070 [00:04<01:53,  9.17it/s]  3%|▎         | 29/1070 [00:04<01:53,  9.16it/s]  3%|▎         | 30/1070 [00:04<01:51,  9.30it/s]  3%|▎         | 31/1070 [00:04<01:50,  9.37it/s]  3%|▎         | 32/1070 [00:04<01:50,  9.37it/s]  3%|▎         | 33/1070 [00:04<01:49,  9.44it/s]  3%|▎         | 34/1070 [00:04<01:50,  9.36it/s]  3%|▎         | 35/1070 [00:05<01:50,  9.38it/s]  3%|▎         | 36/1070 [00:05<01:50,  9.34it/s]  3%|▎         | 37/1070 [00:05<01:51,  9.29it/s]  4%|▎         | 38/1070 [00:05<01:51,  9.29it/s]  4%|▎         | 39/1070 [00:05<01:50,  9.29it/s]  4%|▎         | 40/1070 [00:05<01:49,  9.43it/s]  4%|▍         | 41/1070 [00:05<01:50,  9.32it/s]  4%|▍         | 42/1070 [00:05<01:50,  9.32it/s]  4%|▍         | 43/1070 [00:05<01:50,  9.28it/s]  4%|▍         | 44/1070 [00:05<01:50,  9.32it/s]  4%|▍         | 45/1070 [00:06<01:51,  9.22it/s]  4%|▍         | 46/1070 [00:06<01:50,  9.27it/s]  4%|▍         | 47/1070 [00:06<01:49,  9.31it/s]  4%|▍         | 48/1070 [00:06<01:49,  9.33it/s]  5%|▍         | 49/1070 [00:06<01:49,  9.35it/s]  5%|▍         | 50/1070 [00:06<01:48,  9.40it/s]  5%|▍         | 51/1070 [00:06<01:49,  9.34it/s]  5%|▍         | 52/1070 [00:06<01:49,  9.26it/s]  5%|▍         | 53/1070 [00:06<01:50,  9.22it/s]  5%|▌         | 54/1070 [00:07<01:49,  9.24it/s]  5%|▌         | 55/1070 [00:07<01:49,  9.24it/s]  5%|▌         | 56/1070 [00:07<01:49,  9.25it/s]  5%|▌         | 57/1070 [00:07<01:48,  9.31it/s]  5%|▌         | 58/1070 [00:07<01:48,  9.32it/s]  6%|▌         | 59/1070 [00:07<01:48,  9.32it/s]  6%|▌         | 60/1070 [00:07<01:49,  9.25it/s]  6%|▌         | 61/1070 [00:07<01:49,  9.25it/s]  6%|▌         | 62/1070 [00:07<01:49,  9.17it/s]  6%|▌         | 63/1070 [00:08<01:49,  9.19it/s]  6%|▌         | 64/1070 [00:08<01:49,  9.20it/s]  6%|▌         | 65/1070 [00:08<01:48,  9.26it/s]  6%|▌         | 66/1070 [00:08<01:47,  9.35it/s]  6%|▋         | 67/1070 [00:08<01:45,  9.46it/s]  6%|▋         | 68/1070 [00:08<01:47,  9.33it/s]  6%|▋         | 69/1070 [00:08<01:47,  9.33it/s]  7%|▋         | 70/1070 [00:08<01:48,  9.22it/s]  7%|▋         | 71/1070 [00:08<01:47,  9.30it/s]  7%|▋         | 72/1070 [00:09<01:48,  9.20it/s]  7%|▋         | 73/1070 [00:09<01:47,  9.31it/s]  7%|▋         | 74/1070 [00:09<01:46,  9.37it/s]  7%|▋         | 75/1070 [00:09<01:46,  9.38it/s]  7%|▋         | 76/1070 [00:09<01:45,  9.43it/s]  7%|▋         | 77/1070 [00:09<01:45,  9.40it/s]  7%|▋         | 78/1070 [00:09<01:45,  9.38it/s]  7%|▋         | 79/1070 [00:09<01:46,  9.34it/s]  7%|▋         | 80/1070 [00:09<01:45,  9.37it/s]  8%|▊         | 81/1070 [00:09<01:45,  9.34it/s]  8%|▊         | 82/1070 [00:10<01:45,  9.37it/s]  8%|▊         | 83/1070 [00:10<01:45,  9.32it/s]  8%|▊         | 84/1070 [00:10<01:44,  9.48it/s]  8%|▊         | 85/1070 [00:10<01:44,  9.40it/s]  8%|▊         | 86/1070 [00:10<01:44,  9.38it/s]  8%|▊         | 87/1070 [00:10<01:45,  9.29it/s]  8%|▊         | 88/1070 [00:10<01:44,  9.36it/s]  8%|▊         | 89/1070 [00:10<01:45,  9.26it/s]  8%|▊         | 90/1070 [00:10<01:45,  9.29it/s]  9%|▊         | 91/1070 [00:11<01:44,  9.37it/s]  9%|▊         | 92/1070 [00:11<01:44,  9.35it/s]  9%|▊         | 93/1070 [00:11<01:43,  9.44it/s]  9%|▉         | 94/1070 [00:11<01:42,  9.50it/s]  9%|▉         | 95/1070 [00:11<01:43,  9.38it/s]  9%|▉         | 96/1070 [00:11<01:44,  9.28it/s]  9%|▉         | 97/1070 [00:11<01:44,  9.36it/s]  9%|▉         | 98/1070 [00:11<01:44,  9.31it/s]  9%|▉         | 99/1070 [00:11<01:44,  9.32it/s]  9%|▉         | 100/1070 [00:11<01:44,  9.30it/s]  9%|▉         | 101/1070 [00:12<01:43,  9.38it/s] 10%|▉         | 102/1070 [00:12<01:43,  9.36it/s] 10%|▉         | 103/1070 [00:12<01:43,  9.37it/s] 10%|▉         | 104/1070 [00:12<01:43,  9.29it/s] 10%|▉         | 105/1070 [00:12<01:43,  9.31it/s] 10%|▉         | 106/1070 [00:12<01:43,  9.30it/s] 10%|█         | 107/1070 [00:12<01:44,  9.26it/s] 10%|█         | 108/1070 [00:12<01:42,  9.36it/s] 10%|█         | 109/1070 [00:12<01:42,  9.37it/s] 10%|█         | 110/1070 [00:13<01:42,  9.33it/s] 10%|█         | 111/1070 [00:13<01:40,  9.51it/s] 10%|█         | 112/1070 [00:13<01:42,  9.39it/s] 11%|█         | 113/1070 [00:13<01:41,  9.42it/s] 11%|█         | 114/1070 [00:13<01:42,  9.35it/s] 11%|█         | 115/1070 [00:13<01:41,  9.37it/s] 11%|█         | 116/1070 [00:13<01:42,  9.34it/s] 11%|█         | 117/1070 [00:13<01:41,  9.36it/s] 11%|█         | 118/1070 [00:13<01:41,  9.41it/s] 11%|█         | 119/1070 [00:14<01:40,  9.46it/s] 11%|█         | 120/1070 [00:14<01:40,  9.42it/s] 11%|█▏        | 121/1070 [00:14<01:41,  9.39it/s] 11%|█▏        | 122/1070 [00:14<01:40,  9.39it/s] 11%|█▏        | 123/1070 [00:14<01:41,  9.35it/s] 12%|█▏        | 124/1070 [00:14<01:41,  9.35it/s] 12%|█▏        | 125/1070 [00:14<01:41,  9.32it/s] 12%|█▏        | 126/1070 [00:14<01:40,  9.36it/s] 12%|█▏        | 127/1070 [00:14<01:40,  9.36it/s] 12%|█▏        | 128/1070 [00:14<01:39,  9.46it/s] 12%|█▏        | 129/1070 [00:15<01:40,  9.40it/s] 12%|█▏        | 130/1070 [00:15<01:40,  9.38it/s] 12%|█▏        | 131/1070 [00:15<01:40,  9.33it/s] 12%|█▏        | 132/1070 [00:15<01:40,  9.33it/s] 12%|█▏        | 133/1070 [00:15<01:40,  9.30it/s] 13%|█▎        | 134/1070 [00:15<01:40,  9.32it/s] 13%|█▎        | 135/1070 [00:15<01:39,  9.40it/s] 13%|█▎        | 136/1070 [00:15<01:39,  9.38it/s] 13%|█▎        | 137/1070 [00:15<01:39,  9.40it/s] 13%|█▎        | 138/1070 [00:16<01:39,  9.38it/s] 13%|█▎        | 139/1070 [00:16<01:39,  9.32it/s] 13%|█▎        | 140/1070 [00:16<01:40,  9.24it/s] 13%|█▎        | 141/1070 [00:16<01:40,  9.28it/s] 13%|█▎        | 142/1070 [00:16<01:41,  9.18it/s] 13%|█▎        | 143/1070 [00:16<01:40,  9.25it/s] 13%|█▎        | 144/1070 [00:16<01:40,  9.19it/s] 14%|█▎        | 145/1070 [00:16<01:39,  9.32it/s] 14%|█▎        | 146/1070 [00:16<01:39,  9.27it/s] 14%|█▎        | 147/1070 [00:17<01:39,  9.30it/s] 14%|█▍        | 148/1070 [00:17<01:39,  9.24it/s] 14%|█▍        | 149/1070 [00:17<01:39,  9.29it/s] 14%|█▍        | 150/1070 [00:17<01:39,  9.29it/s] 14%|█▍        | 151/1070 [00:17<01:39,  9.24it/s] 14%|█▍        | 152/1070 [00:17<01:38,  9.29it/s] 14%|█▍        | 153/1070 [00:17<01:37,  9.37it/s] 14%|█▍        | 154/1070 [00:17<01:37,  9.41it/s] 14%|█▍        | 155/1070 [00:17<01:36,  9.47it/s] 15%|█▍        | 156/1070 [00:17<01:37,  9.34it/s] 15%|█▍        | 157/1070 [00:18<01:38,  9.25it/s] 15%|█▍        | 158/1070 [00:18<01:38,  9.24it/s] 15%|█▍        | 159/1070 [00:18<01:38,  9.26it/s] 15%|█▍        | 160/1070 [00:18<01:38,  9.24it/s] 15%|█▌        | 161/1070 [00:18<01:37,  9.28it/s] 15%|█▌        | 162/1070 [00:18<01:36,  9.38it/s] 15%|█▌        | 163/1070 [00:18<01:37,  9.31it/s] 15%|█▌        | 164/1070 [00:18<01:37,  9.27it/s] 15%|█▌        | 165/1070 [00:18<01:37,  9.25it/s] 16%|█▌        | 166/1070 [00:19<01:37,  9.23it/s] 16%|█▌        | 167/1070 [00:19<01:37,  9.26it/s] 16%|█▌        | 168/1070 [00:19<01:37,  9.26it/s] 16%|█▌        | 169/1070 [00:19<01:37,  9.22it/s] 16%|█▌        | 170/1070 [00:19<01:37,  9.22it/s] 16%|█▌        | 171/1070 [00:19<01:37,  9.22it/s] 16%|█▌        | 172/1070 [00:19<01:36,  9.34it/s] 16%|█▌        | 173/1070 [00:19<01:36,  9.26it/s] 16%|█▋        | 174/1070 [00:19<01:36,  9.25it/s] 16%|█▋        | 175/1070 [00:20<01:38,  9.13it/s] 16%|█▋        | 176/1070 [00:20<01:37,  9.21it/s] 17%|█▋        | 177/1070 [00:20<01:37,  9.14it/s] 17%|█▋        | 178/1070 [00:20<01:37,  9.19it/s] 17%|█▋        | 179/1070 [00:20<01:37,  9.16it/s] 17%|█▋        | 180/1070 [00:20<01:36,  9.20it/s] 17%|█▋        | 181/1070 [00:20<01:36,  9.24it/s] 17%|█▋        | 182/1070 [00:20<01:34,  9.36it/s] 17%|█▋        | 183/1070 [00:20<01:35,  9.34it/s] 17%|█▋        | 184/1070 [00:21<01:35,  9.31it/s] 17%|█▋        | 185/1070 [00:21<01:36,  9.21it/s] 17%|█▋        | 186/1070 [00:21<01:36,  9.20it/s] 17%|█▋        | 187/1070 [00:21<01:36,  9.19it/s] 18%|█▊        | 188/1070 [00:21<01:35,  9.22it/s] 18%|█▊        | 189/1070 [00:21<01:34,  9.31it/s] 18%|█▊        | 190/1070 [00:21<01:35,  9.25it/s] 18%|█▊        | 191/1070 [00:21<01:34,  9.30it/s] 18%|█▊        | 192/1070 [00:21<01:34,  9.27it/s] 18%|█▊        | 193/1070 [00:21<01:35,  9.20it/s] 18%|█▊        | 194/1070 [00:22<01:34,  9.28it/s] 18%|█▊        | 195/1070 [00:22<01:34,  9.29it/s] 18%|█▊        | 196/1070 [00:22<01:34,  9.24it/s] 18%|█▊        | 197/1070 [00:22<01:34,  9.26it/s] 19%|█▊        | 198/1070 [00:22<01:33,  9.30it/s] 19%|█▊        | 199/1070 [00:22<01:32,  9.38it/s] 19%|█▊        | 200/1070 [00:22<01:33,  9.26it/s] 19%|█▉        | 201/1070 [00:22<01:33,  9.27it/s] 19%|█▉        | 202/1070 [00:22<01:34,  9.19it/s] 19%|█▉        | 203/1070 [00:23<01:33,  9.24it/s] 19%|█▉        | 204/1070 [00:23<01:33,  9.22it/s] 19%|█▉        | 205/1070 [00:23<01:33,  9.23it/s] 19%|█▉        | 206/1070 [00:23<01:32,  9.31it/s] 19%|█▉        | 207/1070 [00:23<01:33,  9.23it/s] 19%|█▉        | 208/1070 [00:23<01:33,  9.25it/s] 20%|█▉        | 209/1070 [00:23<01:32,  9.34it/s] 20%|█▉        | 210/1070 [00:23<01:32,  9.26it/s] 20%|█▉        | 211/1070 [00:23<01:33,  9.23it/s] 20%|█▉        | 212/1070 [00:24<01:32,  9.24it/s] 20%|█▉        | 213/1070 [00:24<01:32,  9.26it/s]                                                   20%|██        | 214/1070 [00:24<01:32,  9.26it/s][INFO|trainer.py:755] 2023-11-15 20:18:59,774 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:18:59,776 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:18:59,777 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:18:59,777 >>   Batch size = 8
{'loss': 0.4853, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 81.49it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 77.70it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 76.52it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 75.23it/s][A
 45%|████▌     | 43/95 [00:00<00:00, 77.12it/s][A
 54%|█████▎    | 51/95 [00:00<00:00, 75.11it/s][A
 62%|██████▏   | 59/95 [00:00<00:00, 74.95it/s][A
 71%|███████   | 67/95 [00:00<00:00, 74.26it/s][A
 79%|███████▉  | 75/95 [00:00<00:00, 74.81it/s][A
 87%|████████▋ | 83/95 [00:01<00:00, 74.85it/s][A
 96%|█████████▌| 91/95 [00:01<00:00, 75.20it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:25<01:32,  9.26it/s]
100%|██████████| 95/95 [00:01<00:00, 75.20it/s][A
                                               [A 20%|██        | 215/1070 [00:25<05:48,  2.45it/s] 20%|██        | 216/1070 [00:25<04:44,  3.00it/s] 20%|██        | 217/1070 [00:25<03:54,  3.63it/s] 20%|██        | 218/1070 [00:25<03:15,  4.35it/s] 20%|██        | 219/1070 [00:26<02:46,  5.10it/s] 21%|██        | 220/1070 [00:26<02:25,  5.83it/s] 21%|██        | 221/1070 [00:26<02:09,  6.57it/s] 21%|██        | 222/1070 [00:26<01:57,  7.25it/s] 21%|██        | 223/1070 [00:26<01:49,  7.74it/s] 21%|██        | 224/1070 [00:26<01:43,  8.21it/s] 21%|██        | 225/1070 [00:26<01:39,  8.47it/s] 21%|██        | 226/1070 [00:26<01:37,  8.67it/s] 21%|██        | 227/1070 [00:26<01:35,  8.87it/s] 21%|██▏       | 228/1070 [00:27<01:33,  8.96it/s] 21%|██▏       | 229/1070 [00:27<01:32,  9.05it/s] 21%|██▏       | 230/1070 [00:27<01:32,  9.11it/s] 22%|██▏       | 231/1070 [00:27<01:30,  9.25it/s] 22%|██▏       | 232/1070 [00:27<01:30,  9.28it/s] 22%|██▏       | 233/1070 [00:27<01:29,  9.30it/s] 22%|██▏       | 234/1070 [00:27<01:29,  9.31it/s] 22%|██▏       | 235/1070 [00:27<01:30,  9.24it/s] 22%|██▏       | 236/1070 [00:27<01:30,  9.21it/s] 22%|██▏       | 237/1070 [00:28<01:30,  9.19it/s] 22%|██▏       | 238/1070 [00:28<01:30,  9.22it/s] 22%|██▏       | 239/1070 [00:28<01:29,  9.28it/s] 22%|██▏       | 240/1070 [00:28<01:29,  9.27it/s] 23%|██▎       | 241/1070 [00:28<01:28,  9.34it/s] 23%|██▎       | 242/1070 [00:28<01:28,  9.32it/s] 23%|██▎       | 243/1070 [00:28<01:28,  9.32it/s] 23%|██▎       | 244/1070 [00:28<01:28,  9.33it/s] 23%|██▎       | 245/1070 [00:28<01:28,  9.27it/s] 23%|██▎       | 246/1070 [00:29<01:28,  9.27it/s] 23%|██▎       | 247/1070 [00:29<01:28,  9.26it/s] 23%|██▎       | 248/1070 [00:29<01:29,  9.22it/s] 23%|██▎       | 249/1070 [00:29<01:29,  9.19it/s] 23%|██▎       | 250/1070 [00:29<01:29,  9.18it/s] 23%|██▎       | 251/1070 [00:29<01:28,  9.21it/s] 24%|██▎       | 252/1070 [00:29<01:28,  9.27it/s] 24%|██▎       | 253/1070 [00:29<01:27,  9.36it/s] 24%|██▎       | 254/1070 [00:29<01:27,  9.37it/s] 24%|██▍       | 255/1070 [00:29<01:27,  9.33it/s] 24%|██▍       | 256/1070 [00:30<01:27,  9.25it/s] 24%|██▍       | 257/1070 [00:30<01:27,  9.29it/s] 24%|██▍       | 258/1070 [00:30<01:27,  9.24it/s] 24%|██▍       | 259/1070 [00:30<01:27,  9.23it/s] 24%|██▍       | 260/1070 [00:30<01:27,  9.23it/s] 24%|██▍       | 261/1070 [00:30<01:27,  9.29it/s] 24%|██▍       | 262/1070 [00:30<01:26,  9.30it/s] 25%|██▍       | 263/1070 [00:30<01:26,  9.28it/s] 25%|██▍       | 264/1070 [00:30<01:26,  9.28it/s] 25%|██▍       | 265/1070 [00:31<01:27,  9.21it/s] 25%|██▍       | 266/1070 [00:31<01:27,  9.21it/s] 25%|██▍       | 267/1070 [00:31<01:27,  9.20it/s] 25%|██▌       | 268/1070 [00:31<01:27,  9.17it/s] 25%|██▌       | 269/1070 [00:31<01:27,  9.15it/s] 25%|██▌       | 270/1070 [00:31<01:26,  9.22it/s] 25%|██▌       | 271/1070 [00:31<01:26,  9.27it/s] 25%|██▌       | 272/1070 [00:31<01:25,  9.29it/s] 26%|██▌       | 273/1070 [00:31<01:25,  9.30it/s] 26%|██▌       | 274/1070 [00:32<01:25,  9.32it/s] 26%|██▌       | 275/1070 [00:32<01:25,  9.26it/s] 26%|██▌       | 276/1070 [00:32<01:25,  9.24it/s] 26%|██▌       | 277/1070 [00:32<01:26,  9.19it/s] 26%|██▌       | 278/1070 [00:32<01:26,  9.18it/s] 26%|██▌       | 279/1070 [00:32<01:25,  9.20it/s] 26%|██▌       | 280/1070 [00:32<01:26,  9.16it/s] 26%|██▋       | 281/1070 [00:32<01:25,  9.24it/s] 26%|██▋       | 282/1070 [00:32<01:25,  9.27it/s] 26%|██▋       | 283/1070 [00:33<01:24,  9.31it/s] 27%|██▋       | 284/1070 [00:33<01:24,  9.29it/s] 27%|██▋       | 285/1070 [00:33<01:25,  9.23it/s] 27%|██▋       | 286/1070 [00:33<01:25,  9.19it/s] 27%|██▋       | 287/1070 [00:33<01:24,  9.22it/s] 27%|██▋       | 288/1070 [00:33<01:25,  9.19it/s] 27%|██▋       | 289/1070 [00:33<01:24,  9.21it/s] 27%|██▋       | 290/1070 [00:33<01:24,  9.21it/s] 27%|██▋       | 291/1070 [00:33<01:24,  9.24it/s] 27%|██▋       | 292/1070 [00:33<01:23,  9.31it/s] 27%|██▋       | 293/1070 [00:34<01:23,  9.27it/s] 27%|██▋       | 294/1070 [00:34<01:23,  9.28it/s] 28%|██▊       | 295/1070 [00:34<01:23,  9.26it/s] 28%|██▊       | 296/1070 [00:34<01:23,  9.23it/s] 28%|██▊       | 297/1070 [00:34<01:23,  9.22it/s] 28%|██▊       | 298/1070 [00:34<01:24,  9.18it/s] 28%|██▊       | 299/1070 [00:34<01:24,  9.16it/s] 28%|██▊       | 300/1070 [00:34<01:24,  9.16it/s] 28%|██▊       | 301/1070 [00:34<01:23,  9.23it/s] 28%|██▊       | 302/1070 [00:35<01:23,  9.21it/s] 28%|██▊       | 303/1070 [00:35<01:22,  9.28it/s] 28%|██▊       | 304/1070 [00:35<01:22,  9.23it/s] 29%|██▊       | 305/1070 [00:35<01:22,  9.25it/s] 29%|██▊       | 306/1070 [00:35<01:23,  9.19it/s] 29%|██▊       | 307/1070 [00:35<01:22,  9.22it/s] 29%|██▉       | 308/1070 [00:35<01:23,  9.13it/s] 29%|██▉       | 309/1070 [00:35<01:23,  9.16it/s] 29%|██▉       | 310/1070 [00:35<01:23,  9.14it/s] 29%|██▉       | 311/1070 [00:36<01:21,  9.28it/s] 29%|██▉       | 312/1070 [00:36<01:21,  9.26it/s] 29%|██▉       | 313/1070 [00:36<01:21,  9.31it/s] 29%|██▉       | 314/1070 [00:36<01:21,  9.26it/s] 29%|██▉       | 315/1070 [00:36<01:21,  9.31it/s] 30%|██▉       | 316/1070 [00:36<01:21,  9.23it/s] 30%|██▉       | 317/1070 [00:36<01:21,  9.26it/s] 30%|██▉       | 318/1070 [00:36<01:21,  9.20it/s] 30%|██▉       | 319/1070 [00:36<01:21,  9.23it/s] 30%|██▉       | 320/1070 [00:37<01:21,  9.18it/s] 30%|███       | 321/1070 [00:37<01:20,  9.26it/s] 30%|███       | 322/1070 [00:37<01:20,  9.27it/s] 30%|███       | 323/1070 [00:37<01:21,  9.22it/s] 30%|███       | 324/1070 [00:37<01:20,  9.22it/s] 30%|███       | 325/1070 [00:37<01:20,  9.22it/s] 30%|███       | 326/1070 [00:37<01:21,  9.10it/s] 31%|███       | 327/1070 [00:37<01:21,  9.14it/s] 31%|███       | 328/1070 [00:37<01:21,  9.10it/s] 31%|███       | 329/1070 [00:37<01:20,  9.16it/s] 31%|███       | 330/1070 [00:38<01:20,  9.20it/s] 31%|███       | 331/1070 [00:38<01:20,  9.22it/s] 31%|███       | 332/1070 [00:38<01:20,  9.14it/s] 31%|███       | 333/1070 [00:38<01:21,  9.06it/s] 31%|███       | 334/1070 [00:38<01:20,  9.13it/s] 31%|███▏      | 335/1070 [00:38<01:21,  9.06it/s] 31%|███▏      | 336/1070 [00:38<01:20,  9.08it/s] 31%|███▏      | 337/1070 [00:38<01:21,  9.02it/s] 32%|███▏      | 338/1070 [00:38<01:20,  9.13it/s] 32%|███▏      | 339/1070 [00:39<01:20,  9.10it/s] 32%|███▏      | 340/1070 [00:39<01:19,  9.13it/s] 32%|███▏      | 341/1070 [00:39<01:20,  9.06it/s] 32%|███▏      | 342/1070 [00:39<01:19,  9.12it/s] 32%|███▏      | 343/1070 [00:39<01:19,  9.12it/s] 32%|███▏      | 344/1070 [00:39<01:20,  9.05it/s] 32%|███▏      | 345/1070 [00:39<01:19,  9.12it/s] 32%|███▏      | 346/1070 [00:39<01:19,  9.14it/s] 32%|███▏      | 347/1070 [00:39<01:19,  9.07it/s] 33%|███▎      | 348/1070 [00:40<01:19,  9.09it/s] 33%|███▎      | 349/1070 [00:40<01:19,  9.09it/s] 33%|███▎      | 350/1070 [00:40<01:19,  9.03it/s] 33%|███▎      | 351/1070 [00:40<01:19,  9.05it/s] 33%|███▎      | 352/1070 [00:40<01:19,  9.04it/s] 33%|███▎      | 353/1070 [00:40<01:18,  9.13it/s] 33%|███▎      | 354/1070 [00:40<01:18,  9.13it/s] 33%|███▎      | 355/1070 [00:40<01:17,  9.24it/s] 33%|███▎      | 356/1070 [00:40<01:18,  9.12it/s] 33%|███▎      | 357/1070 [00:41<01:17,  9.15it/s] 33%|███▎      | 358/1070 [00:41<01:17,  9.16it/s] 34%|███▎      | 359/1070 [00:41<01:18,  9.11it/s] 34%|███▎      | 360/1070 [00:41<01:18,  9.05it/s] 34%|███▎      | 361/1070 [00:41<01:18,  9.05it/s] 34%|███▍      | 362/1070 [00:41<01:17,  9.16it/s] 34%|███▍      | 363/1070 [00:41<01:17,  9.09it/s] 34%|███▍      | 364/1070 [00:41<01:17,  9.08it/s] 34%|███▍      | 365/1070 [00:41<01:18,  9.04it/s] 34%|███▍      | 366/1070 [00:42<01:17,  9.08it/s] 34%|███▍      | 367/1070 [00:42<01:18,  9.00it/s] 34%|███▍      | 368/1070 [00:42<01:17,  9.08it/s] 34%|███▍      | 369/1070 [00:42<01:16,  9.11it/s] 35%|███▍      | 370/1070 [00:42<01:16,  9.16it/s] 35%|███▍      | 371/1070 [00:42<01:16,  9.19it/s] 35%|███▍      | 372/1070 [00:42<01:15,  9.26it/s] 35%|███▍      | 373/1070 [00:42<01:15,  9.19it/s] 35%|███▍      | 374/1070 [00:42<01:16,  9.15it/s] 35%|███▌      | 375/1070 [00:43<01:15,  9.19it/s] 35%|███▌      | 376/1070 [00:43<01:16,  9.13it/s] 35%|███▌      | 377/1070 [00:43<01:15,  9.16it/s] 35%|███▌      | 378/1070 [00:43<01:15,  9.18it/s] 35%|███▌      | 379/1070 [00:43<01:14,  9.24it/s] 36%|███▌      | 380/1070 [00:43<01:15,  9.20it/s] 36%|███▌      | 381/1070 [00:43<01:14,  9.21it/s] 36%|███▌      | 382/1070 [00:43<01:15,  9.13it/s] 36%|███▌      | 383/1070 [00:43<01:14,  9.16it/s] 36%|███▌      | 384/1070 [00:44<01:15,  9.08it/s] 36%|███▌      | 385/1070 [00:44<01:15,  9.05it/s] 36%|███▌      | 386/1070 [00:44<01:15,  9.06it/s] 36%|███▌      | 387/1070 [00:44<01:15,  9.10it/s] 36%|███▋      | 388/1070 [00:44<01:14,  9.20it/s] 36%|███▋      | 389/1070 [00:44<01:13,  9.26it/s] 36%|███▋      | 390/1070 [00:44<01:13,  9.21it/s] 37%|███▋      | 391/1070 [00:44<01:13,  9.21it/s] 37%|███▋      | 392/1070 [00:44<01:13,  9.23it/s] 37%|███▋      | 393/1070 [00:45<01:13,  9.24it/s] 37%|███▋      | 394/1070 [00:45<01:13,  9.24it/s] 37%|███▋      | 395/1070 [00:45<01:13,  9.16it/s] 37%|███▋      | 396/1070 [00:45<01:12,  9.30it/s] 37%|███▋      | 397/1070 [00:45<01:13,  9.20it/s] 37%|███▋      | 398/1070 [00:45<01:13,  9.17it/s] 37%|███▋      | 399/1070 [00:45<01:13,  9.15it/s] 37%|███▋      | 400/1070 [00:45<01:13,  9.16it/s] 37%|███▋      | 401/1070 [00:45<01:13,  9.12it/s] 38%|███▊      | 402/1070 [00:45<01:13,  9.14it/s] 38%|███▊      | 403/1070 [00:46<01:12,  9.19it/s] 38%|███▊      | 404/1070 [00:46<01:12,  9.19it/s] 38%|███▊      | 405/1070 [00:46<01:12,  9.12it/s] 38%|███▊      | 406/1070 [00:46<01:12,  9.18it/s] 38%|███▊      | 407/1070 [00:46<01:13,  9.07it/s] 38%|███▊      | 408/1070 [00:46<01:13,  9.06it/s] 38%|███▊      | 409/1070 [00:46<01:12,  9.11it/s] 38%|███▊      | 410/1070 [00:46<01:12,  9.14it/s] 38%|███▊      | 411/1070 [00:46<01:12,  9.13it/s] 39%|███▊      | 412/1070 [00:47<01:12,  9.07it/s] 39%|███▊      | 413/1070 [00:47<01:11,  9.19it/s] 39%|███▊      | 414/1070 [00:47<01:11,  9.14it/s] 39%|███▉      | 415/1070 [00:47<01:11,  9.11it/s] 39%|███▉      | 416/1070 [00:47<01:12,  9.06it/s] 39%|███▉      | 417/1070 [00:47<01:11,  9.07it/s] 39%|███▉      | 418/1070 [00:47<01:12,  8.97it/s] 39%|███▉      | 419/1070 [00:47<01:11,  9.05it/s] 39%|███▉      | 420/1070 [00:47<01:11,  9.08it/s] 39%|███▉      | 421/1070 [00:48<01:11,  9.11it/s] 39%|███▉      | 422/1070 [00:48<01:11,  9.13it/s] 40%|███▉      | 423/1070 [00:48<01:10,  9.23it/s] 40%|███▉      | 424/1070 [00:48<01:10,  9.13it/s] 40%|███▉      | 425/1070 [00:48<01:11,  9.07it/s] 40%|███▉      | 426/1070 [00:48<01:11,  9.05it/s] 40%|███▉      | 427/1070 [00:48<01:10,  9.13it/s]                                                   40%|████      | 428/1070 [00:48<01:10,  9.13it/s][INFO|trainer.py:755] 2023-11-15 20:19:24,358 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:19:24,359 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:19:24,360 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:19:24,360 >>   Batch size = 8
{'eval_loss': 0.3392934799194336, 'eval_accuracy': 0.8921052631578947, 'eval_micro_f1': 0.8921052631578947, 'eval_macro_f1': 0.8888626369014562, 'eval_runtime': 1.3073, 'eval_samples_per_second': 581.329, 'eval_steps_per_second': 72.666, 'epoch': 1.0}
{'loss': 0.2406, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 80.99it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 76.31it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 75.07it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 72.86it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 74.00it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 72.78it/s][A
 61%|██████    | 58/95 [00:00<00:00, 72.46it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 73.09it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 71.39it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 71.64it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 71.30it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:50<01:10,  9.13it/s]
100%|██████████| 95/95 [00:01<00:00, 71.30it/s][A
                                               [A 40%|████      | 429/1070 [00:50<04:29,  2.38it/s] 40%|████      | 430/1070 [00:50<03:40,  2.91it/s] 40%|████      | 431/1070 [00:50<03:00,  3.54it/s] 40%|████      | 432/1070 [00:50<02:30,  4.25it/s] 40%|████      | 433/1070 [00:50<02:07,  5.01it/s] 41%|████      | 434/1070 [00:50<01:50,  5.77it/s] 41%|████      | 435/1070 [00:50<01:38,  6.43it/s] 41%|████      | 436/1070 [00:51<01:29,  7.06it/s] 41%|████      | 437/1070 [00:51<01:23,  7.54it/s] 41%|████      | 438/1070 [00:51<01:19,  7.94it/s] 41%|████      | 439/1070 [00:51<01:16,  8.23it/s] 41%|████      | 440/1070 [00:51<01:14,  8.48it/s] 41%|████      | 441/1070 [00:51<01:12,  8.73it/s] 41%|████▏     | 442/1070 [00:51<01:10,  8.91it/s] 41%|████▏     | 443/1070 [00:51<01:09,  9.00it/s] 41%|████▏     | 444/1070 [00:51<01:09,  9.06it/s] 42%|████▏     | 445/1070 [00:52<01:09,  9.00it/s] 42%|████▏     | 446/1070 [00:52<01:09,  8.99it/s] 42%|████▏     | 447/1070 [00:52<01:09,  9.00it/s] 42%|████▏     | 448/1070 [00:52<01:08,  9.06it/s] 42%|████▏     | 449/1070 [00:52<01:08,  9.09it/s] 42%|████▏     | 450/1070 [00:52<01:08,  9.10it/s] 42%|████▏     | 451/1070 [00:52<01:07,  9.15it/s] 42%|████▏     | 452/1070 [00:52<01:07,  9.20it/s] 42%|████▏     | 453/1070 [00:52<01:06,  9.24it/s] 42%|████▏     | 454/1070 [00:53<01:07,  9.17it/s] 43%|████▎     | 455/1070 [00:53<01:07,  9.12it/s] 43%|████▎     | 456/1070 [00:53<01:07,  9.14it/s] 43%|████▎     | 457/1070 [00:53<01:06,  9.15it/s] 43%|████▎     | 458/1070 [00:53<01:06,  9.16it/s] 43%|████▎     | 459/1070 [00:53<01:06,  9.12it/s] 43%|████▎     | 460/1070 [00:53<01:06,  9.12it/s] 43%|████▎     | 461/1070 [00:53<01:06,  9.22it/s] 43%|████▎     | 462/1070 [00:53<01:05,  9.27it/s] 43%|████▎     | 463/1070 [00:54<01:05,  9.26it/s] 43%|████▎     | 464/1070 [00:54<01:05,  9.20it/s] 43%|████▎     | 465/1070 [00:54<01:05,  9.19it/s] 44%|████▎     | 466/1070 [00:54<01:06,  9.14it/s] 44%|████▎     | 467/1070 [00:54<01:05,  9.15it/s] 44%|████▎     | 468/1070 [00:54<01:05,  9.15it/s] 44%|████▍     | 469/1070 [00:54<01:05,  9.14it/s] 44%|████▍     | 470/1070 [00:54<01:05,  9.14it/s] 44%|████▍     | 471/1070 [00:54<01:04,  9.23it/s] 44%|████▍     | 472/1070 [00:54<01:05,  9.16it/s] 44%|████▍     | 473/1070 [00:55<01:05,  9.15it/s] 44%|████▍     | 474/1070 [00:55<01:05,  9.09it/s] 44%|████▍     | 475/1070 [00:55<01:05,  9.14it/s] 44%|████▍     | 476/1070 [00:55<01:05,  9.09it/s] 45%|████▍     | 477/1070 [00:55<01:05,  9.09it/s] 45%|████▍     | 478/1070 [00:55<01:04,  9.18it/s] 45%|████▍     | 479/1070 [00:55<01:03,  9.30it/s] 45%|████▍     | 480/1070 [00:55<01:03,  9.33it/s] 45%|████▍     | 481/1070 [00:55<01:03,  9.31it/s] 45%|████▌     | 482/1070 [00:56<01:04,  9.17it/s] 45%|████▌     | 483/1070 [00:56<01:04,  9.17it/s] 45%|████▌     | 484/1070 [00:56<01:03,  9.20it/s] 45%|████▌     | 485/1070 [00:56<01:04,  9.10it/s] 45%|████▌     | 486/1070 [00:56<01:04,  9.09it/s] 46%|████▌     | 487/1070 [00:56<01:04,  9.02it/s] 46%|████▌     | 488/1070 [00:56<01:03,  9.15it/s] 46%|████▌     | 489/1070 [00:56<01:03,  9.12it/s] 46%|████▌     | 490/1070 [00:56<01:03,  9.12it/s] 46%|████▌     | 491/1070 [00:57<01:03,  9.07it/s] 46%|████▌     | 492/1070 [00:57<01:03,  9.09it/s] 46%|████▌     | 493/1070 [00:57<01:03,  9.05it/s] 46%|████▌     | 494/1070 [00:57<01:03,  9.01it/s] 46%|████▋     | 495/1070 [00:57<01:03,  9.02it/s] 46%|████▋     | 496/1070 [00:57<01:03,  9.09it/s] 46%|████▋     | 497/1070 [00:57<01:02,  9.16it/s] 47%|████▋     | 498/1070 [00:57<01:02,  9.17it/s] 47%|████▋     | 499/1070 [00:57<01:03,  9.06it/s] 47%|████▋     | 500/1070 [00:58<01:02,  9.05it/s] 47%|████▋     | 501/1070 [00:58<01:03,  9.02it/s] 47%|████▋     | 502/1070 [00:58<01:03,  8.99it/s] 47%|████▋     | 503/1070 [00:58<01:02,  9.08it/s] 47%|████▋     | 504/1070 [00:58<01:02,  9.09it/s] 47%|████▋     | 505/1070 [00:58<01:01,  9.18it/s] 47%|████▋     | 506/1070 [00:58<01:01,  9.13it/s] 47%|████▋     | 507/1070 [00:58<01:01,  9.14it/s] 47%|████▋     | 508/1070 [00:58<01:02,  8.98it/s] 48%|████▊     | 509/1070 [00:59<01:01,  9.05it/s] 48%|████▊     | 510/1070 [00:59<01:01,  9.03it/s] 48%|████▊     | 511/1070 [00:59<01:01,  9.06it/s] 48%|████▊     | 512/1070 [00:59<01:01,  9.11it/s] 48%|████▊     | 513/1070 [00:59<01:00,  9.13it/s] 48%|████▊     | 514/1070 [00:59<01:00,  9.18it/s] 48%|████▊     | 515/1070 [00:59<01:00,  9.17it/s] 48%|████▊     | 516/1070 [00:59<01:00,  9.13it/s] 48%|████▊     | 517/1070 [00:59<01:00,  9.11it/s] 48%|████▊     | 518/1070 [01:00<01:00,  9.05it/s] 49%|████▊     | 519/1070 [01:00<01:00,  9.10it/s] 49%|████▊     | 520/1070 [01:00<01:00,  9.14it/s] 49%|████▊     | 521/1070 [01:00<01:00,  9.14it/s] 49%|████▉     | 522/1070 [01:00<00:59,  9.20it/s] 49%|████▉     | 523/1070 [01:00<01:00,  9.11it/s] 49%|████▉     | 524/1070 [01:00<00:59,  9.12it/s] 49%|████▉     | 525/1070 [01:00<00:59,  9.10it/s] 49%|████▉     | 526/1070 [01:00<01:00,  9.05it/s] 49%|████▉     | 527/1070 [01:01<00:59,  9.08it/s] 49%|████▉     | 528/1070 [01:01<00:59,  9.12it/s] 49%|████▉     | 529/1070 [01:01<00:58,  9.22it/s] 50%|████▉     | 530/1070 [01:01<00:59,  9.12it/s] 50%|████▉     | 531/1070 [01:01<00:59,  9.10it/s] 50%|████▉     | 532/1070 [01:01<00:59,  9.02it/s] 50%|████▉     | 533/1070 [01:01<00:59,  9.03it/s] 50%|████▉     | 534/1070 [01:01<00:59,  8.98it/s] 50%|█████     | 535/1070 [01:01<00:59,  9.02it/s] 50%|█████     | 536/1070 [01:02<00:58,  9.09it/s] 50%|█████     | 537/1070 [01:02<00:58,  9.12it/s] 50%|█████     | 538/1070 [01:02<00:58,  9.10it/s] 50%|█████     | 539/1070 [01:02<00:58,  9.06it/s] 50%|█████     | 540/1070 [01:02<00:58,  9.11it/s] 51%|█████     | 541/1070 [01:02<00:58,  9.00it/s] 51%|█████     | 542/1070 [01:02<00:58,  9.00it/s] 51%|█████     | 543/1070 [01:02<00:58,  9.01it/s] 51%|█████     | 544/1070 [01:02<00:58,  9.05it/s] 51%|█████     | 545/1070 [01:03<00:58,  9.04it/s] 51%|█████     | 546/1070 [01:03<00:57,  9.12it/s] 51%|█████     | 547/1070 [01:03<00:57,  9.05it/s] 51%|█████     | 548/1070 [01:03<00:57,  9.05it/s] 51%|█████▏    | 549/1070 [01:03<00:57,  9.06it/s] 51%|█████▏    | 550/1070 [01:03<00:57,  8.97it/s] 51%|█████▏    | 551/1070 [01:03<00:57,  9.04it/s] 52%|█████▏    | 552/1070 [01:03<00:57,  9.00it/s] 52%|█████▏    | 553/1070 [01:03<00:56,  9.12it/s] 52%|█████▏    | 554/1070 [01:04<00:57,  9.03it/s] 52%|█████▏    | 555/1070 [01:04<00:56,  9.05it/s] 52%|█████▏    | 556/1070 [01:04<00:57,  8.96it/s] 52%|█████▏    | 557/1070 [01:04<00:56,  9.02it/s] 52%|█████▏    | 558/1070 [01:04<00:56,  8.99it/s] 52%|█████▏    | 559/1070 [01:04<00:57,  8.91it/s] 52%|█████▏    | 560/1070 [01:04<00:56,  9.07it/s] 52%|█████▏    | 561/1070 [01:04<00:56,  9.07it/s] 53%|█████▎    | 562/1070 [01:04<00:55,  9.11it/s] 53%|█████▎    | 563/1070 [01:05<00:56,  9.05it/s] 53%|█████▎    | 564/1070 [01:05<00:55,  9.07it/s] 53%|█████▎    | 565/1070 [01:05<00:56,  8.97it/s] 53%|█████▎    | 566/1070 [01:05<00:56,  8.95it/s] 53%|█████▎    | 567/1070 [01:05<00:55,  8.98it/s] 53%|█████▎    | 568/1070 [01:05<00:55,  9.03it/s] 53%|█████▎    | 569/1070 [01:05<00:55,  9.00it/s] 53%|█████▎    | 570/1070 [01:05<00:55,  9.03it/s] 53%|█████▎    | 571/1070 [01:05<00:55,  9.02it/s] 53%|█████▎    | 572/1070 [01:06<00:55,  9.00it/s] 54%|█████▎    | 573/1070 [01:06<00:55,  8.95it/s] 54%|█████▎    | 574/1070 [01:06<00:54,  9.02it/s] 54%|█████▎    | 575/1070 [01:06<00:54,  9.01it/s] 54%|█████▍    | 576/1070 [01:06<00:54,  9.01it/s] 54%|█████▍    | 577/1070 [01:06<00:54,  9.00it/s] 54%|█████▍    | 578/1070 [01:06<00:54,  9.02it/s] 54%|█████▍    | 579/1070 [01:06<00:54,  8.96it/s] 54%|█████▍    | 580/1070 [01:06<00:54,  8.96it/s] 54%|█████▍    | 581/1070 [01:07<00:54,  9.00it/s] 54%|█████▍    | 582/1070 [01:07<00:54,  8.99it/s] 54%|█████▍    | 583/1070 [01:07<00:54,  9.00it/s] 55%|█████▍    | 584/1070 [01:07<00:54,  8.98it/s] 55%|█████▍    | 585/1070 [01:07<00:54,  8.96it/s] 55%|█████▍    | 586/1070 [01:07<00:54,  8.93it/s] 55%|█████▍    | 587/1070 [01:07<00:54,  8.91it/s] 55%|█████▍    | 588/1070 [01:07<00:53,  8.99it/s] 55%|█████▌    | 589/1070 [01:07<00:53,  8.95it/s] 55%|█████▌    | 590/1070 [01:08<00:53,  8.99it/s] 55%|█████▌    | 591/1070 [01:08<00:53,  8.98it/s] 55%|█████▌    | 592/1070 [01:08<00:53,  8.99it/s] 55%|█████▌    | 593/1070 [01:08<00:53,  8.95it/s] 56%|█████▌    | 594/1070 [01:08<00:53,  8.93it/s] 56%|█████▌    | 595/1070 [01:08<00:52,  8.96it/s] 56%|█████▌    | 596/1070 [01:08<00:52,  8.99it/s] 56%|█████▌    | 597/1070 [01:08<00:52,  9.01it/s] 56%|█████▌    | 598/1070 [01:08<00:52,  9.01it/s] 56%|█████▌    | 599/1070 [01:09<00:52,  9.00it/s] 56%|█████▌    | 600/1070 [01:09<00:52,  8.90it/s] 56%|█████▌    | 601/1070 [01:09<00:52,  8.92it/s] 56%|█████▋    | 602/1070 [01:09<00:52,  8.92it/s] 56%|█████▋    | 603/1070 [01:09<00:52,  8.95it/s] 56%|█████▋    | 604/1070 [01:09<00:51,  9.04it/s] 57%|█████▋    | 605/1070 [01:09<00:51,  9.01it/s] 57%|█████▋    | 606/1070 [01:09<00:51,  9.00it/s] 57%|█████▋    | 607/1070 [01:09<00:51,  8.93it/s] 57%|█████▋    | 608/1070 [01:10<00:51,  8.95it/s] 57%|█████▋    | 609/1070 [01:10<00:51,  8.99it/s] 57%|█████▋    | 610/1070 [01:10<00:51,  8.97it/s] 57%|█████▋    | 611/1070 [01:10<00:50,  9.01it/s] 57%|█████▋    | 612/1070 [01:10<00:50,  9.01it/s] 57%|█████▋    | 613/1070 [01:10<00:50,  9.01it/s] 57%|█████▋    | 614/1070 [01:10<00:51,  8.91it/s] 57%|█████▋    | 615/1070 [01:10<00:50,  8.96it/s] 58%|█████▊    | 616/1070 [01:10<00:50,  8.94it/s] 58%|█████▊    | 617/1070 [01:11<00:50,  8.95it/s] 58%|█████▊    | 618/1070 [01:11<00:50,  9.00it/s] 58%|█████▊    | 619/1070 [01:11<00:49,  9.03it/s] 58%|█████▊    | 620/1070 [01:11<00:49,  9.01it/s] 58%|█████▊    | 621/1070 [01:11<00:50,  8.91it/s] 58%|█████▊    | 622/1070 [01:11<00:50,  8.91it/s] 58%|█████▊    | 623/1070 [01:11<00:50,  8.88it/s] 58%|█████▊    | 624/1070 [01:11<00:50,  8.91it/s] 58%|█████▊    | 625/1070 [01:11<00:49,  8.95it/s] 59%|█████▊    | 626/1070 [01:12<00:49,  9.00it/s] 59%|█████▊    | 627/1070 [01:12<00:49,  9.00it/s] 59%|█████▊    | 628/1070 [01:12<00:49,  8.93it/s] 59%|█████▉    | 629/1070 [01:12<00:49,  8.93it/s] 59%|█████▉    | 630/1070 [01:12<00:49,  8.97it/s] 59%|█████▉    | 631/1070 [01:12<00:48,  9.01it/s] 59%|█████▉    | 632/1070 [01:12<00:48,  8.99it/s] 59%|█████▉    | 633/1070 [01:12<00:48,  9.00it/s] 59%|█████▉    | 634/1070 [01:12<00:48,  9.02it/s] 59%|█████▉    | 635/1070 [01:13<00:48,  8.92it/s] 59%|█████▉    | 636/1070 [01:13<00:48,  8.90it/s] 60%|█████▉    | 637/1070 [01:13<00:48,  8.89it/s] 60%|█████▉    | 638/1070 [01:13<00:48,  8.96it/s] 60%|█████▉    | 639/1070 [01:13<00:47,  9.00it/s] 60%|█████▉    | 640/1070 [01:13<00:47,  9.02it/s] 60%|█████▉    | 641/1070 [01:13<00:47,  9.00it/s]                                                   60%|██████    | 642/1070 [01:13<00:47,  9.00it/s][INFO|trainer.py:755] 2023-11-15 20:19:49,335 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:19:49,337 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:19:49,338 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:19:49,338 >>   Batch size = 8
{'eval_loss': 0.3055296540260315, 'eval_accuracy': 0.9131578947368421, 'eval_micro_f1': 0.9131578947368421, 'eval_macro_f1': 0.9107881133112583, 'eval_runtime': 1.3596, 'eval_samples_per_second': 558.978, 'eval_steps_per_second': 69.872, 'epoch': 2.0}
{'loss': 0.1488, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 77.32it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 73.26it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 71.49it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 68.84it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 71.86it/s][A
 51%|█████     | 48/95 [00:00<00:00, 69.71it/s][A
 59%|█████▉    | 56/95 [00:00<00:00, 69.44it/s][A
 66%|██████▋   | 63/95 [00:00<00:00, 68.63it/s][A
 74%|███████▎  | 70/95 [00:01<00:00, 68.07it/s][A
 82%|████████▏ | 78/95 [00:01<00:00, 68.60it/s][A
 89%|████████▉ | 85/95 [00:01<00:00, 68.15it/s][A
 98%|█████████▊| 93/95 [00:01<00:00, 69.04it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:15<00:47,  9.00it/s]
100%|██████████| 95/95 [00:01<00:00, 69.04it/s][A
                                               [A 60%|██████    | 643/1070 [01:15<03:08,  2.27it/s] 60%|██████    | 644/1070 [01:15<02:33,  2.78it/s] 60%|██████    | 645/1070 [01:15<02:05,  3.39it/s] 60%|██████    | 646/1070 [01:15<01:43,  4.08it/s] 60%|██████    | 647/1070 [01:15<01:28,  4.81it/s] 61%|██████    | 648/1070 [01:15<01:16,  5.55it/s] 61%|██████    | 649/1070 [01:16<01:07,  6.24it/s] 61%|██████    | 650/1070 [01:16<01:01,  6.79it/s] 61%|██████    | 651/1070 [01:16<00:57,  7.33it/s] 61%|██████    | 652/1070 [01:16<00:53,  7.76it/s] 61%|██████    | 653/1070 [01:16<00:51,  8.11it/s] 61%|██████    | 654/1070 [01:16<00:49,  8.33it/s] 61%|██████    | 655/1070 [01:16<00:48,  8.59it/s] 61%|██████▏   | 656/1070 [01:16<00:47,  8.68it/s] 61%|██████▏   | 657/1070 [01:16<00:47,  8.72it/s] 61%|██████▏   | 658/1070 [01:17<00:47,  8.77it/s] 62%|██████▏   | 659/1070 [01:17<00:46,  8.86it/s] 62%|██████▏   | 660/1070 [01:17<00:45,  8.94it/s] 62%|██████▏   | 661/1070 [01:17<00:45,  9.00it/s] 62%|██████▏   | 662/1070 [01:17<00:45,  9.02it/s] 62%|██████▏   | 663/1070 [01:17<00:45,  9.01it/s] 62%|██████▏   | 664/1070 [01:17<00:45,  8.91it/s] 62%|██████▏   | 665/1070 [01:17<00:45,  8.91it/s] 62%|██████▏   | 666/1070 [01:17<00:45,  8.94it/s] 62%|██████▏   | 667/1070 [01:18<00:44,  8.98it/s] 62%|██████▏   | 668/1070 [01:18<00:44,  8.95it/s] 63%|██████▎   | 669/1070 [01:18<00:44,  8.98it/s] 63%|██████▎   | 670/1070 [01:18<00:44,  8.95it/s] 63%|██████▎   | 671/1070 [01:18<00:44,  8.87it/s] 63%|██████▎   | 672/1070 [01:18<00:44,  8.90it/s] 63%|██████▎   | 673/1070 [01:18<00:44,  8.92it/s] 63%|██████▎   | 674/1070 [01:18<00:43,  9.00it/s] 63%|██████▎   | 675/1070 [01:18<00:44,  8.96it/s] 63%|██████▎   | 676/1070 [01:19<00:43,  9.03it/s] 63%|██████▎   | 677/1070 [01:19<00:44,  8.90it/s] 63%|██████▎   | 678/1070 [01:19<00:44,  8.88it/s] 63%|██████▎   | 679/1070 [01:19<00:44,  8.87it/s] 64%|██████▎   | 680/1070 [01:19<00:43,  8.92it/s] 64%|██████▎   | 681/1070 [01:19<00:43,  8.96it/s] 64%|██████▎   | 682/1070 [01:19<00:43,  8.98it/s] 64%|██████▍   | 683/1070 [01:19<00:42,  9.04it/s] 64%|██████▍   | 684/1070 [01:19<00:43,  8.95it/s] 64%|██████▍   | 685/1070 [01:20<00:43,  8.93it/s] 64%|██████▍   | 686/1070 [01:20<00:43,  8.89it/s] 64%|██████▍   | 687/1070 [01:20<00:42,  8.94it/s] 64%|██████▍   | 688/1070 [01:20<00:42,  9.06it/s] 64%|██████▍   | 689/1070 [01:20<00:42,  9.05it/s] 64%|██████▍   | 690/1070 [01:20<00:41,  9.10it/s] 65%|██████▍   | 691/1070 [01:20<00:41,  9.07it/s] 65%|██████▍   | 692/1070 [01:20<00:42,  8.94it/s] 65%|██████▍   | 693/1070 [01:20<00:42,  8.94it/s] 65%|██████▍   | 694/1070 [01:21<00:42,  8.91it/s] 65%|██████▍   | 695/1070 [01:21<00:41,  8.98it/s] 65%|██████▌   | 696/1070 [01:21<00:41,  9.00it/s] 65%|██████▌   | 697/1070 [01:21<00:41,  9.04it/s] 65%|██████▌   | 698/1070 [01:21<00:41,  8.95it/s] 65%|██████▌   | 699/1070 [01:21<00:41,  8.89it/s] 65%|██████▌   | 700/1070 [01:21<00:41,  8.89it/s] 66%|██████▌   | 701/1070 [01:21<00:41,  8.94it/s] 66%|██████▌   | 702/1070 [01:21<00:41,  8.91it/s] 66%|██████▌   | 703/1070 [01:22<00:40,  9.01it/s] 66%|██████▌   | 704/1070 [01:22<00:40,  9.04it/s] 66%|██████▌   | 705/1070 [01:22<00:40,  9.04it/s] 66%|██████▌   | 706/1070 [01:22<00:40,  8.95it/s] 66%|██████▌   | 707/1070 [01:22<00:40,  8.90it/s] 66%|██████▌   | 708/1070 [01:22<00:40,  8.95it/s] 66%|██████▋   | 709/1070 [01:22<00:40,  8.96it/s] 66%|██████▋   | 710/1070 [01:22<00:40,  8.97it/s] 66%|██████▋   | 711/1070 [01:22<00:39,  9.03it/s] 67%|██████▋   | 712/1070 [01:23<00:39,  8.97it/s] 67%|██████▋   | 713/1070 [01:23<00:40,  8.91it/s] 67%|██████▋   | 714/1070 [01:23<00:39,  8.90it/s] 67%|██████▋   | 715/1070 [01:23<00:39,  8.93it/s] 67%|██████▋   | 716/1070 [01:23<00:39,  9.04it/s] 67%|██████▋   | 717/1070 [01:23<00:38,  9.05it/s] 67%|██████▋   | 718/1070 [01:23<00:38,  9.07it/s] 67%|██████▋   | 719/1070 [01:23<00:39,  8.97it/s] 67%|██████▋   | 720/1070 [01:23<00:39,  8.95it/s] 67%|██████▋   | 721/1070 [01:24<00:38,  8.98it/s] 67%|██████▋   | 722/1070 [01:24<00:38,  8.97it/s] 68%|██████▊   | 723/1070 [01:24<00:38,  9.03it/s] 68%|██████▊   | 724/1070 [01:24<00:38,  8.99it/s] 68%|██████▊   | 725/1070 [01:24<00:37,  9.08it/s] 68%|██████▊   | 726/1070 [01:24<00:38,  8.96it/s] 68%|██████▊   | 727/1070 [01:24<00:38,  8.87it/s] 68%|██████▊   | 728/1070 [01:24<00:38,  8.94it/s] 68%|██████▊   | 729/1070 [01:24<00:38,  8.92it/s] 68%|██████▊   | 730/1070 [01:25<00:37,  8.96it/s] 68%|██████▊   | 731/1070 [01:25<00:38,  8.89it/s] 68%|██████▊   | 732/1070 [01:25<00:37,  9.03it/s] 69%|██████▊   | 733/1070 [01:25<00:37,  8.94it/s] 69%|██████▊   | 734/1070 [01:25<00:37,  8.98it/s] 69%|██████▊   | 735/1070 [01:25<00:37,  8.96it/s] 69%|██████▉   | 736/1070 [01:25<00:37,  8.99it/s] 69%|██████▉   | 737/1070 [01:25<00:37,  8.98it/s] 69%|██████▉   | 738/1070 [01:25<00:36,  9.01it/s] 69%|██████▉   | 739/1070 [01:26<00:36,  9.05it/s] 69%|██████▉   | 740/1070 [01:26<00:36,  8.96it/s] 69%|██████▉   | 741/1070 [01:26<00:36,  9.03it/s] 69%|██████▉   | 742/1070 [01:26<00:36,  8.97it/s] 69%|██████▉   | 743/1070 [01:26<00:36,  8.94it/s] 70%|██████▉   | 744/1070 [01:26<00:36,  8.90it/s] 70%|██████▉   | 745/1070 [01:26<00:36,  8.91it/s] 70%|██████▉   | 746/1070 [01:26<00:36,  8.93it/s] 70%|██████▉   | 747/1070 [01:26<00:35,  8.98it/s] 70%|██████▉   | 748/1070 [01:27<00:35,  8.97it/s] 70%|███████   | 749/1070 [01:27<00:35,  8.96it/s] 70%|███████   | 750/1070 [01:27<00:35,  8.98it/s] 70%|███████   | 751/1070 [01:27<00:35,  8.97it/s] 70%|███████   | 752/1070 [01:27<00:35,  8.95it/s] 70%|███████   | 753/1070 [01:27<00:35,  8.95it/s] 70%|███████   | 754/1070 [01:27<00:35,  8.91it/s] 71%|███████   | 755/1070 [01:27<00:35,  8.96it/s] 71%|███████   | 756/1070 [01:27<00:35,  8.95it/s] 71%|███████   | 757/1070 [01:28<00:35,  8.94it/s] 71%|███████   | 758/1070 [01:28<00:35,  8.88it/s] 71%|███████   | 759/1070 [01:28<00:35,  8.82it/s] 71%|███████   | 760/1070 [01:28<00:35,  8.86it/s] 71%|███████   | 761/1070 [01:28<00:34,  8.93it/s] 71%|███████   | 762/1070 [01:28<00:34,  8.92it/s] 71%|███████▏  | 763/1070 [01:28<00:33,  9.03it/s] 71%|███████▏  | 764/1070 [01:28<00:34,  8.92it/s] 71%|███████▏  | 765/1070 [01:28<00:34,  8.93it/s] 72%|███████▏  | 766/1070 [01:29<00:34,  8.91it/s] 72%|███████▏  | 767/1070 [01:29<00:34,  8.90it/s] 72%|███████▏  | 768/1070 [01:29<00:33,  8.98it/s] 72%|███████▏  | 769/1070 [01:29<00:33,  8.95it/s] 72%|███████▏  | 770/1070 [01:29<00:33,  9.07it/s] 72%|███████▏  | 771/1070 [01:29<00:33,  8.94it/s] 72%|███████▏  | 772/1070 [01:29<00:33,  8.97it/s] 72%|███████▏  | 773/1070 [01:29<00:33,  8.99it/s] 72%|███████▏  | 774/1070 [01:29<00:32,  9.00it/s] 72%|███████▏  | 775/1070 [01:30<00:32,  9.01it/s] 73%|███████▎  | 776/1070 [01:30<00:32,  8.93it/s] 73%|███████▎  | 777/1070 [01:30<00:32,  9.09it/s] 73%|███████▎  | 778/1070 [01:30<00:32,  8.95it/s] 73%|███████▎  | 779/1070 [01:30<00:32,  8.93it/s] 73%|███████▎  | 780/1070 [01:30<00:32,  8.89it/s] 73%|███████▎  | 781/1070 [01:30<00:32,  8.92it/s] 73%|███████▎  | 782/1070 [01:30<00:32,  8.91it/s] 73%|███████▎  | 783/1070 [01:30<00:32,  8.84it/s] 73%|███████▎  | 784/1070 [01:31<00:31,  8.98it/s] 73%|███████▎  | 785/1070 [01:31<00:31,  8.97it/s] 73%|███████▎  | 786/1070 [01:31<00:31,  8.94it/s] 74%|███████▎  | 787/1070 [01:31<00:31,  8.86it/s] 74%|███████▎  | 788/1070 [01:31<00:31,  8.86it/s] 74%|███████▎  | 789/1070 [01:31<00:31,  8.83it/s] 74%|███████▍  | 790/1070 [01:31<00:31,  8.90it/s] 74%|███████▍  | 791/1070 [01:31<00:31,  8.91it/s] 74%|███████▍  | 792/1070 [01:31<00:31,  8.92it/s] 74%|███████▍  | 793/1070 [01:32<00:31,  8.89it/s] 74%|███████▍  | 794/1070 [01:32<00:31,  8.89it/s] 74%|███████▍  | 795/1070 [01:32<00:31,  8.87it/s] 74%|███████▍  | 796/1070 [01:32<00:30,  8.86it/s] 74%|███████▍  | 797/1070 [01:32<00:30,  8.83it/s] 75%|███████▍  | 798/1070 [01:32<00:30,  8.91it/s] 75%|███████▍  | 799/1070 [01:32<00:30,  9.00it/s] 75%|███████▍  | 800/1070 [01:32<00:29,  9.01it/s] 75%|███████▍  | 801/1070 [01:32<00:29,  9.03it/s] 75%|███████▍  | 802/1070 [01:33<00:29,  8.98it/s] 75%|███████▌  | 803/1070 [01:33<00:29,  8.97it/s] 75%|███████▌  | 804/1070 [01:33<00:29,  8.91it/s] 75%|███████▌  | 805/1070 [01:33<00:29,  8.88it/s] 75%|███████▌  | 806/1070 [01:33<00:29,  8.93it/s] 75%|███████▌  | 807/1070 [01:33<00:29,  8.91it/s] 76%|███████▌  | 808/1070 [01:33<00:29,  9.03it/s] 76%|███████▌  | 809/1070 [01:33<00:29,  8.95it/s] 76%|███████▌  | 810/1070 [01:34<00:29,  8.96it/s] 76%|███████▌  | 811/1070 [01:34<00:28,  8.99it/s] 76%|███████▌  | 812/1070 [01:34<00:28,  8.99it/s] 76%|███████▌  | 813/1070 [01:34<00:28,  8.98it/s] 76%|███████▌  | 814/1070 [01:34<00:28,  8.98it/s] 76%|███████▌  | 815/1070 [01:34<00:28,  9.08it/s] 76%|███████▋  | 816/1070 [01:34<00:28,  8.95it/s] 76%|███████▋  | 817/1070 [01:34<00:28,  8.97it/s] 76%|███████▋  | 818/1070 [01:34<00:28,  8.97it/s] 77%|███████▋  | 819/1070 [01:35<00:28,  8.96it/s] 77%|███████▋  | 820/1070 [01:35<00:27,  8.97it/s] 77%|███████▋  | 821/1070 [01:35<00:27,  8.97it/s] 77%|███████▋  | 822/1070 [01:35<00:27,  9.09it/s] 77%|███████▋  | 823/1070 [01:35<00:27,  8.99it/s] 77%|███████▋  | 824/1070 [01:35<00:27,  8.94it/s] 77%|███████▋  | 825/1070 [01:35<00:27,  8.97it/s] 77%|███████▋  | 826/1070 [01:35<00:27,  8.96it/s] 77%|███████▋  | 827/1070 [01:35<00:26,  9.03it/s] 77%|███████▋  | 828/1070 [01:36<00:26,  8.98it/s] 77%|███████▋  | 829/1070 [01:36<00:26,  9.05it/s] 78%|███████▊  | 830/1070 [01:36<00:26,  8.99it/s] 78%|███████▊  | 831/1070 [01:36<00:26,  8.92it/s] 78%|███████▊  | 832/1070 [01:36<00:26,  8.92it/s] 78%|███████▊  | 833/1070 [01:36<00:26,  8.88it/s] 78%|███████▊  | 834/1070 [01:36<00:26,  8.93it/s] 78%|███████▊  | 835/1070 [01:36<00:26,  8.94it/s] 78%|███████▊  | 836/1070 [01:36<00:25,  9.05it/s] 78%|███████▊  | 837/1070 [01:37<00:25,  8.96it/s] 78%|███████▊  | 838/1070 [01:37<00:26,  8.87it/s] 78%|███████▊  | 839/1070 [01:37<00:26,  8.83it/s] 79%|███████▊  | 840/1070 [01:37<00:25,  8.86it/s] 79%|███████▊  | 841/1070 [01:37<00:25,  8.85it/s] 79%|███████▊  | 842/1070 [01:37<00:25,  8.85it/s] 79%|███████▉  | 843/1070 [01:37<00:25,  8.96it/s] 79%|███████▉  | 844/1070 [01:37<00:25,  8.95it/s] 79%|███████▉  | 845/1070 [01:37<00:25,  8.93it/s] 79%|███████▉  | 846/1070 [01:38<00:25,  8.90it/s] 79%|███████▉  | 847/1070 [01:38<00:25,  8.91it/s] 79%|███████▉  | 848/1070 [01:38<00:25,  8.85it/s] 79%|███████▉  | 849/1070 [01:38<00:24,  8.89it/s] 79%|███████▉  | 850/1070 [01:38<00:24,  8.93it/s] 80%|███████▉  | 851/1070 [01:38<00:24,  8.95it/s] 80%|███████▉  | 852/1070 [01:38<00:24,  8.96it/s] 80%|███████▉  | 853/1070 [01:38<00:24,  8.95it/s] 80%|███████▉  | 854/1070 [01:38<00:24,  8.91it/s] 80%|███████▉  | 855/1070 [01:39<00:24,  8.90it/s]                                                   80%|████████  | 856/1070 [01:39<00:24,  8.90it/s][INFO|trainer.py:755] 2023-11-15 20:20:14,668 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:20:14,670 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:20:14,670 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:20:14,671 >>   Batch size = 8
{'eval_loss': 0.3689184784889221, 'eval_accuracy': 0.8973684210526316, 'eval_micro_f1': 0.8973684210526317, 'eval_macro_f1': 0.893814825411444, 'eval_runtime': 1.4176, 'eval_samples_per_second': 536.103, 'eval_steps_per_second': 67.013, 'epoch': 3.0}
{'loss': 0.0817, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 82.39it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 72.11it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 69.53it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 71.96it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 70.74it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 70.99it/s][A
 61%|██████    | 58/95 [00:00<00:00, 69.89it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 69.64it/s][A
 77%|███████▋  | 73/95 [00:01<00:00, 68.53it/s][A
 84%|████████▍ | 80/95 [00:01<00:00, 68.63it/s][A
 93%|█████████▎| 88/95 [00:01<00:00, 70.46it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:40<00:24,  8.90it/s]
100%|██████████| 95/95 [00:01<00:00, 70.46it/s][A
                                               [A 80%|████████  | 857/1070 [01:40<01:32,  2.30it/s] 80%|████████  | 858/1070 [01:40<01:15,  2.82it/s] 80%|████████  | 859/1070 [01:40<01:01,  3.43it/s] 80%|████████  | 860/1070 [01:41<00:51,  4.10it/s] 80%|████████  | 861/1070 [01:41<00:43,  4.82it/s] 81%|████████  | 862/1070 [01:41<00:37,  5.54it/s] 81%|████████  | 863/1070 [01:41<00:33,  6.26it/s] 81%|████████  | 864/1070 [01:41<00:30,  6.83it/s] 81%|████████  | 865/1070 [01:41<00:27,  7.41it/s] 81%|████████  | 866/1070 [01:41<00:26,  7.72it/s] 81%|████████  | 867/1070 [01:41<00:25,  8.05it/s] 81%|████████  | 868/1070 [01:41<00:24,  8.30it/s] 81%|████████  | 869/1070 [01:42<00:23,  8.45it/s] 81%|████████▏ | 870/1070 [01:42<00:23,  8.63it/s] 81%|████████▏ | 871/1070 [01:42<00:22,  8.69it/s] 81%|████████▏ | 872/1070 [01:42<00:22,  8.85it/s] 82%|████████▏ | 873/1070 [01:42<00:22,  8.86it/s] 82%|████████▏ | 874/1070 [01:42<00:22,  8.86it/s] 82%|████████▏ | 875/1070 [01:42<00:21,  8.89it/s] 82%|████████▏ | 876/1070 [01:42<00:21,  8.93it/s] 82%|████████▏ | 877/1070 [01:42<00:21,  8.92it/s] 82%|████████▏ | 878/1070 [01:43<00:21,  8.92it/s] 82%|████████▏ | 879/1070 [01:43<00:21,  9.03it/s] 82%|████████▏ | 880/1070 [01:43<00:21,  8.96it/s] 82%|████████▏ | 881/1070 [01:43<00:21,  8.96it/s] 82%|████████▏ | 882/1070 [01:43<00:20,  8.98it/s] 83%|████████▎ | 883/1070 [01:43<00:20,  8.95it/s] 83%|████████▎ | 884/1070 [01:43<00:20,  8.90it/s] 83%|████████▎ | 885/1070 [01:43<00:20,  8.84it/s] 83%|████████▎ | 886/1070 [01:43<00:20,  8.91it/s] 83%|████████▎ | 887/1070 [01:44<00:20,  8.92it/s] 83%|████████▎ | 888/1070 [01:44<00:20,  8.92it/s] 83%|████████▎ | 889/1070 [01:44<00:20,  8.88it/s] 83%|████████▎ | 890/1070 [01:44<00:20,  8.92it/s] 83%|████████▎ | 891/1070 [01:44<00:20,  8.85it/s] 83%|████████▎ | 892/1070 [01:44<00:20,  8.88it/s] 83%|████████▎ | 893/1070 [01:44<00:19,  8.91it/s] 84%|████████▎ | 894/1070 [01:44<00:19,  8.91it/s] 84%|████████▎ | 895/1070 [01:44<00:19,  8.96it/s] 84%|████████▎ | 896/1070 [01:45<00:19,  8.97it/s] 84%|████████▍ | 897/1070 [01:45<00:19,  8.93it/s] 84%|████████▍ | 898/1070 [01:45<00:19,  8.88it/s] 84%|████████▍ | 899/1070 [01:45<00:19,  8.88it/s] 84%|████████▍ | 900/1070 [01:45<00:19,  8.85it/s] 84%|████████▍ | 901/1070 [01:45<00:18,  8.95it/s] 84%|████████▍ | 902/1070 [01:45<00:18,  8.99it/s] 84%|████████▍ | 903/1070 [01:45<00:18,  9.08it/s] 84%|████████▍ | 904/1070 [01:45<00:18,  8.93it/s] 85%|████████▍ | 905/1070 [01:46<00:18,  8.92it/s] 85%|████████▍ | 906/1070 [01:46<00:18,  8.90it/s] 85%|████████▍ | 907/1070 [01:46<00:18,  8.97it/s] 85%|████████▍ | 908/1070 [01:46<00:17,  9.03it/s] 85%|████████▍ | 909/1070 [01:46<00:17,  8.97it/s] 85%|████████▌ | 910/1070 [01:46<00:17,  9.07it/s] 85%|████████▌ | 911/1070 [01:46<00:17,  8.94it/s] 85%|████████▌ | 912/1070 [01:46<00:17,  8.93it/s] 85%|████████▌ | 913/1070 [01:46<00:17,  8.97it/s] 85%|████████▌ | 914/1070 [01:47<00:17,  8.91it/s] 86%|████████▌ | 915/1070 [01:47<00:17,  8.94it/s] 86%|████████▌ | 916/1070 [01:47<00:17,  8.93it/s] 86%|████████▌ | 917/1070 [01:47<00:16,  9.01it/s] 86%|████████▌ | 918/1070 [01:47<00:16,  8.97it/s] 86%|████████▌ | 919/1070 [01:47<00:16,  8.96it/s] 86%|████████▌ | 920/1070 [01:47<00:16,  8.93it/s] 86%|████████▌ | 921/1070 [01:47<00:16,  8.93it/s] 86%|████████▌ | 922/1070 [01:47<00:16,  8.92it/s] 86%|████████▋ | 923/1070 [01:48<00:16,  8.95it/s] 86%|████████▋ | 924/1070 [01:48<00:16,  8.91it/s] 86%|████████▋ | 925/1070 [01:48<00:16,  9.03it/s] 87%|████████▋ | 926/1070 [01:48<00:15,  9.03it/s] 87%|████████▋ | 927/1070 [01:48<00:15,  9.09it/s] 87%|████████▋ | 928/1070 [01:48<00:15,  9.00it/s] 87%|████████▋ | 929/1070 [01:48<00:15,  9.03it/s] 87%|████████▋ | 930/1070 [01:48<00:15,  8.99it/s] 87%|████████▋ | 931/1070 [01:48<00:15,  8.92it/s] 87%|████████▋ | 932/1070 [01:49<00:15,  8.95it/s] 87%|████████▋ | 933/1070 [01:49<00:15,  8.90it/s] 87%|████████▋ | 934/1070 [01:49<00:15,  8.97it/s] 87%|████████▋ | 935/1070 [01:49<00:15,  8.94it/s] 87%|████████▋ | 936/1070 [01:49<00:14,  8.94it/s] 88%|████████▊ | 937/1070 [01:49<00:14,  8.88it/s] 88%|████████▊ | 938/1070 [01:49<00:14,  8.90it/s] 88%|████████▊ | 939/1070 [01:49<00:14,  8.90it/s] 88%|████████▊ | 940/1070 [01:49<00:14,  8.89it/s] 88%|████████▊ | 941/1070 [01:50<00:14,  8.93it/s] 88%|████████▊ | 942/1070 [01:50<00:14,  9.01it/s] 88%|████████▊ | 943/1070 [01:50<00:14,  8.99it/s] 88%|████████▊ | 944/1070 [01:50<00:13,  9.07it/s] 88%|████████▊ | 945/1070 [01:50<00:13,  9.00it/s] 88%|████████▊ | 946/1070 [01:50<00:13,  9.00it/s] 89%|████████▊ | 947/1070 [01:50<00:13,  8.99it/s] 89%|████████▊ | 948/1070 [01:50<00:13,  8.91it/s] 89%|████████▊ | 949/1070 [01:50<00:13,  8.99it/s] 89%|████████▉ | 950/1070 [01:51<00:13,  8.91it/s] 89%|████████▉ | 951/1070 [01:51<00:13,  9.04it/s] 89%|████████▉ | 952/1070 [01:51<00:13,  8.96it/s] 89%|████████▉ | 953/1070 [01:51<00:13,  8.90it/s] 89%|████████▉ | 954/1070 [01:51<00:13,  8.92it/s] 89%|████████▉ | 955/1070 [01:51<00:12,  8.90it/s] 89%|████████▉ | 956/1070 [01:51<00:12,  8.95it/s] 89%|████████▉ | 957/1070 [01:51<00:12,  8.96it/s] 90%|████████▉ | 958/1070 [01:51<00:12,  9.10it/s] 90%|████████▉ | 959/1070 [01:52<00:12,  9.00it/s] 90%|████████▉ | 960/1070 [01:52<00:12,  8.98it/s] 90%|████████▉ | 961/1070 [01:52<00:12,  8.98it/s] 90%|████████▉ | 962/1070 [01:52<00:12,  8.86it/s] 90%|█████████ | 963/1070 [01:52<00:12,  8.84it/s] 90%|█████████ | 964/1070 [01:52<00:11,  8.90it/s] 90%|█████████ | 965/1070 [01:52<00:11,  9.05it/s] 90%|█████████ | 966/1070 [01:52<00:11,  8.96it/s] 90%|█████████ | 967/1070 [01:52<00:11,  8.96it/s] 90%|█████████ | 968/1070 [01:53<00:11,  8.94it/s] 91%|█████████ | 969/1070 [01:53<00:11,  8.95it/s] 91%|█████████ | 970/1070 [01:53<00:11,  8.94it/s] 91%|█████████ | 971/1070 [01:53<00:11,  8.93it/s] 91%|█████████ | 972/1070 [01:53<00:10,  9.00it/s] 91%|█████████ | 973/1070 [01:53<00:10,  8.89it/s] 91%|█████████ | 974/1070 [01:53<00:10,  8.93it/s] 91%|█████████ | 975/1070 [01:53<00:10,  8.93it/s] 91%|█████████ | 976/1070 [01:53<00:10,  8.93it/s] 91%|█████████▏| 977/1070 [01:54<00:10,  8.91it/s] 91%|█████████▏| 978/1070 [01:54<00:10,  8.89it/s] 91%|█████████▏| 979/1070 [01:54<00:10,  8.96it/s] 92%|█████████▏| 980/1070 [01:54<00:10,  8.98it/s] 92%|█████████▏| 981/1070 [01:54<00:09,  8.96it/s] 92%|█████████▏| 982/1070 [01:54<00:09,  8.99it/s] 92%|█████████▏| 983/1070 [01:54<00:09,  8.95it/s] 92%|█████████▏| 984/1070 [01:54<00:09,  8.90it/s] 92%|█████████▏| 985/1070 [01:54<00:09,  8.88it/s] 92%|█████████▏| 986/1070 [01:55<00:09,  8.97it/s] 92%|█████████▏| 987/1070 [01:55<00:09,  9.01it/s] 92%|█████████▏| 988/1070 [01:55<00:09,  8.99it/s] 92%|█████████▏| 989/1070 [01:55<00:09,  8.96it/s] 93%|█████████▎| 990/1070 [01:55<00:09,  8.88it/s] 93%|█████████▎| 991/1070 [01:55<00:08,  8.89it/s] 93%|█████████▎| 992/1070 [01:55<00:08,  8.84it/s] 93%|█████████▎| 993/1070 [01:55<00:08,  8.86it/s] 93%|█████████▎| 994/1070 [01:55<00:08,  8.89it/s] 93%|█████████▎| 995/1070 [01:56<00:08,  8.89it/s] 93%|█████████▎| 996/1070 [01:56<00:08,  8.99it/s] 93%|█████████▎| 997/1070 [01:56<00:08,  8.85it/s] 93%|█████████▎| 998/1070 [01:56<00:08,  8.87it/s] 93%|█████████▎| 999/1070 [01:56<00:08,  8.84it/s] 93%|█████████▎| 1000/1070 [01:56<00:07,  8.82it/s] 94%|█████████▎| 1001/1070 [01:56<00:07,  8.88it/s] 94%|█████████▎| 1002/1070 [01:56<00:07,  8.92it/s] 94%|█████████▎| 1003/1070 [01:56<00:07,  9.09it/s] 94%|█████████▍| 1004/1070 [01:57<00:07,  8.86it/s] 94%|█████████▍| 1005/1070 [01:57<00:07,  8.86it/s] 94%|█████████▍| 1006/1070 [01:57<00:07,  8.92it/s] 94%|█████████▍| 1007/1070 [01:57<00:07,  8.90it/s] 94%|█████████▍| 1008/1070 [01:57<00:06,  8.92it/s] 94%|█████████▍| 1009/1070 [01:57<00:06,  8.84it/s] 94%|█████████▍| 1010/1070 [01:57<00:06,  9.04it/s] 94%|█████████▍| 1011/1070 [01:57<00:06,  8.91it/s] 95%|█████████▍| 1012/1070 [01:58<00:06,  8.98it/s] 95%|█████████▍| 1013/1070 [01:58<00:06,  8.95it/s] 95%|█████████▍| 1014/1070 [01:58<00:06,  8.90it/s] 95%|█████████▍| 1015/1070 [01:58<00:06,  8.85it/s] 95%|█████████▍| 1016/1070 [01:58<00:06,  8.82it/s] 95%|█████████▌| 1017/1070 [01:58<00:05,  8.95it/s] 95%|█████████▌| 1018/1070 [01:58<00:05,  8.95it/s] 95%|█████████▌| 1019/1070 [01:58<00:05,  8.93it/s] 95%|█████████▌| 1020/1070 [01:58<00:05,  8.93it/s] 95%|█████████▌| 1021/1070 [01:59<00:05,  8.94it/s] 96%|█████████▌| 1022/1070 [01:59<00:05,  8.92it/s] 96%|█████████▌| 1023/1070 [01:59<00:05,  8.86it/s] 96%|█████████▌| 1024/1070 [01:59<00:05,  8.95it/s] 96%|█████████▌| 1025/1070 [01:59<00:05,  8.93it/s] 96%|█████████▌| 1026/1070 [01:59<00:04,  8.82it/s] 96%|█████████▌| 1027/1070 [01:59<00:04,  8.83it/s] 96%|█████████▌| 1028/1070 [01:59<00:04,  8.87it/s] 96%|█████████▌| 1029/1070 [01:59<00:04,  8.81it/s] 96%|█████████▋| 1030/1070 [02:00<00:04,  8.83it/s] 96%|█████████▋| 1031/1070 [02:00<00:04,  8.91it/s] 96%|█████████▋| 1032/1070 [02:00<00:04,  8.93it/s] 97%|█████████▋| 1033/1070 [02:00<00:04,  8.87it/s] 97%|█████████▋| 1034/1070 [02:00<00:04,  8.91it/s] 97%|█████████▋| 1035/1070 [02:00<00:03,  8.92it/s] 97%|█████████▋| 1036/1070 [02:00<00:03,  8.86it/s] 97%|█████████▋| 1037/1070 [02:00<00:03,  8.85it/s] 97%|█████████▋| 1038/1070 [02:00<00:03,  8.90it/s] 97%|█████████▋| 1039/1070 [02:01<00:03,  8.95it/s] 97%|█████████▋| 1040/1070 [02:01<00:03,  8.95it/s] 97%|█████████▋| 1041/1070 [02:01<00:03,  9.00it/s] 97%|█████████▋| 1042/1070 [02:01<00:03,  8.98it/s] 97%|█████████▋| 1043/1070 [02:01<00:03,  8.85it/s] 98%|█████████▊| 1044/1070 [02:01<00:02,  8.90it/s] 98%|█████████▊| 1045/1070 [02:01<00:02,  8.90it/s] 98%|█████████▊| 1046/1070 [02:01<00:02,  8.98it/s] 98%|█████████▊| 1047/1070 [02:01<00:02,  8.97it/s] 98%|█████████▊| 1048/1070 [02:02<00:02,  9.04it/s] 98%|█████████▊| 1049/1070 [02:02<00:02,  8.95it/s] 98%|█████████▊| 1050/1070 [02:02<00:02,  8.86it/s] 98%|█████████▊| 1051/1070 [02:02<00:02,  8.84it/s] 98%|█████████▊| 1052/1070 [02:02<00:02,  8.88it/s] 98%|█████████▊| 1053/1070 [02:02<00:01,  8.99it/s] 99%|█████████▊| 1054/1070 [02:02<00:01,  8.96it/s] 99%|█████████▊| 1055/1070 [02:02<00:01,  9.02it/s] 99%|█████████▊| 1056/1070 [02:02<00:01,  8.95it/s] 99%|█████████▉| 1057/1070 [02:03<00:01,  8.87it/s] 99%|█████████▉| 1058/1070 [02:03<00:01,  8.82it/s] 99%|█████████▉| 1059/1070 [02:03<00:01,  8.83it/s] 99%|█████████▉| 1060/1070 [02:03<00:01,  8.91it/s] 99%|█████████▉| 1061/1070 [02:03<00:01,  8.86it/s] 99%|█████████▉| 1062/1070 [02:03<00:00,  8.93it/s] 99%|█████████▉| 1063/1070 [02:03<00:00,  8.81it/s] 99%|█████████▉| 1064/1070 [02:03<00:00,  8.80it/s]100%|█████████▉| 1065/1070 [02:03<00:00,  8.83it/s]100%|█████████▉| 1066/1070 [02:04<00:00,  8.82it/s]100%|█████████▉| 1067/1070 [02:04<00:00,  8.87it/s]100%|█████████▉| 1068/1070 [02:04<00:00,  8.85it/s]100%|█████████▉| 1069/1070 [02:04<00:00,  9.04it/s]                                                   100%|██████████| 1070/1070 [02:04<00:00,  9.04it/s][INFO|trainer.py:755] 2023-11-15 20:20:40,037 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:20:40,039 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:20:40,039 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:20:40,039 >>   Batch size = 8
{'eval_loss': 0.3818921446800232, 'eval_accuracy': 0.9118421052631579, 'eval_micro_f1': 0.9118421052631579, 'eval_macro_f1': 0.909480458478118, 'eval_runtime': 1.4034, 'eval_samples_per_second': 541.555, 'eval_steps_per_second': 67.694, 'epoch': 4.0}
{'loss': 0.0521, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 78.23it/s][A
 18%|█▊        | 17/95 [00:00<00:01, 72.58it/s][A
 26%|██▋       | 25/95 [00:00<00:00, 73.24it/s][A
 35%|███▍      | 33/95 [00:00<00:00, 71.67it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 70.31it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 71.36it/s][A
 60%|██████    | 57/95 [00:00<00:00, 70.26it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 69.83it/s][A
 76%|███████▌  | 72/95 [00:01<00:00, 69.02it/s][A
 83%|████████▎ | 79/95 [00:01<00:00, 69.17it/s][A
 92%|█████████▏| 87/95 [00:01<00:00, 69.49it/s][A
 99%|█████████▉| 94/95 [00:01<00:00, 69.49it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:05<00:00,  9.04it/s]
100%|██████████| 95/95 [00:01<00:00, 69.49it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 20:20:41,447 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:05<00:00,  9.04it/s]100%|██████████| 1070/1070 [02:05<00:00,  8.50it/s]
[INFO|trainer.py:2855] 2023-11-15 20:20:41,451 >> Saving model checkpoint to ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1
[INFO|configuration_utils.py:460] 2023-11-15 20:20:41,453 >> Configuration saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:20:42,695 >> Model weights saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:20:42,698 >> tokenizer config file saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:20:42,701 >> Special tokens file saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed1/special_tokens_map.json
{'eval_loss': 0.4020337462425232, 'eval_accuracy': 0.9078947368421053, 'eval_micro_f1': 0.9078947368421053, 'eval_macro_f1': 0.9057067916263675, 'eval_runtime': 1.4035, 'eval_samples_per_second': 541.491, 'eval_steps_per_second': 67.686, 'epoch': 5.0}
{'train_runtime': 125.9231, 'train_samples_per_second': 271.594, 'train_steps_per_second': 8.497, 'train_loss': 0.2016981374437564, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2017
  train_runtime            = 0:02:05.92
  train_samples            =       6840
  train_samples_per_second =    271.594
  train_steps_per_second   =      8.497
11/15/2023 20:20:42 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:20:42,747 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:20:42,749 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:20:42,749 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:20:42,749 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  9%|▉         | 9/95 [00:00<00:01, 78.28it/s] 18%|█▊        | 17/95 [00:00<00:01, 73.17it/s] 26%|██▋       | 25/95 [00:00<00:00, 72.88it/s] 35%|███▍      | 33/95 [00:00<00:00, 72.79it/s] 43%|████▎     | 41/95 [00:00<00:00, 71.25it/s] 52%|█████▏    | 49/95 [00:00<00:00, 72.13it/s] 60%|██████    | 57/95 [00:00<00:00, 69.47it/s] 67%|██████▋   | 64/95 [00:00<00:00, 68.96it/s] 75%|███████▍  | 71/95 [00:01<00:00, 68.65it/s] 83%|████████▎ | 79/95 [00:01<00:00, 69.43it/s] 92%|█████████▏| 87/95 [00:01<00:00, 69.99it/s] 99%|█████████▉| 94/95 [00:01<00:00, 69.27it/s]100%|██████████| 95/95 [00:01<00:00, 69.09it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9079
  eval_loss               =      0.402
  eval_macro_f1           =     0.9057
  eval_micro_f1           =     0.9079
  eval_runtime            = 0:00:01.39
  eval_samples            =        760
  eval_samples_per_second =    546.514
  eval_steps_per_second   =     68.314
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁█▃█▆▆
wandb:                      eval/loss ▃▁▆▇██
wandb:                  eval/macro_f1 ▁█▃█▆▆
wandb:                  eval/micro_f1 ▁█▃█▆▆
wandb:                   eval/runtime ▁▄█▇▇▆
wandb:        eval/samples_per_second █▅▁▂▂▃
wandb:          eval/steps_per_second █▅▁▂▂▃
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▁▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.90789
wandb:                      eval/loss 0.40203
wandb:                  eval/macro_f1 0.90571
wandb:                  eval/micro_f1 0.90789
wandb:                   eval/runtime 1.3906
wandb:        eval/samples_per_second 546.514
wandb:          eval/steps_per_second 68.314
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0521
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.2017
wandb:            train/train_runtime 125.9231
wandb: train/train_samples_per_second 271.594
wandb:   train/train_steps_per_second 8.497
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_201716-sis5v0uj
wandb: Find logs at: ./wandb/offline-run-20231115_201716-sis5v0uj/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_roberta-base_adapter__seed2/runs/Nov15_20-20-56_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_roberta-base_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_roberta-base_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:20:56 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:20:56 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_roberta-base_adapter__seed2/runs/Nov15_20-20-55_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_roberta-base_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_roberta-base_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  88%|████████▊ | 4172/4722 [00:00<00:00, 41485.53 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 40594.78 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:21:12,536 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:21:12,548 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:21:22,567 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:21:32,586 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:21:32,587 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:21:52,643 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:21:52,644 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:21:52,644 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:21:52,644 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:21:52,645 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:21:52,645 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:21:52,646 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:21:52,647 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:22:12,841 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:22:13,594 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:22:13,595 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 24751.48 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 24426.51 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 27183.44 examples/s]
11/15/2023 20:22:13 - INFO - __main__ - Sample 2272 of the training set: {'text': 'Carinthia cheese ravioli with wild mushrooms <SEP> Innovations are just as assured, from the simple Carinthia cheese ravioli with wild mushrooms to the caviar-topped sturgeon, beautifully matched with a bright green spinach-vodka sauce.', 'label': 0, 'input_ids': [0, 9518, 35744, 493, 7134, 25283, 14215, 118, 19, 3418, 25038, 28696, 3388, 510, 15698, 20067, 1635, 32, 95, 25, 7189, 6, 31, 5, 2007, 1653, 35744, 493, 7134, 25283, 14215, 118, 19, 3418, 25038, 7, 5, 32426, 12202, 12, 560, 5686, 1690, 710, 20989, 6, 16467, 9184, 19, 10, 4520, 2272, 31225, 12, 705, 40677, 8929, 4, 2, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]}.
11/15/2023 20:22:13 - INFO - __main__ - Sample 1436 of the training set: {'text': 'jazz singer <SEP> jazz singer had a nice voice + she made us all get up to dance to shake some cals to eat some more.', 'label': 0, 'input_ids': [0, 267, 7706, 3250, 28696, 3388, 510, 15698, 11057, 3250, 56, 10, 2579, 2236, 2055, 79, 156, 201, 70, 120, 62, 7, 3836, 7, 8559, 103, 740, 1536, 7, 3529, 103, 55, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:22:13 - INFO - __main__ - Sample 1446 of the training set: {'text': 'iceberg <SEP> The bruscetta is a bit soggy, but the salads were fresh, included a nice mix of greens (not iceberg) all dishes are served piping hot from the kitchen.', 'label': 1, 'input_ids': [0, 2463, 2865, 28696, 3388, 510, 15698, 20, 5378, 20214, 10464, 16, 10, 828, 579, 2154, 4740, 6, 53, 5, 26924, 58, 2310, 6, 1165, 10, 2579, 3344, 9, 16543, 36, 3654, 26937, 43, 70, 10230, 32, 1665, 37273, 2131, 31, 5, 4647, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:22:13 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:22:15,258 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:22:15,266 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:22:15,266 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 20:22:15,266 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:22:15,267 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:22:15,267 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:22:15,267 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:22:15,267 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 20:22:15,268 >>   Number of trainable parameters = 124,647,939
[INFO|integration_utils.py:716] 2023-11-15 20:22:15,269 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<13:19,  1.35s/it]  0%|          | 2/595 [00:01<06:06,  1.62it/s]  1%|          | 3/595 [00:01<03:47,  2.60it/s]  1%|          | 4/595 [00:01<02:42,  3.63it/s]  1%|          | 5/595 [00:01<02:07,  4.61it/s]  1%|          | 6/595 [00:01<01:46,  5.54it/s]  1%|          | 7/595 [00:02<01:32,  6.34it/s]  1%|▏         | 8/595 [00:02<01:23,  7.00it/s]  2%|▏         | 9/595 [00:02<01:17,  7.56it/s]  2%|▏         | 10/595 [00:02<01:13,  7.98it/s]  2%|▏         | 11/595 [00:02<01:09,  8.39it/s]  2%|▏         | 12/595 [00:02<01:08,  8.55it/s]  2%|▏         | 13/595 [00:02<01:06,  8.69it/s]  2%|▏         | 14/595 [00:02<01:06,  8.78it/s]  3%|▎         | 15/595 [00:02<01:05,  8.92it/s]  3%|▎         | 16/595 [00:02<01:04,  9.03it/s]  3%|▎         | 17/595 [00:03<01:03,  9.03it/s]  3%|▎         | 18/595 [00:03<01:03,  9.13it/s]  3%|▎         | 19/595 [00:03<01:03,  9.04it/s]  3%|▎         | 20/595 [00:03<01:03,  9.01it/s]  4%|▎         | 21/595 [00:03<01:03,  9.06it/s]  4%|▎         | 22/595 [00:03<01:03,  9.02it/s]  4%|▍         | 23/595 [00:03<01:02,  9.13it/s]  4%|▍         | 24/595 [00:03<01:02,  9.17it/s]  4%|▍         | 25/595 [00:03<01:02,  9.17it/s]  4%|▍         | 26/595 [00:04<01:02,  9.11it/s]  5%|▍         | 27/595 [00:04<01:02,  9.07it/s]  5%|▍         | 28/595 [00:04<01:02,  9.02it/s]  5%|▍         | 29/595 [00:04<01:02,  9.06it/s]  5%|▌         | 30/595 [00:04<01:01,  9.12it/s]  5%|▌         | 31/595 [00:04<01:01,  9.18it/s]  5%|▌         | 32/595 [00:04<01:01,  9.18it/s]  6%|▌         | 33/595 [00:04<01:01,  9.13it/s]  6%|▌         | 34/595 [00:04<01:01,  9.11it/s]  6%|▌         | 35/595 [00:05<01:01,  9.12it/s]  6%|▌         | 36/595 [00:05<01:01,  9.11it/s]  6%|▌         | 37/595 [00:05<01:01,  9.13it/s]  6%|▋         | 38/595 [00:05<01:00,  9.18it/s]  7%|▋         | 39/595 [00:05<01:00,  9.14it/s]  7%|▋         | 40/595 [00:05<01:00,  9.13it/s]  7%|▋         | 41/595 [00:05<01:00,  9.08it/s]  7%|▋         | 42/595 [00:05<01:01,  9.05it/s]  7%|▋         | 43/595 [00:05<01:00,  9.10it/s]  7%|▋         | 44/595 [00:06<01:00,  9.12it/s]  8%|▊         | 45/595 [00:06<01:00,  9.14it/s]  8%|▊         | 46/595 [00:06<01:00,  9.08it/s]  8%|▊         | 47/595 [00:06<01:00,  9.07it/s]  8%|▊         | 48/595 [00:06<01:00,  9.04it/s]  8%|▊         | 49/595 [00:06<01:00,  8.99it/s]  8%|▊         | 50/595 [00:06<00:59,  9.09it/s]  9%|▊         | 51/595 [00:06<00:59,  9.08it/s]  9%|▊         | 52/595 [00:06<00:59,  9.14it/s]  9%|▉         | 53/595 [00:07<00:59,  9.12it/s]  9%|▉         | 54/595 [00:07<00:59,  9.15it/s]  9%|▉         | 55/595 [00:07<00:59,  9.07it/s]  9%|▉         | 56/595 [00:07<00:59,  9.10it/s] 10%|▉         | 57/595 [00:07<00:58,  9.13it/s] 10%|▉         | 58/595 [00:07<00:58,  9.18it/s] 10%|▉         | 59/595 [00:07<00:58,  9.16it/s] 10%|█         | 60/595 [00:07<00:58,  9.12it/s] 10%|█         | 61/595 [00:07<00:58,  9.09it/s] 10%|█         | 62/595 [00:08<00:58,  9.12it/s] 11%|█         | 63/595 [00:08<00:57,  9.19it/s] 11%|█         | 64/595 [00:08<00:57,  9.16it/s] 11%|█         | 65/595 [00:08<00:57,  9.18it/s] 11%|█         | 66/595 [00:08<00:57,  9.19it/s] 11%|█▏        | 67/595 [00:08<00:57,  9.16it/s] 11%|█▏        | 68/595 [00:08<00:57,  9.16it/s] 12%|█▏        | 69/595 [00:08<00:58,  9.04it/s] 12%|█▏        | 70/595 [00:08<00:57,  9.08it/s] 12%|█▏        | 71/595 [00:09<00:57,  9.13it/s] 12%|█▏        | 72/595 [00:09<00:56,  9.19it/s] 12%|█▏        | 73/595 [00:09<00:56,  9.19it/s] 12%|█▏        | 74/595 [00:09<00:56,  9.14it/s] 13%|█▎        | 75/595 [00:09<00:57,  9.11it/s] 13%|█▎        | 76/595 [00:09<00:56,  9.12it/s] 13%|█▎        | 77/595 [00:09<00:56,  9.13it/s] 13%|█▎        | 78/595 [00:09<00:55,  9.25it/s] 13%|█▎        | 79/595 [00:09<00:56,  9.21it/s] 13%|█▎        | 80/595 [00:09<00:55,  9.23it/s] 14%|█▎        | 81/595 [00:10<00:56,  9.14it/s] 14%|█▍        | 82/595 [00:10<00:56,  9.08it/s] 14%|█▍        | 83/595 [00:10<00:55,  9.15it/s] 14%|█▍        | 84/595 [00:10<00:55,  9.14it/s] 14%|█▍        | 85/595 [00:10<00:55,  9.21it/s] 14%|█▍        | 86/595 [00:10<00:55,  9.20it/s] 15%|█▍        | 87/595 [00:10<00:55,  9.24it/s] 15%|█▍        | 88/595 [00:10<00:55,  9.18it/s] 15%|█▍        | 89/595 [00:10<00:55,  9.19it/s] 15%|█▌        | 90/595 [00:11<00:55,  9.10it/s] 15%|█▌        | 91/595 [00:11<00:55,  9.09it/s] 15%|█▌        | 92/595 [00:11<00:54,  9.17it/s] 16%|█▌        | 93/595 [00:11<00:54,  9.17it/s] 16%|█▌        | 94/595 [00:11<00:54,  9.16it/s] 16%|█▌        | 95/595 [00:11<00:54,  9.17it/s] 16%|█▌        | 96/595 [00:11<00:54,  9.11it/s] 16%|█▋        | 97/595 [00:11<00:54,  9.15it/s] 16%|█▋        | 98/595 [00:11<00:54,  9.16it/s] 17%|█▋        | 99/595 [00:12<00:54,  9.16it/s] 17%|█▋        | 100/595 [00:12<00:54,  9.16it/s] 17%|█▋        | 101/595 [00:12<00:53,  9.20it/s] 17%|█▋        | 102/595 [00:12<00:53,  9.21it/s] 17%|█▋        | 103/595 [00:12<00:53,  9.13it/s] 17%|█▋        | 104/595 [00:12<00:53,  9.16it/s] 18%|█▊        | 105/595 [00:12<00:53,  9.14it/s] 18%|█▊        | 106/595 [00:12<00:53,  9.19it/s] 18%|█▊        | 107/595 [00:12<00:52,  9.22it/s] 18%|█▊        | 108/595 [00:13<00:52,  9.28it/s] 18%|█▊        | 109/595 [00:13<00:52,  9.27it/s] 18%|█▊        | 110/595 [00:13<00:52,  9.21it/s] 19%|█▊        | 111/595 [00:13<00:52,  9.21it/s] 19%|█▉        | 112/595 [00:13<00:52,  9.18it/s] 19%|█▉        | 113/595 [00:13<00:52,  9.25it/s] 19%|█▉        | 114/595 [00:13<00:52,  9.25it/s] 19%|█▉        | 115/595 [00:13<00:51,  9.31it/s] 19%|█▉        | 116/595 [00:13<00:51,  9.28it/s] 20%|█▉        | 117/595 [00:14<00:51,  9.22it/s] 20%|█▉        | 118/595 [00:14<00:51,  9.26it/s]                                                  20%|██        | 119/595 [00:14<00:51,  9.26it/s][INFO|trainer.py:755] 2023-11-15 20:22:29,465 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:22:29,467 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:22:29,467 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:22:29,467 >>   Batch size = 8
{'loss': 0.7114, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 10/119 [00:00<00:01, 87.60it/s][A
 16%|█▌        | 19/119 [00:00<00:01, 79.39it/s][A
 23%|██▎       | 27/119 [00:00<00:01, 77.70it/s][A
 29%|██▉       | 35/119 [00:00<00:01, 75.97it/s][A
 36%|███▌      | 43/119 [00:00<00:01, 74.60it/s][A
 43%|████▎     | 51/119 [00:00<00:00, 74.25it/s][A
 50%|████▉     | 59/119 [00:00<00:00, 73.97it/s][A
 56%|█████▋    | 67/119 [00:00<00:00, 75.20it/s][A
 63%|██████▎   | 75/119 [00:00<00:00, 75.67it/s][A
 70%|██████▉   | 83/119 [00:01<00:00, 74.93it/s][A
 76%|███████▋  | 91/119 [00:01<00:00, 74.91it/s][A
 83%|████████▎ | 99/119 [00:01<00:00, 74.76it/s][A
 90%|████████▉ | 107/119 [00:01<00:00, 73.35it/s][A
 97%|█████████▋| 115/119 [00:01<00:00, 73.41it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:15<00:51,  9.26it/s]
100%|██████████| 119/119 [00:01<00:00, 73.41it/s][A
                                                 [A 20%|██        | 120/595 [00:15<03:44,  2.11it/s] 20%|██        | 121/595 [00:16<03:01,  2.61it/s] 21%|██        | 122/595 [00:16<02:27,  3.21it/s] 21%|██        | 123/595 [00:16<02:01,  3.89it/s] 21%|██        | 124/595 [00:16<01:41,  4.62it/s] 21%|██        | 125/595 [00:16<01:27,  5.38it/s] 21%|██        | 126/595 [00:16<01:16,  6.16it/s] 21%|██▏       | 127/595 [00:16<01:08,  6.82it/s] 22%|██▏       | 128/595 [00:16<01:02,  7.43it/s] 22%|██▏       | 129/595 [00:16<00:59,  7.85it/s] 22%|██▏       | 130/595 [00:17<00:56,  8.23it/s] 22%|██▏       | 131/595 [00:17<00:55,  8.43it/s] 22%|██▏       | 132/595 [00:17<00:53,  8.62it/s] 22%|██▏       | 133/595 [00:17<00:52,  8.76it/s] 23%|██▎       | 134/595 [00:17<00:51,  8.97it/s] 23%|██▎       | 135/595 [00:17<00:51,  9.02it/s] 23%|██▎       | 136/595 [00:17<00:50,  9.10it/s] 23%|██▎       | 137/595 [00:17<00:50,  9.08it/s] 23%|██▎       | 138/595 [00:17<00:50,  9.05it/s] 23%|██▎       | 139/595 [00:18<00:50,  9.07it/s] 24%|██▎       | 140/595 [00:18<00:50,  9.07it/s] 24%|██▎       | 141/595 [00:18<00:49,  9.10it/s] 24%|██▍       | 142/595 [00:18<00:49,  9.08it/s] 24%|██▍       | 143/595 [00:18<00:49,  9.21it/s] 24%|██▍       | 144/595 [00:18<00:49,  9.16it/s] 24%|██▍       | 145/595 [00:18<00:49,  9.14it/s] 25%|██▍       | 146/595 [00:18<00:49,  9.11it/s] 25%|██▍       | 147/595 [00:18<00:49,  9.09it/s] 25%|██▍       | 148/595 [00:18<00:49,  9.09it/s] 25%|██▌       | 149/595 [00:19<00:49,  9.08it/s] 25%|██▌       | 150/595 [00:19<00:48,  9.18it/s] 25%|██▌       | 151/595 [00:19<00:48,  9.17it/s] 26%|██▌       | 152/595 [00:19<00:48,  9.13it/s] 26%|██▌       | 153/595 [00:19<00:48,  9.12it/s] 26%|██▌       | 154/595 [00:19<00:48,  9.04it/s] 26%|██▌       | 155/595 [00:19<00:48,  9.03it/s] 26%|██▌       | 156/595 [00:19<00:48,  9.06it/s] 26%|██▋       | 157/595 [00:19<00:48,  9.08it/s] 27%|██▋       | 158/595 [00:20<00:47,  9.11it/s] 27%|██▋       | 159/595 [00:20<00:47,  9.16it/s] 27%|██▋       | 160/595 [00:20<00:47,  9.21it/s] 27%|██▋       | 161/595 [00:20<00:47,  9.15it/s] 27%|██▋       | 162/595 [00:20<00:47,  9.09it/s] 27%|██▋       | 163/595 [00:20<00:47,  9.08it/s] 28%|██▊       | 164/595 [00:20<00:47,  9.09it/s] 28%|██▊       | 165/595 [00:20<00:47,  9.14it/s] 28%|██▊       | 166/595 [00:20<00:46,  9.14it/s] 28%|██▊       | 167/595 [00:21<00:46,  9.21it/s] 28%|██▊       | 168/595 [00:21<00:47,  9.08it/s] 28%|██▊       | 169/595 [00:21<00:46,  9.11it/s] 29%|██▊       | 170/595 [00:21<00:46,  9.09it/s] 29%|██▊       | 171/595 [00:21<00:46,  9.11it/s] 29%|██▉       | 172/595 [00:21<00:46,  9.12it/s] 29%|██▉       | 173/595 [00:21<00:46,  9.11it/s] 29%|██▉       | 174/595 [00:21<00:45,  9.17it/s] 29%|██▉       | 175/595 [00:21<00:45,  9.17it/s] 30%|██▉       | 176/595 [00:22<00:45,  9.17it/s] 30%|██▉       | 177/595 [00:22<00:45,  9.13it/s] 30%|██▉       | 178/595 [00:22<00:45,  9.08it/s] 30%|███       | 179/595 [00:22<00:46,  9.03it/s] 30%|███       | 180/595 [00:22<00:45,  9.11it/s] 30%|███       | 181/595 [00:22<00:45,  9.18it/s] 31%|███       | 182/595 [00:22<00:45,  9.14it/s] 31%|███       | 183/595 [00:22<00:45,  9.11it/s] 31%|███       | 184/595 [00:22<00:45,  9.01it/s] 31%|███       | 185/595 [00:23<00:45,  9.03it/s] 31%|███▏      | 186/595 [00:23<00:45,  9.02it/s] 31%|███▏      | 187/595 [00:23<00:45,  9.05it/s] 32%|███▏      | 188/595 [00:23<00:44,  9.12it/s] 32%|███▏      | 189/595 [00:23<00:44,  9.08it/s] 32%|███▏      | 190/595 [00:23<00:44,  9.14it/s] 32%|███▏      | 191/595 [00:23<00:44,  9.03it/s] 32%|███▏      | 192/595 [00:23<00:44,  8.98it/s] 32%|███▏      | 193/595 [00:23<00:44,  9.03it/s] 33%|███▎      | 194/595 [00:24<00:44,  9.04it/s] 33%|███▎      | 195/595 [00:24<00:44,  9.08it/s] 33%|███▎      | 196/595 [00:24<00:43,  9.09it/s] 33%|███▎      | 197/595 [00:24<00:43,  9.05it/s] 33%|███▎      | 198/595 [00:24<00:43,  9.03it/s] 33%|███▎      | 199/595 [00:24<00:43,  9.05it/s] 34%|███▎      | 200/595 [00:24<00:43,  9.03it/s] 34%|███▍      | 201/595 [00:24<00:43,  9.05it/s] 34%|███▍      | 202/595 [00:24<00:43,  9.08it/s] 34%|███▍      | 203/595 [00:25<00:43,  9.10it/s] 34%|███▍      | 204/595 [00:25<00:43,  9.05it/s] 34%|███▍      | 205/595 [00:25<00:43,  9.02it/s] 35%|███▍      | 206/595 [00:25<00:43,  8.97it/s] 35%|███▍      | 207/595 [00:25<00:43,  8.93it/s] 35%|███▍      | 208/595 [00:25<00:43,  8.98it/s] 35%|███▌      | 209/595 [00:25<00:42,  9.00it/s] 35%|███▌      | 210/595 [00:25<00:42,  9.00it/s] 35%|███▌      | 211/595 [00:25<00:42,  9.08it/s] 36%|███▌      | 212/595 [00:26<00:42,  9.10it/s] 36%|███▌      | 213/595 [00:26<00:42,  9.06it/s] 36%|███▌      | 214/595 [00:26<00:42,  9.00it/s] 36%|███▌      | 215/595 [00:26<00:42,  9.05it/s] 36%|███▋      | 216/595 [00:26<00:41,  9.07it/s] 36%|███▋      | 217/595 [00:26<00:41,  9.09it/s] 37%|███▋      | 218/595 [00:26<00:41,  9.11it/s] 37%|███▋      | 219/595 [00:26<00:41,  9.12it/s] 37%|███▋      | 220/595 [00:26<00:41,  9.11it/s] 37%|███▋      | 221/595 [00:27<00:41,  9.07it/s] 37%|███▋      | 222/595 [00:27<00:41,  8.98it/s] 37%|███▋      | 223/595 [00:27<00:41,  9.02it/s] 38%|███▊      | 224/595 [00:27<00:41,  9.01it/s] 38%|███▊      | 225/595 [00:27<00:40,  9.07it/s] 38%|███▊      | 226/595 [00:27<00:40,  9.13it/s] 38%|███▊      | 227/595 [00:27<00:40,  9.06it/s] 38%|███▊      | 228/595 [00:27<00:40,  9.05it/s] 38%|███▊      | 229/595 [00:27<00:40,  9.01it/s] 39%|███▊      | 230/595 [00:28<00:40,  8.97it/s] 39%|███▉      | 231/595 [00:28<00:40,  9.05it/s] 39%|███▉      | 232/595 [00:28<00:39,  9.11it/s] 39%|███▉      | 233/595 [00:28<00:39,  9.15it/s] 39%|███▉      | 234/595 [00:28<00:39,  9.05it/s] 39%|███▉      | 235/595 [00:28<00:39,  9.05it/s] 40%|███▉      | 236/595 [00:28<00:39,  9.04it/s] 40%|███▉      | 237/595 [00:28<00:39,  9.06it/s]                                                  40%|████      | 238/595 [00:28<00:39,  9.06it/s][INFO|trainer.py:755] 2023-11-15 20:22:44,122 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:22:44,124 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:22:44,124 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:22:44,125 >>   Batch size = 8
{'eval_loss': 0.5866169333457947, 'eval_accuracy': 0.782010582010582, 'eval_micro_f1': 0.7820105820105819, 'eval_macro_f1': 0.6966864422214024, 'eval_runtime': 1.6332, 'eval_samples_per_second': 578.635, 'eval_steps_per_second': 72.865, 'epoch': 1.0}
{'loss': 0.4655, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 78.70it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 75.08it/s][A
 20%|██        | 24/119 [00:00<00:01, 74.78it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 74.93it/s][A
 34%|███▎      | 40/119 [00:00<00:01, 72.82it/s][A
 40%|████      | 48/119 [00:00<00:00, 74.47it/s][A
 47%|████▋     | 56/119 [00:00<00:00, 72.90it/s][A
 54%|█████▍    | 64/119 [00:00<00:00, 72.55it/s][A
 61%|██████    | 72/119 [00:00<00:00, 71.73it/s][A
 67%|██████▋   | 80/119 [00:01<00:00, 72.06it/s][A
 74%|███████▍  | 88/119 [00:01<00:00, 72.62it/s][A
 81%|████████  | 96/119 [00:01<00:00, 72.61it/s][A
 88%|████████▊ | 105/119 [00:01<00:00, 74.36it/s][A
 95%|█████████▍| 113/119 [00:01<00:00, 73.26it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:30<00:39,  9.06it/s]
100%|██████████| 119/119 [00:01<00:00, 73.26it/s][A
                                                 [A 40%|████      | 239/595 [00:30<02:51,  2.07it/s] 40%|████      | 240/595 [00:30<02:18,  2.56it/s] 41%|████      | 241/595 [00:30<01:52,  3.16it/s] 41%|████      | 242/595 [00:30<01:32,  3.83it/s] 41%|████      | 243/595 [00:31<01:16,  4.57it/s] 41%|████      | 244/595 [00:31<01:05,  5.33it/s] 41%|████      | 245/595 [00:31<00:58,  6.02it/s] 41%|████▏     | 246/595 [00:31<00:52,  6.68it/s] 42%|████▏     | 247/595 [00:31<00:48,  7.21it/s] 42%|████▏     | 248/595 [00:31<00:45,  7.65it/s] 42%|████▏     | 249/595 [00:31<00:43,  7.96it/s] 42%|████▏     | 250/595 [00:31<00:41,  8.34it/s] 42%|████▏     | 251/595 [00:31<00:40,  8.51it/s] 42%|████▏     | 252/595 [00:32<00:39,  8.66it/s] 43%|████▎     | 253/595 [00:32<00:39,  8.74it/s] 43%|████▎     | 254/595 [00:32<00:38,  8.85it/s] 43%|████▎     | 255/595 [00:32<00:38,  8.93it/s] 43%|████▎     | 256/595 [00:32<00:37,  8.93it/s] 43%|████▎     | 257/595 [00:32<00:37,  9.00it/s] 43%|████▎     | 258/595 [00:32<00:37,  9.04it/s] 44%|████▎     | 259/595 [00:32<00:37,  9.00it/s] 44%|████▎     | 260/595 [00:32<00:37,  8.97it/s] 44%|████▍     | 261/595 [00:33<00:37,  8.99it/s] 44%|████▍     | 262/595 [00:33<00:37,  8.96it/s] 44%|████▍     | 263/595 [00:33<00:37,  8.96it/s] 44%|████▍     | 264/595 [00:33<00:36,  9.03it/s] 45%|████▍     | 265/595 [00:33<00:36,  9.06it/s] 45%|████▍     | 266/595 [00:33<00:36,  9.10it/s] 45%|████▍     | 267/595 [00:33<00:36,  9.11it/s] 45%|████▌     | 268/595 [00:33<00:36,  9.07it/s] 45%|████▌     | 269/595 [00:33<00:36,  9.01it/s] 45%|████▌     | 270/595 [00:34<00:36,  9.00it/s] 46%|████▌     | 271/595 [00:34<00:35,  9.00it/s] 46%|████▌     | 272/595 [00:34<00:35,  9.03it/s] 46%|████▌     | 273/595 [00:34<00:35,  9.09it/s] 46%|████▌     | 274/595 [00:34<00:35,  9.11it/s] 46%|████▌     | 275/595 [00:34<00:35,  9.04it/s] 46%|████▋     | 276/595 [00:34<00:35,  9.05it/s] 47%|████▋     | 277/595 [00:34<00:35,  9.01it/s] 47%|████▋     | 278/595 [00:34<00:35,  9.02it/s] 47%|████▋     | 279/595 [00:35<00:35,  9.02it/s] 47%|████▋     | 280/595 [00:35<00:34,  9.07it/s] 47%|████▋     | 281/595 [00:35<00:34,  9.19it/s] 47%|████▋     | 282/595 [00:35<00:34,  9.12it/s] 48%|████▊     | 283/595 [00:35<00:34,  9.13it/s] 48%|████▊     | 284/595 [00:35<00:34,  9.05it/s] 48%|████▊     | 285/595 [00:35<00:34,  9.02it/s] 48%|████▊     | 286/595 [00:35<00:34,  9.06it/s] 48%|████▊     | 287/595 [00:35<00:33,  9.09it/s] 48%|████▊     | 288/595 [00:36<00:33,  9.15it/s] 49%|████▊     | 289/595 [00:36<00:33,  9.11it/s] 49%|████▊     | 290/595 [00:36<00:33,  9.09it/s] 49%|████▉     | 291/595 [00:36<00:33,  9.05it/s] 49%|████▉     | 292/595 [00:36<00:33,  9.11it/s] 49%|████▉     | 293/595 [00:36<00:33,  9.11it/s] 49%|████▉     | 294/595 [00:36<00:32,  9.16it/s] 50%|████▉     | 295/595 [00:36<00:32,  9.21it/s] 50%|████▉     | 296/595 [00:36<00:32,  9.20it/s] 50%|████▉     | 297/595 [00:37<00:32,  9.15it/s] 50%|█████     | 298/595 [00:37<00:32,  9.07it/s] 50%|█████     | 299/595 [00:37<00:32,  9.10it/s] 50%|█████     | 300/595 [00:37<00:32,  9.05it/s] 51%|█████     | 301/595 [00:37<00:32,  9.11it/s] 51%|█████     | 302/595 [00:37<00:32,  9.13it/s] 51%|█████     | 303/595 [00:37<00:31,  9.14it/s] 51%|█████     | 304/595 [00:37<00:32,  9.09it/s] 51%|█████▏    | 305/595 [00:37<00:31,  9.06it/s] 51%|█████▏    | 306/595 [00:38<00:32,  9.03it/s] 52%|█████▏    | 307/595 [00:38<00:31,  9.04it/s] 52%|█████▏    | 308/595 [00:38<00:31,  9.10it/s] 52%|█████▏    | 309/595 [00:38<00:31,  9.02it/s] 52%|█████▏    | 310/595 [00:38<00:31,  9.14it/s] 52%|█████▏    | 311/595 [00:38<00:30,  9.18it/s] 52%|█████▏    | 312/595 [00:38<00:30,  9.23it/s] 53%|█████▎    | 313/595 [00:38<00:30,  9.13it/s] 53%|█████▎    | 314/595 [00:38<00:30,  9.09it/s] 53%|█████▎    | 315/595 [00:39<00:30,  9.07it/s] 53%|█████▎    | 316/595 [00:39<00:30,  9.05it/s] 53%|█████▎    | 317/595 [00:39<00:30,  9.06it/s] 53%|█████▎    | 318/595 [00:39<00:30,  9.11it/s] 54%|█████▎    | 319/595 [00:39<00:30,  9.19it/s] 54%|█████▍    | 320/595 [00:39<00:30,  9.07it/s] 54%|█████▍    | 321/595 [00:39<00:30,  9.05it/s] 54%|█████▍    | 322/595 [00:39<00:30,  9.08it/s] 54%|█████▍    | 323/595 [00:39<00:29,  9.08it/s] 54%|█████▍    | 324/595 [00:40<00:29,  9.11it/s] 55%|█████▍    | 325/595 [00:40<00:29,  9.06it/s] 55%|█████▍    | 326/595 [00:40<00:29,  9.20it/s] 55%|█████▍    | 327/595 [00:40<00:29,  9.15it/s] 55%|█████▌    | 328/595 [00:40<00:29,  9.11it/s] 55%|█████▌    | 329/595 [00:40<00:29,  9.07it/s] 55%|█████▌    | 330/595 [00:40<00:29,  9.05it/s] 56%|█████▌    | 331/595 [00:40<00:29,  8.95it/s] 56%|█████▌    | 332/595 [00:40<00:29,  8.96it/s] 56%|█████▌    | 333/595 [00:40<00:28,  9.11it/s] 56%|█████▌    | 334/595 [00:41<00:28,  9.12it/s] 56%|█████▋    | 335/595 [00:41<00:28,  9.10it/s] 56%|█████▋    | 336/595 [00:41<00:28,  9.07it/s] 57%|█████▋    | 337/595 [00:41<00:28,  9.10it/s] 57%|█████▋    | 338/595 [00:41<00:28,  9.08it/s] 57%|█████▋    | 339/595 [00:41<00:28,  9.06it/s] 57%|█████▋    | 340/595 [00:41<00:27,  9.13it/s] 57%|█████▋    | 341/595 [00:41<00:27,  9.13it/s] 57%|█████▋    | 342/595 [00:41<00:27,  9.14it/s] 58%|█████▊    | 343/595 [00:42<00:27,  9.16it/s] 58%|█████▊    | 344/595 [00:42<00:27,  9.09it/s] 58%|█████▊    | 345/595 [00:42<00:27,  9.05it/s] 58%|█████▊    | 346/595 [00:42<00:27,  9.09it/s] 58%|█████▊    | 347/595 [00:42<00:27,  9.10it/s] 58%|█████▊    | 348/595 [00:42<00:27,  9.09it/s] 59%|█████▊    | 349/595 [00:42<00:26,  9.15it/s] 59%|█████▉    | 350/595 [00:42<00:26,  9.26it/s] 59%|█████▉    | 351/595 [00:42<00:26,  9.20it/s] 59%|█████▉    | 352/595 [00:43<00:26,  9.18it/s] 59%|█████▉    | 353/595 [00:43<00:26,  9.16it/s] 59%|█████▉    | 354/595 [00:43<00:26,  9.14it/s] 60%|█████▉    | 355/595 [00:43<00:26,  9.13it/s] 60%|█████▉    | 356/595 [00:43<00:26,  9.14it/s]                                                  60%|██████    | 357/595 [00:43<00:26,  9.14it/s][INFO|trainer.py:755] 2023-11-15 20:22:58,838 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:22:58,840 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:22:58,840 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:22:58,841 >>   Batch size = 8
{'eval_loss': 0.5178008079528809, 'eval_accuracy': 0.7925925925925926, 'eval_micro_f1': 0.7925925925925926, 'eval_macro_f1': 0.7057217664145655, 'eval_runtime': 1.6735, 'eval_samples_per_second': 564.7, 'eval_steps_per_second': 71.11, 'epoch': 2.0}
{'loss': 0.3233, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 84.10it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 76.13it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 76.19it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 76.27it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 76.57it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 74.53it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 75.53it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 73.46it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 73.56it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 73.09it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 73.14it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 73.73it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 73.58it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 75.07it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:45<00:26,  9.14it/s]
100%|██████████| 119/119 [00:01<00:00, 75.07it/s][A
                                                 [A 60%|██████    | 358/595 [00:45<01:52,  2.11it/s] 60%|██████    | 359/595 [00:45<01:30,  2.61it/s] 61%|██████    | 360/595 [00:45<01:13,  3.20it/s] 61%|██████    | 361/595 [00:45<01:00,  3.89it/s] 61%|██████    | 362/595 [00:45<00:50,  4.63it/s] 61%|██████    | 363/595 [00:45<00:42,  5.41it/s] 61%|██████    | 364/595 [00:45<00:37,  6.09it/s] 61%|██████▏   | 365/595 [00:46<00:33,  6.78it/s] 62%|██████▏   | 366/595 [00:46<00:31,  7.30it/s] 62%|██████▏   | 367/595 [00:46<00:29,  7.78it/s] 62%|██████▏   | 368/595 [00:46<00:28,  8.08it/s] 62%|██████▏   | 369/595 [00:46<00:26,  8.38it/s] 62%|██████▏   | 370/595 [00:46<00:26,  8.58it/s] 62%|██████▏   | 371/595 [00:46<00:25,  8.77it/s] 63%|██████▎   | 372/595 [00:46<00:24,  8.95it/s] 63%|██████▎   | 373/595 [00:46<00:24,  9.10it/s] 63%|██████▎   | 374/595 [00:47<00:24,  9.01it/s] 63%|██████▎   | 375/595 [00:47<00:24,  8.95it/s] 63%|██████▎   | 376/595 [00:47<00:24,  8.98it/s] 63%|██████▎   | 377/595 [00:47<00:24,  9.01it/s] 64%|██████▎   | 378/595 [00:47<00:24,  9.02it/s] 64%|██████▎   | 379/595 [00:47<00:23,  9.06it/s] 64%|██████▍   | 380/595 [00:47<00:23,  9.12it/s] 64%|██████▍   | 381/595 [00:47<00:23,  9.18it/s] 64%|██████▍   | 382/595 [00:47<00:23,  9.14it/s] 64%|██████▍   | 383/595 [00:48<00:23,  9.13it/s] 65%|██████▍   | 384/595 [00:48<00:23,  9.07it/s] 65%|██████▍   | 385/595 [00:48<00:23,  9.06it/s] 65%|██████▍   | 386/595 [00:48<00:23,  9.05it/s] 65%|██████▌   | 387/595 [00:48<00:22,  9.12it/s] 65%|██████▌   | 388/595 [00:48<00:22,  9.13it/s] 65%|██████▌   | 389/595 [00:48<00:22,  9.03it/s] 66%|██████▌   | 390/595 [00:48<00:22,  9.07it/s] 66%|██████▌   | 391/595 [00:48<00:22,  9.01it/s] 66%|██████▌   | 392/595 [00:49<00:22,  8.99it/s] 66%|██████▌   | 393/595 [00:49<00:22,  8.96it/s] 66%|██████▌   | 394/595 [00:49<00:22,  9.04it/s] 66%|██████▋   | 395/595 [00:49<00:22,  9.05it/s] 67%|██████▋   | 396/595 [00:49<00:21,  9.08it/s] 67%|██████▋   | 397/595 [00:49<00:21,  9.02it/s] 67%|██████▋   | 398/595 [00:49<00:22,  8.94it/s] 67%|██████▋   | 399/595 [00:49<00:21,  8.95it/s] 67%|██████▋   | 400/595 [00:49<00:21,  8.96it/s] 67%|██████▋   | 401/595 [00:50<00:21,  9.08it/s] 68%|██████▊   | 402/595 [00:50<00:21,  9.09it/s] 68%|██████▊   | 403/595 [00:50<00:21,  9.08it/s] 68%|██████▊   | 404/595 [00:50<00:21,  9.01it/s] 68%|██████▊   | 405/595 [00:50<00:21,  9.00it/s] 68%|██████▊   | 406/595 [00:50<00:21,  8.98it/s] 68%|██████▊   | 407/595 [00:50<00:21,  8.93it/s] 69%|██████▊   | 408/595 [00:50<00:20,  9.03it/s] 69%|██████▊   | 409/595 [00:50<00:20,  9.05it/s] 69%|██████▉   | 410/595 [00:51<00:20,  9.03it/s] 69%|██████▉   | 411/595 [00:51<00:20,  8.95it/s] 69%|██████▉   | 412/595 [00:51<00:20,  8.96it/s] 69%|██████▉   | 413/595 [00:51<00:20,  8.90it/s] 70%|██████▉   | 414/595 [00:51<00:20,  8.94it/s] 70%|██████▉   | 415/595 [00:51<00:19,  9.07it/s] 70%|██████▉   | 416/595 [00:51<00:19,  9.04it/s] 70%|███████   | 417/595 [00:51<00:19,  9.06it/s] 70%|███████   | 418/595 [00:51<00:19,  8.95it/s] 70%|███████   | 419/595 [00:52<00:19,  8.99it/s] 71%|███████   | 420/595 [00:52<00:19,  8.96it/s] 71%|███████   | 421/595 [00:52<00:19,  8.94it/s] 71%|███████   | 422/595 [00:52<00:19,  9.03it/s] 71%|███████   | 423/595 [00:52<00:18,  9.09it/s] 71%|███████▏  | 424/595 [00:52<00:18,  9.08it/s] 71%|███████▏  | 425/595 [00:52<00:18,  9.03it/s] 72%|███████▏  | 426/595 [00:52<00:18,  9.03it/s] 72%|███████▏  | 427/595 [00:52<00:18,  9.01it/s] 72%|███████▏  | 428/595 [00:53<00:18,  9.01it/s] 72%|███████▏  | 429/595 [00:53<00:18,  9.03it/s] 72%|███████▏  | 430/595 [00:53<00:18,  9.06it/s] 72%|███████▏  | 431/595 [00:53<00:18,  9.05it/s] 73%|███████▎  | 432/595 [00:53<00:18,  8.98it/s] 73%|███████▎  | 433/595 [00:53<00:18,  8.97it/s] 73%|███████▎  | 434/595 [00:53<00:17,  8.97it/s] 73%|███████▎  | 435/595 [00:53<00:17,  8.98it/s] 73%|███████▎  | 436/595 [00:53<00:17,  9.06it/s] 73%|███████▎  | 437/595 [00:54<00:17,  9.01it/s] 74%|███████▎  | 438/595 [00:54<00:17,  9.06it/s] 74%|███████▍  | 439/595 [00:54<00:17,  9.05it/s] 74%|███████▍  | 440/595 [00:54<00:17,  9.04it/s] 74%|███████▍  | 441/595 [00:54<00:17,  9.06it/s] 74%|███████▍  | 442/595 [00:54<00:16,  9.04it/s] 74%|███████▍  | 443/595 [00:54<00:16,  9.09it/s] 75%|███████▍  | 444/595 [00:54<00:16,  9.15it/s] 75%|███████▍  | 445/595 [00:54<00:16,  9.13it/s] 75%|███████▍  | 446/595 [00:55<00:16,  9.06it/s] 75%|███████▌  | 447/595 [00:55<00:16,  9.04it/s] 75%|███████▌  | 448/595 [00:55<00:16,  8.97it/s] 75%|███████▌  | 449/595 [00:55<00:16,  8.95it/s] 76%|███████▌  | 450/595 [00:55<00:16,  8.98it/s] 76%|███████▌  | 451/595 [00:55<00:15,  9.07it/s] 76%|███████▌  | 452/595 [00:55<00:15,  9.08it/s] 76%|███████▌  | 453/595 [00:55<00:15,  9.08it/s] 76%|███████▋  | 454/595 [00:55<00:15,  9.02it/s] 76%|███████▋  | 455/595 [00:56<00:15,  9.00it/s] 77%|███████▋  | 456/595 [00:56<00:15,  8.97it/s] 77%|███████▋  | 457/595 [00:56<00:15,  9.04it/s] 77%|███████▋  | 458/595 [00:56<00:15,  9.08it/s] 77%|███████▋  | 459/595 [00:56<00:15,  9.06it/s] 77%|███████▋  | 460/595 [00:56<00:14,  9.05it/s] 77%|███████▋  | 461/595 [00:56<00:14,  8.99it/s] 78%|███████▊  | 462/595 [00:56<00:14,  8.96it/s] 78%|███████▊  | 463/595 [00:56<00:14,  8.95it/s] 78%|███████▊  | 464/595 [00:57<00:14,  9.01it/s] 78%|███████▊  | 465/595 [00:57<00:14,  9.03it/s] 78%|███████▊  | 466/595 [00:57<00:14,  9.04it/s] 78%|███████▊  | 467/595 [00:57<00:14,  9.05it/s] 79%|███████▊  | 468/595 [00:57<00:14,  8.96it/s] 79%|███████▉  | 469/595 [00:57<00:14,  8.96it/s] 79%|███████▉  | 470/595 [00:57<00:14,  8.91it/s] 79%|███████▉  | 471/595 [00:57<00:13,  8.92it/s] 79%|███████▉  | 472/595 [00:57<00:13,  8.98it/s] 79%|███████▉  | 473/595 [00:58<00:13,  8.97it/s] 80%|███████▉  | 474/595 [00:58<00:13,  9.01it/s] 80%|███████▉  | 475/595 [00:58<00:13,  9.02it/s]                                                  80%|████████  | 476/595 [00:58<00:13,  9.02it/s][INFO|trainer.py:755] 2023-11-15 20:23:13,582 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:23:13,583 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:23:13,584 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:23:13,584 >>   Batch size = 8
{'eval_loss': 0.49311962723731995, 'eval_accuracy': 0.8296296296296296, 'eval_micro_f1': 0.8296296296296296, 'eval_macro_f1': 0.7682348343117434, 'eval_runtime': 1.6392, 'eval_samples_per_second': 576.497, 'eval_steps_per_second': 72.596, 'epoch': 3.0}
{'loss': 0.2228, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 81.39it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 80.26it/s][A
 23%|██▎       | 27/119 [00:00<00:01, 74.09it/s][A
 29%|██▉       | 35/119 [00:00<00:01, 72.92it/s][A
 36%|███▌      | 43/119 [00:00<00:01, 71.41it/s][A
 43%|████▎     | 51/119 [00:00<00:00, 72.06it/s][A
 50%|████▉     | 59/119 [00:00<00:00, 70.77it/s][A
 56%|█████▋    | 67/119 [00:00<00:00, 71.98it/s][A
 63%|██████▎   | 75/119 [00:01<00:00, 72.95it/s][A
 70%|██████▉   | 83/119 [00:01<00:00, 72.46it/s][A
 76%|███████▋  | 91/119 [00:01<00:00, 70.85it/s][A
 83%|████████▎ | 99/119 [00:01<00:00, 70.21it/s][A
 90%|████████▉ | 107/119 [00:01<00:00, 71.76it/s][A
 97%|█████████▋| 115/119 [00:01<00:00, 70.99it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [01:00<00:13,  9.02it/s]
100%|██████████| 119/119 [00:01<00:00, 70.99it/s][A
                                                 [A 80%|████████  | 477/595 [01:00<00:57,  2.05it/s] 80%|████████  | 478/595 [01:00<00:46,  2.54it/s] 81%|████████  | 479/595 [01:00<00:37,  3.12it/s] 81%|████████  | 480/595 [01:00<00:30,  3.78it/s] 81%|████████  | 481/595 [01:00<00:25,  4.52it/s] 81%|████████  | 482/595 [01:00<00:21,  5.27it/s] 81%|████████  | 483/595 [01:00<00:18,  5.99it/s] 81%|████████▏ | 484/595 [01:00<00:16,  6.63it/s] 82%|████████▏ | 485/595 [01:01<00:15,  7.13it/s] 82%|████████▏ | 486/595 [01:01<00:14,  7.56it/s] 82%|████████▏ | 487/595 [01:01<00:13,  7.96it/s] 82%|████████▏ | 488/595 [01:01<00:12,  8.27it/s] 82%|████████▏ | 489/595 [01:01<00:12,  8.44it/s] 82%|████████▏ | 490/595 [01:01<00:12,  8.63it/s] 83%|████████▎ | 491/595 [01:01<00:12,  8.65it/s] 83%|████████▎ | 492/595 [01:01<00:11,  8.74it/s] 83%|████████▎ | 493/595 [01:01<00:11,  8.78it/s] 83%|████████▎ | 494/595 [01:02<00:11,  8.79it/s] 83%|████████▎ | 495/595 [01:02<00:11,  8.89it/s] 83%|████████▎ | 496/595 [01:02<00:11,  8.95it/s] 84%|████████▎ | 497/595 [01:02<00:11,  8.91it/s] 84%|████████▎ | 498/595 [01:02<00:10,  8.89it/s] 84%|████████▍ | 499/595 [01:02<00:10,  8.88it/s] 84%|████████▍ | 500/595 [01:02<00:10,  8.85it/s] 84%|████████▍ | 501/595 [01:02<00:10,  8.87it/s] 84%|████████▍ | 502/595 [01:02<00:10,  8.93it/s] 85%|████████▍ | 503/595 [01:03<00:10,  8.92it/s] 85%|████████▍ | 504/595 [01:03<00:10,  8.96it/s] 85%|████████▍ | 505/595 [01:03<00:10,  8.85it/s] 85%|████████▌ | 506/595 [01:03<00:10,  8.89it/s] 85%|████████▌ | 507/595 [01:03<00:09,  8.90it/s] 85%|████████▌ | 508/595 [01:03<00:09,  8.90it/s] 86%|████████▌ | 509/595 [01:03<00:09,  9.01it/s] 86%|████████▌ | 510/595 [01:03<00:09,  8.96it/s] 86%|████████▌ | 511/595 [01:03<00:09,  9.01it/s] 86%|████████▌ | 512/595 [01:04<00:09,  9.03it/s] 86%|████████▌ | 513/595 [01:04<00:09,  8.99it/s] 86%|████████▋ | 514/595 [01:04<00:09,  8.96it/s] 87%|████████▋ | 515/595 [01:04<00:08,  8.99it/s] 87%|████████▋ | 516/595 [01:04<00:08,  9.05it/s] 87%|████████▋ | 517/595 [01:04<00:08,  8.99it/s] 87%|████████▋ | 518/595 [01:04<00:08,  8.97it/s] 87%|████████▋ | 519/595 [01:04<00:08,  9.01it/s] 87%|████████▋ | 520/595 [01:04<00:08,  9.01it/s] 88%|████████▊ | 521/595 [01:05<00:08,  9.01it/s] 88%|████████▊ | 522/595 [01:05<00:08,  9.03it/s] 88%|████████▊ | 523/595 [01:05<00:07,  9.12it/s] 88%|████████▊ | 524/595 [01:05<00:07,  8.97it/s] 88%|████████▊ | 525/595 [01:05<00:07,  8.97it/s] 88%|████████▊ | 526/595 [01:05<00:07,  8.93it/s] 89%|████████▊ | 527/595 [01:05<00:07,  8.96it/s] 89%|████████▊ | 528/595 [01:05<00:07,  8.97it/s] 89%|████████▉ | 529/595 [01:05<00:07,  8.98it/s] 89%|████████▉ | 530/595 [01:06<00:07,  9.06it/s] 89%|████████▉ | 531/595 [01:06<00:07,  9.02it/s] 89%|████████▉ | 532/595 [01:06<00:07,  9.00it/s] 90%|████████▉ | 533/595 [01:06<00:06,  8.94it/s] 90%|████████▉ | 534/595 [01:06<00:06,  9.05it/s] 90%|████████▉ | 535/595 [01:06<00:06,  8.98it/s] 90%|█████████ | 536/595 [01:06<00:06,  9.05it/s] 90%|█████████ | 537/595 [01:06<00:06,  9.02it/s] 90%|█████████ | 538/595 [01:06<00:06,  8.99it/s] 91%|█████████ | 539/595 [01:07<00:06,  8.88it/s] 91%|█████████ | 540/595 [01:07<00:06,  8.93it/s] 91%|█████████ | 541/595 [01:07<00:06,  9.00it/s] 91%|█████████ | 542/595 [01:07<00:05,  8.99it/s] 91%|█████████▏| 543/595 [01:07<00:05,  9.01it/s] 91%|█████████▏| 544/595 [01:07<00:05,  8.97it/s] 92%|█████████▏| 545/595 [01:07<00:05,  8.89it/s] 92%|█████████▏| 546/595 [01:07<00:05,  8.87it/s] 92%|█████████▏| 547/595 [01:07<00:05,  8.88it/s] 92%|█████████▏| 548/595 [01:08<00:05,  9.01it/s] 92%|█████████▏| 549/595 [01:08<00:05,  9.07it/s] 92%|█████████▏| 550/595 [01:08<00:04,  9.01it/s] 93%|█████████▎| 551/595 [01:08<00:04,  8.93it/s] 93%|█████████▎| 552/595 [01:08<00:04,  8.91it/s] 93%|█████████▎| 553/595 [01:08<00:04,  8.93it/s] 93%|█████████▎| 554/595 [01:08<00:04,  8.94it/s] 93%|█████████▎| 555/595 [01:08<00:04,  8.97it/s] 93%|█████████▎| 556/595 [01:08<00:04,  8.98it/s] 94%|█████████▎| 557/595 [01:09<00:04,  8.99it/s] 94%|█████████▍| 558/595 [01:09<00:04,  8.99it/s] 94%|█████████▍| 559/595 [01:09<00:04,  8.96it/s] 94%|█████████▍| 560/595 [01:09<00:03,  8.92it/s] 94%|█████████▍| 561/595 [01:09<00:03,  8.90it/s] 94%|█████████▍| 562/595 [01:09<00:03,  9.01it/s] 95%|█████████▍| 563/595 [01:09<00:03,  8.95it/s] 95%|█████████▍| 564/595 [01:09<00:03,  8.96it/s] 95%|█████████▍| 565/595 [01:09<00:03,  8.96it/s] 95%|█████████▌| 566/595 [01:10<00:03,  8.94it/s] 95%|█████████▌| 567/595 [01:10<00:03,  8.90it/s] 95%|█████████▌| 568/595 [01:10<00:03,  8.95it/s] 96%|█████████▌| 569/595 [01:10<00:02,  9.06it/s] 96%|█████████▌| 570/595 [01:10<00:02,  9.05it/s] 96%|█████████▌| 571/595 [01:10<00:02,  8.97it/s] 96%|█████████▌| 572/595 [01:10<00:02,  8.91it/s] 96%|█████████▋| 573/595 [01:10<00:02,  8.92it/s] 96%|█████████▋| 574/595 [01:10<00:02,  8.93it/s] 97%|█████████▋| 575/595 [01:11<00:02,  8.92it/s] 97%|█████████▋| 576/595 [01:11<00:02,  9.00it/s] 97%|█████████▋| 577/595 [01:11<00:01,  9.04it/s] 97%|█████████▋| 578/595 [01:11<00:01,  8.97it/s] 97%|█████████▋| 579/595 [01:11<00:01,  8.88it/s] 97%|█████████▋| 580/595 [01:11<00:01,  8.92it/s] 98%|█████████▊| 581/595 [01:11<00:01,  8.85it/s] 98%|█████████▊| 582/595 [01:11<00:01,  8.89it/s] 98%|█████████▊| 583/595 [01:11<00:01,  9.00it/s] 98%|█████████▊| 584/595 [01:12<00:01,  8.99it/s] 98%|█████████▊| 585/595 [01:12<00:01,  8.96it/s] 98%|█████████▊| 586/595 [01:12<00:00,  9.04it/s] 99%|█████████▊| 587/595 [01:12<00:00,  9.02it/s] 99%|█████████▉| 588/595 [01:12<00:00,  9.01it/s] 99%|█████████▉| 589/595 [01:12<00:00,  8.96it/s] 99%|█████████▉| 590/595 [01:12<00:00,  9.02it/s] 99%|█████████▉| 591/595 [01:12<00:00,  9.00it/s] 99%|█████████▉| 592/595 [01:12<00:00,  9.00it/s]100%|█████████▉| 593/595 [01:13<00:00,  9.06it/s]100%|█████████▉| 594/595 [01:13<00:00,  8.99it/s]                                                 100%|██████████| 595/595 [01:13<00:00,  8.99it/s][INFO|trainer.py:755] 2023-11-15 20:23:28,487 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:23:28,489 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:23:28,489 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:23:28,490 >>   Batch size = 8
{'eval_loss': 0.5261925458908081, 'eval_accuracy': 0.8359788359788359, 'eval_micro_f1': 0.8359788359788359, 'eval_macro_f1': 0.7747101115710913, 'eval_runtime': 1.6904, 'eval_samples_per_second': 559.051, 'eval_steps_per_second': 70.399, 'epoch': 4.0}
{'loss': 0.1795, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 78.89it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 74.92it/s][A
 20%|██        | 24/119 [00:00<00:01, 73.14it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 72.10it/s][A
 34%|███▎      | 40/119 [00:00<00:01, 72.14it/s][A
 40%|████      | 48/119 [00:00<00:00, 74.19it/s][A
 47%|████▋     | 56/119 [00:00<00:00, 72.21it/s][A
 54%|█████▍    | 64/119 [00:00<00:00, 71.64it/s][A
 61%|██████    | 72/119 [00:00<00:00, 71.25it/s][A
 67%|██████▋   | 80/119 [00:01<00:00, 71.17it/s][A
 74%|███████▍  | 88/119 [00:01<00:00, 71.26it/s][A
 81%|████████  | 96/119 [00:01<00:00, 71.79it/s][A
 87%|████████▋ | 104/119 [00:01<00:00, 72.54it/s][A
 94%|█████████▍| 112/119 [00:01<00:00, 70.97it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:14<00:00,  8.99it/s]
100%|██████████| 119/119 [00:01<00:00, 70.97it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 20:23:30,194 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:14<00:00,  8.99it/s]100%|██████████| 595/595 [01:14<00:00,  7.94it/s]
[INFO|trainer.py:2855] 2023-11-15 20:23:30,198 >> Saving model checkpoint to ./result/restaurant_roberta-base_adapter__seed2
[INFO|configuration_utils.py:460] 2023-11-15 20:23:30,201 >> Configuration saved in ./result/restaurant_roberta-base_adapter__seed2/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:23:31,656 >> Model weights saved in ./result/restaurant_roberta-base_adapter__seed2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:23:31,660 >> tokenizer config file saved in ./result/restaurant_roberta-base_adapter__seed2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:23:31,662 >> Special tokens file saved in ./result/restaurant_roberta-base_adapter__seed2/special_tokens_map.json
{'eval_loss': 0.5265376567840576, 'eval_accuracy': 0.8402116402116402, 'eval_micro_f1': 0.8402116402116402, 'eval_macro_f1': 0.7835653266677892, 'eval_runtime': 1.7003, 'eval_samples_per_second': 555.795, 'eval_steps_per_second': 69.989, 'epoch': 5.0}
{'train_runtime': 74.9254, 'train_samples_per_second': 252.051, 'train_steps_per_second': 7.941, 'train_loss': 0.38050994231921287, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3805
  train_runtime            = 0:01:14.92
  train_samples            =       3777
  train_samples_per_second =    252.051
  train_steps_per_second   =      7.941
11/15/2023 20:23:31 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:23:31,763 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:23:31,765 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:23:31,765 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:23:31,765 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  7%|▋         | 8/119 [00:00<00:01, 77.65it/s] 13%|█▎        | 16/119 [00:00<00:01, 76.11it/s] 20%|██        | 24/119 [00:00<00:01, 74.49it/s] 27%|██▋       | 32/119 [00:00<00:01, 72.61it/s] 34%|███▎      | 40/119 [00:00<00:01, 73.58it/s] 40%|████      | 48/119 [00:00<00:00, 72.44it/s] 47%|████▋     | 56/119 [00:00<00:00, 71.69it/s] 54%|█████▍    | 64/119 [00:00<00:00, 71.88it/s] 61%|██████    | 72/119 [00:00<00:00, 72.67it/s] 67%|██████▋   | 80/119 [00:01<00:00, 71.55it/s] 74%|███████▍  | 88/119 [00:01<00:00, 70.98it/s] 81%|████████  | 96/119 [00:01<00:00, 70.93it/s] 87%|████████▋ | 104/119 [00:01<00:00, 71.63it/s] 94%|█████████▍| 112/119 [00:01<00:00, 70.98it/s]100%|██████████| 119/119 [00:01<00:00, 70.89it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8402
  eval_loss               =     0.5265
  eval_macro_f1           =     0.7836
  eval_micro_f1           =     0.8402
  eval_runtime            = 0:00:01.69
  eval_samples            =        945
  eval_samples_per_second =    558.263
  eval_steps_per_second   =       70.3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▂▇▇██
wandb:                      eval/loss █▃▁▃▄▄
wandb:                  eval/macro_f1 ▁▂▇▇██
wandb:                  eval/micro_f1 ▁▂▇▇██
wandb:                   eval/runtime ▁▅▂▇█▇
wandb:        eval/samples_per_second █▄▇▂▁▂
wandb:          eval/steps_per_second █▄▇▂▁▂
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.84021
wandb:                      eval/loss 0.52654
wandb:                  eval/macro_f1 0.78357
wandb:                  eval/micro_f1 0.84021
wandb:                   eval/runtime 1.6928
wandb:        eval/samples_per_second 558.263
wandb:          eval/steps_per_second 70.3
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1795
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.38051
wandb:            train/train_runtime 74.9254
wandb: train/train_samples_per_second 252.051
wandb:   train/train_steps_per_second 7.941
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_202057-11z92syn
wandb: Find logs at: ./wandb/offline-run-20231115_202057-11z92syn/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_bert-base-cased_adapter__seed2/runs/Nov15_20-23-44_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_bert-base-cased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_bert-base-cased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:23:44 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:23:44 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_bert-base-cased_adapter__seed2/runs/Nov15_20-23-43_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_bert-base-cased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_bert-base-cased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  87%|████████▋ | 4125/4722 [00:00<00:00, 41006.40 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 40122.33 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:24:00,604 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:24:00,616 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 20:24:10,633 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:24:10,634 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:24:10,637 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:24:10,638 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:24:10,638 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:24:10,638 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:24:10,638 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 20:24:10,640 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:24:10,641 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:24:30,811 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:24:31,429 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:24:31,430 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 23288.33 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 22977.90 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 26343.68 examples/s]
11/15/2023 20:24:31 - INFO - __main__ - Sample 2272 of the training set: {'text': 'Carinthia cheese ravioli with wild mushrooms <SEP> Innovations are just as assured, from the simple Carinthia cheese ravioli with wild mushrooms to the caviar-topped sturgeon, beautifully matched with a bright green spinach-vodka sauce.', 'label': 0, 'input_ids': [101, 8185, 10879, 10652, 9553, 187, 21704, 11014, 1114, 4098, 25590, 1116, 133, 12342, 2101, 135, 13886, 1116, 1132, 1198, 1112, 8642, 117, 1121, 1103, 3014, 8185, 10879, 10652, 9553, 187, 21704, 11014, 1114, 4098, 25590, 1116, 1106, 1103, 11019, 7137, 1197, 118, 9065, 188, 20362, 21565, 117, 19758, 10260, 1114, 170, 3999, 2448, 6898, 7291, 118, 27407, 14313, 119, 102, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}.
11/15/2023 20:24:31 - INFO - __main__ - Sample 1436 of the training set: {'text': 'jazz singer <SEP> jazz singer had a nice voice + she made us all get up to dance to shake some cals to eat some more.', 'label': 0, 'input_ids': [101, 4888, 2483, 133, 12342, 2101, 135, 4888, 2483, 1125, 170, 3505, 1490, 116, 1131, 1189, 1366, 1155, 1243, 1146, 1106, 2842, 1106, 5854, 1199, 11019, 3447, 1106, 3940, 1199, 1167, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:24:31 - INFO - __main__ - Sample 1446 of the training set: {'text': 'iceberg <SEP> The bruscetta is a bit soggy, but the salads were fresh, included a nice mix of greens (not iceberg) all dishes are served piping hot from the kitchen.', 'label': 1, 'input_ids': [101, 2854, 2953, 133, 12342, 2101, 135, 1109, 9304, 1361, 2093, 5100, 1110, 170, 2113, 1177, 14720, 117, 1133, 1103, 19359, 1116, 1127, 4489, 117, 1529, 170, 3505, 5495, 1104, 2448, 1116, 113, 1136, 2854, 2953, 114, 1155, 10514, 1132, 1462, 185, 9717, 1158, 2633, 1121, 1103, 3119, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:24:31 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:24:33,069 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:24:33,076 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:24:33,077 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 20:24:33,077 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:24:33,077 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:24:33,078 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:24:33,078 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:24:33,078 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 20:24:33,079 >>   Number of trainable parameters = 108,312,579
[INFO|integration_utils.py:716] 2023-11-15 20:24:33,080 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<13:31,  1.37s/it]  0%|          | 2/595 [00:01<06:10,  1.60it/s]  1%|          | 3/595 [00:01<03:49,  2.58it/s]  1%|          | 4/595 [00:01<02:44,  3.60it/s]  1%|          | 5/595 [00:01<02:08,  4.60it/s]  1%|          | 6/595 [00:01<01:46,  5.55it/s]  1%|          | 7/595 [00:02<01:32,  6.39it/s]  1%|▏         | 8/595 [00:02<01:22,  7.13it/s]  2%|▏         | 9/595 [00:02<01:16,  7.68it/s]  2%|▏         | 10/595 [00:02<01:11,  8.16it/s]  2%|▏         | 11/595 [00:02<01:09,  8.43it/s]  2%|▏         | 12/595 [00:02<01:06,  8.70it/s]  2%|▏         | 13/595 [00:02<01:05,  8.89it/s]  2%|▏         | 14/595 [00:02<01:04,  8.98it/s]  3%|▎         | 15/595 [00:02<01:04,  9.05it/s]  3%|▎         | 16/595 [00:02<01:03,  9.12it/s]  3%|▎         | 17/595 [00:03<01:03,  9.14it/s]  3%|▎         | 18/595 [00:03<01:02,  9.21it/s]  3%|▎         | 19/595 [00:03<01:01,  9.32it/s]  3%|▎         | 20/595 [00:03<01:01,  9.35it/s]  4%|▎         | 21/595 [00:03<01:01,  9.31it/s]  4%|▎         | 22/595 [00:03<01:01,  9.31it/s]  4%|▍         | 23/595 [00:03<01:01,  9.29it/s]  4%|▍         | 24/595 [00:03<01:01,  9.25it/s]  4%|▍         | 25/595 [00:03<01:01,  9.32it/s]  4%|▍         | 26/595 [00:04<01:01,  9.22it/s]  5%|▍         | 27/595 [00:04<01:01,  9.26it/s]  5%|▍         | 28/595 [00:04<01:01,  9.25it/s]  5%|▍         | 29/595 [00:04<01:01,  9.21it/s]  5%|▌         | 30/595 [00:04<01:00,  9.36it/s]  5%|▌         | 31/595 [00:04<01:00,  9.32it/s]  5%|▌         | 32/595 [00:04<01:00,  9.26it/s]  6%|▌         | 33/595 [00:04<01:01,  9.21it/s]  6%|▌         | 34/595 [00:04<01:00,  9.32it/s]  6%|▌         | 35/595 [00:05<00:59,  9.34it/s]  6%|▌         | 36/595 [00:05<01:00,  9.26it/s]  6%|▌         | 37/595 [00:05<01:00,  9.24it/s]  6%|▋         | 38/595 [00:05<01:00,  9.28it/s]  7%|▋         | 39/595 [00:05<00:59,  9.28it/s]  7%|▋         | 40/595 [00:05<00:59,  9.31it/s]  7%|▋         | 41/595 [00:05<00:58,  9.47it/s]  7%|▋         | 42/595 [00:05<00:58,  9.40it/s]  7%|▋         | 43/595 [00:05<00:58,  9.38it/s]  7%|▋         | 44/595 [00:05<00:59,  9.31it/s]  8%|▊         | 45/595 [00:06<00:59,  9.31it/s]  8%|▊         | 46/595 [00:06<00:58,  9.37it/s]  8%|▊         | 47/595 [00:06<00:58,  9.36it/s]  8%|▊         | 48/595 [00:06<00:58,  9.32it/s]  8%|▊         | 49/595 [00:06<00:58,  9.30it/s]  8%|▊         | 50/595 [00:06<00:58,  9.33it/s]  9%|▊         | 51/595 [00:06<00:58,  9.33it/s]  9%|▊         | 52/595 [00:06<00:57,  9.46it/s]  9%|▉         | 53/595 [00:06<00:58,  9.30it/s]  9%|▉         | 54/595 [00:07<00:58,  9.25it/s]  9%|▉         | 55/595 [00:07<00:58,  9.25it/s]  9%|▉         | 56/595 [00:07<00:58,  9.25it/s] 10%|▉         | 57/595 [00:07<00:57,  9.29it/s] 10%|▉         | 58/595 [00:07<00:57,  9.31it/s] 10%|▉         | 59/595 [00:07<00:57,  9.29it/s] 10%|█         | 60/595 [00:07<00:57,  9.24it/s] 10%|█         | 61/595 [00:07<00:57,  9.26it/s] 10%|█         | 62/595 [00:07<00:57,  9.25it/s] 11%|█         | 63/595 [00:08<00:56,  9.39it/s] 11%|█         | 64/595 [00:08<00:56,  9.32it/s] 11%|█         | 65/595 [00:08<00:56,  9.37it/s] 11%|█         | 66/595 [00:08<00:56,  9.33it/s] 11%|█▏        | 67/595 [00:08<00:56,  9.32it/s] 11%|█▏        | 68/595 [00:08<00:56,  9.34it/s] 12%|█▏        | 69/595 [00:08<00:56,  9.33it/s] 12%|█▏        | 70/595 [00:08<00:56,  9.28it/s] 12%|█▏        | 71/595 [00:08<00:56,  9.31it/s] 12%|█▏        | 72/595 [00:08<00:56,  9.27it/s] 12%|█▏        | 73/595 [00:09<00:56,  9.20it/s] 12%|█▏        | 74/595 [00:09<00:55,  9.31it/s] 13%|█▎        | 75/595 [00:09<00:56,  9.26it/s] 13%|█▎        | 76/595 [00:09<00:56,  9.26it/s] 13%|█▎        | 77/595 [00:09<00:56,  9.24it/s] 13%|█▎        | 78/595 [00:09<00:55,  9.28it/s] 13%|█▎        | 79/595 [00:09<00:55,  9.27it/s] 13%|█▎        | 80/595 [00:09<00:55,  9.30it/s] 14%|█▎        | 81/595 [00:09<00:55,  9.22it/s] 14%|█▍        | 82/595 [00:10<00:55,  9.22it/s] 14%|█▍        | 83/595 [00:10<00:55,  9.21it/s] 14%|█▍        | 84/595 [00:10<00:55,  9.16it/s] 14%|█▍        | 85/595 [00:10<00:54,  9.30it/s] 14%|█▍        | 86/595 [00:10<00:54,  9.26it/s] 15%|█▍        | 87/595 [00:10<00:54,  9.31it/s] 15%|█▍        | 88/595 [00:10<00:54,  9.30it/s] 15%|█▍        | 89/595 [00:10<00:54,  9.31it/s] 15%|█▌        | 90/595 [00:10<00:53,  9.36it/s] 15%|█▌        | 91/595 [00:11<00:54,  9.27it/s] 15%|█▌        | 92/595 [00:11<00:54,  9.19it/s] 16%|█▌        | 93/595 [00:11<00:54,  9.19it/s] 16%|█▌        | 94/595 [00:11<00:54,  9.18it/s] 16%|█▌        | 95/595 [00:11<00:53,  9.27it/s] 16%|█▌        | 96/595 [00:11<00:53,  9.39it/s] 16%|█▋        | 97/595 [00:11<00:53,  9.28it/s] 16%|█▋        | 98/595 [00:11<00:53,  9.26it/s] 17%|█▋        | 99/595 [00:11<00:54,  9.18it/s] 17%|█▋        | 100/595 [00:12<00:53,  9.23it/s] 17%|█▋        | 101/595 [00:12<00:53,  9.26it/s] 17%|█▋        | 102/595 [00:12<00:53,  9.23it/s] 17%|█▋        | 103/595 [00:12<00:53,  9.27it/s] 17%|█▋        | 104/595 [00:12<00:53,  9.16it/s] 18%|█▊        | 105/595 [00:12<00:53,  9.09it/s] 18%|█▊        | 106/595 [00:12<00:53,  9.09it/s] 18%|█▊        | 107/595 [00:12<00:52,  9.28it/s] 18%|█▊        | 108/595 [00:12<00:52,  9.25it/s] 18%|█▊        | 109/595 [00:12<00:52,  9.27it/s] 18%|█▊        | 110/595 [00:13<00:52,  9.26it/s] 19%|█▊        | 111/595 [00:13<00:51,  9.33it/s] 19%|█▉        | 112/595 [00:13<00:52,  9.27it/s] 19%|█▉        | 113/595 [00:13<00:51,  9.29it/s] 19%|█▉        | 114/595 [00:13<00:52,  9.25it/s] 19%|█▉        | 115/595 [00:13<00:52,  9.22it/s] 19%|█▉        | 116/595 [00:13<00:52,  9.19it/s] 20%|█▉        | 117/595 [00:13<00:51,  9.26it/s] 20%|█▉        | 118/595 [00:13<00:51,  9.35it/s]                                                  20%|██        | 119/595 [00:14<00:50,  9.35it/s][INFO|trainer.py:755] 2023-11-15 20:24:47,107 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:24:47,109 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:24:47,109 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:24:47,110 >>   Batch size = 8
{'loss': 0.7115, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 82.27it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 72.93it/s][A
 23%|██▎       | 27/119 [00:00<00:01, 75.41it/s][A
 29%|██▉       | 35/119 [00:00<00:01, 73.48it/s][A
 36%|███▌      | 43/119 [00:00<00:01, 72.46it/s][A
 43%|████▎     | 51/119 [00:00<00:00, 71.82it/s][A
 50%|████▉     | 59/119 [00:00<00:00, 71.02it/s][A
 56%|█████▋    | 67/119 [00:00<00:00, 70.45it/s][A
 63%|██████▎   | 75/119 [00:01<00:00, 70.31it/s][A
 70%|██████▉   | 83/119 [00:01<00:00, 72.66it/s][A
 76%|███████▋  | 91/119 [00:01<00:00, 71.51it/s][A
 83%|████████▎ | 99/119 [00:01<00:00, 72.27it/s][A
 90%|████████▉ | 107/119 [00:01<00:00, 70.79it/s][A
 97%|█████████▋| 115/119 [00:01<00:00, 70.90it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:15<00:50,  9.35it/s]
100%|██████████| 119/119 [00:01<00:00, 70.90it/s][A
                                                 [A 20%|██        | 120/595 [00:15<03:52,  2.05it/s] 20%|██        | 121/595 [00:15<03:06,  2.54it/s] 21%|██        | 122/595 [00:16<02:31,  3.13it/s] 21%|██        | 123/595 [00:16<02:03,  3.82it/s] 21%|██        | 124/595 [00:16<01:43,  4.57it/s] 21%|██        | 125/595 [00:16<01:27,  5.37it/s] 21%|██        | 126/595 [00:16<01:16,  6.09it/s] 21%|██▏       | 127/595 [00:16<01:09,  6.74it/s] 22%|██▏       | 128/595 [00:16<01:03,  7.30it/s] 22%|██▏       | 129/595 [00:16<00:59,  7.84it/s] 22%|██▏       | 130/595 [00:16<00:56,  8.20it/s] 22%|██▏       | 131/595 [00:17<00:54,  8.47it/s] 22%|██▏       | 132/595 [00:17<00:53,  8.66it/s] 22%|██▏       | 133/595 [00:17<00:52,  8.83it/s] 23%|██▎       | 134/595 [00:17<00:51,  9.01it/s] 23%|██▎       | 135/595 [00:17<00:51,  9.02it/s] 23%|██▎       | 136/595 [00:17<00:49,  9.24it/s] 23%|██▎       | 137/595 [00:17<00:49,  9.26it/s] 23%|██▎       | 138/595 [00:17<00:49,  9.21it/s] 23%|██▎       | 139/595 [00:17<00:49,  9.18it/s] 24%|██▎       | 140/595 [00:17<00:49,  9.17it/s] 24%|██▎       | 141/595 [00:18<00:49,  9.17it/s] 24%|██▍       | 142/595 [00:18<00:49,  9.17it/s] 24%|██▍       | 143/595 [00:18<00:49,  9.16it/s] 24%|██▍       | 144/595 [00:18<00:49,  9.09it/s] 24%|██▍       | 145/595 [00:18<00:49,  9.15it/s] 25%|██▍       | 146/595 [00:18<00:48,  9.18it/s] 25%|██▍       | 147/595 [00:18<00:48,  9.33it/s] 25%|██▍       | 148/595 [00:18<00:47,  9.32it/s] 25%|██▌       | 149/595 [00:18<00:48,  9.23it/s] 25%|██▌       | 150/595 [00:19<00:48,  9.27it/s] 25%|██▌       | 151/595 [00:19<00:48,  9.16it/s] 26%|██▌       | 152/595 [00:19<00:47,  9.27it/s] 26%|██▌       | 153/595 [00:19<00:47,  9.25it/s] 26%|██▌       | 154/595 [00:19<00:47,  9.34it/s] 26%|██▌       | 155/595 [00:19<00:47,  9.28it/s] 26%|██▌       | 156/595 [00:19<00:47,  9.24it/s] 26%|██▋       | 157/595 [00:19<00:47,  9.15it/s] 27%|██▋       | 158/595 [00:19<00:47,  9.20it/s] 27%|██▋       | 159/595 [00:20<00:47,  9.23it/s] 27%|██▋       | 160/595 [00:20<00:46,  9.28it/s] 27%|██▋       | 161/595 [00:20<00:47,  9.17it/s] 27%|██▋       | 162/595 [00:20<00:47,  9.15it/s] 27%|██▋       | 163/595 [00:20<00:47,  9.16it/s] 28%|██▊       | 164/595 [00:20<00:46,  9.19it/s] 28%|██▊       | 165/595 [00:20<00:46,  9.32it/s] 28%|██▊       | 166/595 [00:20<00:46,  9.26it/s] 28%|██▊       | 167/595 [00:20<00:46,  9.29it/s] 28%|██▊       | 168/595 [00:21<00:46,  9.23it/s] 28%|██▊       | 169/595 [00:21<00:46,  9.24it/s] 29%|██▊       | 170/595 [00:21<00:45,  9.27it/s] 29%|██▊       | 171/595 [00:21<00:45,  9.28it/s] 29%|██▉       | 172/595 [00:21<00:45,  9.25it/s] 29%|██▉       | 173/595 [00:21<00:45,  9.22it/s] 29%|██▉       | 174/595 [00:21<00:45,  9.20it/s] 29%|██▉       | 175/595 [00:21<00:45,  9.16it/s] 30%|██▉       | 176/595 [00:21<00:45,  9.27it/s] 30%|██▉       | 177/595 [00:22<00:45,  9.28it/s] 30%|██▉       | 178/595 [00:22<00:45,  9.23it/s] 30%|███       | 179/595 [00:22<00:44,  9.26it/s] 30%|███       | 180/595 [00:22<00:45,  9.17it/s] 30%|███       | 181/595 [00:22<00:45,  9.19it/s] 31%|███       | 182/595 [00:22<00:44,  9.19it/s] 31%|███       | 183/595 [00:22<00:44,  9.28it/s] 31%|███       | 184/595 [00:22<00:44,  9.23it/s] 31%|███       | 185/595 [00:22<00:44,  9.24it/s] 31%|███▏      | 186/595 [00:22<00:44,  9.15it/s] 31%|███▏      | 187/595 [00:23<00:44,  9.14it/s] 32%|███▏      | 188/595 [00:23<00:44,  9.19it/s] 32%|███▏      | 189/595 [00:23<00:44,  9.16it/s] 32%|███▏      | 190/595 [00:23<00:43,  9.22it/s] 32%|███▏      | 191/595 [00:23<00:43,  9.24it/s] 32%|███▏      | 192/595 [00:23<00:43,  9.21it/s] 32%|███▏      | 193/595 [00:23<00:43,  9.23it/s] 33%|███▎      | 194/595 [00:23<00:42,  9.38it/s] 33%|███▎      | 195/595 [00:23<00:42,  9.32it/s] 33%|███▎      | 196/595 [00:24<00:43,  9.28it/s] 33%|███▎      | 197/595 [00:24<00:43,  9.23it/s] 33%|███▎      | 198/595 [00:24<00:43,  9.18it/s] 33%|███▎      | 199/595 [00:24<00:42,  9.28it/s] 34%|███▎      | 200/595 [00:24<00:42,  9.23it/s] 34%|███▍      | 201/595 [00:24<00:42,  9.22it/s] 34%|███▍      | 202/595 [00:24<00:42,  9.19it/s] 34%|███▍      | 203/595 [00:24<00:42,  9.14it/s] 34%|███▍      | 204/595 [00:24<00:42,  9.12it/s] 34%|███▍      | 205/595 [00:25<00:42,  9.17it/s] 35%|███▍      | 206/595 [00:25<00:42,  9.07it/s] 35%|███▍      | 207/595 [00:25<00:42,  9.04it/s] 35%|███▍      | 208/595 [00:25<00:42,  9.03it/s] 35%|███▌      | 209/595 [00:25<00:42,  9.03it/s] 35%|███▌      | 210/595 [00:25<00:42,  9.03it/s] 35%|███▌      | 211/595 [00:25<00:42,  9.06it/s] 36%|███▌      | 212/595 [00:25<00:42,  9.12it/s] 36%|███▌      | 213/595 [00:25<00:41,  9.13it/s] 36%|███▌      | 214/595 [00:26<00:41,  9.16it/s] 36%|███▌      | 215/595 [00:26<00:41,  9.19it/s] 36%|███▋      | 216/595 [00:26<00:41,  9.22it/s] 36%|███▋      | 217/595 [00:26<00:40,  9.30it/s] 37%|███▋      | 218/595 [00:26<00:40,  9.29it/s] 37%|███▋      | 219/595 [00:26<00:40,  9.26it/s] 37%|███▋      | 220/595 [00:26<00:40,  9.20it/s] 37%|███▋      | 221/595 [00:26<00:40,  9.17it/s] 37%|███▋      | 222/595 [00:26<00:40,  9.21it/s] 37%|███▋      | 223/595 [00:27<00:40,  9.30it/s] 38%|███▊      | 224/595 [00:27<00:40,  9.27it/s] 38%|███▊      | 225/595 [00:27<00:40,  9.24it/s] 38%|███▊      | 226/595 [00:27<00:40,  9.17it/s] 38%|███▊      | 227/595 [00:27<00:40,  9.19it/s] 38%|███▊      | 228/595 [00:27<00:39,  9.19it/s] 38%|███▊      | 229/595 [00:27<00:39,  9.23it/s] 39%|███▊      | 230/595 [00:27<00:39,  9.31it/s] 39%|███▉      | 231/595 [00:27<00:39,  9.27it/s] 39%|███▉      | 232/595 [00:27<00:39,  9.26it/s] 39%|███▉      | 233/595 [00:28<00:39,  9.18it/s] 39%|███▉      | 234/595 [00:28<00:39,  9.20it/s] 39%|███▉      | 235/595 [00:28<00:39,  9.22it/s] 40%|███▉      | 236/595 [00:28<00:38,  9.21it/s] 40%|███▉      | 237/595 [00:28<00:38,  9.25it/s]                                                  40%|████      | 238/595 [00:28<00:38,  9.25it/s][INFO|trainer.py:755] 2023-11-15 20:25:01,654 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:25:01,656 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:25:01,656 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:25:01,656 >>   Batch size = 8
{'eval_loss': 0.6356382369995117, 'eval_accuracy': 0.7470899470899471, 'eval_micro_f1': 0.7470899470899471, 'eval_macro_f1': 0.6572112881391231, 'eval_runtime': 1.7029, 'eval_samples_per_second': 554.944, 'eval_steps_per_second': 69.882, 'epoch': 1.0}
{'loss': 0.4778, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 83.64it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 77.02it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 76.19it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 72.95it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 72.36it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 72.79it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 73.54it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 73.54it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 73.34it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 72.42it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 72.21it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 72.72it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 72.66it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 74.07it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:30<00:38,  9.25it/s]
100%|██████████| 119/119 [00:01<00:00, 74.07it/s][A
                                                 [A 40%|████      | 239/595 [00:30<02:49,  2.09it/s] 40%|████      | 240/595 [00:30<02:17,  2.58it/s] 41%|████      | 241/595 [00:30<01:51,  3.17it/s] 41%|████      | 242/595 [00:30<01:31,  3.86it/s] 41%|████      | 243/595 [00:30<01:16,  4.61it/s] 41%|████      | 244/595 [00:30<01:05,  5.37it/s] 41%|████      | 245/595 [00:31<00:57,  6.06it/s] 41%|████▏     | 246/595 [00:31<00:52,  6.69it/s] 42%|████▏     | 247/595 [00:31<00:48,  7.24it/s] 42%|████▏     | 248/595 [00:31<00:44,  7.72it/s] 42%|████▏     | 249/595 [00:31<00:42,  8.10it/s] 42%|████▏     | 250/595 [00:31<00:41,  8.39it/s] 42%|████▏     | 251/595 [00:31<00:40,  8.58it/s] 42%|████▏     | 252/595 [00:31<00:39,  8.78it/s] 43%|████▎     | 253/595 [00:31<00:38,  8.83it/s] 43%|████▎     | 254/595 [00:32<00:38,  8.84it/s] 43%|████▎     | 255/595 [00:32<00:37,  8.98it/s] 43%|████▎     | 256/595 [00:32<00:37,  9.00it/s] 43%|████▎     | 257/595 [00:32<00:37,  9.00it/s] 43%|████▎     | 258/595 [00:32<00:37,  9.05it/s] 44%|████▎     | 259/595 [00:32<00:37,  8.98it/s] 44%|████▎     | 260/595 [00:32<00:37,  9.00it/s] 44%|████▍     | 261/595 [00:32<00:37,  9.00it/s] 44%|████▍     | 262/595 [00:32<00:36,  9.14it/s] 44%|████▍     | 263/595 [00:32<00:36,  9.13it/s] 44%|████▍     | 264/595 [00:33<00:36,  9.11it/s] 45%|████▍     | 265/595 [00:33<00:36,  9.08it/s] 45%|████▍     | 266/595 [00:33<00:36,  9.04it/s] 45%|████▍     | 267/595 [00:33<00:36,  9.02it/s] 45%|████▌     | 268/595 [00:33<00:36,  9.03it/s] 45%|████▌     | 269/595 [00:33<00:35,  9.18it/s] 45%|████▌     | 270/595 [00:33<00:35,  9.12it/s] 46%|████▌     | 271/595 [00:33<00:35,  9.09it/s] 46%|████▌     | 272/595 [00:33<00:35,  9.05it/s] 46%|████▌     | 273/595 [00:34<00:35,  9.00it/s] 46%|████▌     | 274/595 [00:34<00:35,  9.06it/s] 46%|████▌     | 275/595 [00:34<00:35,  9.05it/s] 46%|████▋     | 276/595 [00:34<00:35,  9.05it/s] 47%|████▋     | 277/595 [00:34<00:35,  8.98it/s] 47%|████▋     | 278/595 [00:34<00:35,  8.97it/s] 47%|████▋     | 279/595 [00:34<00:35,  8.97it/s] 47%|████▋     | 280/595 [00:34<00:34,  9.04it/s] 47%|████▋     | 281/595 [00:34<00:34,  9.03it/s] 47%|████▋     | 282/595 [00:35<00:34,  8.97it/s] 48%|████▊     | 283/595 [00:35<00:34,  9.00it/s] 48%|████▊     | 284/595 [00:35<00:34,  9.01it/s] 48%|████▊     | 285/595 [00:35<00:34,  8.92it/s] 48%|████▊     | 286/595 [00:35<00:34,  8.98it/s] 48%|████▊     | 287/595 [00:35<00:34,  9.04it/s] 48%|████▊     | 288/595 [00:35<00:34,  9.00it/s] 49%|████▊     | 289/595 [00:35<00:33,  9.02it/s] 49%|████▊     | 290/595 [00:35<00:34,  8.96it/s] 49%|████▉     | 291/595 [00:36<00:33,  9.00it/s] 49%|████▉     | 292/595 [00:36<00:33,  8.98it/s] 49%|████▉     | 293/595 [00:36<00:33,  8.98it/s] 49%|████▉     | 294/595 [00:36<00:32,  9.12it/s] 50%|████▉     | 295/595 [00:36<00:33,  9.05it/s] 50%|████▉     | 296/595 [00:36<00:33,  9.02it/s] 50%|████▉     | 297/595 [00:36<00:33,  8.98it/s] 50%|█████     | 298/595 [00:36<00:33,  8.90it/s] 50%|█████     | 299/595 [00:36<00:33,  8.88it/s] 50%|█████     | 300/595 [00:37<00:33,  8.91it/s] 51%|█████     | 301/595 [00:37<00:32,  9.01it/s] 51%|█████     | 302/595 [00:37<00:32,  9.04it/s] 51%|█████     | 303/595 [00:37<00:32,  9.03it/s] 51%|█████     | 304/595 [00:37<00:32,  9.01it/s] 51%|█████▏    | 305/595 [00:37<00:32,  8.99it/s] 51%|█████▏    | 306/595 [00:37<00:32,  8.99it/s] 52%|█████▏    | 307/595 [00:37<00:32,  8.98it/s] 52%|█████▏    | 308/595 [00:37<00:31,  9.07it/s] 52%|█████▏    | 309/595 [00:38<00:31,  9.04it/s] 52%|█████▏    | 310/595 [00:38<00:31,  9.01it/s] 52%|█████▏    | 311/595 [00:38<00:31,  8.99it/s] 52%|█████▏    | 312/595 [00:38<00:31,  8.97it/s] 53%|█████▎    | 313/595 [00:38<00:31,  9.02it/s] 53%|█████▎    | 314/595 [00:38<00:31,  8.96it/s] 53%|█████▎    | 315/595 [00:38<00:30,  9.13it/s] 53%|█████▎    | 316/595 [00:38<00:30,  9.09it/s] 53%|█████▎    | 317/595 [00:38<00:30,  9.06it/s] 53%|█████▎    | 318/595 [00:39<00:30,  9.03it/s] 54%|█████▎    | 319/595 [00:39<00:30,  9.03it/s] 54%|█████▍    | 320/595 [00:39<00:30,  9.08it/s] 54%|█████▍    | 321/595 [00:39<00:30,  9.10it/s] 54%|█████▍    | 322/595 [00:39<00:29,  9.13it/s] 54%|█████▍    | 323/595 [00:39<00:29,  9.11it/s] 54%|█████▍    | 324/595 [00:39<00:30,  9.03it/s] 55%|█████▍    | 325/595 [00:39<00:29,  9.08it/s] 55%|█████▍    | 326/595 [00:39<00:29,  9.13it/s] 55%|█████▍    | 327/595 [00:40<00:29,  9.06it/s] 55%|█████▌    | 328/595 [00:40<00:29,  9.04it/s] 55%|█████▌    | 329/595 [00:40<00:29,  9.05it/s] 55%|█████▌    | 330/595 [00:40<00:29,  9.10it/s] 56%|█████▌    | 331/595 [00:40<00:29,  9.00it/s] 56%|█████▌    | 332/595 [00:40<00:29,  9.01it/s] 56%|█████▌    | 333/595 [00:40<00:28,  9.06it/s] 56%|█████▌    | 334/595 [00:40<00:28,  9.11it/s] 56%|█████▋    | 335/595 [00:40<00:28,  9.03it/s] 56%|█████▋    | 336/595 [00:41<00:28,  9.08it/s] 57%|█████▋    | 337/595 [00:41<00:28,  9.07it/s] 57%|█████▋    | 338/595 [00:41<00:28,  9.02it/s] 57%|█████▋    | 339/595 [00:41<00:28,  9.02it/s] 57%|█████▋    | 340/595 [00:41<00:27,  9.11it/s] 57%|█████▋    | 341/595 [00:41<00:27,  9.12it/s] 57%|█████▋    | 342/595 [00:41<00:28,  9.01it/s] 58%|█████▊    | 343/595 [00:41<00:27,  9.04it/s] 58%|█████▊    | 344/595 [00:41<00:27,  8.97it/s] 58%|█████▊    | 345/595 [00:42<00:27,  9.00it/s] 58%|█████▊    | 346/595 [00:42<00:27,  9.02it/s] 58%|█████▊    | 347/595 [00:42<00:27,  9.08it/s] 58%|█████▊    | 348/595 [00:42<00:27,  9.02it/s] 59%|█████▊    | 349/595 [00:42<00:27,  9.05it/s] 59%|█████▉    | 350/595 [00:42<00:27,  8.97it/s] 59%|█████▉    | 351/595 [00:42<00:27,  8.99it/s] 59%|█████▉    | 352/595 [00:42<00:26,  9.04it/s] 59%|█████▉    | 353/595 [00:42<00:26,  9.02it/s] 59%|█████▉    | 354/595 [00:43<00:26,  9.11it/s] 60%|█████▉    | 355/595 [00:43<00:26,  9.02it/s] 60%|█████▉    | 356/595 [00:43<00:26,  9.05it/s]                                                  60%|██████    | 357/595 [00:43<00:26,  9.05it/s][INFO|trainer.py:755] 2023-11-15 20:25:16,417 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:25:16,418 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:25:16,418 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:25:16,419 >>   Batch size = 8
{'eval_loss': 0.5938804745674133, 'eval_accuracy': 0.7682539682539683, 'eval_micro_f1': 0.7682539682539683, 'eval_macro_f1': 0.6791445668434651, 'eval_runtime': 1.663, 'eval_samples_per_second': 568.264, 'eval_steps_per_second': 71.559, 'epoch': 2.0}
{'loss': 0.3333, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 86.96it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 74.66it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 72.20it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 69.73it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 69.78it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 69.66it/s][A
 48%|████▊     | 57/119 [00:00<00:00, 69.61it/s][A
 55%|█████▍    | 65/119 [00:00<00:00, 70.88it/s][A
 61%|██████▏   | 73/119 [00:01<00:00, 69.83it/s][A
 68%|██████▊   | 81/119 [00:01<00:00, 70.10it/s][A
 75%|███████▍  | 89/119 [00:01<00:00, 69.35it/s][A
 81%|████████  | 96/119 [00:01<00:00, 69.24it/s][A
 87%|████████▋ | 103/119 [00:01<00:00, 68.79it/s][A
 92%|█████████▏| 110/119 [00:01<00:00, 69.01it/s][A
 99%|█████████▉| 118/119 [00:01<00:00, 70.81it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:45<00:26,  9.05it/s]
100%|██████████| 119/119 [00:01<00:00, 70.81it/s][A
                                                 [A 60%|██████    | 358/595 [00:45<01:57,  2.02it/s] 60%|██████    | 359/595 [00:45<01:34,  2.50it/s] 61%|██████    | 360/595 [00:45<01:16,  3.08it/s] 61%|██████    | 361/595 [00:45<01:02,  3.73it/s] 61%|██████    | 362/595 [00:45<00:52,  4.47it/s] 61%|██████    | 363/595 [00:45<00:44,  5.21it/s] 61%|██████    | 364/595 [00:45<00:38,  5.97it/s] 61%|██████▏   | 365/595 [00:45<00:34,  6.66it/s] 62%|██████▏   | 366/595 [00:46<00:31,  7.21it/s] 62%|██████▏   | 367/595 [00:46<00:29,  7.65it/s] 62%|██████▏   | 368/595 [00:46<00:28,  7.99it/s] 62%|██████▏   | 369/595 [00:46<00:27,  8.24it/s] 62%|██████▏   | 370/595 [00:46<00:26,  8.48it/s] 62%|██████▏   | 371/595 [00:46<00:25,  8.67it/s] 63%|██████▎   | 372/595 [00:46<00:25,  8.76it/s] 63%|██████▎   | 373/595 [00:46<00:25,  8.86it/s] 63%|██████▎   | 374/595 [00:46<00:24,  8.88it/s] 63%|██████▎   | 375/595 [00:47<00:24,  8.92it/s] 63%|██████▎   | 376/595 [00:47<00:24,  8.89it/s] 63%|██████▎   | 377/595 [00:47<00:24,  8.93it/s] 64%|██████▎   | 378/595 [00:47<00:24,  8.96it/s] 64%|██████▎   | 379/595 [00:47<00:23,  9.01it/s] 64%|██████▍   | 380/595 [00:47<00:23,  8.98it/s] 64%|██████▍   | 381/595 [00:47<00:24,  8.89it/s] 64%|██████▍   | 382/595 [00:47<00:23,  8.92it/s] 64%|██████▍   | 383/595 [00:47<00:23,  8.90it/s] 65%|██████▍   | 384/595 [00:48<00:23,  8.94it/s] 65%|██████▍   | 385/595 [00:48<00:23,  9.04it/s] 65%|██████▍   | 386/595 [00:48<00:23,  9.06it/s] 65%|██████▌   | 387/595 [00:48<00:23,  9.03it/s] 65%|██████▌   | 388/595 [00:48<00:23,  8.98it/s] 65%|██████▌   | 389/595 [00:48<00:22,  8.96it/s] 66%|██████▌   | 390/595 [00:48<00:22,  8.94it/s] 66%|██████▌   | 391/595 [00:48<00:22,  8.91it/s] 66%|██████▌   | 392/595 [00:48<00:22,  9.03it/s] 66%|██████▌   | 393/595 [00:49<00:22,  9.00it/s] 66%|██████▌   | 394/595 [00:49<00:22,  8.99it/s] 66%|██████▋   | 395/595 [00:49<00:22,  9.01it/s] 67%|██████▋   | 396/595 [00:49<00:22,  8.96it/s] 67%|██████▋   | 397/595 [00:49<00:21,  9.00it/s] 67%|██████▋   | 398/595 [00:49<00:21,  9.03it/s] 67%|██████▋   | 399/595 [00:49<00:21,  9.05it/s] 67%|██████▋   | 400/595 [00:49<00:21,  9.00it/s] 67%|██████▋   | 401/595 [00:49<00:21,  9.00it/s] 68%|██████▊   | 402/595 [00:50<00:21,  8.97it/s] 68%|██████▊   | 403/595 [00:50<00:21,  8.99it/s] 68%|██████▊   | 404/595 [00:50<00:21,  8.95it/s] 68%|██████▊   | 405/595 [00:50<00:21,  8.99it/s] 68%|██████▊   | 406/595 [00:50<00:21,  8.99it/s] 68%|██████▊   | 407/595 [00:50<00:20,  9.04it/s] 69%|██████▊   | 408/595 [00:50<00:20,  8.98it/s] 69%|██████▊   | 409/595 [00:50<00:20,  9.04it/s] 69%|██████▉   | 410/595 [00:50<00:20,  8.97it/s] 69%|██████▉   | 411/595 [00:51<00:20,  8.98it/s] 69%|██████▉   | 412/595 [00:51<00:20,  8.98it/s] 69%|██████▉   | 413/595 [00:51<00:20,  8.98it/s] 70%|██████▉   | 414/595 [00:51<00:20,  8.99it/s] 70%|██████▉   | 415/595 [00:51<00:19,  9.06it/s] 70%|██████▉   | 416/595 [00:51<00:19,  9.11it/s] 70%|███████   | 417/595 [00:51<00:19,  9.05it/s] 70%|███████   | 418/595 [00:51<00:19,  9.05it/s] 70%|███████   | 419/595 [00:51<00:19,  8.98it/s] 71%|███████   | 420/595 [00:52<00:19,  8.92it/s] 71%|███████   | 421/595 [00:52<00:19,  8.97it/s] 71%|███████   | 422/595 [00:52<00:19,  9.04it/s] 71%|███████   | 423/595 [00:52<00:18,  9.15it/s] 71%|███████▏  | 424/595 [00:52<00:18,  9.10it/s] 71%|███████▏  | 425/595 [00:52<00:18,  9.10it/s] 72%|███████▏  | 426/595 [00:52<00:18,  9.07it/s] 72%|███████▏  | 427/595 [00:52<00:18,  9.08it/s] 72%|███████▏  | 428/595 [00:52<00:18,  9.05it/s] 72%|███████▏  | 429/595 [00:53<00:18,  9.09it/s] 72%|███████▏  | 430/595 [00:53<00:18,  9.15it/s] 72%|███████▏  | 431/595 [00:53<00:17,  9.13it/s] 73%|███████▎  | 432/595 [00:53<00:17,  9.16it/s] 73%|███████▎  | 433/595 [00:53<00:17,  9.14it/s] 73%|███████▎  | 434/595 [00:53<00:17,  9.10it/s] 73%|███████▎  | 435/595 [00:53<00:17,  9.09it/s] 73%|███████▎  | 436/595 [00:53<00:17,  9.03it/s] 73%|███████▎  | 437/595 [00:53<00:17,  9.06it/s] 74%|███████▎  | 438/595 [00:54<00:17,  9.09it/s] 74%|███████▍  | 439/595 [00:54<00:17,  9.11it/s] 74%|███████▍  | 440/595 [00:54<00:16,  9.23it/s] 74%|███████▍  | 441/595 [00:54<00:16,  9.15it/s] 74%|███████▍  | 442/595 [00:54<00:16,  9.14it/s] 74%|███████▍  | 443/595 [00:54<00:16,  9.05it/s] 75%|███████▍  | 444/595 [00:54<00:16,  9.04it/s] 75%|███████▍  | 445/595 [00:54<00:16,  9.02it/s] 75%|███████▍  | 446/595 [00:54<00:16,  9.00it/s] 75%|███████▌  | 447/595 [00:55<00:16,  9.11it/s] 75%|███████▌  | 448/595 [00:55<00:16,  9.12it/s] 75%|███████▌  | 449/595 [00:55<00:16,  9.07it/s] 76%|███████▌  | 450/595 [00:55<00:15,  9.13it/s] 76%|███████▌  | 451/595 [00:55<00:15,  9.14it/s] 76%|███████▌  | 452/595 [00:55<00:15,  9.11it/s] 76%|███████▌  | 453/595 [00:55<00:15,  9.19it/s] 76%|███████▋  | 454/595 [00:55<00:15,  9.12it/s] 76%|███████▋  | 455/595 [00:55<00:15,  9.17it/s] 77%|███████▋  | 456/595 [00:56<00:15,  9.14it/s] 77%|███████▋  | 457/595 [00:56<00:14,  9.30it/s] 77%|███████▋  | 458/595 [00:56<00:14,  9.20it/s] 77%|███████▋  | 459/595 [00:56<00:14,  9.19it/s] 77%|███████▋  | 460/595 [00:56<00:14,  9.10it/s] 77%|███████▋  | 461/595 [00:56<00:14,  9.08it/s] 78%|███████▊  | 462/595 [00:56<00:14,  9.13it/s] 78%|███████▊  | 463/595 [00:56<00:14,  9.13it/s] 78%|███████▊  | 464/595 [00:56<00:14,  9.17it/s] 78%|███████▊  | 465/595 [00:57<00:14,  9.19it/s] 78%|███████▊  | 466/595 [00:57<00:14,  9.17it/s] 78%|███████▊  | 467/595 [00:57<00:13,  9.29it/s] 79%|███████▊  | 468/595 [00:57<00:13,  9.20it/s] 79%|███████▉  | 469/595 [00:57<00:13,  9.16it/s] 79%|███████▉  | 470/595 [00:57<00:13,  9.17it/s] 79%|███████▉  | 471/595 [00:57<00:13,  9.12it/s] 79%|███████▉  | 472/595 [00:57<00:13,  9.11it/s] 79%|███████▉  | 473/595 [00:57<00:13,  9.10it/s] 80%|███████▉  | 474/595 [00:57<00:13,  9.13it/s] 80%|███████▉  | 475/595 [00:58<00:13,  9.15it/s]                                                  80%|████████  | 476/595 [00:58<00:13,  9.15it/s][INFO|trainer.py:755] 2023-11-15 20:25:31,222 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:25:31,224 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:25:31,224 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:25:31,224 >>   Batch size = 8
{'eval_loss': 0.5589022040367126, 'eval_accuracy': 0.8, 'eval_micro_f1': 0.8000000000000002, 'eval_macro_f1': 0.7306627720444343, 'eval_runtime': 1.7343, 'eval_samples_per_second': 544.874, 'eval_steps_per_second': 68.614, 'epoch': 3.0}
{'loss': 0.2423, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 82.03it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 76.87it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 73.71it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 74.59it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 74.10it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 73.68it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 73.04it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 74.00it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 72.64it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 73.27it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 70.74it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 70.60it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 71.32it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 71.25it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [00:59<00:13,  9.15it/s]
100%|██████████| 119/119 [00:01<00:00, 71.25it/s][A
                                                 [A 80%|████████  | 477/595 [00:59<00:56,  2.07it/s] 80%|████████  | 478/595 [01:00<00:45,  2.56it/s] 81%|████████  | 479/595 [01:00<00:36,  3.14it/s] 81%|████████  | 480/595 [01:00<00:30,  3.82it/s] 81%|████████  | 481/595 [01:00<00:25,  4.54it/s] 81%|████████  | 482/595 [01:00<00:21,  5.29it/s] 81%|████████  | 483/595 [01:00<00:18,  6.04it/s] 81%|████████▏ | 484/595 [01:00<00:16,  6.64it/s] 82%|████████▏ | 485/595 [01:00<00:15,  7.22it/s] 82%|████████▏ | 486/595 [01:00<00:14,  7.69it/s] 82%|████████▏ | 487/595 [01:01<00:13,  8.05it/s] 82%|████████▏ | 488/595 [01:01<00:12,  8.36it/s] 82%|████████▏ | 489/595 [01:01<00:12,  8.52it/s] 82%|████████▏ | 490/595 [01:01<00:12,  8.65it/s] 83%|████████▎ | 491/595 [01:01<00:11,  8.83it/s] 83%|████████▎ | 492/595 [01:01<00:11,  8.85it/s] 83%|████████▎ | 493/595 [01:01<00:11,  9.06it/s] 83%|████████▎ | 494/595 [01:01<00:11,  9.01it/s] 83%|████████▎ | 495/595 [01:01<00:11,  9.02it/s] 83%|████████▎ | 496/595 [01:02<00:11,  8.99it/s] 84%|████████▎ | 497/595 [01:02<00:10,  8.98it/s] 84%|████████▎ | 498/595 [01:02<00:10,  9.04it/s] 84%|████████▍ | 499/595 [01:02<00:10,  9.01it/s] 84%|████████▍ | 500/595 [01:02<00:10,  9.07it/s] 84%|████████▍ | 501/595 [01:02<00:10,  9.05it/s] 84%|████████▍ | 502/595 [01:02<00:10,  9.06it/s] 85%|████████▍ | 503/595 [01:02<00:10,  9.06it/s] 85%|████████▍ | 504/595 [01:02<00:10,  9.08it/s] 85%|████████▍ | 505/595 [01:03<00:09,  9.04it/s] 85%|████████▌ | 506/595 [01:03<00:09,  9.00it/s] 85%|████████▌ | 507/595 [01:03<00:09,  9.03it/s] 85%|████████▌ | 508/595 [01:03<00:09,  8.99it/s] 86%|████████▌ | 509/595 [01:03<00:09,  8.94it/s] 86%|████████▌ | 510/595 [01:03<00:09,  9.10it/s] 86%|████████▌ | 511/595 [01:03<00:09,  9.07it/s] 86%|████████▌ | 512/595 [01:03<00:09,  9.00it/s] 86%|████████▌ | 513/595 [01:03<00:09,  9.03it/s] 86%|████████▋ | 514/595 [01:04<00:08,  9.00it/s] 87%|████████▋ | 515/595 [01:04<00:08,  8.98it/s] 87%|████████▋ | 516/595 [01:04<00:08,  8.98it/s] 87%|████████▋ | 517/595 [01:04<00:08,  9.08it/s] 87%|████████▋ | 518/595 [01:04<00:08,  9.04it/s] 87%|████████▋ | 519/595 [01:04<00:08,  9.03it/s] 87%|████████▋ | 520/595 [01:04<00:08,  9.01it/s] 88%|████████▊ | 521/595 [01:04<00:08,  9.04it/s] 88%|████████▊ | 522/595 [01:04<00:08,  9.03it/s] 88%|████████▊ | 523/595 [01:05<00:07,  9.02it/s] 88%|████████▊ | 524/595 [01:05<00:07,  9.03it/s] 88%|████████▊ | 525/595 [01:05<00:07,  9.01it/s] 88%|████████▊ | 526/595 [01:05<00:07,  9.00it/s] 89%|████████▊ | 527/595 [01:05<00:07,  8.98it/s] 89%|████████▊ | 528/595 [01:05<00:07,  8.92it/s] 89%|████████▉ | 529/595 [01:05<00:07,  8.93it/s] 89%|████████▉ | 530/595 [01:05<00:07,  8.93it/s] 89%|████████▉ | 531/595 [01:05<00:07,  8.92it/s] 89%|████████▉ | 532/595 [01:06<00:07,  8.85it/s] 90%|████████▉ | 533/595 [01:06<00:06,  8.86it/s] 90%|████████▉ | 534/595 [01:06<00:06,  8.92it/s] 90%|████████▉ | 535/595 [01:06<00:06,  8.91it/s] 90%|█████████ | 536/595 [01:06<00:06,  8.86it/s] 90%|█████████ | 537/595 [01:06<00:06,  8.84it/s] 90%|█████████ | 538/595 [01:06<00:06,  8.92it/s] 91%|█████████ | 539/595 [01:06<00:06,  8.85it/s] 91%|█████████ | 540/595 [01:06<00:06,  8.86it/s] 91%|█████████ | 541/595 [01:07<00:06,  8.89it/s] 91%|█████████ | 542/595 [01:07<00:05,  8.91it/s] 91%|█████████▏| 543/595 [01:07<00:05,  8.91it/s] 91%|█████████▏| 544/595 [01:07<00:05,  8.93it/s] 92%|█████████▏| 545/595 [01:07<00:05,  8.99it/s] 92%|█████████▏| 546/595 [01:07<00:05,  8.90it/s] 92%|█████████▏| 547/595 [01:07<00:05,  8.90it/s] 92%|█████████▏| 548/595 [01:07<00:05,  8.94it/s] 92%|█████████▏| 549/595 [01:07<00:05,  8.93it/s] 92%|█████████▏| 550/595 [01:08<00:05,  8.94it/s] 93%|█████████▎| 551/595 [01:08<00:05,  8.70it/s] 93%|█████████▎| 552/595 [01:08<00:04,  8.75it/s] 93%|█████████▎| 553/595 [01:08<00:04,  8.75it/s] 93%|█████████▎| 554/595 [01:08<00:04,  8.77it/s] 93%|█████████▎| 555/595 [01:08<00:04,  8.83it/s] 93%|█████████▎| 556/595 [01:08<00:04,  8.84it/s] 94%|█████████▎| 557/595 [01:08<00:04,  8.90it/s] 94%|█████████▍| 558/595 [01:08<00:04,  8.92it/s] 94%|█████████▍| 559/595 [01:09<00:04,  8.97it/s] 94%|█████████▍| 560/595 [01:09<00:03,  8.93it/s] 94%|█████████▍| 561/595 [01:09<00:03,  8.88it/s] 94%|█████████▍| 562/595 [01:09<00:03,  8.90it/s] 95%|█████████▍| 563/595 [01:09<00:03,  8.90it/s] 95%|█████████▍| 564/595 [01:09<00:03,  8.89it/s] 95%|█████████▍| 565/595 [01:09<00:03,  8.92it/s] 95%|█████████▌| 566/595 [01:09<00:03,  9.03it/s] 95%|█████████▌| 567/595 [01:09<00:03,  8.94it/s] 95%|█████████▌| 568/595 [01:10<00:03,  8.85it/s] 96%|█████████▌| 569/595 [01:10<00:02,  8.84it/s] 96%|█████████▌| 570/595 [01:10<00:02,  8.82it/s] 96%|█████████▌| 571/595 [01:10<00:02,  8.84it/s] 96%|█████████▌| 572/595 [01:10<00:02,  8.87it/s] 96%|█████████▋| 573/595 [01:10<00:02,  9.01it/s] 96%|█████████▋| 574/595 [01:10<00:02,  8.90it/s] 97%|█████████▋| 575/595 [01:10<00:02,  8.82it/s] 97%|█████████▋| 576/595 [01:10<00:02,  8.77it/s] 97%|█████████▋| 577/595 [01:11<00:02,  8.81it/s] 97%|█████████▋| 578/595 [01:11<00:01,  8.87it/s] 97%|█████████▋| 579/595 [01:11<00:01,  8.79it/s] 97%|█████████▋| 580/595 [01:11<00:01,  8.95it/s] 98%|█████████▊| 581/595 [01:11<00:01,  8.87it/s] 98%|█████████▊| 582/595 [01:11<00:01,  8.92it/s] 98%|█████████▊| 583/595 [01:11<00:01,  8.89it/s] 98%|█████████▊| 584/595 [01:11<00:01,  8.84it/s] 98%|█████████▊| 585/595 [01:12<00:01,  8.76it/s] 98%|█████████▊| 586/595 [01:12<00:01,  8.71it/s] 99%|█████████▊| 587/595 [01:12<00:00,  8.92it/s] 99%|█████████▉| 588/595 [01:12<00:00,  8.95it/s] 99%|█████████▉| 589/595 [01:12<00:00,  8.94it/s] 99%|█████████▉| 590/595 [01:12<00:00,  8.86it/s] 99%|█████████▉| 591/595 [01:12<00:00,  8.81it/s] 99%|█████████▉| 592/595 [01:12<00:00,  8.82it/s]100%|█████████▉| 593/595 [01:12<00:00,  8.80it/s]100%|█████████▉| 594/595 [01:13<00:00,  9.03it/s]                                                 100%|██████████| 595/595 [01:13<00:00,  9.03it/s][INFO|trainer.py:755] 2023-11-15 20:25:46,149 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:25:46,151 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:25:46,152 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:25:46,152 >>   Batch size = 8
{'eval_loss': 0.5890371799468994, 'eval_accuracy': 0.8031746031746032, 'eval_micro_f1': 0.8031746031746032, 'eval_macro_f1': 0.7323183460163115, 'eval_runtime': 1.6818, 'eval_samples_per_second': 561.889, 'eval_steps_per_second': 70.756, 'epoch': 4.0}
{'loss': 0.1777, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 81.01it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 72.71it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 69.40it/s][A
 28%|██▊       | 33/119 [00:00<00:01, 67.71it/s][A
 34%|███▎      | 40/119 [00:00<00:01, 68.04it/s][A
 39%|███▉      | 47/119 [00:00<00:01, 66.74it/s][A
 45%|████▌     | 54/119 [00:00<00:00, 67.45it/s][A
 51%|█████▏    | 61/119 [00:00<00:00, 67.93it/s][A
 57%|█████▋    | 68/119 [00:00<00:00, 68.19it/s][A
 63%|██████▎   | 75/119 [00:01<00:00, 67.62it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 67.27it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 68.51it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 67.83it/s][A
 88%|████████▊ | 105/119 [00:01<00:00, 69.30it/s][A
 94%|█████████▍| 112/119 [00:01<00:00, 67.64it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:14<00:00,  9.03it/s]
100%|██████████| 119/119 [00:01<00:00, 67.64it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 20:25:47,949 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:14<00:00,  9.03it/s]100%|██████████| 595/595 [01:14<00:00,  7.95it/s]
[INFO|trainer.py:2855] 2023-11-15 20:25:47,954 >> Saving model checkpoint to ./result/restaurant_bert-base-cased_adapter__seed2
[INFO|configuration_utils.py:460] 2023-11-15 20:25:47,957 >> Configuration saved in ./result/restaurant_bert-base-cased_adapter__seed2/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:25:49,179 >> Model weights saved in ./result/restaurant_bert-base-cased_adapter__seed2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:25:49,182 >> tokenizer config file saved in ./result/restaurant_bert-base-cased_adapter__seed2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:25:49,185 >> Special tokens file saved in ./result/restaurant_bert-base-cased_adapter__seed2/special_tokens_map.json
{'eval_loss': 0.6073454022407532, 'eval_accuracy': 0.8042328042328042, 'eval_micro_f1': 0.8042328042328042, 'eval_macro_f1': 0.7351610213211303, 'eval_runtime': 1.7926, 'eval_samples_per_second': 527.166, 'eval_steps_per_second': 66.384, 'epoch': 5.0}
{'train_runtime': 74.8708, 'train_samples_per_second': 252.235, 'train_steps_per_second': 7.947, 'train_loss': 0.38850170424004565, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3885
  train_runtime            = 0:01:14.87
  train_samples            =       3777
  train_samples_per_second =    252.235
  train_steps_per_second   =      7.947
11/15/2023 20:25:49 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:25:49,227 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:25:49,228 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:25:49,229 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:25:49,229 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  8%|▊         | 9/119 [00:00<00:01, 80.65it/s] 15%|█▌        | 18/119 [00:00<00:01, 75.51it/s] 22%|██▏       | 26/119 [00:00<00:01, 72.72it/s] 29%|██▊       | 34/119 [00:00<00:01, 74.19it/s] 35%|███▌      | 42/119 [00:00<00:01, 71.53it/s] 42%|████▏     | 50/119 [00:00<00:00, 70.88it/s] 49%|████▊     | 58/119 [00:00<00:00, 67.93it/s] 55%|█████▌    | 66/119 [00:00<00:00, 68.70it/s] 62%|██████▏   | 74/119 [00:01<00:00, 69.49it/s] 68%|██████▊   | 81/119 [00:01<00:00, 68.77it/s] 75%|███████▍  | 89/119 [00:01<00:00, 70.52it/s] 82%|████████▏ | 97/119 [00:01<00:00, 69.60it/s] 87%|████████▋ | 104/119 [00:01<00:00, 69.48it/s] 93%|█████████▎| 111/119 [00:01<00:00, 69.23it/s]100%|██████████| 119/119 [00:01<00:00, 71.38it/s]100%|██████████| 119/119 [00:01<00:00, 69.42it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8042
  eval_loss               =     0.6073
  eval_macro_f1           =     0.7352
  eval_micro_f1           =     0.8042
  eval_runtime            = 0:00:01.74
  eval_samples            =        945
  eval_samples_per_second =    542.103
  eval_steps_per_second   =     68.265
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▄▇███
wandb:                      eval/loss █▄▁▄▅▅
wandb:                  eval/macro_f1 ▁▃████
wandb:                  eval/micro_f1 ▁▄▇███
wandb:                   eval/runtime ▃▁▅▂█▅
wandb:        eval/samples_per_second ▆█▄▇▁▄
wandb:          eval/steps_per_second ▆█▄▇▁▄
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.80423
wandb:                      eval/loss 0.60735
wandb:                  eval/macro_f1 0.73516
wandb:                  eval/micro_f1 0.80423
wandb:                   eval/runtime 1.7432
wandb:        eval/samples_per_second 542.103
wandb:          eval/steps_per_second 68.265
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1777
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.3885
wandb:            train/train_runtime 74.8708
wandb: train/train_samples_per_second 252.235
wandb:   train/train_steps_per_second 7.947
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_202345-6ux48vr6
wandb: Find logs at: ./wandb/offline-run-20231115_202345-6ux48vr6/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2/runs/Nov15_20-26-02_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:26:02 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:26:02 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2/runs/Nov15_20-26-02_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  89%|████████▉ | 4191/4722 [00:00<00:00, 41698.08 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 40924.27 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:26:18,974 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:26:18,986 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:26:29,003 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:26:39,063 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:26:39,064 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:26:59,103 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:26:59,103 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:26:59,104 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:26:59,104 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:26:59,104 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:26:59,106 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:26:59,107 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 20:26:59,128 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:26:59,129 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:27:19,276 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 20:27:20,869 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:27:20,870 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 24021.35 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 23648.52 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 27526.08 examples/s]
11/15/2023 20:27:21 - INFO - __main__ - Sample 2272 of the training set: {'text': 'Carinthia cheese ravioli with wild mushrooms <SEP> Innovations are just as assured, from the simple Carinthia cheese ravioli with wild mushrooms to the caviar-topped sturgeon, beautifully matched with a bright green spinach-vodka sauce.', 'label': 0, 'input_ids': [102, 808, 2600, 4481, 30110, 29149, 23804, 12881, 30109, 190, 3530, 26391, 23172, 962, 9892, 1374, 15900, 220, 3008, 188, 22676, 30118, 422, 263, 111, 2177, 808, 2600, 4481, 30110, 29149, 23804, 12881, 30109, 190, 3530, 26391, 23172, 147, 111, 12289, 426, 30114, 579, 1623, 5633, 26809, 303, 110, 422, 25724, 3238, 1435, 30126, 7137, 190, 106, 8932, 3755, 4748, 339, 579, 5034, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 20:27:21 - INFO - __main__ - Sample 1436 of the training set: {'text': 'jazz singer <SEP> jazz singer had a nice voice + she made us all get up to dance to shake some cals to eat some more.', 'label': 0, 'input_ids': [102, 6837, 10207, 29137, 962, 9892, 1374, 6837, 10207, 29137, 883, 106, 18502, 9769, 473, 2281, 1827, 227, 355, 2744, 692, 147, 26282, 147, 19535, 1359, 693, 771, 30113, 147, 17692, 693, 475, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:27:21 - INFO - __main__ - Sample 1446 of the training set: {'text': 'iceberg <SEP> The bruscetta is a bit soggy, but the salads were fresh, included a nice mix of greens (not iceberg) all dishes are served piping hot from the kitchen.', 'label': 1, 'input_ids': [102, 6282, 3519, 962, 9892, 1374, 111, 25179, 974, 10750, 30110, 165, 106, 4626, 24461, 15970, 422, 563, 111, 1896, 5260, 267, 5893, 422, 1936, 106, 18502, 1877, 131, 3755, 30113, 145, 302, 6282, 3519, 546, 355, 19272, 220, 9334, 5879, 140, 6281, 263, 111, 5479, 6997, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:27:21 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:27:22,643 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:27:22,651 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:27:22,652 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 20:27:22,652 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:27:22,652 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:27:22,652 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:27:22,653 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:27:22,653 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 20:27:22,654 >>   Number of trainable parameters = 109,920,771
[INFO|integration_utils.py:716] 2023-11-15 20:27:22,655 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<14:31,  1.47s/it]  0%|          | 2/595 [00:01<06:34,  1.50it/s]  1%|          | 3/595 [00:01<04:03,  2.43it/s]  1%|          | 4/595 [00:01<02:52,  3.42it/s]  1%|          | 5/595 [00:01<02:13,  4.43it/s]  1%|          | 6/595 [00:02<01:48,  5.41it/s]  1%|          | 7/595 [00:02<01:34,  6.25it/s]  1%|▏         | 8/595 [00:02<01:24,  6.94it/s]  2%|▏         | 9/595 [00:02<01:17,  7.58it/s]  2%|▏         | 10/595 [00:02<01:13,  8.01it/s]  2%|▏         | 11/595 [00:02<01:10,  8.31it/s]  2%|▏         | 12/595 [00:02<01:07,  8.62it/s]  2%|▏         | 13/595 [00:02<01:06,  8.80it/s]  2%|▏         | 14/595 [00:02<01:05,  8.90it/s]  3%|▎         | 15/595 [00:02<01:04,  9.03it/s]  3%|▎         | 16/595 [00:03<01:03,  9.12it/s]  3%|▎         | 17/595 [00:03<01:03,  9.17it/s]  3%|▎         | 18/595 [00:03<01:02,  9.23it/s]  3%|▎         | 19/595 [00:03<01:03,  9.14it/s]  3%|▎         | 20/595 [00:03<01:02,  9.16it/s]  4%|▎         | 21/595 [00:03<01:02,  9.17it/s]  4%|▎         | 22/595 [00:03<01:02,  9.14it/s]  4%|▍         | 23/595 [00:03<01:01,  9.31it/s]  4%|▍         | 24/595 [00:03<01:01,  9.21it/s]  4%|▍         | 25/595 [00:04<01:01,  9.27it/s]  4%|▍         | 26/595 [00:04<01:01,  9.24it/s]  5%|▍         | 27/595 [00:04<01:01,  9.25it/s]  5%|▍         | 28/595 [00:04<01:01,  9.23it/s]  5%|▍         | 29/595 [00:04<01:01,  9.28it/s]  5%|▌         | 30/595 [00:04<01:00,  9.28it/s]  5%|▌         | 31/595 [00:04<01:00,  9.27it/s]  5%|▌         | 32/595 [00:04<01:00,  9.32it/s]  6%|▌         | 33/595 [00:04<01:00,  9.30it/s]  6%|▌         | 34/595 [00:05<01:00,  9.34it/s]  6%|▌         | 35/595 [00:05<01:00,  9.28it/s]  6%|▌         | 36/595 [00:05<01:00,  9.21it/s]  6%|▌         | 37/595 [00:05<01:00,  9.25it/s]  6%|▋         | 38/595 [00:05<01:00,  9.24it/s]  7%|▋         | 39/595 [00:05<01:00,  9.18it/s]  7%|▋         | 40/595 [00:05<01:00,  9.20it/s]  7%|▋         | 41/595 [00:05<00:59,  9.30it/s]  7%|▋         | 42/595 [00:05<00:59,  9.37it/s]  7%|▋         | 43/595 [00:05<00:59,  9.32it/s]  7%|▋         | 44/595 [00:06<00:59,  9.25it/s]  8%|▊         | 45/595 [00:06<00:59,  9.21it/s]  8%|▊         | 46/595 [00:06<00:59,  9.20it/s]  8%|▊         | 47/595 [00:06<00:59,  9.19it/s]  8%|▊         | 48/595 [00:06<00:58,  9.30it/s]  8%|▊         | 49/595 [00:06<00:59,  9.25it/s]  8%|▊         | 50/595 [00:06<00:58,  9.28it/s]  9%|▊         | 51/595 [00:06<00:58,  9.28it/s]  9%|▊         | 52/595 [00:06<00:58,  9.35it/s]  9%|▉         | 53/595 [00:07<00:58,  9.33it/s]  9%|▉         | 54/595 [00:07<00:58,  9.30it/s]  9%|▉         | 55/595 [00:07<00:58,  9.24it/s]  9%|▉         | 56/595 [00:07<00:58,  9.19it/s] 10%|▉         | 57/595 [00:07<00:58,  9.19it/s] 10%|▉         | 58/595 [00:07<00:58,  9.16it/s] 10%|▉         | 59/595 [00:07<00:58,  9.20it/s] 10%|█         | 60/595 [00:07<00:58,  9.21it/s] 10%|█         | 61/595 [00:07<00:57,  9.22it/s] 10%|█         | 62/595 [00:08<00:57,  9.20it/s] 11%|█         | 63/595 [00:08<00:58,  9.14it/s] 11%|█         | 64/595 [00:08<00:58,  9.12it/s] 11%|█         | 65/595 [00:08<00:57,  9.17it/s] 11%|█         | 66/595 [00:08<00:57,  9.27it/s] 11%|█▏        | 67/595 [00:08<00:57,  9.16it/s] 11%|█▏        | 68/595 [00:08<00:57,  9.18it/s] 12%|█▏        | 69/595 [00:08<00:57,  9.13it/s] 12%|█▏        | 70/595 [00:08<00:57,  9.14it/s] 12%|█▏        | 71/595 [00:09<00:56,  9.20it/s] 12%|█▏        | 72/595 [00:09<00:56,  9.26it/s] 12%|█▏        | 73/595 [00:09<00:56,  9.30it/s] 12%|█▏        | 74/595 [00:09<00:56,  9.24it/s] 13%|█▎        | 75/595 [00:09<00:56,  9.24it/s] 13%|█▎        | 76/595 [00:09<00:56,  9.20it/s] 13%|█▎        | 77/595 [00:09<00:55,  9.29it/s] 13%|█▎        | 78/595 [00:09<00:55,  9.24it/s] 13%|█▎        | 79/595 [00:09<00:56,  9.20it/s] 13%|█▎        | 80/595 [00:10<00:55,  9.21it/s] 14%|█▎        | 81/595 [00:10<00:55,  9.21it/s] 14%|█▍        | 82/595 [00:10<00:55,  9.28it/s] 14%|█▍        | 83/595 [00:10<00:55,  9.24it/s] 14%|█▍        | 84/595 [00:10<00:54,  9.34it/s] 14%|█▍        | 85/595 [00:10<00:55,  9.21it/s] 14%|█▍        | 86/595 [00:10<00:54,  9.27it/s] 15%|█▍        | 87/595 [00:10<00:55,  9.20it/s] 15%|█▍        | 88/595 [00:10<00:55,  9.20it/s] 15%|█▍        | 89/595 [00:10<00:55,  9.18it/s] 15%|█▌        | 90/595 [00:11<00:54,  9.20it/s] 15%|█▌        | 91/595 [00:11<00:54,  9.33it/s] 15%|█▌        | 92/595 [00:11<00:54,  9.28it/s] 16%|█▌        | 93/595 [00:11<00:54,  9.25it/s] 16%|█▌        | 94/595 [00:11<00:54,  9.24it/s] 16%|█▌        | 95/595 [00:11<00:54,  9.19it/s] 16%|█▌        | 96/595 [00:11<00:54,  9.15it/s] 16%|█▋        | 97/595 [00:11<00:54,  9.17it/s] 16%|█▋        | 98/595 [00:11<00:53,  9.29it/s] 17%|█▋        | 99/595 [00:12<00:53,  9.25it/s] 17%|█▋        | 100/595 [00:12<00:53,  9.19it/s] 17%|█▋        | 101/595 [00:12<00:54,  9.12it/s] 17%|█▋        | 102/595 [00:12<00:54,  9.11it/s] 17%|█▋        | 103/595 [00:12<00:53,  9.15it/s] 17%|█▋        | 104/595 [00:12<00:53,  9.20it/s] 18%|█▊        | 105/595 [00:12<00:52,  9.35it/s] 18%|█▊        | 106/595 [00:12<00:52,  9.30it/s] 18%|█▊        | 107/595 [00:12<00:53,  9.19it/s] 18%|█▊        | 108/595 [00:13<00:53,  9.17it/s] 18%|█▊        | 109/595 [00:13<00:52,  9.20it/s] 18%|█▊        | 110/595 [00:13<00:52,  9.18it/s] 19%|█▊        | 111/595 [00:13<00:52,  9.28it/s] 19%|█▉        | 112/595 [00:13<00:52,  9.29it/s] 19%|█▉        | 113/595 [00:13<00:52,  9.26it/s] 19%|█▉        | 114/595 [00:13<00:51,  9.26it/s] 19%|█▉        | 115/595 [00:13<00:52,  9.20it/s] 19%|█▉        | 116/595 [00:13<00:51,  9.27it/s] 20%|█▉        | 117/595 [00:14<00:51,  9.20it/s] 20%|█▉        | 118/595 [00:14<00:51,  9.26it/s]                                                  20%|██        | 119/595 [00:14<00:51,  9.26it/s][INFO|trainer.py:755] 2023-11-15 20:27:36,842 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:27:36,844 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:27:36,844 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:27:36,845 >>   Batch size = 8
{'loss': 0.697, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 83.24it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 76.77it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 74.27it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 74.89it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 73.45it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 73.02it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 72.35it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 71.95it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 71.87it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 71.41it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 72.39it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 70.08it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 70.92it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 71.26it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:15<00:51,  9.26it/s]
100%|██████████| 119/119 [00:01<00:00, 71.26it/s][A
                                                 [A 20%|██        | 120/595 [00:15<03:50,  2.06it/s] 20%|██        | 121/595 [00:16<03:06,  2.55it/s] 21%|██        | 122/595 [00:16<02:30,  3.15it/s] 21%|██        | 123/595 [00:16<02:03,  3.82it/s] 21%|██        | 124/595 [00:16<01:43,  4.56it/s] 21%|██        | 125/595 [00:16<01:28,  5.31it/s] 21%|██        | 126/595 [00:16<01:18,  6.00it/s] 21%|██▏       | 127/595 [00:16<01:10,  6.66it/s] 22%|██▏       | 128/595 [00:16<01:04,  7.18it/s] 22%|██▏       | 129/595 [00:16<01:00,  7.73it/s] 22%|██▏       | 130/595 [00:17<00:57,  8.06it/s] 22%|██▏       | 131/595 [00:17<00:55,  8.35it/s] 22%|██▏       | 132/595 [00:17<00:54,  8.54it/s] 22%|██▏       | 133/595 [00:17<00:53,  8.63it/s] 23%|██▎       | 134/595 [00:17<00:52,  8.80it/s] 23%|██▎       | 135/595 [00:17<00:51,  8.92it/s] 23%|██▎       | 136/595 [00:17<00:50,  9.03it/s] 23%|██▎       | 137/595 [00:17<00:50,  9.03it/s] 23%|██▎       | 138/595 [00:17<00:50,  9.01it/s] 23%|██▎       | 139/595 [00:18<00:50,  9.02it/s] 24%|██▎       | 140/595 [00:18<00:50,  9.05it/s] 24%|██▎       | 141/595 [00:18<00:50,  9.01it/s] 24%|██▍       | 142/595 [00:18<00:49,  9.08it/s] 24%|██▍       | 143/595 [00:18<00:49,  9.13it/s] 24%|██▍       | 144/595 [00:18<00:49,  9.17it/s] 24%|██▍       | 145/595 [00:18<00:49,  9.15it/s] 25%|██▍       | 146/595 [00:18<00:49,  9.06it/s] 25%|██▍       | 147/595 [00:18<00:48,  9.15it/s] 25%|██▍       | 148/595 [00:19<00:49,  9.06it/s] 25%|██▌       | 149/595 [00:19<00:49,  9.07it/s] 25%|██▌       | 150/595 [00:19<00:49,  9.06it/s] 25%|██▌       | 151/595 [00:19<00:49,  9.05it/s] 26%|██▌       | 152/595 [00:19<00:48,  9.09it/s] 26%|██▌       | 153/595 [00:19<00:48,  9.03it/s] 26%|██▌       | 154/595 [00:19<00:48,  9.10it/s] 26%|██▌       | 155/595 [00:19<00:48,  9.03it/s] 26%|██▌       | 156/595 [00:19<00:48,  9.04it/s] 26%|██▋       | 157/595 [00:20<00:48,  9.11it/s] 27%|██▋       | 158/595 [00:20<00:48,  9.09it/s] 27%|██▋       | 159/595 [00:20<00:48,  9.08it/s] 27%|██▋       | 160/595 [00:20<00:48,  9.05it/s] 27%|██▋       | 161/595 [00:20<00:47,  9.10it/s] 27%|██▋       | 162/595 [00:20<00:47,  9.03it/s] 27%|██▋       | 163/595 [00:20<00:47,  9.03it/s] 28%|██▊       | 164/595 [00:20<00:47,  9.09it/s] 28%|██▊       | 165/595 [00:20<00:47,  9.10it/s] 28%|██▊       | 166/595 [00:21<00:47,  9.05it/s] 28%|██▊       | 167/595 [00:21<00:47,  9.01it/s] 28%|██▊       | 168/595 [00:21<00:47,  8.99it/s] 28%|██▊       | 169/595 [00:21<00:47,  9.05it/s] 29%|██▊       | 170/595 [00:21<00:46,  9.11it/s] 29%|██▊       | 171/595 [00:21<00:46,  9.16it/s] 29%|██▉       | 172/595 [00:21<00:46,  9.15it/s] 29%|██▉       | 173/595 [00:21<00:46,  9.08it/s] 29%|██▉       | 174/595 [00:21<00:46,  9.06it/s] 29%|██▉       | 175/595 [00:22<00:46,  9.03it/s] 30%|██▉       | 176/595 [00:22<00:46,  9.01it/s] 30%|██▉       | 177/595 [00:22<00:46,  9.01it/s] 30%|██▉       | 178/595 [00:22<00:45,  9.10it/s] 30%|███       | 179/595 [00:22<00:45,  9.07it/s] 30%|███       | 180/595 [00:22<00:45,  9.06it/s] 30%|███       | 181/595 [00:22<00:45,  9.02it/s] 31%|███       | 182/595 [00:22<00:45,  9.08it/s] 31%|███       | 183/595 [00:22<00:45,  9.09it/s] 31%|███       | 184/595 [00:23<00:45,  9.07it/s] 31%|███       | 185/595 [00:23<00:44,  9.14it/s] 31%|███▏      | 186/595 [00:23<00:44,  9.15it/s] 31%|███▏      | 187/595 [00:23<00:44,  9.07it/s] 32%|███▏      | 188/595 [00:23<00:45,  9.01it/s] 32%|███▏      | 189/595 [00:23<00:44,  9.05it/s] 32%|███▏      | 190/595 [00:23<00:45,  9.00it/s] 32%|███▏      | 191/595 [00:23<00:44,  9.05it/s] 32%|███▏      | 192/595 [00:23<00:44,  9.09it/s] 32%|███▏      | 193/595 [00:24<00:44,  9.07it/s] 33%|███▎      | 194/595 [00:24<00:44,  9.01it/s] 33%|███▎      | 195/595 [00:24<00:44,  8.96it/s] 33%|███▎      | 196/595 [00:24<00:44,  9.03it/s] 33%|███▎      | 197/595 [00:24<00:44,  9.01it/s] 33%|███▎      | 198/595 [00:24<00:43,  9.07it/s] 33%|███▎      | 199/595 [00:24<00:43,  9.08it/s] 34%|███▎      | 200/595 [00:24<00:43,  9.07it/s] 34%|███▍      | 201/595 [00:24<00:43,  9.04it/s] 34%|███▍      | 202/595 [00:25<00:43,  9.07it/s] 34%|███▍      | 203/595 [00:25<00:43,  9.03it/s] 34%|███▍      | 204/595 [00:25<00:43,  8.95it/s] 34%|███▍      | 205/595 [00:25<00:43,  8.97it/s] 35%|███▍      | 206/595 [00:25<00:43,  9.01it/s] 35%|███▍      | 207/595 [00:25<00:43,  9.00it/s] 35%|███▍      | 208/595 [00:25<00:43,  8.91it/s] 35%|███▌      | 209/595 [00:25<00:43,  8.97it/s] 35%|███▌      | 210/595 [00:25<00:42,  9.03it/s] 35%|███▌      | 211/595 [00:26<00:42,  8.99it/s] 36%|███▌      | 212/595 [00:26<00:42,  9.04it/s] 36%|███▌      | 213/595 [00:26<00:42,  9.03it/s] 36%|███▌      | 214/595 [00:26<00:42,  8.96it/s] 36%|███▌      | 215/595 [00:26<00:42,  8.93it/s] 36%|███▋      | 216/595 [00:26<00:42,  8.91it/s] 36%|███▋      | 217/595 [00:26<00:42,  8.94it/s] 37%|███▋      | 218/595 [00:26<00:42,  8.91it/s] 37%|███▋      | 219/595 [00:26<00:42,  8.92it/s] 37%|███▋      | 220/595 [00:27<00:41,  9.01it/s] 37%|███▋      | 221/595 [00:27<00:41,  9.02it/s] 37%|███▋      | 222/595 [00:27<00:41,  8.98it/s] 37%|███▋      | 223/595 [00:27<00:41,  8.95it/s] 38%|███▊      | 224/595 [00:27<00:41,  8.99it/s] 38%|███▊      | 225/595 [00:27<00:41,  8.96it/s] 38%|███▊      | 226/595 [00:27<00:41,  8.93it/s] 38%|███▊      | 227/595 [00:27<00:41,  8.91it/s] 38%|███▊      | 228/595 [00:27<00:41,  8.92it/s] 38%|███▊      | 229/595 [00:28<00:41,  8.92it/s] 39%|███▊      | 230/595 [00:28<00:41,  8.85it/s] 39%|███▉      | 231/595 [00:28<00:40,  8.90it/s] 39%|███▉      | 232/595 [00:28<00:41,  8.82it/s] 39%|███▉      | 233/595 [00:28<00:40,  8.88it/s] 39%|███▉      | 234/595 [00:28<00:40,  8.88it/s] 39%|███▉      | 235/595 [00:28<00:40,  8.87it/s] 40%|███▉      | 236/595 [00:28<00:40,  8.77it/s] 40%|███▉      | 237/595 [00:28<00:40,  8.89it/s]                                                  40%|████      | 238/595 [00:28<00:40,  8.89it/s][INFO|trainer.py:755] 2023-11-15 20:27:51,651 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:27:51,653 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:27:51,654 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:27:51,654 >>   Batch size = 8
{'eval_loss': 0.6322436332702637, 'eval_accuracy': 0.746031746031746, 'eval_micro_f1': 0.746031746031746, 'eval_macro_f1': 0.6456855508842757, 'eval_runtime': 1.6869, 'eval_samples_per_second': 560.212, 'eval_steps_per_second': 70.545, 'epoch': 1.0}
{'loss': 0.4621, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 79.70it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 73.27it/s][A
 20%|██        | 24/119 [00:00<00:01, 69.58it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 71.75it/s][A
 34%|███▎      | 40/119 [00:00<00:01, 69.64it/s][A
 39%|███▉      | 47/119 [00:00<00:01, 69.27it/s][A
 46%|████▌     | 55/119 [00:00<00:00, 69.88it/s][A
 53%|█████▎    | 63/119 [00:00<00:00, 70.72it/s][A
 60%|█████▉    | 71/119 [00:01<00:00, 69.91it/s][A
 66%|██████▌   | 78/119 [00:01<00:00, 68.41it/s][A
 72%|███████▏  | 86/119 [00:01<00:00, 70.17it/s][A
 79%|███████▉  | 94/119 [00:01<00:00, 69.00it/s][A
 86%|████████▌ | 102/119 [00:01<00:00, 68.95it/s][A
 92%|█████████▏| 110/119 [00:01<00:00, 69.42it/s][A
 98%|█████████▊| 117/119 [00:01<00:00, 69.57it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:30<00:40,  8.89it/s]
100%|██████████| 119/119 [00:01<00:00, 69.57it/s][A
                                                 [A 40%|████      | 239/595 [00:30<02:57,  2.01it/s] 40%|████      | 240/595 [00:30<02:23,  2.48it/s] 41%|████      | 241/595 [00:31<01:56,  3.05it/s] 41%|████      | 242/595 [00:31<01:35,  3.71it/s] 41%|████      | 243/595 [00:31<01:19,  4.42it/s] 41%|████      | 244/595 [00:31<01:07,  5.22it/s] 41%|████      | 245/595 [00:31<00:59,  5.92it/s] 41%|████▏     | 246/595 [00:31<00:53,  6.52it/s] 42%|████▏     | 247/595 [00:31<00:49,  7.05it/s] 42%|████▏     | 248/595 [00:31<00:46,  7.49it/s] 42%|████▏     | 249/595 [00:31<00:44,  7.83it/s] 42%|████▏     | 250/595 [00:32<00:42,  8.13it/s] 42%|████▏     | 251/595 [00:32<00:40,  8.42it/s] 42%|████▏     | 252/595 [00:32<00:40,  8.56it/s] 43%|████▎     | 253/595 [00:32<00:39,  8.60it/s] 43%|████▎     | 254/595 [00:32<00:39,  8.65it/s] 43%|████▎     | 255/595 [00:32<00:39,  8.72it/s] 43%|████▎     | 256/595 [00:32<00:38,  8.77it/s] 43%|████▎     | 257/595 [00:32<00:38,  8.85it/s] 43%|████▎     | 258/595 [00:32<00:37,  9.01it/s] 44%|████▎     | 259/595 [00:33<00:37,  8.90it/s] 44%|████▎     | 260/595 [00:33<00:37,  8.85it/s] 44%|████▍     | 261/595 [00:33<00:37,  8.79it/s] 44%|████▍     | 262/595 [00:33<00:38,  8.76it/s] 44%|████▍     | 263/595 [00:33<00:37,  8.81it/s] 44%|████▍     | 264/595 [00:33<00:37,  8.86it/s] 45%|████▍     | 265/595 [00:33<00:36,  9.00it/s] 45%|████▍     | 266/595 [00:33<00:36,  8.96it/s] 45%|████▍     | 267/595 [00:34<00:37,  8.84it/s] 45%|████▌     | 268/595 [00:34<00:36,  8.88it/s] 45%|████▌     | 269/595 [00:34<00:37,  8.80it/s] 45%|████▌     | 270/595 [00:34<00:37,  8.78it/s] 46%|████▌     | 271/595 [00:34<00:37,  8.74it/s] 46%|████▌     | 272/595 [00:34<00:35,  9.00it/s] 46%|████▌     | 273/595 [00:34<00:36,  8.90it/s] 46%|████▌     | 274/595 [00:34<00:36,  8.84it/s] 46%|████▌     | 275/595 [00:34<00:36,  8.82it/s] 46%|████▋     | 276/595 [00:35<00:36,  8.80it/s] 47%|████▋     | 277/595 [00:35<00:36,  8.80it/s] 47%|████▋     | 278/595 [00:35<00:35,  8.85it/s] 47%|████▋     | 279/595 [00:35<00:35,  8.95it/s] 47%|████▋     | 280/595 [00:35<00:35,  8.90it/s] 47%|████▋     | 281/595 [00:35<00:35,  8.88it/s] 47%|████▋     | 282/595 [00:35<00:35,  8.71it/s] 48%|████▊     | 283/595 [00:35<00:35,  8.72it/s] 48%|████▊     | 284/595 [00:35<00:35,  8.75it/s] 48%|████▊     | 285/595 [00:36<00:35,  8.66it/s] 48%|████▊     | 286/595 [00:36<00:35,  8.83it/s] 48%|████▊     | 287/595 [00:36<00:34,  8.82it/s] 48%|████▊     | 288/595 [00:36<00:34,  8.81it/s] 49%|████▊     | 289/595 [00:36<00:34,  8.77it/s] 49%|████▊     | 290/595 [00:36<00:34,  8.79it/s] 49%|████▉     | 291/595 [00:36<00:34,  8.88it/s] 49%|████▉     | 292/595 [00:36<00:34,  8.87it/s] 49%|████▉     | 293/595 [00:36<00:33,  8.92it/s] 49%|████▉     | 294/595 [00:37<00:33,  8.86it/s] 50%|████▉     | 295/595 [00:37<00:34,  8.82it/s] 50%|████▉     | 296/595 [00:37<00:34,  8.74it/s] 50%|████▉     | 297/595 [00:37<00:34,  8.73it/s] 50%|█████     | 298/595 [00:37<00:33,  8.75it/s] 50%|█████     | 299/595 [00:37<00:33,  8.78it/s] 50%|█████     | 300/595 [00:37<00:33,  8.90it/s] 51%|█████     | 301/595 [00:37<00:33,  8.82it/s] 51%|█████     | 302/595 [00:37<00:33,  8.74it/s] 51%|█████     | 303/595 [00:38<00:33,  8.71it/s] 51%|█████     | 304/595 [00:38<00:33,  8.70it/s] 51%|█████▏    | 305/595 [00:38<00:33,  8.78it/s] 51%|█████▏    | 306/595 [00:38<00:32,  8.80it/s] 52%|█████▏    | 307/595 [00:38<00:32,  8.85it/s] 52%|█████▏    | 308/595 [00:38<00:32,  8.83it/s] 52%|█████▏    | 309/595 [00:38<00:32,  8.78it/s] 52%|█████▏    | 310/595 [00:38<00:32,  8.72it/s] 52%|█████▏    | 311/595 [00:39<00:32,  8.80it/s] 52%|█████▏    | 312/595 [00:39<00:31,  8.85it/s] 53%|█████▎    | 313/595 [00:39<00:31,  8.90it/s] 53%|█████▎    | 314/595 [00:39<00:31,  8.99it/s] 53%|█████▎    | 315/595 [00:39<00:31,  8.94it/s] 53%|█████▎    | 316/595 [00:39<00:31,  8.87it/s] 53%|█████▎    | 317/595 [00:39<00:31,  8.81it/s] 53%|█████▎    | 318/595 [00:39<00:31,  8.75it/s] 54%|█████▎    | 319/595 [00:39<00:31,  8.81it/s] 54%|█████▍    | 320/595 [00:40<00:31,  8.86it/s] 54%|█████▍    | 321/595 [00:40<00:30,  9.02it/s] 54%|█████▍    | 322/595 [00:40<00:30,  9.02it/s] 54%|█████▍    | 323/595 [00:40<00:30,  9.02it/s] 54%|█████▍    | 324/595 [00:40<00:30,  8.92it/s] 55%|█████▍    | 325/595 [00:40<00:30,  8.96it/s] 55%|█████▍    | 326/595 [00:40<00:30,  8.89it/s] 55%|█████▍    | 327/595 [00:40<00:29,  8.95it/s] 55%|█████▌    | 328/595 [00:40<00:29,  9.00it/s] 55%|█████▌    | 329/595 [00:41<00:29,  8.98it/s] 55%|█████▌    | 330/595 [00:41<00:29,  8.88it/s] 56%|█████▌    | 331/595 [00:41<00:29,  8.88it/s] 56%|█████▌    | 332/595 [00:41<00:29,  8.91it/s] 56%|█████▌    | 333/595 [00:41<00:29,  8.90it/s] 56%|█████▌    | 334/595 [00:41<00:29,  8.93it/s] 56%|█████▋    | 335/595 [00:41<00:28,  8.98it/s] 56%|█████▋    | 336/595 [00:41<00:28,  9.01it/s] 57%|█████▋    | 337/595 [00:41<00:28,  8.98it/s] 57%|█████▋    | 338/595 [00:42<00:28,  8.88it/s] 57%|█████▋    | 339/595 [00:42<00:28,  8.87it/s] 57%|█████▋    | 340/595 [00:42<00:28,  8.83it/s] 57%|█████▋    | 341/595 [00:42<00:28,  8.86it/s] 57%|█████▋    | 342/595 [00:42<00:28,  8.87it/s] 58%|█████▊    | 343/595 [00:42<00:28,  8.92it/s] 58%|█████▊    | 344/595 [00:42<00:28,  8.86it/s] 58%|█████▊    | 345/595 [00:42<00:28,  8.85it/s] 58%|█████▊    | 346/595 [00:42<00:27,  8.90it/s] 58%|█████▊    | 347/595 [00:43<00:28,  8.83it/s] 58%|█████▊    | 348/595 [00:43<00:27,  8.86it/s] 59%|█████▊    | 349/595 [00:43<00:27,  8.93it/s] 59%|█████▉    | 350/595 [00:43<00:27,  8.94it/s] 59%|█████▉    | 351/595 [00:43<00:27,  8.86it/s] 59%|█████▉    | 352/595 [00:43<00:27,  8.85it/s] 59%|█████▉    | 353/595 [00:43<00:27,  8.95it/s] 59%|█████▉    | 354/595 [00:43<00:27,  8.86it/s] 60%|█████▉    | 355/595 [00:43<00:27,  8.88it/s] 60%|█████▉    | 356/595 [00:44<00:26,  8.93it/s]                                                  60%|██████    | 357/595 [00:44<00:26,  8.93it/s][INFO|trainer.py:755] 2023-11-15 20:28:06,751 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:28:06,753 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:28:06,753 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:28:06,754 >>   Batch size = 8
{'eval_loss': 0.5304182171821594, 'eval_accuracy': 0.7851851851851852, 'eval_micro_f1': 0.7851851851851852, 'eval_macro_f1': 0.7079797932633364, 'eval_runtime': 1.7393, 'eval_samples_per_second': 543.323, 'eval_steps_per_second': 68.418, 'epoch': 2.0}
{'loss': 0.3123, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 83.60it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 72.50it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 72.88it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 68.70it/s][A
 34%|███▍      | 41/119 [00:00<00:01, 67.79it/s][A
 40%|████      | 48/119 [00:00<00:01, 68.30it/s][A
 46%|████▌     | 55/119 [00:00<00:00, 67.47it/s][A
 53%|█████▎    | 63/119 [00:00<00:00, 68.47it/s][A
 59%|█████▉    | 70/119 [00:01<00:00, 68.15it/s][A
 66%|██████▌   | 78/119 [00:01<00:00, 68.78it/s][A
 71%|███████▏  | 85/119 [00:01<00:00, 67.51it/s][A
 77%|███████▋  | 92/119 [00:01<00:00, 66.31it/s][A
 83%|████████▎ | 99/119 [00:01<00:00, 66.28it/s][A
 90%|████████▉ | 107/119 [00:01<00:00, 67.38it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 66.66it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:45<00:26,  8.93it/s]
100%|██████████| 119/119 [00:01<00:00, 66.66it/s][A
                                                 [A 60%|██████    | 358/595 [00:46<02:01,  1.96it/s] 60%|██████    | 359/595 [00:46<01:37,  2.43it/s] 61%|██████    | 360/595 [00:46<01:18,  3.00it/s] 61%|██████    | 361/595 [00:46<01:04,  3.64it/s] 61%|██████    | 362/595 [00:46<00:53,  4.37it/s] 61%|██████    | 363/595 [00:46<00:45,  5.09it/s] 61%|██████    | 364/595 [00:46<00:39,  5.81it/s] 61%|██████▏   | 365/595 [00:46<00:35,  6.45it/s] 62%|██████▏   | 366/595 [00:46<00:32,  7.01it/s] 62%|██████▏   | 367/595 [00:47<00:30,  7.48it/s] 62%|██████▏   | 368/595 [00:47<00:29,  7.76it/s] 62%|██████▏   | 369/595 [00:47<00:27,  8.24it/s] 62%|██████▏   | 370/595 [00:47<00:27,  8.29it/s] 62%|██████▏   | 371/595 [00:47<00:26,  8.45it/s] 63%|██████▎   | 372/595 [00:47<00:25,  8.58it/s] 63%|██████▎   | 373/595 [00:47<00:25,  8.62it/s] 63%|██████▎   | 374/595 [00:47<00:25,  8.69it/s] 63%|██████▎   | 375/595 [00:47<00:25,  8.61it/s] 63%|██████▎   | 376/595 [00:48<00:24,  8.85it/s] 63%|██████▎   | 377/595 [00:48<00:24,  8.72it/s] 64%|██████▎   | 378/595 [00:48<00:24,  8.72it/s] 64%|██████▎   | 379/595 [00:48<00:24,  8.77it/s] 64%|██████▍   | 380/595 [00:48<00:24,  8.75it/s] 64%|██████▍   | 381/595 [00:48<00:24,  8.83it/s] 64%|██████▍   | 382/595 [00:48<00:24,  8.73it/s] 64%|██████▍   | 383/595 [00:48<00:23,  8.98it/s] 65%|██████▍   | 384/595 [00:48<00:23,  8.87it/s] 65%|██████▍   | 385/595 [00:49<00:23,  8.89it/s] 65%|██████▍   | 386/595 [00:49<00:23,  8.88it/s] 65%|██████▌   | 387/595 [00:49<00:23,  8.89it/s] 65%|██████▌   | 388/595 [00:49<00:23,  8.90it/s] 65%|██████▌   | 389/595 [00:49<00:23,  8.79it/s] 66%|██████▌   | 390/595 [00:49<00:22,  8.98it/s] 66%|██████▌   | 391/595 [00:49<00:23,  8.85it/s] 66%|██████▌   | 392/595 [00:49<00:22,  8.87it/s] 66%|██████▌   | 393/595 [00:49<00:22,  8.89it/s] 66%|██████▌   | 394/595 [00:50<00:22,  8.86it/s] 66%|██████▋   | 395/595 [00:50<00:22,  8.86it/s] 67%|██████▋   | 396/595 [00:50<00:22,  8.85it/s] 67%|██████▋   | 397/595 [00:50<00:22,  8.98it/s] 67%|██████▋   | 398/595 [00:50<00:22,  8.84it/s] 67%|██████▋   | 399/595 [00:50<00:22,  8.84it/s] 67%|██████▋   | 400/595 [00:50<00:22,  8.82it/s] 67%|██████▋   | 401/595 [00:50<00:22,  8.79it/s] 68%|██████▊   | 402/595 [00:50<00:21,  8.79it/s] 68%|██████▊   | 403/595 [00:51<00:22,  8.71it/s] 68%|██████▊   | 404/595 [00:51<00:21,  8.96it/s] 68%|██████▊   | 405/595 [00:51<00:21,  8.82it/s] 68%|██████▊   | 406/595 [00:51<00:21,  8.78it/s] 68%|██████▊   | 407/595 [00:51<00:21,  8.78it/s] 69%|██████▊   | 408/595 [00:51<00:21,  8.79it/s] 69%|██████▊   | 409/595 [00:51<00:21,  8.82it/s] 69%|██████▉   | 410/595 [00:51<00:21,  8.74it/s] 69%|██████▉   | 411/595 [00:51<00:20,  8.93it/s] 69%|██████▉   | 412/595 [00:52<00:20,  8.75it/s] 69%|██████▉   | 413/595 [00:52<00:20,  8.76it/s] 70%|██████▉   | 414/595 [00:52<00:20,  8.82it/s] 70%|██████▉   | 415/595 [00:52<00:20,  8.79it/s] 70%|██████▉   | 416/595 [00:52<00:20,  8.80it/s] 70%|███████   | 417/595 [00:52<00:20,  8.81it/s] 70%|███████   | 418/595 [00:52<00:19,  8.94it/s] 70%|███████   | 419/595 [00:52<00:19,  8.83it/s] 71%|███████   | 420/595 [00:53<00:19,  8.84it/s] 71%|███████   | 421/595 [00:53<00:19,  8.82it/s] 71%|███████   | 422/595 [00:53<00:19,  8.84it/s] 71%|███████   | 423/595 [00:53<00:19,  8.81it/s] 71%|███████▏  | 424/595 [00:53<00:19,  8.76it/s] 71%|███████▏  | 425/595 [00:53<00:19,  8.88it/s] 72%|███████▏  | 426/595 [00:53<00:19,  8.81it/s] 72%|███████▏  | 427/595 [00:53<00:19,  8.79it/s] 72%|███████▏  | 428/595 [00:53<00:18,  8.81it/s] 72%|███████▏  | 429/595 [00:54<00:18,  8.83it/s] 72%|███████▏  | 430/595 [00:54<00:18,  8.88it/s] 72%|███████▏  | 431/595 [00:54<00:18,  8.83it/s] 73%|███████▎  | 432/595 [00:54<00:18,  9.01it/s] 73%|███████▎  | 433/595 [00:54<00:18,  8.87it/s] 73%|███████▎  | 434/595 [00:54<00:18,  8.89it/s] 73%|███████▎  | 435/595 [00:54<00:18,  8.87it/s] 73%|███████▎  | 436/595 [00:54<00:17,  8.94it/s] 73%|███████▎  | 437/595 [00:54<00:17,  8.93it/s] 74%|███████▎  | 438/595 [00:55<00:17,  8.87it/s] 74%|███████▍  | 440/595 [00:55<00:16,  9.57it/s] 74%|███████▍  | 442/595 [00:55<00:15, 10.07it/s] 75%|███████▍  | 444/595 [00:55<00:14, 10.37it/s] 75%|███████▍  | 446/595 [00:55<00:14, 10.17it/s] 75%|███████▌  | 448/595 [00:56<00:15,  9.65it/s] 75%|███████▌  | 449/595 [00:56<00:15,  9.54it/s] 76%|███████▌  | 450/595 [00:56<00:15,  9.35it/s] 76%|███████▌  | 451/595 [00:56<00:15,  9.22it/s] 76%|███████▌  | 452/595 [00:56<00:15,  9.12it/s] 76%|███████▌  | 453/595 [00:56<00:15,  9.09it/s] 76%|███████▋  | 454/595 [00:56<00:15,  9.04it/s] 76%|███████▋  | 455/595 [00:56<00:15,  8.95it/s] 77%|███████▋  | 456/595 [00:56<00:15,  9.05it/s] 77%|███████▋  | 457/595 [00:57<00:15,  8.94it/s] 77%|███████▋  | 458/595 [00:57<00:15,  8.90it/s] 77%|███████▋  | 459/595 [00:57<00:15,  8.95it/s] 77%|███████▋  | 460/595 [00:57<00:15,  8.94it/s] 77%|███████▋  | 461/595 [00:57<00:14,  8.94it/s] 78%|███████▊  | 462/595 [00:57<00:14,  8.94it/s] 78%|███████▊  | 463/595 [00:57<00:14,  9.00it/s] 78%|███████▊  | 464/595 [00:57<00:14,  8.99it/s] 78%|███████▊  | 465/595 [00:57<00:14,  8.87it/s] 78%|███████▊  | 466/595 [00:58<00:14,  8.86it/s] 78%|███████▊  | 467/595 [00:58<00:14,  8.99it/s] 79%|███████▊  | 468/595 [00:58<00:14,  8.91it/s] 79%|███████▉  | 469/595 [00:58<00:14,  8.91it/s] 79%|███████▉  | 470/595 [00:58<00:13,  8.96it/s] 79%|███████▉  | 471/595 [00:58<00:13,  8.92it/s] 79%|███████▉  | 472/595 [00:58<00:13,  8.94it/s] 79%|███████▉  | 473/595 [00:58<00:13,  8.80it/s] 80%|███████▉  | 474/595 [00:58<00:13,  9.04it/s] 80%|███████▉  | 475/595 [00:59<00:13,  9.01it/s]                                                  80%|████████  | 476/595 [00:59<00:13,  9.01it/s][INFO|trainer.py:755] 2023-11-15 20:28:21,768 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:28:21,770 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:28:21,771 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:28:21,771 >>   Batch size = 8
{'eval_loss': 0.5983103513717651, 'eval_accuracy': 0.8021164021164021, 'eval_micro_f1': 0.8021164021164021, 'eval_macro_f1': 0.7322820037105752, 'eval_runtime': 1.7923, 'eval_samples_per_second': 527.264, 'eval_steps_per_second': 66.396, 'epoch': 3.0}
{'loss': 0.2101, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 80.61it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 78.99it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 73.45it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 73.03it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 71.88it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 72.00it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 71.92it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 69.83it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 72.29it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 70.28it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 69.54it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 70.01it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 70.94it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 71.49it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [01:00<00:13,  9.01it/s]
100%|██████████| 119/119 [00:01<00:00, 71.49it/s][A
                                                 [A 80%|████████  | 477/595 [01:00<00:57,  2.04it/s] 80%|████████  | 478/595 [01:01<00:46,  2.52it/s] 81%|████████  | 479/595 [01:01<00:37,  3.09it/s] 81%|████████  | 480/595 [01:01<00:30,  3.76it/s] 81%|████████  | 481/595 [01:01<00:25,  4.48it/s] 81%|████████  | 482/595 [01:01<00:21,  5.21it/s] 81%|████████  | 483/595 [01:01<00:18,  5.95it/s] 81%|████████▏ | 484/595 [01:01<00:16,  6.61it/s] 82%|████████▏ | 485/595 [01:01<00:15,  7.17it/s] 82%|████████▏ | 486/595 [01:01<00:14,  7.58it/s] 82%|████████▏ | 487/595 [01:02<00:13,  7.97it/s] 82%|████████▏ | 488/595 [01:02<00:12,  8.29it/s] 82%|████████▏ | 489/595 [01:02<00:12,  8.42it/s] 82%|████████▏ | 490/595 [01:02<00:12,  8.55it/s] 83%|████████▎ | 491/595 [01:02<00:12,  8.66it/s] 83%|████████▎ | 492/595 [01:02<00:11,  8.75it/s] 83%|████████▎ | 493/595 [01:02<00:11,  8.76it/s] 83%|████████▎ | 494/595 [01:02<00:11,  8.78it/s] 83%|████████▎ | 495/595 [01:02<00:11,  8.97it/s] 83%|████████▎ | 496/595 [01:03<00:11,  8.90it/s] 84%|████████▎ | 497/595 [01:03<00:11,  8.87it/s] 84%|████████▎ | 498/595 [01:03<00:10,  8.89it/s] 84%|████████▍ | 499/595 [01:03<00:10,  8.89it/s] 84%|████████▍ | 500/595 [01:03<00:10,  8.92it/s] 84%|████████▍ | 501/595 [01:03<00:10,  8.89it/s] 84%|████████▍ | 502/595 [01:03<00:10,  9.05it/s] 85%|████████▍ | 503/595 [01:03<00:10,  9.07it/s] 85%|████████▍ | 504/595 [01:03<00:10,  9.00it/s] 85%|████████▍ | 505/595 [01:04<00:10,  8.96it/s] 85%|████████▌ | 506/595 [01:04<00:09,  9.01it/s] 85%|████████▌ | 507/595 [01:04<00:09,  8.88it/s] 85%|████████▌ | 508/595 [01:04<00:09,  8.92it/s] 86%|████████▌ | 509/595 [01:04<00:09,  8.88it/s] 86%|████████▌ | 510/595 [01:04<00:09,  8.83it/s] 86%|████████▌ | 511/595 [01:04<00:09,  8.83it/s] 86%|████████▌ | 512/595 [01:04<00:09,  8.86it/s] 86%|████████▌ | 513/595 [01:04<00:09,  8.97it/s] 86%|████████▋ | 514/595 [01:05<00:09,  8.93it/s] 87%|████████▋ | 515/595 [01:05<00:09,  8.89it/s] 87%|████████▋ | 516/595 [01:05<00:08,  8.90it/s] 87%|████████▋ | 517/595 [01:05<00:08,  8.89it/s] 87%|████████▋ | 518/595 [01:05<00:08,  8.90it/s] 87%|████████▋ | 519/595 [01:05<00:08,  8.78it/s] 87%|████████▋ | 520/595 [01:05<00:08,  9.03it/s] 88%|████████▊ | 521/595 [01:05<00:08,  8.94it/s] 88%|████████▊ | 522/595 [01:05<00:08,  8.88it/s] 88%|████████▊ | 523/595 [01:06<00:08,  8.84it/s] 88%|████████▊ | 524/595 [01:06<00:07,  8.94it/s] 88%|████████▊ | 525/595 [01:06<00:07,  8.92it/s] 88%|████████▊ | 526/595 [01:06<00:07,  8.96it/s] 89%|████████▊ | 527/595 [01:06<00:07,  8.94it/s] 89%|████████▊ | 528/595 [01:06<00:07,  8.96it/s] 89%|████████▉ | 529/595 [01:06<00:07,  8.85it/s] 89%|████████▉ | 530/595 [01:06<00:07,  8.91it/s] 89%|████████▉ | 531/595 [01:06<00:07,  9.09it/s] 89%|████████▉ | 532/595 [01:07<00:07,  8.93it/s] 90%|████████▉ | 533/595 [01:07<00:06,  8.89it/s] 90%|████████▉ | 534/595 [01:07<00:06,  8.94it/s] 90%|████████▉ | 535/595 [01:07<00:06,  8.85it/s] 90%|█████████ | 536/595 [01:07<00:06,  8.88it/s] 90%|█████████ | 537/595 [01:07<00:06,  8.89it/s] 90%|█████████ | 538/595 [01:07<00:06,  9.10it/s] 91%|█████████ | 539/595 [01:07<00:06,  8.98it/s] 91%|█████████ | 540/595 [01:07<00:06,  8.94it/s] 91%|█████████ | 541/595 [01:08<00:06,  8.89it/s] 91%|█████████ | 542/595 [01:08<00:05,  8.89it/s] 91%|█████████▏| 543/595 [01:08<00:05,  8.84it/s] 91%|█████████▏| 544/595 [01:08<00:05,  8.77it/s] 92%|█████████▏| 545/595 [01:08<00:05,  9.00it/s] 92%|█████████▏| 546/595 [01:08<00:05,  8.98it/s] 92%|█████████▏| 547/595 [01:08<00:05,  8.84it/s] 92%|█████████▏| 548/595 [01:08<00:05,  8.87it/s] 92%|█████████▏| 549/595 [01:09<00:05,  8.95it/s] 92%|█████████▏| 550/595 [01:09<00:05,  8.77it/s] 93%|█████████▎| 551/595 [01:09<00:04,  8.83it/s] 93%|█████████▎| 552/595 [01:09<00:04,  8.90it/s] 93%|█████████▎| 553/595 [01:09<00:04,  8.90it/s] 93%|█████████▎| 554/595 [01:09<00:04,  8.89it/s] 93%|█████████▎| 555/595 [01:09<00:04,  8.88it/s] 93%|█████████▎| 556/595 [01:09<00:04,  9.08it/s] 94%|█████████▎| 557/595 [01:09<00:04,  8.94it/s] 94%|█████████▍| 558/595 [01:10<00:04,  8.86it/s] 94%|█████████▍| 559/595 [01:10<00:04,  8.92it/s] 94%|█████████▍| 560/595 [01:10<00:03,  8.91it/s] 94%|█████████▍| 561/595 [01:10<00:03,  8.91it/s] 94%|█████████▍| 562/595 [01:10<00:03,  8.90it/s] 95%|█████████▍| 563/595 [01:10<00:03,  9.06it/s] 95%|█████████▍| 564/595 [01:10<00:03,  8.94it/s] 95%|█████████▍| 565/595 [01:10<00:03,  8.89it/s] 95%|█████████▌| 566/595 [01:10<00:03,  8.89it/s] 95%|█████████▌| 567/595 [01:11<00:03,  8.98it/s] 95%|█████████▌| 568/595 [01:11<00:03,  8.88it/s] 96%|█████████▌| 569/595 [01:11<00:02,  8.96it/s] 96%|█████████▌| 570/595 [01:11<00:02,  8.93it/s] 96%|█████████▌| 571/595 [01:11<00:02,  8.93it/s] 96%|█████████▌| 572/595 [01:11<00:02,  8.86it/s] 96%|█████████▋| 573/595 [01:11<00:02,  8.83it/s] 96%|█████████▋| 574/595 [01:11<00:02,  8.94it/s] 97%|█████████▋| 575/595 [01:11<00:02,  8.84it/s] 97%|█████████▋| 576/595 [01:12<00:02,  8.83it/s] 97%|█████████▋| 577/595 [01:12<00:02,  8.87it/s] 97%|█████████▋| 578/595 [01:12<00:01,  8.94it/s] 97%|█████████▋| 579/595 [01:12<00:01,  8.89it/s] 97%|█████████▋| 580/595 [01:12<00:01,  8.95it/s] 98%|█████████▊| 581/595 [01:12<00:01,  9.04it/s] 98%|█████████▊| 582/595 [01:12<00:01,  9.04it/s] 98%|█████████▊| 583/595 [01:12<00:01,  8.89it/s] 98%|█████████▊| 584/595 [01:12<00:01,  8.88it/s] 98%|█████████▊| 585/595 [01:13<00:01,  8.99it/s] 98%|█████████▊| 586/595 [01:13<00:01,  8.91it/s] 99%|█████████▊| 587/595 [01:13<00:00,  8.89it/s] 99%|█████████▉| 588/595 [01:13<00:00,  8.93it/s] 99%|█████████▉| 589/595 [01:13<00:00,  8.87it/s] 99%|█████████▉| 590/595 [01:13<00:00,  8.86it/s] 99%|█████████▉| 591/595 [01:13<00:00,  8.81it/s] 99%|█████████▉| 592/595 [01:13<00:00,  9.00it/s]100%|█████████▉| 593/595 [01:13<00:00,  8.89it/s]100%|█████████▉| 594/595 [01:14<00:00,  8.85it/s]                                                 100%|██████████| 595/595 [01:14<00:00,  8.85it/s][INFO|trainer.py:755] 2023-11-15 20:28:36,757 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:28:36,759 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:28:36,759 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:28:36,760 >>   Batch size = 8
{'eval_loss': 0.5981378555297852, 'eval_accuracy': 0.7957671957671958, 'eval_micro_f1': 0.7957671957671958, 'eval_macro_f1': 0.724557247276703, 'eval_runtime': 1.7083, 'eval_samples_per_second': 553.171, 'eval_steps_per_second': 69.659, 'epoch': 4.0}
{'loss': 0.1547, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 87.82it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 75.81it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 72.21it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 70.96it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 70.92it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 71.05it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 68.22it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 71.37it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 70.07it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 68.81it/s][A
 75%|███████▍  | 89/119 [00:01<00:00, 68.16it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 70.53it/s][A
 88%|████████▊ | 105/119 [00:01<00:00, 69.58it/s][A
 94%|█████████▍| 112/119 [00:01<00:00, 68.83it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:15<00:00,  8.85it/s]
100%|██████████| 119/119 [00:01<00:00, 68.83it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 20:28:38,510 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:15<00:00,  8.85it/s]100%|██████████| 595/595 [01:15<00:00,  7.84it/s]
[INFO|trainer.py:2855] 2023-11-15 20:28:38,513 >> Saving model checkpoint to ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2
[INFO|configuration_utils.py:460] 2023-11-15 20:28:38,516 >> Configuration saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:28:39,958 >> Model weights saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:28:39,961 >> tokenizer config file saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:28:39,963 >> Special tokens file saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed2/special_tokens_map.json
{'eval_loss': 0.6275898218154907, 'eval_accuracy': 0.7947089947089947, 'eval_micro_f1': 0.7947089947089947, 'eval_macro_f1': 0.7221617645745931, 'eval_runtime': 1.7452, 'eval_samples_per_second': 541.478, 'eval_steps_per_second': 68.186, 'epoch': 5.0}
{'train_runtime': 75.8558, 'train_samples_per_second': 248.959, 'train_steps_per_second': 7.844, 'train_loss': 0.36723525103400734, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3672
  train_runtime            = 0:01:15.85
  train_samples            =       3777
  train_samples_per_second =    248.959
  train_steps_per_second   =      7.844
11/15/2023 20:28:40 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:28:40,009 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:28:40,011 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:28:40,011 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:28:40,012 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  8%|▊         | 9/119 [00:00<00:01, 82.43it/s] 15%|█▌        | 18/119 [00:00<00:01, 78.11it/s] 22%|██▏       | 26/119 [00:00<00:01, 72.78it/s] 29%|██▊       | 34/119 [00:00<00:01, 72.54it/s] 35%|███▌      | 42/119 [00:00<00:01, 74.25it/s] 42%|████▏     | 50/119 [00:00<00:00, 70.94it/s] 49%|████▊     | 58/119 [00:00<00:00, 71.74it/s] 55%|█████▌    | 66/119 [00:00<00:00, 71.14it/s] 62%|██████▏   | 74/119 [00:01<00:00, 71.74it/s] 69%|██████▉   | 82/119 [00:01<00:00, 72.38it/s] 76%|███████▌  | 90/119 [00:01<00:00, 71.33it/s] 82%|████████▏ | 98/119 [00:01<00:00, 73.56it/s] 89%|████████▉ | 106/119 [00:01<00:00, 70.70it/s] 96%|█████████▌| 114/119 [00:01<00:00, 70.59it/s]100%|██████████| 119/119 [00:01<00:00, 70.96it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.7947
  eval_loss               =     0.6276
  eval_macro_f1           =     0.7222
  eval_micro_f1           =     0.7947
  eval_runtime            = 0:00:01.69
  eval_samples            =        945
  eval_samples_per_second =    558.083
  eval_steps_per_second   =     70.277
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▆█▇▇▇
wandb:                      eval/loss █▁▆▆██
wandb:                  eval/macro_f1 ▁▆█▇▇▇
wandb:                  eval/micro_f1 ▁▆█▇▇▇
wandb:                   eval/runtime ▁▄█▂▅▁
wandb:        eval/samples_per_second █▄▁▇▄█
wandb:          eval/steps_per_second █▄▁▇▄█
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.79471
wandb:                      eval/loss 0.62759
wandb:                  eval/macro_f1 0.72216
wandb:                  eval/micro_f1 0.79471
wandb:                   eval/runtime 1.6933
wandb:        eval/samples_per_second 558.083
wandb:          eval/steps_per_second 70.277
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1547
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.36724
wandb:            train/train_runtime 75.8558
wandb: train/train_samples_per_second 248.959
wandb:   train/train_steps_per_second 7.844
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_202604-odlxc1uq
wandb: Find logs at: ./wandb/offline-run-20231115_202604-odlxc1uq/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_roberta-base_adapter__seed2/runs/Nov15_20-28-52_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_roberta-base_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_roberta-base_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:28:52 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:28:52 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_roberta-base_adapter__seed2/runs/Nov15_20-28-51_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_roberta-base_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_roberta-base_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  38%|███▊      | 4203/11020 [00:00<00:00, 41800.72 examples/s]Map:  76%|███████▋  | 8411/11020 [00:00<00:00, 41961.37 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 41478.20 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:29:08,786 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:29:08,799 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:29:18,816 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:29:28,834 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:29:28,835 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:29:48,890 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:29:48,890 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:29:48,891 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:29:48,891 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:29:48,892 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:29:48,892 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:29:48,894 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:29:48,895 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:30:09,085 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:30:09,798 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:30:09,799 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  23%|██▎       | 2000/8816 [00:00<00:00, 15653.37 examples/s]Running tokenizer on dataset:  45%|████▌     | 4000/8816 [00:00<00:00, 16033.87 examples/s]Running tokenizer on dataset:  68%|██████▊   | 6000/8816 [00:00<00:00, 16164.62 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 17885.66 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 17128.98 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 21119.76 examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 20771.58 examples/s]
11/15/2023 20:30:10 - INFO - __main__ - Sample 5747 of the training set: {'text': 'While the redox buffer pairs (e.g. GSH/GSSG, reduced PC/oxidised PC, and reduced Protein/oxidised Protein) can protect cells from oxidative damage (Tsuji et al., 2002), this produces an imbalance in the redox status that may lead to other unwanted effects such as changes in intracellular pH, which…', 'label': 0, 'input_ids': [0, 5771, 5, 1275, 4325, 21944, 15029, 36, 242, 4, 571, 4, 272, 10237, 73, 534, 8108, 534, 6, 2906, 4985, 73, 4325, 808, 1720, 4985, 6, 8, 2906, 34786, 73, 4325, 808, 1720, 34786, 43, 64, 1744, 4590, 31, 46099, 1880, 36, 565, 9228, 5186, 4400, 1076, 482, 5241, 238, 42, 9108, 41, 27340, 11, 5, 1275, 4325, 2194, 14, 189, 483, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 20:30:10 - INFO - __main__ - Sample 5785 of the training set: {'text': 'BDNF has been shown to interact with several neurotrans-\nmitter systems, including the DA (Spenger et al., 1995), serotonin (5-HT) (Lyons et al., 1999; Rumajogee et al., 2002), and NPY systems (Barnea and Roberts, 2001; Nawa et al., 1993, 1994).', 'label': 0, 'input_ids': [0, 18941, 25356, 34, 57, 2343, 7, 10754, 19, 484, 44755, 12, 50118, 44370, 1743, 6, 217, 5, 9036, 36, 104, 9675, 2403, 4400, 1076, 482, 7969, 238, 43399, 36, 245, 12, 14469, 43, 36, 38683, 1790, 4400, 1076, 482, 6193, 131, 13772, 13745, 25601, 4400, 1076, 482, 5241, 238, 8, 26266, 975, 1743, 36, 14507, 22423, 8, 6274, 6, 5155, 131, 234, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 20:30:10 - INFO - __main__ - Sample 3534 of the training set: {'text': 'Studies have shown that alcohol consumption may contribute to the spread of HIV/AIDS by diminishing sexual inhibitions and interfering with one’s ability to adequately assess risk (Gordon et al. 1997; MacDonald et al. 2000a, b; Maisto et al. 2004).', 'label': 0, 'input_ids': [0, 46000, 33, 2343, 14, 3766, 4850, 189, 5042, 7, 5, 2504, 9, 7947, 73, 30968, 30, 28953, 1363, 38512, 8237, 8, 23524, 19, 65, 17, 27, 29, 1460, 7, 17327, 7118, 810, 36, 43226, 4400, 1076, 4, 7528, 131, 22207, 4400, 1076, 4, 3788, 102, 6, 741, 131, 3066, 661, 139, 4400, 1076, 4, 4482, 322, 2, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:30:10 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:30:11,565 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:30:11,574 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:30:11,574 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 20:30:11,574 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:30:11,575 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:30:11,575 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:30:11,575 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:30:11,576 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 20:30:11,576 >>   Number of trainable parameters = 124,647,939
[INFO|integration_utils.py:716] 2023-11-15 20:30:11,577 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<24:35,  1.07s/it]  0%|          | 3/1380 [00:01<07:51,  2.92it/s]  0%|          | 5/1380 [00:01<04:53,  4.69it/s]  1%|          | 7/1380 [00:01<03:41,  6.21it/s]  1%|          | 9/1380 [00:01<03:04,  7.44it/s]  1%|          | 11/1380 [00:01<02:42,  8.40it/s]  1%|          | 13/1380 [00:02<02:29,  9.15it/s]  1%|          | 15/1380 [00:02<02:20,  9.69it/s]  1%|          | 17/1380 [00:02<02:15, 10.08it/s]  1%|▏         | 19/1380 [00:02<02:10, 10.41it/s]  2%|▏         | 21/1380 [00:02<02:08, 10.62it/s]  2%|▏         | 23/1380 [00:03<02:06, 10.76it/s]  2%|▏         | 25/1380 [00:03<02:04, 10.85it/s]  2%|▏         | 27/1380 [00:03<02:03, 10.93it/s]  2%|▏         | 29/1380 [00:03<02:03, 10.98it/s]  2%|▏         | 31/1380 [00:03<02:02, 10.98it/s]  2%|▏         | 33/1380 [00:03<02:01, 11.05it/s]  3%|▎         | 35/1380 [00:04<02:01, 11.11it/s]  3%|▎         | 37/1380 [00:04<02:00, 11.16it/s]  3%|▎         | 39/1380 [00:04<02:00, 11.17it/s]  3%|▎         | 41/1380 [00:04<02:00, 11.15it/s]  3%|▎         | 43/1380 [00:04<01:59, 11.17it/s]  3%|▎         | 45/1380 [00:05<01:59, 11.17it/s]  3%|▎         | 47/1380 [00:05<01:59, 11.16it/s]  4%|▎         | 49/1380 [00:05<01:59, 11.16it/s]  4%|▎         | 51/1380 [00:05<01:59, 11.17it/s]  4%|▍         | 53/1380 [00:05<01:58, 11.18it/s]  4%|▍         | 55/1380 [00:05<01:58, 11.15it/s]  4%|▍         | 57/1380 [00:06<01:58, 11.17it/s]  4%|▍         | 59/1380 [00:06<01:58, 11.19it/s]  4%|▍         | 61/1380 [00:06<01:57, 11.19it/s]  5%|▍         | 63/1380 [00:06<01:57, 11.17it/s]  5%|▍         | 65/1380 [00:06<01:57, 11.19it/s]  5%|▍         | 67/1380 [00:06<01:57, 11.18it/s]  5%|▌         | 69/1380 [00:07<01:57, 11.19it/s]  5%|▌         | 71/1380 [00:07<01:57, 11.19it/s]  5%|▌         | 73/1380 [00:07<01:56, 11.20it/s]  5%|▌         | 75/1380 [00:07<01:56, 11.21it/s]  6%|▌         | 77/1380 [00:07<01:56, 11.20it/s]  6%|▌         | 79/1380 [00:08<01:56, 11.18it/s]  6%|▌         | 81/1380 [00:08<01:56, 11.17it/s]  6%|▌         | 83/1380 [00:08<01:56, 11.18it/s]  6%|▌         | 85/1380 [00:08<01:55, 11.19it/s]  6%|▋         | 87/1380 [00:08<01:55, 11.20it/s]  6%|▋         | 89/1380 [00:08<01:55, 11.19it/s]  7%|▋         | 91/1380 [00:09<01:55, 11.16it/s]  7%|▋         | 93/1380 [00:09<01:55, 11.17it/s]  7%|▋         | 95/1380 [00:09<01:55, 11.16it/s]  7%|▋         | 97/1380 [00:09<01:54, 11.17it/s]  7%|▋         | 99/1380 [00:09<01:54, 11.16it/s]  7%|▋         | 101/1380 [00:10<01:54, 11.16it/s]  7%|▋         | 103/1380 [00:10<01:54, 11.16it/s]  8%|▊         | 105/1380 [00:10<01:54, 11.17it/s]  8%|▊         | 107/1380 [00:10<01:53, 11.17it/s]  8%|▊         | 109/1380 [00:10<01:54, 11.15it/s]  8%|▊         | 111/1380 [00:10<01:53, 11.18it/s]  8%|▊         | 113/1380 [00:11<01:53, 11.18it/s]  8%|▊         | 115/1380 [00:11<01:52, 11.20it/s]  8%|▊         | 117/1380 [00:11<01:52, 11.20it/s]  9%|▊         | 119/1380 [00:11<01:52, 11.17it/s]  9%|▉         | 121/1380 [00:11<01:52, 11.17it/s]  9%|▉         | 123/1380 [00:12<01:52, 11.18it/s]  9%|▉         | 125/1380 [00:12<01:52, 11.18it/s]  9%|▉         | 127/1380 [00:12<01:52, 11.18it/s]  9%|▉         | 129/1380 [00:12<01:52, 11.17it/s]  9%|▉         | 131/1380 [00:12<01:51, 11.16it/s] 10%|▉         | 133/1380 [00:12<01:51, 11.15it/s] 10%|▉         | 135/1380 [00:13<01:51, 11.15it/s] 10%|▉         | 137/1380 [00:13<01:51, 11.16it/s] 10%|█         | 139/1380 [00:13<01:51, 11.15it/s] 10%|█         | 141/1380 [00:13<01:51, 11.15it/s] 10%|█         | 143/1380 [00:13<01:50, 11.16it/s] 11%|█         | 145/1380 [00:13<01:50, 11.15it/s] 11%|█         | 147/1380 [00:14<01:50, 11.16it/s] 11%|█         | 149/1380 [00:14<01:50, 11.14it/s] 11%|█         | 151/1380 [00:14<01:50, 11.14it/s] 11%|█         | 153/1380 [00:14<01:50, 11.15it/s] 11%|█         | 155/1380 [00:14<01:49, 11.14it/s] 11%|█▏        | 157/1380 [00:15<01:49, 11.13it/s] 12%|█▏        | 159/1380 [00:15<01:49, 11.12it/s] 12%|█▏        | 161/1380 [00:15<01:49, 11.13it/s] 12%|█▏        | 163/1380 [00:15<01:49, 11.13it/s] 12%|█▏        | 165/1380 [00:15<01:49, 11.13it/s] 12%|█▏        | 167/1380 [00:15<01:49, 11.13it/s] 12%|█▏        | 169/1380 [00:16<01:48, 11.14it/s] 12%|█▏        | 171/1380 [00:16<01:48, 11.13it/s] 13%|█▎        | 173/1380 [00:16<01:48, 11.14it/s] 13%|█▎        | 175/1380 [00:16<01:48, 11.13it/s] 13%|█▎        | 177/1380 [00:16<01:48, 11.13it/s] 13%|█▎        | 179/1380 [00:17<01:47, 11.13it/s] 13%|█▎        | 181/1380 [00:17<01:47, 11.17it/s] 13%|█▎        | 183/1380 [00:17<01:47, 11.14it/s] 13%|█▎        | 185/1380 [00:17<01:47, 11.13it/s] 14%|█▎        | 187/1380 [00:17<01:47, 11.11it/s] 14%|█▎        | 189/1380 [00:17<01:47, 11.11it/s] 14%|█▍        | 191/1380 [00:18<01:46, 11.12it/s] 14%|█▍        | 193/1380 [00:18<01:46, 11.14it/s] 14%|█▍        | 195/1380 [00:18<01:46, 11.14it/s] 14%|█▍        | 197/1380 [00:18<01:46, 11.14it/s] 14%|█▍        | 199/1380 [00:18<01:46, 11.13it/s] 15%|█▍        | 201/1380 [00:19<01:45, 11.13it/s] 15%|█▍        | 203/1380 [00:19<01:45, 11.13it/s] 15%|█▍        | 205/1380 [00:19<01:45, 11.13it/s] 15%|█▌        | 207/1380 [00:19<01:45, 11.12it/s] 15%|█▌        | 209/1380 [00:19<01:45, 11.13it/s] 15%|█▌        | 211/1380 [00:19<01:45, 11.13it/s] 15%|█▌        | 213/1380 [00:20<01:44, 11.13it/s] 16%|█▌        | 215/1380 [00:20<01:44, 11.15it/s] 16%|█▌        | 217/1380 [00:20<01:44, 11.15it/s] 16%|█▌        | 219/1380 [00:20<01:44, 11.14it/s] 16%|█▌        | 221/1380 [00:20<01:43, 11.15it/s] 16%|█▌        | 223/1380 [00:20<01:43, 11.15it/s] 16%|█▋        | 225/1380 [00:21<01:43, 11.15it/s] 16%|█▋        | 227/1380 [00:21<01:43, 11.14it/s] 17%|█▋        | 229/1380 [00:21<01:43, 11.14it/s] 17%|█▋        | 231/1380 [00:21<01:43, 11.15it/s] 17%|█▋        | 233/1380 [00:21<01:42, 11.15it/s] 17%|█▋        | 235/1380 [00:22<01:42, 11.13it/s] 17%|█▋        | 237/1380 [00:22<01:42, 11.12it/s] 17%|█▋        | 239/1380 [00:22<01:42, 11.13it/s] 17%|█▋        | 241/1380 [00:22<01:42, 11.15it/s] 18%|█▊        | 243/1380 [00:22<01:42, 11.13it/s] 18%|█▊        | 245/1380 [00:22<01:42, 11.12it/s] 18%|█▊        | 247/1380 [00:23<01:41, 11.13it/s] 18%|█▊        | 249/1380 [00:23<01:41, 11.14it/s] 18%|█▊        | 251/1380 [00:23<01:41, 11.12it/s] 18%|█▊        | 253/1380 [00:23<01:41, 11.13it/s] 18%|█▊        | 255/1380 [00:23<01:40, 11.15it/s] 19%|█▊        | 257/1380 [00:24<01:40, 11.14it/s] 19%|█▉        | 259/1380 [00:24<01:40, 11.13it/s] 19%|█▉        | 261/1380 [00:24<01:40, 11.13it/s] 19%|█▉        | 263/1380 [00:24<01:40, 11.13it/s] 19%|█▉        | 265/1380 [00:24<01:40, 11.11it/s] 19%|█▉        | 267/1380 [00:24<01:40, 11.10it/s] 19%|█▉        | 269/1380 [00:25<01:39, 11.12it/s] 20%|█▉        | 271/1380 [00:25<01:39, 11.14it/s] 20%|█▉        | 273/1380 [00:25<01:39, 11.10it/s] 20%|█▉        | 275/1380 [00:25<01:39, 11.12it/s]                                                   20%|██        | 276/1380 [00:25<01:39, 11.12it/s][INFO|trainer.py:755] 2023-11-15 20:30:37,299 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:30:37,301 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:30:37,301 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:30:37,302 >>   Batch size = 8
{'loss': 0.5036, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 123.86it/s][A
  9%|▉         | 26/276 [00:00<00:02, 116.95it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 115.48it/s][A
 18%|█▊        | 50/276 [00:00<00:01, 113.66it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 112.99it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 112.59it/s][A
 31%|███       | 86/276 [00:00<00:01, 112.39it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 111.86it/s][A
 40%|███▉      | 110/276 [00:00<00:01, 111.14it/s][A
 44%|████▍     | 122/276 [00:01<00:01, 110.78it/s][A
 49%|████▊     | 134/276 [00:01<00:01, 110.69it/s][A
 53%|█████▎    | 146/276 [00:01<00:01, 111.18it/s][A
 57%|█████▋    | 158/276 [00:01<00:01, 111.44it/s][A
 62%|██████▏   | 170/276 [00:01<00:00, 111.22it/s][A
 66%|██████▌   | 182/276 [00:01<00:00, 111.18it/s][A
 70%|███████   | 194/276 [00:01<00:00, 111.22it/s][A
 75%|███████▍  | 206/276 [00:01<00:00, 110.70it/s][A
 79%|███████▉  | 218/276 [00:01<00:00, 110.36it/s][A
 83%|████████▎ | 230/276 [00:02<00:00, 110.19it/s][A
 88%|████████▊ | 242/276 [00:02<00:00, 110.31it/s][A
 92%|█████████▏| 254/276 [00:02<00:00, 110.66it/s][A
 96%|█████████▋| 266/276 [00:02<00:00, 110.76it/s][A                                                  
                                                  [A 20%|██        | 276/1380 [00:28<01:39, 11.12it/s]
100%|██████████| 276/276 [00:02<00:00, 110.76it/s][A
                                                  [A 20%|██        | 277/1380 [00:28<08:33,  2.15it/s] 20%|██        | 279/1380 [00:28<06:28,  2.83it/s] 20%|██        | 281/1380 [00:28<05:01,  3.65it/s] 21%|██        | 283/1380 [00:28<04:00,  4.57it/s] 21%|██        | 285/1380 [00:29<03:17,  5.55it/s] 21%|██        | 287/1380 [00:29<02:47,  6.51it/s] 21%|██        | 289/1380 [00:29<02:26,  7.43it/s] 21%|██        | 291/1380 [00:29<02:11,  8.25it/s] 21%|██        | 293/1380 [00:29<02:01,  8.95it/s] 21%|██▏       | 295/1380 [00:29<01:54,  9.51it/s] 22%|██▏       | 297/1380 [00:30<01:49,  9.93it/s] 22%|██▏       | 299/1380 [00:30<01:45, 10.21it/s] 22%|██▏       | 301/1380 [00:30<01:43, 10.46it/s] 22%|██▏       | 303/1380 [00:30<01:41, 10.62it/s] 22%|██▏       | 305/1380 [00:30<01:39, 10.76it/s] 22%|██▏       | 307/1380 [00:31<01:38, 10.85it/s] 22%|██▏       | 309/1380 [00:31<01:38, 10.91it/s] 23%|██▎       | 311/1380 [00:31<01:37, 10.95it/s] 23%|██▎       | 313/1380 [00:31<01:37, 10.97it/s] 23%|██▎       | 315/1380 [00:31<01:36, 10.99it/s] 23%|██▎       | 317/1380 [00:31<01:36, 11.01it/s] 23%|██▎       | 319/1380 [00:32<01:36, 11.03it/s] 23%|██▎       | 321/1380 [00:32<01:35, 11.03it/s] 23%|██▎       | 323/1380 [00:32<01:35, 11.03it/s] 24%|██▎       | 325/1380 [00:32<01:35, 11.04it/s] 24%|██▎       | 327/1380 [00:32<01:35, 11.05it/s] 24%|██▍       | 329/1380 [00:33<01:35, 11.03it/s] 24%|██▍       | 331/1380 [00:33<01:34, 11.05it/s] 24%|██▍       | 333/1380 [00:33<01:34, 11.07it/s] 24%|██▍       | 335/1380 [00:33<01:34, 11.07it/s] 24%|██▍       | 337/1380 [00:33<01:34, 11.03it/s] 25%|██▍       | 339/1380 [00:33<01:34, 11.04it/s] 25%|██▍       | 341/1380 [00:34<01:34, 11.05it/s] 25%|██▍       | 343/1380 [00:34<01:33, 11.06it/s] 25%|██▌       | 345/1380 [00:34<01:33, 11.06it/s] 25%|██▌       | 347/1380 [00:34<01:33, 11.07it/s] 25%|██▌       | 349/1380 [00:34<01:33, 11.07it/s] 25%|██▌       | 351/1380 [00:35<01:33, 11.05it/s] 26%|██▌       | 353/1380 [00:35<01:33, 11.04it/s] 26%|██▌       | 355/1380 [00:35<01:32, 11.04it/s] 26%|██▌       | 357/1380 [00:35<01:32, 11.05it/s] 26%|██▌       | 359/1380 [00:35<01:32, 11.05it/s] 26%|██▌       | 361/1380 [00:35<01:32, 11.06it/s] 26%|██▋       | 363/1380 [00:36<01:32, 11.04it/s] 26%|██▋       | 365/1380 [00:36<01:31, 11.07it/s] 27%|██▋       | 367/1380 [00:36<01:31, 11.06it/s] 27%|██▋       | 369/1380 [00:36<01:31, 11.06it/s] 27%|██▋       | 371/1380 [00:36<01:31, 11.06it/s] 27%|██▋       | 373/1380 [00:37<01:30, 11.07it/s] 27%|██▋       | 375/1380 [00:37<01:30, 11.05it/s] 27%|██▋       | 377/1380 [00:37<01:30, 11.05it/s] 27%|██▋       | 379/1380 [00:37<01:30, 11.05it/s] 28%|██▊       | 381/1380 [00:37<01:30, 11.05it/s] 28%|██▊       | 383/1380 [00:37<01:30, 11.03it/s] 28%|██▊       | 385/1380 [00:38<01:29, 11.06it/s] 28%|██▊       | 387/1380 [00:38<01:29, 11.07it/s] 28%|██▊       | 389/1380 [00:38<01:29, 11.06it/s] 28%|██▊       | 391/1380 [00:38<01:29, 11.04it/s] 28%|██▊       | 393/1380 [00:38<01:29, 11.05it/s] 29%|██▊       | 395/1380 [00:39<01:29, 11.05it/s] 29%|██▉       | 397/1380 [00:39<01:29, 11.02it/s] 29%|██▉       | 399/1380 [00:39<01:29, 11.02it/s] 29%|██▉       | 401/1380 [00:39<01:29, 11.00it/s] 29%|██▉       | 403/1380 [00:39<01:28, 11.03it/s] 29%|██▉       | 405/1380 [00:39<01:28, 11.03it/s] 29%|██▉       | 407/1380 [00:40<01:28, 11.02it/s] 30%|██▉       | 409/1380 [00:40<01:28, 11.03it/s] 30%|██▉       | 411/1380 [00:40<01:27, 11.04it/s] 30%|██▉       | 413/1380 [00:40<01:27, 11.04it/s] 30%|███       | 415/1380 [00:40<01:27, 11.05it/s] 30%|███       | 417/1380 [00:41<01:26, 11.08it/s] 30%|███       | 419/1380 [00:41<01:26, 11.06it/s] 31%|███       | 421/1380 [00:41<01:26, 11.04it/s] 31%|███       | 423/1380 [00:41<01:26, 11.05it/s] 31%|███       | 425/1380 [00:41<01:26, 11.06it/s] 31%|███       | 427/1380 [00:41<01:26, 11.06it/s] 31%|███       | 429/1380 [00:42<01:26, 11.06it/s] 31%|███       | 431/1380 [00:42<01:25, 11.05it/s] 31%|███▏      | 433/1380 [00:42<01:25, 11.06it/s] 32%|███▏      | 435/1380 [00:42<01:25, 11.07it/s] 32%|███▏      | 437/1380 [00:42<01:25, 11.05it/s] 32%|███▏      | 439/1380 [00:42<01:25, 11.05it/s] 32%|███▏      | 441/1380 [00:43<01:24, 11.07it/s] 32%|███▏      | 443/1380 [00:43<01:24, 11.06it/s] 32%|███▏      | 445/1380 [00:43<01:24, 11.05it/s] 32%|███▏      | 447/1380 [00:43<01:24, 11.06it/s] 33%|███▎      | 449/1380 [00:43<01:24, 11.07it/s] 33%|███▎      | 451/1380 [00:44<01:24, 11.05it/s] 33%|███▎      | 453/1380 [00:44<01:23, 11.05it/s] 33%|███▎      | 455/1380 [00:44<01:23, 11.05it/s] 33%|███▎      | 457/1380 [00:44<01:23, 11.05it/s] 33%|███▎      | 459/1380 [00:44<01:23, 11.05it/s] 33%|███▎      | 461/1380 [00:44<01:23, 11.06it/s] 34%|███▎      | 463/1380 [00:45<01:22, 11.06it/s] 34%|███▎      | 465/1380 [00:45<01:22, 11.07it/s] 34%|███▍      | 467/1380 [00:45<01:22, 11.03it/s] 34%|███▍      | 469/1380 [00:45<01:22, 11.04it/s] 34%|███▍      | 471/1380 [00:45<01:22, 11.04it/s] 34%|███▍      | 473/1380 [00:46<01:22, 11.05it/s] 34%|███▍      | 475/1380 [00:46<01:21, 11.04it/s] 35%|███▍      | 477/1380 [00:46<01:21, 11.04it/s] 35%|███▍      | 479/1380 [00:46<01:21, 11.05it/s] 35%|███▍      | 481/1380 [00:46<01:21, 11.05it/s] 35%|███▌      | 483/1380 [00:46<01:21, 11.04it/s] 35%|███▌      | 485/1380 [00:47<01:21, 11.03it/s] 35%|███▌      | 487/1380 [00:47<01:20, 11.03it/s] 35%|███▌      | 489/1380 [00:47<01:20, 11.02it/s] 36%|███▌      | 491/1380 [00:47<01:20, 11.01it/s] 36%|███▌      | 493/1380 [00:47<01:20, 11.04it/s] 36%|███▌      | 495/1380 [00:48<01:20, 11.04it/s] 36%|███▌      | 497/1380 [00:48<01:19, 11.05it/s] 36%|███▌      | 499/1380 [00:48<01:19, 11.04it/s] 36%|███▋      | 501/1380 [00:48<01:19, 11.03it/s] 36%|███▋      | 503/1380 [00:48<01:19, 11.03it/s] 37%|███▋      | 505/1380 [00:48<01:19, 11.02it/s] 37%|███▋      | 507/1380 [00:49<01:19, 11.03it/s] 37%|███▋      | 509/1380 [00:49<01:18, 11.04it/s] 37%|███▋      | 511/1380 [00:49<01:18, 11.04it/s] 37%|███▋      | 513/1380 [00:49<01:18, 11.01it/s] 37%|███▋      | 515/1380 [00:49<01:18, 11.01it/s] 37%|███▋      | 517/1380 [00:50<01:18, 11.03it/s] 38%|███▊      | 519/1380 [00:50<01:18, 11.03it/s] 38%|███▊      | 521/1380 [00:50<01:17, 11.02it/s] 38%|███▊      | 523/1380 [00:50<01:17, 11.04it/s] 38%|███▊      | 525/1380 [00:50<01:17, 11.04it/s] 38%|███▊      | 527/1380 [00:50<01:17, 11.02it/s] 38%|███▊      | 529/1380 [00:51<01:17, 11.00it/s] 38%|███▊      | 531/1380 [00:51<01:17, 11.00it/s] 39%|███▊      | 533/1380 [00:51<01:16, 11.02it/s] 39%|███▉      | 535/1380 [00:51<01:16, 11.05it/s] 39%|███▉      | 537/1380 [00:51<01:16, 11.02it/s] 39%|███▉      | 539/1380 [00:52<01:16, 11.03it/s] 39%|███▉      | 541/1380 [00:52<01:16, 11.02it/s] 39%|███▉      | 543/1380 [00:52<01:16, 11.01it/s] 39%|███▉      | 545/1380 [00:52<01:15, 11.00it/s] 40%|███▉      | 547/1380 [00:52<01:15, 11.01it/s] 40%|███▉      | 549/1380 [00:52<01:15, 11.02it/s] 40%|███▉      | 551/1380 [00:53<01:15, 11.04it/s]                                                   40%|████      | 552/1380 [00:53<01:15, 11.04it/s][INFO|trainer.py:755] 2023-11-15 20:31:04,788 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:31:04,789 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:31:04,790 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:31:04,790 >>   Batch size = 8
{'eval_loss': 0.39551693201065063, 'eval_accuracy': 0.8502722323049002, 'eval_micro_f1': 0.8502722323049003, 'eval_macro_f1': 0.8239548223448706, 'eval_runtime': 2.5284, 'eval_samples_per_second': 871.695, 'eval_steps_per_second': 109.16, 'epoch': 1.0}
{'loss': 0.3262, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 123.92it/s][A
  9%|▉         | 26/276 [00:00<00:02, 117.33it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 114.89it/s][A
 18%|█▊        | 50/276 [00:00<00:01, 113.34it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 112.50it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 111.76it/s][A
 31%|███       | 86/276 [00:00<00:01, 110.89it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 110.19it/s][A
 40%|███▉      | 110/276 [00:00<00:01, 109.39it/s][A
 44%|████▍     | 121/276 [00:01<00:01, 109.29it/s][A
 48%|████▊     | 132/276 [00:01<00:01, 109.28it/s][A
 52%|█████▏    | 144/276 [00:01<00:01, 109.67it/s][A
 56%|█████▌    | 155/276 [00:01<00:01, 109.70it/s][A
 60%|██████    | 166/276 [00:01<00:01, 109.28it/s][A
 64%|██████▍   | 177/276 [00:01<00:00, 109.15it/s][A
 68%|██████▊   | 188/276 [00:01<00:00, 108.95it/s][A
 72%|███████▏  | 199/276 [00:01<00:00, 108.74it/s][A
 76%|███████▌  | 210/276 [00:01<00:00, 108.39it/s][A
 80%|████████  | 221/276 [00:02<00:00, 108.11it/s][A
 84%|████████▍ | 232/276 [00:02<00:00, 108.07it/s][A
 88%|████████▊ | 243/276 [00:02<00:00, 108.06it/s][A
 92%|█████████▏| 254/276 [00:02<00:00, 108.19it/s][A
 96%|█████████▌| 265/276 [00:02<00:00, 108.36it/s][A                                                  
                                                  [A 40%|████      | 552/1380 [00:55<01:15, 11.04it/s]
100%|██████████| 276/276 [00:02<00:00, 108.36it/s][A
                                                  [A 40%|████      | 553/1380 [00:55<06:30,  2.12it/s] 40%|████      | 555/1380 [00:56<04:55,  2.79it/s] 40%|████      | 557/1380 [00:56<03:48,  3.60it/s] 41%|████      | 559/1380 [00:56<03:02,  4.51it/s] 41%|████      | 561/1380 [00:56<02:29,  5.48it/s] 41%|████      | 563/1380 [00:56<02:06,  6.44it/s] 41%|████      | 565/1380 [00:56<01:50,  7.37it/s] 41%|████      | 567/1380 [00:57<01:39,  8.19it/s] 41%|████      | 569/1380 [00:57<01:31,  8.88it/s] 41%|████▏     | 571/1380 [00:57<01:25,  9.44it/s] 42%|████▏     | 573/1380 [00:57<01:21,  9.86it/s] 42%|████▏     | 575/1380 [00:57<01:19, 10.18it/s] 42%|████▏     | 577/1380 [00:58<01:17, 10.41it/s] 42%|████▏     | 579/1380 [00:58<01:15, 10.58it/s] 42%|████▏     | 581/1380 [00:58<01:14, 10.73it/s] 42%|████▏     | 583/1380 [00:58<01:13, 10.83it/s] 42%|████▏     | 585/1380 [00:58<01:13, 10.88it/s] 43%|████▎     | 587/1380 [00:58<01:12, 10.90it/s] 43%|████▎     | 589/1380 [00:59<01:12, 10.93it/s] 43%|████▎     | 591/1380 [00:59<01:11, 10.97it/s] 43%|████▎     | 593/1380 [00:59<01:11, 11.00it/s] 43%|████▎     | 595/1380 [00:59<01:11, 11.00it/s] 43%|████▎     | 597/1380 [00:59<01:11, 11.01it/s] 43%|████▎     | 599/1380 [01:00<01:10, 11.02it/s] 44%|████▎     | 601/1380 [01:00<01:10, 11.00it/s] 44%|████▎     | 603/1380 [01:00<01:10, 11.00it/s] 44%|████▍     | 605/1380 [01:00<01:10, 11.01it/s] 44%|████▍     | 607/1380 [01:00<01:10, 11.01it/s] 44%|████▍     | 609/1380 [01:00<01:09, 11.02it/s] 44%|████▍     | 611/1380 [01:01<01:09, 11.02it/s] 44%|████▍     | 613/1380 [01:01<01:09, 11.00it/s] 45%|████▍     | 615/1380 [01:01<01:09, 10.99it/s] 45%|████▍     | 617/1380 [01:01<01:09, 11.00it/s] 45%|████▍     | 619/1380 [01:01<01:09, 11.03it/s] 45%|████▌     | 621/1380 [01:02<01:08, 11.03it/s] 45%|████▌     | 623/1380 [01:02<01:08, 11.01it/s] 45%|████▌     | 625/1380 [01:02<01:08, 10.98it/s] 45%|████▌     | 627/1380 [01:02<01:08, 10.98it/s] 46%|████▌     | 629/1380 [01:02<01:08, 11.00it/s] 46%|████▌     | 631/1380 [01:02<01:08, 11.01it/s] 46%|████▌     | 633/1380 [01:03<01:08, 10.98it/s] 46%|████▌     | 635/1380 [01:03<01:07, 10.98it/s] 46%|████▌     | 637/1380 [01:03<01:07, 11.00it/s] 46%|████▋     | 639/1380 [01:03<01:07, 11.00it/s] 46%|████▋     | 641/1380 [01:03<01:07, 11.00it/s] 47%|████▋     | 643/1380 [01:04<01:06, 11.01it/s] 47%|████▋     | 645/1380 [01:04<01:06, 11.00it/s] 47%|████▋     | 647/1380 [01:04<01:06, 10.98it/s] 47%|████▋     | 649/1380 [01:04<01:06, 11.00it/s] 47%|████▋     | 651/1380 [01:04<01:06, 11.00it/s] 47%|████▋     | 653/1380 [01:04<01:06, 11.00it/s] 47%|████▋     | 655/1380 [01:05<01:05, 11.00it/s] 48%|████▊     | 657/1380 [01:05<01:05, 10.98it/s] 48%|████▊     | 659/1380 [01:05<01:05, 10.99it/s] 48%|████▊     | 661/1380 [01:05<01:05, 11.01it/s] 48%|████▊     | 663/1380 [01:05<01:05, 10.99it/s] 48%|████▊     | 665/1380 [01:06<01:05, 10.98it/s] 48%|████▊     | 667/1380 [01:06<01:04, 10.99it/s] 48%|████▊     | 669/1380 [01:06<01:04, 10.98it/s] 49%|████▊     | 671/1380 [01:06<01:04, 10.98it/s] 49%|████▉     | 673/1380 [01:06<01:04, 10.99it/s] 49%|████▉     | 675/1380 [01:06<01:04, 10.99it/s] 49%|████▉     | 677/1380 [01:07<01:03, 10.99it/s] 49%|████▉     | 679/1380 [01:07<01:03, 10.99it/s] 49%|████▉     | 681/1380 [01:07<01:03, 10.99it/s] 49%|████▉     | 683/1380 [01:07<01:03, 10.99it/s] 50%|████▉     | 685/1380 [01:07<01:03, 10.99it/s] 50%|████▉     | 687/1380 [01:08<01:03, 10.98it/s] 50%|████▉     | 689/1380 [01:08<01:02, 10.99it/s] 50%|█████     | 691/1380 [01:08<01:02, 10.99it/s] 50%|█████     | 693/1380 [01:08<01:02, 10.98it/s] 50%|█████     | 695/1380 [01:08<01:02, 10.97it/s] 51%|█████     | 697/1380 [01:08<01:02, 10.99it/s] 51%|█████     | 699/1380 [01:09<01:01, 11.00it/s] 51%|█████     | 701/1380 [01:09<01:01, 10.98it/s] 51%|█████     | 703/1380 [01:09<01:01, 10.97it/s] 51%|█████     | 705/1380 [01:09<01:01, 10.97it/s] 51%|█████     | 707/1380 [01:09<01:01, 10.95it/s] 51%|█████▏    | 709/1380 [01:10<01:01, 10.94it/s] 52%|█████▏    | 711/1380 [01:10<01:01, 10.96it/s] 52%|█████▏    | 713/1380 [01:10<01:00, 10.97it/s] 52%|█████▏    | 715/1380 [01:10<01:00, 10.99it/s] 52%|█████▏    | 717/1380 [01:10<01:00, 10.96it/s] 52%|█████▏    | 719/1380 [01:10<01:00, 10.96it/s] 52%|█████▏    | 721/1380 [01:11<01:00, 10.97it/s] 52%|█████▏    | 723/1380 [01:11<00:59, 10.96it/s] 53%|█████▎    | 725/1380 [01:11<00:59, 10.96it/s] 53%|█████▎    | 727/1380 [01:11<00:59, 10.97it/s] 53%|█████▎    | 729/1380 [01:11<00:59, 10.98it/s] 53%|█████▎    | 731/1380 [01:12<00:59, 10.99it/s] 53%|█████▎    | 733/1380 [01:12<00:58, 10.98it/s] 53%|█████▎    | 735/1380 [01:12<00:58, 10.99it/s] 53%|█████▎    | 737/1380 [01:12<00:58, 10.99it/s] 54%|█████▎    | 739/1380 [01:12<00:58, 10.98it/s] 54%|█████▎    | 741/1380 [01:12<00:58, 10.98it/s] 54%|█████▍    | 743/1380 [01:13<00:58, 10.98it/s] 54%|█████▍    | 745/1380 [01:13<00:57, 11.00it/s] 54%|█████▍    | 747/1380 [01:13<00:57, 10.98it/s] 54%|█████▍    | 749/1380 [01:13<00:57, 10.99it/s] 54%|█████▍    | 751/1380 [01:13<00:57, 11.00it/s] 55%|█████▍    | 753/1380 [01:14<00:56, 11.01it/s] 55%|█████▍    | 755/1380 [01:14<00:56, 10.97it/s] 55%|█████▍    | 757/1380 [01:14<00:56, 10.98it/s] 55%|█████▌    | 759/1380 [01:14<00:56, 10.98it/s] 55%|█████▌    | 761/1380 [01:14<00:56, 10.99it/s] 55%|█████▌    | 763/1380 [01:14<00:56, 10.98it/s] 55%|█████▌    | 765/1380 [01:15<00:56, 10.98it/s] 56%|█████▌    | 767/1380 [01:15<00:55, 10.97it/s] 56%|█████▌    | 769/1380 [01:15<00:55, 10.99it/s] 56%|█████▌    | 771/1380 [01:15<00:55, 10.99it/s] 56%|█████▌    | 773/1380 [01:15<00:55, 10.98it/s] 56%|█████▌    | 775/1380 [01:16<00:55, 10.98it/s] 56%|█████▋    | 777/1380 [01:16<00:55, 10.96it/s] 56%|█████▋    | 779/1380 [01:16<00:54, 10.97it/s] 57%|█████▋    | 781/1380 [01:16<00:54, 10.97it/s] 57%|█████▋    | 783/1380 [01:16<00:54, 10.97it/s] 57%|█████▋    | 785/1380 [01:16<00:54, 10.97it/s] 57%|█████▋    | 787/1380 [01:17<00:54, 10.97it/s] 57%|█████▋    | 789/1380 [01:17<00:53, 10.98it/s] 57%|█████▋    | 791/1380 [01:17<00:53, 10.97it/s] 57%|█████▋    | 793/1380 [01:17<00:53, 10.97it/s] 58%|█████▊    | 795/1380 [01:17<00:53, 10.98it/s] 58%|█████▊    | 797/1380 [01:18<00:53, 10.98it/s] 58%|█████▊    | 799/1380 [01:18<00:52, 10.96it/s] 58%|█████▊    | 801/1380 [01:18<00:52, 10.96it/s] 58%|█████▊    | 803/1380 [01:18<00:52, 10.96it/s] 58%|█████▊    | 805/1380 [01:18<00:52, 10.98it/s] 58%|█████▊    | 807/1380 [01:18<00:52, 10.97it/s] 59%|█████▊    | 809/1380 [01:19<00:52, 10.96it/s] 59%|█████▉    | 811/1380 [01:19<00:51, 10.97it/s] 59%|█████▉    | 813/1380 [01:19<00:51, 10.98it/s] 59%|█████▉    | 815/1380 [01:19<00:51, 10.96it/s] 59%|█████▉    | 817/1380 [01:19<00:51, 10.96it/s] 59%|█████▉    | 819/1380 [01:20<00:51, 10.97it/s] 59%|█████▉    | 821/1380 [01:20<00:50, 10.98it/s] 60%|█████▉    | 823/1380 [01:20<00:50, 10.97it/s] 60%|█████▉    | 825/1380 [01:20<00:50, 10.97it/s] 60%|█████▉    | 827/1380 [01:20<00:50, 10.97it/s]                                                   60%|██████    | 828/1380 [01:20<00:50, 10.97it/s][INFO|trainer.py:755] 2023-11-15 20:31:32,447 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:31:32,448 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:31:32,449 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:31:32,449 >>   Batch size = 8
{'eval_loss': 0.3911113739013672, 'eval_accuracy': 0.8629764065335753, 'eval_micro_f1': 0.8629764065335753, 'eval_macro_f1': 0.8455104654369284, 'eval_runtime': 2.567, 'eval_samples_per_second': 858.603, 'eval_steps_per_second': 107.52, 'epoch': 2.0}
{'loss': 0.2498, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 122.87it/s][A
  9%|▉         | 26/276 [00:00<00:02, 116.00it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 113.77it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 112.55it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.36it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.69it/s][A
 31%|███       | 86/276 [00:00<00:01, 110.15it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 109.27it/s][A
 39%|███▉      | 109/276 [00:00<00:01, 108.48it/s][A
 43%|████▎     | 120/276 [00:01<00:01, 108.10it/s][A
 47%|████▋     | 131/276 [00:01<00:01, 108.34it/s][A
 51%|█████▏    | 142/276 [00:01<00:01, 108.52it/s][A
 55%|█████▌    | 153/276 [00:01<00:01, 108.41it/s][A
 59%|█████▉    | 164/276 [00:01<00:01, 108.31it/s][A
 63%|██████▎   | 175/276 [00:01<00:00, 107.90it/s][A
 67%|██████▋   | 186/276 [00:01<00:00, 107.76it/s][A
 71%|███████▏  | 197/276 [00:01<00:00, 107.41it/s][A
 75%|███████▌  | 208/276 [00:01<00:00, 107.01it/s][A
 79%|███████▉  | 219/276 [00:02<00:00, 106.62it/s][A
 83%|████████▎ | 230/276 [00:02<00:00, 106.60it/s][A
 87%|████████▋ | 241/276 [00:02<00:00, 106.63it/s][A
 91%|█████████▏| 252/276 [00:02<00:00, 106.81it/s][A
 95%|█████████▌| 263/276 [00:02<00:00, 106.94it/s][A
 99%|█████████▉| 274/276 [00:02<00:00, 106.82it/s][A                                                  
                                                  [A 60%|██████    | 828/1380 [01:23<00:50, 10.97it/s]
100%|██████████| 276/276 [00:02<00:00, 106.82it/s][A
                                                  [A 60%|██████    | 829/1380 [01:23<04:22,  2.10it/s] 60%|██████    | 831/1380 [01:23<03:18,  2.76it/s] 60%|██████    | 833/1380 [01:23<02:33,  3.56it/s] 61%|██████    | 835/1380 [01:24<02:02,  4.46it/s] 61%|██████    | 837/1380 [01:24<01:39,  5.44it/s] 61%|██████    | 839/1380 [01:24<01:24,  6.39it/s] 61%|██████    | 841/1380 [01:24<01:13,  7.31it/s] 61%|██████    | 843/1380 [01:24<01:06,  8.12it/s] 61%|██████    | 845/1380 [01:25<01:00,  8.82it/s] 61%|██████▏   | 847/1380 [01:25<00:56,  9.36it/s] 62%|██████▏   | 849/1380 [01:25<00:54,  9.79it/s] 62%|██████▏   | 851/1380 [01:25<00:52, 10.11it/s] 62%|██████▏   | 853/1380 [01:25<00:50, 10.36it/s] 62%|██████▏   | 855/1380 [01:25<00:49, 10.53it/s] 62%|██████▏   | 857/1380 [01:26<00:49, 10.66it/s] 62%|██████▏   | 859/1380 [01:26<00:48, 10.74it/s] 62%|██████▏   | 861/1380 [01:26<00:48, 10.79it/s] 63%|██████▎   | 863/1380 [01:26<00:47, 10.84it/s] 63%|██████▎   | 865/1380 [01:26<00:47, 10.89it/s] 63%|██████▎   | 867/1380 [01:27<00:46, 10.92it/s] 63%|██████▎   | 869/1380 [01:27<00:46, 10.93it/s] 63%|██████▎   | 871/1380 [01:27<00:46, 10.95it/s] 63%|██████▎   | 873/1380 [01:27<00:46, 10.95it/s] 63%|██████▎   | 875/1380 [01:27<00:46, 10.95it/s] 64%|██████▎   | 877/1380 [01:27<00:45, 10.96it/s] 64%|██████▎   | 879/1380 [01:28<00:45, 10.96it/s] 64%|██████▍   | 881/1380 [01:28<00:45, 10.97it/s] 64%|██████▍   | 883/1380 [01:28<00:45, 10.96it/s] 64%|██████▍   | 885/1380 [01:28<00:45, 10.97it/s] 64%|██████▍   | 887/1380 [01:28<00:44, 10.99it/s] 64%|██████▍   | 889/1380 [01:29<00:44, 10.99it/s] 65%|██████▍   | 891/1380 [01:29<00:44, 10.98it/s] 65%|██████▍   | 893/1380 [01:29<00:44, 10.97it/s] 65%|██████▍   | 895/1380 [01:29<00:44, 10.98it/s] 65%|██████▌   | 897/1380 [01:29<00:43, 10.98it/s] 65%|██████▌   | 899/1380 [01:29<00:43, 10.97it/s] 65%|██████▌   | 901/1380 [01:30<00:43, 10.98it/s] 65%|██████▌   | 903/1380 [01:30<00:43, 10.99it/s] 66%|██████▌   | 905/1380 [01:30<00:43, 10.98it/s] 66%|██████▌   | 907/1380 [01:30<00:43, 10.98it/s] 66%|██████▌   | 909/1380 [01:30<00:42, 10.98it/s] 66%|██████▌   | 911/1380 [01:31<00:42, 10.98it/s] 66%|██████▌   | 913/1380 [01:31<00:42, 10.96it/s] 66%|██████▋   | 915/1380 [01:31<00:42, 10.98it/s] 66%|██████▋   | 917/1380 [01:31<00:42, 10.98it/s] 67%|██████▋   | 919/1380 [01:31<00:42, 10.97it/s] 67%|██████▋   | 921/1380 [01:31<00:41, 10.97it/s] 67%|██████▋   | 923/1380 [01:32<00:41, 10.98it/s] 67%|██████▋   | 925/1380 [01:32<00:41, 10.98it/s] 67%|██████▋   | 927/1380 [01:32<00:41, 10.97it/s] 67%|██████▋   | 929/1380 [01:32<00:41, 10.97it/s] 67%|██████▋   | 931/1380 [01:32<00:40, 10.97it/s] 68%|██████▊   | 933/1380 [01:33<00:40, 10.97it/s] 68%|██████▊   | 935/1380 [01:33<00:40, 10.97it/s] 68%|██████▊   | 937/1380 [01:33<00:40, 10.98it/s] 68%|██████▊   | 939/1380 [01:33<00:40, 10.99it/s] 68%|██████▊   | 941/1380 [01:33<00:39, 11.00it/s] 68%|██████▊   | 943/1380 [01:33<00:39, 10.99it/s] 68%|██████▊   | 945/1380 [01:34<00:39, 10.99it/s] 69%|██████▊   | 947/1380 [01:34<00:39, 10.98it/s] 69%|██████▉   | 949/1380 [01:34<00:39, 10.98it/s] 69%|██████▉   | 951/1380 [01:34<00:39, 10.97it/s] 69%|██████▉   | 953/1380 [01:34<00:38, 10.98it/s] 69%|██████▉   | 955/1380 [01:35<00:38, 10.97it/s] 69%|██████▉   | 957/1380 [01:35<00:38, 10.98it/s] 69%|██████▉   | 959/1380 [01:35<00:38, 10.97it/s] 70%|██████▉   | 961/1380 [01:35<00:38, 10.98it/s] 70%|██████▉   | 963/1380 [01:35<00:37, 10.98it/s] 70%|██████▉   | 965/1380 [01:35<00:37, 10.96it/s] 70%|███████   | 967/1380 [01:36<00:37, 10.98it/s] 70%|███████   | 969/1380 [01:36<00:37, 10.98it/s] 70%|███████   | 971/1380 [01:36<00:37, 10.99it/s] 71%|███████   | 973/1380 [01:36<00:37, 10.96it/s] 71%|███████   | 975/1380 [01:36<00:36, 10.98it/s] 71%|███████   | 977/1380 [01:37<00:36, 10.98it/s] 71%|███████   | 979/1380 [01:37<00:36, 10.98it/s] 71%|███████   | 981/1380 [01:37<00:36, 10.98it/s] 71%|███████   | 983/1380 [01:37<00:36, 10.98it/s] 71%|███████▏  | 985/1380 [01:37<00:35, 10.99it/s] 72%|███████▏  | 987/1380 [01:37<00:35, 10.97it/s] 72%|███████▏  | 989/1380 [01:38<00:35, 10.98it/s] 72%|███████▏  | 991/1380 [01:38<00:35, 10.98it/s] 72%|███████▏  | 993/1380 [01:38<00:35, 10.99it/s] 72%|███████▏  | 995/1380 [01:38<00:35, 10.99it/s] 72%|███████▏  | 997/1380 [01:38<00:34, 10.99it/s] 72%|███████▏  | 999/1380 [01:39<00:34, 10.98it/s] 73%|███████▎  | 1001/1380 [01:39<00:34, 10.97it/s] 73%|███████▎  | 1003/1380 [01:39<00:34, 10.96it/s] 73%|███████▎  | 1005/1380 [01:39<00:34, 10.96it/s] 73%|███████▎  | 1007/1380 [01:39<00:34, 10.92it/s] 73%|███████▎  | 1009/1380 [01:39<00:34, 10.91it/s] 73%|███████▎  | 1011/1380 [01:40<00:33, 10.92it/s] 73%|███████▎  | 1013/1380 [01:40<00:33, 10.92it/s] 74%|███████▎  | 1015/1380 [01:40<00:33, 10.96it/s] 74%|███████▎  | 1017/1380 [01:40<00:33, 10.94it/s] 74%|███████▍  | 1019/1380 [01:40<00:32, 10.95it/s] 74%|███████▍  | 1021/1380 [01:41<00:32, 10.96it/s] 74%|███████▍  | 1023/1380 [01:41<00:32, 10.98it/s] 74%|███████▍  | 1025/1380 [01:41<00:32, 10.97it/s] 74%|███████▍  | 1027/1380 [01:41<00:32, 10.97it/s] 75%|███████▍  | 1029/1380 [01:41<00:31, 10.98it/s] 75%|███████▍  | 1031/1380 [01:41<00:31, 10.96it/s] 75%|███████▍  | 1033/1380 [01:42<00:31, 10.97it/s] 75%|███████▌  | 1035/1380 [01:42<00:31, 10.96it/s] 75%|███████▌  | 1037/1380 [01:42<00:31, 10.96it/s] 75%|███████▌  | 1039/1380 [01:42<00:31, 10.96it/s] 75%|███████▌  | 1041/1380 [01:42<00:30, 10.95it/s] 76%|███████▌  | 1043/1380 [01:43<00:30, 10.97it/s] 76%|███████▌  | 1045/1380 [01:43<00:30, 10.97it/s] 76%|███████▌  | 1047/1380 [01:43<00:30, 10.95it/s] 76%|███████▌  | 1049/1380 [01:43<00:30, 10.97it/s] 76%|███████▌  | 1051/1380 [01:43<00:29, 10.97it/s] 76%|███████▋  | 1053/1380 [01:43<00:29, 10.94it/s] 76%|███████▋  | 1055/1380 [01:44<00:29, 10.95it/s] 77%|███████▋  | 1057/1380 [01:44<00:29, 10.97it/s] 77%|███████▋  | 1059/1380 [01:44<00:29, 10.97it/s] 77%|███████▋  | 1061/1380 [01:44<00:29, 10.95it/s] 77%|███████▋  | 1063/1380 [01:44<00:28, 10.96it/s] 77%|███████▋  | 1065/1380 [01:45<00:28, 10.98it/s] 77%|███████▋  | 1067/1380 [01:45<00:28, 10.98it/s] 77%|███████▋  | 1069/1380 [01:45<00:28, 10.96it/s] 78%|███████▊  | 1071/1380 [01:45<00:28, 10.97it/s] 78%|███████▊  | 1073/1380 [01:45<00:27, 10.97it/s] 78%|███████▊  | 1075/1380 [01:45<00:27, 10.96it/s] 78%|███████▊  | 1077/1380 [01:46<00:27, 10.95it/s] 78%|███████▊  | 1079/1380 [01:46<00:27, 10.85it/s] 78%|███████▊  | 1081/1380 [01:46<00:27, 10.88it/s] 78%|███████▊  | 1083/1380 [01:46<00:27, 10.91it/s] 79%|███████▊  | 1085/1380 [01:46<00:27, 10.92it/s] 79%|███████▉  | 1087/1380 [01:47<00:26, 10.92it/s] 79%|███████▉  | 1089/1380 [01:47<00:26, 10.93it/s] 79%|███████▉  | 1091/1380 [01:47<00:26, 10.92it/s] 79%|███████▉  | 1093/1380 [01:47<00:26, 10.93it/s] 79%|███████▉  | 1095/1380 [01:47<00:26, 10.95it/s] 79%|███████▉  | 1097/1380 [01:48<00:25, 10.95it/s] 80%|███████▉  | 1099/1380 [01:48<00:25, 10.94it/s] 80%|███████▉  | 1101/1380 [01:48<00:25, 10.94it/s] 80%|███████▉  | 1103/1380 [01:48<00:25, 10.94it/s]                                                    80%|████████  | 1104/1380 [01:48<00:25, 10.94it/s][INFO|trainer.py:755] 2023-11-15 20:32:00,198 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:32:00,200 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:32:00,200 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:32:00,200 >>   Batch size = 8
{'eval_loss': 0.4093973636627197, 'eval_accuracy': 0.8593466424682396, 'eval_micro_f1': 0.8593466424682396, 'eval_macro_f1': 0.8447382400720502, 'eval_runtime': 2.5972, 'eval_samples_per_second': 848.603, 'eval_steps_per_second': 106.268, 'epoch': 3.0}
{'loss': 0.1973, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 121.92it/s][A
  9%|▉         | 26/276 [00:00<00:02, 115.87it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 113.25it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 111.44it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 110.67it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.07it/s][A
 31%|███       | 86/276 [00:00<00:01, 109.45it/s][A
 35%|███▌      | 97/276 [00:00<00:01, 108.88it/s][A
 39%|███▉      | 108/276 [00:00<00:01, 108.09it/s][A
 43%|████▎     | 119/276 [00:01<00:01, 107.78it/s][A
 47%|████▋     | 130/276 [00:01<00:01, 108.04it/s][A
 51%|█████     | 141/276 [00:01<00:01, 107.95it/s][A
 55%|█████▌    | 152/276 [00:01<00:01, 107.90it/s][A
 59%|█████▉    | 163/276 [00:01<00:01, 107.76it/s][A
 63%|██████▎   | 174/276 [00:01<00:00, 107.82it/s][A
 67%|██████▋   | 185/276 [00:01<00:00, 107.48it/s][A
 71%|███████   | 196/276 [00:01<00:00, 107.36it/s][A
 75%|███████▌  | 207/276 [00:01<00:00, 107.08it/s][A
 79%|███████▉  | 218/276 [00:02<00:00, 106.81it/s][A
 83%|████████▎ | 229/276 [00:02<00:00, 106.55it/s][A
 87%|████████▋ | 240/276 [00:02<00:00, 106.68it/s][A
 91%|█████████ | 251/276 [00:02<00:00, 106.78it/s][A
 95%|█████████▍| 262/276 [00:02<00:00, 106.98it/s][A
 99%|█████████▉| 273/276 [00:02<00:00, 106.99it/s][A                                                   
                                                  [A 80%|████████  | 1104/1380 [01:51<00:25, 10.94it/s]
100%|██████████| 276/276 [00:02<00:00, 106.99it/s][A
                                                  [A 80%|████████  | 1105/1380 [01:51<02:11,  2.09it/s] 80%|████████  | 1107/1380 [01:51<01:39,  2.76it/s] 80%|████████  | 1109/1380 [01:51<01:16,  3.55it/s] 81%|████████  | 1111/1380 [01:51<01:00,  4.46it/s] 81%|████████  | 1113/1380 [01:52<00:49,  5.42it/s] 81%|████████  | 1115/1380 [01:52<00:41,  6.37it/s] 81%|████████  | 1117/1380 [01:52<00:36,  7.28it/s] 81%|████████  | 1119/1380 [01:52<00:32,  8.09it/s] 81%|████████  | 1121/1380 [01:52<00:29,  8.77it/s] 81%|████████▏ | 1123/1380 [01:52<00:27,  9.34it/s] 82%|████████▏ | 1125/1380 [01:53<00:26,  9.76it/s] 82%|████████▏ | 1127/1380 [01:53<00:25, 10.09it/s] 82%|████████▏ | 1129/1380 [01:53<00:24, 10.31it/s] 82%|████████▏ | 1131/1380 [01:53<00:23, 10.50it/s] 82%|████████▏ | 1133/1380 [01:53<00:23, 10.64it/s] 82%|████████▏ | 1135/1380 [01:54<00:22, 10.75it/s] 82%|████████▏ | 1137/1380 [01:54<00:22, 10.80it/s] 83%|████████▎ | 1139/1380 [01:54<00:22, 10.84it/s] 83%|████████▎ | 1141/1380 [01:54<00:21, 10.87it/s] 83%|████████▎ | 1143/1380 [01:54<00:21, 10.89it/s] 83%|████████▎ | 1145/1380 [01:54<00:21, 10.90it/s] 83%|████████▎ | 1147/1380 [01:55<00:21, 10.92it/s] 83%|████████▎ | 1149/1380 [01:55<00:21, 10.93it/s] 83%|████████▎ | 1151/1380 [01:55<00:20, 10.92it/s] 84%|████████▎ | 1153/1380 [01:55<00:20, 10.93it/s] 84%|████████▎ | 1155/1380 [01:55<00:20, 10.93it/s] 84%|████████▍ | 1157/1380 [01:56<00:20, 10.94it/s] 84%|████████▍ | 1159/1380 [01:56<00:20, 10.92it/s] 84%|████████▍ | 1161/1380 [01:56<00:20, 10.94it/s] 84%|████████▍ | 1163/1380 [01:56<00:19, 10.96it/s] 84%|████████▍ | 1165/1380 [01:56<00:19, 10.94it/s] 85%|████████▍ | 1167/1380 [01:56<00:19, 10.95it/s] 85%|████████▍ | 1169/1380 [01:57<00:19, 10.96it/s] 85%|████████▍ | 1171/1380 [01:57<00:19, 10.97it/s] 85%|████████▌ | 1173/1380 [01:57<00:18, 10.95it/s] 85%|████████▌ | 1175/1380 [01:57<00:18, 10.94it/s] 85%|████████▌ | 1177/1380 [01:57<00:18, 10.96it/s] 85%|████████▌ | 1179/1380 [01:58<00:18, 10.97it/s] 86%|████████▌ | 1181/1380 [01:58<00:18, 10.95it/s] 86%|████████▌ | 1183/1380 [01:58<00:17, 10.96it/s] 86%|████████▌ | 1185/1380 [01:58<00:17, 10.97it/s] 86%|████████▌ | 1187/1380 [01:58<00:17, 10.96it/s] 86%|████████▌ | 1189/1380 [01:58<00:17, 10.95it/s] 86%|████████▋ | 1191/1380 [01:59<00:17, 10.95it/s] 86%|████████▋ | 1193/1380 [01:59<00:17, 10.96it/s] 87%|████████▋ | 1195/1380 [01:59<00:16, 10.96it/s] 87%|████████▋ | 1197/1380 [01:59<00:16, 10.96it/s] 87%|████████▋ | 1199/1380 [01:59<00:16, 10.97it/s] 87%|████████▋ | 1201/1380 [02:00<00:16, 10.96it/s] 87%|████████▋ | 1203/1380 [02:00<00:16, 10.96it/s] 87%|████████▋ | 1205/1380 [02:00<00:15, 10.95it/s] 87%|████████▋ | 1207/1380 [02:00<00:15, 10.95it/s] 88%|████████▊ | 1209/1380 [02:00<00:15, 10.97it/s] 88%|████████▊ | 1211/1380 [02:01<00:15, 10.96it/s] 88%|████████▊ | 1213/1380 [02:01<00:15, 10.95it/s] 88%|████████▊ | 1215/1380 [02:01<00:15, 10.95it/s] 88%|████████▊ | 1217/1380 [02:01<00:14, 10.95it/s] 88%|████████▊ | 1219/1380 [02:01<00:14, 10.96it/s] 88%|████████▊ | 1221/1380 [02:01<00:14, 10.95it/s] 89%|████████▊ | 1223/1380 [02:02<00:14, 10.96it/s] 89%|████████▉ | 1225/1380 [02:02<00:14, 10.94it/s] 89%|████████▉ | 1227/1380 [02:02<00:13, 10.96it/s] 89%|████████▉ | 1229/1380 [02:02<00:13, 10.96it/s] 89%|████████▉ | 1231/1380 [02:02<00:13, 10.97it/s] 89%|████████▉ | 1233/1380 [02:03<00:13, 10.95it/s] 89%|████████▉ | 1235/1380 [02:03<00:13, 10.95it/s] 90%|████████▉ | 1237/1380 [02:03<00:13, 10.95it/s] 90%|████████▉ | 1239/1380 [02:03<00:12, 10.95it/s] 90%|████████▉ | 1241/1380 [02:03<00:12, 10.95it/s] 90%|█████████ | 1243/1380 [02:03<00:12, 10.95it/s] 90%|█████████ | 1245/1380 [02:04<00:12, 10.94it/s] 90%|█████████ | 1247/1380 [02:04<00:12, 10.94it/s] 91%|█████████ | 1249/1380 [02:04<00:11, 10.94it/s] 91%|█████████ | 1251/1380 [02:04<00:11, 10.94it/s] 91%|█████████ | 1253/1380 [02:04<00:11, 10.96it/s] 91%|█████████ | 1255/1380 [02:05<00:11, 10.96it/s] 91%|█████████ | 1257/1380 [02:05<00:11, 10.95it/s] 91%|█████████ | 1259/1380 [02:05<00:11, 10.96it/s] 91%|█████████▏| 1261/1380 [02:05<00:10, 10.95it/s] 92%|█████████▏| 1263/1380 [02:05<00:10, 10.95it/s] 92%|█████████▏| 1265/1380 [02:05<00:10, 10.95it/s] 92%|█████████▏| 1267/1380 [02:06<00:10, 10.95it/s] 92%|█████████▏| 1269/1380 [02:06<00:10, 10.94it/s] 92%|█████████▏| 1271/1380 [02:06<00:09, 10.96it/s] 92%|█████████▏| 1273/1380 [02:06<00:09, 10.97it/s] 92%|█████████▏| 1275/1380 [02:06<00:09, 10.96it/s] 93%|█████████▎| 1277/1380 [02:07<00:09, 10.95it/s] 93%|█████████▎| 1279/1380 [02:07<00:09, 10.96it/s] 93%|█████████▎| 1281/1380 [02:07<00:09, 10.94it/s] 93%|█████████▎| 1283/1380 [02:07<00:08, 10.95it/s] 93%|█████████▎| 1285/1380 [02:07<00:08, 10.96it/s] 93%|█████████▎| 1287/1380 [02:07<00:08, 10.96it/s] 93%|█████████▎| 1289/1380 [02:08<00:08, 10.96it/s] 94%|█████████▎| 1291/1380 [02:08<00:08, 10.94it/s] 94%|█████████▎| 1293/1380 [02:08<00:07, 10.94it/s] 94%|█████████▍| 1295/1380 [02:08<00:07, 10.95it/s] 94%|█████████▍| 1297/1380 [02:08<00:07, 10.96it/s] 94%|█████████▍| 1299/1380 [02:09<00:07, 10.96it/s] 94%|█████████▍| 1301/1380 [02:09<00:07, 10.97it/s] 94%|█████████▍| 1303/1380 [02:09<00:07, 10.96it/s] 95%|█████████▍| 1305/1380 [02:09<00:06, 10.95it/s] 95%|█████████▍| 1307/1380 [02:09<00:06, 10.94it/s] 95%|█████████▍| 1309/1380 [02:09<00:06, 10.94it/s] 95%|█████████▌| 1311/1380 [02:10<00:06, 10.93it/s] 95%|█████████▌| 1313/1380 [02:10<00:06, 10.92it/s] 95%|█████████▌| 1315/1380 [02:10<00:05, 10.93it/s] 95%|█████████▌| 1317/1380 [02:10<00:05, 10.93it/s] 96%|█████████▌| 1319/1380 [02:10<00:05, 10.94it/s] 96%|█████████▌| 1321/1380 [02:11<00:05, 10.93it/s] 96%|█████████▌| 1323/1380 [02:11<00:05, 10.94it/s] 96%|█████████▌| 1325/1380 [02:11<00:05, 10.94it/s] 96%|█████████▌| 1327/1380 [02:11<00:04, 10.96it/s] 96%|█████████▋| 1329/1380 [02:11<00:04, 10.94it/s] 96%|█████████▋| 1331/1380 [02:11<00:04, 10.95it/s] 97%|█████████▋| 1333/1380 [02:12<00:04, 10.96it/s] 97%|█████████▋| 1335/1380 [02:12<00:04, 10.95it/s] 97%|█████████▋| 1337/1380 [02:12<00:03, 10.95it/s] 97%|█████████▋| 1339/1380 [02:12<00:03, 10.95it/s] 97%|█████████▋| 1341/1380 [02:12<00:03, 10.96it/s] 97%|█████████▋| 1343/1380 [02:13<00:03, 10.93it/s] 97%|█████████▋| 1345/1380 [02:13<00:03, 10.93it/s] 98%|█████████▊| 1347/1380 [02:13<00:03, 10.93it/s] 98%|█████████▊| 1349/1380 [02:13<00:02, 10.93it/s] 98%|█████████▊| 1351/1380 [02:13<00:02, 10.93it/s] 98%|█████████▊| 1353/1380 [02:13<00:02, 10.93it/s] 98%|█████████▊| 1355/1380 [02:14<00:02, 10.95it/s] 98%|█████████▊| 1357/1380 [02:14<00:02, 10.94it/s] 98%|█████████▊| 1359/1380 [02:14<00:01, 10.94it/s] 99%|█████████▊| 1361/1380 [02:14<00:01, 10.94it/s] 99%|█████████▉| 1363/1380 [02:14<00:01, 10.96it/s] 99%|█████████▉| 1365/1380 [02:15<00:01, 10.93it/s] 99%|█████████▉| 1367/1380 [02:15<00:01, 10.93it/s] 99%|█████████▉| 1369/1380 [02:15<00:01, 10.95it/s] 99%|█████████▉| 1371/1380 [02:15<00:00, 10.94it/s] 99%|█████████▉| 1373/1380 [02:15<00:00, 10.93it/s]100%|█████████▉| 1375/1380 [02:15<00:00, 10.93it/s]100%|█████████▉| 1377/1380 [02:16<00:00, 10.94it/s]100%|█████████▉| 1379/1380 [02:16<00:00, 10.94it/s]                                                   100%|██████████| 1380/1380 [02:16<00:00, 10.94it/s][INFO|trainer.py:755] 2023-11-15 20:32:27,995 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:32:27,996 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:32:27,996 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:32:27,997 >>   Batch size = 8
{'eval_loss': 0.451282799243927, 'eval_accuracy': 0.8607078039927405, 'eval_micro_f1': 0.8607078039927405, 'eval_macro_f1': 0.8449848655832399, 'eval_runtime': 2.6026, 'eval_samples_per_second': 846.84, 'eval_steps_per_second': 106.047, 'epoch': 4.0}
{'loss': 0.1397, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 122.56it/s][A
  9%|▉         | 26/276 [00:00<00:02, 115.95it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 113.84it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 112.29it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.09it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.35it/s][A
 31%|███       | 86/276 [00:00<00:01, 109.74it/s][A
 35%|███▌      | 97/276 [00:00<00:01, 108.96it/s][A
 39%|███▉      | 108/276 [00:00<00:01, 108.09it/s][A
 43%|████▎     | 119/276 [00:01<00:01, 107.91it/s][A
 47%|████▋     | 130/276 [00:01<00:01, 108.09it/s][A
 51%|█████     | 141/276 [00:01<00:01, 108.30it/s][A
 55%|█████▌    | 152/276 [00:01<00:01, 108.42it/s][A
 59%|█████▉    | 163/276 [00:01<00:01, 108.21it/s][A
 63%|██████▎   | 174/276 [00:01<00:00, 107.95it/s][A
 67%|██████▋   | 185/276 [00:01<00:00, 107.69it/s][A
 71%|███████   | 196/276 [00:01<00:00, 107.11it/s][A
 75%|███████▌  | 207/276 [00:01<00:00, 106.65it/s][A
 79%|███████▉  | 218/276 [00:02<00:00, 106.32it/s][A
 83%|████████▎ | 229/276 [00:02<00:00, 106.32it/s][A
 87%|████████▋ | 240/276 [00:02<00:00, 106.50it/s][A
 91%|█████████ | 251/276 [00:02<00:00, 106.66it/s][A
 95%|█████████▍| 262/276 [00:02<00:00, 106.76it/s][A
 99%|█████████▉| 273/276 [00:02<00:00, 106.65it/s][A                                                   
                                                  [A100%|██████████| 1380/1380 [02:19<00:00, 10.94it/s]
100%|██████████| 276/276 [00:02<00:00, 106.65it/s][A
                                                  [A[INFO|trainer.py:1963] 2023-11-15 20:32:30,601 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:19<00:00, 10.94it/s]100%|██████████| 1380/1380 [02:19<00:00,  9.93it/s]
[INFO|trainer.py:2855] 2023-11-15 20:32:30,605 >> Saving model checkpoint to ./result/acl_roberta-base_adapter__seed2
[INFO|configuration_utils.py:460] 2023-11-15 20:32:30,608 >> Configuration saved in ./result/acl_roberta-base_adapter__seed2/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:32:31,907 >> Model weights saved in ./result/acl_roberta-base_adapter__seed2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:32:31,910 >> tokenizer config file saved in ./result/acl_roberta-base_adapter__seed2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:32:31,913 >> Special tokens file saved in ./result/acl_roberta-base_adapter__seed2/special_tokens_map.json
{'eval_loss': 0.5283844470977783, 'eval_accuracy': 0.8584392014519057, 'eval_micro_f1': 0.8584392014519057, 'eval_macro_f1': 0.8413761712245891, 'eval_runtime': 2.6002, 'eval_samples_per_second': 847.633, 'eval_steps_per_second': 106.146, 'epoch': 5.0}
{'train_runtime': 139.0241, 'train_samples_per_second': 317.067, 'train_steps_per_second': 9.926, 'train_loss': 0.28333639614823936, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2833
  train_runtime            = 0:02:19.02
  train_samples            =       8816
  train_samples_per_second =    317.067
  train_steps_per_second   =      9.926
11/15/2023 20:32:32 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:32:32,012 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:32:32,013 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:32:32,013 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:32:32,014 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  5%|▍         | 13/276 [00:00<00:02, 121.54it/s]  9%|▉         | 26/276 [00:00<00:02, 113.58it/s] 14%|█▍        | 38/276 [00:00<00:02, 111.16it/s] 18%|█▊        | 50/276 [00:00<00:02, 109.96it/s] 22%|██▏       | 62/276 [00:00<00:01, 109.17it/s] 26%|██▋       | 73/276 [00:00<00:01, 108.65it/s] 30%|███       | 84/276 [00:00<00:01, 108.37it/s] 34%|███▍      | 95/276 [00:00<00:01, 107.97it/s] 38%|███▊      | 106/276 [00:00<00:01, 106.95it/s] 42%|████▏     | 117/276 [00:01<00:01, 106.61it/s] 46%|████▋     | 128/276 [00:01<00:01, 106.72it/s] 50%|█████     | 139/276 [00:01<00:01, 106.99it/s] 54%|█████▍    | 150/276 [00:01<00:01, 106.99it/s] 58%|█████▊    | 161/276 [00:01<00:01, 107.15it/s] 62%|██████▏   | 172/276 [00:01<00:00, 107.27it/s] 66%|██████▋   | 183/276 [00:01<00:00, 107.31it/s] 70%|███████   | 194/276 [00:01<00:00, 107.40it/s] 74%|███████▍  | 205/276 [00:01<00:00, 106.96it/s] 78%|███████▊  | 216/276 [00:02<00:00, 106.47it/s] 82%|████████▏ | 227/276 [00:02<00:00, 106.36it/s] 86%|████████▌ | 238/276 [00:02<00:00, 106.47it/s] 90%|█████████ | 249/276 [00:02<00:00, 106.77it/s] 94%|█████████▍| 260/276 [00:02<00:00, 107.11it/s] 98%|█████████▊| 271/276 [00:02<00:00, 107.33it/s]100%|██████████| 276/276 [00:02<00:00, 106.09it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8584
  eval_loss               =     0.5284
  eval_macro_f1           =     0.8414
  eval_micro_f1           =     0.8584
  eval_runtime            = 0:00:02.61
  eval_samples            =       2204
  eval_samples_per_second =    843.393
  eval_steps_per_second   =    105.615
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁█▆▇▅▅
wandb:                      eval/loss ▁▁▂▄██
wandb:                  eval/macro_f1 ▁███▇▇
wandb:                  eval/micro_f1 ▁█▆▇▅▅
wandb:                   eval/runtime ▁▄▇▇▇█
wandb:        eval/samples_per_second █▅▂▂▂▁
wandb:          eval/steps_per_second █▅▂▂▂▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.85844
wandb:                      eval/loss 0.52838
wandb:                  eval/macro_f1 0.84138
wandb:                  eval/micro_f1 0.85844
wandb:                   eval/runtime 2.6133
wandb:        eval/samples_per_second 843.393
wandb:          eval/steps_per_second 105.615
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1397
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.28334
wandb:            train/train_runtime 139.0241
wandb: train/train_samples_per_second 317.067
wandb:   train/train_steps_per_second 9.926
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_202853-srhxfp6w
wandb: Find logs at: ./wandb/offline-run-20231115_202853-srhxfp6w/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_bert-base-cased_adapter__seed2/runs/Nov15_20-32-44_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_bert-base-cased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_bert-base-cased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:32:44 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:32:44 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_bert-base-cased_adapter__seed2/runs/Nov15_20-32-44_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_bert-base-cased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_bert-base-cased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  37%|███▋      | 4127/11020 [00:00<00:00, 40425.54 examples/s]Map:  76%|███████▌  | 8336/11020 [00:00<00:00, 41388.77 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 40885.47 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:33:00,835 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:33:00,846 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 20:33:10,862 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:33:10,863 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:33:10,866 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:33:10,866 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:33:10,866 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:33:10,866 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:33:10,867 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 20:33:10,868 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:33:10,868 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:33:31,051 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:33:31,714 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:33:31,716 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  23%|██▎       | 2000/8816 [00:00<00:00, 18159.48 examples/s]Running tokenizer on dataset:  68%|██████▊   | 6000/8816 [00:00<00:00, 19608.72 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 19626.93 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 19408.01 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 21585.74 examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 21244.84 examples/s]
11/15/2023 20:33:32 - INFO - __main__ - Sample 5747 of the training set: {'text': 'While the redox buffer pairs (e.g. GSH/GSSG, reduced PC/oxidised PC, and reduced Protein/oxidised Protein) can protect cells from oxidative damage (Tsuji et al., 2002), this produces an imbalance in the redox status that may lead to other unwanted effects such as changes in intracellular pH, which…', 'label': 0, 'input_ids': [101, 1799, 1103, 1894, 10649, 20232, 7608, 113, 174, 119, 176, 119, 144, 1708, 3048, 120, 144, 12480, 2349, 117, 3549, 7054, 120, 184, 8745, 10396, 1174, 7054, 117, 1105, 3549, 5096, 7242, 120, 184, 8745, 10396, 1174, 5096, 7242, 114, 1169, 3244, 3652, 1121, 184, 8745, 1810, 3946, 3290, 113, 157, 6385, 3454, 3084, 2393, 119, 117, 1617, 114, 117, 1142, 6570, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 20:33:32 - INFO - __main__ - Sample 5785 of the training set: {'text': 'BDNF has been shown to interact with several neurotrans-\nmitter systems, including the DA (Spenger et al., 1995), serotonin (5-HT) (Lyons et al., 1999; Rumajogee et al., 2002), and NPY systems (Barnea and Roberts, 2001; Nawa et al., 1993, 1994).', 'label': 0, 'input_ids': [101, 139, 2137, 28047, 1144, 1151, 2602, 1106, 12254, 1114, 1317, 24928, 11955, 4487, 2316, 118, 26410, 2083, 2344, 117, 1259, 1103, 141, 1592, 113, 156, 11741, 2895, 3084, 2393, 119, 117, 1876, 114, 117, 14516, 10595, 11153, 1179, 113, 126, 118, 145, 1942, 114, 113, 17728, 3084, 2393, 119, 117, 1729, 132, 155, 10161, 5077, 15762, 3084, 2393, 119, 117, 1617, 114, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 20:33:32 - INFO - __main__ - Sample 3534 of the training set: {'text': 'Studies have shown that alcohol consumption may contribute to the spread of HIV/AIDS by diminishing sexual inhibitions and interfering with one’s ability to adequately assess risk (Gordon et al. 1997; MacDonald et al. 2000a, b; Maisto et al. 2004).', 'label': 0, 'input_ids': [101, 3829, 1138, 2602, 1115, 6272, 8160, 1336, 8681, 1106, 1103, 2819, 1104, 9622, 120, 9837, 1118, 12563, 4729, 12802, 3785, 1107, 16485, 1116, 1105, 27666, 1114, 1141, 787, 188, 2912, 1106, 26449, 15187, 3187, 113, 4345, 3084, 2393, 119, 1816, 132, 14023, 3084, 2393, 119, 1539, 1161, 117, 171, 132, 17551, 12223, 3084, 2393, 119, 1516, 114, 119, 102, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]}.
11/15/2023 20:33:32 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:33:33,527 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:33:33,535 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:33:33,536 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 20:33:33,536 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:33:33,536 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:33:33,537 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:33:33,537 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:33:33,537 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 20:33:33,538 >>   Number of trainable parameters = 108,312,579
[INFO|integration_utils.py:716] 2023-11-15 20:33:33,539 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<28:06,  1.22s/it]  0%|          | 3/1380 [00:01<08:47,  2.61it/s]  0%|          | 5/1380 [00:01<05:20,  4.29it/s]  1%|          | 7/1380 [00:01<03:56,  5.80it/s]  1%|          | 9/1380 [00:01<03:14,  7.06it/s]  1%|          | 11/1380 [00:02<02:49,  8.08it/s]  1%|          | 13/1380 [00:02<02:34,  8.87it/s]  1%|          | 15/1380 [00:02<02:24,  9.46it/s]  1%|          | 17/1380 [00:02<02:17,  9.91it/s]  1%|▏         | 19/1380 [00:02<02:12, 10.24it/s]  2%|▏         | 21/1380 [00:03<02:09, 10.46it/s]  2%|▏         | 23/1380 [00:03<02:07, 10.63it/s]  2%|▏         | 25/1380 [00:03<02:05, 10.76it/s]  2%|▏         | 27/1380 [00:03<02:04, 10.88it/s]  2%|▏         | 29/1380 [00:03<02:03, 10.97it/s]  2%|▏         | 31/1380 [00:03<02:02, 11.00it/s]  2%|▏         | 33/1380 [00:04<02:02, 11.03it/s]  3%|▎         | 35/1380 [00:04<02:01, 11.05it/s]  3%|▎         | 37/1380 [00:04<02:01, 11.07it/s]  3%|▎         | 39/1380 [00:04<02:01, 11.05it/s]  3%|▎         | 41/1380 [00:04<02:00, 11.07it/s]  3%|▎         | 43/1380 [00:05<02:00, 11.08it/s]  3%|▎         | 45/1380 [00:05<02:00, 11.09it/s]  3%|▎         | 47/1380 [00:05<02:00, 11.08it/s]  4%|▎         | 49/1380 [00:05<02:00, 11.09it/s]  4%|▎         | 51/1380 [00:05<01:59, 11.12it/s]  4%|▍         | 53/1380 [00:05<01:59, 11.14it/s]  4%|▍         | 55/1380 [00:06<01:58, 11.15it/s]  4%|▍         | 57/1380 [00:06<01:58, 11.15it/s]  4%|▍         | 59/1380 [00:06<01:58, 11.15it/s]  4%|▍         | 61/1380 [00:06<01:58, 11.16it/s]  5%|▍         | 63/1380 [00:06<01:57, 11.16it/s]  5%|▍         | 65/1380 [00:06<01:57, 11.18it/s]  5%|▍         | 67/1380 [00:07<01:57, 11.17it/s]  5%|▌         | 69/1380 [00:07<01:57, 11.16it/s]  5%|▌         | 71/1380 [00:07<01:57, 11.18it/s]  5%|▌         | 73/1380 [00:07<01:57, 11.15it/s]  5%|▌         | 75/1380 [00:07<01:56, 11.16it/s]  6%|▌         | 77/1380 [00:08<01:57, 11.13it/s]  6%|▌         | 79/1380 [00:08<01:56, 11.14it/s]  6%|▌         | 81/1380 [00:08<01:56, 11.16it/s]  6%|▌         | 83/1380 [00:08<01:56, 11.17it/s]  6%|▌         | 85/1380 [00:08<01:56, 11.14it/s]  6%|▋         | 87/1380 [00:08<01:56, 11.13it/s]  6%|▋         | 89/1380 [00:09<01:56, 11.13it/s]  7%|▋         | 91/1380 [00:09<01:55, 11.13it/s]  7%|▋         | 93/1380 [00:09<01:55, 11.14it/s]  7%|▋         | 95/1380 [00:09<01:55, 11.14it/s]  7%|▋         | 97/1380 [00:09<01:55, 11.14it/s]  7%|▋         | 99/1380 [00:10<01:55, 11.13it/s]  7%|▋         | 101/1380 [00:10<01:54, 11.13it/s]  7%|▋         | 103/1380 [00:10<01:54, 11.13it/s]  8%|▊         | 105/1380 [00:10<01:54, 11.13it/s]  8%|▊         | 107/1380 [00:10<01:54, 11.12it/s]  8%|▊         | 109/1380 [00:10<01:54, 11.12it/s]  8%|▊         | 111/1380 [00:11<01:54, 11.13it/s]  8%|▊         | 113/1380 [00:11<01:53, 11.14it/s]  8%|▊         | 115/1380 [00:11<01:53, 11.13it/s]  8%|▊         | 117/1380 [00:11<01:53, 11.15it/s]  9%|▊         | 119/1380 [00:11<01:53, 11.11it/s]  9%|▉         | 121/1380 [00:12<01:53, 11.11it/s]  9%|▉         | 123/1380 [00:12<01:53, 11.10it/s]  9%|▉         | 125/1380 [00:12<01:53, 11.10it/s]  9%|▉         | 127/1380 [00:12<01:52, 11.10it/s]  9%|▉         | 129/1380 [00:12<01:52, 11.08it/s]  9%|▉         | 131/1380 [00:12<01:52, 11.07it/s] 10%|▉         | 133/1380 [00:13<01:52, 11.09it/s] 10%|▉         | 135/1380 [00:13<01:52, 11.11it/s] 10%|▉         | 137/1380 [00:13<01:52, 11.10it/s] 10%|█         | 139/1380 [00:13<01:51, 11.11it/s] 10%|█         | 141/1380 [00:13<01:51, 11.12it/s] 10%|█         | 143/1380 [00:13<01:50, 11.15it/s] 11%|█         | 145/1380 [00:14<01:50, 11.17it/s] 11%|█         | 147/1380 [00:14<01:50, 11.15it/s] 11%|█         | 149/1380 [00:14<01:50, 11.16it/s] 11%|█         | 151/1380 [00:14<01:50, 11.13it/s] 11%|█         | 153/1380 [00:14<01:50, 11.14it/s] 11%|█         | 155/1380 [00:15<01:49, 11.15it/s] 11%|█▏        | 157/1380 [00:15<01:49, 11.14it/s] 12%|█▏        | 159/1380 [00:15<01:49, 11.14it/s] 12%|█▏        | 161/1380 [00:15<01:49, 11.13it/s] 12%|█▏        | 163/1380 [00:15<01:49, 11.13it/s] 12%|█▏        | 165/1380 [00:15<01:49, 11.13it/s] 12%|█▏        | 167/1380 [00:16<01:49, 11.12it/s] 12%|█▏        | 169/1380 [00:16<01:49, 11.08it/s] 12%|█▏        | 171/1380 [00:16<01:49, 11.08it/s] 13%|█▎        | 173/1380 [00:16<01:49, 11.07it/s] 13%|█▎        | 175/1380 [00:16<01:48, 11.07it/s] 13%|█▎        | 177/1380 [00:17<01:48, 11.08it/s] 13%|█▎        | 179/1380 [00:17<01:48, 11.10it/s] 13%|█▎        | 181/1380 [00:17<01:47, 11.12it/s] 13%|█▎        | 183/1380 [00:17<01:48, 11.08it/s] 13%|█▎        | 185/1380 [00:17<01:47, 11.08it/s] 14%|█▎        | 187/1380 [00:17<01:47, 11.10it/s] 14%|█▎        | 189/1380 [00:18<01:47, 11.10it/s] 14%|█▍        | 191/1380 [00:18<01:47, 11.09it/s] 14%|█▍        | 193/1380 [00:18<01:46, 11.10it/s] 14%|█▍        | 195/1380 [00:18<01:46, 11.10it/s] 14%|█▍        | 197/1380 [00:18<01:46, 11.11it/s] 14%|█▍        | 199/1380 [00:19<01:46, 11.10it/s] 15%|█▍        | 201/1380 [00:19<01:46, 11.09it/s] 15%|█▍        | 203/1380 [00:19<01:45, 11.11it/s] 15%|█▍        | 205/1380 [00:19<01:45, 11.11it/s] 15%|█▌        | 207/1380 [00:19<01:45, 11.12it/s] 15%|█▌        | 209/1380 [00:19<01:45, 11.12it/s] 15%|█▌        | 211/1380 [00:20<01:44, 11.14it/s] 15%|█▌        | 213/1380 [00:20<01:44, 11.13it/s] 16%|█▌        | 215/1380 [00:20<01:44, 11.13it/s] 16%|█▌        | 217/1380 [00:20<01:44, 11.11it/s] 16%|█▌        | 219/1380 [00:20<01:44, 11.11it/s] 16%|█▌        | 221/1380 [00:21<01:44, 11.12it/s] 16%|█▌        | 223/1380 [00:21<01:44, 11.11it/s] 16%|█▋        | 225/1380 [00:21<01:43, 11.15it/s] 16%|█▋        | 227/1380 [00:21<01:43, 11.12it/s] 17%|█▋        | 229/1380 [00:21<01:43, 11.12it/s] 17%|█▋        | 231/1380 [00:21<01:43, 11.12it/s] 17%|█▋        | 233/1380 [00:22<01:43, 11.11it/s] 17%|█▋        | 235/1380 [00:22<01:43, 11.10it/s] 17%|█▋        | 237/1380 [00:22<01:43, 11.07it/s] 17%|█▋        | 239/1380 [00:22<01:42, 11.11it/s] 17%|█▋        | 241/1380 [00:22<01:42, 11.12it/s] 18%|█▊        | 243/1380 [00:22<01:42, 11.08it/s] 18%|█▊        | 245/1380 [00:23<01:42, 11.09it/s] 18%|█▊        | 247/1380 [00:23<01:42, 11.08it/s] 18%|█▊        | 249/1380 [00:23<01:41, 11.11it/s] 18%|█▊        | 251/1380 [00:23<01:41, 11.07it/s] 18%|█▊        | 253/1380 [00:23<01:41, 11.09it/s] 18%|█▊        | 255/1380 [00:24<01:41, 11.07it/s] 19%|█▊        | 257/1380 [00:24<01:41, 11.08it/s] 19%|█▉        | 259/1380 [00:24<01:41, 11.08it/s] 19%|█▉        | 261/1380 [00:24<01:40, 11.10it/s] 19%|█▉        | 263/1380 [00:24<01:40, 11.09it/s] 19%|█▉        | 265/1380 [00:24<01:40, 11.09it/s] 19%|█▉        | 267/1380 [00:25<01:40, 11.07it/s] 19%|█▉        | 269/1380 [00:25<01:40, 11.09it/s] 20%|█▉        | 271/1380 [00:25<01:39, 11.10it/s] 20%|█▉        | 273/1380 [00:25<01:39, 11.08it/s] 20%|█▉        | 275/1380 [00:25<01:39, 11.10it/s]                                                   20%|██        | 276/1380 [00:25<01:39, 11.10it/s][INFO|trainer.py:755] 2023-11-15 20:33:59,491 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:33:59,493 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:33:59,493 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:33:59,493 >>   Batch size = 8
{'loss': 0.5181, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 120.27it/s][A
  9%|▉         | 26/276 [00:00<00:02, 114.74it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 112.46it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 111.29it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 109.52it/s][A
 26%|██▋       | 73/276 [00:00<00:01, 108.70it/s][A
 30%|███       | 84/276 [00:00<00:01, 107.94it/s][A
 34%|███▍      | 95/276 [00:00<00:01, 107.73it/s][A
 38%|███▊      | 106/276 [00:00<00:01, 107.20it/s][A
 42%|████▏     | 117/276 [00:01<00:01, 106.23it/s][A
 46%|████▋     | 128/276 [00:01<00:01, 106.41it/s][A
 50%|█████     | 139/276 [00:01<00:01, 106.70it/s][A
 54%|█████▍    | 150/276 [00:01<00:01, 107.38it/s][A
 58%|█████▊    | 161/276 [00:01<00:01, 107.26it/s][A
 62%|██████▏   | 172/276 [00:01<00:00, 107.86it/s][A
 66%|██████▋   | 183/276 [00:01<00:00, 107.60it/s][A
 70%|███████   | 194/276 [00:01<00:00, 107.87it/s][A
 74%|███████▍  | 205/276 [00:01<00:00, 107.61it/s][A
 78%|███████▊  | 216/276 [00:01<00:00, 107.25it/s][A
 82%|████████▏ | 227/276 [00:02<00:00, 107.34it/s][A
 86%|████████▌ | 238/276 [00:02<00:00, 107.00it/s][A
 90%|█████████ | 249/276 [00:02<00:00, 107.39it/s][A
 94%|█████████▍| 260/276 [00:02<00:00, 107.26it/s][A
 98%|█████████▊| 271/276 [00:02<00:00, 107.48it/s][A                                                  
                                                  [A 20%|██        | 276/1380 [00:28<01:39, 11.10it/s]
100%|██████████| 276/276 [00:02<00:00, 107.48it/s][A
                                                  [A 20%|██        | 277/1380 [00:28<08:48,  2.09it/s] 20%|██        | 279/1380 [00:28<06:39,  2.76it/s] 20%|██        | 281/1380 [00:29<05:09,  3.56it/s] 21%|██        | 283/1380 [00:29<04:05,  4.47it/s] 21%|██        | 285/1380 [00:29<03:21,  5.43it/s] 21%|██        | 287/1380 [00:29<02:50,  6.42it/s] 21%|██        | 289/1380 [00:29<02:28,  7.33it/s] 21%|██        | 291/1380 [00:29<02:13,  8.16it/s] 21%|██        | 293/1380 [00:30<02:02,  8.86it/s] 21%|██▏       | 295/1380 [00:30<01:54,  9.44it/s] 22%|██▏       | 297/1380 [00:30<01:49,  9.88it/s] 22%|██▏       | 299/1380 [00:30<01:46, 10.18it/s] 22%|██▏       | 301/1380 [00:30<01:43, 10.42it/s] 22%|██▏       | 303/1380 [00:31<01:41, 10.58it/s] 22%|██▏       | 305/1380 [00:31<01:40, 10.75it/s] 22%|██▏       | 307/1380 [00:31<01:38, 10.84it/s] 22%|██▏       | 309/1380 [00:31<01:38, 10.91it/s] 23%|██▎       | 311/1380 [00:31<01:37, 10.96it/s] 23%|██▎       | 313/1380 [00:31<01:37, 10.94it/s] 23%|██▎       | 315/1380 [00:32<01:36, 11.02it/s] 23%|██▎       | 317/1380 [00:32<01:36, 11.06it/s] 23%|██▎       | 319/1380 [00:32<01:35, 11.08it/s] 23%|██▎       | 321/1380 [00:32<01:35, 11.08it/s] 23%|██▎       | 323/1380 [00:32<01:35, 11.09it/s] 24%|██▎       | 325/1380 [00:32<01:34, 11.11it/s] 24%|██▎       | 327/1380 [00:33<01:34, 11.11it/s] 24%|██▍       | 329/1380 [00:33<01:34, 11.10it/s] 24%|██▍       | 331/1380 [00:33<01:34, 11.11it/s] 24%|██▍       | 333/1380 [00:33<01:34, 11.10it/s] 24%|██▍       | 335/1380 [00:33<01:34, 11.10it/s] 24%|██▍       | 337/1380 [00:34<01:34, 11.10it/s] 25%|██▍       | 339/1380 [00:34<01:33, 11.08it/s] 25%|██▍       | 341/1380 [00:34<01:33, 11.06it/s] 25%|██▍       | 343/1380 [00:34<01:34, 11.02it/s] 25%|██▌       | 345/1380 [00:34<01:33, 11.03it/s] 25%|██▌       | 347/1380 [00:34<01:33, 11.04it/s] 25%|██▌       | 349/1380 [00:35<01:33, 11.05it/s] 25%|██▌       | 351/1380 [00:35<01:33, 11.06it/s] 26%|██▌       | 353/1380 [00:35<01:32, 11.05it/s] 26%|██▌       | 355/1380 [00:35<01:32, 11.09it/s] 26%|██▌       | 357/1380 [00:35<01:32, 11.09it/s] 26%|██▌       | 359/1380 [00:36<01:32, 11.07it/s] 26%|██▌       | 361/1380 [00:36<01:31, 11.08it/s] 26%|██▋       | 363/1380 [00:36<01:31, 11.07it/s] 26%|██▋       | 365/1380 [00:36<01:31, 11.10it/s] 27%|██▋       | 367/1380 [00:36<01:31, 11.10it/s] 27%|██▋       | 369/1380 [00:36<01:31, 11.10it/s] 27%|██▋       | 371/1380 [00:37<01:30, 11.09it/s] 27%|██▋       | 373/1380 [00:37<01:30, 11.09it/s] 27%|██▋       | 375/1380 [00:37<01:30, 11.08it/s] 27%|██▋       | 377/1380 [00:37<01:30, 11.08it/s] 27%|██▋       | 379/1380 [00:37<01:30, 11.07it/s] 28%|██▊       | 381/1380 [00:38<01:30, 11.04it/s] 28%|██▊       | 383/1380 [00:38<01:30, 11.06it/s] 28%|██▊       | 385/1380 [00:38<01:29, 11.07it/s] 28%|██▊       | 387/1380 [00:38<01:29, 11.05it/s] 28%|██▊       | 389/1380 [00:38<01:29, 11.05it/s] 28%|██▊       | 391/1380 [00:38<01:29, 11.07it/s] 28%|██▊       | 393/1380 [00:39<01:29, 11.09it/s] 29%|██▊       | 395/1380 [00:39<01:28, 11.10it/s] 29%|██▉       | 397/1380 [00:39<01:28, 11.07it/s] 29%|██▉       | 399/1380 [00:39<01:28, 11.05it/s] 29%|██▉       | 401/1380 [00:39<01:28, 11.04it/s] 29%|██▉       | 403/1380 [00:40<01:28, 11.02it/s] 29%|██▉       | 405/1380 [00:40<01:28, 11.04it/s] 29%|██▉       | 407/1380 [00:40<01:27, 11.06it/s] 30%|██▉       | 409/1380 [00:40<01:27, 11.09it/s] 30%|██▉       | 411/1380 [00:40<01:27, 11.03it/s] 30%|██▉       | 413/1380 [00:40<01:27, 11.07it/s] 30%|███       | 415/1380 [00:41<01:27, 11.07it/s] 30%|███       | 417/1380 [00:41<01:26, 11.07it/s] 30%|███       | 419/1380 [00:41<01:27, 11.04it/s] 31%|███       | 421/1380 [00:41<01:26, 11.05it/s] 31%|███       | 423/1380 [00:41<01:26, 11.07it/s] 31%|███       | 425/1380 [00:42<01:26, 11.03it/s] 31%|███       | 427/1380 [00:42<01:26, 11.05it/s] 31%|███       | 429/1380 [00:42<01:25, 11.06it/s] 31%|███       | 431/1380 [00:42<01:25, 11.07it/s] 31%|███▏      | 433/1380 [00:42<01:25, 11.06it/s] 32%|███▏      | 435/1380 [00:42<01:25, 11.08it/s] 32%|███▏      | 437/1380 [00:43<01:25, 11.06it/s] 32%|███▏      | 439/1380 [00:43<01:24, 11.07it/s] 32%|███▏      | 441/1380 [00:43<01:25, 10.94it/s] 32%|███▏      | 443/1380 [00:43<01:24, 11.05it/s] 32%|███▏      | 445/1380 [00:43<01:24, 11.07it/s] 32%|███▏      | 447/1380 [00:44<01:24, 11.06it/s] 33%|███▎      | 449/1380 [00:44<01:24, 11.02it/s] 33%|███▎      | 451/1380 [00:44<01:23, 11.08it/s] 33%|███▎      | 453/1380 [00:44<01:23, 11.08it/s] 33%|███▎      | 455/1380 [00:44<01:23, 11.04it/s] 33%|███▎      | 457/1380 [00:44<01:23, 11.03it/s] 33%|███▎      | 459/1380 [00:45<01:23, 11.04it/s] 33%|███▎      | 461/1380 [00:45<01:23, 11.06it/s] 34%|███▎      | 463/1380 [00:45<01:22, 11.06it/s] 34%|███▎      | 465/1380 [00:45<01:22, 11.06it/s] 34%|███▍      | 467/1380 [00:45<01:22, 11.06it/s] 34%|███▍      | 469/1380 [00:46<01:22, 11.07it/s] 34%|███▍      | 471/1380 [00:46<01:22, 10.99it/s] 34%|███▍      | 473/1380 [00:46<01:22, 11.05it/s] 34%|███▍      | 475/1380 [00:46<01:21, 11.06it/s] 35%|███▍      | 477/1380 [00:46<01:21, 11.06it/s] 35%|███▍      | 479/1380 [00:46<01:21, 11.05it/s] 35%|███▍      | 481/1380 [00:47<01:21, 11.06it/s] 35%|███▌      | 483/1380 [00:47<01:21, 11.06it/s] 35%|███▌      | 485/1380 [00:47<01:21, 11.04it/s] 35%|███▌      | 487/1380 [00:47<01:20, 11.03it/s] 35%|███▌      | 489/1380 [00:47<01:20, 11.06it/s] 36%|███▌      | 491/1380 [00:48<01:20, 11.07it/s] 36%|███▌      | 493/1380 [00:48<01:20, 11.09it/s] 36%|███▌      | 495/1380 [00:48<01:19, 11.08it/s] 36%|███▌      | 497/1380 [00:48<01:19, 11.08it/s] 36%|███▌      | 499/1380 [00:48<01:19, 11.04it/s] 36%|███▋      | 501/1380 [00:48<01:19, 11.03it/s] 36%|███▋      | 503/1380 [00:49<01:19, 11.00it/s] 37%|███▋      | 505/1380 [00:49<01:19, 11.04it/s] 37%|███▋      | 507/1380 [00:49<01:18, 11.05it/s] 37%|███▋      | 509/1380 [00:49<01:18, 11.04it/s] 37%|███▋      | 511/1380 [00:49<01:18, 11.05it/s] 37%|███▋      | 513/1380 [00:49<01:18, 11.03it/s] 37%|███▋      | 515/1380 [00:50<01:18, 11.02it/s] 37%|███▋      | 517/1380 [00:50<01:18, 11.00it/s] 38%|███▊      | 519/1380 [00:50<01:18, 11.03it/s] 38%|███▊      | 521/1380 [00:50<01:17, 11.04it/s] 38%|███▊      | 523/1380 [00:50<01:17, 11.05it/s] 38%|███▊      | 525/1380 [00:51<01:17, 11.05it/s] 38%|███▊      | 527/1380 [00:51<01:17, 11.06it/s] 38%|███▊      | 529/1380 [00:51<01:16, 11.06it/s] 38%|███▊      | 531/1380 [00:51<01:16, 11.06it/s] 39%|███▊      | 533/1380 [00:51<01:16, 11.04it/s] 39%|███▉      | 535/1380 [00:51<01:16, 11.03it/s] 39%|███▉      | 537/1380 [00:52<01:16, 11.04it/s] 39%|███▉      | 539/1380 [00:52<01:16, 11.04it/s] 39%|███▉      | 541/1380 [00:52<01:15, 11.04it/s] 39%|███▉      | 543/1380 [00:52<01:15, 11.04it/s] 39%|███▉      | 545/1380 [00:52<01:15, 11.03it/s] 40%|███▉      | 547/1380 [00:53<01:15, 11.00it/s] 40%|███▉      | 549/1380 [00:53<01:15, 11.03it/s] 40%|███▉      | 551/1380 [00:53<01:14, 11.07it/s]                                                   40%|████      | 552/1380 [00:53<01:14, 11.07it/s][INFO|trainer.py:755] 2023-11-15 20:34:27,045 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:34:27,047 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:34:27,047 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:34:27,047 >>   Batch size = 8
{'eval_loss': 0.4360584318637848, 'eval_accuracy': 0.838475499092559, 'eval_micro_f1': 0.8384754990925591, 'eval_macro_f1': 0.8114567736645717, 'eval_runtime': 2.6155, 'eval_samples_per_second': 842.653, 'eval_steps_per_second': 105.523, 'epoch': 1.0}
{'loss': 0.3224, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 121.42it/s][A
  9%|▉         | 26/276 [00:00<00:02, 113.42it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 111.86it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 109.27it/s][A
 22%|██▏       | 61/276 [00:00<00:01, 109.25it/s][A
 26%|██▌       | 72/276 [00:00<00:01, 108.25it/s][A
 30%|███       | 83/276 [00:00<00:01, 108.13it/s][A
 34%|███▍      | 94/276 [00:00<00:01, 107.41it/s][A
 38%|███▊      | 105/276 [00:00<00:01, 106.91it/s][A
 42%|████▏     | 116/276 [00:01<00:01, 106.27it/s][A
 46%|████▌     | 127/276 [00:01<00:01, 106.01it/s][A
 50%|█████     | 138/276 [00:01<00:01, 106.29it/s][A
 54%|█████▍    | 149/276 [00:01<00:01, 106.15it/s][A
 58%|█████▊    | 160/276 [00:01<00:01, 105.93it/s][A
 62%|██████▏   | 171/276 [00:01<00:00, 105.74it/s][A
 66%|██████▌   | 182/276 [00:01<00:00, 106.04it/s][A
 70%|██████▉   | 193/276 [00:01<00:00, 105.72it/s][A
 74%|███████▍  | 204/276 [00:01<00:00, 105.62it/s][A
 78%|███████▊  | 215/276 [00:02<00:00, 105.04it/s][A
 82%|████████▏ | 226/276 [00:02<00:00, 105.36it/s][A
 86%|████████▌ | 237/276 [00:02<00:00, 105.10it/s][A
 90%|████████▉ | 248/276 [00:02<00:00, 105.61it/s][A
 94%|█████████▍| 259/276 [00:02<00:00, 105.08it/s][A
 98%|█████████▊| 270/276 [00:02<00:00, 105.75it/s][A                                                  
                                                  [A 40%|████      | 552/1380 [00:56<01:14, 11.07it/s]
100%|██████████| 276/276 [00:02<00:00, 105.75it/s][A
                                                  [A 40%|████      | 553/1380 [00:56<06:39,  2.07it/s] 40%|████      | 555/1380 [00:56<05:01,  2.73it/s] 40%|████      | 557/1380 [00:56<03:53,  3.53it/s] 41%|████      | 559/1380 [00:56<03:05,  4.43it/s] 41%|████      | 561/1380 [00:56<02:31,  5.41it/s] 41%|████      | 563/1380 [00:57<02:08,  6.38it/s] 41%|████      | 565/1380 [00:57<01:51,  7.31it/s] 41%|████      | 567/1380 [00:57<01:39,  8.13it/s] 41%|████      | 569/1380 [00:57<01:31,  8.84it/s] 41%|████▏     | 571/1380 [00:57<01:26,  9.40it/s] 42%|████▏     | 573/1380 [00:58<01:21,  9.85it/s] 42%|████▏     | 575/1380 [00:58<01:19, 10.17it/s] 42%|████▏     | 577/1380 [00:58<01:17, 10.42it/s] 42%|████▏     | 579/1380 [00:58<01:15, 10.61it/s] 42%|████▏     | 581/1380 [00:58<01:14, 10.68it/s] 42%|████▏     | 583/1380 [00:58<01:13, 10.83it/s] 42%|████▏     | 585/1380 [00:59<01:13, 10.88it/s] 43%|████▎     | 587/1380 [00:59<01:12, 10.93it/s] 43%|████▎     | 589/1380 [00:59<01:12, 10.96it/s] 43%|████▎     | 591/1380 [00:59<01:11, 10.98it/s] 43%|████▎     | 593/1380 [00:59<01:11, 11.01it/s] 43%|████▎     | 595/1380 [01:00<01:11, 11.01it/s] 43%|████▎     | 597/1380 [01:00<01:11, 11.00it/s] 43%|████▎     | 599/1380 [01:00<01:10, 11.01it/s] 44%|████▎     | 601/1380 [01:00<01:10, 11.04it/s] 44%|████▎     | 603/1380 [01:00<01:10, 11.05it/s] 44%|████▍     | 605/1380 [01:00<01:10, 11.05it/s] 44%|████▍     | 607/1380 [01:01<01:09, 11.04it/s] 44%|████▍     | 609/1380 [01:01<01:09, 11.04it/s] 44%|████▍     | 611/1380 [01:01<01:09, 11.02it/s] 44%|████▍     | 613/1380 [01:01<01:09, 11.01it/s] 45%|████▍     | 615/1380 [01:01<01:09, 11.02it/s] 45%|████▍     | 617/1380 [01:02<01:09, 11.04it/s] 45%|████▍     | 619/1380 [01:02<01:08, 11.04it/s] 45%|████▌     | 621/1380 [01:02<01:08, 11.06it/s] 45%|████▌     | 623/1380 [01:02<01:08, 11.06it/s] 45%|████▌     | 625/1380 [01:02<01:08, 11.05it/s] 45%|████▌     | 627/1380 [01:02<01:08, 11.03it/s] 46%|████▌     | 629/1380 [01:03<01:08, 11.04it/s] 46%|████▌     | 631/1380 [01:03<01:07, 11.05it/s] 46%|████▌     | 633/1380 [01:03<01:07, 11.05it/s] 46%|████▌     | 635/1380 [01:03<01:07, 11.04it/s] 46%|████▌     | 637/1380 [01:03<01:07, 11.06it/s] 46%|████▋     | 639/1380 [01:04<01:06, 11.06it/s] 46%|████▋     | 641/1380 [01:04<01:06, 11.06it/s] 47%|████▋     | 643/1380 [01:04<01:06, 11.07it/s] 47%|████▋     | 645/1380 [01:04<01:06, 11.06it/s] 47%|████▋     | 647/1380 [01:04<01:06, 11.06it/s] 47%|████▋     | 649/1380 [01:04<01:06, 11.06it/s] 47%|████▋     | 651/1380 [01:05<01:05, 11.05it/s] 47%|████▋     | 653/1380 [01:05<01:05, 11.06it/s] 47%|████▋     | 655/1380 [01:05<01:05, 11.04it/s] 48%|████▊     | 657/1380 [01:05<01:05, 11.03it/s] 48%|████▊     | 659/1380 [01:05<01:05, 11.03it/s] 48%|████▊     | 661/1380 [01:06<01:05, 11.03it/s] 48%|████▊     | 663/1380 [01:06<01:05, 11.03it/s] 48%|████▊     | 665/1380 [01:06<01:04, 11.03it/s] 48%|████▊     | 667/1380 [01:06<01:04, 11.04it/s] 48%|████▊     | 669/1380 [01:06<01:04, 11.04it/s] 49%|████▊     | 671/1380 [01:06<01:04, 11.04it/s] 49%|████▉     | 673/1380 [01:07<01:04, 11.04it/s] 49%|████▉     | 675/1380 [01:07<01:03, 11.07it/s] 49%|████▉     | 677/1380 [01:07<01:03, 11.08it/s] 49%|████▉     | 679/1380 [01:07<01:03, 11.07it/s] 49%|████▉     | 681/1380 [01:07<01:03, 11.06it/s] 49%|████▉     | 683/1380 [01:08<01:03, 11.05it/s] 50%|████▉     | 685/1380 [01:08<01:02, 11.04it/s] 50%|████▉     | 687/1380 [01:08<01:02, 11.06it/s] 50%|████▉     | 689/1380 [01:08<01:02, 11.05it/s] 50%|█████     | 691/1380 [01:08<01:02, 11.05it/s] 50%|█████     | 693/1380 [01:08<01:02, 11.05it/s] 50%|█████     | 695/1380 [01:09<01:02, 11.04it/s] 51%|█████     | 697/1380 [01:09<01:01, 11.06it/s] 51%|█████     | 699/1380 [01:09<01:01, 11.06it/s] 51%|█████     | 701/1380 [01:09<01:01, 11.05it/s] 51%|█████     | 703/1380 [01:09<01:01, 11.02it/s] 51%|█████     | 705/1380 [01:10<01:01, 11.02it/s] 51%|█████     | 707/1380 [01:10<01:01, 11.03it/s] 51%|█████▏    | 709/1380 [01:10<01:00, 11.04it/s] 52%|█████▏    | 711/1380 [01:10<01:01, 10.96it/s] 52%|█████▏    | 713/1380 [01:10<01:01, 10.92it/s] 52%|█████▏    | 715/1380 [01:10<01:00, 10.95it/s] 52%|█████▏    | 717/1380 [01:11<01:00, 10.98it/s] 52%|█████▏    | 719/1380 [01:11<01:00, 10.92it/s] 52%|█████▏    | 721/1380 [01:11<01:00, 10.96it/s] 52%|█████▏    | 723/1380 [01:11<00:59, 10.99it/s] 53%|█████▎    | 725/1380 [01:11<00:59, 11.00it/s] 53%|█████▎    | 727/1380 [01:12<00:59, 11.01it/s] 53%|█████▎    | 729/1380 [01:12<00:59, 11.02it/s] 53%|█████▎    | 731/1380 [01:12<00:58, 11.02it/s] 53%|█████▎    | 733/1380 [01:12<00:59, 10.94it/s] 53%|█████▎    | 735/1380 [01:12<00:58, 11.00it/s] 53%|█████▎    | 737/1380 [01:12<00:58, 11.01it/s] 54%|█████▎    | 739/1380 [01:13<00:58, 11.02it/s] 54%|█████▎    | 741/1380 [01:13<00:58, 11.01it/s] 54%|█████▍    | 743/1380 [01:13<00:57, 11.01it/s] 54%|█████▍    | 745/1380 [01:13<00:57, 11.01it/s] 54%|█████▍    | 747/1380 [01:13<00:57, 11.03it/s] 54%|█████▍    | 749/1380 [01:14<00:57, 11.00it/s] 54%|█████▍    | 751/1380 [01:14<00:57, 11.01it/s] 55%|█████▍    | 753/1380 [01:14<00:56, 11.03it/s] 55%|█████▍    | 755/1380 [01:14<00:56, 11.02it/s] 55%|█████▍    | 757/1380 [01:14<00:56, 11.02it/s] 55%|█████▌    | 759/1380 [01:14<00:56, 11.00it/s] 55%|█████▌    | 761/1380 [01:15<00:56, 11.01it/s] 55%|█████▌    | 763/1380 [01:15<00:56, 10.98it/s] 55%|█████▌    | 765/1380 [01:15<00:55, 11.00it/s] 56%|█████▌    | 767/1380 [01:15<00:55, 11.00it/s] 56%|█████▌    | 769/1380 [01:15<00:55, 11.02it/s] 56%|█████▌    | 771/1380 [01:16<00:55, 11.02it/s] 56%|█████▌    | 773/1380 [01:16<00:55, 11.02it/s] 56%|█████▌    | 775/1380 [01:16<00:54, 11.03it/s] 56%|█████▋    | 777/1380 [01:16<00:54, 11.00it/s] 56%|█████▋    | 779/1380 [01:16<00:54, 11.00it/s] 57%|█████▋    | 781/1380 [01:16<00:54, 10.97it/s] 57%|█████▋    | 783/1380 [01:17<00:54, 10.97it/s] 57%|█████▋    | 785/1380 [01:17<00:54, 10.94it/s] 57%|█████▋    | 787/1380 [01:17<00:53, 10.99it/s] 57%|█████▋    | 789/1380 [01:17<00:53, 10.99it/s] 57%|█████▋    | 791/1380 [01:17<00:53, 11.01it/s] 57%|█████▋    | 793/1380 [01:18<00:53, 11.00it/s] 58%|█████▊    | 795/1380 [01:18<00:53, 11.01it/s] 58%|█████▊    | 797/1380 [01:18<00:52, 11.01it/s] 58%|█████▊    | 799/1380 [01:18<00:52, 11.01it/s] 58%|█████▊    | 801/1380 [01:18<00:52, 11.01it/s] 58%|█████▊    | 803/1380 [01:18<00:52, 11.01it/s] 58%|█████▊    | 805/1380 [01:19<00:52, 11.01it/s] 58%|█████▊    | 807/1380 [01:19<00:52, 11.00it/s] 59%|█████▊    | 809/1380 [01:19<00:51, 11.00it/s] 59%|█████▉    | 811/1380 [01:19<00:51, 11.01it/s] 59%|█████▉    | 813/1380 [01:19<00:51, 11.02it/s] 59%|█████▉    | 815/1380 [01:20<00:51, 11.01it/s] 59%|█████▉    | 817/1380 [01:20<00:51, 11.00it/s] 59%|█████▉    | 819/1380 [01:20<00:50, 11.01it/s] 59%|█████▉    | 821/1380 [01:20<00:50, 11.01it/s] 60%|█████▉    | 823/1380 [01:20<00:50, 11.00it/s] 60%|█████▉    | 825/1380 [01:20<00:50, 11.02it/s] 60%|█████▉    | 827/1380 [01:21<00:50, 11.04it/s]                                                   60%|██████    | 828/1380 [01:21<00:49, 11.04it/s][INFO|trainer.py:755] 2023-11-15 20:34:54,699 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:34:54,701 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:34:54,701 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:34:54,701 >>   Batch size = 8
{'eval_loss': 0.41974830627441406, 'eval_accuracy': 0.8566243194192378, 'eval_micro_f1': 0.8566243194192377, 'eval_macro_f1': 0.8368107529506439, 'eval_runtime': 2.638, 'eval_samples_per_second': 835.496, 'eval_steps_per_second': 104.627, 'epoch': 2.0}
{'loss': 0.2201, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 120.06it/s][A
  9%|▉         | 26/276 [00:00<00:02, 113.24it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 111.48it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 110.39it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 109.42it/s][A
 26%|██▋       | 73/276 [00:00<00:01, 108.55it/s][A
 30%|███       | 84/276 [00:00<00:01, 107.90it/s][A
 34%|███▍      | 95/276 [00:00<00:01, 107.29it/s][A
 38%|███▊      | 106/276 [00:00<00:01, 106.60it/s][A
 42%|████▏     | 117/276 [00:01<00:01, 106.27it/s][A
 46%|████▋     | 128/276 [00:01<00:01, 106.31it/s][A
 50%|█████     | 139/276 [00:01<00:01, 106.31it/s][A
 54%|█████▍    | 150/276 [00:01<00:01, 106.42it/s][A
 58%|█████▊    | 161/276 [00:01<00:01, 106.21it/s][A
 62%|██████▏   | 172/276 [00:01<00:00, 106.17it/s][A
 66%|██████▋   | 183/276 [00:01<00:00, 105.85it/s][A
 70%|███████   | 194/276 [00:01<00:00, 105.67it/s][A
 74%|███████▍  | 205/276 [00:01<00:00, 105.17it/s][A
 78%|███████▊  | 216/276 [00:02<00:00, 104.82it/s][A
 82%|████████▏ | 227/276 [00:02<00:00, 104.46it/s][A
 86%|████████▌ | 238/276 [00:02<00:00, 104.35it/s][A
 90%|█████████ | 249/276 [00:02<00:00, 104.67it/s][A
 94%|█████████▍| 260/276 [00:02<00:00, 104.96it/s][A
 98%|█████████▊| 271/276 [00:02<00:00, 104.95it/s][A                                                  
                                                  [A 60%|██████    | 828/1380 [01:23<00:49, 11.04it/s]
100%|██████████| 276/276 [00:02<00:00, 104.95it/s][A
                                                  [A 60%|██████    | 829/1380 [01:23<04:26,  2.07it/s] 60%|██████    | 831/1380 [01:24<03:21,  2.73it/s] 60%|██████    | 833/1380 [01:24<02:35,  3.52it/s] 61%|██████    | 835/1380 [01:24<02:03,  4.43it/s] 61%|██████    | 837/1380 [01:24<01:40,  5.39it/s] 61%|██████    | 839/1380 [01:24<01:25,  6.36it/s] 61%|██████    | 841/1380 [01:24<01:14,  7.28it/s] 61%|██████    | 843/1380 [01:25<01:06,  8.10it/s] 61%|██████    | 845/1380 [01:25<01:00,  8.80it/s] 61%|██████▏   | 847/1380 [01:25<00:56,  9.37it/s] 62%|██████▏   | 849/1380 [01:25<00:54,  9.80it/s] 62%|██████▏   | 851/1380 [01:25<00:52, 10.15it/s] 62%|██████▏   | 853/1380 [01:26<00:50, 10.39it/s] 62%|██████▏   | 855/1380 [01:26<00:49, 10.57it/s] 62%|██████▏   | 857/1380 [01:26<00:48, 10.69it/s] 62%|██████▏   | 859/1380 [01:26<00:48, 10.79it/s] 62%|██████▏   | 861/1380 [01:26<00:47, 10.85it/s] 63%|██████▎   | 863/1380 [01:26<00:47, 10.90it/s] 63%|██████▎   | 865/1380 [01:27<00:47, 10.94it/s] 63%|██████▎   | 867/1380 [01:27<00:46, 10.96it/s] 63%|██████▎   | 869/1380 [01:27<00:46, 10.99it/s] 63%|██████▎   | 871/1380 [01:27<00:46, 10.99it/s] 63%|██████▎   | 873/1380 [01:27<00:46, 10.99it/s] 63%|██████▎   | 875/1380 [01:28<00:45, 10.98it/s] 64%|██████▎   | 877/1380 [01:28<00:45, 11.00it/s] 64%|██████▎   | 879/1380 [01:28<00:45, 11.02it/s] 64%|██████▍   | 881/1380 [01:28<00:45, 11.00it/s] 64%|██████▍   | 883/1380 [01:28<00:45, 10.97it/s] 64%|██████▍   | 885/1380 [01:28<00:45, 10.97it/s] 64%|██████▍   | 887/1380 [01:29<00:44, 10.97it/s] 64%|██████▍   | 889/1380 [01:29<00:44, 10.96it/s] 65%|██████▍   | 891/1380 [01:29<00:44, 10.97it/s] 65%|██████▍   | 893/1380 [01:29<00:44, 10.98it/s] 65%|██████▍   | 895/1380 [01:29<00:44, 10.99it/s] 65%|██████▌   | 897/1380 [01:30<00:44, 10.97it/s] 65%|██████▌   | 899/1380 [01:30<00:43, 10.96it/s] 65%|██████▌   | 901/1380 [01:30<00:43, 10.98it/s] 65%|██████▌   | 903/1380 [01:30<00:43, 11.00it/s] 66%|██████▌   | 905/1380 [01:30<00:43, 10.99it/s] 66%|██████▌   | 907/1380 [01:30<00:43, 10.98it/s] 66%|██████▌   | 909/1380 [01:31<00:42, 10.97it/s] 66%|██████▌   | 911/1380 [01:31<00:42, 10.98it/s] 66%|██████▌   | 913/1380 [01:31<00:42, 10.99it/s] 66%|██████▋   | 915/1380 [01:31<00:42, 10.99it/s] 66%|██████▋   | 917/1380 [01:31<00:42, 10.98it/s] 67%|██████▋   | 919/1380 [01:32<00:42, 10.96it/s] 67%|██████▋   | 921/1380 [01:32<00:41, 10.99it/s] 67%|██████▋   | 923/1380 [01:32<00:41, 11.00it/s] 67%|██████▋   | 925/1380 [01:32<00:41, 11.01it/s] 67%|██████▋   | 927/1380 [01:32<00:41, 10.99it/s] 67%|██████▋   | 929/1380 [01:32<00:41, 10.99it/s] 67%|██████▋   | 931/1380 [01:33<00:40, 11.00it/s] 68%|██████▊   | 933/1380 [01:33<00:40, 10.99it/s] 68%|██████▊   | 935/1380 [01:33<00:40, 10.98it/s] 68%|██████▊   | 937/1380 [01:33<00:40, 10.97it/s] 68%|██████▊   | 939/1380 [01:33<00:40, 10.98it/s] 68%|██████▊   | 941/1380 [01:34<00:40, 10.97it/s] 68%|██████▊   | 943/1380 [01:34<00:39, 10.98it/s] 68%|██████▊   | 945/1380 [01:34<00:39, 10.98it/s] 69%|██████▊   | 947/1380 [01:34<00:39, 10.98it/s] 69%|██████▉   | 949/1380 [01:34<00:39, 10.98it/s] 69%|██████▉   | 951/1380 [01:35<00:39, 10.99it/s] 69%|██████▉   | 953/1380 [01:35<00:38, 11.01it/s] 69%|██████▉   | 955/1380 [01:35<00:38, 10.99it/s] 69%|██████▉   | 957/1380 [01:35<00:38, 10.98it/s] 69%|██████▉   | 959/1380 [01:35<00:38, 10.98it/s] 70%|██████▉   | 961/1380 [01:35<00:38, 10.98it/s] 70%|██████▉   | 963/1380 [01:36<00:38, 10.97it/s] 70%|██████▉   | 965/1380 [01:36<00:37, 10.98it/s] 70%|███████   | 967/1380 [01:36<00:37, 10.99it/s] 70%|███████   | 969/1380 [01:36<00:37, 11.00it/s] 70%|███████   | 971/1380 [01:36<00:37, 11.00it/s] 71%|███████   | 973/1380 [01:37<00:37, 11.00it/s] 71%|███████   | 975/1380 [01:37<00:36, 11.00it/s] 71%|███████   | 977/1380 [01:37<00:36, 10.98it/s] 71%|███████   | 979/1380 [01:37<00:36, 10.99it/s] 71%|███████   | 981/1380 [01:37<00:36, 11.00it/s] 71%|███████   | 983/1380 [01:37<00:36, 11.00it/s] 71%|███████▏  | 985/1380 [01:38<00:35, 10.99it/s] 72%|███████▏  | 987/1380 [01:38<00:35, 11.00it/s] 72%|███████▏  | 989/1380 [01:38<00:35, 11.01it/s] 72%|███████▏  | 991/1380 [01:38<00:35, 11.01it/s] 72%|███████▏  | 993/1380 [01:38<00:35, 10.98it/s] 72%|███████▏  | 995/1380 [01:39<00:35, 10.97it/s] 72%|███████▏  | 997/1380 [01:39<00:34, 10.95it/s] 72%|███████▏  | 999/1380 [01:39<00:34, 10.98it/s] 73%|███████▎  | 1001/1380 [01:39<00:34, 11.00it/s] 73%|███████▎  | 1003/1380 [01:39<00:34, 11.00it/s] 73%|███████▎  | 1005/1380 [01:39<00:34, 10.97it/s] 73%|███████▎  | 1007/1380 [01:40<00:34, 10.97it/s] 73%|███████▎  | 1009/1380 [01:40<00:33, 10.93it/s] 73%|███████▎  | 1011/1380 [01:40<00:33, 10.94it/s] 73%|███████▎  | 1013/1380 [01:40<00:33, 10.95it/s] 74%|███████▎  | 1015/1380 [01:40<00:33, 10.94it/s] 74%|███████▎  | 1017/1380 [01:41<00:33, 10.96it/s] 74%|███████▍  | 1019/1380 [01:41<00:32, 10.96it/s] 74%|███████▍  | 1021/1380 [01:41<00:32, 10.97it/s] 74%|███████▍  | 1023/1380 [01:41<00:32, 10.95it/s] 74%|███████▍  | 1025/1380 [01:41<00:32, 10.96it/s] 74%|███████▍  | 1027/1380 [01:41<00:32, 10.97it/s] 75%|███████▍  | 1029/1380 [01:42<00:31, 10.98it/s] 75%|███████▍  | 1031/1380 [01:42<00:31, 10.97it/s] 75%|███████▍  | 1033/1380 [01:42<00:31, 11.00it/s] 75%|███████▌  | 1035/1380 [01:42<00:31, 11.00it/s] 75%|███████▌  | 1037/1380 [01:42<00:31, 10.99it/s] 75%|███████▌  | 1039/1380 [01:43<00:31, 10.98it/s] 75%|███████▌  | 1041/1380 [01:43<00:30, 10.98it/s] 76%|███████▌  | 1043/1380 [01:43<00:30, 10.96it/s] 76%|███████▌  | 1045/1380 [01:43<00:30, 10.96it/s] 76%|███████▌  | 1047/1380 [01:43<00:30, 10.97it/s] 76%|███████▌  | 1049/1380 [01:43<00:30, 10.99it/s] 76%|███████▌  | 1051/1380 [01:44<00:29, 10.99it/s] 76%|███████▋  | 1053/1380 [01:44<00:29, 10.98it/s] 76%|███████▋  | 1055/1380 [01:44<00:29, 11.00it/s] 77%|███████▋  | 1057/1380 [01:44<00:29, 11.00it/s] 77%|███████▋  | 1059/1380 [01:44<00:29, 11.00it/s] 77%|███████▋  | 1061/1380 [01:45<00:28, 11.01it/s] 77%|███████▋  | 1063/1380 [01:45<00:28, 11.01it/s] 77%|███████▋  | 1065/1380 [01:45<00:28, 11.02it/s] 77%|███████▋  | 1067/1380 [01:45<00:28, 11.00it/s] 77%|███████▋  | 1069/1380 [01:45<00:28, 10.77it/s] 78%|███████▊  | 1071/1380 [01:45<00:28, 10.83it/s] 78%|███████▊  | 1073/1380 [01:46<00:28, 10.86it/s] 78%|███████▊  | 1075/1380 [01:46<00:28, 10.88it/s] 78%|███████▊  | 1077/1380 [01:46<00:27, 10.94it/s] 78%|███████▊  | 1079/1380 [01:46<00:27, 10.96it/s] 78%|███████▊  | 1081/1380 [01:46<00:27, 10.97it/s] 78%|███████▊  | 1083/1380 [01:47<00:27, 10.97it/s] 79%|███████▊  | 1085/1380 [01:47<00:26, 10.98it/s] 79%|███████▉  | 1087/1380 [01:47<00:26, 10.99it/s] 79%|███████▉  | 1089/1380 [01:47<00:26, 10.98it/s] 79%|███████▉  | 1091/1380 [01:47<00:26, 10.98it/s] 79%|███████▉  | 1093/1380 [01:47<00:26, 10.98it/s] 79%|███████▉  | 1095/1380 [01:48<00:25, 10.98it/s] 79%|███████▉  | 1097/1380 [01:48<00:25, 10.98it/s] 80%|███████▉  | 1099/1380 [01:48<00:25, 11.00it/s] 80%|███████▉  | 1101/1380 [01:48<00:25, 10.98it/s] 80%|███████▉  | 1103/1380 [01:48<00:25, 10.99it/s]                                                    80%|████████  | 1104/1380 [01:48<00:25, 10.99it/s][INFO|trainer.py:755] 2023-11-15 20:35:22,457 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:35:22,459 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:35:22,459 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:35:22,459 >>   Batch size = 8
{'eval_loss': 0.4740481972694397, 'eval_accuracy': 0.8480036297640653, 'eval_micro_f1': 0.8480036297640654, 'eval_macro_f1': 0.8258813150141853, 'eval_runtime': 2.6447, 'eval_samples_per_second': 833.35, 'eval_steps_per_second': 104.358, 'epoch': 3.0}
{'loss': 0.1515, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 119.41it/s][A
  9%|▉         | 25/276 [00:00<00:02, 113.09it/s][A
 13%|█▎        | 37/276 [00:00<00:02, 111.05it/s][A
 18%|█▊        | 49/276 [00:00<00:02, 109.90it/s][A
 22%|██▏       | 60/276 [00:00<00:01, 109.12it/s][A
 26%|██▌       | 71/276 [00:00<00:01, 108.27it/s][A
 30%|██▉       | 82/276 [00:00<00:01, 107.42it/s][A
 34%|███▎      | 93/276 [00:00<00:01, 106.92it/s][A
 38%|███▊      | 104/276 [00:00<00:01, 106.01it/s][A
 42%|████▏     | 115/276 [00:01<00:01, 105.45it/s][A
 46%|████▌     | 126/276 [00:01<00:01, 105.38it/s][A
 50%|████▉     | 137/276 [00:01<00:01, 105.51it/s][A
 54%|█████▎    | 148/276 [00:01<00:01, 105.51it/s][A
 58%|█████▊    | 159/276 [00:01<00:01, 105.69it/s][A
 62%|██████▏   | 170/276 [00:01<00:01, 105.44it/s][A
 66%|██████▌   | 181/276 [00:01<00:00, 105.34it/s][A
 70%|██████▉   | 192/276 [00:01<00:00, 105.17it/s][A
 74%|███████▎  | 203/276 [00:01<00:00, 104.62it/s][A
 78%|███████▊  | 214/276 [00:02<00:00, 103.86it/s][A
 82%|████████▏ | 225/276 [00:02<00:00, 103.76it/s][A
 86%|████████▌ | 236/276 [00:02<00:00, 104.00it/s][A
 89%|████████▉ | 247/276 [00:02<00:00, 104.23it/s][A
 93%|█████████▎| 258/276 [00:02<00:00, 104.42it/s][A
 97%|█████████▋| 269/276 [00:02<00:00, 104.51it/s][A                                                   
                                                  [A 80%|████████  | 1104/1380 [01:51<00:25, 10.99it/s]
100%|██████████| 276/276 [00:02<00:00, 104.51it/s][A
                                                  [A 80%|████████  | 1105/1380 [01:51<02:13,  2.06it/s] 80%|████████  | 1107/1380 [01:51<01:40,  2.71it/s] 80%|████████  | 1109/1380 [01:52<01:17,  3.50it/s] 81%|████████  | 1111/1380 [01:52<01:01,  4.40it/s] 81%|████████  | 1113/1380 [01:52<00:49,  5.37it/s] 81%|████████  | 1115/1380 [01:52<00:41,  6.34it/s] 81%|████████  | 1117/1380 [01:52<00:36,  7.26it/s] 81%|████████  | 1119/1380 [01:52<00:32,  8.08it/s] 81%|████████  | 1121/1380 [01:53<00:29,  8.78it/s] 81%|████████▏ | 1123/1380 [01:53<00:27,  9.35it/s] 82%|████████▏ | 1125/1380 [01:53<00:26,  9.79it/s] 82%|████████▏ | 1127/1380 [01:53<00:25, 10.10it/s] 82%|████████▏ | 1129/1380 [01:53<00:24, 10.34it/s] 82%|████████▏ | 1131/1380 [01:54<00:23, 10.54it/s] 82%|████████▏ | 1133/1380 [01:54<00:23, 10.67it/s] 82%|████████▏ | 1135/1380 [01:54<00:22, 10.75it/s] 82%|████████▏ | 1137/1380 [01:54<00:22, 10.83it/s] 83%|████████▎ | 1139/1380 [01:54<00:22, 10.88it/s] 83%|████████▎ | 1141/1380 [01:54<00:21, 10.92it/s] 83%|████████▎ | 1143/1380 [01:55<00:21, 10.92it/s] 83%|████████▎ | 1145/1380 [01:55<00:21, 10.93it/s] 83%|████████▎ | 1147/1380 [01:55<00:21, 10.96it/s] 83%|████████▎ | 1149/1380 [01:55<00:21, 10.95it/s] 83%|████████▎ | 1151/1380 [01:55<00:20, 10.97it/s] 84%|████████▎ | 1153/1380 [01:56<00:20, 10.97it/s] 84%|████████▎ | 1155/1380 [01:56<00:20, 10.99it/s] 84%|████████▍ | 1157/1380 [01:56<00:20, 10.99it/s] 84%|████████▍ | 1159/1380 [01:56<00:20, 11.00it/s] 84%|████████▍ | 1161/1380 [01:56<00:19, 10.98it/s] 84%|████████▍ | 1163/1380 [01:56<00:19, 10.99it/s] 84%|████████▍ | 1165/1380 [01:57<00:19, 10.98it/s] 85%|████████▍ | 1167/1380 [01:57<00:19, 10.98it/s] 85%|████████▍ | 1169/1380 [01:57<00:19, 11.00it/s] 85%|████████▍ | 1171/1380 [01:57<00:19, 10.98it/s] 85%|████████▌ | 1173/1380 [01:57<00:18, 10.94it/s] 85%|████████▌ | 1175/1380 [01:58<00:18, 10.96it/s] 85%|████████▌ | 1177/1380 [01:58<00:18, 10.97it/s] 85%|████████▌ | 1179/1380 [01:58<00:18, 10.98it/s] 86%|████████▌ | 1181/1380 [01:58<00:18, 10.99it/s] 86%|████████▌ | 1183/1380 [01:58<00:17, 10.98it/s] 86%|████████▌ | 1185/1380 [01:58<00:17, 10.99it/s] 86%|████████▌ | 1187/1380 [01:59<00:17, 10.99it/s] 86%|████████▌ | 1189/1380 [01:59<00:17, 11.01it/s] 86%|████████▋ | 1191/1380 [01:59<00:17, 11.00it/s] 86%|████████▋ | 1193/1380 [01:59<00:17, 10.99it/s] 87%|████████▋ | 1195/1380 [01:59<00:16, 10.99it/s] 87%|████████▋ | 1197/1380 [02:00<00:16, 11.02it/s] 87%|████████▋ | 1199/1380 [02:00<00:16, 11.02it/s] 87%|████████▋ | 1201/1380 [02:00<00:16, 11.03it/s] 87%|████████▋ | 1203/1380 [02:00<00:16, 11.03it/s] 87%|████████▋ | 1205/1380 [02:00<00:15, 11.02it/s] 87%|████████▋ | 1207/1380 [02:00<00:15, 10.98it/s] 88%|████████▊ | 1209/1380 [02:01<00:15, 10.98it/s] 88%|████████▊ | 1211/1380 [02:01<00:15, 10.98it/s] 88%|████████▊ | 1213/1380 [02:01<00:15, 10.99it/s] 88%|████████▊ | 1215/1380 [02:01<00:15, 10.98it/s] 88%|████████▊ | 1217/1380 [02:01<00:14, 11.00it/s] 88%|████████▊ | 1219/1380 [02:02<00:14, 11.01it/s] 88%|████████▊ | 1221/1380 [02:02<00:14, 11.02it/s] 89%|████████▊ | 1223/1380 [02:02<00:14, 11.01it/s] 89%|████████▉ | 1225/1380 [02:02<00:14, 11.00it/s] 89%|████████▉ | 1227/1380 [02:02<00:13, 10.98it/s] 89%|████████▉ | 1229/1380 [02:02<00:13, 10.99it/s] 89%|████████▉ | 1231/1380 [02:03<00:13, 10.98it/s] 89%|████████▉ | 1233/1380 [02:03<00:13, 10.98it/s] 89%|████████▉ | 1235/1380 [02:03<00:13, 11.01it/s] 90%|████████▉ | 1237/1380 [02:03<00:13, 11.00it/s] 90%|████████▉ | 1239/1380 [02:03<00:12, 11.00it/s] 90%|████████▉ | 1241/1380 [02:04<00:12, 11.00it/s] 90%|█████████ | 1243/1380 [02:04<00:12, 11.01it/s] 90%|█████████ | 1245/1380 [02:04<00:12, 10.99it/s] 90%|█████████ | 1247/1380 [02:04<00:12, 10.98it/s] 91%|█████████ | 1249/1380 [02:04<00:11, 11.00it/s] 91%|█████████ | 1251/1380 [02:04<00:11, 11.01it/s] 91%|█████████ | 1253/1380 [02:05<00:11, 11.00it/s] 91%|█████████ | 1255/1380 [02:05<00:11, 11.00it/s] 91%|█████████ | 1257/1380 [02:05<00:11, 11.02it/s] 91%|█████████ | 1259/1380 [02:05<00:10, 11.01it/s] 91%|█████████▏| 1261/1380 [02:05<00:10, 11.00it/s] 92%|█████████▏| 1263/1380 [02:06<00:10, 11.02it/s] 92%|█████████▏| 1265/1380 [02:06<00:10, 11.01it/s] 92%|█████████▏| 1267/1380 [02:06<00:10, 10.99it/s] 92%|█████████▏| 1269/1380 [02:06<00:10, 11.01it/s] 92%|█████████▏| 1271/1380 [02:06<00:09, 11.01it/s] 92%|█████████▏| 1273/1380 [02:06<00:09, 11.00it/s] 92%|█████████▏| 1275/1380 [02:07<00:09, 10.98it/s] 93%|█████████▎| 1277/1380 [02:07<00:09, 10.97it/s] 93%|█████████▎| 1279/1380 [02:07<00:09, 10.97it/s] 93%|█████████▎| 1281/1380 [02:07<00:09, 10.98it/s] 93%|█████████▎| 1283/1380 [02:07<00:08, 10.97it/s] 93%|█████████▎| 1285/1380 [02:08<00:08, 10.97it/s] 93%|█████████▎| 1287/1380 [02:08<00:08, 10.98it/s] 93%|█████████▎| 1289/1380 [02:08<00:08, 10.97it/s] 94%|█████████▎| 1291/1380 [02:08<00:08, 10.99it/s] 94%|█████████▎| 1293/1380 [02:08<00:07, 10.98it/s] 94%|█████████▍| 1295/1380 [02:08<00:07, 10.97it/s] 94%|█████████▍| 1297/1380 [02:09<00:07, 10.98it/s] 94%|█████████▍| 1299/1380 [02:09<00:07, 11.00it/s] 94%|█████████▍| 1301/1380 [02:09<00:07, 10.99it/s] 94%|█████████▍| 1303/1380 [02:09<00:06, 11.01it/s] 95%|█████████▍| 1305/1380 [02:09<00:06, 11.00it/s] 95%|█████████▍| 1307/1380 [02:10<00:06, 11.00it/s] 95%|█████████▍| 1309/1380 [02:10<00:06, 11.00it/s] 95%|█████████▌| 1311/1380 [02:10<00:06, 10.99it/s] 95%|█████████▌| 1313/1380 [02:10<00:06, 10.99it/s] 95%|█████████▌| 1315/1380 [02:10<00:05, 11.00it/s] 95%|█████████▌| 1317/1380 [02:10<00:05, 11.00it/s] 96%|█████████▌| 1319/1380 [02:11<00:05, 11.01it/s] 96%|█████████▌| 1321/1380 [02:11<00:05, 11.02it/s] 96%|█████████▌| 1323/1380 [02:11<00:05, 11.03it/s] 96%|█████████▌| 1325/1380 [02:11<00:04, 11.04it/s] 96%|█████████▌| 1327/1380 [02:11<00:04, 11.02it/s] 96%|█████████▋| 1329/1380 [02:12<00:04, 11.01it/s] 96%|█████████▋| 1331/1380 [02:12<00:04, 11.01it/s] 97%|█████████▋| 1333/1380 [02:12<00:04, 10.99it/s] 97%|█████████▋| 1335/1380 [02:12<00:04, 10.98it/s] 97%|█████████▋| 1337/1380 [02:12<00:03, 11.01it/s] 97%|█████████▋| 1339/1380 [02:12<00:03, 11.00it/s] 97%|█████████▋| 1341/1380 [02:13<00:03, 11.00it/s] 97%|█████████▋| 1343/1380 [02:13<00:03, 11.00it/s] 97%|█████████▋| 1345/1380 [02:13<00:03, 10.99it/s] 98%|█████████▊| 1347/1380 [02:13<00:03, 10.98it/s] 98%|█████████▊| 1349/1380 [02:13<00:02, 10.97it/s] 98%|█████████▊| 1351/1380 [02:14<00:02, 10.98it/s] 98%|█████████▊| 1353/1380 [02:14<00:02, 11.00it/s] 98%|█████████▊| 1355/1380 [02:14<00:02, 11.00it/s] 98%|█████████▊| 1357/1380 [02:14<00:02, 10.98it/s] 98%|█████████▊| 1359/1380 [02:14<00:01, 10.98it/s] 99%|█████████▊| 1361/1380 [02:14<00:01, 10.99it/s] 99%|█████████▉| 1363/1380 [02:15<00:01, 10.99it/s] 99%|█████████▉| 1365/1380 [02:15<00:01, 11.00it/s] 99%|█████████▉| 1367/1380 [02:15<00:01, 11.01it/s] 99%|█████████▉| 1369/1380 [02:15<00:00, 11.00it/s] 99%|█████████▉| 1371/1380 [02:15<00:00, 10.99it/s] 99%|█████████▉| 1373/1380 [02:16<00:00, 11.01it/s]100%|█████████▉| 1375/1380 [02:16<00:00, 11.02it/s]100%|█████████▉| 1377/1380 [02:16<00:00, 11.01it/s]100%|█████████▉| 1379/1380 [02:16<00:00, 11.01it/s]                                                   100%|██████████| 1380/1380 [02:16<00:00, 11.01it/s][INFO|trainer.py:755] 2023-11-15 20:35:50,205 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:35:50,207 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:35:50,207 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:35:50,207 >>   Batch size = 8
{'eval_loss': 0.513552188873291, 'eval_accuracy': 0.8507259528130672, 'eval_micro_f1': 0.8507259528130672, 'eval_macro_f1': 0.8314963739171909, 'eval_runtime': 2.6601, 'eval_samples_per_second': 828.544, 'eval_steps_per_second': 103.756, 'epoch': 4.0}
{'loss': 0.1079, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 119.27it/s][A
  9%|▉         | 25/276 [00:00<00:02, 113.68it/s][A
 13%|█▎        | 37/276 [00:00<00:02, 110.99it/s][A
 18%|█▊        | 49/276 [00:00<00:02, 109.98it/s][A
 22%|██▏       | 60/276 [00:00<00:01, 108.97it/s][A
 26%|██▌       | 71/276 [00:00<00:01, 108.44it/s][A
 30%|██▉       | 82/276 [00:00<00:01, 107.70it/s][A
 34%|███▎      | 93/276 [00:00<00:01, 107.27it/s][A
 38%|███▊      | 104/276 [00:00<00:01, 106.23it/s][A
 42%|████▏     | 115/276 [00:01<00:01, 105.76it/s][A
 46%|████▌     | 126/276 [00:01<00:01, 105.74it/s][A
 50%|████▉     | 137/276 [00:01<00:01, 105.76it/s][A
 54%|█████▎    | 148/276 [00:01<00:01, 105.74it/s][A
 58%|█████▊    | 159/276 [00:01<00:01, 105.70it/s][A
 62%|██████▏   | 170/276 [00:01<00:01, 105.80it/s][A
 66%|██████▌   | 181/276 [00:01<00:00, 105.46it/s][A
 70%|██████▉   | 192/276 [00:01<00:00, 105.40it/s][A
 74%|███████▎  | 203/276 [00:01<00:00, 104.56it/s][A
 78%|███████▊  | 214/276 [00:02<00:00, 104.18it/s][A
 82%|████████▏ | 225/276 [00:02<00:00, 103.87it/s][A
 86%|████████▌ | 236/276 [00:02<00:00, 104.08it/s][A
 89%|████████▉ | 247/276 [00:02<00:00, 104.17it/s][A
 93%|█████████▎| 258/276 [00:02<00:00, 104.60it/s][A
 97%|█████████▋| 269/276 [00:02<00:00, 104.24it/s][A                                                   
                                                  [A100%|██████████| 1380/1380 [02:19<00:00, 11.01it/s]
100%|██████████| 276/276 [00:02<00:00, 104.24it/s][A
                                                  [A[INFO|trainer.py:1963] 2023-11-15 20:35:52,866 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:19<00:00, 11.01it/s]100%|██████████| 1380/1380 [02:19<00:00,  9.90it/s]
[INFO|trainer.py:2855] 2023-11-15 20:35:52,871 >> Saving model checkpoint to ./result/acl_bert-base-cased_adapter__seed2
[INFO|configuration_utils.py:460] 2023-11-15 20:35:52,874 >> Configuration saved in ./result/acl_bert-base-cased_adapter__seed2/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:35:53,846 >> Model weights saved in ./result/acl_bert-base-cased_adapter__seed2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:35:53,849 >> tokenizer config file saved in ./result/acl_bert-base-cased_adapter__seed2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:35:53,850 >> Special tokens file saved in ./result/acl_bert-base-cased_adapter__seed2/special_tokens_map.json
{'eval_loss': 0.561844527721405, 'eval_accuracy': 0.8470961887477314, 'eval_micro_f1': 0.8470961887477315, 'eval_macro_f1': 0.8275152627370869, 'eval_runtime': 2.6553, 'eval_samples_per_second': 830.033, 'eval_steps_per_second': 103.942, 'epoch': 5.0}
{'train_runtime': 139.3283, 'train_samples_per_second': 316.375, 'train_steps_per_second': 9.905, 'train_loss': 0.26399305868839873, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =      0.264
  train_runtime            = 0:02:19.32
  train_samples            =       8816
  train_samples_per_second =    316.375
  train_steps_per_second   =      9.905
11/15/2023 20:35:53 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:35:53,894 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:35:53,895 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:35:53,895 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:35:53,896 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  5%|▍         | 13/276 [00:00<00:02, 119.29it/s]  9%|▉         | 25/276 [00:00<00:02, 110.58it/s] 13%|█▎        | 37/276 [00:00<00:02, 108.51it/s] 17%|█▋        | 48/276 [00:00<00:02, 107.17it/s] 21%|██▏       | 59/276 [00:00<00:02, 106.41it/s] 25%|██▌       | 70/276 [00:00<00:01, 105.84it/s] 29%|██▉       | 81/276 [00:00<00:01, 105.63it/s] 33%|███▎      | 92/276 [00:00<00:01, 105.27it/s] 37%|███▋      | 103/276 [00:00<00:01, 105.13it/s] 41%|████▏     | 114/276 [00:01<00:01, 104.89it/s] 45%|████▌     | 125/276 [00:01<00:01, 104.99it/s] 49%|████▉     | 136/276 [00:01<00:01, 104.90it/s] 53%|█████▎    | 147/276 [00:01<00:01, 104.97it/s] 57%|█████▋    | 158/276 [00:01<00:01, 104.96it/s] 61%|██████    | 169/276 [00:01<00:01, 104.71it/s] 65%|██████▌   | 180/276 [00:01<00:00, 104.70it/s] 69%|██████▉   | 191/276 [00:01<00:00, 104.79it/s] 73%|███████▎  | 202/276 [00:01<00:00, 104.79it/s] 77%|███████▋  | 213/276 [00:02<00:00, 104.72it/s] 81%|████████  | 224/276 [00:02<00:00, 104.79it/s] 85%|████████▌ | 235/276 [00:02<00:00, 104.54it/s] 89%|████████▉ | 246/276 [00:02<00:00, 104.60it/s] 93%|█████████▎| 257/276 [00:02<00:00, 104.59it/s] 97%|█████████▋| 268/276 [00:02<00:00, 104.73it/s]100%|██████████| 276/276 [00:02<00:00, 103.87it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8471
  eval_loss               =     0.5618
  eval_macro_f1           =     0.8275
  eval_micro_f1           =     0.8471
  eval_runtime            = 0:00:02.66
  eval_samples            =       2204
  eval_samples_per_second =    825.633
  eval_steps_per_second   =    103.391
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁█▅▆▄▄
wandb:                      eval/loss ▂▁▄▆██
wandb:                  eval/macro_f1 ▁█▅▇▅▅
wandb:                  eval/micro_f1 ▁█▅▆▄▄
wandb:                   eval/runtime ▁▄▅▇▆█
wandb:        eval/samples_per_second █▅▄▂▃▁
wandb:          eval/steps_per_second █▅▄▂▃▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.8471
wandb:                      eval/loss 0.56184
wandb:                  eval/macro_f1 0.82752
wandb:                  eval/micro_f1 0.8471
wandb:                   eval/runtime 2.6695
wandb:        eval/samples_per_second 825.633
wandb:          eval/steps_per_second 103.391
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1079
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.26399
wandb:            train/train_runtime 139.3283
wandb: train/train_samples_per_second 316.375
wandb:   train/train_steps_per_second 9.905
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_203245-ofmts3xj
wandb: Find logs at: ./wandb/offline-run-20231115_203245-ofmts3xj/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2/runs/Nov15_20-36-07_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:36:07 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:36:07 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2/runs/Nov15_20-36-06_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  37%|███▋      | 4060/11020 [00:00<00:00, 39539.60 examples/s]Map:  75%|███████▍  | 8239/11020 [00:00<00:00, 40846.26 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 39997.40 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:36:23,428 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:36:23,438 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:36:33,454 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:36:43,473 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:36:43,474 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:37:03,510 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:37:03,511 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:37:03,511 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:37:03,511 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:37:03,512 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:37:03,513 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:37:03,513 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 20:37:03,533 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:37:03,534 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:37:23,665 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 20:37:25,010 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:37:25,011 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  23%|██▎       | 2000/8816 [00:00<00:00, 19052.89 examples/s]Running tokenizer on dataset:  57%|█████▋    | 5000/8816 [00:00<00:00, 19718.35 examples/s]Running tokenizer on dataset:  79%|███████▉  | 7000/8816 [00:00<00:00, 19407.48 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 19681.73 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 19805.22 examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 19469.48 examples/s]
11/15/2023 20:37:25 - INFO - __main__ - Sample 5747 of the training set: {'text': 'While the redox buffer pairs (e.g. GSH/GSSG, reduced PC/oxidised PC, and reduced Protein/oxidised Protein) can protect cells from oxidative damage (Tsuji et al., 2002), this produces an imbalance in the redox status that may lead to other unwanted effects such as changes in intracellular pH, which…', 'label': 0, 'input_ids': [102, 969, 111, 12180, 3520, 4169, 145, 139, 205, 159, 205, 15166, 1352, 9326, 15615, 422, 1797, 3658, 1352, 3035, 1736, 3658, 422, 137, 1797, 787, 1352, 3035, 1736, 787, 546, 300, 8986, 576, 263, 6058, 3810, 145, 3450, 14802, 30109, 365, 186, 205, 422, 8063, 546, 422, 238, 6707, 130, 15807, 121, 111, 12180, 2726, 198, 552, 1269, 147, 494, 20628, 1056, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 20:37:25 - INFO - __main__ - Sample 5785 of the training set: {'text': 'BDNF has been shown to interact with several neurotrans-\nmitter systems, including the DA (Spenger et al., 1995), serotonin (5-HT) (Lyons et al., 1999; Rumajogee et al., 2002), and NPY systems (Barnea and Roberts, 2001; Nawa et al., 1993, 1994).', 'label': 0, 'input_ids': [102, 18500, 434, 528, 817, 147, 5049, 190, 1323, 14912, 579, 26233, 114, 1078, 422, 1471, 111, 2762, 145, 1631, 5733, 114, 365, 186, 205, 422, 11285, 546, 422, 15319, 145, 305, 579, 6301, 546, 145, 28080, 30113, 365, 186, 205, 422, 9135, 1814, 15333, 6079, 14441, 30107, 365, 186, 205, 422, 8063, 546, 422, 137, 5242, 30126, 1078, 145, 2261, 13677, 137, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 20:37:25 - INFO - __main__ - Sample 3534 of the training set: {'text': 'Studies have shown that alcohol consumption may contribute to the spread of HIV/AIDS by diminishing sexual inhibitions and interfering with one’s ability to adequately assess risk (Gordon et al. 1997; MacDonald et al. 2000a, b; Maisto et al. 2004).', 'label': 0, 'input_ids': [102, 826, 360, 817, 198, 4617, 3337, 552, 4362, 147, 111, 4696, 131, 3690, 1352, 10557, 214, 28940, 5471, 3308, 30113, 137, 16617, 190, 482, 5459, 112, 2495, 147, 13463, 1285, 1265, 145, 19898, 365, 186, 205, 10812, 1814, 2175, 28101, 365, 186, 205, 4708, 30110, 422, 132, 1814, 19208, 861, 365, 186, 205, 6706, 546, 205, 103, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:37:25 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:37:27,215 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:37:27,224 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:37:27,224 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 20:37:27,224 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:37:27,225 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:37:27,225 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:37:27,225 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:37:27,225 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 20:37:27,226 >>   Number of trainable parameters = 109,920,771
[INFO|integration_utils.py:716] 2023-11-15 20:37:27,227 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<28:52,  1.26s/it]  0%|          | 3/1380 [00:01<08:59,  2.55it/s]  0%|          | 5/1380 [00:01<05:25,  4.23it/s]  1%|          | 7/1380 [00:01<03:59,  5.74it/s]  1%|          | 9/1380 [00:01<03:15,  7.02it/s]  1%|          | 11/1380 [00:02<02:49,  8.07it/s]  1%|          | 13/1380 [00:02<02:33,  8.88it/s]  1%|          | 15/1380 [00:02<02:23,  9.49it/s]  1%|          | 17/1380 [00:02<02:17,  9.95it/s]  1%|▏         | 19/1380 [00:02<02:12, 10.26it/s]  2%|▏         | 21/1380 [00:03<02:09, 10.50it/s]  2%|▏         | 23/1380 [00:03<02:07, 10.68it/s]  2%|▏         | 25/1380 [00:03<02:05, 10.80it/s]  2%|▏         | 27/1380 [00:03<02:05, 10.82it/s]  2%|▏         | 29/1380 [00:03<02:04, 10.89it/s]  2%|▏         | 31/1380 [00:03<02:03, 10.94it/s]  2%|▏         | 33/1380 [00:04<02:02, 10.99it/s]  3%|▎         | 35/1380 [00:04<02:02, 10.99it/s]  3%|▎         | 37/1380 [00:04<02:01, 11.03it/s]  3%|▎         | 39/1380 [00:04<02:01, 11.05it/s]  3%|▎         | 41/1380 [00:04<02:00, 11.07it/s]  3%|▎         | 43/1380 [00:05<02:00, 11.06it/s]  3%|▎         | 45/1380 [00:05<02:00, 11.06it/s]  3%|▎         | 47/1380 [00:05<02:00, 11.07it/s]  4%|▎         | 49/1380 [00:05<02:00, 11.06it/s]  4%|▎         | 51/1380 [00:05<02:00, 11.05it/s]  4%|▍         | 53/1380 [00:05<02:00, 11.05it/s]  4%|▍         | 55/1380 [00:06<02:00, 11.02it/s]  4%|▍         | 57/1380 [00:06<02:00, 10.99it/s]  4%|▍         | 59/1380 [00:06<02:00, 10.99it/s]  4%|▍         | 61/1380 [00:06<01:59, 11.01it/s]  5%|▍         | 63/1380 [00:06<01:59, 11.01it/s]  5%|▍         | 65/1380 [00:07<01:59, 10.98it/s]  5%|▍         | 67/1380 [00:07<01:59, 11.01it/s]  5%|▌         | 69/1380 [00:07<01:58, 11.04it/s]  5%|▌         | 71/1380 [00:07<01:58, 11.04it/s]  5%|▌         | 73/1380 [00:07<01:58, 11.03it/s]  5%|▌         | 75/1380 [00:07<01:58, 11.03it/s]  6%|▌         | 77/1380 [00:08<01:58, 11.02it/s]  6%|▌         | 79/1380 [00:08<01:58, 11.02it/s]  6%|▌         | 81/1380 [00:08<01:58, 10.99it/s]  6%|▌         | 83/1380 [00:08<01:57, 11.04it/s]  6%|▌         | 85/1380 [00:08<01:56, 11.08it/s]  6%|▋         | 87/1380 [00:09<01:56, 11.06it/s]  6%|▋         | 89/1380 [00:09<01:56, 11.08it/s]  7%|▋         | 91/1380 [00:09<01:56, 11.11it/s]  7%|▋         | 93/1380 [00:09<01:55, 11.11it/s]  7%|▋         | 95/1380 [00:09<01:55, 11.10it/s]  7%|▋         | 97/1380 [00:09<01:55, 11.10it/s]  7%|▋         | 99/1380 [00:10<01:55, 11.12it/s]  7%|▋         | 101/1380 [00:10<01:55, 11.11it/s]  7%|▋         | 103/1380 [00:10<01:55, 11.09it/s]  8%|▊         | 105/1380 [00:10<01:54, 11.11it/s]  8%|▊         | 107/1380 [00:10<01:54, 11.13it/s]  8%|▊         | 109/1380 [00:11<01:54, 11.13it/s]  8%|▊         | 111/1380 [00:11<01:54, 11.12it/s]  8%|▊         | 113/1380 [00:11<01:53, 11.14it/s]  8%|▊         | 115/1380 [00:11<01:53, 11.13it/s]  8%|▊         | 117/1380 [00:11<01:53, 11.09it/s]  9%|▊         | 119/1380 [00:11<01:53, 11.12it/s]  9%|▉         | 121/1380 [00:12<01:53, 11.12it/s]  9%|▉         | 123/1380 [00:12<01:52, 11.12it/s]  9%|▉         | 125/1380 [00:12<01:52, 11.11it/s]  9%|▉         | 127/1380 [00:12<01:52, 11.11it/s]  9%|▉         | 129/1380 [00:12<01:52, 11.13it/s]  9%|▉         | 131/1380 [00:12<01:52, 11.12it/s] 10%|▉         | 133/1380 [00:13<01:52, 11.11it/s] 10%|▉         | 135/1380 [00:13<01:51, 11.12it/s] 10%|▉         | 137/1380 [00:13<01:52, 11.10it/s] 10%|█         | 139/1380 [00:13<01:51, 11.10it/s] 10%|█         | 141/1380 [00:13<01:51, 11.12it/s] 10%|█         | 143/1380 [00:14<01:51, 11.13it/s] 11%|█         | 145/1380 [00:14<01:51, 11.11it/s] 11%|█         | 147/1380 [00:14<01:51, 11.11it/s] 11%|█         | 149/1380 [00:14<01:50, 11.13it/s] 11%|█         | 151/1380 [00:14<01:50, 11.13it/s] 11%|█         | 153/1380 [00:14<01:50, 11.11it/s] 11%|█         | 155/1380 [00:15<01:50, 11.11it/s] 11%|█▏        | 157/1380 [00:15<01:50, 11.08it/s] 12%|█▏        | 159/1380 [00:15<01:49, 11.13it/s] 12%|█▏        | 161/1380 [00:15<01:49, 11.12it/s] 12%|█▏        | 163/1380 [00:15<01:49, 11.10it/s] 12%|█▏        | 165/1380 [00:16<01:49, 11.11it/s] 12%|█▏        | 167/1380 [00:16<01:49, 11.10it/s] 12%|█▏        | 169/1380 [00:16<01:49, 11.10it/s] 12%|█▏        | 171/1380 [00:16<01:49, 11.08it/s] 13%|█▎        | 173/1380 [00:16<01:48, 11.09it/s] 13%|█▎        | 175/1380 [00:16<01:48, 11.11it/s] 13%|█▎        | 177/1380 [00:17<01:48, 11.12it/s] 13%|█▎        | 179/1380 [00:17<01:48, 11.10it/s] 13%|█▎        | 181/1380 [00:17<01:47, 11.11it/s] 13%|█▎        | 183/1380 [00:17<01:47, 11.11it/s] 13%|█▎        | 185/1380 [00:17<01:47, 11.12it/s] 14%|█▎        | 187/1380 [00:18<01:47, 11.11it/s] 14%|█▎        | 189/1380 [00:18<01:47, 11.11it/s] 14%|█▍        | 191/1380 [00:18<01:46, 11.12it/s] 14%|█▍        | 193/1380 [00:18<01:46, 11.14it/s] 14%|█▍        | 195/1380 [00:18<01:46, 11.10it/s] 14%|█▍        | 197/1380 [00:18<01:46, 11.12it/s] 14%|█▍        | 199/1380 [00:19<01:46, 11.12it/s] 15%|█▍        | 201/1380 [00:19<01:45, 11.12it/s] 15%|█▍        | 203/1380 [00:19<01:45, 11.11it/s] 15%|█▍        | 205/1380 [00:19<01:45, 11.11it/s] 15%|█▌        | 207/1380 [00:19<01:45, 11.12it/s] 15%|█▌        | 209/1380 [00:20<01:45, 11.11it/s] 15%|█▌        | 211/1380 [00:20<01:45, 11.12it/s] 15%|█▌        | 213/1380 [00:20<01:44, 11.11it/s] 16%|█▌        | 215/1380 [00:20<01:44, 11.12it/s] 16%|█▌        | 217/1380 [00:20<01:44, 11.11it/s] 16%|█▌        | 219/1380 [00:20<01:44, 11.12it/s] 16%|█▌        | 221/1380 [00:21<01:44, 11.13it/s] 16%|█▌        | 223/1380 [00:21<01:43, 11.13it/s] 16%|█▋        | 225/1380 [00:21<01:43, 11.13it/s] 16%|█▋        | 227/1380 [00:21<01:43, 11.11it/s] 17%|█▋        | 229/1380 [00:21<01:43, 11.12it/s] 17%|█▋        | 231/1380 [00:21<01:43, 11.14it/s] 17%|█▋        | 233/1380 [00:22<01:43, 11.11it/s] 17%|█▋        | 235/1380 [00:22<01:42, 11.14it/s] 17%|█▋        | 237/1380 [00:22<01:42, 11.13it/s] 17%|█▋        | 239/1380 [00:22<01:42, 11.16it/s] 17%|█▋        | 241/1380 [00:22<01:42, 11.15it/s] 18%|█▊        | 243/1380 [00:23<01:42, 11.14it/s] 18%|█▊        | 245/1380 [00:23<01:41, 11.15it/s] 18%|█▊        | 247/1380 [00:23<01:41, 11.13it/s] 18%|█▊        | 249/1380 [00:23<01:41, 11.12it/s] 18%|█▊        | 251/1380 [00:23<01:41, 11.13it/s] 18%|█▊        | 253/1380 [00:23<01:41, 11.12it/s] 18%|█▊        | 255/1380 [00:24<01:41, 11.12it/s] 19%|█▊        | 257/1380 [00:24<01:40, 11.13it/s] 19%|█▉        | 259/1380 [00:24<01:40, 11.12it/s] 19%|█▉        | 261/1380 [00:24<01:40, 11.15it/s] 19%|█▉        | 263/1380 [00:24<01:40, 11.12it/s] 19%|█▉        | 265/1380 [00:25<01:40, 11.12it/s] 19%|█▉        | 267/1380 [00:25<01:40, 11.12it/s] 19%|█▉        | 269/1380 [00:25<01:39, 11.13it/s] 20%|█▉        | 271/1380 [00:25<01:39, 11.11it/s] 20%|█▉        | 273/1380 [00:25<01:39, 11.10it/s] 20%|█▉        | 275/1380 [00:25<01:39, 11.14it/s]                                                   20%|██        | 276/1380 [00:26<01:39, 11.14it/s][INFO|trainer.py:755] 2023-11-15 20:37:53,235 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:37:53,237 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:37:53,237 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:37:53,237 >>   Batch size = 8
{'loss': 0.4361, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 120.84it/s][A
  9%|▉         | 26/276 [00:00<00:02, 113.70it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 111.93it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 110.71it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 110.11it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 109.70it/s][A
 31%|███       | 85/276 [00:00<00:01, 109.13it/s][A
 35%|███▍      | 96/276 [00:00<00:01, 108.85it/s][A
 39%|███▉      | 107/276 [00:00<00:01, 108.25it/s][A
 43%|████▎     | 118/276 [00:01<00:01, 107.96it/s][A
 47%|████▋     | 129/276 [00:01<00:01, 107.64it/s][A
 51%|█████     | 140/276 [00:01<00:01, 107.74it/s][A
 55%|█████▍    | 151/276 [00:01<00:01, 107.93it/s][A
 59%|█████▊    | 162/276 [00:01<00:01, 107.83it/s][A
 63%|██████▎   | 173/276 [00:01<00:00, 107.55it/s][A
 67%|██████▋   | 184/276 [00:01<00:00, 107.31it/s][A
 71%|███████   | 195/276 [00:01<00:00, 107.61it/s][A
 75%|███████▍  | 206/276 [00:01<00:00, 107.56it/s][A
 79%|███████▊  | 217/276 [00:01<00:00, 107.33it/s][A
 83%|████████▎ | 228/276 [00:02<00:00, 107.26it/s][A
 87%|████████▋ | 239/276 [00:02<00:00, 107.44it/s][A
 91%|█████████ | 250/276 [00:02<00:00, 107.09it/s][A
 95%|█████████▍| 261/276 [00:02<00:00, 107.12it/s][A
 99%|█████████▊| 272/276 [00:02<00:00, 106.95it/s][A                                                  
                                                  [A 20%|██        | 276/1380 [00:28<01:39, 11.14it/s]
100%|██████████| 276/276 [00:02<00:00, 106.95it/s][A
                                                  [A 20%|██        | 277/1380 [00:28<08:46,  2.10it/s] 20%|██        | 279/1380 [00:28<06:37,  2.77it/s] 20%|██        | 281/1380 [00:29<05:07,  3.57it/s] 21%|██        | 283/1380 [00:29<04:04,  4.48it/s] 21%|██        | 285/1380 [00:29<03:20,  5.46it/s] 21%|██        | 287/1380 [00:29<02:49,  6.45it/s] 21%|██        | 289/1380 [00:29<02:28,  7.37it/s] 21%|██        | 291/1380 [00:29<02:12,  8.21it/s] 21%|██        | 293/1380 [00:30<02:01,  8.92it/s] 21%|██▏       | 295/1380 [00:30<01:54,  9.49it/s] 22%|██▏       | 297/1380 [00:30<01:49,  9.92it/s] 22%|██▏       | 299/1380 [00:30<01:45, 10.26it/s] 22%|██▏       | 301/1380 [00:30<01:42, 10.52it/s] 22%|██▏       | 303/1380 [00:31<01:40, 10.67it/s] 22%|██▏       | 305/1380 [00:31<01:39, 10.80it/s] 22%|██▏       | 307/1380 [00:31<01:38, 10.90it/s] 22%|██▏       | 309/1380 [00:31<01:37, 10.93it/s] 23%|██▎       | 311/1380 [00:31<01:37, 10.94it/s] 23%|██▎       | 313/1380 [00:31<01:37, 11.00it/s] 23%|██▎       | 315/1380 [00:32<01:36, 11.04it/s] 23%|██▎       | 317/1380 [00:32<01:36, 11.07it/s] 23%|██▎       | 319/1380 [00:32<01:35, 11.06it/s] 23%|██▎       | 321/1380 [00:32<01:35, 11.08it/s] 23%|██▎       | 323/1380 [00:32<01:35, 11.06it/s] 24%|██▎       | 325/1380 [00:33<01:35, 11.07it/s] 24%|██▎       | 327/1380 [00:33<01:35, 11.05it/s] 24%|██▍       | 329/1380 [00:33<01:34, 11.07it/s] 24%|██▍       | 331/1380 [00:33<01:34, 11.09it/s] 24%|██▍       | 333/1380 [00:33<01:34, 11.09it/s] 24%|██▍       | 335/1380 [00:33<01:34, 11.09it/s] 24%|██▍       | 337/1380 [00:34<01:33, 11.11it/s] 25%|██▍       | 339/1380 [00:34<01:33, 11.11it/s] 25%|██▍       | 341/1380 [00:34<01:33, 11.12it/s] 25%|██▍       | 343/1380 [00:34<01:33, 11.12it/s] 25%|██▌       | 345/1380 [00:34<01:33, 11.12it/s] 25%|██▌       | 347/1380 [00:35<01:32, 11.13it/s] 25%|██▌       | 349/1380 [00:35<01:32, 11.11it/s] 25%|██▌       | 351/1380 [00:35<01:32, 11.12it/s] 26%|██▌       | 353/1380 [00:35<01:32, 11.14it/s] 26%|██▌       | 355/1380 [00:35<01:31, 11.15it/s] 26%|██▌       | 357/1380 [00:35<01:32, 11.12it/s] 26%|██▌       | 359/1380 [00:36<01:31, 11.13it/s] 26%|██▌       | 361/1380 [00:36<01:31, 11.13it/s] 26%|██▋       | 363/1380 [00:36<01:31, 11.12it/s] 26%|██▋       | 365/1380 [00:36<01:31, 11.12it/s] 27%|██▋       | 367/1380 [00:36<01:30, 11.14it/s] 27%|██▋       | 369/1380 [00:36<01:30, 11.14it/s] 27%|██▋       | 371/1380 [00:37<01:30, 11.14it/s] 27%|██▋       | 373/1380 [00:37<01:30, 11.16it/s] 27%|██▋       | 375/1380 [00:37<01:30, 11.17it/s] 27%|██▋       | 377/1380 [00:37<01:29, 11.17it/s] 27%|██▋       | 379/1380 [00:37<01:29, 11.14it/s] 28%|██▊       | 381/1380 [00:38<01:29, 11.15it/s] 28%|██▊       | 383/1380 [00:38<01:29, 11.17it/s] 28%|██▊       | 385/1380 [00:38<01:29, 11.17it/s] 28%|██▊       | 387/1380 [00:38<01:29, 11.14it/s] 28%|██▊       | 389/1380 [00:38<01:28, 11.14it/s] 28%|██▊       | 391/1380 [00:38<01:28, 11.15it/s] 28%|██▊       | 393/1380 [00:39<01:28, 11.14it/s] 29%|██▊       | 395/1380 [00:39<01:28, 11.13it/s] 29%|██▉       | 397/1380 [00:39<01:28, 11.15it/s] 29%|██▉       | 399/1380 [00:39<01:27, 11.15it/s] 29%|██▉       | 401/1380 [00:39<01:27, 11.14it/s] 29%|██▉       | 403/1380 [00:40<01:27, 11.14it/s] 29%|██▉       | 405/1380 [00:40<01:27, 11.15it/s] 29%|██▉       | 407/1380 [00:40<01:27, 11.15it/s] 30%|██▉       | 409/1380 [00:40<01:27, 11.13it/s] 30%|██▉       | 411/1380 [00:40<01:26, 11.14it/s] 30%|██▉       | 413/1380 [00:40<01:26, 11.16it/s] 30%|███       | 415/1380 [00:41<01:26, 11.17it/s] 30%|███       | 417/1380 [00:41<01:26, 11.13it/s] 30%|███       | 419/1380 [00:41<01:26, 11.15it/s] 31%|███       | 421/1380 [00:41<01:26, 11.15it/s] 31%|███       | 423/1380 [00:41<01:26, 11.10it/s] 31%|███       | 425/1380 [00:42<01:25, 11.13it/s] 31%|███       | 427/1380 [00:42<01:25, 11.14it/s] 31%|███       | 429/1380 [00:42<01:25, 11.16it/s] 31%|███       | 431/1380 [00:42<01:25, 11.15it/s] 31%|███▏      | 433/1380 [00:42<01:24, 11.15it/s] 32%|███▏      | 435/1380 [00:42<01:24, 11.16it/s] 32%|███▏      | 437/1380 [00:43<01:24, 11.16it/s] 32%|███▏      | 439/1380 [00:43<01:24, 11.13it/s] 32%|███▏      | 441/1380 [00:43<01:24, 11.15it/s] 32%|███▏      | 443/1380 [00:43<01:24, 11.13it/s] 32%|███▏      | 445/1380 [00:43<01:23, 11.14it/s] 32%|███▏      | 447/1380 [00:43<01:23, 11.13it/s] 33%|███▎      | 449/1380 [00:44<01:23, 11.14it/s] 33%|███▎      | 451/1380 [00:44<01:23, 11.14it/s] 33%|███▎      | 453/1380 [00:44<01:23, 11.11it/s] 33%|███▎      | 455/1380 [00:44<01:23, 11.12it/s] 33%|███▎      | 457/1380 [00:44<01:22, 11.13it/s] 33%|███▎      | 459/1380 [00:45<01:22, 11.14it/s] 33%|███▎      | 461/1380 [00:45<01:22, 11.13it/s] 34%|███▎      | 463/1380 [00:45<01:22, 11.12it/s] 34%|███▎      | 465/1380 [00:45<01:22, 11.14it/s] 34%|███▍      | 467/1380 [00:45<01:21, 11.16it/s] 34%|███▍      | 469/1380 [00:45<01:21, 11.13it/s] 34%|███▍      | 471/1380 [00:46<01:21, 11.15it/s] 34%|███▍      | 473/1380 [00:46<01:21, 11.14it/s] 34%|███▍      | 475/1380 [00:46<01:21, 11.16it/s] 35%|███▍      | 477/1380 [00:46<01:21, 11.13it/s] 35%|███▍      | 479/1380 [00:46<01:20, 11.14it/s] 35%|███▍      | 481/1380 [00:47<01:20, 11.15it/s] 35%|███▌      | 483/1380 [00:47<01:20, 11.15it/s] 35%|███▌      | 485/1380 [00:47<01:20, 11.15it/s] 35%|███▌      | 487/1380 [00:47<01:20, 11.15it/s] 35%|███▌      | 489/1380 [00:47<01:19, 11.16it/s] 36%|███▌      | 491/1380 [00:47<01:19, 11.16it/s] 36%|███▌      | 493/1380 [00:48<01:19, 11.16it/s] 36%|███▌      | 495/1380 [00:48<01:19, 11.17it/s] 36%|███▌      | 497/1380 [00:48<01:18, 11.18it/s] 36%|███▌      | 499/1380 [00:48<01:18, 11.16it/s] 36%|███▋      | 501/1380 [00:48<01:18, 11.17it/s] 36%|███▋      | 503/1380 [00:49<01:18, 11.16it/s] 37%|███▋      | 505/1380 [00:49<01:18, 11.16it/s] 37%|███▋      | 507/1380 [00:49<01:18, 11.16it/s] 37%|███▋      | 509/1380 [00:49<01:18, 11.17it/s] 37%|███▋      | 511/1380 [00:49<01:17, 11.18it/s] 37%|███▋      | 513/1380 [00:49<01:17, 11.17it/s] 37%|███▋      | 515/1380 [00:50<01:17, 11.17it/s] 37%|███▋      | 517/1380 [00:50<01:17, 11.17it/s] 38%|███▊      | 519/1380 [00:50<01:17, 11.18it/s] 38%|███▊      | 521/1380 [00:50<01:16, 11.17it/s] 38%|███▊      | 523/1380 [00:50<01:16, 11.21it/s] 38%|███▊      | 525/1380 [00:50<01:16, 11.18it/s] 38%|███▊      | 527/1380 [00:51<01:16, 11.17it/s] 38%|███▊      | 529/1380 [00:51<01:16, 11.16it/s] 38%|███▊      | 531/1380 [00:51<01:16, 11.15it/s] 39%|███▊      | 533/1380 [00:51<01:15, 11.16it/s] 39%|███▉      | 535/1380 [00:51<01:15, 11.17it/s] 39%|███▉      | 537/1380 [00:52<01:15, 11.15it/s] 39%|███▉      | 539/1380 [00:52<01:15, 11.16it/s] 39%|███▉      | 541/1380 [00:52<01:15, 11.18it/s] 39%|███▉      | 543/1380 [00:52<01:14, 11.17it/s] 39%|███▉      | 545/1380 [00:52<01:14, 11.16it/s] 40%|███▉      | 547/1380 [00:52<01:14, 11.16it/s] 40%|███▉      | 549/1380 [00:53<01:14, 11.15it/s] 40%|███▉      | 551/1380 [00:53<01:14, 11.16it/s]                                                   40%|████      | 552/1380 [00:53<01:14, 11.16it/s][INFO|trainer.py:755] 2023-11-15 20:38:20,598 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:38:20,601 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:38:20,601 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:38:20,601 >>   Batch size = 8
{'eval_loss': 0.39588800072669983, 'eval_accuracy': 0.8566243194192378, 'eval_micro_f1': 0.8566243194192377, 'eval_macro_f1': 0.8320104569409019, 'eval_runtime': 2.6067, 'eval_samples_per_second': 845.515, 'eval_steps_per_second': 105.881, 'epoch': 1.0}
{'loss': 0.2857, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 122.76it/s][A
  9%|▉         | 26/276 [00:00<00:02, 115.85it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 113.74it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 112.44it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.63it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.64it/s][A
 31%|███       | 86/276 [00:00<00:01, 109.95it/s][A
 35%|███▌      | 97/276 [00:00<00:01, 109.24it/s][A
 39%|███▉      | 108/276 [00:00<00:01, 108.30it/s][A
 43%|████▎     | 119/276 [00:01<00:01, 108.03it/s][A
 47%|████▋     | 130/276 [00:01<00:01, 108.32it/s][A
 51%|█████     | 141/276 [00:01<00:01, 108.52it/s][A
 55%|█████▌    | 152/276 [00:01<00:01, 108.56it/s][A
 59%|█████▉    | 163/276 [00:01<00:01, 108.63it/s][A
 63%|██████▎   | 174/276 [00:01<00:00, 108.51it/s][A
 67%|██████▋   | 185/276 [00:01<00:00, 108.22it/s][A
 71%|███████   | 196/276 [00:01<00:00, 107.99it/s][A
 75%|███████▌  | 207/276 [00:01<00:00, 107.68it/s][A
 79%|███████▉  | 218/276 [00:01<00:00, 107.18it/s][A
 83%|████████▎ | 229/276 [00:02<00:00, 107.30it/s][A
 87%|████████▋ | 240/276 [00:02<00:00, 107.46it/s][A
 91%|█████████ | 251/276 [00:02<00:00, 107.63it/s][A
 95%|█████████▍| 262/276 [00:02<00:00, 107.96it/s][A
 99%|█████████▉| 273/276 [00:02<00:00, 108.01it/s][A                                                  
                                                  [A 40%|████      | 552/1380 [00:55<01:14, 11.16it/s]
100%|██████████| 276/276 [00:02<00:00, 108.01it/s][A
                                                  [A 40%|████      | 553/1380 [00:56<06:32,  2.11it/s] 40%|████      | 555/1380 [00:56<04:56,  2.78it/s] 40%|████      | 557/1380 [00:56<03:49,  3.59it/s] 41%|████      | 559/1380 [00:56<03:02,  4.50it/s] 41%|████      | 561/1380 [00:56<02:29,  5.48it/s] 41%|████      | 563/1380 [00:56<02:06,  6.45it/s] 41%|████      | 565/1380 [00:57<01:50,  7.39it/s] 41%|████      | 567/1380 [00:57<01:38,  8.22it/s] 41%|████      | 569/1380 [00:57<01:31,  8.91it/s] 41%|████▏     | 571/1380 [00:57<01:25,  9.48it/s] 42%|████▏     | 573/1380 [00:57<01:21,  9.93it/s] 42%|████▏     | 575/1380 [00:58<01:18, 10.25it/s] 42%|████▏     | 577/1380 [00:58<01:16, 10.50it/s] 42%|████▏     | 579/1380 [00:58<01:14, 10.69it/s] 42%|████▏     | 581/1380 [00:58<01:13, 10.84it/s] 42%|████▏     | 583/1380 [00:58<01:12, 10.92it/s] 42%|████▏     | 585/1380 [00:58<01:12, 10.99it/s] 43%|████▎     | 587/1380 [00:59<01:11, 11.04it/s] 43%|████▎     | 589/1380 [00:59<01:11, 11.07it/s] 43%|████▎     | 591/1380 [00:59<01:11, 11.07it/s] 43%|████▎     | 593/1380 [00:59<01:10, 11.10it/s] 43%|████▎     | 595/1380 [00:59<01:10, 11.11it/s] 43%|████▎     | 597/1380 [01:00<01:10, 11.11it/s] 43%|████▎     | 599/1380 [01:00<01:10, 11.12it/s] 44%|████▎     | 601/1380 [01:00<01:10, 11.13it/s] 44%|████▎     | 603/1380 [01:00<01:09, 11.13it/s] 44%|████▍     | 605/1380 [01:00<01:09, 11.11it/s] 44%|████▍     | 607/1380 [01:00<01:09, 11.12it/s] 44%|████▍     | 609/1380 [01:01<01:09, 11.12it/s] 44%|████▍     | 611/1380 [01:01<01:09, 11.12it/s] 44%|████▍     | 613/1380 [01:01<01:08, 11.13it/s] 45%|████▍     | 615/1380 [01:01<01:08, 11.13it/s] 45%|████▍     | 617/1380 [01:01<01:08, 11.13it/s] 45%|████▍     | 619/1380 [01:01<01:08, 11.11it/s] 45%|████▌     | 621/1380 [01:02<01:08, 11.13it/s] 45%|████▌     | 623/1380 [01:02<01:08, 11.13it/s] 45%|████▌     | 625/1380 [01:02<01:07, 11.14it/s] 45%|████▌     | 627/1380 [01:02<01:07, 11.13it/s] 46%|████▌     | 629/1380 [01:02<01:07, 11.13it/s] 46%|████▌     | 631/1380 [01:03<01:07, 11.12it/s] 46%|████▌     | 633/1380 [01:03<01:07, 11.11it/s] 46%|████▌     | 635/1380 [01:03<01:07, 11.11it/s] 46%|████▌     | 637/1380 [01:03<01:06, 11.12it/s] 46%|████▋     | 639/1380 [01:03<01:06, 11.12it/s] 46%|████▋     | 641/1380 [01:03<01:06, 11.11it/s] 47%|████▋     | 643/1380 [01:04<01:06, 11.09it/s] 47%|████▋     | 645/1380 [01:04<01:06, 11.11it/s] 47%|████▋     | 647/1380 [01:04<01:05, 11.12it/s] 47%|████▋     | 649/1380 [01:04<01:05, 11.10it/s] 47%|████▋     | 651/1380 [01:04<01:05, 11.12it/s] 47%|████▋     | 653/1380 [01:05<01:05, 11.11it/s] 47%|████▋     | 655/1380 [01:05<01:05, 11.11it/s] 48%|████▊     | 657/1380 [01:05<01:05, 11.10it/s] 48%|████▊     | 659/1380 [01:05<01:04, 11.11it/s] 48%|████▊     | 661/1380 [01:05<01:04, 11.12it/s] 48%|████▊     | 663/1380 [01:05<01:04, 11.11it/s] 48%|████▊     | 665/1380 [01:06<01:04, 11.11it/s] 48%|████▊     | 667/1380 [01:06<01:04, 11.10it/s] 48%|████▊     | 669/1380 [01:06<01:04, 11.10it/s] 49%|████▊     | 671/1380 [01:06<01:03, 11.08it/s] 49%|████▉     | 673/1380 [01:06<01:03, 11.09it/s] 49%|████▉     | 675/1380 [01:07<01:03, 11.09it/s] 49%|████▉     | 677/1380 [01:07<01:03, 11.09it/s] 49%|████▉     | 679/1380 [01:07<01:03, 11.07it/s] 49%|████▉     | 681/1380 [01:07<01:03, 11.08it/s] 49%|████▉     | 683/1380 [01:07<01:03, 11.06it/s] 50%|████▉     | 685/1380 [01:07<01:02, 11.04it/s] 50%|████▉     | 687/1380 [01:08<01:02, 11.07it/s] 50%|████▉     | 689/1380 [01:08<01:02, 11.09it/s] 50%|█████     | 691/1380 [01:08<01:02, 11.09it/s] 50%|█████     | 693/1380 [01:08<01:02, 11.06it/s] 50%|█████     | 695/1380 [01:08<01:01, 11.09it/s] 51%|█████     | 697/1380 [01:09<01:01, 11.10it/s] 51%|█████     | 699/1380 [01:09<01:01, 11.09it/s] 51%|█████     | 701/1380 [01:09<01:01, 11.07it/s] 51%|█████     | 703/1380 [01:09<01:01, 11.08it/s] 51%|█████     | 705/1380 [01:09<01:00, 11.09it/s] 51%|█████     | 707/1380 [01:09<01:00, 11.05it/s] 51%|█████▏    | 709/1380 [01:10<01:00, 11.06it/s] 52%|█████▏    | 711/1380 [01:10<01:00, 11.06it/s] 52%|█████▏    | 713/1380 [01:10<01:00, 11.08it/s] 52%|█████▏    | 715/1380 [01:10<01:00, 11.07it/s] 52%|█████▏    | 717/1380 [01:10<00:59, 11.08it/s] 52%|█████▏    | 719/1380 [01:10<00:59, 11.09it/s] 52%|█████▏    | 721/1380 [01:11<00:59, 11.10it/s] 52%|█████▏    | 723/1380 [01:11<00:59, 11.09it/s] 53%|█████▎    | 725/1380 [01:11<00:59, 11.10it/s] 53%|█████▎    | 727/1380 [01:11<00:58, 11.10it/s] 53%|█████▎    | 729/1380 [01:11<00:58, 11.10it/s] 53%|█████▎    | 731/1380 [01:12<00:58, 11.09it/s] 53%|█████▎    | 733/1380 [01:12<00:58, 11.10it/s] 53%|█████▎    | 735/1380 [01:12<00:58, 11.10it/s] 53%|█████▎    | 737/1380 [01:12<00:57, 11.10it/s] 54%|█████▎    | 739/1380 [01:12<00:57, 11.11it/s] 54%|█████▎    | 741/1380 [01:12<00:57, 11.11it/s] 54%|█████▍    | 743/1380 [01:13<00:57, 11.11it/s] 54%|█████▍    | 745/1380 [01:13<00:57, 11.10it/s] 54%|█████▍    | 747/1380 [01:13<00:57, 11.10it/s] 54%|█████▍    | 749/1380 [01:13<00:56, 11.10it/s] 54%|█████▍    | 751/1380 [01:13<00:56, 11.09it/s] 55%|█████▍    | 753/1380 [01:14<00:56, 11.06it/s] 55%|█████▍    | 755/1380 [01:14<00:56, 11.05it/s] 55%|█████▍    | 757/1380 [01:14<00:56, 11.05it/s] 55%|█████▌    | 759/1380 [01:14<00:56, 11.05it/s] 55%|█████▌    | 761/1380 [01:14<00:56, 11.05it/s] 55%|█████▌    | 763/1380 [01:14<00:55, 11.05it/s] 55%|█████▌    | 765/1380 [01:15<00:55, 11.06it/s] 56%|█████▌    | 767/1380 [01:15<00:55, 11.05it/s] 56%|█████▌    | 769/1380 [01:15<00:55, 11.06it/s] 56%|█████▌    | 771/1380 [01:15<00:54, 11.08it/s] 56%|█████▌    | 773/1380 [01:15<00:54, 11.05it/s] 56%|█████▌    | 775/1380 [01:16<00:54, 11.05it/s] 56%|█████▋    | 777/1380 [01:16<00:54, 10.99it/s] 56%|█████▋    | 779/1380 [01:16<00:54, 10.99it/s] 57%|█████▋    | 781/1380 [01:16<00:54, 11.02it/s] 57%|█████▋    | 783/1380 [01:16<00:54, 10.97it/s] 57%|█████▋    | 785/1380 [01:16<00:54, 11.01it/s] 57%|█████▋    | 787/1380 [01:17<00:53, 11.03it/s] 57%|█████▋    | 789/1380 [01:17<00:53, 11.03it/s] 57%|█████▋    | 791/1380 [01:17<00:53, 11.02it/s] 57%|█████▋    | 793/1380 [01:17<00:53, 11.05it/s] 58%|█████▊    | 795/1380 [01:17<00:52, 11.08it/s] 58%|█████▊    | 797/1380 [01:18<00:52, 11.08it/s] 58%|█████▊    | 799/1380 [01:18<00:52, 11.07it/s] 58%|█████▊    | 801/1380 [01:18<00:52, 11.08it/s] 58%|█████▊    | 803/1380 [01:18<00:52, 11.07it/s] 58%|█████▊    | 805/1380 [01:18<00:51, 11.08it/s] 58%|█████▊    | 807/1380 [01:18<00:51, 11.09it/s] 59%|█████▊    | 809/1380 [01:19<00:51, 11.08it/s] 59%|█████▉    | 811/1380 [01:19<00:51, 11.06it/s] 59%|█████▉    | 813/1380 [01:19<00:51, 11.08it/s] 59%|█████▉    | 815/1380 [01:19<00:51, 11.06it/s] 59%|█████▉    | 817/1380 [01:19<00:50, 11.06it/s] 59%|█████▉    | 819/1380 [01:20<00:50, 11.06it/s] 59%|█████▉    | 821/1380 [01:20<00:50, 11.06it/s] 60%|█████▉    | 823/1380 [01:20<00:50, 11.07it/s] 60%|█████▉    | 825/1380 [01:20<00:50, 11.08it/s] 60%|█████▉    | 827/1380 [01:20<00:49, 11.10it/s]                                                   60%|██████    | 828/1380 [01:20<00:49, 11.10it/s][INFO|trainer.py:755] 2023-11-15 20:38:48,051 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:38:48,053 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:38:48,053 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:38:48,053 >>   Batch size = 8
{'eval_loss': 0.40954217314720154, 'eval_accuracy': 0.8638838475499092, 'eval_micro_f1': 0.8638838475499093, 'eval_macro_f1': 0.8471149431706957, 'eval_runtime': 2.5885, 'eval_samples_per_second': 851.449, 'eval_steps_per_second': 106.624, 'epoch': 2.0}
{'loss': 0.1903, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 120.16it/s][A
  9%|▉         | 26/276 [00:00<00:02, 113.52it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 111.22it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 109.93it/s][A
 22%|██▏       | 61/276 [00:00<00:01, 108.84it/s][A
 26%|██▌       | 72/276 [00:00<00:01, 108.16it/s][A
 30%|███       | 83/276 [00:00<00:01, 107.77it/s][A
 34%|███▍      | 94/276 [00:00<00:01, 107.19it/s][A
 38%|███▊      | 105/276 [00:00<00:01, 106.52it/s][A
 42%|████▏     | 116/276 [00:01<00:01, 106.18it/s][A
 46%|████▌     | 127/276 [00:01<00:01, 106.27it/s][A
 50%|█████     | 138/276 [00:01<00:01, 106.20it/s][A
 54%|█████▍    | 149/276 [00:01<00:01, 106.14it/s][A
 58%|█████▊    | 160/276 [00:01<00:01, 106.08it/s][A
 62%|██████▏   | 171/276 [00:01<00:00, 105.90it/s][A
 66%|██████▌   | 182/276 [00:01<00:00, 105.90it/s][A
 70%|██████▉   | 193/276 [00:01<00:00, 105.73it/s][A
 74%|███████▍  | 204/276 [00:01<00:00, 105.35it/s][A
 78%|███████▊  | 215/276 [00:02<00:00, 105.04it/s][A
 82%|████████▏ | 226/276 [00:02<00:00, 105.07it/s][A
 86%|████████▌ | 237/276 [00:02<00:00, 105.12it/s][A
 90%|████████▉ | 248/276 [00:02<00:00, 105.15it/s][A
 94%|█████████▍| 259/276 [00:02<00:00, 105.27it/s][A
 98%|█████████▊| 270/276 [00:02<00:00, 105.16it/s][A                                                  
                                                  [A 60%|██████    | 828/1380 [01:23<00:49, 11.10it/s]
100%|██████████| 276/276 [00:02<00:00, 105.16it/s][A
                                                  [A 60%|██████    | 829/1380 [01:23<04:26,  2.07it/s] 60%|██████    | 831/1380 [01:23<03:20,  2.73it/s] 60%|██████    | 833/1380 [01:23<02:35,  3.53it/s] 61%|██████    | 835/1380 [01:24<02:03,  4.43it/s] 61%|██████    | 837/1380 [01:24<01:40,  5.41it/s] 61%|██████    | 839/1380 [01:24<01:24,  6.38it/s] 61%|██████    | 841/1380 [01:24<01:13,  7.31it/s] 61%|██████    | 843/1380 [01:24<01:06,  8.12it/s] 61%|██████    | 845/1380 [01:25<01:00,  8.82it/s] 61%|██████▏   | 847/1380 [01:25<00:56,  9.38it/s] 62%|██████▏   | 849/1380 [01:25<00:54,  9.82it/s] 62%|██████▏   | 851/1380 [01:25<00:52, 10.17it/s] 62%|██████▏   | 853/1380 [01:25<00:50, 10.42it/s] 62%|██████▏   | 855/1380 [01:25<00:49, 10.60it/s] 62%|██████▏   | 857/1380 [01:26<00:48, 10.72it/s] 62%|██████▏   | 859/1380 [01:26<00:48, 10.83it/s] 62%|██████▏   | 861/1380 [01:26<00:47, 10.91it/s] 63%|██████▎   | 863/1380 [01:26<00:47, 10.94it/s] 63%|██████▎   | 865/1380 [01:26<00:46, 10.98it/s] 63%|██████▎   | 867/1380 [01:27<00:46, 11.00it/s] 63%|██████▎   | 869/1380 [01:27<00:46, 11.02it/s] 63%|██████▎   | 871/1380 [01:27<00:46, 11.03it/s] 63%|██████▎   | 873/1380 [01:27<00:45, 11.04it/s] 63%|██████▎   | 875/1380 [01:27<00:45, 11.05it/s] 64%|██████▎   | 877/1380 [01:27<00:45, 11.05it/s] 64%|██████▎   | 879/1380 [01:28<00:45, 11.04it/s] 64%|██████▍   | 881/1380 [01:28<00:45, 11.04it/s] 64%|██████▍   | 883/1380 [01:28<00:45, 11.04it/s] 64%|██████▍   | 885/1380 [01:28<00:44, 11.05it/s] 64%|██████▍   | 887/1380 [01:28<00:44, 11.04it/s] 64%|██████▍   | 889/1380 [01:28<00:44, 11.04it/s] 65%|██████▍   | 891/1380 [01:29<00:44, 11.05it/s] 65%|██████▍   | 893/1380 [01:29<00:44, 11.05it/s] 65%|██████▍   | 895/1380 [01:29<00:43, 11.05it/s] 65%|██████▌   | 897/1380 [01:29<00:43, 11.04it/s] 65%|██████▌   | 899/1380 [01:29<00:43, 11.02it/s] 65%|██████▌   | 901/1380 [01:30<00:43, 11.02it/s] 65%|██████▌   | 903/1380 [01:30<00:43, 11.03it/s] 66%|██████▌   | 905/1380 [01:30<00:43, 11.04it/s] 66%|██████▌   | 907/1380 [01:30<00:42, 11.05it/s] 66%|██████▌   | 909/1380 [01:30<00:42, 11.03it/s] 66%|██████▌   | 911/1380 [01:30<00:42, 11.05it/s] 66%|██████▌   | 913/1380 [01:31<00:42, 11.05it/s] 66%|██████▋   | 915/1380 [01:31<00:42, 11.04it/s] 66%|██████▋   | 917/1380 [01:31<00:41, 11.03it/s] 67%|██████▋   | 919/1380 [01:31<00:41, 11.03it/s] 67%|██████▋   | 921/1380 [01:31<00:41, 11.05it/s] 67%|██████▋   | 923/1380 [01:32<00:41, 11.05it/s] 67%|██████▋   | 925/1380 [01:32<00:41, 11.06it/s] 67%|██████▋   | 927/1380 [01:32<00:40, 11.06it/s] 67%|██████▋   | 929/1380 [01:32<00:40, 11.06it/s] 67%|██████▋   | 931/1380 [01:32<00:40, 11.04it/s] 68%|██████▊   | 933/1380 [01:32<00:40, 11.03it/s] 68%|██████▊   | 935/1380 [01:33<00:40, 11.03it/s] 68%|██████▊   | 937/1380 [01:33<00:40, 11.01it/s] 68%|██████▊   | 939/1380 [01:33<00:40, 11.02it/s] 68%|██████▊   | 941/1380 [01:33<00:39, 11.03it/s] 68%|██████▊   | 943/1380 [01:33<00:39, 11.04it/s] 68%|██████▊   | 945/1380 [01:34<00:39, 11.02it/s] 69%|██████▊   | 947/1380 [01:34<00:39, 11.02it/s] 69%|██████▉   | 949/1380 [01:34<00:39, 11.03it/s] 69%|██████▉   | 951/1380 [01:34<00:38, 11.03it/s] 69%|██████▉   | 953/1380 [01:34<00:38, 11.04it/s] 69%|██████▉   | 955/1380 [01:34<00:38, 11.05it/s] 69%|██████▉   | 957/1380 [01:35<00:38, 11.06it/s] 69%|██████▉   | 959/1380 [01:35<00:38, 11.05it/s] 70%|██████▉   | 961/1380 [01:35<00:38, 11.02it/s] 70%|██████▉   | 963/1380 [01:35<00:37, 11.02it/s] 70%|██████▉   | 965/1380 [01:35<00:37, 11.03it/s] 70%|███████   | 967/1380 [01:36<00:37, 11.03it/s] 70%|███████   | 969/1380 [01:36<00:37, 11.03it/s] 70%|███████   | 971/1380 [01:36<00:37, 11.03it/s] 71%|███████   | 973/1380 [01:36<00:36, 11.03it/s] 71%|███████   | 975/1380 [01:36<00:36, 11.01it/s] 71%|███████   | 977/1380 [01:36<00:36, 11.02it/s] 71%|███████   | 979/1380 [01:37<00:36, 11.02it/s] 71%|███████   | 981/1380 [01:37<00:36, 11.04it/s] 71%|███████   | 983/1380 [01:37<00:35, 11.04it/s] 71%|███████▏  | 985/1380 [01:37<00:35, 11.04it/s] 72%|███████▏  | 987/1380 [01:37<00:35, 11.05it/s] 72%|███████▏  | 989/1380 [01:38<00:35, 11.02it/s] 72%|███████▏  | 991/1380 [01:38<00:35, 11.02it/s] 72%|███████▏  | 993/1380 [01:38<00:35, 11.00it/s] 72%|███████▏  | 995/1380 [01:38<00:34, 11.02it/s] 72%|███████▏  | 997/1380 [01:38<00:34, 11.03it/s] 72%|███████▏  | 999/1380 [01:38<00:34, 11.02it/s] 73%|███████▎  | 1001/1380 [01:39<00:34, 11.00it/s] 73%|███████▎  | 1003/1380 [01:39<00:34, 11.00it/s] 73%|███████▎  | 1005/1380 [01:39<00:34, 11.00it/s] 73%|███████▎  | 1007/1380 [01:39<00:33, 11.00it/s] 73%|███████▎  | 1009/1380 [01:39<00:33, 10.99it/s] 73%|███████▎  | 1011/1380 [01:40<00:33, 10.99it/s] 73%|███████▎  | 1013/1380 [01:40<00:33, 10.99it/s] 74%|███████▎  | 1015/1380 [01:40<00:33, 10.99it/s] 74%|███████▎  | 1017/1380 [01:40<00:32, 11.01it/s] 74%|███████▍  | 1019/1380 [01:40<00:32, 11.02it/s] 74%|███████▍  | 1021/1380 [01:40<00:32, 11.03it/s] 74%|███████▍  | 1023/1380 [01:41<00:32, 11.01it/s] 74%|███████▍  | 1025/1380 [01:41<00:32, 11.01it/s] 74%|███████▍  | 1027/1380 [01:41<00:32, 11.00it/s] 75%|███████▍  | 1029/1380 [01:41<00:31, 11.02it/s] 75%|███████▍  | 1031/1380 [01:41<00:31, 11.02it/s] 75%|███████▍  | 1033/1380 [01:42<00:31, 11.00it/s] 75%|███████▌  | 1035/1380 [01:42<00:31, 11.00it/s] 75%|███████▌  | 1037/1380 [01:42<00:31, 10.98it/s] 75%|███████▌  | 1039/1380 [01:42<00:31, 10.99it/s] 75%|███████▌  | 1041/1380 [01:42<00:30, 11.00it/s] 76%|███████▌  | 1043/1380 [01:42<00:30, 11.00it/s] 76%|███████▌  | 1045/1380 [01:43<00:30, 11.01it/s] 76%|███████▌  | 1047/1380 [01:43<00:30, 11.00it/s] 76%|███████▌  | 1049/1380 [01:43<00:30, 11.00it/s] 76%|███████▌  | 1051/1380 [01:43<00:29, 11.01it/s] 76%|███████▋  | 1053/1380 [01:43<00:29, 11.00it/s] 76%|███████▋  | 1055/1380 [01:44<00:29, 10.98it/s] 77%|███████▋  | 1057/1380 [01:44<00:29, 10.97it/s] 77%|███████▋  | 1059/1380 [01:44<00:29, 10.98it/s] 77%|███████▋  | 1061/1380 [01:44<00:29, 10.98it/s] 77%|███████▋  | 1063/1380 [01:44<00:28, 10.95it/s] 77%|███████▋  | 1065/1380 [01:44<00:28, 10.97it/s] 77%|███████▋  | 1067/1380 [01:45<00:28, 10.98it/s] 77%|███████▋  | 1069/1380 [01:45<00:28, 10.98it/s] 78%|███████▊  | 1071/1380 [01:45<00:28, 11.00it/s] 78%|███████▊  | 1073/1380 [01:45<00:27, 11.00it/s] 78%|███████▊  | 1075/1380 [01:45<00:27, 11.01it/s] 78%|███████▊  | 1077/1380 [01:46<00:27, 11.02it/s] 78%|███████▊  | 1079/1380 [01:46<00:27, 11.02it/s] 78%|███████▊  | 1081/1380 [01:46<00:27, 11.03it/s] 78%|███████▊  | 1083/1380 [01:46<00:26, 11.03it/s] 79%|███████▊  | 1085/1380 [01:46<00:26, 11.02it/s] 79%|███████▉  | 1087/1380 [01:46<00:26, 11.01it/s] 79%|███████▉  | 1089/1380 [01:47<00:26, 11.01it/s] 79%|███████▉  | 1091/1380 [01:47<00:26, 11.02it/s] 79%|███████▉  | 1093/1380 [01:47<00:26, 11.01it/s] 79%|███████▉  | 1095/1380 [01:47<00:25, 11.01it/s] 79%|███████▉  | 1097/1380 [01:47<00:25, 11.01it/s] 80%|███████▉  | 1099/1380 [01:48<00:25, 11.00it/s] 80%|███████▉  | 1101/1380 [01:48<00:25, 10.99it/s] 80%|███████▉  | 1103/1380 [01:48<00:25, 11.03it/s]                                                    80%|████████  | 1104/1380 [01:48<00:25, 11.03it/s][INFO|trainer.py:755] 2023-11-15 20:39:15,713 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:39:15,717 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:39:15,717 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:39:15,718 >>   Batch size = 8
{'eval_loss': 0.453052818775177, 'eval_accuracy': 0.8598003629764065, 'eval_micro_f1': 0.8598003629764064, 'eval_macro_f1': 0.8448601746179172, 'eval_runtime': 2.6444, 'eval_samples_per_second': 833.457, 'eval_steps_per_second': 104.371, 'epoch': 3.0}
{'loss': 0.126, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 119.50it/s][A
  9%|▉         | 25/276 [00:00<00:02, 113.06it/s][A
 13%|█▎        | 37/276 [00:00<00:02, 110.87it/s][A
 18%|█▊        | 49/276 [00:00<00:02, 109.38it/s][A
 22%|██▏       | 60/276 [00:00<00:01, 108.23it/s][A
 26%|██▌       | 71/276 [00:00<00:01, 107.30it/s][A
 30%|██▉       | 82/276 [00:00<00:01, 106.71it/s][A
 34%|███▎      | 93/276 [00:00<00:01, 106.31it/s][A
 38%|███▊      | 104/276 [00:00<00:01, 105.29it/s][A
 42%|████▏     | 115/276 [00:01<00:01, 104.86it/s][A
 46%|████▌     | 126/276 [00:01<00:01, 104.59it/s][A
 50%|████▉     | 137/276 [00:01<00:01, 104.90it/s][A
 54%|█████▎    | 148/276 [00:01<00:01, 105.16it/s][A
 58%|█████▊    | 159/276 [00:01<00:01, 105.22it/s][A
 62%|██████▏   | 170/276 [00:01<00:01, 104.99it/s][A
 66%|██████▌   | 181/276 [00:01<00:00, 104.57it/s][A
 70%|██████▉   | 192/276 [00:01<00:00, 104.24it/s][A
 74%|███████▎  | 203/276 [00:01<00:00, 104.01it/s][A
 78%|███████▊  | 214/276 [00:02<00:00, 103.57it/s][A
 82%|████████▏ | 225/276 [00:02<00:00, 103.43it/s][A
 86%|████████▌ | 236/276 [00:02<00:00, 103.69it/s][A
 89%|████████▉ | 247/276 [00:02<00:00, 103.94it/s][A
 93%|█████████▎| 258/276 [00:02<00:00, 103.99it/s][A
 97%|█████████▋| 269/276 [00:02<00:00, 103.83it/s][A                                                   
                                                  [A 80%|████████  | 1104/1380 [01:51<00:25, 11.03it/s]
100%|██████████| 276/276 [00:02<00:00, 103.83it/s][A
                                                  [A 80%|████████  | 1105/1380 [01:51<02:14,  2.05it/s] 80%|████████  | 1107/1380 [01:51<01:41,  2.70it/s] 80%|████████  | 1109/1380 [01:51<01:17,  3.49it/s] 81%|████████  | 1111/1380 [01:51<01:01,  4.39it/s] 81%|████████  | 1113/1380 [01:51<00:49,  5.36it/s] 81%|████████  | 1115/1380 [01:52<00:41,  6.32it/s] 81%|████████  | 1117/1380 [01:52<00:36,  7.25it/s] 81%|████████  | 1119/1380 [01:52<00:32,  8.08it/s] 81%|████████  | 1121/1380 [01:52<00:29,  8.78it/s] 81%|████████▏ | 1123/1380 [01:52<00:27,  9.34it/s] 82%|████████▏ | 1125/1380 [01:53<00:26,  9.80it/s] 82%|████████▏ | 1127/1380 [01:53<00:24, 10.14it/s] 82%|████████▏ | 1129/1380 [01:53<00:24, 10.38it/s] 82%|████████▏ | 1131/1380 [01:53<00:23, 10.55it/s] 82%|████████▏ | 1133/1380 [01:53<00:23, 10.68it/s] 82%|████████▏ | 1135/1380 [01:53<00:22, 10.78it/s] 82%|████████▏ | 1137/1380 [01:54<00:22, 10.85it/s] 83%|████████▎ | 1139/1380 [01:54<00:22, 10.89it/s] 83%|████████▎ | 1141/1380 [01:54<00:21, 10.92it/s] 83%|████████▎ | 1143/1380 [01:54<00:21, 10.93it/s] 83%|████████▎ | 1145/1380 [01:54<00:21, 10.93it/s] 83%|████████▎ | 1147/1380 [01:55<00:21, 10.96it/s] 83%|████████▎ | 1149/1380 [01:55<00:21, 10.98it/s] 83%|████████▎ | 1151/1380 [01:55<00:20, 10.98it/s] 84%|████████▎ | 1153/1380 [01:55<00:20, 10.97it/s] 84%|████████▎ | 1155/1380 [01:55<00:20, 11.00it/s] 84%|████████▍ | 1157/1380 [01:55<00:20, 11.01it/s] 84%|████████▍ | 1159/1380 [01:56<00:20, 11.03it/s] 84%|████████▍ | 1161/1380 [01:56<00:19, 11.01it/s] 84%|████████▍ | 1163/1380 [01:56<00:19, 11.00it/s] 84%|████████▍ | 1165/1380 [01:56<00:19, 10.99it/s] 85%|████████▍ | 1167/1380 [01:56<00:19, 10.99it/s] 85%|████████▍ | 1169/1380 [01:57<00:19, 11.00it/s] 85%|████████▍ | 1171/1380 [01:57<00:18, 11.01it/s] 85%|████████▌ | 1173/1380 [01:57<00:18, 11.02it/s] 85%|████████▌ | 1175/1380 [01:57<00:18, 11.01it/s] 85%|████████▌ | 1177/1380 [01:57<00:18, 11.00it/s] 85%|████████▌ | 1179/1380 [01:57<00:18, 11.02it/s] 86%|████████▌ | 1181/1380 [01:58<00:18, 11.03it/s] 86%|████████▌ | 1183/1380 [01:58<00:17, 11.03it/s] 86%|████████▌ | 1185/1380 [01:58<00:17, 11.03it/s] 86%|████████▌ | 1187/1380 [01:58<00:17, 11.02it/s] 86%|████████▌ | 1189/1380 [01:58<00:17, 11.00it/s] 86%|████████▋ | 1191/1380 [01:59<00:17, 11.00it/s] 86%|████████▋ | 1193/1380 [01:59<00:16, 11.00it/s] 87%|████████▋ | 1195/1380 [01:59<00:16, 11.03it/s] 87%|████████▋ | 1197/1380 [01:59<00:16, 11.02it/s] 87%|████████▋ | 1199/1380 [01:59<00:16, 11.01it/s] 87%|████████▋ | 1201/1380 [01:59<00:16, 10.99it/s] 87%|████████▋ | 1203/1380 [02:00<00:16, 11.01it/s] 87%|████████▋ | 1205/1380 [02:00<00:15, 11.00it/s] 87%|████████▋ | 1207/1380 [02:00<00:15, 11.00it/s] 88%|████████▊ | 1209/1380 [02:00<00:15, 11.01it/s] 88%|████████▊ | 1211/1380 [02:00<00:15, 11.01it/s] 88%|████████▊ | 1213/1380 [02:01<00:15, 11.01it/s] 88%|████████▊ | 1215/1380 [02:01<00:14, 11.00it/s] 88%|████████▊ | 1217/1380 [02:01<00:14, 11.01it/s] 88%|████████▊ | 1219/1380 [02:01<00:14, 11.02it/s] 88%|████████▊ | 1221/1380 [02:01<00:14, 11.00it/s] 89%|████████▊ | 1223/1380 [02:01<00:14, 11.00it/s] 89%|████████▉ | 1225/1380 [02:02<00:14, 11.02it/s] 89%|████████▉ | 1227/1380 [02:02<00:13, 11.02it/s] 89%|████████▉ | 1229/1380 [02:02<00:13, 11.02it/s] 89%|████████▉ | 1231/1380 [02:02<00:13, 11.03it/s] 89%|████████▉ | 1233/1380 [02:02<00:13, 11.02it/s] 89%|████████▉ | 1235/1380 [02:03<00:13, 11.00it/s] 90%|████████▉ | 1237/1380 [02:03<00:13, 10.97it/s] 90%|████████▉ | 1239/1380 [02:03<00:12, 10.98it/s] 90%|████████▉ | 1241/1380 [02:03<00:12, 10.98it/s] 90%|█████████ | 1243/1380 [02:03<00:12, 10.95it/s] 90%|█████████ | 1245/1380 [02:03<00:12, 10.97it/s] 90%|█████████ | 1247/1380 [02:04<00:12, 11.00it/s] 91%|█████████ | 1249/1380 [02:04<00:11, 11.02it/s] 91%|█████████ | 1251/1380 [02:04<00:11, 10.99it/s] 91%|█████████ | 1253/1380 [02:04<00:11, 10.99it/s] 91%|█████████ | 1255/1380 [02:04<00:11, 10.98it/s] 91%|█████████ | 1257/1380 [02:05<00:11, 10.99it/s] 91%|█████████ | 1259/1380 [02:05<00:11, 10.97it/s] 91%|█████████▏| 1261/1380 [02:05<00:10, 10.98it/s] 92%|█████████▏| 1263/1380 [02:05<00:10, 10.99it/s] 92%|█████████▏| 1265/1380 [02:05<00:10, 10.99it/s] 92%|█████████▏| 1267/1380 [02:05<00:10, 10.99it/s] 92%|█████████▏| 1269/1380 [02:06<00:10, 11.00it/s] 92%|█████████▏| 1271/1380 [02:06<00:09, 11.00it/s] 92%|█████████▏| 1273/1380 [02:06<00:09, 10.98it/s] 92%|█████████▏| 1275/1380 [02:06<00:09, 10.98it/s] 93%|█████████▎| 1277/1380 [02:06<00:09, 11.01it/s] 93%|█████████▎| 1279/1380 [02:07<00:09, 11.01it/s] 93%|█████████▎| 1281/1380 [02:07<00:09, 11.00it/s] 93%|█████████▎| 1283/1380 [02:07<00:08, 10.99it/s] 93%|█████████▎| 1285/1380 [02:07<00:08, 11.00it/s] 93%|█████████▎| 1287/1380 [02:07<00:08, 11.03it/s] 93%|█████████▎| 1289/1380 [02:07<00:08, 11.04it/s] 94%|█████████▎| 1291/1380 [02:08<00:08, 11.03it/s] 94%|█████████▎| 1293/1380 [02:08<00:07, 11.01it/s] 94%|█████████▍| 1295/1380 [02:08<00:07, 10.99it/s] 94%|█████████▍| 1297/1380 [02:08<00:07, 11.00it/s] 94%|█████████▍| 1299/1380 [02:08<00:07, 11.02it/s] 94%|█████████▍| 1301/1380 [02:09<00:07, 11.04it/s] 94%|█████████▍| 1303/1380 [02:09<00:06, 11.01it/s] 95%|█████████▍| 1305/1380 [02:09<00:06, 11.01it/s] 95%|█████████▍| 1307/1380 [02:09<00:06, 11.00it/s] 95%|█████████▍| 1309/1380 [02:09<00:06, 10.98it/s] 95%|█████████▌| 1311/1380 [02:09<00:06, 11.00it/s] 95%|█████████▌| 1313/1380 [02:10<00:06, 11.03it/s] 95%|█████████▌| 1315/1380 [02:10<00:05, 11.03it/s] 95%|█████████▌| 1317/1380 [02:10<00:05, 11.01it/s] 96%|█████████▌| 1319/1380 [02:10<00:05, 10.99it/s] 96%|█████████▌| 1321/1380 [02:10<00:05, 11.00it/s] 96%|█████████▌| 1323/1380 [02:11<00:05, 11.03it/s] 96%|█████████▌| 1325/1380 [02:11<00:04, 11.03it/s] 96%|█████████▌| 1327/1380 [02:11<00:04, 11.04it/s] 96%|█████████▋| 1329/1380 [02:11<00:04, 11.03it/s] 96%|█████████▋| 1331/1380 [02:11<00:04, 11.02it/s] 97%|█████████▋| 1333/1380 [02:11<00:04, 11.01it/s] 97%|█████████▋| 1335/1380 [02:12<00:04, 11.01it/s] 97%|█████████▋| 1337/1380 [02:12<00:03, 11.03it/s] 97%|█████████▋| 1339/1380 [02:12<00:03, 11.03it/s] 97%|█████████▋| 1341/1380 [02:12<00:03, 11.01it/s] 97%|█████████▋| 1343/1380 [02:12<00:03, 11.02it/s] 97%|█████████▋| 1345/1380 [02:13<00:03, 11.01it/s] 98%|█████████▊| 1347/1380 [02:13<00:02, 11.01it/s] 98%|█████████▊| 1349/1380 [02:13<00:02, 11.00it/s] 98%|█████████▊| 1351/1380 [02:13<00:02, 11.02it/s] 98%|█████████▊| 1353/1380 [02:13<00:02, 11.01it/s] 98%|█████████▊| 1355/1380 [02:13<00:02, 11.01it/s] 98%|█████████▊| 1357/1380 [02:14<00:02, 10.99it/s] 98%|█████████▊| 1359/1380 [02:14<00:01, 11.01it/s] 99%|█████████▊| 1361/1380 [02:14<00:01, 11.02it/s] 99%|█████████▉| 1363/1380 [02:14<00:01, 11.03it/s] 99%|█████████▉| 1365/1380 [02:14<00:01, 11.02it/s] 99%|█████████▉| 1367/1380 [02:15<00:01, 11.01it/s] 99%|█████████▉| 1369/1380 [02:15<00:00, 11.00it/s] 99%|█████████▉| 1371/1380 [02:15<00:00, 10.99it/s] 99%|█████████▉| 1373/1380 [02:15<00:00, 11.01it/s]100%|█████████▉| 1375/1380 [02:15<00:00, 11.03it/s]100%|█████████▉| 1377/1380 [02:15<00:00, 11.03it/s]100%|█████████▉| 1379/1380 [02:16<00:00, 11.04it/s]                                                   100%|██████████| 1380/1380 [02:16<00:00, 11.04it/s][INFO|trainer.py:755] 2023-11-15 20:39:43,448 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:39:43,450 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:39:43,450 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:39:43,450 >>   Batch size = 8
{'eval_loss': 0.5311357975006104, 'eval_accuracy': 0.8602540834845736, 'eval_micro_f1': 0.8602540834845736, 'eval_macro_f1': 0.8438914409342045, 'eval_runtime': 2.6771, 'eval_samples_per_second': 823.275, 'eval_steps_per_second': 103.096, 'epoch': 4.0}
{'loss': 0.0815, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  4%|▍         | 12/276 [00:00<00:02, 119.76it/s][A
  9%|▊         | 24/276 [00:00<00:02, 113.20it/s][A
 13%|█▎        | 36/276 [00:00<00:02, 110.92it/s][A
 17%|█▋        | 48/276 [00:00<00:02, 109.62it/s][A
 21%|██▏       | 59/276 [00:00<00:01, 108.96it/s][A
 25%|██▌       | 70/276 [00:00<00:01, 107.94it/s][A
 29%|██▉       | 81/276 [00:00<00:01, 107.28it/s][A
 33%|███▎      | 92/276 [00:00<00:01, 106.64it/s][A
 37%|███▋      | 103/276 [00:00<00:01, 105.77it/s][A
 41%|████▏     | 114/276 [00:01<00:01, 105.34it/s][A
 45%|████▌     | 125/276 [00:01<00:01, 105.18it/s][A
 49%|████▉     | 136/276 [00:01<00:01, 105.23it/s][A
 53%|█████▎    | 147/276 [00:01<00:01, 105.03it/s][A
 57%|█████▋    | 158/276 [00:01<00:01, 105.01it/s][A
 61%|██████    | 169/276 [00:01<00:01, 104.93it/s][A
 65%|██████▌   | 180/276 [00:01<00:00, 104.83it/s][A
 69%|██████▉   | 191/276 [00:01<00:00, 104.64it/s][A
 73%|███████▎  | 202/276 [00:01<00:00, 104.25it/s][A
 77%|███████▋  | 213/276 [00:02<00:00, 103.58it/s][A
 81%|████████  | 224/276 [00:02<00:00, 103.45it/s][A
 85%|████████▌ | 235/276 [00:02<00:00, 103.69it/s][A
 89%|████████▉ | 246/276 [00:02<00:00, 103.87it/s][A
 93%|█████████▎| 257/276 [00:02<00:00, 104.15it/s][A
 97%|█████████▋| 268/276 [00:02<00:00, 104.10it/s][A                                                   
                                                  [A100%|██████████| 1380/1380 [02:18<00:00, 11.04it/s]
100%|██████████| 276/276 [00:02<00:00, 104.10it/s][A
                                                  [A[INFO|trainer.py:1963] 2023-11-15 20:39:46,119 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:18<00:00, 11.04it/s]100%|██████████| 1380/1380 [02:18<00:00,  9.94it/s]
[INFO|trainer.py:2855] 2023-11-15 20:39:46,123 >> Saving model checkpoint to ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2
[INFO|configuration_utils.py:460] 2023-11-15 20:39:46,126 >> Configuration saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:39:47,110 >> Model weights saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:39:47,112 >> tokenizer config file saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:39:47,115 >> Special tokens file saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed2/special_tokens_map.json
{'eval_loss': 0.5905539393424988, 'eval_accuracy': 0.8602540834845736, 'eval_micro_f1': 0.8602540834845736, 'eval_macro_f1': 0.8440202932340016, 'eval_runtime': 2.665, 'eval_samples_per_second': 827.006, 'eval_steps_per_second': 103.563, 'epoch': 5.0}
{'train_runtime': 138.8929, 'train_samples_per_second': 317.367, 'train_steps_per_second': 9.936, 'train_loss': 0.22392953651538794, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2239
  train_runtime            = 0:02:18.89
  train_samples            =       8816
  train_samples_per_second =    317.367
  train_steps_per_second   =      9.936
11/15/2023 20:39:47 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:39:47,160 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:39:47,161 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:39:47,162 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:39:47,162 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  4%|▍         | 12/276 [00:00<00:02, 119.18it/s]  9%|▊         | 24/276 [00:00<00:02, 110.82it/s] 13%|█▎        | 36/276 [00:00<00:02, 108.31it/s] 17%|█▋        | 47/276 [00:00<00:02, 106.71it/s] 21%|██        | 58/276 [00:00<00:02, 106.10it/s] 25%|██▌       | 69/276 [00:00<00:01, 105.56it/s] 29%|██▉       | 80/276 [00:00<00:01, 105.46it/s] 33%|███▎      | 91/276 [00:00<00:01, 105.10it/s] 37%|███▋      | 102/276 [00:00<00:01, 104.32it/s] 41%|████      | 113/276 [00:01<00:01, 103.84it/s] 45%|████▍     | 124/276 [00:01<00:01, 104.15it/s] 49%|████▉     | 135/276 [00:01<00:01, 104.15it/s] 53%|█████▎    | 146/276 [00:01<00:01, 104.25it/s] 57%|█████▋    | 157/276 [00:01<00:01, 104.28it/s] 61%|██████    | 168/276 [00:01<00:01, 104.31it/s] 65%|██████▍   | 179/276 [00:01<00:00, 104.36it/s] 69%|██████▉   | 190/276 [00:01<00:00, 104.22it/s] 73%|███████▎  | 201/276 [00:01<00:00, 104.29it/s] 77%|███████▋  | 212/276 [00:02<00:00, 104.17it/s] 81%|████████  | 223/276 [00:02<00:00, 104.26it/s] 85%|████████▍ | 234/276 [00:02<00:00, 104.57it/s] 89%|████████▉ | 245/276 [00:02<00:00, 104.65it/s] 93%|█████████▎| 256/276 [00:02<00:00, 104.62it/s] 97%|█████████▋| 267/276 [00:02<00:00, 104.47it/s]100%|██████████| 276/276 [00:02<00:00, 103.43it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8603
  eval_loss               =     0.5906
  eval_macro_f1           =      0.844
  eval_micro_f1           =     0.8603
  eval_runtime            = 0:00:02.68
  eval_samples            =       2204
  eval_samples_per_second =    822.159
  eval_steps_per_second   =    102.956
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁█▄▅▅▅
wandb:                      eval/loss ▁▁▃▆██
wandb:                  eval/macro_f1 ▁█▇▇▇▇
wandb:                  eval/micro_f1 ▁█▄▅▅▅
wandb:                   eval/runtime ▂▁▅█▇█
wandb:        eval/samples_per_second ▇█▄▁▂▁
wandb:          eval/steps_per_second ▇█▄▁▂▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.86025
wandb:                      eval/loss 0.59055
wandb:                  eval/macro_f1 0.84402
wandb:                  eval/micro_f1 0.86025
wandb:                   eval/runtime 2.6807
wandb:        eval/samples_per_second 822.159
wandb:          eval/steps_per_second 102.956
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0815
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.22393
wandb:            train/train_runtime 138.8929
wandb: train/train_samples_per_second 317.367
wandb:   train/train_steps_per_second 9.936
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_203608-sw6t4phn
wandb: Find logs at: ./wandb/offline-run-20231115_203608-sw6t4phn/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_roberta-base_adapter__seed2/runs/Nov15_20-40-01_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_roberta-base_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_roberta-base_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:40:01 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:40:01 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_roberta-base_adapter__seed2/runs/Nov15_20-40-00_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_roberta-base_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_roberta-base_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 20:40:16,458 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:40:16,469 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:40:26,484 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:40:36,502 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:40:36,503 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:40:56,551 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:40:56,551 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:40:56,551 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:40:56,552 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:40:56,552 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:40:56,552 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:40:56,553 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:40:56,554 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:41:16,722 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:41:17,476 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:41:17,477 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  29%|██▉       | 2000/6840 [00:00<00:00, 16978.48 examples/s]Running tokenizer on dataset:  58%|█████▊    | 4000/6840 [00:00<00:00, 17726.61 examples/s]Running tokenizer on dataset:  88%|████████▊ | 6000/6840 [00:00<00:00, 17672.74 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 17477.22 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 19324.96 examples/s]
11/15/2023 20:41:17 - INFO - __main__ - Sample 4545 of the training set: {'text': "Yankees' Brown Has Successful Surgery Kevin Brown had successful surgery on his broken left hand Sunday and vowed to pitch again for the Yankees this season.", 'label': 0, 'input_ids': [0, 43033, 41563, 108, 1547, 6233, 14361, 2650, 26793, 2363, 1547, 56, 1800, 3012, 15, 39, 3187, 314, 865, 395, 8, 7588, 7, 3242, 456, 13, 5, 6742, 42, 191, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:41:17 - INFO - __main__ - Sample 2873 of the training set: {'text': 'Bush shields shrimp industry The Bush administration yesterday said Chinese and Vietnamese shrimp are sold at unfairly low prices in the United States, siding with US fishermen as they try to fend off overseas competition.', 'label': 1, 'input_ids': [0, 43294, 31768, 22126, 539, 20, 3516, 942, 2350, 26, 1111, 8, 16859, 22126, 32, 1088, 23, 19106, 614, 850, 11, 5, 315, 532, 6, 579, 8231, 19, 382, 16516, 25, 51, 860, 7, 26885, 160, 4886, 1465, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:41:17 - INFO - __main__ - Sample 2892 of the training set: {'text': 'How the credit policy will affect you The Reserve Bank of India announced the mid-term review of its monetary policy on Tuesday. Though the central Bank kept away from the much expected interest rate hike, the policy contained recommendations ', 'label': 1, 'input_ids': [0, 6179, 5, 1361, 714, 40, 3327, 47, 20, 3965, 788, 9, 666, 585, 5, 1084, 12, 1279, 1551, 9, 63, 5775, 714, 15, 294, 4, 3791, 5, 1353, 788, 1682, 409, 31, 5, 203, 421, 773, 731, 5960, 6, 5, 714, 5558, 4664, 1437, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:41:18 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:41:19,127 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:41:19,135 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:41:19,135 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 20:41:19,135 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:41:19,136 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:41:19,136 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:41:19,136 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:41:19,137 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 20:41:19,137 >>   Number of trainable parameters = 124,648,708
[INFO|integration_utils.py:716] 2023-11-15 20:41:19,138 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<19:50,  1.11s/it]  0%|          | 3/1070 [00:01<06:19,  2.81it/s]  0%|          | 5/1070 [00:01<03:53,  4.56it/s]  1%|          | 7/1070 [00:01<02:55,  6.07it/s]  1%|          | 9/1070 [00:01<02:24,  7.32it/s]  1%|          | 11/1070 [00:02<02:07,  8.33it/s]  1%|          | 13/1070 [00:02<01:56,  9.08it/s]  1%|▏         | 15/1070 [00:02<01:49,  9.64it/s]  2%|▏         | 17/1070 [00:02<01:44, 10.06it/s]  2%|▏         | 19/1070 [00:02<01:41, 10.36it/s]  2%|▏         | 21/1070 [00:02<01:39, 10.58it/s]  2%|▏         | 23/1070 [00:03<01:37, 10.74it/s]  2%|▏         | 25/1070 [00:03<01:36, 10.84it/s]  3%|▎         | 27/1070 [00:03<01:35, 10.92it/s]  3%|▎         | 29/1070 [00:03<01:34, 10.98it/s]  3%|▎         | 31/1070 [00:03<01:34, 11.01it/s]  3%|▎         | 33/1070 [00:03<01:33, 11.03it/s]  3%|▎         | 35/1070 [00:04<01:33, 11.02it/s]  3%|▎         | 37/1070 [00:04<01:33, 11.08it/s]  4%|▎         | 39/1070 [00:04<01:32, 11.12it/s]  4%|▍         | 41/1070 [00:04<01:32, 11.14it/s]  4%|▍         | 43/1070 [00:04<01:32, 11.16it/s]  4%|▍         | 45/1070 [00:05<01:31, 11.17it/s]  4%|▍         | 47/1070 [00:05<01:31, 11.17it/s]  5%|▍         | 49/1070 [00:05<01:31, 11.18it/s]  5%|▍         | 51/1070 [00:05<01:31, 11.19it/s]  5%|▍         | 53/1070 [00:05<01:30, 11.20it/s]  5%|▌         | 55/1070 [00:05<01:30, 11.20it/s]  5%|▌         | 57/1070 [00:06<01:30, 11.20it/s]  6%|▌         | 59/1070 [00:06<01:30, 11.19it/s]  6%|▌         | 61/1070 [00:06<01:30, 11.12it/s]  6%|▌         | 63/1070 [00:06<01:30, 11.18it/s]  6%|▌         | 65/1070 [00:06<01:29, 11.18it/s]  6%|▋         | 67/1070 [00:07<01:29, 11.18it/s]  6%|▋         | 69/1070 [00:07<01:29, 11.19it/s]  7%|▋         | 71/1070 [00:07<01:29, 11.15it/s]  7%|▋         | 73/1070 [00:07<01:29, 11.16it/s]  7%|▋         | 75/1070 [00:07<01:29, 11.17it/s]  7%|▋         | 77/1070 [00:07<01:28, 11.18it/s]  7%|▋         | 79/1070 [00:08<01:28, 11.18it/s]  8%|▊         | 81/1070 [00:08<01:28, 11.18it/s]  8%|▊         | 83/1070 [00:08<01:28, 11.18it/s]  8%|▊         | 85/1070 [00:08<01:28, 11.17it/s]  8%|▊         | 87/1070 [00:08<01:27, 11.18it/s]  8%|▊         | 89/1070 [00:09<01:27, 11.16it/s]  9%|▊         | 91/1070 [00:09<01:27, 11.16it/s]  9%|▊         | 93/1070 [00:09<01:27, 11.16it/s]  9%|▉         | 95/1070 [00:09<01:27, 11.17it/s]  9%|▉         | 97/1070 [00:09<01:27, 11.17it/s]  9%|▉         | 99/1070 [00:09<01:26, 11.17it/s]  9%|▉         | 101/1070 [00:10<01:26, 11.17it/s] 10%|▉         | 103/1070 [00:10<01:26, 11.18it/s] 10%|▉         | 105/1070 [00:10<01:26, 11.19it/s] 10%|█         | 107/1070 [00:10<01:26, 11.19it/s] 10%|█         | 109/1070 [00:10<01:25, 11.19it/s] 10%|█         | 111/1070 [00:10<01:25, 11.20it/s] 11%|█         | 113/1070 [00:11<01:25, 11.18it/s] 11%|█         | 115/1070 [00:11<01:25, 11.19it/s] 11%|█         | 117/1070 [00:11<01:25, 11.18it/s] 11%|█         | 119/1070 [00:11<01:25, 11.18it/s] 11%|█▏        | 121/1070 [00:11<01:24, 11.17it/s] 11%|█▏        | 123/1070 [00:12<01:24, 11.17it/s] 12%|█▏        | 125/1070 [00:12<01:24, 11.17it/s] 12%|█▏        | 127/1070 [00:12<01:24, 11.17it/s] 12%|█▏        | 129/1070 [00:12<01:24, 11.17it/s] 12%|█▏        | 131/1070 [00:12<01:24, 11.16it/s] 12%|█▏        | 133/1070 [00:12<01:23, 11.16it/s] 13%|█▎        | 135/1070 [00:13<01:23, 11.16it/s] 13%|█▎        | 137/1070 [00:13<01:23, 11.14it/s] 13%|█▎        | 139/1070 [00:13<01:23, 11.13it/s] 13%|█▎        | 141/1070 [00:13<01:23, 11.14it/s] 13%|█▎        | 143/1070 [00:13<01:23, 11.15it/s] 14%|█▎        | 145/1070 [00:14<01:22, 11.16it/s] 14%|█▎        | 147/1070 [00:14<01:22, 11.16it/s] 14%|█▍        | 149/1070 [00:14<01:22, 11.17it/s] 14%|█▍        | 151/1070 [00:14<01:22, 11.16it/s] 14%|█▍        | 153/1070 [00:14<01:22, 11.15it/s] 14%|█▍        | 155/1070 [00:14<01:21, 11.16it/s] 15%|█▍        | 157/1070 [00:15<01:21, 11.15it/s] 15%|█▍        | 159/1070 [00:15<01:21, 11.15it/s] 15%|█▌        | 161/1070 [00:15<01:21, 11.15it/s] 15%|█▌        | 163/1070 [00:15<01:21, 11.15it/s] 15%|█▌        | 165/1070 [00:15<01:21, 11.16it/s] 16%|█▌        | 167/1070 [00:15<01:20, 11.15it/s] 16%|█▌        | 169/1070 [00:16<01:20, 11.14it/s] 16%|█▌        | 171/1070 [00:16<01:20, 11.15it/s] 16%|█▌        | 173/1070 [00:16<01:20, 11.15it/s] 16%|█▋        | 175/1070 [00:16<01:20, 11.16it/s] 17%|█▋        | 177/1070 [00:16<01:20, 11.15it/s] 17%|█▋        | 179/1070 [00:17<01:19, 11.16it/s] 17%|█▋        | 181/1070 [00:17<01:19, 11.15it/s] 17%|█▋        | 183/1070 [00:17<01:19, 11.15it/s] 17%|█▋        | 185/1070 [00:17<01:19, 11.15it/s] 17%|█▋        | 187/1070 [00:17<01:19, 11.15it/s] 18%|█▊        | 189/1070 [00:17<01:19, 11.14it/s] 18%|█▊        | 191/1070 [00:18<01:18, 11.15it/s] 18%|█▊        | 193/1070 [00:18<01:18, 11.15it/s] 18%|█▊        | 195/1070 [00:18<01:18, 11.16it/s] 18%|█▊        | 197/1070 [00:18<01:18, 11.15it/s] 19%|█▊        | 199/1070 [00:18<01:18, 11.14it/s] 19%|█▉        | 201/1070 [00:19<01:17, 11.15it/s] 19%|█▉        | 203/1070 [00:19<01:17, 11.14it/s] 19%|█▉        | 205/1070 [00:19<01:17, 11.14it/s] 19%|█▉        | 207/1070 [00:19<01:17, 11.12it/s] 20%|█▉        | 209/1070 [00:19<01:17, 11.12it/s] 20%|█▉        | 211/1070 [00:19<01:17, 11.13it/s] 20%|█▉        | 213/1070 [00:20<01:17, 11.12it/s]                                                   20%|██        | 214/1070 [00:20<01:16, 11.12it/s][INFO|trainer.py:755] 2023-11-15 20:41:39,345 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:41:39,347 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:41:39,348 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:41:39,348 >>   Batch size = 8
{'loss': 0.4551, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 123.76it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 117.65it/s][A
 40%|████      | 38/95 [00:00<00:00, 115.66it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 114.67it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 114.09it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 113.70it/s][A
 91%|█████████ | 86/95 [00:00<00:00, 113.30it/s][A                                                  
                                                [A 20%|██        | 214/1070 [00:21<01:16, 11.12it/s]
100%|██████████| 95/95 [00:00<00:00, 113.30it/s][A
                                                [A 20%|██        | 215/1070 [00:21<03:07,  4.56it/s] 20%|██        | 217/1070 [00:21<02:34,  5.52it/s] 20%|██        | 219/1070 [00:21<02:10,  6.50it/s] 21%|██        | 221/1070 [00:21<01:54,  7.43it/s] 21%|██        | 223/1070 [00:21<01:42,  8.26it/s] 21%|██        | 225/1070 [00:22<01:34,  8.95it/s] 21%|██        | 227/1070 [00:22<01:28,  9.52it/s] 21%|██▏       | 229/1070 [00:22<01:24,  9.95it/s] 22%|██▏       | 231/1070 [00:22<01:21, 10.27it/s] 22%|██▏       | 233/1070 [00:22<01:19, 10.51it/s] 22%|██▏       | 235/1070 [00:22<01:18, 10.68it/s] 22%|██▏       | 237/1070 [00:23<01:17, 10.81it/s] 22%|██▏       | 239/1070 [00:23<01:16, 10.90it/s] 23%|██▎       | 241/1070 [00:23<01:15, 10.96it/s] 23%|██▎       | 243/1070 [00:23<01:15, 11.00it/s] 23%|██▎       | 245/1070 [00:23<01:14, 11.04it/s] 23%|██▎       | 247/1070 [00:24<01:14, 11.06it/s] 23%|██▎       | 249/1070 [00:24<01:14, 11.08it/s] 23%|██▎       | 251/1070 [00:24<01:13, 11.10it/s] 24%|██▎       | 253/1070 [00:24<01:13, 11.11it/s] 24%|██▍       | 255/1070 [00:24<01:13, 11.06it/s] 24%|██▍       | 257/1070 [00:24<01:13, 11.11it/s] 24%|██▍       | 259/1070 [00:25<01:13, 11.10it/s] 24%|██▍       | 261/1070 [00:25<01:12, 11.11it/s] 25%|██▍       | 263/1070 [00:25<01:12, 11.11it/s] 25%|██▍       | 265/1070 [00:25<01:12, 11.12it/s] 25%|██▍       | 267/1070 [00:25<01:12, 11.11it/s] 25%|██▌       | 269/1070 [00:26<01:12, 11.11it/s] 25%|██▌       | 271/1070 [00:26<01:11, 11.10it/s] 26%|██▌       | 273/1070 [00:26<01:11, 11.10it/s] 26%|██▌       | 275/1070 [00:26<01:11, 11.11it/s] 26%|██▌       | 277/1070 [00:26<01:11, 11.11it/s] 26%|██▌       | 279/1070 [00:26<01:11, 11.11it/s] 26%|██▋       | 281/1070 [00:27<01:10, 11.12it/s] 26%|██▋       | 283/1070 [00:27<01:10, 11.12it/s] 27%|██▋       | 285/1070 [00:27<01:10, 11.12it/s] 27%|██▋       | 287/1070 [00:27<01:10, 11.12it/s] 27%|██▋       | 289/1070 [00:27<01:10, 11.15it/s] 27%|██▋       | 291/1070 [00:28<01:09, 11.14it/s] 27%|██▋       | 293/1070 [00:28<01:09, 11.13it/s] 28%|██▊       | 295/1070 [00:28<01:09, 11.12it/s] 28%|██▊       | 297/1070 [00:28<01:09, 11.11it/s] 28%|██▊       | 299/1070 [00:28<01:09, 11.11it/s] 28%|██▊       | 301/1070 [00:28<01:09, 11.06it/s] 28%|██▊       | 303/1070 [00:29<01:09, 11.08it/s] 29%|██▊       | 305/1070 [00:29<01:09, 11.08it/s] 29%|██▊       | 307/1070 [00:29<01:08, 11.10it/s] 29%|██▉       | 309/1070 [00:29<01:08, 11.11it/s] 29%|██▉       | 311/1070 [00:29<01:08, 11.11it/s] 29%|██▉       | 313/1070 [00:29<01:08, 11.12it/s] 29%|██▉       | 315/1070 [00:30<01:07, 11.11it/s] 30%|██▉       | 317/1070 [00:30<01:07, 11.11it/s] 30%|██▉       | 319/1070 [00:30<01:07, 11.11it/s] 30%|███       | 321/1070 [00:30<01:07, 11.13it/s] 30%|███       | 323/1070 [00:30<01:07, 11.13it/s] 30%|███       | 325/1070 [00:31<01:06, 11.12it/s] 31%|███       | 327/1070 [00:31<01:06, 11.12it/s] 31%|███       | 329/1070 [00:31<01:06, 11.12it/s] 31%|███       | 331/1070 [00:31<01:06, 11.12it/s] 31%|███       | 333/1070 [00:31<01:06, 11.12it/s] 31%|███▏      | 335/1070 [00:31<01:06, 11.12it/s] 31%|███▏      | 337/1070 [00:32<01:05, 11.12it/s] 32%|███▏      | 339/1070 [00:32<01:05, 11.12it/s] 32%|███▏      | 341/1070 [00:32<01:05, 11.12it/s] 32%|███▏      | 343/1070 [00:32<01:05, 11.12it/s] 32%|███▏      | 345/1070 [00:32<01:05, 11.10it/s] 32%|███▏      | 347/1070 [00:33<01:05, 11.10it/s] 33%|███▎      | 349/1070 [00:33<01:04, 11.11it/s] 33%|███▎      | 351/1070 [00:33<01:04, 11.12it/s] 33%|███▎      | 353/1070 [00:33<01:04, 11.03it/s] 33%|███▎      | 355/1070 [00:33<01:04, 11.07it/s] 33%|███▎      | 357/1070 [00:33<01:04, 11.07it/s] 34%|███▎      | 359/1070 [00:34<01:04, 11.07it/s] 34%|███▎      | 361/1070 [00:34<01:03, 11.08it/s] 34%|███▍      | 363/1070 [00:34<01:03, 11.08it/s] 34%|███▍      | 365/1070 [00:34<01:03, 11.08it/s] 34%|███▍      | 367/1070 [00:34<01:03, 11.07it/s] 34%|███▍      | 369/1070 [00:35<01:03, 11.06it/s] 35%|███▍      | 371/1070 [00:35<01:03, 11.07it/s] 35%|███▍      | 373/1070 [00:35<01:03, 11.06it/s] 35%|███▌      | 375/1070 [00:35<01:02, 11.07it/s] 35%|███▌      | 377/1070 [00:35<01:02, 11.06it/s] 35%|███▌      | 379/1070 [00:35<01:02, 11.08it/s] 36%|███▌      | 381/1070 [00:36<01:02, 11.09it/s] 36%|███▌      | 383/1070 [00:36<01:01, 11.10it/s] 36%|███▌      | 385/1070 [00:36<01:01, 11.10it/s] 36%|███▌      | 387/1070 [00:36<01:01, 11.09it/s] 36%|███▋      | 389/1070 [00:36<01:01, 11.08it/s] 37%|███▋      | 391/1070 [00:37<01:01, 11.07it/s] 37%|███▋      | 393/1070 [00:37<01:01, 11.07it/s] 37%|███▋      | 395/1070 [00:37<01:01, 11.05it/s] 37%|███▋      | 397/1070 [00:37<01:00, 11.05it/s] 37%|███▋      | 399/1070 [00:37<01:00, 11.05it/s] 37%|███▋      | 401/1070 [00:37<01:00, 11.06it/s] 38%|███▊      | 403/1070 [00:38<01:00, 11.07it/s] 38%|███▊      | 405/1070 [00:38<00:59, 11.08it/s] 38%|███▊      | 407/1070 [00:38<00:59, 11.08it/s] 38%|███▊      | 409/1070 [00:38<00:59, 11.08it/s] 38%|███▊      | 411/1070 [00:38<00:59, 11.08it/s] 39%|███▊      | 413/1070 [00:39<00:59, 11.09it/s] 39%|███▉      | 415/1070 [00:39<00:59, 11.09it/s] 39%|███▉      | 417/1070 [00:39<00:58, 11.09it/s] 39%|███▉      | 419/1070 [00:39<00:58, 11.09it/s] 39%|███▉      | 421/1070 [00:39<00:58, 11.01it/s] 40%|███▉      | 423/1070 [00:39<00:58, 11.06it/s] 40%|███▉      | 425/1070 [00:40<00:58, 11.05it/s] 40%|███▉      | 427/1070 [00:40<00:58, 11.07it/s]                                                   40%|████      | 428/1070 [00:40<00:58, 11.07it/s][INFO|trainer.py:755] 2023-11-15 20:41:59,494 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:41:59,496 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:41:59,497 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:41:59,497 >>   Batch size = 8
{'eval_loss': 0.30189210176467896, 'eval_accuracy': 0.9013157894736842, 'eval_micro_f1': 0.9013157894736842, 'eval_macro_f1': 0.8975349580811953, 'eval_runtime': 0.8734, 'eval_samples_per_second': 870.149, 'eval_steps_per_second': 108.769, 'epoch': 1.0}
{'loss': 0.2353, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 123.29it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 116.93it/s][A
 40%|████      | 38/95 [00:00<00:00, 114.76it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 113.66it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 113.04it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 112.18it/s][A
 91%|█████████ | 86/95 [00:00<00:00, 111.75it/s][A                                                  
                                                [A 40%|████      | 428/1070 [00:41<00:58, 11.07it/s]
100%|██████████| 95/95 [00:00<00:00, 111.75it/s][A
                                                [A 40%|████      | 429/1070 [00:41<02:21,  4.52it/s] 40%|████      | 431/1070 [00:41<01:56,  5.48it/s] 40%|████      | 433/1070 [00:41<01:38,  6.44it/s] 41%|████      | 435/1070 [00:41<01:26,  7.36it/s] 41%|████      | 437/1070 [00:42<01:17,  8.18it/s] 41%|████      | 439/1070 [00:42<01:11,  8.88it/s] 41%|████      | 441/1070 [00:42<01:06,  9.44it/s] 41%|████▏     | 443/1070 [00:42<01:03,  9.88it/s] 42%|████▏     | 445/1070 [00:42<01:01, 10.21it/s] 42%|████▏     | 447/1070 [00:42<00:59, 10.45it/s] 42%|████▏     | 449/1070 [00:43<00:58, 10.62it/s] 42%|████▏     | 451/1070 [00:43<00:57, 10.74it/s] 42%|████▏     | 453/1070 [00:43<00:56, 10.83it/s] 43%|████▎     | 455/1070 [00:43<00:56, 10.89it/s] 43%|████▎     | 457/1070 [00:43<00:56, 10.93it/s] 43%|████▎     | 459/1070 [00:44<00:55, 10.97it/s] 43%|████▎     | 461/1070 [00:44<00:55, 11.00it/s] 43%|████▎     | 463/1070 [00:44<00:55, 11.01it/s] 43%|████▎     | 465/1070 [00:44<00:54, 11.03it/s] 44%|████▎     | 467/1070 [00:44<00:54, 11.04it/s] 44%|████▍     | 469/1070 [00:44<00:54, 11.04it/s] 44%|████▍     | 471/1070 [00:45<00:54, 11.04it/s] 44%|████▍     | 473/1070 [00:45<00:54, 11.05it/s] 44%|████▍     | 475/1070 [00:45<00:53, 11.04it/s] 45%|████▍     | 477/1070 [00:45<00:53, 11.06it/s] 45%|████▍     | 479/1070 [00:45<00:53, 11.06it/s] 45%|████▍     | 481/1070 [00:46<00:53, 10.98it/s] 45%|████▌     | 483/1070 [00:46<00:53, 10.92it/s] 45%|████▌     | 485/1070 [00:46<00:53, 10.93it/s] 46%|████▌     | 487/1070 [00:46<00:53, 10.91it/s] 46%|████▌     | 489/1070 [00:46<00:53, 10.86it/s] 46%|████▌     | 491/1070 [00:46<00:53, 10.89it/s] 46%|████▌     | 493/1070 [00:47<00:53, 10.88it/s] 46%|████▋     | 495/1070 [00:47<00:52, 10.86it/s] 46%|████▋     | 497/1070 [00:47<00:52, 10.86it/s] 47%|████▋     | 499/1070 [00:47<00:52, 10.92it/s] 47%|████▋     | 501/1070 [00:47<00:52, 10.94it/s] 47%|████▋     | 503/1070 [00:48<00:51, 10.97it/s] 47%|████▋     | 505/1070 [00:48<00:51, 10.99it/s] 47%|████▋     | 507/1070 [00:48<00:51, 11.00it/s] 48%|████▊     | 509/1070 [00:48<00:50, 11.01it/s] 48%|████▊     | 511/1070 [00:48<00:50, 11.02it/s] 48%|████▊     | 513/1070 [00:48<00:50, 11.03it/s] 48%|████▊     | 515/1070 [00:49<00:50, 11.02it/s] 48%|████▊     | 517/1070 [00:49<00:50, 11.02it/s] 49%|████▊     | 519/1070 [00:49<00:49, 11.03it/s] 49%|████▊     | 521/1070 [00:49<00:49, 11.03it/s] 49%|████▉     | 523/1070 [00:49<00:49, 11.02it/s] 49%|████▉     | 525/1070 [00:50<00:49, 11.02it/s] 49%|████▉     | 527/1070 [00:50<00:49, 11.02it/s] 49%|████▉     | 529/1070 [00:50<00:48, 11.04it/s] 50%|████▉     | 531/1070 [00:50<00:48, 11.02it/s] 50%|████▉     | 533/1070 [00:50<00:48, 11.02it/s] 50%|█████     | 535/1070 [00:50<00:48, 11.01it/s] 50%|█████     | 537/1070 [00:51<00:48, 11.01it/s] 50%|█████     | 539/1070 [00:51<00:48, 11.02it/s] 51%|█████     | 541/1070 [00:51<00:47, 11.02it/s] 51%|█████     | 543/1070 [00:51<00:47, 11.03it/s] 51%|█████     | 545/1070 [00:51<00:47, 11.02it/s] 51%|█████     | 547/1070 [00:52<00:47, 11.02it/s] 51%|█████▏    | 549/1070 [00:52<00:47, 11.01it/s] 51%|█████▏    | 551/1070 [00:52<00:47, 11.02it/s] 52%|█████▏    | 553/1070 [00:52<00:46, 11.02it/s] 52%|█████▏    | 555/1070 [00:52<00:46, 11.03it/s] 52%|█████▏    | 557/1070 [00:52<00:46, 11.03it/s] 52%|█████▏    | 559/1070 [00:53<00:46, 11.04it/s] 52%|█████▏    | 561/1070 [00:53<00:46, 11.01it/s] 53%|█████▎    | 563/1070 [00:53<00:46, 11.02it/s] 53%|█████▎    | 565/1070 [00:53<00:45, 11.03it/s] 53%|█████▎    | 567/1070 [00:53<00:45, 11.01it/s] 53%|█████▎    | 569/1070 [00:54<00:45, 10.99it/s] 53%|█████▎    | 571/1070 [00:54<00:45, 11.00it/s] 54%|█████▎    | 573/1070 [00:54<00:45, 11.00it/s] 54%|█████▎    | 575/1070 [00:54<00:44, 11.00it/s] 54%|█████▍    | 577/1070 [00:54<00:44, 11.01it/s] 54%|█████▍    | 579/1070 [00:54<00:44, 11.01it/s] 54%|█████▍    | 581/1070 [00:55<00:44, 11.01it/s] 54%|█████▍    | 583/1070 [00:55<00:44, 10.96it/s] 55%|█████▍    | 585/1070 [00:55<00:44, 10.98it/s] 55%|█████▍    | 587/1070 [00:55<00:43, 11.00it/s] 55%|█████▌    | 589/1070 [00:55<00:43, 10.99it/s] 55%|█████▌    | 591/1070 [00:56<00:43, 10.98it/s] 55%|█████▌    | 593/1070 [00:56<00:43, 10.99it/s] 56%|█████▌    | 595/1070 [00:56<00:43, 11.01it/s] 56%|█████▌    | 597/1070 [00:56<00:42, 11.02it/s] 56%|█████▌    | 599/1070 [00:56<00:42, 11.03it/s] 56%|█████▌    | 601/1070 [00:56<00:42, 11.03it/s] 56%|█████▋    | 603/1070 [00:57<00:42, 11.02it/s] 57%|█████▋    | 605/1070 [00:57<00:42, 10.99it/s] 57%|█████▋    | 607/1070 [00:57<00:42, 11.01it/s] 57%|█████▋    | 609/1070 [00:57<00:41, 11.01it/s] 57%|█████▋    | 611/1070 [00:57<00:41, 11.02it/s] 57%|█████▋    | 613/1070 [00:58<00:41, 11.01it/s] 57%|█████▋    | 615/1070 [00:58<00:41, 11.00it/s] 58%|█████▊    | 617/1070 [00:58<00:41, 11.00it/s] 58%|█████▊    | 619/1070 [00:58<00:40, 11.01it/s] 58%|█████▊    | 621/1070 [00:58<00:40, 11.01it/s] 58%|█████▊    | 623/1070 [00:58<00:40, 11.00it/s] 58%|█████▊    | 625/1070 [00:59<00:40, 11.00it/s] 59%|█████▊    | 627/1070 [00:59<00:40, 10.99it/s] 59%|█████▉    | 629/1070 [00:59<00:40, 11.01it/s] 59%|█████▉    | 631/1070 [00:59<00:39, 11.01it/s] 59%|█████▉    | 633/1070 [00:59<00:39, 11.01it/s] 59%|█████▉    | 635/1070 [01:00<00:39, 11.01it/s] 60%|█████▉    | 637/1070 [01:00<00:39, 11.00it/s] 60%|█████▉    | 639/1070 [01:00<00:39, 11.00it/s] 60%|█████▉    | 641/1070 [01:00<00:39, 10.98it/s]                                                   60%|██████    | 642/1070 [01:00<00:38, 10.98it/s][INFO|trainer.py:755] 2023-11-15 20:42:19,812 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:42:19,813 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:42:19,814 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:42:19,814 >>   Batch size = 8
{'eval_loss': 0.2859923243522644, 'eval_accuracy': 0.9105263157894737, 'eval_micro_f1': 0.9105263157894739, 'eval_macro_f1': 0.9067122984110956, 'eval_runtime': 0.8823, 'eval_samples_per_second': 861.369, 'eval_steps_per_second': 107.671, 'epoch': 2.0}
{'loss': 0.1647, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 123.06it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 116.50it/s][A
 40%|████      | 38/95 [00:00<00:00, 114.26it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 113.19it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 112.60it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 111.70it/s][A
 91%|█████████ | 86/95 [00:00<00:00, 110.94it/s][A                                                  
                                                [A 60%|██████    | 642/1070 [01:01<00:38, 10.98it/s]
100%|██████████| 95/95 [00:00<00:00, 110.94it/s][A
                                                [A 60%|██████    | 643/1070 [01:01<01:35,  4.49it/s] 60%|██████    | 645/1070 [01:01<01:18,  5.44it/s] 60%|██████    | 647/1070 [01:02<01:05,  6.41it/s] 61%|██████    | 649/1070 [01:02<00:57,  7.34it/s] 61%|██████    | 651/1070 [01:02<00:51,  8.17it/s] 61%|██████    | 653/1070 [01:02<00:47,  8.84it/s] 61%|██████    | 655/1070 [01:02<00:44,  9.36it/s] 61%|██████▏   | 657/1070 [01:02<00:42,  9.79it/s] 62%|██████▏   | 659/1070 [01:03<00:40, 10.14it/s] 62%|██████▏   | 661/1070 [01:03<00:39, 10.38it/s] 62%|██████▏   | 663/1070 [01:03<00:38, 10.55it/s] 62%|██████▏   | 665/1070 [01:03<00:37, 10.67it/s] 62%|██████▏   | 667/1070 [01:03<00:37, 10.77it/s] 63%|██████▎   | 669/1070 [01:04<00:36, 10.84it/s] 63%|██████▎   | 671/1070 [01:04<00:36, 10.90it/s] 63%|██████▎   | 673/1070 [01:04<00:36, 10.94it/s] 63%|██████▎   | 675/1070 [01:04<00:36, 10.95it/s] 63%|██████▎   | 677/1070 [01:04<00:35, 10.97it/s] 63%|██████▎   | 679/1070 [01:04<00:35, 10.97it/s] 64%|██████▎   | 681/1070 [01:05<00:35, 11.00it/s] 64%|██████▍   | 683/1070 [01:05<00:35, 11.00it/s] 64%|██████▍   | 685/1070 [01:05<00:34, 11.00it/s] 64%|██████▍   | 687/1070 [01:05<00:34, 10.97it/s] 64%|██████▍   | 689/1070 [01:05<00:34, 10.98it/s] 65%|██████▍   | 691/1070 [01:06<00:34, 11.01it/s] 65%|██████▍   | 693/1070 [01:06<00:34, 11.02it/s] 65%|██████▍   | 695/1070 [01:06<00:34, 11.01it/s] 65%|██████▌   | 697/1070 [01:06<00:33, 11.00it/s] 65%|██████▌   | 699/1070 [01:06<00:33, 10.98it/s] 66%|██████▌   | 701/1070 [01:06<00:33, 11.00it/s] 66%|██████▌   | 703/1070 [01:07<00:33, 11.00it/s] 66%|██████▌   | 705/1070 [01:07<00:33, 11.00it/s] 66%|██████▌   | 707/1070 [01:07<00:33, 11.00it/s] 66%|██████▋   | 709/1070 [01:07<00:32, 10.99it/s] 66%|██████▋   | 711/1070 [01:07<00:32, 10.98it/s] 67%|██████▋   | 713/1070 [01:08<00:32, 10.99it/s] 67%|██████▋   | 715/1070 [01:08<00:32, 11.00it/s] 67%|██████▋   | 717/1070 [01:08<00:32, 10.99it/s] 67%|██████▋   | 719/1070 [01:08<00:31, 10.98it/s] 67%|██████▋   | 721/1070 [01:08<00:31, 10.99it/s] 68%|██████▊   | 723/1070 [01:08<00:31, 10.98it/s] 68%|██████▊   | 725/1070 [01:09<00:31, 10.98it/s] 68%|██████▊   | 727/1070 [01:09<00:31, 10.98it/s] 68%|██████▊   | 729/1070 [01:09<00:31, 10.99it/s] 68%|██████▊   | 731/1070 [01:09<00:30, 10.99it/s] 69%|██████▊   | 733/1070 [01:09<00:30, 10.98it/s] 69%|██████▊   | 735/1070 [01:10<00:30, 10.98it/s] 69%|██████▉   | 737/1070 [01:10<00:30, 10.98it/s] 69%|██████▉   | 739/1070 [01:10<00:30, 10.99it/s] 69%|██████▉   | 741/1070 [01:10<00:29, 10.99it/s] 69%|██████▉   | 743/1070 [01:10<00:29, 10.99it/s] 70%|██████▉   | 745/1070 [01:10<00:29, 10.99it/s] 70%|██████▉   | 747/1070 [01:11<00:29, 10.98it/s] 70%|███████   | 749/1070 [01:11<00:29, 10.96it/s] 70%|███████   | 751/1070 [01:11<00:29, 10.98it/s] 70%|███████   | 753/1070 [01:11<00:28, 10.97it/s] 71%|███████   | 755/1070 [01:11<00:28, 10.96it/s] 71%|███████   | 757/1070 [01:12<00:28, 10.97it/s] 71%|███████   | 759/1070 [01:12<00:28, 10.95it/s] 71%|███████   | 761/1070 [01:12<00:28, 10.96it/s] 71%|███████▏  | 763/1070 [01:12<00:28, 10.93it/s] 71%|███████▏  | 765/1070 [01:12<00:27, 10.95it/s] 72%|███████▏  | 767/1070 [01:12<00:27, 10.95it/s] 72%|███████▏  | 769/1070 [01:13<00:27, 10.96it/s] 72%|███████▏  | 771/1070 [01:13<00:27, 10.95it/s] 72%|███████▏  | 773/1070 [01:13<00:27, 10.98it/s] 72%|███████▏  | 775/1070 [01:13<00:26, 10.99it/s] 73%|███████▎  | 777/1070 [01:13<00:26, 10.97it/s] 73%|███████▎  | 779/1070 [01:14<00:26, 10.97it/s] 73%|███████▎  | 781/1070 [01:14<00:26, 10.99it/s] 73%|███████▎  | 783/1070 [01:14<00:26, 10.99it/s] 73%|███████▎  | 785/1070 [01:14<00:25, 10.98it/s] 74%|███████▎  | 787/1070 [01:14<00:25, 10.97it/s] 74%|███████▎  | 789/1070 [01:14<00:25, 10.98it/s] 74%|███████▍  | 791/1070 [01:15<00:25, 10.98it/s] 74%|███████▍  | 793/1070 [01:15<00:25, 10.97it/s] 74%|███████▍  | 795/1070 [01:15<00:25, 10.97it/s] 74%|███████▍  | 797/1070 [01:15<00:24, 10.97it/s] 75%|███████▍  | 799/1070 [01:15<00:24, 10.97it/s] 75%|███████▍  | 801/1070 [01:16<00:24, 10.98it/s] 75%|███████▌  | 803/1070 [01:16<00:24, 10.97it/s] 75%|███████▌  | 805/1070 [01:16<00:24, 10.97it/s] 75%|███████▌  | 807/1070 [01:16<00:23, 10.98it/s] 76%|███████▌  | 809/1070 [01:16<00:23, 10.98it/s] 76%|███████▌  | 811/1070 [01:16<00:23, 10.97it/s] 76%|███████▌  | 813/1070 [01:17<00:23, 10.96it/s] 76%|███████▌  | 815/1070 [01:17<00:23, 10.96it/s] 76%|███████▋  | 817/1070 [01:17<00:23, 10.97it/s] 77%|███████▋  | 819/1070 [01:17<00:22, 10.97it/s] 77%|███████▋  | 821/1070 [01:17<00:22, 10.96it/s] 77%|███████▋  | 823/1070 [01:18<00:22, 10.96it/s] 77%|███████▋  | 825/1070 [01:18<00:22, 10.97it/s] 77%|███████▋  | 827/1070 [01:18<00:22, 10.98it/s] 77%|███████▋  | 829/1070 [01:18<00:21, 10.97it/s] 78%|███████▊  | 831/1070 [01:18<00:21, 10.97it/s] 78%|███████▊  | 833/1070 [01:18<00:21, 10.97it/s] 78%|███████▊  | 835/1070 [01:19<00:21, 10.99it/s] 78%|███████▊  | 837/1070 [01:19<00:21, 10.97it/s] 78%|███████▊  | 839/1070 [01:19<00:21, 10.97it/s] 79%|███████▊  | 841/1070 [01:19<00:20, 10.98it/s] 79%|███████▉  | 843/1070 [01:19<00:20, 10.99it/s] 79%|███████▉  | 845/1070 [01:20<00:20, 10.98it/s] 79%|███████▉  | 847/1070 [01:20<00:20, 10.97it/s] 79%|███████▉  | 849/1070 [01:20<00:20, 10.98it/s] 80%|███████▉  | 851/1070 [01:20<00:19, 10.99it/s] 80%|███████▉  | 853/1070 [01:20<00:19, 10.98it/s] 80%|███████▉  | 855/1070 [01:20<00:19, 10.98it/s]                                                   80%|████████  | 856/1070 [01:21<00:19, 10.98it/s][INFO|trainer.py:755] 2023-11-15 20:42:40,180 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:42:40,182 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:42:40,182 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:42:40,183 >>   Batch size = 8
{'eval_loss': 0.3087446093559265, 'eval_accuracy': 0.9105263157894737, 'eval_micro_f1': 0.9105263157894739, 'eval_macro_f1': 0.9078834473033359, 'eval_runtime': 0.8893, 'eval_samples_per_second': 854.558, 'eval_steps_per_second': 106.82, 'epoch': 3.0}
{'loss': 0.1084, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 121.49it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 115.84it/s][A
 40%|████      | 38/95 [00:00<00:00, 113.79it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 112.39it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 111.50it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 110.67it/s][A
 91%|█████████ | 86/95 [00:00<00:00, 110.04it/s][A                                                  
                                                [A 80%|████████  | 856/1070 [01:21<00:19, 10.98it/s]
100%|██████████| 95/95 [00:00<00:00, 110.04it/s][A
                                                [A 80%|████████  | 857/1070 [01:22<00:47,  4.44it/s] 80%|████████  | 859/1070 [01:22<00:39,  5.39it/s] 80%|████████  | 861/1070 [01:22<00:32,  6.36it/s] 81%|████████  | 863/1070 [01:22<00:28,  7.27it/s] 81%|████████  | 865/1070 [01:22<00:25,  8.08it/s] 81%|████████  | 867/1070 [01:22<00:23,  8.76it/s] 81%|████████  | 869/1070 [01:23<00:21,  9.33it/s] 81%|████████▏ | 871/1070 [01:23<00:20,  9.74it/s] 82%|████████▏ | 873/1070 [01:23<00:19, 10.07it/s] 82%|████████▏ | 875/1070 [01:23<00:18, 10.33it/s] 82%|████████▏ | 877/1070 [01:23<00:18, 10.52it/s] 82%|████████▏ | 879/1070 [01:24<00:17, 10.64it/s] 82%|████████▏ | 881/1070 [01:24<00:17, 10.73it/s] 83%|████████▎ | 883/1070 [01:24<00:17, 10.81it/s] 83%|████████▎ | 885/1070 [01:24<00:17, 10.86it/s] 83%|████████▎ | 887/1070 [01:24<00:16, 10.89it/s] 83%|████████▎ | 889/1070 [01:24<00:16, 10.90it/s] 83%|████████▎ | 891/1070 [01:25<00:16, 10.92it/s] 83%|████████▎ | 893/1070 [01:25<00:16, 10.93it/s] 84%|████████▎ | 895/1070 [01:25<00:16, 10.93it/s] 84%|████████▍ | 897/1070 [01:25<00:15, 10.94it/s] 84%|████████▍ | 899/1070 [01:25<00:15, 10.96it/s] 84%|████████▍ | 901/1070 [01:26<00:15, 10.95it/s] 84%|████████▍ | 903/1070 [01:26<00:15, 10.96it/s] 85%|████████▍ | 905/1070 [01:26<00:15, 10.94it/s] 85%|████████▍ | 907/1070 [01:26<00:14, 10.96it/s] 85%|████████▍ | 909/1070 [01:26<00:14, 10.96it/s] 85%|████████▌ | 911/1070 [01:26<00:14, 10.95it/s] 85%|████████▌ | 913/1070 [01:27<00:14, 10.97it/s] 86%|████████▌ | 915/1070 [01:27<00:14, 10.97it/s] 86%|████████▌ | 917/1070 [01:27<00:13, 10.96it/s] 86%|████████▌ | 919/1070 [01:27<00:13, 10.96it/s] 86%|████████▌ | 921/1070 [01:27<00:13, 10.94it/s] 86%|████████▋ | 923/1070 [01:28<00:13, 10.94it/s] 86%|████████▋ | 925/1070 [01:28<00:13, 10.91it/s] 87%|████████▋ | 927/1070 [01:28<00:13, 10.94it/s] 87%|████████▋ | 929/1070 [01:28<00:12, 10.96it/s] 87%|████████▋ | 931/1070 [01:28<00:12, 10.95it/s] 87%|████████▋ | 933/1070 [01:28<00:12, 10.94it/s] 87%|████████▋ | 935/1070 [01:29<00:12, 10.94it/s] 88%|████████▊ | 937/1070 [01:29<00:12, 10.94it/s] 88%|████████▊ | 939/1070 [01:29<00:11, 10.94it/s] 88%|████████▊ | 941/1070 [01:29<00:11, 10.95it/s] 88%|████████▊ | 943/1070 [01:29<00:11, 10.97it/s] 88%|████████▊ | 945/1070 [01:30<00:11, 10.97it/s] 89%|████████▊ | 947/1070 [01:30<00:11, 10.94it/s] 89%|████████▊ | 949/1070 [01:30<00:11, 10.93it/s] 89%|████████▉ | 951/1070 [01:30<00:10, 10.95it/s] 89%|████████▉ | 953/1070 [01:30<00:10, 10.96it/s] 89%|████████▉ | 955/1070 [01:30<00:10, 10.95it/s] 89%|████████▉ | 957/1070 [01:31<00:10, 10.95it/s] 90%|████████▉ | 959/1070 [01:31<00:10, 10.96it/s] 90%|████████▉ | 961/1070 [01:31<00:09, 10.96it/s] 90%|█████████ | 963/1070 [01:31<00:09, 10.96it/s] 90%|█████████ | 965/1070 [01:31<00:09, 10.95it/s] 90%|█████████ | 967/1070 [01:32<00:09, 10.95it/s] 91%|█████████ | 969/1070 [01:32<00:09, 10.94it/s] 91%|█████████ | 971/1070 [01:32<00:09, 10.93it/s] 91%|█████████ | 973/1070 [01:32<00:08, 10.95it/s] 91%|█████████ | 975/1070 [01:32<00:08, 10.95it/s] 91%|█████████▏| 977/1070 [01:32<00:08, 10.95it/s] 91%|█████████▏| 979/1070 [01:33<00:08, 10.94it/s] 92%|█████████▏| 981/1070 [01:33<00:08, 10.95it/s] 92%|█████████▏| 983/1070 [01:33<00:07, 10.94it/s] 92%|█████████▏| 985/1070 [01:33<00:07, 10.94it/s] 92%|█████████▏| 987/1070 [01:33<00:07, 10.96it/s] 92%|█████████▏| 989/1070 [01:34<00:07, 10.96it/s] 93%|█████████▎| 991/1070 [01:34<00:07, 10.95it/s] 93%|█████████▎| 993/1070 [01:34<00:07, 10.93it/s] 93%|█████████▎| 995/1070 [01:34<00:06, 10.92it/s] 93%|█████████▎| 997/1070 [01:34<00:06, 10.93it/s] 93%|█████████▎| 999/1070 [01:35<00:06, 10.93it/s] 94%|█████████▎| 1001/1070 [01:35<00:06, 10.94it/s] 94%|█████████▎| 1003/1070 [01:35<00:06, 10.93it/s] 94%|█████████▍| 1005/1070 [01:35<00:05, 10.94it/s] 94%|█████████▍| 1007/1070 [01:35<00:05, 10.94it/s] 94%|█████████▍| 1009/1070 [01:35<00:05, 10.95it/s] 94%|█████████▍| 1011/1070 [01:36<00:05, 10.95it/s] 95%|█████████▍| 1013/1070 [01:36<00:05, 10.95it/s] 95%|█████████▍| 1015/1070 [01:36<00:05, 10.94it/s] 95%|█████████▌| 1017/1070 [01:36<00:04, 10.95it/s] 95%|█████████▌| 1019/1070 [01:36<00:04, 10.95it/s] 95%|█████████▌| 1021/1070 [01:37<00:04, 10.94it/s] 96%|█████████▌| 1023/1070 [01:37<00:04, 10.94it/s] 96%|█████████▌| 1025/1070 [01:37<00:04, 10.94it/s] 96%|█████████▌| 1027/1070 [01:37<00:03, 10.94it/s] 96%|█████████▌| 1029/1070 [01:37<00:03, 10.94it/s] 96%|█████████▋| 1031/1070 [01:37<00:03, 10.94it/s] 97%|█████████▋| 1033/1070 [01:38<00:03, 10.94it/s] 97%|█████████▋| 1035/1070 [01:38<00:03, 10.95it/s] 97%|█████████▋| 1037/1070 [01:38<00:03, 10.95it/s] 97%|█████████▋| 1039/1070 [01:38<00:02, 10.95it/s] 97%|█████████▋| 1041/1070 [01:38<00:02, 10.95it/s] 97%|█████████▋| 1043/1070 [01:39<00:02, 10.96it/s] 98%|█████████▊| 1045/1070 [01:39<00:02, 10.97it/s] 98%|█████████▊| 1047/1070 [01:39<00:02, 10.96it/s] 98%|█████████▊| 1049/1070 [01:39<00:01, 10.93it/s] 98%|█████████▊| 1051/1070 [01:39<00:01, 10.93it/s] 98%|█████████▊| 1053/1070 [01:39<00:01, 10.93it/s] 99%|█████████▊| 1055/1070 [01:40<00:01, 10.94it/s] 99%|█████████▉| 1057/1070 [01:40<00:01, 10.95it/s] 99%|█████████▉| 1059/1070 [01:40<00:01, 10.95it/s] 99%|█████████▉| 1061/1070 [01:40<00:00, 10.94it/s] 99%|█████████▉| 1063/1070 [01:40<00:00, 10.93it/s]100%|█████████▉| 1065/1070 [01:41<00:00, 10.94it/s]100%|█████████▉| 1067/1070 [01:41<00:00, 10.90it/s]100%|█████████▉| 1069/1070 [01:41<00:00, 10.92it/s]                                                   100%|██████████| 1070/1070 [01:41<00:00, 10.92it/s][INFO|trainer.py:755] 2023-11-15 20:43:00,628 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:43:00,629 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:43:00,630 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:43:00,630 >>   Batch size = 8
{'eval_loss': 0.33504846692085266, 'eval_accuracy': 0.9092105263157895, 'eval_micro_f1': 0.9092105263157895, 'eval_macro_f1': 0.9066230692034609, 'eval_runtime': 0.8988, 'eval_samples_per_second': 845.574, 'eval_steps_per_second': 105.697, 'epoch': 4.0}
{'loss': 0.0834, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 121.93it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 115.64it/s][A
 40%|████      | 38/95 [00:00<00:00, 113.46it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 112.02it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 110.95it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 109.99it/s][A
 91%|█████████ | 86/95 [00:00<00:00, 109.28it/s][A                                                   
                                                [A100%|██████████| 1070/1070 [01:42<00:00, 10.92it/s]
100%|██████████| 95/95 [00:00<00:00, 109.28it/s][A
                                                [A[INFO|trainer.py:1963] 2023-11-15 20:43:01,532 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [01:42<00:00, 10.92it/s]100%|██████████| 1070/1070 [01:42<00:00, 10.45it/s]
[INFO|trainer.py:2855] 2023-11-15 20:43:01,535 >> Saving model checkpoint to ./result/agnews_sup_roberta-base_adapter__seed2
[INFO|configuration_utils.py:460] 2023-11-15 20:43:01,538 >> Configuration saved in ./result/agnews_sup_roberta-base_adapter__seed2/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:43:02,611 >> Model weights saved in ./result/agnews_sup_roberta-base_adapter__seed2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:43:02,614 >> tokenizer config file saved in ./result/agnews_sup_roberta-base_adapter__seed2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:43:02,616 >> Special tokens file saved in ./result/agnews_sup_roberta-base_adapter__seed2/special_tokens_map.json
{'eval_loss': 0.3549925982952118, 'eval_accuracy': 0.9171052631578948, 'eval_micro_f1': 0.9171052631578948, 'eval_macro_f1': 0.9148490505802009, 'eval_runtime': 0.8989, 'eval_samples_per_second': 845.466, 'eval_steps_per_second': 105.683, 'epoch': 5.0}
{'train_runtime': 102.3947, 'train_samples_per_second': 334.002, 'train_steps_per_second': 10.45, 'train_loss': 0.2093791640807535, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2094
  train_runtime            = 0:01:42.39
  train_samples            =       6840
  train_samples_per_second =    334.002
  train_steps_per_second   =      10.45
11/15/2023 20:43:02 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:43:02,709 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:43:02,710 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:43:02,711 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:43:02,711 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s] 14%|█▎        | 13/95 [00:00<00:00, 120.67it/s] 27%|██▋       | 26/95 [00:00<00:00, 112.75it/s] 40%|████      | 38/95 [00:00<00:00, 110.37it/s] 53%|█████▎    | 50/95 [00:00<00:00, 103.76it/s] 64%|██████▍   | 61/95 [00:00<00:00, 104.91it/s] 76%|███████▌  | 72/95 [00:00<00:00, 105.54it/s] 87%|████████▋ | 83/95 [00:00<00:00, 105.85it/s] 99%|█████████▉| 94/95 [00:00<00:00, 105.96it/s]100%|██████████| 95/95 [00:00<00:00, 102.66it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9171
  eval_loss               =      0.355
  eval_macro_f1           =     0.9148
  eval_micro_f1           =     0.9171
  eval_runtime            = 0:00:00.93
  eval_samples            =        760
  eval_samples_per_second =    810.643
  eval_steps_per_second   =     101.33
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▅▅▄██
wandb:                      eval/loss ▃▁▃▆██
wandb:                  eval/macro_f1 ▁▅▅▅██
wandb:                  eval/micro_f1 ▁▅▅▄██
wandb:                   eval/runtime ▁▂▃▄▄█
wandb:        eval/samples_per_second █▇▆▅▅▁
wandb:          eval/steps_per_second █▇▆▅▅▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▁▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.91711
wandb:                      eval/loss 0.35499
wandb:                  eval/macro_f1 0.91485
wandb:                  eval/micro_f1 0.91711
wandb:                   eval/runtime 0.9375
wandb:        eval/samples_per_second 810.643
wandb:          eval/steps_per_second 101.33
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0834
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.20938
wandb:            train/train_runtime 102.3947
wandb: train/train_samples_per_second 334.002
wandb:   train/train_steps_per_second 10.45
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_204002-83ru4sgc
wandb: Find logs at: ./wandb/offline-run-20231115_204002-83ru4sgc/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_bert-base-cased_adapter__seed2/runs/Nov15_20-43-12_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_bert-base-cased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_bert-base-cased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:43:12 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:43:12 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_bert-base-cased_adapter__seed2/runs/Nov15_20-43-11_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_bert-base-cased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_bert-base-cased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 20:43:27,733 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:43:27,743 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 20:43:37,759 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:43:37,760 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:43:37,763 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:43:37,763 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:43:37,763 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:43:37,764 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:43:37,764 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 20:43:37,765 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:43:37,765 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:43:57,901 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:43:58,599 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:43:58,600 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  44%|████▍     | 3000/6840 [00:00<00:00, 21873.78 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 22163.45 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 21949.37 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 24026.16 examples/s]
11/15/2023 20:43:58 - INFO - __main__ - Sample 4545 of the training set: {'text': "Yankees' Brown Has Successful Surgery Kevin Brown had successful surgery on his broken left hand Sunday and vowed to pitch again for the Yankees this season.", 'label': 0, 'input_ids': [101, 11063, 112, 2671, 10736, 25911, 2365, 17910, 4101, 2671, 1125, 2265, 6059, 1113, 1117, 3088, 1286, 1289, 3625, 1105, 19562, 1106, 6158, 1254, 1111, 1103, 11063, 1142, 1265, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:43:58 - INFO - __main__ - Sample 2873 of the training set: {'text': 'Bush shields shrimp industry The Bush administration yesterday said Chinese and Vietnamese shrimp are sold at unfairly low prices in the United States, siding with US fishermen as they try to fend off overseas competition.', 'label': 1, 'input_ids': [101, 6096, 18254, 23982, 2380, 1109, 6096, 3469, 8128, 1163, 1922, 1105, 8763, 23982, 1132, 1962, 1120, 17111, 1193, 1822, 7352, 1107, 1103, 1244, 1311, 117, 20181, 1114, 1646, 18993, 1112, 1152, 2222, 1106, 175, 6696, 1228, 7474, 2208, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:43:58 - INFO - __main__ - Sample 2892 of the training set: {'text': 'How the credit policy will affect you The Reserve Bank of India announced the mid-term review of its monetary policy on Tuesday. Though the central Bank kept away from the much expected interest rate hike, the policy contained recommendations ', 'label': 1, 'input_ids': [101, 1731, 1103, 4755, 2818, 1209, 6975, 1128, 1109, 5081, 2950, 1104, 1726, 1717, 1103, 2286, 118, 1858, 3189, 1104, 1157, 15997, 2818, 1113, 9667, 119, 3473, 1103, 2129, 2950, 2023, 1283, 1121, 1103, 1277, 2637, 2199, 2603, 25401, 117, 1103, 2818, 4049, 11859, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:43:59 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:44:00,378 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:44:00,385 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:44:00,385 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 20:44:00,385 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:44:00,386 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:44:00,386 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:44:00,386 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:44:00,386 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 20:44:00,387 >>   Number of trainable parameters = 108,313,348
[INFO|integration_utils.py:716] 2023-11-15 20:44:00,388 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<23:44,  1.33s/it]  0%|          | 2/1070 [00:01<10:54,  1.63it/s]  0%|          | 3/1070 [00:01<06:47,  2.62it/s]  0%|          | 4/1070 [00:01<04:49,  3.68it/s]  0%|          | 5/1070 [00:01<03:47,  4.69it/s]  1%|          | 6/1070 [00:01<03:08,  5.64it/s]  1%|          | 7/1070 [00:01<02:43,  6.49it/s]  1%|          | 8/1070 [00:02<02:27,  7.20it/s]  1%|          | 9/1070 [00:02<02:17,  7.70it/s]  1%|          | 10/1070 [00:02<02:10,  8.15it/s]  1%|          | 11/1070 [00:02<02:03,  8.56it/s]  1%|          | 12/1070 [00:02<02:00,  8.76it/s]  1%|          | 13/1070 [00:02<01:58,  8.89it/s]  1%|▏         | 14/1070 [00:02<01:57,  8.97it/s]  1%|▏         | 15/1070 [00:02<01:57,  8.98it/s]  1%|▏         | 16/1070 [00:02<01:56,  9.08it/s]  2%|▏         | 17/1070 [00:03<01:54,  9.16it/s]  2%|▏         | 18/1070 [00:03<01:53,  9.28it/s]  2%|▏         | 19/1070 [00:03<01:54,  9.22it/s]  2%|▏         | 20/1070 [00:03<01:53,  9.22it/s]  2%|▏         | 21/1070 [00:03<01:52,  9.29it/s]  2%|▏         | 22/1070 [00:03<01:51,  9.43it/s]  2%|▏         | 23/1070 [00:03<01:53,  9.26it/s]  2%|▏         | 24/1070 [00:03<01:52,  9.29it/s]  2%|▏         | 25/1070 [00:03<01:53,  9.21it/s]  2%|▏         | 26/1070 [00:04<01:54,  9.12it/s]  3%|▎         | 27/1070 [00:04<01:53,  9.16it/s]  3%|▎         | 28/1070 [00:04<01:53,  9.19it/s]  3%|▎         | 29/1070 [00:04<01:52,  9.22it/s]  3%|▎         | 30/1070 [00:04<01:53,  9.19it/s]  3%|▎         | 31/1070 [00:04<01:53,  9.17it/s]  3%|▎         | 32/1070 [00:04<01:54,  9.03it/s]  3%|▎         | 33/1070 [00:04<01:52,  9.25it/s]  3%|▎         | 34/1070 [00:04<01:52,  9.21it/s]  3%|▎         | 35/1070 [00:05<01:53,  9.15it/s]  3%|▎         | 36/1070 [00:05<01:52,  9.16it/s]  3%|▎         | 37/1070 [00:05<01:54,  9.06it/s]  4%|▎         | 38/1070 [00:05<01:53,  9.09it/s]  4%|▎         | 39/1070 [00:05<01:54,  9.04it/s]  4%|▎         | 40/1070 [00:05<01:53,  9.04it/s]  4%|▍         | 41/1070 [00:05<01:53,  9.09it/s]  4%|▍         | 42/1070 [00:05<01:53,  9.09it/s]  4%|▍         | 43/1070 [00:05<01:52,  9.11it/s]  4%|▍         | 44/1070 [00:05<01:50,  9.28it/s]  4%|▍         | 45/1070 [00:06<01:50,  9.25it/s]  4%|▍         | 46/1070 [00:06<01:51,  9.17it/s]  4%|▍         | 47/1070 [00:06<01:51,  9.21it/s]  4%|▍         | 48/1070 [00:06<01:49,  9.35it/s]  5%|▍         | 49/1070 [00:06<01:50,  9.27it/s]  5%|▍         | 50/1070 [00:06<01:51,  9.17it/s]  5%|▍         | 51/1070 [00:06<01:50,  9.19it/s]  5%|▍         | 52/1070 [00:06<01:50,  9.17it/s]  5%|▍         | 53/1070 [00:06<01:51,  9.13it/s]  5%|▌         | 54/1070 [00:07<01:51,  9.12it/s]  5%|▌         | 55/1070 [00:07<01:51,  9.12it/s]  5%|▌         | 56/1070 [00:07<01:51,  9.07it/s]  5%|▌         | 57/1070 [00:07<01:51,  9.06it/s]  5%|▌         | 58/1070 [00:07<01:53,  8.94it/s]  6%|▌         | 59/1070 [00:07<01:49,  9.22it/s]  6%|▌         | 60/1070 [00:07<01:49,  9.18it/s]  6%|▌         | 61/1070 [00:07<01:51,  9.08it/s]  6%|▌         | 62/1070 [00:07<01:50,  9.09it/s]  6%|▌         | 63/1070 [00:08<01:50,  9.13it/s]  6%|▌         | 64/1070 [00:08<01:50,  9.12it/s]  6%|▌         | 65/1070 [00:08<01:49,  9.18it/s]  6%|▌         | 66/1070 [00:08<01:49,  9.17it/s]  6%|▋         | 67/1070 [00:08<01:49,  9.14it/s]  6%|▋         | 68/1070 [00:08<01:49,  9.16it/s]  6%|▋         | 69/1070 [00:08<01:49,  9.10it/s]  7%|▋         | 70/1070 [00:08<01:46,  9.35it/s]  7%|▋         | 71/1070 [00:08<01:48,  9.22it/s]  7%|▋         | 72/1070 [00:09<01:49,  9.09it/s]  7%|▋         | 73/1070 [00:09<01:50,  9.06it/s]  7%|▋         | 74/1070 [00:09<01:48,  9.15it/s]  7%|▋         | 75/1070 [00:09<01:48,  9.17it/s]  7%|▋         | 76/1070 [00:09<01:48,  9.19it/s]  7%|▋         | 77/1070 [00:09<01:48,  9.14it/s]  7%|▋         | 78/1070 [00:09<01:48,  9.16it/s]  7%|▋         | 79/1070 [00:09<01:47,  9.25it/s]  7%|▋         | 80/1070 [00:09<01:47,  9.21it/s]  8%|▊         | 81/1070 [00:10<01:46,  9.27it/s]  8%|▊         | 82/1070 [00:10<01:47,  9.21it/s]  8%|▊         | 83/1070 [00:10<01:47,  9.17it/s]  8%|▊         | 84/1070 [00:10<01:47,  9.14it/s]  8%|▊         | 85/1070 [00:10<01:45,  9.33it/s]  8%|▊         | 86/1070 [00:10<01:47,  9.19it/s]  8%|▊         | 87/1070 [00:10<01:47,  9.16it/s]  8%|▊         | 88/1070 [00:10<01:47,  9.16it/s]  8%|▊         | 89/1070 [00:10<01:46,  9.21it/s]  8%|▊         | 90/1070 [00:11<01:46,  9.19it/s]  9%|▊         | 91/1070 [00:11<01:46,  9.16it/s]  9%|▊         | 92/1070 [00:11<01:46,  9.23it/s]  9%|▊         | 93/1070 [00:11<01:45,  9.22it/s]  9%|▉         | 94/1070 [00:11<01:45,  9.21it/s]  9%|▉         | 95/1070 [00:11<01:46,  9.16it/s]  9%|▉         | 96/1070 [00:11<01:46,  9.15it/s]  9%|▉         | 97/1070 [00:11<01:46,  9.11it/s]  9%|▉         | 98/1070 [00:11<01:47,  9.05it/s]  9%|▉         | 99/1070 [00:11<01:47,  9.07it/s]  9%|▉         | 100/1070 [00:12<01:44,  9.26it/s]  9%|▉         | 101/1070 [00:12<01:45,  9.18it/s] 10%|▉         | 102/1070 [00:12<01:46,  9.10it/s] 10%|▉         | 103/1070 [00:12<01:45,  9.14it/s] 10%|▉         | 104/1070 [00:12<01:44,  9.27it/s] 10%|▉         | 105/1070 [00:12<01:44,  9.25it/s] 10%|▉         | 106/1070 [00:12<01:45,  9.15it/s] 10%|█         | 107/1070 [00:12<01:45,  9.15it/s] 10%|█         | 108/1070 [00:12<01:44,  9.18it/s] 10%|█         | 109/1070 [00:13<01:44,  9.17it/s] 10%|█         | 110/1070 [00:13<01:45,  9.13it/s] 10%|█         | 111/1070 [00:13<01:45,  9.05it/s] 10%|█         | 112/1070 [00:13<01:45,  9.05it/s] 11%|█         | 113/1070 [00:13<01:46,  9.03it/s] 11%|█         | 114/1070 [00:13<01:46,  9.01it/s] 11%|█         | 115/1070 [00:13<01:43,  9.27it/s] 11%|█         | 116/1070 [00:13<01:44,  9.15it/s] 11%|█         | 117/1070 [00:13<01:44,  9.09it/s] 11%|█         | 118/1070 [00:14<01:44,  9.07it/s] 11%|█         | 119/1070 [00:14<01:43,  9.21it/s] 11%|█         | 120/1070 [00:14<01:43,  9.18it/s] 11%|█▏        | 121/1070 [00:14<01:43,  9.21it/s] 11%|█▏        | 122/1070 [00:14<01:42,  9.22it/s] 11%|█▏        | 123/1070 [00:14<01:42,  9.25it/s] 12%|█▏        | 124/1070 [00:14<01:41,  9.28it/s] 12%|█▏        | 125/1070 [00:14<01:42,  9.25it/s] 12%|█▏        | 126/1070 [00:14<01:41,  9.28it/s] 12%|█▏        | 127/1070 [00:15<01:42,  9.23it/s] 12%|█▏        | 128/1070 [00:15<01:41,  9.32it/s] 12%|█▏        | 129/1070 [00:15<01:41,  9.26it/s] 12%|█▏        | 130/1070 [00:15<01:42,  9.22it/s] 12%|█▏        | 131/1070 [00:15<01:40,  9.32it/s] 12%|█▏        | 132/1070 [00:15<01:40,  9.35it/s] 12%|█▏        | 133/1070 [00:15<01:41,  9.26it/s] 13%|█▎        | 134/1070 [00:15<01:40,  9.35it/s] 13%|█▎        | 135/1070 [00:15<01:40,  9.28it/s] 13%|█▎        | 136/1070 [00:16<01:42,  9.13it/s] 13%|█▎        | 137/1070 [00:16<01:42,  9.08it/s] 13%|█▎        | 138/1070 [00:16<01:40,  9.27it/s] 13%|█▎        | 139/1070 [00:16<01:40,  9.26it/s] 13%|█▎        | 140/1070 [00:16<01:41,  9.18it/s] 13%|█▎        | 141/1070 [00:16<01:41,  9.18it/s] 13%|█▎        | 142/1070 [00:16<01:41,  9.10it/s] 13%|█▎        | 143/1070 [00:16<01:41,  9.14it/s] 13%|█▎        | 144/1070 [00:16<01:41,  9.12it/s] 14%|█▎        | 145/1070 [00:16<01:39,  9.25it/s] 14%|█▎        | 146/1070 [00:17<01:40,  9.18it/s] 14%|█▎        | 147/1070 [00:17<01:41,  9.12it/s] 14%|█▍        | 148/1070 [00:17<01:41,  9.05it/s] 14%|█▍        | 149/1070 [00:17<01:41,  9.07it/s] 14%|█▍        | 150/1070 [00:17<01:40,  9.12it/s] 14%|█▍        | 151/1070 [00:17<01:40,  9.12it/s] 14%|█▍        | 152/1070 [00:17<01:40,  9.10it/s] 14%|█▍        | 153/1070 [00:17<01:40,  9.13it/s] 14%|█▍        | 154/1070 [00:17<01:40,  9.12it/s] 14%|█▍        | 155/1070 [00:18<01:39,  9.16it/s] 15%|█▍        | 156/1070 [00:18<01:38,  9.24it/s] 15%|█▍        | 157/1070 [00:18<01:39,  9.22it/s] 15%|█▍        | 158/1070 [00:18<01:38,  9.24it/s] 15%|█▍        | 159/1070 [00:18<01:38,  9.20it/s] 15%|█▍        | 160/1070 [00:18<01:38,  9.20it/s] 15%|█▌        | 161/1070 [00:18<01:39,  9.18it/s] 15%|█▌        | 162/1070 [00:18<01:40,  9.07it/s] 15%|█▌        | 163/1070 [00:18<01:37,  9.32it/s] 15%|█▌        | 164/1070 [00:19<01:37,  9.25it/s] 15%|█▌        | 165/1070 [00:19<01:37,  9.30it/s] 16%|█▌        | 166/1070 [00:19<01:38,  9.14it/s] 16%|█▌        | 167/1070 [00:19<01:38,  9.15it/s] 16%|█▌        | 168/1070 [00:19<01:39,  9.08it/s] 16%|█▌        | 169/1070 [00:19<01:39,  9.05it/s] 16%|█▌        | 170/1070 [00:19<01:38,  9.18it/s] 16%|█▌        | 171/1070 [00:19<01:38,  9.13it/s] 16%|█▌        | 172/1070 [00:19<01:38,  9.16it/s] 16%|█▌        | 173/1070 [00:20<01:38,  9.07it/s] 16%|█▋        | 174/1070 [00:20<01:38,  9.14it/s] 16%|█▋        | 175/1070 [00:20<01:37,  9.21it/s] 16%|█▋        | 176/1070 [00:20<01:38,  9.11it/s] 17%|█▋        | 177/1070 [00:20<01:35,  9.32it/s] 17%|█▋        | 178/1070 [00:20<01:36,  9.24it/s] 17%|█▋        | 179/1070 [00:20<01:37,  9.14it/s] 17%|█▋        | 180/1070 [00:20<01:37,  9.13it/s] 17%|█▋        | 181/1070 [00:20<01:36,  9.18it/s] 17%|█▋        | 182/1070 [00:21<01:36,  9.21it/s] 17%|█▋        | 183/1070 [00:21<01:36,  9.18it/s] 17%|█▋        | 184/1070 [00:21<01:36,  9.20it/s] 17%|█▋        | 185/1070 [00:21<01:37,  9.12it/s] 17%|█▋        | 186/1070 [00:21<01:38,  9.02it/s] 17%|█▋        | 187/1070 [00:21<01:37,  9.07it/s] 18%|█▊        | 188/1070 [00:21<01:37,  9.07it/s] 18%|█▊        | 189/1070 [00:21<01:36,  9.11it/s] 18%|█▊        | 190/1070 [00:21<01:36,  9.16it/s] 18%|█▊        | 191/1070 [00:22<01:36,  9.13it/s] 18%|█▊        | 192/1070 [00:22<01:35,  9.17it/s] 18%|█▊        | 193/1070 [00:22<01:36,  9.06it/s] 18%|█▊        | 194/1070 [00:22<01:37,  9.01it/s] 18%|█▊        | 195/1070 [00:22<01:35,  9.20it/s] 18%|█▊        | 196/1070 [00:22<01:35,  9.14it/s] 18%|█▊        | 197/1070 [00:22<01:35,  9.11it/s] 19%|█▊        | 198/1070 [00:22<01:36,  9.08it/s] 19%|█▊        | 199/1070 [00:22<01:35,  9.13it/s] 19%|█▊        | 200/1070 [00:23<01:35,  9.09it/s] 19%|█▉        | 201/1070 [00:23<01:36,  9.03it/s] 19%|█▉        | 202/1070 [00:23<01:34,  9.19it/s] 19%|█▉        | 203/1070 [00:23<01:34,  9.14it/s] 19%|█▉        | 204/1070 [00:23<01:35,  9.08it/s] 19%|█▉        | 205/1070 [00:23<01:34,  9.13it/s] 19%|█▉        | 206/1070 [00:23<01:34,  9.17it/s] 19%|█▉        | 207/1070 [00:23<01:34,  9.11it/s] 19%|█▉        | 208/1070 [00:23<01:35,  9.05it/s] 20%|█▉        | 209/1070 [00:23<01:33,  9.20it/s] 20%|█▉        | 210/1070 [00:24<01:34,  9.12it/s] 20%|█▉        | 211/1070 [00:24<01:34,  9.10it/s] 20%|█▉        | 212/1070 [00:24<01:33,  9.16it/s] 20%|█▉        | 213/1070 [00:24<01:33,  9.12it/s]                                                   20%|██        | 214/1070 [00:24<01:33,  9.12it/s][INFO|trainer.py:755] 2023-11-15 20:44:24,930 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:44:24,931 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:44:24,932 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:44:24,932 >>   Batch size = 8
{'loss': 0.5194, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 80.49it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 83.70it/s][A
 28%|██▊       | 27/95 [00:00<00:00, 80.07it/s][A
 38%|███▊      | 36/95 [00:00<00:00, 77.12it/s][A
 47%|████▋     | 45/95 [00:00<00:00, 78.96it/s][A
 56%|█████▌    | 53/95 [00:00<00:00, 77.31it/s][A
 64%|██████▍   | 61/95 [00:00<00:00, 75.05it/s][A
 73%|███████▎  | 69/95 [00:00<00:00, 75.58it/s][A
 81%|████████  | 77/95 [00:01<00:00, 74.89it/s][A
 89%|████████▉ | 85/95 [00:01<00:00, 75.51it/s][A
 98%|█████████▊| 93/95 [00:01<00:00, 75.04it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:25<01:33,  9.12it/s]
100%|██████████| 95/95 [00:01<00:00, 75.04it/s][A
                                               [A 20%|██        | 215/1070 [00:25<05:45,  2.48it/s] 20%|██        | 216/1070 [00:26<04:43,  3.01it/s] 20%|██        | 217/1070 [00:26<03:54,  3.64it/s] 20%|██        | 218/1070 [00:26<03:16,  4.34it/s] 20%|██        | 219/1070 [00:26<02:47,  5.07it/s] 21%|██        | 220/1070 [00:26<02:25,  5.82it/s] 21%|██        | 221/1070 [00:26<02:10,  6.51it/s] 21%|██        | 222/1070 [00:26<01:58,  7.14it/s] 21%|██        | 223/1070 [00:26<01:50,  7.64it/s] 21%|██        | 224/1070 [00:26<01:45,  7.99it/s] 21%|██        | 225/1070 [00:27<01:41,  8.35it/s] 21%|██        | 226/1070 [00:27<01:38,  8.53it/s] 21%|██        | 227/1070 [00:27<01:36,  8.69it/s] 21%|██▏       | 228/1070 [00:27<01:35,  8.79it/s] 21%|██▏       | 229/1070 [00:27<01:33,  8.96it/s] 21%|██▏       | 230/1070 [00:27<01:33,  9.00it/s] 22%|██▏       | 231/1070 [00:27<01:32,  9.04it/s] 22%|██▏       | 232/1070 [00:27<01:31,  9.15it/s] 22%|██▏       | 233/1070 [00:27<01:31,  9.13it/s] 22%|██▏       | 234/1070 [00:28<01:31,  9.13it/s] 22%|██▏       | 235/1070 [00:28<01:31,  9.16it/s] 22%|██▏       | 236/1070 [00:28<01:29,  9.27it/s] 22%|██▏       | 237/1070 [00:28<01:30,  9.22it/s] 22%|██▏       | 238/1070 [00:28<01:30,  9.21it/s] 22%|██▏       | 239/1070 [00:28<01:30,  9.20it/s] 22%|██▏       | 240/1070 [00:28<01:30,  9.17it/s] 23%|██▎       | 241/1070 [00:28<01:30,  9.14it/s] 23%|██▎       | 242/1070 [00:28<01:30,  9.12it/s] 23%|██▎       | 243/1070 [00:28<01:29,  9.26it/s] 23%|██▎       | 244/1070 [00:29<01:29,  9.27it/s] 23%|██▎       | 245/1070 [00:29<01:29,  9.25it/s] 23%|██▎       | 246/1070 [00:29<01:30,  9.15it/s] 23%|██▎       | 247/1070 [00:29<01:29,  9.20it/s] 23%|██▎       | 248/1070 [00:29<01:29,  9.18it/s] 23%|██▎       | 249/1070 [00:29<01:29,  9.18it/s] 23%|██▎       | 250/1070 [00:29<01:28,  9.29it/s] 23%|██▎       | 251/1070 [00:29<01:28,  9.23it/s] 24%|██▎       | 252/1070 [00:29<01:28,  9.29it/s] 24%|██▎       | 253/1070 [00:30<01:28,  9.25it/s] 24%|██▎       | 254/1070 [00:30<01:28,  9.22it/s] 24%|██▍       | 255/1070 [00:30<01:28,  9.18it/s] 24%|██▍       | 256/1070 [00:30<01:28,  9.19it/s] 24%|██▍       | 257/1070 [00:30<01:27,  9.27it/s] 24%|██▍       | 258/1070 [00:30<01:27,  9.27it/s] 24%|██▍       | 259/1070 [00:30<01:27,  9.32it/s] 24%|██▍       | 260/1070 [00:30<01:26,  9.38it/s] 24%|██▍       | 261/1070 [00:30<01:27,  9.28it/s] 24%|██▍       | 262/1070 [00:31<01:27,  9.27it/s] 25%|██▍       | 263/1070 [00:31<01:26,  9.28it/s] 25%|██▍       | 264/1070 [00:31<01:27,  9.25it/s] 25%|██▍       | 265/1070 [00:31<01:27,  9.17it/s] 25%|██▍       | 266/1070 [00:31<01:28,  9.12it/s] 25%|██▍       | 267/1070 [00:31<01:26,  9.27it/s] 25%|██▌       | 268/1070 [00:31<01:27,  9.19it/s] 25%|██▌       | 269/1070 [00:31<01:26,  9.23it/s] 25%|██▌       | 270/1070 [00:31<01:27,  9.11it/s] 25%|██▌       | 271/1070 [00:32<01:26,  9.22it/s] 25%|██▌       | 272/1070 [00:32<01:26,  9.22it/s] 26%|██▌       | 273/1070 [00:32<01:27,  9.15it/s] 26%|██▌       | 274/1070 [00:32<01:25,  9.30it/s] 26%|██▌       | 275/1070 [00:32<01:26,  9.19it/s] 26%|██▌       | 276/1070 [00:32<01:26,  9.23it/s] 26%|██▌       | 277/1070 [00:32<01:26,  9.14it/s] 26%|██▌       | 278/1070 [00:32<01:26,  9.11it/s] 26%|██▌       | 279/1070 [00:32<01:26,  9.14it/s] 26%|██▌       | 280/1070 [00:33<01:27,  9.06it/s] 26%|██▋       | 281/1070 [00:33<01:25,  9.24it/s] 26%|██▋       | 282/1070 [00:33<01:25,  9.16it/s] 26%|██▋       | 283/1070 [00:33<01:25,  9.17it/s] 27%|██▋       | 284/1070 [00:33<01:26,  9.09it/s] 27%|██▋       | 285/1070 [00:33<01:26,  9.09it/s] 27%|██▋       | 286/1070 [00:33<01:25,  9.14it/s] 27%|██▋       | 287/1070 [00:33<01:25,  9.14it/s] 27%|██▋       | 288/1070 [00:33<01:23,  9.35it/s] 27%|██▋       | 289/1070 [00:33<01:24,  9.29it/s] 27%|██▋       | 290/1070 [00:34<01:23,  9.32it/s] 27%|██▋       | 291/1070 [00:34<01:24,  9.26it/s] 27%|██▋       | 292/1070 [00:34<01:24,  9.23it/s] 27%|██▋       | 293/1070 [00:34<01:24,  9.20it/s] 27%|██▋       | 294/1070 [00:34<01:24,  9.19it/s] 28%|██▊       | 295/1070 [00:34<01:23,  9.28it/s] 28%|██▊       | 296/1070 [00:34<01:22,  9.33it/s] 28%|██▊       | 297/1070 [00:34<01:23,  9.30it/s] 28%|██▊       | 298/1070 [00:34<01:23,  9.26it/s] 28%|██▊       | 299/1070 [00:35<01:23,  9.18it/s] 28%|██▊       | 300/1070 [00:35<01:24,  9.16it/s] 28%|██▊       | 301/1070 [00:35<01:23,  9.17it/s] 28%|██▊       | 302/1070 [00:35<01:23,  9.20it/s] 28%|██▊       | 303/1070 [00:35<01:23,  9.19it/s] 28%|██▊       | 304/1070 [00:35<01:23,  9.21it/s] 29%|██▊       | 305/1070 [00:35<01:21,  9.34it/s] 29%|██▊       | 306/1070 [00:35<01:22,  9.25it/s] 29%|██▊       | 307/1070 [00:35<01:22,  9.26it/s] 29%|██▉       | 308/1070 [00:36<01:22,  9.28it/s] 29%|██▉       | 309/1070 [00:36<01:22,  9.27it/s] 29%|██▉       | 310/1070 [00:36<01:22,  9.23it/s] 29%|██▉       | 311/1070 [00:36<01:22,  9.16it/s] 29%|██▉       | 312/1070 [00:36<01:21,  9.32it/s] 29%|██▉       | 313/1070 [00:36<01:22,  9.22it/s] 29%|██▉       | 314/1070 [00:36<01:22,  9.21it/s] 29%|██▉       | 315/1070 [00:36<01:23,  9.09it/s] 30%|██▉       | 316/1070 [00:36<01:22,  9.10it/s] 30%|██▉       | 317/1070 [00:37<01:22,  9.13it/s] 30%|██▉       | 318/1070 [00:37<01:22,  9.10it/s] 30%|██▉       | 319/1070 [00:37<01:21,  9.27it/s] 30%|██▉       | 320/1070 [00:37<01:21,  9.22it/s] 30%|███       | 321/1070 [00:37<01:20,  9.28it/s] 30%|███       | 322/1070 [00:37<01:21,  9.16it/s] 30%|███       | 323/1070 [00:37<01:21,  9.21it/s] 30%|███       | 324/1070 [00:37<01:21,  9.15it/s] 30%|███       | 325/1070 [00:37<01:21,  9.13it/s] 30%|███       | 326/1070 [00:38<01:21,  9.16it/s] 31%|███       | 327/1070 [00:38<01:21,  9.14it/s] 31%|███       | 328/1070 [00:38<01:19,  9.30it/s] 31%|███       | 329/1070 [00:38<01:19,  9.29it/s] 31%|███       | 330/1070 [00:38<01:19,  9.28it/s] 31%|███       | 331/1070 [00:38<01:19,  9.28it/s] 31%|███       | 332/1070 [00:38<01:20,  9.18it/s] 31%|███       | 333/1070 [00:38<01:20,  9.19it/s] 31%|███       | 334/1070 [00:38<01:20,  9.17it/s] 31%|███▏      | 335/1070 [00:38<01:19,  9.22it/s] 31%|███▏      | 336/1070 [00:39<01:18,  9.29it/s] 31%|███▏      | 337/1070 [00:39<01:19,  9.20it/s] 32%|███▏      | 338/1070 [00:39<01:20,  9.14it/s] 32%|███▏      | 339/1070 [00:39<01:19,  9.17it/s] 32%|███▏      | 340/1070 [00:39<01:19,  9.21it/s] 32%|███▏      | 341/1070 [00:39<01:19,  9.19it/s] 32%|███▏      | 342/1070 [00:39<01:19,  9.16it/s] 32%|███▏      | 343/1070 [00:39<01:18,  9.29it/s] 32%|███▏      | 344/1070 [00:39<01:18,  9.20it/s] 32%|███▏      | 345/1070 [00:40<01:18,  9.22it/s] 32%|███▏      | 346/1070 [00:40<01:18,  9.16it/s] 32%|███▏      | 347/1070 [00:40<01:18,  9.21it/s] 33%|███▎      | 348/1070 [00:40<01:18,  9.20it/s] 33%|███▎      | 349/1070 [00:40<01:18,  9.17it/s] 33%|███▎      | 350/1070 [00:40<01:17,  9.28it/s] 33%|███▎      | 351/1070 [00:40<01:17,  9.23it/s] 33%|███▎      | 352/1070 [00:40<01:17,  9.21it/s] 33%|███▎      | 353/1070 [00:40<01:18,  9.17it/s] 33%|███▎      | 354/1070 [00:41<01:17,  9.18it/s] 33%|███▎      | 355/1070 [00:41<01:17,  9.17it/s] 33%|███▎      | 356/1070 [00:41<01:17,  9.16it/s] 33%|███▎      | 357/1070 [00:41<01:17,  9.18it/s] 33%|███▎      | 358/1070 [00:41<01:17,  9.15it/s] 34%|███▎      | 359/1070 [00:41<01:16,  9.24it/s] 34%|███▎      | 360/1070 [00:41<01:16,  9.27it/s] 34%|███▎      | 361/1070 [00:41<01:16,  9.21it/s] 34%|███▍      | 362/1070 [00:41<01:17,  9.19it/s] 34%|███▍      | 363/1070 [00:42<01:17,  9.16it/s] 34%|███▍      | 364/1070 [00:42<01:17,  9.15it/s] 34%|███▍      | 365/1070 [00:42<01:17,  9.14it/s] 34%|███▍      | 366/1070 [00:42<01:16,  9.15it/s] 34%|███▍      | 367/1070 [00:42<01:15,  9.29it/s] 34%|███▍      | 368/1070 [00:42<01:16,  9.22it/s] 34%|███▍      | 369/1070 [00:42<01:16,  9.21it/s] 35%|███▍      | 370/1070 [00:42<01:15,  9.21it/s] 35%|███▍      | 371/1070 [00:42<01:16,  9.15it/s] 35%|███▍      | 372/1070 [00:43<01:15,  9.19it/s] 35%|███▍      | 373/1070 [00:43<01:15,  9.19it/s] 35%|███▍      | 374/1070 [00:43<01:15,  9.27it/s] 35%|███▌      | 375/1070 [00:43<01:15,  9.18it/s] 35%|███▌      | 376/1070 [00:43<01:15,  9.21it/s] 35%|███▌      | 377/1070 [00:43<01:15,  9.17it/s] 35%|███▌      | 378/1070 [00:43<01:15,  9.14it/s] 35%|███▌      | 379/1070 [00:43<01:15,  9.16it/s] 36%|███▌      | 380/1070 [00:43<01:15,  9.14it/s] 36%|███▌      | 381/1070 [00:43<01:15,  9.16it/s] 36%|███▌      | 382/1070 [00:44<01:15,  9.12it/s] 36%|███▌      | 383/1070 [00:44<01:15,  9.13it/s] 36%|███▌      | 384/1070 [00:44<01:14,  9.24it/s] 36%|███▌      | 385/1070 [00:44<01:14,  9.24it/s] 36%|███▌      | 386/1070 [00:44<01:13,  9.24it/s] 36%|███▌      | 387/1070 [00:44<01:13,  9.25it/s] 36%|███▋      | 388/1070 [00:44<01:14,  9.21it/s] 36%|███▋      | 389/1070 [00:44<01:14,  9.20it/s] 36%|███▋      | 390/1070 [00:44<01:14,  9.17it/s] 37%|███▋      | 391/1070 [00:45<01:13,  9.28it/s] 37%|███▋      | 392/1070 [00:45<01:12,  9.30it/s] 37%|███▋      | 393/1070 [00:45<01:13,  9.27it/s] 37%|███▋      | 394/1070 [00:45<01:13,  9.19it/s] 37%|███▋      | 395/1070 [00:45<01:13,  9.20it/s] 37%|███▋      | 396/1070 [00:45<01:13,  9.19it/s] 37%|███▋      | 397/1070 [00:45<01:12,  9.27it/s] 37%|███▋      | 398/1070 [00:45<01:13,  9.20it/s] 37%|███▋      | 399/1070 [00:45<01:12,  9.21it/s] 37%|███▋      | 400/1070 [00:46<01:12,  9.21it/s] 37%|███▋      | 401/1070 [00:46<01:12,  9.29it/s] 38%|███▊      | 402/1070 [00:46<01:12,  9.23it/s] 38%|███▊      | 403/1070 [00:46<01:11,  9.31it/s] 38%|███▊      | 404/1070 [00:46<01:12,  9.22it/s] 38%|███▊      | 405/1070 [00:46<01:11,  9.26it/s] 38%|███▊      | 406/1070 [00:46<01:11,  9.24it/s] 38%|███▊      | 407/1070 [00:46<01:11,  9.23it/s] 38%|███▊      | 408/1070 [00:46<01:11,  9.28it/s] 38%|███▊      | 409/1070 [00:47<01:10,  9.32it/s] 38%|███▊      | 410/1070 [00:47<01:11,  9.27it/s] 38%|███▊      | 411/1070 [00:47<01:10,  9.33it/s] 39%|███▊      | 412/1070 [00:47<01:11,  9.25it/s] 39%|███▊      | 413/1070 [00:47<01:11,  9.20it/s] 39%|███▊      | 414/1070 [00:47<01:11,  9.12it/s] 39%|███▉      | 415/1070 [00:47<01:12,  9.08it/s] 39%|███▉      | 416/1070 [00:47<01:11,  9.16it/s] 39%|███▉      | 417/1070 [00:47<01:11,  9.15it/s] 39%|███▉      | 418/1070 [00:47<01:10,  9.27it/s] 39%|███▉      | 419/1070 [00:48<01:10,  9.26it/s] 39%|███▉      | 420/1070 [00:48<01:10,  9.22it/s] 39%|███▉      | 421/1070 [00:48<01:10,  9.22it/s] 39%|███▉      | 422/1070 [00:48<01:10,  9.20it/s] 40%|███▉      | 423/1070 [00:48<01:10,  9.21it/s] 40%|███▉      | 424/1070 [00:48<01:10,  9.19it/s] 40%|███▉      | 425/1070 [00:48<01:09,  9.25it/s] 40%|███▉      | 426/1070 [00:48<01:09,  9.20it/s] 40%|███▉      | 427/1070 [00:48<01:10,  9.18it/s]                                                   40%|████      | 428/1070 [00:49<01:09,  9.18it/s][INFO|trainer.py:755] 2023-11-15 20:44:49,455 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:44:49,457 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:44:49,457 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:44:49,458 >>   Batch size = 8
{'eval_loss': 0.3106633126735687, 'eval_accuracy': 0.8986842105263158, 'eval_micro_f1': 0.8986842105263158, 'eval_macro_f1': 0.8942361512260074, 'eval_runtime': 1.2905, 'eval_samples_per_second': 588.929, 'eval_steps_per_second': 73.616, 'epoch': 1.0}
{'loss': 0.2382, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 82.55it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 76.41it/s][A
 28%|██▊       | 27/95 [00:00<00:00, 78.86it/s][A
 37%|███▋      | 35/95 [00:00<00:00, 76.99it/s][A
 45%|████▌     | 43/95 [00:00<00:00, 76.67it/s][A
 54%|█████▎    | 51/95 [00:00<00:00, 74.17it/s][A
 62%|██████▏   | 59/95 [00:00<00:00, 75.25it/s][A
 71%|███████   | 67/95 [00:00<00:00, 73.98it/s][A
 79%|███████▉  | 75/95 [00:00<00:00, 74.16it/s][A
 87%|████████▋ | 83/95 [00:01<00:00, 74.07it/s][A
 96%|█████████▌| 91/95 [00:01<00:00, 72.55it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:50<01:09,  9.18it/s]
100%|██████████| 95/95 [00:01<00:00, 72.55it/s][A
                                               [A 40%|████      | 429/1070 [00:50<04:22,  2.44it/s] 40%|████      | 430/1070 [00:50<03:34,  2.99it/s] 40%|████      | 431/1070 [00:50<02:56,  3.62it/s] 40%|████      | 432/1070 [00:50<02:27,  4.34it/s] 40%|████      | 433/1070 [00:50<02:04,  5.11it/s] 41%|████      | 434/1070 [00:51<01:49,  5.83it/s] 41%|████      | 435/1070 [00:51<01:37,  6.50it/s] 41%|████      | 436/1070 [00:51<01:28,  7.15it/s] 41%|████      | 437/1070 [00:51<01:22,  7.66it/s] 41%|████      | 438/1070 [00:51<01:18,  8.02it/s] 41%|████      | 439/1070 [00:51<01:15,  8.36it/s] 41%|████      | 440/1070 [00:51<01:14,  8.48it/s] 41%|████      | 441/1070 [00:51<01:12,  8.71it/s] 41%|████▏     | 442/1070 [00:51<01:11,  8.80it/s] 41%|████▏     | 443/1070 [00:52<01:09,  9.04it/s] 41%|████▏     | 444/1070 [00:52<01:09,  9.07it/s] 42%|████▏     | 445/1070 [00:52<01:08,  9.13it/s] 42%|████▏     | 446/1070 [00:52<01:07,  9.21it/s] 42%|████▏     | 447/1070 [00:52<01:07,  9.24it/s] 42%|████▏     | 448/1070 [00:52<01:07,  9.18it/s] 42%|████▏     | 449/1070 [00:52<01:07,  9.20it/s] 42%|████▏     | 450/1070 [00:52<01:06,  9.30it/s] 42%|████▏     | 451/1070 [00:52<01:06,  9.35it/s] 42%|████▏     | 452/1070 [00:52<01:06,  9.30it/s] 42%|████▏     | 453/1070 [00:53<01:05,  9.39it/s] 42%|████▏     | 454/1070 [00:53<01:05,  9.35it/s] 43%|████▎     | 455/1070 [00:53<01:06,  9.26it/s] 43%|████▎     | 456/1070 [00:53<01:07,  9.14it/s] 43%|████▎     | 457/1070 [00:53<01:07,  9.11it/s] 43%|████▎     | 458/1070 [00:53<01:06,  9.17it/s] 43%|████▎     | 459/1070 [00:53<01:06,  9.21it/s] 43%|████▎     | 460/1070 [00:53<01:05,  9.33it/s] 43%|████▎     | 461/1070 [00:53<01:04,  9.38it/s] 43%|████▎     | 462/1070 [00:54<01:05,  9.32it/s] 43%|████▎     | 463/1070 [00:54<01:05,  9.21it/s] 43%|████▎     | 464/1070 [00:54<01:05,  9.25it/s] 43%|████▎     | 465/1070 [00:54<01:05,  9.22it/s] 44%|████▎     | 466/1070 [00:54<01:05,  9.23it/s] 44%|████▎     | 467/1070 [00:54<01:04,  9.33it/s] 44%|████▎     | 468/1070 [00:54<01:04,  9.28it/s] 44%|████▍     | 469/1070 [00:54<01:04,  9.26it/s] 44%|████▍     | 470/1070 [00:54<01:04,  9.27it/s] 44%|████▍     | 471/1070 [00:55<01:04,  9.30it/s] 44%|████▍     | 472/1070 [00:55<01:04,  9.28it/s] 44%|████▍     | 473/1070 [00:55<01:04,  9.26it/s] 44%|████▍     | 474/1070 [00:55<01:04,  9.20it/s] 44%|████▍     | 475/1070 [00:55<01:04,  9.17it/s] 44%|████▍     | 476/1070 [00:55<01:04,  9.23it/s] 45%|████▍     | 477/1070 [00:55<01:03,  9.32it/s] 45%|████▍     | 478/1070 [00:55<01:03,  9.28it/s] 45%|████▍     | 479/1070 [00:55<01:03,  9.29it/s] 45%|████▍     | 480/1070 [00:56<01:04,  9.21it/s] 45%|████▍     | 481/1070 [00:56<01:03,  9.29it/s] 45%|████▌     | 482/1070 [00:56<01:03,  9.25it/s] 45%|████▌     | 483/1070 [00:56<01:03,  9.28it/s] 45%|████▌     | 484/1070 [00:56<01:02,  9.37it/s] 45%|████▌     | 485/1070 [00:56<01:03,  9.25it/s] 45%|████▌     | 486/1070 [00:56<01:02,  9.28it/s] 46%|████▌     | 487/1070 [00:56<01:02,  9.37it/s] 46%|████▌     | 488/1070 [00:56<01:02,  9.33it/s] 46%|████▌     | 489/1070 [00:56<01:02,  9.24it/s] 46%|████▌     | 490/1070 [00:57<01:02,  9.21it/s] 46%|████▌     | 491/1070 [00:57<01:03,  9.16it/s] 46%|████▌     | 492/1070 [00:57<01:02,  9.27it/s] 46%|████▌     | 493/1070 [00:57<01:02,  9.23it/s] 46%|████▌     | 494/1070 [00:57<01:01,  9.34it/s] 46%|████▋     | 495/1070 [00:57<01:01,  9.33it/s] 46%|████▋     | 496/1070 [00:57<01:01,  9.34it/s] 46%|████▋     | 497/1070 [00:57<01:00,  9.40it/s] 47%|████▋     | 498/1070 [00:57<01:01,  9.37it/s] 47%|████▋     | 499/1070 [00:58<01:00,  9.37it/s] 47%|████▋     | 500/1070 [00:58<01:00,  9.37it/s] 47%|████▋     | 501/1070 [00:58<01:00,  9.40it/s] 47%|████▋     | 502/1070 [00:58<01:00,  9.34it/s] 47%|████▋     | 503/1070 [00:58<01:01,  9.29it/s] 47%|████▋     | 504/1070 [00:58<01:00,  9.37it/s] 47%|████▋     | 505/1070 [00:58<01:00,  9.33it/s] 47%|████▋     | 506/1070 [00:58<01:00,  9.32it/s] 47%|████▋     | 507/1070 [00:58<01:00,  9.35it/s] 47%|████▋     | 508/1070 [00:59<01:00,  9.36it/s] 48%|████▊     | 509/1070 [00:59<01:00,  9.28it/s] 48%|████▊     | 510/1070 [00:59<01:00,  9.29it/s] 48%|████▊     | 511/1070 [00:59<01:00,  9.26it/s] 48%|████▊     | 512/1070 [00:59<01:00,  9.25it/s] 48%|████▊     | 513/1070 [00:59<01:00,  9.28it/s] 48%|████▊     | 514/1070 [00:59<00:59,  9.38it/s] 48%|████▊     | 515/1070 [00:59<00:59,  9.27it/s] 48%|████▊     | 516/1070 [00:59<01:00,  9.20it/s] 48%|████▊     | 517/1070 [00:59<01:00,  9.21it/s] 48%|████▊     | 518/1070 [01:00<00:59,  9.28it/s] 49%|████▊     | 519/1070 [01:00<00:59,  9.30it/s] 49%|████▊     | 520/1070 [01:00<00:59,  9.26it/s] 49%|████▊     | 521/1070 [01:00<00:58,  9.39it/s] 49%|████▉     | 522/1070 [01:00<00:58,  9.30it/s] 49%|████▉     | 523/1070 [01:00<00:58,  9.28it/s] 49%|████▉     | 524/1070 [01:00<00:57,  9.42it/s] 49%|████▉     | 525/1070 [01:00<00:58,  9.37it/s] 49%|████▉     | 526/1070 [01:00<00:58,  9.24it/s] 49%|████▉     | 527/1070 [01:01<00:58,  9.26it/s] 49%|████▉     | 528/1070 [01:01<00:58,  9.20it/s] 49%|████▉     | 529/1070 [01:01<00:58,  9.28it/s] 50%|████▉     | 530/1070 [01:01<00:57,  9.31it/s] 50%|████▉     | 531/1070 [01:01<00:56,  9.46it/s] 50%|████▉     | 532/1070 [01:01<00:57,  9.29it/s] 50%|████▉     | 533/1070 [01:01<00:57,  9.29it/s] 50%|████▉     | 534/1070 [01:01<00:57,  9.30it/s] 50%|█████     | 535/1070 [01:01<00:57,  9.33it/s] 50%|█████     | 536/1070 [01:02<00:57,  9.27it/s] 50%|█████     | 537/1070 [01:02<00:57,  9.24it/s] 50%|█████     | 538/1070 [01:02<00:56,  9.34it/s] 50%|█████     | 539/1070 [01:02<00:57,  9.19it/s] 50%|█████     | 540/1070 [01:02<00:57,  9.19it/s] 51%|█████     | 541/1070 [01:02<00:57,  9.25it/s] 51%|█████     | 542/1070 [01:02<00:56,  9.27it/s] 51%|█████     | 543/1070 [01:02<00:56,  9.25it/s] 51%|█████     | 544/1070 [01:02<00:56,  9.23it/s] 51%|█████     | 545/1070 [01:03<00:57,  9.16it/s] 51%|█████     | 546/1070 [01:03<00:57,  9.15it/s] 51%|█████     | 547/1070 [01:03<00:56,  9.20it/s] 51%|█████     | 548/1070 [01:03<00:55,  9.36it/s] 51%|█████▏    | 549/1070 [01:03<00:55,  9.32it/s] 51%|█████▏    | 550/1070 [01:03<00:56,  9.29it/s] 51%|█████▏    | 551/1070 [01:03<00:56,  9.24it/s] 52%|█████▏    | 552/1070 [01:03<00:56,  9.21it/s] 52%|█████▏    | 553/1070 [01:03<00:55,  9.23it/s] 52%|█████▏    | 554/1070 [01:03<00:55,  9.27it/s] 52%|█████▏    | 555/1070 [01:04<00:55,  9.34it/s] 52%|█████▏    | 556/1070 [01:04<00:55,  9.28it/s] 52%|█████▏    | 557/1070 [01:04<00:55,  9.26it/s] 52%|█████▏    | 558/1070 [01:04<00:54,  9.42it/s] 52%|█████▏    | 559/1070 [01:04<00:54,  9.35it/s] 52%|█████▏    | 560/1070 [01:04<00:55,  9.23it/s] 52%|█████▏    | 561/1070 [01:04<00:54,  9.27it/s] 53%|█████▎    | 562/1070 [01:04<00:55,  9.20it/s] 53%|█████▎    | 563/1070 [01:04<00:54,  9.26it/s] 53%|█████▎    | 564/1070 [01:05<00:54,  9.27it/s] 53%|█████▎    | 565/1070 [01:05<00:54,  9.27it/s] 53%|█████▎    | 566/1070 [01:05<00:54,  9.21it/s] 53%|█████▎    | 567/1070 [01:05<00:54,  9.20it/s] 53%|█████▎    | 568/1070 [01:05<00:53,  9.33it/s] 53%|█████▎    | 569/1070 [01:05<00:54,  9.25it/s] 53%|█████▎    | 570/1070 [01:05<00:54,  9.11it/s] 53%|█████▎    | 571/1070 [01:05<00:54,  9.14it/s] 53%|█████▎    | 572/1070 [01:05<00:53,  9.31it/s] 54%|█████▎    | 573/1070 [01:06<00:53,  9.28it/s] 54%|█████▎    | 574/1070 [01:06<00:53,  9.24it/s] 54%|█████▎    | 575/1070 [01:06<00:52,  9.40it/s] 54%|█████▍    | 576/1070 [01:06<00:53,  9.30it/s] 54%|█████▍    | 577/1070 [01:06<00:53,  9.25it/s] 54%|█████▍    | 578/1070 [01:06<00:52,  9.34it/s] 54%|█████▍    | 579/1070 [01:06<00:52,  9.32it/s] 54%|█████▍    | 580/1070 [01:06<00:52,  9.32it/s] 54%|█████▍    | 581/1070 [01:06<00:53,  9.20it/s] 54%|█████▍    | 582/1070 [01:06<00:52,  9.25it/s] 54%|█████▍    | 583/1070 [01:07<00:52,  9.24it/s] 55%|█████▍    | 584/1070 [01:07<00:52,  9.25it/s] 55%|█████▍    | 585/1070 [01:07<00:51,  9.39it/s] 55%|█████▍    | 586/1070 [01:07<00:52,  9.30it/s] 55%|█████▍    | 587/1070 [01:07<00:52,  9.16it/s] 55%|█████▍    | 588/1070 [01:07<00:52,  9.24it/s] 55%|█████▌    | 589/1070 [01:07<00:52,  9.25it/s] 55%|█████▌    | 590/1070 [01:07<00:52,  9.22it/s] 55%|█████▌    | 591/1070 [01:07<00:52,  9.07it/s] 55%|█████▌    | 592/1070 [01:08<00:51,  9.22it/s] 55%|█████▌    | 593/1070 [01:08<00:51,  9.20it/s] 56%|█████▌    | 594/1070 [01:08<00:51,  9.23it/s] 56%|█████▌    | 595/1070 [01:08<00:50,  9.33it/s] 56%|█████▌    | 596/1070 [01:08<00:51,  9.26it/s] 56%|█████▌    | 597/1070 [01:08<00:52,  9.06it/s] 56%|█████▌    | 598/1070 [01:08<00:51,  9.10it/s] 56%|█████▌    | 599/1070 [01:08<00:51,  9.11it/s] 56%|█████▌    | 600/1070 [01:08<00:51,  9.19it/s] 56%|█████▌    | 601/1070 [01:09<00:50,  9.22it/s] 56%|█████▋    | 602/1070 [01:09<00:50,  9.36it/s] 56%|█████▋    | 603/1070 [01:09<00:50,  9.19it/s] 56%|█████▋    | 604/1070 [01:09<00:50,  9.16it/s] 57%|█████▋    | 605/1070 [01:09<00:50,  9.26it/s] 57%|█████▋    | 606/1070 [01:09<00:50,  9.28it/s] 57%|█████▋    | 607/1070 [01:09<00:50,  9.26it/s] 57%|█████▋    | 608/1070 [01:09<00:51,  9.04it/s] 57%|█████▋    | 609/1070 [01:09<00:50,  9.19it/s] 57%|█████▋    | 610/1070 [01:10<00:50,  9.15it/s] 57%|█████▋    | 611/1070 [01:10<00:49,  9.19it/s] 57%|█████▋    | 612/1070 [01:10<00:49,  9.24it/s] 57%|█████▋    | 613/1070 [01:10<00:49,  9.27it/s] 57%|█████▋    | 614/1070 [01:10<00:50,  9.11it/s] 57%|█████▋    | 615/1070 [01:10<00:49,  9.12it/s] 58%|█████▊    | 616/1070 [01:10<00:49,  9.14it/s] 58%|█████▊    | 617/1070 [01:10<00:49,  9.15it/s] 58%|█████▊    | 618/1070 [01:10<00:49,  9.16it/s] 58%|█████▊    | 619/1070 [01:11<00:48,  9.32it/s] 58%|█████▊    | 620/1070 [01:11<00:49,  9.15it/s] 58%|█████▊    | 621/1070 [01:11<00:49,  9.15it/s] 58%|█████▊    | 622/1070 [01:11<00:48,  9.26it/s] 58%|█████▊    | 623/1070 [01:11<00:48,  9.24it/s] 58%|█████▊    | 624/1070 [01:11<00:48,  9.23it/s] 58%|█████▊    | 625/1070 [01:11<00:48,  9.17it/s] 59%|█████▊    | 626/1070 [01:11<00:47,  9.33it/s] 59%|█████▊    | 627/1070 [01:11<00:48,  9.19it/s] 59%|█████▊    | 628/1070 [01:11<00:47,  9.24it/s] 59%|█████▉    | 629/1070 [01:12<00:47,  9.27it/s] 59%|█████▉    | 630/1070 [01:12<00:47,  9.26it/s] 59%|█████▉    | 631/1070 [01:12<00:47,  9.27it/s] 59%|█████▉    | 632/1070 [01:12<00:47,  9.13it/s] 59%|█████▉    | 633/1070 [01:12<00:47,  9.19it/s] 59%|█████▉    | 634/1070 [01:12<00:47,  9.20it/s] 59%|█████▉    | 635/1070 [01:12<00:47,  9.22it/s] 59%|█████▉    | 636/1070 [01:12<00:46,  9.33it/s] 60%|█████▉    | 637/1070 [01:12<00:46,  9.28it/s] 60%|█████▉    | 638/1070 [01:13<00:47,  9.19it/s] 60%|█████▉    | 639/1070 [01:13<00:46,  9.19it/s] 60%|█████▉    | 640/1070 [01:13<00:46,  9.23it/s] 60%|█████▉    | 641/1070 [01:13<00:46,  9.30it/s]                                                   60%|██████    | 642/1070 [01:13<00:46,  9.30it/s][INFO|trainer.py:755] 2023-11-15 20:45:13,887 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:45:13,888 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:45:13,889 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:45:13,889 >>   Batch size = 8
{'eval_loss': 0.2946847081184387, 'eval_accuracy': 0.906578947368421, 'eval_micro_f1': 0.906578947368421, 'eval_macro_f1': 0.9029097641234338, 'eval_runtime': 1.315, 'eval_samples_per_second': 577.931, 'eval_steps_per_second': 72.241, 'epoch': 2.0}
{'loss': 0.1502, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 11%|█         | 10/95 [00:00<00:00, 94.54it/s][A
 21%|██        | 20/95 [00:00<00:00, 79.88it/s][A
 31%|███       | 29/95 [00:00<00:00, 78.11it/s][A
 39%|███▉      | 37/95 [00:00<00:00, 78.74it/s][A
 47%|████▋     | 45/95 [00:00<00:00, 76.21it/s][A
 56%|█████▌    | 53/95 [00:00<00:00, 74.32it/s][A
 64%|██████▍   | 61/95 [00:00<00:00, 73.32it/s][A
 73%|███████▎  | 69/95 [00:00<00:00, 74.21it/s][A
 81%|████████  | 77/95 [00:01<00:00, 73.82it/s][A
 89%|████████▉ | 85/95 [00:01<00:00, 73.62it/s][A
 99%|█████████▉| 94/95 [00:01<00:00, 76.19it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:14<00:46,  9.30it/s]
100%|██████████| 95/95 [00:01<00:00, 76.19it/s][A
                                               [A 60%|██████    | 643/1070 [01:14<02:53,  2.46it/s] 60%|██████    | 644/1070 [01:15<02:22,  3.00it/s] 60%|██████    | 645/1070 [01:15<01:56,  3.66it/s] 60%|██████    | 646/1070 [01:15<01:37,  4.34it/s] 60%|██████    | 647/1070 [01:15<01:22,  5.11it/s] 61%|██████    | 648/1070 [01:15<01:13,  5.78it/s] 61%|██████    | 649/1070 [01:15<01:04,  6.49it/s] 61%|██████    | 650/1070 [01:15<00:59,  7.03it/s] 61%|██████    | 651/1070 [01:15<00:55,  7.60it/s] 61%|██████    | 652/1070 [01:15<00:52,  8.03it/s] 61%|██████    | 653/1070 [01:16<00:49,  8.38it/s] 61%|██████    | 654/1070 [01:16<00:48,  8.64it/s] 61%|██████    | 655/1070 [01:16<00:46,  8.96it/s] 61%|██████▏   | 656/1070 [01:16<00:46,  8.97it/s] 61%|██████▏   | 657/1070 [01:16<00:45,  9.10it/s] 61%|██████▏   | 658/1070 [01:16<00:45,  9.12it/s] 62%|██████▏   | 659/1070 [01:16<00:44,  9.18it/s] 62%|██████▏   | 660/1070 [01:16<00:44,  9.24it/s] 62%|██████▏   | 661/1070 [01:16<00:44,  9.24it/s] 62%|██████▏   | 662/1070 [01:16<00:43,  9.39it/s] 62%|██████▏   | 663/1070 [01:17<00:44,  9.25it/s] 62%|██████▏   | 664/1070 [01:17<00:43,  9.28it/s] 62%|██████▏   | 665/1070 [01:17<00:43,  9.33it/s] 62%|██████▏   | 666/1070 [01:17<00:43,  9.32it/s] 62%|██████▏   | 667/1070 [01:17<00:43,  9.32it/s] 62%|██████▏   | 668/1070 [01:17<00:43,  9.23it/s] 63%|██████▎   | 669/1070 [01:17<00:42,  9.38it/s] 63%|██████▎   | 670/1070 [01:17<00:42,  9.33it/s] 63%|██████▎   | 671/1070 [01:17<00:42,  9.38it/s] 63%|██████▎   | 672/1070 [01:18<00:42,  9.41it/s] 63%|██████▎   | 673/1070 [01:18<00:42,  9.33it/s] 63%|██████▎   | 674/1070 [01:18<00:42,  9.32it/s] 63%|██████▎   | 675/1070 [01:18<00:42,  9.27it/s] 63%|██████▎   | 676/1070 [01:18<00:42,  9.33it/s] 63%|██████▎   | 677/1070 [01:18<00:41,  9.40it/s] 63%|██████▎   | 678/1070 [01:18<00:41,  9.38it/s] 63%|██████▎   | 679/1070 [01:18<00:41,  9.48it/s] 64%|██████▎   | 680/1070 [01:18<00:41,  9.31it/s] 64%|██████▎   | 681/1070 [01:19<00:42,  9.25it/s] 64%|██████▎   | 682/1070 [01:19<00:41,  9.28it/s] 64%|██████▍   | 683/1070 [01:19<00:41,  9.33it/s] 64%|██████▍   | 684/1070 [01:19<00:41,  9.32it/s] 64%|██████▍   | 685/1070 [01:19<00:41,  9.23it/s] 64%|██████▍   | 686/1070 [01:19<00:41,  9.28it/s] 64%|██████▍   | 687/1070 [01:19<00:41,  9.31it/s] 64%|██████▍   | 688/1070 [01:19<00:41,  9.27it/s] 64%|██████▍   | 689/1070 [01:19<00:40,  9.43it/s] 64%|██████▍   | 690/1070 [01:19<00:40,  9.30it/s] 65%|██████▍   | 691/1070 [01:20<00:40,  9.31it/s] 65%|██████▍   | 692/1070 [01:20<00:40,  9.27it/s] 65%|██████▍   | 693/1070 [01:20<00:40,  9.33it/s] 65%|██████▍   | 694/1070 [01:20<00:40,  9.28it/s] 65%|██████▍   | 695/1070 [01:20<00:40,  9.28it/s] 65%|██████▌   | 696/1070 [01:20<00:39,  9.39it/s] 65%|██████▌   | 697/1070 [01:20<00:40,  9.25it/s] 65%|██████▌   | 698/1070 [01:20<00:40,  9.26it/s] 65%|██████▌   | 699/1070 [01:20<00:40,  9.27it/s] 65%|██████▌   | 700/1070 [01:21<00:39,  9.31it/s] 66%|██████▌   | 701/1070 [01:21<00:39,  9.23it/s] 66%|██████▌   | 702/1070 [01:21<00:39,  9.20it/s] 66%|██████▌   | 703/1070 [01:21<00:39,  9.36it/s] 66%|██████▌   | 704/1070 [01:21<00:39,  9.21it/s] 66%|██████▌   | 705/1070 [01:21<00:39,  9.25it/s] 66%|██████▌   | 706/1070 [01:21<00:39,  9.33it/s] 66%|██████▌   | 707/1070 [01:21<00:39,  9.27it/s] 66%|██████▌   | 708/1070 [01:21<00:39,  9.18it/s] 66%|██████▋   | 709/1070 [01:22<00:39,  9.17it/s] 66%|██████▋   | 710/1070 [01:22<00:38,  9.30it/s] 66%|██████▋   | 711/1070 [01:22<00:38,  9.24it/s] 67%|██████▋   | 712/1070 [01:22<00:38,  9.26it/s] 67%|██████▋   | 713/1070 [01:22<00:38,  9.39it/s] 67%|██████▋   | 714/1070 [01:22<00:38,  9.31it/s] 67%|██████▋   | 715/1070 [01:22<00:38,  9.15it/s] 67%|██████▋   | 716/1070 [01:22<00:38,  9.18it/s] 67%|██████▋   | 717/1070 [01:22<00:38,  9.17it/s] 67%|██████▋   | 718/1070 [01:22<00:37,  9.29it/s] 67%|██████▋   | 719/1070 [01:23<00:38,  9.22it/s] 67%|██████▋   | 720/1070 [01:23<00:37,  9.40it/s] 67%|██████▋   | 721/1070 [01:23<00:37,  9.30it/s] 67%|██████▋   | 722/1070 [01:23<00:37,  9.24it/s] 68%|██████▊   | 723/1070 [01:23<00:37,  9.23it/s] 68%|██████▊   | 724/1070 [01:23<00:37,  9.25it/s] 68%|██████▊   | 725/1070 [01:23<00:37,  9.26it/s] 68%|██████▊   | 726/1070 [01:23<00:37,  9.15it/s] 68%|██████▊   | 728/1070 [01:24<00:36,  9.33it/s] 68%|██████▊   | 729/1070 [01:24<00:36,  9.27it/s] 68%|██████▊   | 730/1070 [01:24<00:36,  9.31it/s] 68%|██████▊   | 731/1070 [01:24<00:36,  9.28it/s] 68%|██████▊   | 732/1070 [01:24<00:36,  9.30it/s] 69%|██████▊   | 733/1070 [01:24<00:36,  9.24it/s] 69%|██████▊   | 734/1070 [01:24<00:36,  9.31it/s] 69%|██████▊   | 735/1070 [01:24<00:36,  9.29it/s] 69%|██████▉   | 736/1070 [01:24<00:36,  9.20it/s] 69%|██████▉   | 737/1070 [01:25<00:35,  9.32it/s] 69%|██████▉   | 738/1070 [01:25<00:35,  9.33it/s] 69%|██████▉   | 739/1070 [01:25<00:35,  9.34it/s] 69%|██████▉   | 740/1070 [01:25<00:35,  9.22it/s] 69%|██████▉   | 741/1070 [01:25<00:35,  9.39it/s] 69%|██████▉   | 742/1070 [01:25<00:35,  9.32it/s] 69%|██████▉   | 743/1070 [01:25<00:35,  9.22it/s] 70%|██████▉   | 744/1070 [01:25<00:35,  9.26it/s] 70%|██████▉   | 745/1070 [01:25<00:35,  9.22it/s] 70%|██████▉   | 746/1070 [01:26<00:35,  9.19it/s] 70%|██████▉   | 747/1070 [01:26<00:35,  9.08it/s] 70%|██████▉   | 748/1070 [01:26<00:34,  9.30it/s] 70%|███████   | 749/1070 [01:26<00:35,  9.16it/s] 70%|███████   | 750/1070 [01:26<00:34,  9.23it/s] 70%|███████   | 751/1070 [01:26<00:34,  9.27it/s] 70%|███████   | 752/1070 [01:26<00:34,  9.26it/s] 70%|███████   | 753/1070 [01:26<00:34,  9.28it/s] 70%|███████   | 754/1070 [01:26<00:34,  9.15it/s] 71%|███████   | 755/1070 [01:26<00:34,  9.26it/s] 71%|███████   | 756/1070 [01:27<00:33,  9.28it/s] 71%|███████   | 757/1070 [01:27<00:34,  9.20it/s] 71%|███████   | 758/1070 [01:27<00:33,  9.39it/s] 71%|███████   | 759/1070 [01:27<00:33,  9.25it/s] 71%|███████   | 760/1070 [01:27<00:33,  9.31it/s] 71%|███████   | 761/1070 [01:27<00:32,  9.38it/s] 71%|███████   | 762/1070 [01:27<00:32,  9.36it/s] 71%|███████▏  | 763/1070 [01:27<00:32,  9.38it/s] 71%|███████▏  | 764/1070 [01:27<00:32,  9.30it/s] 71%|███████▏  | 765/1070 [01:28<00:32,  9.43it/s] 72%|███████▏  | 766/1070 [01:28<00:32,  9.43it/s] 72%|███████▏  | 767/1070 [01:28<00:32,  9.40it/s] 72%|███████▏  | 768/1070 [01:28<00:31,  9.46it/s] 72%|███████▏  | 769/1070 [01:28<00:32,  9.35it/s] 72%|███████▏  | 770/1070 [01:28<00:32,  9.37it/s] 72%|███████▏  | 771/1070 [01:28<00:31,  9.39it/s] 72%|███████▏  | 772/1070 [01:28<00:31,  9.40it/s] 72%|███████▏  | 773/1070 [01:28<00:31,  9.42it/s] 72%|███████▏  | 774/1070 [01:29<00:31,  9.35it/s] 72%|███████▏  | 775/1070 [01:29<00:31,  9.46it/s] 73%|███████▎  | 776/1070 [01:29<00:31,  9.47it/s] 73%|███████▎  | 777/1070 [01:29<00:30,  9.53it/s] 73%|███████▎  | 778/1070 [01:29<00:30,  9.63it/s] 73%|███████▎  | 779/1070 [01:29<00:30,  9.51it/s] 73%|███████▎  | 780/1070 [01:29<00:30,  9.42it/s] 73%|███████▎  | 781/1070 [01:29<00:30,  9.41it/s] 73%|███████▎  | 782/1070 [01:29<00:30,  9.38it/s] 73%|███████▎  | 783/1070 [01:29<00:30,  9.34it/s] 73%|███████▎  | 784/1070 [01:30<00:30,  9.32it/s] 73%|███████▎  | 785/1070 [01:30<00:30,  9.45it/s] 73%|███████▎  | 786/1070 [01:30<00:30,  9.36it/s] 74%|███████▎  | 787/1070 [01:30<00:30,  9.42it/s] 74%|███████▎  | 788/1070 [01:30<00:29,  9.47it/s] 74%|███████▎  | 789/1070 [01:30<00:29,  9.47it/s] 74%|███████▍  | 790/1070 [01:30<00:29,  9.35it/s] 74%|███████▍  | 791/1070 [01:30<00:29,  9.33it/s] 74%|███████▍  | 792/1070 [01:30<00:29,  9.41it/s] 74%|███████▍  | 793/1070 [01:31<00:29,  9.38it/s] 74%|███████▍  | 794/1070 [01:31<00:29,  9.33it/s] 74%|███████▍  | 795/1070 [01:31<00:28,  9.50it/s] 74%|███████▍  | 796/1070 [01:31<00:29,  9.33it/s] 74%|███████▍  | 797/1070 [01:31<00:29,  9.40it/s] 75%|███████▍  | 798/1070 [01:31<00:28,  9.43it/s] 75%|███████▍  | 799/1070 [01:31<00:28,  9.47it/s] 75%|███████▍  | 800/1070 [01:31<00:28,  9.40it/s] 75%|███████▍  | 801/1070 [01:31<00:28,  9.37it/s] 75%|███████▍  | 802/1070 [01:31<00:28,  9.42it/s] 75%|███████▌  | 803/1070 [01:32<00:28,  9.42it/s] 75%|███████▌  | 804/1070 [01:32<00:28,  9.42it/s] 75%|███████▌  | 805/1070 [01:32<00:27,  9.48it/s] 75%|███████▌  | 806/1070 [01:32<00:28,  9.35it/s] 75%|███████▌  | 807/1070 [01:32<00:28,  9.25it/s] 76%|███████▌  | 808/1070 [01:32<00:28,  9.23it/s] 76%|███████▌  | 809/1070 [01:32<00:28,  9.27it/s] 76%|███████▌  | 810/1070 [01:32<00:28,  9.27it/s] 76%|███████▌  | 811/1070 [01:32<00:28,  9.14it/s] 76%|███████▌  | 813/1070 [01:33<00:27,  9.28it/s] 76%|███████▌  | 814/1070 [01:33<00:27,  9.24it/s] 76%|███████▌  | 815/1070 [01:33<00:27,  9.27it/s] 76%|███████▋  | 816/1070 [01:33<00:27,  9.24it/s] 76%|███████▋  | 817/1070 [01:33<00:27,  9.25it/s] 76%|███████▋  | 818/1070 [01:33<00:27,  9.21it/s] 77%|███████▋  | 819/1070 [01:33<00:26,  9.32it/s] 77%|███████▋  | 820/1070 [01:33<00:26,  9.30it/s] 77%|███████▋  | 821/1070 [01:34<00:26,  9.26it/s] 77%|███████▋  | 822/1070 [01:34<00:26,  9.31it/s] 77%|███████▋  | 823/1070 [01:34<00:26,  9.30it/s] 77%|███████▋  | 824/1070 [01:34<00:26,  9.19it/s] 77%|███████▋  | 825/1070 [01:34<00:26,  9.19it/s] 77%|███████▋  | 826/1070 [01:34<00:26,  9.23it/s] 77%|███████▋  | 827/1070 [01:34<00:26,  9.32it/s] 77%|███████▋  | 828/1070 [01:34<00:26,  9.30it/s] 77%|███████▋  | 829/1070 [01:34<00:25,  9.37it/s] 78%|███████▊  | 830/1070 [01:35<00:25,  9.24it/s] 78%|███████▊  | 831/1070 [01:35<00:25,  9.21it/s] 78%|███████▊  | 832/1070 [01:35<00:25,  9.21it/s] 78%|███████▊  | 833/1070 [01:35<00:25,  9.19it/s] 78%|███████▊  | 834/1070 [01:35<00:25,  9.15it/s] 78%|███████▊  | 835/1070 [01:35<00:25,  9.20it/s] 78%|███████▊  | 836/1070 [01:35<00:25,  9.28it/s] 78%|███████▊  | 837/1070 [01:35<00:25,  9.27it/s] 78%|███████▊  | 838/1070 [01:35<00:25,  9.22it/s] 78%|███████▊  | 839/1070 [01:35<00:24,  9.26it/s] 79%|███████▊  | 840/1070 [01:36<00:24,  9.26it/s] 79%|███████▊  | 841/1070 [01:36<00:24,  9.23it/s] 79%|███████▊  | 842/1070 [01:36<00:24,  9.15it/s] 79%|███████▉  | 843/1070 [01:36<00:24,  9.33it/s] 79%|███████▉  | 844/1070 [01:36<00:24,  9.27it/s] 79%|███████▉  | 845/1070 [01:36<00:24,  9.28it/s] 79%|███████▉  | 846/1070 [01:36<00:24,  9.30it/s] 79%|███████▉  | 847/1070 [01:36<00:24,  9.27it/s] 79%|███████▉  | 848/1070 [01:36<00:24,  9.20it/s] 79%|███████▉  | 849/1070 [01:37<00:24,  9.20it/s] 79%|███████▉  | 850/1070 [01:37<00:23,  9.20it/s] 80%|███████▉  | 851/1070 [01:37<00:23,  9.15it/s] 80%|███████▉  | 852/1070 [01:37<00:23,  9.14it/s] 80%|███████▉  | 853/1070 [01:37<00:23,  9.26it/s] 80%|███████▉  | 854/1070 [01:37<00:23,  9.20it/s] 80%|███████▉  | 855/1070 [01:37<00:23,  9.23it/s]                                                   80%|████████  | 856/1070 [01:37<00:23,  9.23it/s][INFO|trainer.py:755] 2023-11-15 20:45:38,207 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:45:38,208 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:45:38,208 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:45:38,209 >>   Batch size = 8
{'eval_loss': 0.2916134297847748, 'eval_accuracy': 0.9105263157894737, 'eval_micro_f1': 0.9105263157894739, 'eval_macro_f1': 0.907527246243005, 'eval_runtime': 1.3049, 'eval_samples_per_second': 582.431, 'eval_steps_per_second': 72.804, 'epoch': 3.0}
{'loss': 0.0909, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 79.57it/s][A
 18%|█▊        | 17/95 [00:00<00:01, 76.31it/s][A
 26%|██▋       | 25/95 [00:00<00:00, 76.66it/s][A
 35%|███▍      | 33/95 [00:00<00:00, 74.60it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 75.00it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 74.47it/s][A
 60%|██████    | 57/95 [00:00<00:00, 74.85it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 73.36it/s][A
 77%|███████▋  | 73/95 [00:00<00:00, 73.22it/s][A
 85%|████████▌ | 81/95 [00:01<00:00, 73.58it/s][A
 94%|█████████▎| 89/95 [00:01<00:00, 73.85it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:39<00:23,  9.23it/s]
100%|██████████| 95/95 [00:01<00:00, 73.85it/s][A
                                               [A 80%|████████  | 857/1070 [01:39<01:27,  2.43it/s] 80%|████████  | 858/1070 [01:39<01:11,  2.96it/s] 80%|████████  | 859/1070 [01:39<00:58,  3.60it/s] 80%|████████  | 860/1070 [01:39<00:48,  4.30it/s] 80%|████████  | 861/1070 [01:39<00:41,  5.07it/s] 81%|████████  | 862/1070 [01:39<00:35,  5.79it/s] 81%|████████  | 863/1070 [01:39<00:31,  6.52it/s] 81%|████████  | 864/1070 [01:40<00:28,  7.10it/s] 81%|████████  | 865/1070 [01:40<00:26,  7.61it/s] 81%|████████  | 866/1070 [01:40<00:25,  7.98it/s] 81%|████████  | 867/1070 [01:40<00:24,  8.31it/s] 81%|████████  | 868/1070 [01:40<00:23,  8.54it/s] 81%|████████  | 869/1070 [01:40<00:23,  8.73it/s] 81%|████████▏ | 870/1070 [01:40<00:22,  8.82it/s] 81%|████████▏ | 871/1070 [01:40<00:22,  9.04it/s] 81%|████████▏ | 872/1070 [01:40<00:21,  9.00it/s] 82%|████████▏ | 873/1070 [01:40<00:21,  9.12it/s] 82%|████████▏ | 874/1070 [01:41<00:21,  9.06it/s] 82%|████████▏ | 875/1070 [01:41<00:21,  9.12it/s] 82%|████████▏ | 876/1070 [01:41<00:21,  9.04it/s] 82%|████████▏ | 877/1070 [01:41<00:21,  9.01it/s] 82%|████████▏ | 878/1070 [01:41<00:21,  9.07it/s] 82%|████████▏ | 879/1070 [01:41<00:20,  9.12it/s] 82%|████████▏ | 880/1070 [01:41<00:21,  9.03it/s] 82%|████████▏ | 881/1070 [01:41<00:20,  9.23it/s] 82%|████████▏ | 882/1070 [01:41<00:20,  9.15it/s] 83%|████████▎ | 883/1070 [01:42<00:20,  9.14it/s] 83%|████████▎ | 884/1070 [01:42<00:20,  9.12it/s] 83%|████████▎ | 885/1070 [01:42<00:20,  9.14it/s] 83%|████████▎ | 886/1070 [01:42<00:20,  9.14it/s] 83%|████████▎ | 887/1070 [01:42<00:20,  9.08it/s] 83%|████████▎ | 888/1070 [01:42<00:19,  9.16it/s] 83%|████████▎ | 889/1070 [01:42<00:19,  9.12it/s] 83%|████████▎ | 890/1070 [01:42<00:19,  9.17it/s] 83%|████████▎ | 891/1070 [01:42<00:19,  9.26it/s] 83%|████████▎ | 892/1070 [01:43<00:19,  9.18it/s] 83%|████████▎ | 893/1070 [01:43<00:19,  9.21it/s] 84%|████████▎ | 894/1070 [01:43<00:19,  9.19it/s] 84%|████████▎ | 895/1070 [01:43<00:19,  9.19it/s] 84%|████████▎ | 896/1070 [01:43<00:18,  9.20it/s] 84%|████████▍ | 897/1070 [01:43<00:18,  9.24it/s] 84%|████████▍ | 898/1070 [01:43<00:18,  9.17it/s] 84%|████████▍ | 899/1070 [01:43<00:18,  9.25it/s] 84%|████████▍ | 900/1070 [01:43<00:18,  9.21it/s] 84%|████████▍ | 901/1070 [01:44<00:18,  9.23it/s] 84%|████████▍ | 902/1070 [01:44<00:18,  9.17it/s] 84%|████████▍ | 903/1070 [01:44<00:18,  9.16it/s] 84%|████████▍ | 904/1070 [01:44<00:17,  9.29it/s] 85%|████████▍ | 905/1070 [01:44<00:17,  9.23it/s] 85%|████████▍ | 906/1070 [01:44<00:17,  9.16it/s] 85%|████████▍ | 907/1070 [01:44<00:17,  9.18it/s] 85%|████████▍ | 908/1070 [01:44<00:17,  9.22it/s] 85%|████████▍ | 909/1070 [01:44<00:17,  9.20it/s] 85%|████████▌ | 910/1070 [01:45<00:17,  9.12it/s] 85%|████████▌ | 911/1070 [01:45<00:17,  9.10it/s] 85%|████████▌ | 912/1070 [01:45<00:17,  9.10it/s] 85%|████████▌ | 913/1070 [01:45<00:17,  9.11it/s] 85%|████████▌ | 914/1070 [01:45<00:17,  9.17it/s] 86%|████████▌ | 915/1070 [01:45<00:17,  9.05it/s] 86%|████████▌ | 916/1070 [01:45<00:16,  9.07it/s] 86%|████████▌ | 917/1070 [01:45<00:16,  9.07it/s] 86%|████████▌ | 918/1070 [01:45<00:16,  9.09it/s] 86%|████████▌ | 919/1070 [01:46<00:16,  9.06it/s] 86%|████████▌ | 920/1070 [01:46<00:16,  9.06it/s] 86%|████████▌ | 921/1070 [01:46<00:16,  9.03it/s] 86%|████████▌ | 922/1070 [01:46<00:16,  9.05it/s] 86%|████████▋ | 923/1070 [01:46<00:16,  9.08it/s] 86%|████████▋ | 924/1070 [01:46<00:15,  9.21it/s] 86%|████████▋ | 925/1070 [01:46<00:15,  9.20it/s] 87%|████████▋ | 926/1070 [01:46<00:15,  9.15it/s] 87%|████████▋ | 927/1070 [01:46<00:15,  9.08it/s] 87%|████████▋ | 928/1070 [01:47<00:15,  9.10it/s] 87%|████████▋ | 929/1070 [01:47<00:15,  9.09it/s] 87%|████████▋ | 930/1070 [01:47<00:15,  9.05it/s] 87%|████████▋ | 931/1070 [01:47<00:15,  9.16it/s] 87%|████████▋ | 932/1070 [01:47<00:15,  9.16it/s] 87%|████████▋ | 933/1070 [01:47<00:15,  9.05it/s] 87%|████████▋ | 934/1070 [01:47<00:14,  9.10it/s] 87%|████████▋ | 935/1070 [01:47<00:14,  9.03it/s] 87%|████████▋ | 936/1070 [01:47<00:14,  9.04it/s] 88%|████████▊ | 937/1070 [01:48<00:14,  9.04it/s] 88%|████████▊ | 938/1070 [01:48<00:14,  9.00it/s] 88%|████████▊ | 939/1070 [01:48<00:14,  8.96it/s] 88%|████████▊ | 940/1070 [01:48<00:14,  8.90it/s] 88%|████████▊ | 941/1070 [01:48<00:14,  8.98it/s] 88%|████████▊ | 942/1070 [01:48<00:14,  8.98it/s] 88%|████████▊ | 943/1070 [01:48<00:14,  8.99it/s] 88%|████████▊ | 944/1070 [01:48<00:14,  9.00it/s] 88%|████████▊ | 945/1070 [01:48<00:13,  9.00it/s] 88%|████████▊ | 946/1070 [01:49<00:13,  8.99it/s] 89%|████████▊ | 947/1070 [01:49<00:13,  9.00it/s] 89%|████████▊ | 948/1070 [01:49<00:13,  9.07it/s] 89%|████████▊ | 949/1070 [01:49<00:13,  9.08it/s] 89%|████████▉ | 950/1070 [01:49<00:13,  9.05it/s] 89%|████████▉ | 951/1070 [01:49<00:13,  9.11it/s] 89%|████████▉ | 952/1070 [01:49<00:13,  9.07it/s] 89%|████████▉ | 953/1070 [01:49<00:12,  9.06it/s] 89%|████████▉ | 954/1070 [01:49<00:12,  9.03it/s] 89%|████████▉ | 955/1070 [01:50<00:12,  9.05it/s] 89%|████████▉ | 956/1070 [01:50<00:12,  9.05it/s] 89%|████████▉ | 957/1070 [01:50<00:12,  8.98it/s] 90%|████████▉ | 958/1070 [01:50<00:12,  9.05it/s] 90%|████████▉ | 959/1070 [01:50<00:12,  9.05it/s] 90%|████████▉ | 960/1070 [01:50<00:12,  9.04it/s] 90%|████████▉ | 961/1070 [01:50<00:11,  9.12it/s] 90%|████████▉ | 962/1070 [01:50<00:11,  9.07it/s] 90%|█████████ | 963/1070 [01:50<00:11,  8.99it/s] 90%|█████████ | 964/1070 [01:51<00:11,  8.97it/s] 90%|█████████ | 965/1070 [01:51<00:11,  9.00it/s] 90%|█████████ | 966/1070 [01:51<00:11,  9.05it/s] 90%|█████████ | 967/1070 [01:51<00:11,  9.05it/s] 90%|█████████ | 968/1070 [01:51<00:11,  9.08it/s] 91%|█████████ | 969/1070 [01:51<00:11,  9.07it/s] 91%|█████████ | 970/1070 [01:51<00:11,  9.08it/s] 91%|█████████ | 971/1070 [01:51<00:10,  9.10it/s] 91%|█████████ | 972/1070 [01:51<00:10,  8.93it/s] 91%|█████████ | 973/1070 [01:52<00:10,  8.94it/s] 91%|█████████ | 975/1070 [01:52<00:09,  9.56it/s] 91%|█████████▏| 977/1070 [01:52<00:09, 10.02it/s] 91%|█████████▏| 979/1070 [01:52<00:08, 10.36it/s] 92%|█████████▏| 981/1070 [01:52<00:08, 10.20it/s] 92%|█████████▏| 983/1070 [01:52<00:08,  9.79it/s] 92%|█████████▏| 984/1070 [01:53<00:08,  9.65it/s] 92%|█████████▏| 985/1070 [01:53<00:08,  9.61it/s] 92%|█████████▏| 986/1070 [01:53<00:08,  9.53it/s] 92%|█████████▏| 987/1070 [01:53<00:08,  9.52it/s] 92%|█████████▏| 988/1070 [01:53<00:08,  9.39it/s] 92%|█████████▏| 989/1070 [01:53<00:08,  9.33it/s] 93%|█████████▎| 990/1070 [01:53<00:08,  9.27it/s] 93%|█████████▎| 991/1070 [01:53<00:08,  9.22it/s] 93%|█████████▎| 992/1070 [01:53<00:08,  9.14it/s] 93%|█████████▎| 993/1070 [01:54<00:08,  9.13it/s] 93%|█████████▎| 994/1070 [01:54<00:08,  9.16it/s] 93%|█████████▎| 995/1070 [01:54<00:08,  9.15it/s] 93%|█████████▎| 996/1070 [01:54<00:08,  9.22it/s] 93%|█████████▎| 997/1070 [01:54<00:07,  9.13it/s] 93%|█████████▎| 998/1070 [01:54<00:07,  9.04it/s] 93%|█████████▎| 999/1070 [01:54<00:07,  9.06it/s] 93%|█████████▎| 1000/1070 [01:54<00:07,  9.06it/s] 94%|█████████▎| 1001/1070 [01:54<00:07,  9.09it/s] 94%|█████████▎| 1002/1070 [01:55<00:07,  9.16it/s] 94%|█████████▎| 1003/1070 [01:55<00:07,  9.01it/s] 94%|█████████▍| 1004/1070 [01:55<00:07,  9.14it/s] 94%|█████████▍| 1005/1070 [01:55<00:07,  9.06it/s] 94%|█████████▍| 1006/1070 [01:55<00:07,  9.04it/s] 94%|█████████▍| 1007/1070 [01:55<00:06,  9.09it/s] 94%|█████████▍| 1008/1070 [01:55<00:06,  9.06it/s] 94%|█████████▍| 1009/1070 [01:55<00:06,  9.08it/s] 94%|█████████▍| 1010/1070 [01:55<00:06,  9.07it/s] 94%|█████████▍| 1011/1070 [01:56<00:06,  9.11it/s] 95%|█████████▍| 1012/1070 [01:56<00:06,  9.13it/s] 95%|█████████▍| 1013/1070 [01:56<00:06,  9.13it/s] 95%|█████████▍| 1014/1070 [01:56<00:06,  9.13it/s] 95%|█████████▍| 1015/1070 [01:56<00:06,  9.13it/s] 95%|█████████▍| 1016/1070 [01:56<00:05,  9.12it/s] 95%|█████████▌| 1017/1070 [01:56<00:05,  9.11it/s] 95%|█████████▌| 1018/1070 [01:56<00:05,  9.20it/s] 95%|█████████▌| 1019/1070 [01:56<00:05,  9.20it/s] 95%|█████████▌| 1020/1070 [01:57<00:05,  9.19it/s] 95%|█████████▌| 1021/1070 [01:57<00:05,  9.22it/s] 96%|█████████▌| 1022/1070 [01:57<00:05,  9.23it/s] 96%|█████████▌| 1023/1070 [01:57<00:05,  9.23it/s] 96%|█████████▌| 1024/1070 [01:57<00:04,  9.21it/s] 96%|█████████▌| 1025/1070 [01:57<00:04,  9.21it/s] 96%|█████████▌| 1026/1070 [01:57<00:04,  9.13it/s] 96%|█████████▌| 1027/1070 [01:57<00:04,  9.13it/s] 96%|█████████▌| 1028/1070 [01:57<00:04,  9.22it/s] 96%|█████████▌| 1029/1070 [01:58<00:04,  9.20it/s] 96%|█████████▋| 1030/1070 [01:58<00:04,  9.07it/s] 96%|█████████▋| 1031/1070 [01:58<00:04,  9.00it/s] 96%|█████████▋| 1032/1070 [01:58<00:04,  9.03it/s] 97%|█████████▋| 1033/1070 [01:58<00:04,  9.01it/s] 97%|█████████▋| 1034/1070 [01:58<00:03,  9.01it/s] 97%|█████████▋| 1035/1070 [01:58<00:03,  9.14it/s] 97%|█████████▋| 1036/1070 [01:58<00:03,  9.15it/s] 97%|█████████▋| 1037/1070 [01:58<00:03,  9.21it/s] 97%|█████████▋| 1038/1070 [01:59<00:03,  9.13it/s] 97%|█████████▋| 1039/1070 [01:59<00:03,  9.15it/s] 97%|█████████▋| 1040/1070 [01:59<00:03,  9.12it/s] 97%|█████████▋| 1041/1070 [01:59<00:03,  9.12it/s] 97%|█████████▋| 1042/1070 [01:59<00:03,  9.21it/s] 97%|█████████▋| 1043/1070 [01:59<00:02,  9.17it/s] 98%|█████████▊| 1044/1070 [01:59<00:02,  9.11it/s] 98%|█████████▊| 1045/1070 [01:59<00:02,  9.04it/s] 98%|█████████▊| 1046/1070 [01:59<00:02,  9.08it/s] 98%|█████████▊| 1047/1070 [01:59<00:02,  9.12it/s] 98%|█████████▊| 1048/1070 [02:00<00:02,  9.05it/s] 98%|█████████▊| 1049/1070 [02:00<00:02,  9.12it/s] 98%|█████████▊| 1050/1070 [02:00<00:02,  9.13it/s] 98%|█████████▊| 1051/1070 [02:00<00:02,  9.04it/s] 98%|█████████▊| 1052/1070 [02:00<00:01,  9.09it/s] 98%|█████████▊| 1053/1070 [02:00<00:01,  9.09it/s] 99%|█████████▊| 1054/1070 [02:00<00:01,  9.09it/s] 99%|█████████▊| 1055/1070 [02:00<00:01,  9.11it/s] 99%|█████████▊| 1056/1070 [02:00<00:01,  9.04it/s] 99%|█████████▉| 1057/1070 [02:01<00:01,  9.09it/s] 99%|█████████▉| 1058/1070 [02:01<00:01,  9.08it/s] 99%|█████████▉| 1059/1070 [02:01<00:01,  9.19it/s] 99%|█████████▉| 1060/1070 [02:01<00:01,  9.12it/s] 99%|█████████▉| 1061/1070 [02:01<00:00,  9.16it/s] 99%|█████████▉| 1062/1070 [02:01<00:00,  9.10it/s] 99%|█████████▉| 1063/1070 [02:01<00:00,  9.07it/s] 99%|█████████▉| 1064/1070 [02:01<00:00,  9.07it/s]100%|█████████▉| 1065/1070 [02:01<00:00,  9.12it/s]100%|█████████▉| 1066/1070 [02:02<00:00,  9.19it/s]100%|█████████▉| 1067/1070 [02:02<00:00,  9.16it/s]100%|█████████▉| 1068/1070 [02:02<00:00,  9.02it/s]100%|█████████▉| 1069/1070 [02:02<00:00,  9.02it/s]                                                   100%|██████████| 1070/1070 [02:02<00:00,  9.02it/s][INFO|trainer.py:755] 2023-11-15 20:46:02,902 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:46:02,904 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:46:02,904 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:46:02,904 >>   Batch size = 8
{'eval_loss': 0.3397299647331238, 'eval_accuracy': 0.9052631578947369, 'eval_micro_f1': 0.9052631578947369, 'eval_macro_f1': 0.903130002503775, 'eval_runtime': 1.3245, 'eval_samples_per_second': 573.788, 'eval_steps_per_second': 71.724, 'epoch': 4.0}
{'loss': 0.0573, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 83.76it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 75.01it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 75.50it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 75.14it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 74.65it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 75.48it/s][A
 61%|██████    | 58/95 [00:00<00:00, 74.36it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 74.13it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 73.61it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 74.49it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 73.05it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:03<00:00,  9.02it/s]
100%|██████████| 95/95 [00:01<00:00, 73.05it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 20:46:04,233 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:03<00:00,  9.02it/s]100%|██████████| 1070/1070 [02:03<00:00,  8.64it/s]
[INFO|trainer.py:2855] 2023-11-15 20:46:04,236 >> Saving model checkpoint to ./result/agnews_sup_bert-base-cased_adapter__seed2
[INFO|configuration_utils.py:460] 2023-11-15 20:46:04,238 >> Configuration saved in ./result/agnews_sup_bert-base-cased_adapter__seed2/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:46:05,250 >> Model weights saved in ./result/agnews_sup_bert-base-cased_adapter__seed2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:46:05,253 >> tokenizer config file saved in ./result/agnews_sup_bert-base-cased_adapter__seed2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:46:05,255 >> Special tokens file saved in ./result/agnews_sup_bert-base-cased_adapter__seed2/special_tokens_map.json
{'eval_loss': 0.3651319146156311, 'eval_accuracy': 0.9052631578947369, 'eval_micro_f1': 0.9052631578947369, 'eval_macro_f1': 0.902950687816465, 'eval_runtime': 1.3254, 'eval_samples_per_second': 573.426, 'eval_steps_per_second': 71.678, 'epoch': 5.0}
{'train_runtime': 123.8458, 'train_samples_per_second': 276.15, 'train_steps_per_second': 8.64, 'train_loss': 0.21118346241032965, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2112
  train_runtime            = 0:02:03.84
  train_samples            =       6840
  train_samples_per_second =     276.15
  train_steps_per_second   =       8.64
11/15/2023 20:46:05 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:46:05,295 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:46:05,296 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:46:05,296 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:46:05,297 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  9%|▉         | 9/95 [00:00<00:01, 80.49it/s] 19%|█▉        | 18/95 [00:00<00:01, 74.65it/s] 27%|██▋       | 26/95 [00:00<00:00, 74.03it/s] 36%|███▌      | 34/95 [00:00<00:00, 71.86it/s] 44%|████▍     | 42/95 [00:00<00:00, 73.03it/s] 53%|█████▎    | 50/95 [00:00<00:00, 73.30it/s] 61%|██████    | 58/95 [00:00<00:00, 72.77it/s] 69%|██████▉   | 66/95 [00:00<00:00, 73.05it/s] 78%|███████▊  | 74/95 [00:01<00:00, 72.55it/s] 86%|████████▋ | 82/95 [00:01<00:00, 71.80it/s] 95%|█████████▍| 90/95 [00:01<00:00, 72.78it/s]100%|██████████| 95/95 [00:01<00:00, 71.77it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9053
  eval_loss               =     0.3651
  eval_macro_f1           =      0.903
  eval_micro_f1           =     0.9053
  eval_runtime            = 0:00:01.34
  eval_samples            =        760
  eval_samples_per_second =    566.987
  eval_steps_per_second   =     70.873
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▆█▅▅▅
wandb:                      eval/loss ▃▁▁▆██
wandb:                  eval/macro_f1 ▁▆█▆▆▆
wandb:                  eval/micro_f1 ▁▆█▅▅▅
wandb:                   eval/runtime ▁▄▃▆▆█
wandb:        eval/samples_per_second █▄▆▃▃▁
wandb:          eval/steps_per_second █▄▆▃▃▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▂▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.90526
wandb:                      eval/loss 0.36513
wandb:                  eval/macro_f1 0.90295
wandb:                  eval/micro_f1 0.90526
wandb:                   eval/runtime 1.3404
wandb:        eval/samples_per_second 566.987
wandb:          eval/steps_per_second 70.873
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0573
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.21118
wandb:            train/train_runtime 123.8458
wandb: train/train_samples_per_second 276.15
wandb:   train/train_steps_per_second 8.64
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_204313-ps7tu6ob
wandb: Find logs at: ./wandb/offline-run-20231115_204313-ps7tu6ob/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2/runs/Nov15_20-46-17_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:46:17 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:46:17 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2/runs/Nov15_20-46-16_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=333,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 20:46:32,650 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:46:32,661 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:46:42,677 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:46:52,695 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:46:52,696 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:47:12,733 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:47:12,734 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:47:12,734 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:47:12,734 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:47:12,734 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:47:12,736 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:47:12,736 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 20:47:12,760 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:47:12,761 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:47:32,894 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 20:47:34,360 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:47:34,361 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  44%|████▍     | 3000/6840 [00:00<00:00, 21577.52 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 22119.87 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 21888.40 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 24411.45 examples/s]
11/15/2023 20:47:34 - INFO - __main__ - Sample 4545 of the training set: {'text': "Yankees' Brown Has Successful Surgery Kevin Brown had successful surgery on his broken left hand Sunday and vowed to pitch again for the Yankees this season.", 'label': 0, 'input_ids': [102, 14288, 23970, 30113, 2505, 6378, 434, 3026, 2797, 15720, 107, 6378, 883, 3026, 2797, 191, 1972, 12265, 2101, 1500, 21444, 240, 137, 14775, 119, 147, 10673, 1573, 168, 111, 14288, 23970, 30113, 238, 7843, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:47:34 - INFO - __main__ - Sample 2873 of the training set: {'text': 'Bush shields shrimp industry The Bush administration yesterday said Chinese and Vietnamese shrimp are sold at unfairly low prices in the United States, siding with US fishermen as they try to fend off overseas competition.', 'label': 1, 'input_ids': [102, 26384, 13705, 30113, 27277, 4569, 111, 26384, 3762, 7870, 192, 3113, 6032, 6123, 137, 24982, 11556, 27277, 220, 17922, 235, 11490, 3132, 179, 629, 6759, 121, 111, 4274, 1898, 422, 17092, 140, 190, 227, 8534, 4393, 188, 698, 8475, 147, 19234, 30118, 1874, 573, 28300, 6543, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:47:34 - INFO - __main__ - Sample 2892 of the training set: {'text': 'How the credit policy will affect you The Reserve Bank of India announced the mid-term review of its monetary policy on Tuesday. Though the central Bank kept away from the much expected interest rate hike, the policy contained recommendations ', 'label': 1, 'input_ids': [102, 539, 111, 8388, 2951, 650, 2606, 3034, 111, 12287, 5108, 131, 6666, 25964, 111, 2589, 579, 902, 1579, 131, 633, 13029, 2951, 191, 6355, 123, 3113, 205, 2461, 111, 2435, 5108, 6890, 6257, 263, 111, 1839, 2182, 1291, 1013, 5305, 1359, 422, 111, 2951, 4482, 6869, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:47:34 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:47:36,190 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:47:36,198 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:47:36,199 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 20:47:36,199 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:47:36,199 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:47:36,199 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:47:36,200 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:47:36,200 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 20:47:36,201 >>   Number of trainable parameters = 109,921,540
[INFO|integration_utils.py:716] 2023-11-15 20:47:36,201 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<26:01,  1.46s/it]  0%|          | 2/1070 [00:01<11:51,  1.50it/s]  0%|          | 3/1070 [00:01<07:20,  2.42it/s]  0%|          | 4/1070 [00:01<05:11,  3.42it/s]  0%|          | 5/1070 [00:01<04:00,  4.43it/s]  1%|          | 6/1070 [00:02<03:18,  5.37it/s]  1%|          | 7/1070 [00:02<02:50,  6.23it/s]  1%|          | 8/1070 [00:02<02:33,  6.94it/s]  1%|          | 9/1070 [00:02<02:21,  7.51it/s]  1%|          | 10/1070 [00:02<02:13,  7.91it/s]  1%|          | 11/1070 [00:02<02:06,  8.38it/s]  1%|          | 12/1070 [00:02<02:03,  8.57it/s]  1%|          | 13/1070 [00:02<02:00,  8.77it/s]  1%|▏         | 14/1070 [00:02<01:58,  8.90it/s]  1%|▏         | 15/1070 [00:02<01:57,  8.94it/s]  1%|▏         | 16/1070 [00:03<01:57,  8.99it/s]  2%|▏         | 17/1070 [00:03<01:58,  8.92it/s]  2%|▏         | 18/1070 [00:03<01:56,  9.01it/s]  2%|▏         | 19/1070 [00:03<01:55,  9.08it/s]  2%|▏         | 20/1070 [00:03<01:55,  9.12it/s]  2%|▏         | 21/1070 [00:03<01:53,  9.24it/s]  2%|▏         | 22/1070 [00:03<01:54,  9.17it/s]  2%|▏         | 23/1070 [00:03<01:55,  9.08it/s]  2%|▏         | 24/1070 [00:03<01:55,  9.09it/s]  2%|▏         | 25/1070 [00:04<01:54,  9.10it/s]  2%|▏         | 26/1070 [00:04<01:54,  9.08it/s]  3%|▎         | 27/1070 [00:04<01:54,  9.15it/s]  3%|▎         | 28/1070 [00:04<01:52,  9.23it/s]  3%|▎         | 29/1070 [00:04<01:52,  9.23it/s]  3%|▎         | 30/1070 [00:04<01:52,  9.21it/s]  3%|▎         | 31/1070 [00:04<01:52,  9.22it/s]  3%|▎         | 32/1070 [00:04<01:52,  9.21it/s]  3%|▎         | 33/1070 [00:04<01:52,  9.20it/s]  3%|▎         | 34/1070 [00:05<01:53,  9.16it/s]  3%|▎         | 35/1070 [00:05<01:51,  9.27it/s]  3%|▎         | 36/1070 [00:05<01:52,  9.18it/s]  3%|▎         | 37/1070 [00:05<01:52,  9.20it/s]  4%|▎         | 38/1070 [00:05<01:52,  9.18it/s]  4%|▎         | 39/1070 [00:05<01:52,  9.20it/s]  4%|▎         | 40/1070 [00:05<01:52,  9.17it/s]  4%|▍         | 41/1070 [00:05<01:53,  9.03it/s]  4%|▍         | 42/1070 [00:05<01:53,  9.04it/s]  4%|▍         | 43/1070 [00:06<01:53,  9.04it/s]  4%|▍         | 44/1070 [00:06<01:53,  9.04it/s]  4%|▍         | 45/1070 [00:06<01:51,  9.16it/s]  4%|▍         | 46/1070 [00:06<01:52,  9.10it/s]  4%|▍         | 47/1070 [00:06<01:52,  9.10it/s]  4%|▍         | 48/1070 [00:06<01:52,  9.08it/s]  5%|▍         | 49/1070 [00:06<01:51,  9.13it/s]  5%|▍         | 50/1070 [00:06<01:52,  9.10it/s]  5%|▍         | 51/1070 [00:06<01:51,  9.10it/s]  5%|▍         | 52/1070 [00:07<01:50,  9.23it/s]  5%|▍         | 53/1070 [00:07<01:50,  9.22it/s]  5%|▌         | 54/1070 [00:07<01:50,  9.20it/s]  5%|▌         | 55/1070 [00:07<01:49,  9.26it/s]  5%|▌         | 56/1070 [00:07<01:49,  9.24it/s]  5%|▌         | 57/1070 [00:07<01:51,  9.11it/s]  5%|▌         | 58/1070 [00:07<01:50,  9.16it/s]  6%|▌         | 59/1070 [00:07<01:50,  9.16it/s]  6%|▌         | 60/1070 [00:07<01:49,  9.21it/s]  6%|▌         | 61/1070 [00:08<01:48,  9.28it/s]  6%|▌         | 62/1070 [00:08<01:48,  9.27it/s]  6%|▌         | 63/1070 [00:08<01:49,  9.17it/s]  6%|▌         | 64/1070 [00:08<01:49,  9.16it/s]  6%|▌         | 65/1070 [00:08<01:50,  9.14it/s]  6%|▌         | 66/1070 [00:08<01:49,  9.19it/s]  6%|▋         | 67/1070 [00:08<01:48,  9.23it/s]  6%|▋         | 68/1070 [00:08<01:48,  9.27it/s]  6%|▋         | 69/1070 [00:08<01:46,  9.40it/s]  7%|▋         | 70/1070 [00:08<01:47,  9.33it/s]  7%|▋         | 71/1070 [00:09<01:47,  9.31it/s]  7%|▋         | 72/1070 [00:09<01:47,  9.26it/s]  7%|▋         | 73/1070 [00:09<01:47,  9.24it/s]  7%|▋         | 74/1070 [00:09<01:46,  9.32it/s]  7%|▋         | 75/1070 [00:09<01:46,  9.33it/s]  7%|▋         | 76/1070 [00:09<01:45,  9.42it/s]  7%|▋         | 77/1070 [00:09<01:46,  9.33it/s]  7%|▋         | 78/1070 [00:09<01:46,  9.33it/s]  7%|▋         | 79/1070 [00:09<01:46,  9.30it/s]  7%|▋         | 80/1070 [00:10<01:46,  9.32it/s]  8%|▊         | 81/1070 [00:10<01:45,  9.34it/s]  8%|▊         | 82/1070 [00:10<01:46,  9.27it/s]  8%|▊         | 83/1070 [00:10<01:45,  9.38it/s]  8%|▊         | 84/1070 [00:10<01:45,  9.36it/s]  8%|▊         | 85/1070 [00:10<01:45,  9.35it/s]  8%|▊         | 86/1070 [00:10<01:44,  9.37it/s]  8%|▊         | 87/1070 [00:10<01:45,  9.34it/s]  8%|▊         | 88/1070 [00:10<01:46,  9.26it/s]  8%|▊         | 89/1070 [00:11<01:46,  9.18it/s]  8%|▊         | 90/1070 [00:11<01:46,  9.22it/s]  9%|▊         | 91/1070 [00:11<01:46,  9.18it/s]  9%|▊         | 92/1070 [00:11<01:46,  9.18it/s]  9%|▊         | 93/1070 [00:11<01:45,  9.30it/s]  9%|▉         | 94/1070 [00:11<01:45,  9.25it/s]  9%|▉         | 95/1070 [00:11<01:46,  9.17it/s]  9%|▉         | 96/1070 [00:11<01:46,  9.16it/s]  9%|▉         | 97/1070 [00:11<01:46,  9.17it/s]  9%|▉         | 98/1070 [00:12<01:45,  9.17it/s]  9%|▉         | 99/1070 [00:12<01:46,  9.14it/s]  9%|▉         | 100/1070 [00:12<01:44,  9.28it/s]  9%|▉         | 101/1070 [00:12<01:45,  9.21it/s] 10%|▉         | 102/1070 [00:12<01:46,  9.07it/s] 10%|▉         | 103/1070 [00:12<01:46,  9.08it/s] 10%|▉         | 104/1070 [00:12<01:45,  9.12it/s] 10%|▉         | 105/1070 [00:12<01:45,  9.12it/s] 10%|▉         | 106/1070 [00:12<01:45,  9.16it/s] 10%|█         | 107/1070 [00:12<01:43,  9.29it/s] 10%|█         | 108/1070 [00:13<01:44,  9.22it/s] 10%|█         | 109/1070 [00:13<01:45,  9.10it/s] 10%|█         | 110/1070 [00:13<01:46,  9.04it/s] 10%|█         | 111/1070 [00:13<01:45,  9.13it/s] 10%|█         | 112/1070 [00:13<01:45,  9.10it/s] 11%|█         | 113/1070 [00:13<01:44,  9.16it/s] 11%|█         | 114/1070 [00:13<01:43,  9.28it/s] 11%|█         | 115/1070 [00:13<01:43,  9.18it/s] 11%|█         | 116/1070 [00:13<01:44,  9.17it/s] 11%|█         | 117/1070 [00:14<01:44,  9.12it/s] 11%|█         | 118/1070 [00:14<01:43,  9.16it/s] 11%|█         | 119/1070 [00:14<01:43,  9.16it/s] 11%|█         | 120/1070 [00:14<01:43,  9.16it/s] 11%|█▏        | 121/1070 [00:14<01:42,  9.29it/s] 11%|█▏        | 122/1070 [00:14<01:42,  9.21it/s] 11%|█▏        | 123/1070 [00:14<01:43,  9.14it/s] 12%|█▏        | 124/1070 [00:14<01:43,  9.12it/s] 12%|█▏        | 125/1070 [00:14<01:43,  9.12it/s] 12%|█▏        | 126/1070 [00:15<01:43,  9.08it/s] 12%|█▏        | 127/1070 [00:15<01:43,  9.12it/s] 12%|█▏        | 128/1070 [00:15<01:43,  9.14it/s] 12%|█▏        | 129/1070 [00:15<01:43,  9.13it/s] 12%|█▏        | 130/1070 [00:15<01:42,  9.16it/s] 12%|█▏        | 131/1070 [00:15<01:43,  9.07it/s] 12%|█▏        | 132/1070 [00:15<01:43,  9.07it/s] 12%|█▏        | 133/1070 [00:15<01:42,  9.11it/s] 13%|█▎        | 134/1070 [00:15<01:42,  9.17it/s] 13%|█▎        | 135/1070 [00:16<01:41,  9.18it/s] 13%|█▎        | 136/1070 [00:16<01:42,  9.15it/s] 13%|█▎        | 137/1070 [00:16<01:42,  9.11it/s] 13%|█▎        | 138/1070 [00:16<01:43,  9.04it/s] 13%|█▎        | 139/1070 [00:16<01:42,  9.05it/s] 13%|█▎        | 140/1070 [00:16<01:42,  9.07it/s] 13%|█▎        | 141/1070 [00:16<01:42,  9.06it/s] 13%|█▎        | 142/1070 [00:16<01:41,  9.18it/s] 13%|█▎        | 143/1070 [00:16<01:42,  9.04it/s] 13%|█▎        | 144/1070 [00:17<01:42,  9.02it/s] 14%|█▎        | 145/1070 [00:17<01:42,  8.99it/s] 14%|█▎        | 146/1070 [00:17<01:42,  9.03it/s] 14%|█▎        | 147/1070 [00:17<01:41,  9.06it/s] 14%|█▍        | 148/1070 [00:17<01:41,  9.05it/s] 14%|█▍        | 149/1070 [00:17<01:41,  9.07it/s] 14%|█▍        | 150/1070 [00:17<01:42,  9.02it/s] 14%|█▍        | 151/1070 [00:17<01:43,  8.92it/s] 14%|█▍        | 152/1070 [00:17<01:42,  8.96it/s] 14%|█▍        | 153/1070 [00:18<01:41,  9.00it/s] 14%|█▍        | 154/1070 [00:18<01:41,  9.01it/s] 14%|█▍        | 155/1070 [00:18<01:41,  8.97it/s] 15%|█▍        | 156/1070 [00:18<01:40,  9.09it/s] 15%|█▍        | 157/1070 [00:18<01:40,  9.05it/s] 15%|█▍        | 158/1070 [00:18<01:40,  9.06it/s] 15%|█▍        | 159/1070 [00:18<01:39,  9.12it/s] 15%|█▍        | 160/1070 [00:18<01:38,  9.19it/s] 15%|█▌        | 161/1070 [00:18<01:38,  9.23it/s] 15%|█▌        | 162/1070 [00:19<01:38,  9.19it/s] 15%|█▌        | 163/1070 [00:19<01:38,  9.24it/s] 15%|█▌        | 164/1070 [00:19<01:38,  9.24it/s] 15%|█▌        | 165/1070 [00:19<01:38,  9.22it/s] 16%|█▌        | 166/1070 [00:19<01:36,  9.36it/s] 16%|█▌        | 167/1070 [00:19<01:37,  9.31it/s] 16%|█▌        | 168/1070 [00:19<01:37,  9.21it/s] 16%|█▌        | 169/1070 [00:19<01:38,  9.15it/s] 16%|█▌        | 170/1070 [00:19<01:37,  9.22it/s] 16%|█▌        | 171/1070 [00:19<01:37,  9.18it/s] 16%|█▌        | 172/1070 [00:20<01:37,  9.18it/s] 16%|█▌        | 173/1070 [00:20<01:37,  9.23it/s] 16%|█▋        | 174/1070 [00:20<01:36,  9.24it/s] 16%|█▋        | 175/1070 [00:20<01:37,  9.20it/s] 16%|█▋        | 176/1070 [00:20<01:37,  9.21it/s] 17%|█▋        | 177/1070 [00:20<01:36,  9.23it/s] 17%|█▋        | 178/1070 [00:20<01:36,  9.23it/s] 17%|█▋        | 179/1070 [00:20<01:36,  9.21it/s] 17%|█▋        | 180/1070 [00:20<01:36,  9.25it/s] 17%|█▋        | 181/1070 [00:21<01:36,  9.21it/s] 17%|█▋        | 182/1070 [00:21<01:36,  9.16it/s] 17%|█▋        | 183/1070 [00:21<01:35,  9.28it/s] 17%|█▋        | 184/1070 [00:21<01:35,  9.25it/s] 17%|█▋        | 185/1070 [00:21<01:36,  9.18it/s] 17%|█▋        | 186/1070 [00:21<01:36,  9.13it/s] 17%|█▋        | 187/1070 [00:21<01:37,  9.07it/s] 18%|█▊        | 188/1070 [00:21<01:36,  9.13it/s] 18%|█▊        | 189/1070 [00:21<01:35,  9.19it/s] 18%|█▊        | 190/1070 [00:22<01:34,  9.34it/s] 18%|█▊        | 191/1070 [00:22<01:35,  9.21it/s] 18%|█▊        | 192/1070 [00:22<01:35,  9.15it/s] 18%|█▊        | 193/1070 [00:22<01:35,  9.17it/s] 18%|█▊        | 194/1070 [00:22<01:35,  9.17it/s] 18%|█▊        | 195/1070 [00:22<01:35,  9.16it/s] 18%|█▊        | 196/1070 [00:22<01:36,  9.08it/s] 18%|█▊        | 197/1070 [00:22<01:35,  9.10it/s] 19%|█▊        | 198/1070 [00:22<01:36,  9.07it/s] 19%|█▊        | 199/1070 [00:23<01:35,  9.14it/s] 19%|█▊        | 200/1070 [00:23<01:34,  9.18it/s] 19%|█▉        | 201/1070 [00:23<01:34,  9.17it/s] 19%|█▉        | 202/1070 [00:23<01:34,  9.15it/s] 19%|█▉        | 203/1070 [00:23<01:34,  9.13it/s] 19%|█▉        | 204/1070 [00:23<01:35,  9.11it/s] 19%|█▉        | 205/1070 [00:23<01:34,  9.12it/s] 19%|█▉        | 206/1070 [00:23<01:34,  9.10it/s] 19%|█▉        | 207/1070 [00:23<01:33,  9.23it/s] 19%|█▉        | 208/1070 [00:24<01:33,  9.18it/s] 20%|█▉        | 209/1070 [00:24<01:33,  9.19it/s] 20%|█▉        | 210/1070 [00:24<01:34,  9.11it/s] 20%|█▉        | 211/1070 [00:24<01:33,  9.17it/s] 20%|█▉        | 212/1070 [00:24<01:33,  9.15it/s] 20%|█▉        | 213/1070 [00:24<01:33,  9.18it/s]                                                   20%|██        | 214/1070 [00:24<01:33,  9.18it/s][INFO|trainer.py:755] 2023-11-15 20:48:00,871 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:48:00,873 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:48:00,873 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:48:00,874 >>   Batch size = 8
{'loss': 0.5035, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 84.32it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 75.87it/s][A
 31%|███       | 29/95 [00:00<00:00, 89.56it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 98.00it/s][A
 56%|█████▌    | 53/95 [00:00<00:00, 102.44it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 105.20it/s][A
 81%|████████  | 77/95 [00:00<00:00, 106.89it/s][A
 94%|█████████▎| 89/95 [00:00<00:00, 108.12it/s][A                                                  
                                                [A 20%|██        | 214/1070 [00:25<01:33,  9.18it/s]
100%|██████████| 95/95 [00:00<00:00, 108.12it/s][A
                                                [A 20%|██        | 215/1070 [00:25<04:39,  3.06it/s] 20%|██        | 216/1070 [00:25<03:52,  3.67it/s] 20%|██        | 217/1070 [00:25<03:16,  4.34it/s] 20%|██        | 218/1070 [00:26<02:47,  5.08it/s] 20%|██        | 219/1070 [00:26<02:26,  5.83it/s] 21%|██        | 220/1070 [00:26<02:10,  6.53it/s] 21%|██        | 221/1070 [00:26<01:58,  7.14it/s] 21%|██        | 222/1070 [00:26<01:49,  7.76it/s] 21%|██        | 223/1070 [00:26<01:44,  8.08it/s] 21%|██        | 224/1070 [00:26<01:40,  8.38it/s] 21%|██        | 225/1070 [00:26<01:38,  8.56it/s] 21%|██        | 226/1070 [00:26<01:35,  8.81it/s] 21%|██        | 227/1070 [00:27<01:34,  8.96it/s] 21%|██▏       | 228/1070 [00:27<01:33,  8.99it/s] 21%|██▏       | 229/1070 [00:27<01:31,  9.18it/s] 21%|██▏       | 230/1070 [00:27<01:31,  9.20it/s] 22%|██▏       | 231/1070 [00:27<01:31,  9.14it/s] 22%|██▏       | 232/1070 [00:27<01:31,  9.13it/s] 22%|██▏       | 234/1070 [00:27<01:30,  9.26it/s] 22%|██▏       | 235/1070 [00:27<01:30,  9.26it/s] 22%|██▏       | 236/1070 [00:27<01:29,  9.34it/s] 22%|██▏       | 237/1070 [00:28<01:29,  9.33it/s] 22%|██▏       | 238/1070 [00:28<01:29,  9.31it/s] 22%|██▏       | 239/1070 [00:28<01:29,  9.29it/s] 23%|██▎       | 241/1070 [00:28<01:27,  9.44it/s] 23%|██▎       | 242/1070 [00:28<01:28,  9.36it/s] 23%|██▎       | 243/1070 [00:28<01:28,  9.36it/s] 23%|██▎       | 244/1070 [00:28<01:28,  9.33it/s] 23%|██▎       | 245/1070 [00:28<01:28,  9.33it/s] 23%|██▎       | 246/1070 [00:29<01:28,  9.34it/s] 23%|██▎       | 247/1070 [00:29<01:26,  9.50it/s] 23%|██▎       | 248/1070 [00:29<01:27,  9.38it/s] 23%|██▎       | 249/1070 [00:29<01:28,  9.25it/s] 23%|██▎       | 250/1070 [00:29<01:28,  9.25it/s] 23%|██▎       | 251/1070 [00:29<01:26,  9.42it/s] 24%|██▎       | 252/1070 [00:29<01:27,  9.37it/s] 24%|██▎       | 253/1070 [00:29<01:27,  9.34it/s] 24%|██▎       | 254/1070 [00:29<01:26,  9.43it/s] 24%|██▍       | 255/1070 [00:30<01:26,  9.42it/s] 24%|██▍       | 256/1070 [00:30<01:27,  9.32it/s] 24%|██▍       | 257/1070 [00:30<01:28,  9.23it/s] 24%|██▍       | 258/1070 [00:30<01:26,  9.35it/s] 24%|██▍       | 259/1070 [00:30<01:27,  9.27it/s] 24%|██▍       | 260/1070 [00:30<01:27,  9.25it/s] 24%|██▍       | 261/1070 [00:30<01:26,  9.37it/s] 24%|██▍       | 262/1070 [00:30<01:26,  9.33it/s] 25%|██▍       | 263/1070 [00:30<01:26,  9.35it/s] 25%|██▍       | 264/1070 [00:30<01:26,  9.27it/s] 25%|██▍       | 266/1070 [00:31<01:26,  9.34it/s] 25%|██▍       | 267/1070 [00:31<01:26,  9.29it/s] 25%|██▌       | 268/1070 [00:31<01:26,  9.30it/s] 25%|██▌       | 269/1070 [00:31<01:26,  9.26it/s] 25%|██▌       | 270/1070 [00:31<01:26,  9.23it/s] 25%|██▌       | 271/1070 [00:31<01:27,  9.16it/s] 26%|██▌       | 273/1070 [00:31<01:25,  9.30it/s] 26%|██▌       | 274/1070 [00:32<01:26,  9.20it/s] 26%|██▌       | 275/1070 [00:32<01:26,  9.22it/s] 26%|██▌       | 276/1070 [00:32<01:26,  9.22it/s] 26%|██▌       | 277/1070 [00:32<01:25,  9.23it/s] 26%|██▌       | 278/1070 [00:32<01:25,  9.25it/s] 26%|██▌       | 279/1070 [00:32<01:24,  9.38it/s] 26%|██▌       | 280/1070 [00:32<01:25,  9.26it/s] 26%|██▋       | 281/1070 [00:32<01:25,  9.21it/s] 26%|██▋       | 282/1070 [00:32<01:26,  9.08it/s] 26%|██▋       | 283/1070 [00:33<01:25,  9.18it/s] 27%|██▋       | 284/1070 [00:33<01:25,  9.15it/s] 27%|██▋       | 285/1070 [00:33<01:25,  9.16it/s] 27%|██▋       | 286/1070 [00:33<01:24,  9.28it/s] 27%|██▋       | 287/1070 [00:33<01:24,  9.21it/s] 27%|██▋       | 288/1070 [00:33<01:25,  9.12it/s] 27%|██▋       | 289/1070 [00:33<01:26,  9.04it/s] 27%|██▋       | 290/1070 [00:33<01:24,  9.20it/s] 27%|██▋       | 291/1070 [00:33<01:25,  9.08it/s] 27%|██▋       | 292/1070 [00:34<01:26,  9.05it/s] 27%|██▋       | 293/1070 [00:34<01:24,  9.17it/s] 27%|██▋       | 294/1070 [00:34<01:25,  9.12it/s] 28%|██▊       | 295/1070 [00:34<01:25,  9.07it/s] 28%|██▊       | 296/1070 [00:34<01:25,  9.08it/s] 28%|██▊       | 297/1070 [00:34<01:22,  9.32it/s] 28%|██▊       | 298/1070 [00:34<01:24,  9.16it/s] 28%|██▊       | 299/1070 [00:34<01:24,  9.10it/s] 28%|██▊       | 300/1070 [00:34<01:24,  9.12it/s] 28%|██▊       | 301/1070 [00:35<01:24,  9.15it/s] 28%|██▊       | 302/1070 [00:35<01:24,  9.12it/s] 28%|██▊       | 303/1070 [00:35<01:23,  9.15it/s] 28%|██▊       | 304/1070 [00:35<01:21,  9.36it/s] 29%|██▊       | 305/1070 [00:35<01:22,  9.29it/s] 29%|██▊       | 306/1070 [00:35<01:23,  9.18it/s] 29%|██▊       | 307/1070 [00:35<01:23,  9.18it/s] 29%|██▉       | 308/1070 [00:35<01:21,  9.37it/s] 29%|██▉       | 309/1070 [00:35<01:22,  9.23it/s] 29%|██▉       | 310/1070 [00:35<01:22,  9.22it/s] 29%|██▉       | 311/1070 [00:36<01:21,  9.35it/s] 29%|██▉       | 312/1070 [00:36<01:21,  9.25it/s] 29%|██▉       | 313/1070 [00:36<01:21,  9.24it/s] 29%|██▉       | 314/1070 [00:36<01:21,  9.24it/s] 29%|██▉       | 315/1070 [00:36<01:21,  9.29it/s] 30%|██▉       | 316/1070 [00:36<01:21,  9.27it/s] 30%|██▉       | 317/1070 [00:36<01:21,  9.20it/s] 30%|██▉       | 319/1070 [00:36<01:15,  9.99it/s] 30%|███       | 321/1070 [00:37<01:11, 10.42it/s] 30%|███       | 323/1070 [00:37<01:10, 10.67it/s] 30%|███       | 325/1070 [00:37<01:09, 10.65it/s] 31%|███       | 327/1070 [00:37<01:13, 10.09it/s] 31%|███       | 329/1070 [00:37<01:15,  9.86it/s] 31%|███       | 330/1070 [00:38<01:16,  9.69it/s] 31%|███       | 331/1070 [00:38<01:16,  9.60it/s] 31%|███       | 332/1070 [00:38<01:17,  9.56it/s] 31%|███       | 333/1070 [00:38<01:18,  9.43it/s] 31%|███       | 334/1070 [00:38<01:18,  9.38it/s] 31%|███▏      | 335/1070 [00:38<01:19,  9.28it/s] 31%|███▏      | 336/1070 [00:38<01:17,  9.47it/s] 31%|███▏      | 337/1070 [00:38<01:18,  9.34it/s] 32%|███▏      | 338/1070 [00:38<01:19,  9.17it/s] 32%|███▏      | 339/1070 [00:39<01:19,  9.15it/s] 32%|███▏      | 340/1070 [00:39<01:18,  9.28it/s] 32%|███▏      | 341/1070 [00:39<01:18,  9.31it/s] 32%|███▏      | 342/1070 [00:39<01:18,  9.23it/s] 32%|███▏      | 343/1070 [00:39<01:17,  9.33it/s] 32%|███▏      | 344/1070 [00:39<01:18,  9.26it/s] 32%|███▏      | 345/1070 [00:39<01:18,  9.27it/s] 32%|███▏      | 346/1070 [00:39<01:18,  9.20it/s] 32%|███▏      | 347/1070 [00:39<01:17,  9.39it/s] 33%|███▎      | 348/1070 [00:39<01:18,  9.24it/s] 33%|███▎      | 349/1070 [00:40<01:18,  9.19it/s] 33%|███▎      | 350/1070 [00:40<01:18,  9.18it/s] 33%|███▎      | 351/1070 [00:40<01:17,  9.27it/s] 33%|███▎      | 352/1070 [00:40<01:17,  9.23it/s] 33%|███▎      | 353/1070 [00:40<01:18,  9.19it/s] 33%|███▎      | 354/1070 [00:40<01:16,  9.30it/s] 33%|███▎      | 355/1070 [00:40<01:17,  9.26it/s] 33%|███▎      | 356/1070 [00:40<01:17,  9.16it/s] 33%|███▎      | 357/1070 [00:40<01:17,  9.20it/s] 33%|███▎      | 358/1070 [00:41<01:15,  9.40it/s] 34%|███▎      | 359/1070 [00:41<01:16,  9.28it/s] 34%|███▎      | 360/1070 [00:41<01:17,  9.22it/s] 34%|███▎      | 361/1070 [00:41<01:17,  9.18it/s] 34%|███▍      | 362/1070 [00:41<01:17,  9.19it/s] 34%|███▍      | 363/1070 [00:41<01:16,  9.27it/s] 34%|███▍      | 364/1070 [00:41<01:16,  9.23it/s] 34%|███▍      | 365/1070 [00:41<01:15,  9.31it/s] 34%|███▍      | 366/1070 [00:41<01:15,  9.27it/s] 34%|███▍      | 367/1070 [00:42<01:16,  9.21it/s] 34%|███▍      | 368/1070 [00:42<01:16,  9.22it/s] 34%|███▍      | 369/1070 [00:42<01:14,  9.42it/s] 35%|███▍      | 370/1070 [00:42<01:15,  9.23it/s] 35%|███▍      | 371/1070 [00:42<01:16,  9.18it/s] 35%|███▍      | 372/1070 [00:42<01:16,  9.15it/s] 35%|███▍      | 373/1070 [00:42<01:15,  9.26it/s] 35%|███▍      | 374/1070 [00:42<01:15,  9.18it/s] 35%|███▌      | 375/1070 [00:42<01:15,  9.16it/s] 35%|███▌      | 376/1070 [00:43<01:15,  9.23it/s] 35%|███▌      | 377/1070 [00:43<01:15,  9.12it/s] 35%|███▌      | 378/1070 [00:43<01:15,  9.14it/s] 35%|███▌      | 379/1070 [00:43<01:16,  9.04it/s] 36%|███▌      | 380/1070 [00:43<01:14,  9.22it/s] 36%|███▌      | 381/1070 [00:43<01:16,  9.06it/s] 36%|███▌      | 382/1070 [00:43<01:15,  9.09it/s] 36%|███▌      | 383/1070 [00:43<01:16,  9.01it/s] 36%|███▌      | 384/1070 [00:43<01:15,  9.04it/s] 36%|███▌      | 385/1070 [00:43<01:15,  9.13it/s] 36%|███▌      | 386/1070 [00:44<01:15,  9.11it/s] 36%|███▌      | 387/1070 [00:44<01:14,  9.14it/s] 36%|███▋      | 388/1070 [00:44<01:14,  9.14it/s] 36%|███▋      | 389/1070 [00:44<01:15,  9.05it/s] 36%|███▋      | 390/1070 [00:44<01:15,  8.99it/s] 37%|███▋      | 391/1070 [00:44<01:14,  9.12it/s] 37%|███▋      | 392/1070 [00:44<01:14,  9.08it/s] 37%|███▋      | 393/1070 [00:44<01:14,  9.07it/s] 37%|███▋      | 394/1070 [00:44<01:14,  9.09it/s] 37%|███▋      | 395/1070 [00:45<01:13,  9.15it/s] 37%|███▋      | 396/1070 [00:45<01:12,  9.24it/s] 37%|███▋      | 397/1070 [00:45<01:14,  9.08it/s] 37%|███▋      | 398/1070 [00:45<01:13,  9.20it/s] 37%|███▋      | 399/1070 [00:45<01:13,  9.19it/s] 37%|███▋      | 400/1070 [00:45<01:13,  9.10it/s] 37%|███▋      | 401/1070 [00:45<01:14,  9.03it/s] 38%|███▊      | 402/1070 [00:45<01:12,  9.27it/s] 38%|███▊      | 403/1070 [00:45<01:13,  9.12it/s] 38%|███▊      | 404/1070 [00:46<01:12,  9.13it/s] 38%|███▊      | 405/1070 [00:46<01:13,  9.06it/s] 38%|███▊      | 406/1070 [00:46<01:12,  9.16it/s] 38%|███▊      | 407/1070 [00:46<01:12,  9.10it/s] 38%|███▊      | 408/1070 [00:46<01:12,  9.11it/s] 38%|███▊      | 409/1070 [00:46<01:11,  9.21it/s] 38%|███▊      | 410/1070 [00:46<01:11,  9.19it/s] 38%|███▊      | 411/1070 [00:46<01:12,  9.10it/s] 39%|███▊      | 412/1070 [00:46<01:11,  9.15it/s] 39%|███▊      | 413/1070 [00:47<01:10,  9.32it/s] 39%|███▊      | 414/1070 [00:47<01:11,  9.16it/s] 39%|███▉      | 415/1070 [00:47<01:11,  9.17it/s] 39%|███▉      | 416/1070 [00:47<01:11,  9.17it/s] 39%|███▉      | 417/1070 [00:47<01:10,  9.21it/s] 39%|███▉      | 418/1070 [00:47<01:10,  9.19it/s] 39%|███▉      | 419/1070 [00:47<01:11,  9.15it/s] 39%|███▉      | 420/1070 [00:47<01:09,  9.30it/s] 39%|███▉      | 421/1070 [00:47<01:10,  9.21it/s] 39%|███▉      | 422/1070 [00:48<01:10,  9.16it/s] 40%|███▉      | 423/1070 [00:48<01:10,  9.13it/s] 40%|███▉      | 424/1070 [00:48<01:10,  9.21it/s] 40%|███▉      | 425/1070 [00:48<01:10,  9.18it/s] 40%|███▉      | 426/1070 [00:48<01:10,  9.10it/s] 40%|███▉      | 427/1070 [00:48<01:10,  9.14it/s]                                                   40%|████      | 428/1070 [00:48<01:10,  9.14it/s][INFO|trainer.py:755] 2023-11-15 20:48:24,893 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:48:24,895 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:48:24,895 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:48:24,895 >>   Batch size = 8
{'eval_loss': 0.3398067355155945, 'eval_accuracy': 0.8868421052631579, 'eval_micro_f1': 0.886842105263158, 'eval_macro_f1': 0.8839535066708237, 'eval_runtime': 0.9786, 'eval_samples_per_second': 776.642, 'eval_steps_per_second': 97.08, 'epoch': 1.0}
{'loss': 0.2661, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 79.27it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 73.80it/s][A
 26%|██▋       | 25/95 [00:00<00:00, 75.66it/s][A
 35%|███▍      | 33/95 [00:00<00:00, 73.84it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 71.72it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 73.45it/s][A
 60%|██████    | 57/95 [00:00<00:00, 72.03it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 70.21it/s][A
 77%|███████▋  | 73/95 [00:01<00:00, 69.97it/s][A
 85%|████████▌ | 81/95 [00:01<00:00, 72.32it/s][A
 94%|█████████▎| 89/95 [00:01<00:00, 71.07it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:50<01:10,  9.14it/s]
100%|██████████| 95/95 [00:01<00:00, 71.07it/s][A
                                               [A 40%|████      | 429/1070 [00:50<04:31,  2.36it/s] 40%|████      | 430/1070 [00:50<03:42,  2.88it/s] 40%|████      | 431/1070 [00:50<03:02,  3.50it/s] 40%|████      | 432/1070 [00:50<02:32,  4.19it/s] 40%|████      | 433/1070 [00:50<02:08,  4.97it/s] 41%|████      | 434/1070 [00:50<01:52,  5.66it/s] 41%|████      | 435/1070 [00:50<01:39,  6.37it/s] 41%|████      | 436/1070 [00:50<01:30,  7.04it/s] 41%|████      | 437/1070 [00:51<01:24,  7.50it/s] 41%|████      | 438/1070 [00:51<01:20,  7.84it/s] 41%|████      | 439/1070 [00:51<01:17,  8.10it/s] 41%|████      | 440/1070 [00:51<01:14,  8.44it/s] 41%|████      | 441/1070 [00:51<01:13,  8.60it/s] 41%|████▏     | 442/1070 [00:51<01:12,  8.70it/s] 41%|████▏     | 443/1070 [00:51<01:10,  8.88it/s] 41%|████▏     | 444/1070 [00:51<01:09,  8.95it/s] 42%|████▏     | 445/1070 [00:51<01:10,  8.92it/s] 42%|████▏     | 446/1070 [00:52<01:09,  9.02it/s] 42%|████▏     | 447/1070 [00:52<01:08,  9.15it/s] 42%|████▏     | 448/1070 [00:52<01:08,  9.09it/s] 42%|████▏     | 449/1070 [00:52<01:08,  9.07it/s] 42%|████▏     | 450/1070 [00:52<01:08,  9.06it/s] 42%|████▏     | 451/1070 [00:52<01:08,  9.10it/s] 42%|████▏     | 452/1070 [00:52<01:08,  9.03it/s] 42%|████▏     | 453/1070 [00:52<01:08,  9.01it/s] 42%|████▏     | 454/1070 [00:52<01:06,  9.21it/s] 43%|████▎     | 455/1070 [00:53<01:07,  9.12it/s] 43%|████▎     | 456/1070 [00:53<01:07,  9.09it/s] 43%|████▎     | 457/1070 [00:53<01:07,  9.15it/s] 43%|████▎     | 458/1070 [00:53<01:06,  9.16it/s] 43%|████▎     | 459/1070 [00:53<01:06,  9.20it/s] 43%|████▎     | 460/1070 [00:53<01:06,  9.16it/s] 43%|████▎     | 461/1070 [00:53<01:06,  9.21it/s] 43%|████▎     | 462/1070 [00:53<01:05,  9.22it/s] 43%|████▎     | 463/1070 [00:53<01:06,  9.08it/s] 43%|████▎     | 464/1070 [00:54<01:07,  9.02it/s] 43%|████▎     | 465/1070 [00:54<01:06,  9.16it/s] 44%|████▎     | 466/1070 [00:54<01:06,  9.09it/s] 44%|████▎     | 467/1070 [00:54<01:06,  9.10it/s] 44%|████▎     | 468/1070 [00:54<01:06,  9.05it/s] 44%|████▍     | 469/1070 [00:54<01:06,  9.07it/s] 44%|████▍     | 470/1070 [00:54<01:06,  9.07it/s] 44%|████▍     | 471/1070 [00:54<01:06,  9.03it/s] 44%|████▍     | 472/1070 [00:54<01:05,  9.17it/s] 44%|████▍     | 473/1070 [00:55<01:05,  9.05it/s] 44%|████▍     | 474/1070 [00:55<01:06,  8.98it/s] 44%|████▍     | 475/1070 [00:55<01:06,  9.01it/s] 44%|████▍     | 476/1070 [00:55<01:05,  9.11it/s] 45%|████▍     | 477/1070 [00:55<01:05,  9.08it/s] 45%|████▍     | 478/1070 [00:55<01:05,  9.10it/s] 45%|████▍     | 479/1070 [00:55<01:04,  9.13it/s] 45%|████▍     | 480/1070 [00:55<01:04,  9.09it/s] 45%|████▍     | 481/1070 [00:55<01:04,  9.12it/s] 45%|████▌     | 482/1070 [00:56<01:04,  9.05it/s] 45%|████▌     | 483/1070 [00:56<01:03,  9.25it/s] 45%|████▌     | 484/1070 [00:56<01:04,  9.06it/s] 45%|████▌     | 485/1070 [00:56<01:04,  9.05it/s] 45%|████▌     | 486/1070 [00:56<01:04,  9.11it/s] 46%|████▌     | 487/1070 [00:56<01:03,  9.12it/s] 46%|████▌     | 488/1070 [00:56<01:04,  9.09it/s] 46%|████▌     | 489/1070 [00:56<01:04,  8.97it/s] 46%|████▌     | 490/1070 [00:56<01:03,  9.08it/s] 46%|████▌     | 491/1070 [00:57<01:04,  8.98it/s] 46%|████▌     | 492/1070 [00:57<01:04,  8.97it/s] 46%|████▌     | 493/1070 [00:57<01:04,  8.96it/s] 46%|████▌     | 494/1070 [00:57<01:03,  9.07it/s] 46%|████▋     | 495/1070 [00:57<01:03,  9.00it/s] 46%|████▋     | 496/1070 [00:57<01:03,  8.99it/s] 46%|████▋     | 497/1070 [00:57<01:04,  8.95it/s] 47%|████▋     | 498/1070 [00:57<01:03,  8.99it/s] 47%|████▋     | 499/1070 [00:57<01:03,  9.04it/s] 47%|████▋     | 500/1070 [00:58<01:03,  9.00it/s] 47%|████▋     | 501/1070 [00:58<01:02,  9.09it/s] 47%|████▋     | 502/1070 [00:58<01:03,  9.01it/s] 47%|████▋     | 503/1070 [00:58<01:03,  8.97it/s] 47%|████▋     | 504/1070 [00:58<01:03,  8.87it/s] 47%|████▋     | 505/1070 [00:58<01:03,  8.95it/s] 47%|████▋     | 506/1070 [00:58<01:03,  8.88it/s] 47%|████▋     | 507/1070 [00:58<01:03,  8.88it/s] 47%|████▋     | 508/1070 [00:58<01:03,  8.91it/s] 48%|████▊     | 509/1070 [00:59<01:03,  8.90it/s] 48%|████▊     | 510/1070 [00:59<01:03,  8.81it/s] 48%|████▊     | 511/1070 [00:59<01:03,  8.85it/s] 48%|████▊     | 512/1070 [00:59<01:01,  9.04it/s] 48%|████▊     | 513/1070 [00:59<01:02,  8.93it/s] 48%|████▊     | 514/1070 [00:59<01:02,  8.88it/s] 48%|████▊     | 515/1070 [00:59<01:02,  8.85it/s] 48%|████▊     | 516/1070 [00:59<01:02,  8.92it/s] 48%|████▊     | 517/1070 [00:59<01:02,  8.90it/s] 48%|████▊     | 518/1070 [01:00<01:01,  8.96it/s] 49%|████▊     | 519/1070 [01:00<01:01,  8.99it/s] 49%|████▊     | 520/1070 [01:00<01:01,  8.98it/s] 49%|████▊     | 521/1070 [01:00<01:01,  8.96it/s] 49%|████▉     | 522/1070 [01:00<01:01,  8.98it/s] 49%|████▉     | 523/1070 [01:00<00:59,  9.16it/s] 49%|████▉     | 524/1070 [01:00<01:00,  9.08it/s] 49%|████▉     | 525/1070 [01:00<01:00,  8.96it/s] 49%|████▉     | 526/1070 [01:00<01:00,  8.95it/s] 49%|████▉     | 527/1070 [01:01<01:00,  8.95it/s] 49%|████▉     | 528/1070 [01:01<01:00,  8.95it/s] 49%|████▉     | 529/1070 [01:01<01:00,  8.96it/s] 50%|████▉     | 530/1070 [01:01<01:00,  8.99it/s] 50%|████▉     | 531/1070 [01:01<01:00,  8.97it/s] 50%|████▉     | 532/1070 [01:01<01:00,  8.94it/s] 50%|████▉     | 533/1070 [01:01<01:00,  8.95it/s] 50%|████▉     | 534/1070 [01:01<00:58,  9.11it/s] 50%|█████     | 535/1070 [01:01<00:59,  8.96it/s] 50%|█████     | 536/1070 [01:02<00:59,  8.92it/s] 50%|█████     | 537/1070 [01:02<00:59,  8.99it/s] 50%|█████     | 538/1070 [01:02<00:59,  9.01it/s] 50%|█████     | 539/1070 [01:02<00:58,  9.06it/s] 50%|█████     | 540/1070 [01:02<00:58,  9.06it/s] 51%|█████     | 541/1070 [01:02<00:57,  9.21it/s] 51%|█████     | 542/1070 [01:02<00:57,  9.12it/s] 51%|█████     | 543/1070 [01:02<00:58,  9.06it/s] 51%|█████     | 544/1070 [01:02<00:57,  9.09it/s] 51%|█████     | 545/1070 [01:03<00:57,  9.06it/s] 51%|█████     | 546/1070 [01:03<00:57,  9.04it/s] 51%|█████     | 547/1070 [01:03<00:57,  9.02it/s] 51%|█████     | 548/1070 [01:03<00:57,  9.08it/s] 51%|█████▏    | 549/1070 [01:03<00:57,  9.09it/s] 51%|█████▏    | 550/1070 [01:03<00:57,  8.98it/s] 51%|█████▏    | 551/1070 [01:03<00:58,  8.94it/s] 52%|█████▏    | 552/1070 [01:03<00:57,  9.05it/s] 52%|█████▏    | 553/1070 [01:03<00:57,  9.05it/s] 52%|█████▏    | 554/1070 [01:04<00:56,  9.12it/s] 52%|█████▏    | 555/1070 [01:04<00:56,  9.11it/s] 52%|█████▏    | 556/1070 [01:04<00:56,  9.10it/s] 52%|█████▏    | 557/1070 [01:04<00:56,  9.08it/s] 52%|█████▏    | 558/1070 [01:04<00:56,  9.01it/s] 52%|█████▏    | 559/1070 [01:04<00:56,  9.09it/s] 52%|█████▏    | 560/1070 [01:04<00:56,  9.08it/s] 52%|█████▏    | 561/1070 [01:04<00:56,  9.08it/s] 53%|█████▎    | 562/1070 [01:04<00:55,  9.14it/s] 53%|█████▎    | 563/1070 [01:04<00:55,  9.14it/s] 53%|█████▎    | 564/1070 [01:05<00:55,  9.10it/s] 53%|█████▎    | 565/1070 [01:05<00:55,  9.11it/s] 53%|█████▎    | 566/1070 [01:05<00:53,  9.35it/s] 53%|█████▎    | 567/1070 [01:05<00:54,  9.17it/s] 53%|█████▎    | 568/1070 [01:05<00:54,  9.21it/s] 53%|█████▎    | 569/1070 [01:05<00:54,  9.16it/s] 53%|█████▎    | 570/1070 [01:05<00:54,  9.17it/s] 53%|█████▎    | 571/1070 [01:05<00:54,  9.19it/s] 53%|█████▎    | 572/1070 [01:05<00:55,  9.05it/s] 54%|█████▎    | 573/1070 [01:06<00:53,  9.25it/s] 54%|█████▎    | 574/1070 [01:06<00:54,  9.09it/s] 54%|█████▎    | 575/1070 [01:06<00:54,  9.07it/s] 54%|█████▍    | 576/1070 [01:06<00:54,  9.13it/s] 54%|█████▍    | 577/1070 [01:06<00:53,  9.16it/s] 54%|█████▍    | 578/1070 [01:06<00:53,  9.18it/s] 54%|█████▍    | 579/1070 [01:06<00:53,  9.10it/s] 54%|█████▍    | 580/1070 [01:06<00:52,  9.30it/s] 54%|█████▍    | 581/1070 [01:06<00:53,  9.20it/s] 54%|█████▍    | 582/1070 [01:07<00:53,  9.12it/s] 54%|█████▍    | 583/1070 [01:07<00:53,  9.14it/s] 55%|█████▍    | 584/1070 [01:07<00:53,  9.10it/s] 55%|█████▍    | 585/1070 [01:07<00:53,  9.03it/s] 55%|█████▍    | 586/1070 [01:07<00:53,  9.09it/s] 55%|█████▍    | 587/1070 [01:07<00:52,  9.19it/s] 55%|█████▍    | 588/1070 [01:07<00:52,  9.19it/s] 55%|█████▌    | 589/1070 [01:07<00:52,  9.22it/s] 55%|█████▌    | 590/1070 [01:07<00:52,  9.22it/s] 55%|█████▌    | 591/1070 [01:08<00:51,  9.24it/s] 55%|█████▌    | 592/1070 [01:08<00:52,  9.11it/s] 55%|█████▌    | 593/1070 [01:08<00:52,  9.10it/s] 56%|█████▌    | 594/1070 [01:08<00:51,  9.18it/s] 56%|█████▌    | 595/1070 [01:08<00:51,  9.24it/s] 56%|█████▌    | 596/1070 [01:08<00:51,  9.18it/s] 56%|█████▌    | 597/1070 [01:08<00:50,  9.37it/s] 56%|█████▌    | 598/1070 [01:08<00:51,  9.23it/s] 56%|█████▌    | 599/1070 [01:08<00:51,  9.14it/s] 56%|█████▌    | 600/1070 [01:09<00:51,  9.16it/s] 56%|█████▌    | 601/1070 [01:09<00:51,  9.14it/s] 56%|█████▋    | 602/1070 [01:09<00:50,  9.22it/s] 56%|█████▋    | 603/1070 [01:09<00:50,  9.21it/s] 56%|█████▋    | 604/1070 [01:09<00:50,  9.32it/s] 57%|█████▋    | 605/1070 [01:09<00:50,  9.23it/s] 57%|█████▋    | 606/1070 [01:09<00:50,  9.23it/s] 57%|█████▋    | 607/1070 [01:09<00:49,  9.30it/s] 57%|█████▋    | 608/1070 [01:09<00:49,  9.33it/s] 57%|█████▋    | 609/1070 [01:09<00:49,  9.28it/s] 57%|█████▋    | 610/1070 [01:10<00:49,  9.21it/s] 57%|█████▋    | 611/1070 [01:10<00:49,  9.25it/s] 57%|█████▋    | 612/1070 [01:10<00:49,  9.18it/s] 57%|█████▋    | 613/1070 [01:10<00:50,  9.13it/s] 57%|█████▋    | 614/1070 [01:10<00:49,  9.27it/s] 57%|█████▋    | 615/1070 [01:10<00:49,  9.18it/s] 58%|█████▊    | 616/1070 [01:10<00:49,  9.08it/s] 58%|█████▊    | 617/1070 [01:10<00:49,  9.12it/s] 58%|█████▊    | 618/1070 [01:10<00:49,  9.16it/s] 58%|█████▊    | 619/1070 [01:11<00:49,  9.19it/s] 58%|█████▊    | 620/1070 [01:11<00:49,  9.15it/s] 58%|█████▊    | 622/1070 [01:11<00:48,  9.32it/s] 58%|█████▊    | 623/1070 [01:11<00:48,  9.24it/s] 58%|█████▊    | 624/1070 [01:11<00:48,  9.22it/s] 58%|█████▊    | 625/1070 [01:11<00:48,  9.22it/s] 59%|█████▊    | 626/1070 [01:11<00:48,  9.20it/s] 59%|█████▊    | 627/1070 [01:11<00:48,  9.14it/s] 59%|█████▊    | 628/1070 [01:12<00:47,  9.28it/s] 59%|█████▉    | 629/1070 [01:12<00:47,  9.21it/s] 59%|█████▉    | 630/1070 [01:12<00:47,  9.20it/s] 59%|█████▉    | 631/1070 [01:12<00:47,  9.21it/s] 59%|█████▉    | 632/1070 [01:12<00:47,  9.16it/s] 59%|█████▉    | 633/1070 [01:12<00:47,  9.17it/s] 59%|█████▉    | 634/1070 [01:12<00:47,  9.11it/s] 59%|█████▉    | 635/1070 [01:12<00:47,  9.25it/s] 59%|█████▉    | 636/1070 [01:12<00:47,  9.16it/s] 60%|█████▉    | 637/1070 [01:13<00:47,  9.20it/s] 60%|█████▉    | 638/1070 [01:13<00:46,  9.25it/s] 60%|█████▉    | 639/1070 [01:13<00:46,  9.22it/s] 60%|█████▉    | 640/1070 [01:13<00:46,  9.19it/s] 60%|█████▉    | 641/1070 [01:13<00:47,  9.11it/s]                                                   60%|██████    | 642/1070 [01:13<00:46,  9.11it/s][INFO|trainer.py:755] 2023-11-15 20:48:49,778 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:48:49,780 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:48:49,780 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:48:49,780 >>   Batch size = 8
{'eval_loss': 0.2963477373123169, 'eval_accuracy': 0.9078947368421053, 'eval_micro_f1': 0.9078947368421053, 'eval_macro_f1': 0.9049344714075592, 'eval_runtime': 1.3721, 'eval_samples_per_second': 553.891, 'eval_steps_per_second': 69.236, 'epoch': 2.0}
{'loss': 0.1635, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 79.38it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 75.40it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 74.85it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 74.42it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 73.30it/s][A
 51%|█████     | 48/95 [00:00<00:00, 71.54it/s][A
 60%|██████    | 57/95 [00:00<00:00, 74.27it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 72.65it/s][A
 77%|███████▋  | 73/95 [00:00<00:00, 72.42it/s][A
 85%|████████▌ | 81/95 [00:01<00:00, 72.79it/s][A
 94%|█████████▎| 89/95 [00:01<00:00, 72.97it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:14<00:46,  9.11it/s]
100%|██████████| 95/95 [00:01<00:00, 72.97it/s][A
                                               [A 60%|██████    | 643/1070 [01:15<02:57,  2.40it/s] 60%|██████    | 644/1070 [01:15<02:24,  2.95it/s] 60%|██████    | 645/1070 [01:15<01:58,  3.57it/s] 60%|██████    | 646/1070 [01:15<01:39,  4.26it/s] 60%|██████    | 647/1070 [01:15<01:24,  5.03it/s] 61%|██████    | 648/1070 [01:15<01:13,  5.77it/s] 61%|██████    | 649/1070 [01:15<01:05,  6.47it/s] 61%|██████    | 650/1070 [01:15<00:59,  7.04it/s] 61%|██████    | 651/1070 [01:15<00:55,  7.54it/s] 61%|██████    | 652/1070 [01:16<00:52,  7.92it/s] 61%|██████    | 653/1070 [01:16<00:50,  8.19it/s] 61%|██████    | 654/1070 [01:16<00:49,  8.43it/s] 61%|██████    | 655/1070 [01:16<00:47,  8.81it/s] 61%|██████▏   | 656/1070 [01:16<00:46,  8.81it/s] 61%|██████▏   | 657/1070 [01:16<00:46,  8.92it/s] 61%|██████▏   | 658/1070 [01:16<00:45,  8.99it/s] 62%|██████▏   | 659/1070 [01:16<00:46,  8.93it/s] 62%|██████▏   | 660/1070 [01:16<00:45,  9.02it/s] 62%|██████▏   | 661/1070 [01:17<00:45,  9.04it/s] 62%|██████▏   | 662/1070 [01:17<00:45,  8.95it/s] 62%|██████▏   | 663/1070 [01:17<00:45,  8.94it/s] 62%|██████▏   | 664/1070 [01:17<00:46,  8.66it/s] 62%|██████▏   | 665/1070 [01:17<00:46,  8.72it/s] 62%|██████▏   | 666/1070 [01:17<00:46,  8.78it/s] 62%|██████▏   | 667/1070 [01:17<00:46,  8.73it/s] 62%|██████▏   | 668/1070 [01:17<00:45,  8.79it/s] 63%|██████▎   | 669/1070 [01:17<00:45,  8.81it/s] 63%|██████▎   | 670/1070 [01:18<00:44,  8.93it/s] 63%|██████▎   | 671/1070 [01:18<00:44,  8.88it/s] 63%|██████▎   | 672/1070 [01:18<00:44,  8.91it/s] 63%|██████▎   | 673/1070 [01:18<00:44,  8.97it/s] 63%|██████▎   | 674/1070 [01:18<00:43,  9.02it/s] 63%|██████▎   | 675/1070 [01:18<00:43,  9.10it/s] 63%|██████▎   | 676/1070 [01:18<00:43,  9.06it/s] 63%|██████▎   | 677/1070 [01:18<00:43,  9.06it/s] 63%|██████▎   | 678/1070 [01:18<00:43,  9.06it/s] 63%|██████▎   | 679/1070 [01:19<00:43,  9.07it/s] 64%|██████▎   | 680/1070 [01:19<00:42,  9.12it/s] 64%|██████▎   | 681/1070 [01:19<00:41,  9.32it/s] 64%|██████▎   | 682/1070 [01:19<00:42,  9.22it/s] 64%|██████▍   | 683/1070 [01:19<00:42,  9.09it/s] 64%|██████▍   | 684/1070 [01:19<00:42,  9.11it/s] 64%|██████▍   | 685/1070 [01:19<00:42,  9.14it/s] 64%|██████▍   | 686/1070 [01:19<00:42,  9.13it/s] 64%|██████▍   | 687/1070 [01:19<00:42,  9.08it/s] 64%|██████▍   | 688/1070 [01:20<00:41,  9.10it/s] 64%|██████▍   | 689/1070 [01:20<00:41,  9.11it/s] 64%|██████▍   | 690/1070 [01:20<00:42,  9.02it/s] 65%|██████▍   | 691/1070 [01:20<00:41,  9.04it/s] 65%|██████▍   | 692/1070 [01:20<00:41,  9.12it/s] 65%|██████▍   | 693/1070 [01:20<00:41,  9.10it/s] 65%|██████▍   | 694/1070 [01:20<00:41,  9.10it/s] 65%|██████▍   | 695/1070 [01:20<00:40,  9.20it/s] 65%|██████▌   | 696/1070 [01:20<00:40,  9.22it/s] 65%|██████▌   | 697/1070 [01:20<00:40,  9.30it/s] 65%|██████▌   | 698/1070 [01:21<00:40,  9.21it/s] 65%|██████▌   | 699/1070 [01:21<00:39,  9.41it/s] 65%|██████▌   | 700/1070 [01:21<00:40,  9.23it/s] 66%|██████▌   | 701/1070 [01:21<00:40,  9.21it/s] 66%|██████▌   | 702/1070 [01:21<00:40,  9.20it/s] 66%|██████▌   | 703/1070 [01:21<00:39,  9.24it/s] 66%|██████▌   | 704/1070 [01:21<00:39,  9.24it/s] 66%|██████▌   | 705/1070 [01:21<00:39,  9.14it/s] 66%|██████▌   | 706/1070 [01:21<00:38,  9.35it/s] 66%|██████▌   | 707/1070 [01:22<00:39,  9.24it/s] 66%|██████▌   | 708/1070 [01:22<00:39,  9.23it/s] 66%|██████▋   | 709/1070 [01:22<00:39,  9.17it/s] 66%|██████▋   | 710/1070 [01:22<00:39,  9.21it/s] 66%|██████▋   | 711/1070 [01:22<00:38,  9.22it/s] 67%|██████▋   | 712/1070 [01:22<00:39,  9.13it/s] 67%|██████▋   | 713/1070 [01:22<00:38,  9.35it/s] 67%|██████▋   | 714/1070 [01:22<00:38,  9.21it/s] 67%|██████▋   | 715/1070 [01:22<00:38,  9.17it/s] 67%|██████▋   | 716/1070 [01:23<00:38,  9.16it/s] 67%|██████▋   | 717/1070 [01:23<00:37,  9.35it/s] 67%|██████▋   | 718/1070 [01:23<00:37,  9.29it/s] 67%|██████▋   | 719/1070 [01:23<00:38,  9.18it/s] 67%|██████▋   | 720/1070 [01:23<00:37,  9.33it/s] 67%|██████▋   | 722/1070 [01:23<00:34, 10.03it/s] 68%|██████▊   | 724/1070 [01:23<00:33, 10.39it/s] 68%|██████▊   | 726/1070 [01:24<00:32, 10.60it/s] 68%|██████▊   | 728/1070 [01:24<00:31, 10.71it/s] 68%|██████▊   | 730/1070 [01:24<00:33, 10.26it/s] 68%|██████▊   | 732/1070 [01:24<00:33,  9.98it/s] 69%|██████▊   | 733/1070 [01:24<00:34,  9.81it/s] 69%|██████▊   | 734/1070 [01:24<00:34,  9.67it/s] 69%|██████▊   | 735/1070 [01:24<00:34,  9.59it/s] 69%|██████▉   | 736/1070 [01:25<00:35,  9.52it/s] 69%|██████▉   | 737/1070 [01:25<00:35,  9.51it/s] 69%|██████▉   | 738/1070 [01:25<00:35,  9.34it/s] 69%|██████▉   | 739/1070 [01:25<00:34,  9.46it/s] 69%|██████▉   | 740/1070 [01:25<00:35,  9.33it/s] 69%|██████▉   | 741/1070 [01:25<00:35,  9.33it/s] 69%|██████▉   | 742/1070 [01:25<00:34,  9.40it/s] 69%|██████▉   | 743/1070 [01:25<00:34,  9.39it/s] 70%|██████▉   | 744/1070 [01:25<00:34,  9.38it/s] 70%|██████▉   | 745/1070 [01:26<00:34,  9.31it/s] 70%|██████▉   | 746/1070 [01:26<00:34,  9.42it/s] 70%|██████▉   | 747/1070 [01:26<00:34,  9.28it/s] 70%|██████▉   | 748/1070 [01:26<00:34,  9.30it/s] 70%|███████   | 749/1070 [01:26<00:34,  9.32it/s] 70%|███████   | 750/1070 [01:26<00:34,  9.37it/s] 70%|███████   | 751/1070 [01:26<00:34,  9.27it/s] 70%|███████   | 752/1070 [01:26<00:34,  9.27it/s] 70%|███████   | 753/1070 [01:26<00:33,  9.37it/s] 70%|███████   | 754/1070 [01:26<00:33,  9.36it/s] 71%|███████   | 755/1070 [01:27<00:33,  9.37it/s] 71%|███████   | 756/1070 [01:27<00:33,  9.42it/s] 71%|███████   | 757/1070 [01:27<00:33,  9.35it/s] 71%|███████   | 758/1070 [01:27<00:33,  9.35it/s] 71%|███████   | 759/1070 [01:27<00:33,  9.32it/s] 71%|███████   | 760/1070 [01:27<00:32,  9.41it/s] 71%|███████   | 761/1070 [01:27<00:33,  9.34it/s] 71%|███████   | 762/1070 [01:27<00:33,  9.30it/s] 71%|███████▏  | 763/1070 [01:27<00:32,  9.42it/s] 71%|███████▏  | 764/1070 [01:28<00:32,  9.38it/s] 71%|███████▏  | 765/1070 [01:28<00:32,  9.29it/s] 72%|███████▏  | 766/1070 [01:28<00:32,  9.31it/s] 72%|███████▏  | 767/1070 [01:28<00:32,  9.37it/s] 72%|███████▏  | 768/1070 [01:28<00:32,  9.37it/s] 72%|███████▏  | 769/1070 [01:28<00:32,  9.37it/s] 72%|███████▏  | 770/1070 [01:28<00:31,  9.47it/s] 72%|███████▏  | 771/1070 [01:28<00:31,  9.41it/s] 72%|███████▏  | 772/1070 [01:28<00:31,  9.38it/s] 72%|███████▏  | 773/1070 [01:29<00:31,  9.36it/s] 72%|███████▏  | 774/1070 [01:29<00:31,  9.43it/s] 72%|███████▏  | 775/1070 [01:29<00:31,  9.39it/s] 73%|███████▎  | 776/1070 [01:29<00:31,  9.28it/s] 73%|███████▎  | 777/1070 [01:29<00:31,  9.38it/s] 73%|███████▎  | 778/1070 [01:29<00:31,  9.30it/s] 73%|███████▎  | 779/1070 [01:29<00:31,  9.25it/s] 73%|███████▎  | 780/1070 [01:29<00:31,  9.31it/s] 73%|███████▎  | 781/1070 [01:29<00:31,  9.30it/s] 73%|███████▎  | 782/1070 [01:29<00:30,  9.33it/s] 73%|███████▎  | 783/1070 [01:30<00:30,  9.27it/s] 73%|███████▎  | 784/1070 [01:30<00:30,  9.46it/s] 73%|███████▎  | 785/1070 [01:30<00:30,  9.31it/s] 73%|███████▎  | 786/1070 [01:30<00:30,  9.30it/s] 74%|███████▎  | 787/1070 [01:30<00:30,  9.35it/s] 74%|███████▎  | 788/1070 [01:30<00:30,  9.37it/s] 74%|███████▎  | 789/1070 [01:30<00:30,  9.35it/s] 74%|███████▍  | 790/1070 [01:30<00:30,  9.27it/s] 74%|███████▍  | 791/1070 [01:30<00:29,  9.42it/s] 74%|███████▍  | 792/1070 [01:31<00:29,  9.31it/s] 74%|███████▍  | 793/1070 [01:31<00:29,  9.31it/s] 74%|███████▍  | 794/1070 [01:31<00:29,  9.31it/s] 74%|███████▍  | 795/1070 [01:31<00:29,  9.29it/s] 74%|███████▍  | 796/1070 [01:31<00:29,  9.29it/s] 74%|███████▍  | 797/1070 [01:31<00:29,  9.29it/s] 75%|███████▍  | 798/1070 [01:31<00:28,  9.43it/s] 75%|███████▍  | 799/1070 [01:31<00:28,  9.39it/s] 75%|███████▍  | 800/1070 [01:31<00:28,  9.35it/s] 75%|███████▍  | 801/1070 [01:32<00:28,  9.31it/s] 75%|███████▍  | 802/1070 [01:32<00:28,  9.29it/s] 75%|███████▌  | 803/1070 [01:32<00:28,  9.23it/s] 75%|███████▌  | 804/1070 [01:32<00:28,  9.20it/s] 75%|███████▌  | 805/1070 [01:32<00:28,  9.34it/s] 75%|███████▌  | 806/1070 [01:32<00:28,  9.27it/s] 75%|███████▌  | 807/1070 [01:32<00:28,  9.25it/s] 76%|███████▌  | 808/1070 [01:32<00:28,  9.27it/s] 76%|███████▌  | 809/1070 [01:32<00:28,  9.30it/s] 76%|███████▌  | 810/1070 [01:33<00:28,  9.16it/s] 76%|███████▌  | 811/1070 [01:33<00:28,  9.11it/s] 76%|███████▌  | 812/1070 [01:33<00:27,  9.25it/s] 76%|███████▌  | 813/1070 [01:33<00:27,  9.20it/s] 76%|███████▌  | 814/1070 [01:33<00:27,  9.16it/s] 76%|███████▌  | 815/1070 [01:33<00:27,  9.20it/s] 76%|███████▋  | 816/1070 [01:33<00:27,  9.22it/s] 76%|███████▋  | 817/1070 [01:33<00:27,  9.10it/s] 76%|███████▋  | 818/1070 [01:33<00:27,  9.09it/s] 77%|███████▋  | 819/1070 [01:33<00:27,  9.29it/s] 77%|███████▋  | 820/1070 [01:34<00:27,  9.22it/s] 77%|███████▋  | 821/1070 [01:34<00:27,  9.20it/s] 77%|███████▋  | 822/1070 [01:34<00:26,  9.32it/s] 77%|███████▋  | 823/1070 [01:34<00:26,  9.21it/s] 77%|███████▋  | 824/1070 [01:34<00:27,  9.09it/s] 77%|███████▋  | 825/1070 [01:34<00:26,  9.09it/s] 77%|███████▋  | 826/1070 [01:34<00:26,  9.23it/s] 77%|███████▋  | 827/1070 [01:34<00:26,  9.19it/s] 77%|███████▋  | 828/1070 [01:34<00:26,  9.21it/s] 77%|███████▋  | 829/1070 [01:35<00:26,  9.24it/s] 78%|███████▊  | 830/1070 [01:35<00:26,  9.14it/s] 78%|███████▊  | 831/1070 [01:35<00:26,  9.10it/s] 78%|███████▊  | 832/1070 [01:35<00:26,  9.06it/s] 78%|███████▊  | 833/1070 [01:35<00:25,  9.29it/s] 78%|███████▊  | 834/1070 [01:35<00:25,  9.20it/s] 78%|███████▊  | 835/1070 [01:35<00:25,  9.23it/s] 78%|███████▊  | 836/1070 [01:35<00:25,  9.21it/s] 78%|███████▊  | 837/1070 [01:35<00:25,  9.21it/s] 78%|███████▊  | 838/1070 [01:36<00:25,  9.16it/s] 78%|███████▊  | 839/1070 [01:36<00:25,  9.22it/s] 79%|███████▊  | 840/1070 [01:36<00:24,  9.28it/s] 79%|███████▊  | 841/1070 [01:36<00:25,  9.13it/s] 79%|███████▊  | 842/1070 [01:36<00:25,  9.05it/s] 79%|███████▉  | 843/1070 [01:36<00:25,  9.07it/s] 79%|███████▉  | 844/1070 [01:36<00:25,  9.00it/s] 79%|███████▉  | 845/1070 [01:36<00:24,  9.14it/s] 79%|███████▉  | 846/1070 [01:36<00:24,  9.10it/s] 79%|███████▉  | 847/1070 [01:37<00:24,  9.13it/s] 79%|███████▉  | 848/1070 [01:37<00:24,  9.04it/s] 79%|███████▉  | 849/1070 [01:37<00:24,  9.03it/s] 79%|███████▉  | 850/1070 [01:37<00:24,  9.00it/s] 80%|███████▉  | 851/1070 [01:37<00:23,  9.13it/s] 80%|███████▉  | 852/1070 [01:37<00:23,  9.19it/s] 80%|███████▉  | 853/1070 [01:37<00:23,  9.20it/s] 80%|███████▉  | 854/1070 [01:37<00:23,  9.12it/s] 80%|███████▉  | 855/1070 [01:37<00:23,  9.15it/s]                                                   80%|████████  | 856/1070 [01:38<00:23,  9.15it/s][INFO|trainer.py:755] 2023-11-15 20:49:14,216 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:49:14,217 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:49:14,218 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:49:14,218 >>   Batch size = 8
{'eval_loss': 0.3294144868850708, 'eval_accuracy': 0.9052631578947369, 'eval_micro_f1': 0.9052631578947369, 'eval_macro_f1': 0.9021478188791989, 'eval_runtime': 1.3442, 'eval_samples_per_second': 565.4, 'eval_steps_per_second': 70.675, 'epoch': 3.0}
{'loss': 0.1028, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:00, 86.55it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 81.96it/s][A
 28%|██▊       | 27/95 [00:00<00:00, 77.89it/s][A
 37%|███▋      | 35/95 [00:00<00:00, 73.54it/s][A
 45%|████▌     | 43/95 [00:00<00:00, 73.92it/s][A
 54%|█████▎    | 51/95 [00:00<00:00, 71.66it/s][A
 62%|██████▏   | 59/95 [00:00<00:00, 72.16it/s][A
 71%|███████   | 67/95 [00:00<00:00, 72.58it/s][A
 79%|███████▉  | 75/95 [00:01<00:00, 72.81it/s][A
 87%|████████▋ | 83/95 [00:01<00:00, 73.78it/s][A
 96%|█████████▌| 91/95 [00:01<00:00, 73.15it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:39<00:23,  9.15it/s]
100%|██████████| 95/95 [00:01<00:00, 73.15it/s][A
                                               [A 80%|████████  | 857/1070 [01:39<01:28,  2.40it/s] 80%|████████  | 858/1070 [01:39<01:12,  2.93it/s] 80%|████████  | 859/1070 [01:39<00:59,  3.55it/s] 80%|████████  | 860/1070 [01:39<00:49,  4.28it/s] 80%|████████  | 861/1070 [01:39<00:41,  4.98it/s] 81%|████████  | 862/1070 [01:40<00:36,  5.70it/s] 81%|████████  | 863/1070 [01:40<00:32,  6.40it/s] 81%|████████  | 864/1070 [01:40<00:29,  7.00it/s] 81%|████████  | 865/1070 [01:40<00:27,  7.51it/s] 81%|████████  | 866/1070 [01:40<00:25,  7.90it/s] 81%|████████  | 867/1070 [01:40<00:24,  8.28it/s] 81%|████████  | 868/1070 [01:40<00:23,  8.51it/s] 81%|████████  | 869/1070 [01:40<00:23,  8.59it/s] 81%|████████▏ | 870/1070 [01:40<00:22,  8.74it/s] 81%|████████▏ | 871/1070 [01:41<00:22,  8.93it/s] 81%|████████▏ | 872/1070 [01:41<00:22,  8.94it/s] 82%|████████▏ | 873/1070 [01:41<00:21,  9.02it/s] 82%|████████▏ | 874/1070 [01:41<00:21,  9.02it/s] 82%|████████▏ | 875/1070 [01:41<00:21,  9.07it/s] 82%|████████▏ | 876/1070 [01:41<00:21,  9.01it/s] 82%|████████▏ | 877/1070 [01:41<00:21,  9.06it/s] 82%|████████▏ | 878/1070 [01:41<00:20,  9.20it/s] 82%|████████▏ | 879/1070 [01:41<00:20,  9.15it/s] 82%|████████▏ | 880/1070 [01:42<00:20,  9.12it/s] 82%|████████▏ | 881/1070 [01:42<00:20,  9.05it/s] 82%|████████▏ | 882/1070 [01:42<00:21,  8.95it/s] 83%|████████▎ | 883/1070 [01:42<00:20,  9.04it/s] 83%|████████▎ | 884/1070 [01:42<00:20,  9.11it/s] 83%|████████▎ | 885/1070 [01:42<00:20,  9.19it/s] 83%|████████▎ | 886/1070 [01:42<00:20,  9.10it/s] 83%|████████▎ | 887/1070 [01:42<00:20,  9.03it/s] 83%|████████▎ | 888/1070 [01:42<00:20,  9.02it/s] 83%|████████▎ | 889/1070 [01:42<00:20,  8.96it/s] 83%|████████▎ | 890/1070 [01:43<00:19,  9.03it/s] 83%|████████▎ | 891/1070 [01:43<00:19,  9.06it/s] 83%|████████▎ | 892/1070 [01:43<00:19,  9.13it/s] 83%|████████▎ | 893/1070 [01:43<00:19,  9.02it/s] 84%|████████▎ | 894/1070 [01:43<00:19,  8.96it/s] 84%|████████▎ | 895/1070 [01:43<00:19,  9.01it/s] 84%|████████▎ | 896/1070 [01:43<00:19,  9.01it/s] 84%|████████▍ | 897/1070 [01:43<00:19,  9.05it/s] 84%|████████▍ | 898/1070 [01:43<00:18,  9.12it/s] 84%|████████▍ | 899/1070 [01:44<00:18,  9.13it/s] 84%|████████▍ | 900/1070 [01:44<00:18,  9.06it/s] 84%|████████▍ | 901/1070 [01:44<00:18,  8.93it/s] 84%|████████▍ | 902/1070 [01:44<00:18,  8.99it/s] 84%|████████▍ | 903/1070 [01:44<00:18,  9.08it/s] 84%|████████▍ | 904/1070 [01:44<00:18,  9.05it/s] 85%|████████▍ | 905/1070 [01:44<00:18,  9.09it/s] 85%|████████▍ | 906/1070 [01:44<00:17,  9.13it/s] 85%|████████▍ | 907/1070 [01:44<00:17,  9.12it/s] 85%|████████▍ | 908/1070 [01:45<00:18,  8.95it/s] 85%|████████▍ | 909/1070 [01:45<00:17,  8.95it/s] 85%|████████▌ | 910/1070 [01:45<00:17,  9.09it/s] 85%|████████▌ | 911/1070 [01:45<00:17,  9.07it/s] 85%|████████▌ | 912/1070 [01:45<00:17,  9.08it/s] 85%|████████▌ | 913/1070 [01:45<00:17,  9.00it/s] 85%|████████▌ | 914/1070 [01:45<00:17,  9.01it/s] 86%|████████▌ | 915/1070 [01:45<00:17,  8.99it/s] 86%|████████▌ | 916/1070 [01:45<00:17,  8.92it/s] 86%|████████▌ | 917/1070 [01:46<00:16,  9.11it/s] 86%|████████▌ | 918/1070 [01:46<00:16,  9.07it/s] 86%|████████▌ | 919/1070 [01:46<00:16,  9.02it/s] 86%|████████▌ | 920/1070 [01:46<00:16,  9.01it/s] 86%|████████▌ | 921/1070 [01:46<00:16,  9.03it/s] 86%|████████▌ | 922/1070 [01:46<00:16,  9.11it/s] 86%|████████▋ | 923/1070 [01:46<00:16,  9.15it/s] 86%|████████▋ | 924/1070 [01:46<00:15,  9.25it/s] 86%|████████▋ | 925/1070 [01:46<00:15,  9.14it/s] 87%|████████▋ | 926/1070 [01:47<00:15,  9.10it/s] 87%|████████▋ | 927/1070 [01:47<00:15,  9.02it/s] 87%|████████▋ | 928/1070 [01:47<00:15,  9.10it/s] 87%|████████▋ | 929/1070 [01:47<00:15,  9.09it/s] 87%|████████▋ | 930/1070 [01:47<00:15,  9.04it/s] 87%|████████▋ | 931/1070 [01:47<00:15,  9.01it/s] 87%|████████▋ | 932/1070 [01:47<00:15,  9.01it/s] 87%|████████▋ | 933/1070 [01:47<00:15,  8.97it/s] 87%|████████▋ | 934/1070 [01:47<00:15,  8.90it/s] 87%|████████▋ | 935/1070 [01:48<00:14,  9.07it/s] 87%|████████▋ | 936/1070 [01:48<00:14,  9.01it/s] 88%|████████▊ | 937/1070 [01:48<00:14,  9.03it/s] 88%|████████▊ | 938/1070 [01:48<00:14,  8.98it/s] 88%|████████▊ | 939/1070 [01:48<00:14,  8.98it/s] 88%|████████▊ | 940/1070 [01:48<00:14,  9.06it/s] 88%|████████▊ | 941/1070 [01:48<00:14,  8.95it/s] 88%|████████▊ | 942/1070 [01:48<00:14,  9.06it/s] 88%|████████▊ | 943/1070 [01:48<00:14,  9.00it/s] 88%|████████▊ | 944/1070 [01:49<00:14,  8.94it/s] 88%|████████▊ | 945/1070 [01:49<00:13,  8.97it/s] 88%|████████▊ | 946/1070 [01:49<00:13,  9.09it/s] 89%|████████▊ | 947/1070 [01:49<00:13,  9.07it/s] 89%|████████▊ | 948/1070 [01:49<00:13,  9.03it/s] 89%|████████▊ | 949/1070 [01:49<00:13,  9.02it/s] 89%|████████▉ | 950/1070 [01:49<00:13,  8.99it/s] 89%|████████▉ | 951/1070 [01:49<00:13,  8.92it/s] 89%|████████▉ | 952/1070 [01:49<00:13,  8.89it/s] 89%|████████▉ | 953/1070 [01:50<00:12,  9.13it/s] 89%|████████▉ | 954/1070 [01:50<00:12,  9.07it/s] 89%|████████▉ | 955/1070 [01:50<00:12,  8.97it/s] 89%|████████▉ | 956/1070 [01:50<00:12,  8.99it/s] 89%|████████▉ | 957/1070 [01:50<00:12,  9.01it/s] 90%|████████▉ | 958/1070 [01:50<00:12,  9.05it/s] 90%|████████▉ | 959/1070 [01:50<00:12,  9.01it/s] 90%|████████▉ | 960/1070 [01:50<00:12,  9.05it/s] 90%|████████▉ | 961/1070 [01:50<00:12,  9.04it/s] 90%|████████▉ | 962/1070 [01:51<00:12,  8.98it/s] 90%|█████████ | 963/1070 [01:51<00:11,  8.95it/s] 90%|█████████ | 964/1070 [01:51<00:11,  9.09it/s] 90%|█████████ | 965/1070 [01:51<00:11,  9.02it/s] 90%|█████████ | 966/1070 [01:51<00:11,  8.96it/s] 90%|█████████ | 967/1070 [01:51<00:11,  8.96it/s] 90%|█████████ | 968/1070 [01:51<00:11,  8.91it/s] 91%|█████████ | 969/1070 [01:51<00:11,  8.96it/s] 91%|█████████ | 970/1070 [01:51<00:11,  8.96it/s] 91%|█████████ | 971/1070 [01:52<00:11,  8.96it/s] 91%|█████████ | 972/1070 [01:52<00:11,  8.90it/s] 91%|█████████ | 973/1070 [01:52<00:10,  8.87it/s] 91%|█████████ | 974/1070 [01:52<00:10,  8.90it/s] 91%|█████████ | 975/1070 [01:52<00:10,  9.07it/s] 91%|█████████ | 976/1070 [01:52<00:10,  8.99it/s] 91%|█████████▏| 977/1070 [01:52<00:10,  8.97it/s] 91%|█████████▏| 978/1070 [01:52<00:10,  8.99it/s] 91%|█████████▏| 979/1070 [01:52<00:10,  9.01it/s] 92%|█████████▏| 980/1070 [01:53<00:09,  9.10it/s] 92%|█████████▏| 981/1070 [01:53<00:09,  9.01it/s] 92%|█████████▏| 982/1070 [01:53<00:09,  9.14it/s] 92%|█████████▏| 983/1070 [01:53<00:09,  9.10it/s] 92%|█████████▏| 984/1070 [01:53<00:09,  9.09it/s] 92%|█████████▏| 985/1070 [01:53<00:09,  9.00it/s] 92%|█████████▏| 986/1070 [01:53<00:09,  9.18it/s] 92%|█████████▏| 987/1070 [01:53<00:09,  9.02it/s] 92%|█████████▏| 988/1070 [01:53<00:09,  9.04it/s] 92%|█████████▏| 989/1070 [01:54<00:09,  8.94it/s] 93%|█████████▎| 990/1070 [01:54<00:09,  8.88it/s] 93%|█████████▎| 991/1070 [01:54<00:08,  8.91it/s] 93%|█████████▎| 992/1070 [01:54<00:08,  8.91it/s] 93%|█████████▎| 993/1070 [01:54<00:08,  8.95it/s] 93%|█████████▎| 994/1070 [01:54<00:08,  8.95it/s] 93%|█████████▎| 995/1070 [01:54<00:08,  8.93it/s] 93%|█████████▎| 996/1070 [01:54<00:08,  8.88it/s] 93%|█████████▎| 997/1070 [01:54<00:08,  9.12it/s] 93%|█████████▎| 998/1070 [01:55<00:08,  8.97it/s] 93%|█████████▎| 999/1070 [01:55<00:07,  8.93it/s] 93%|█████████▎| 1000/1070 [01:55<00:07,  8.88it/s] 94%|█████████▎| 1001/1070 [01:55<00:07,  8.93it/s] 94%|█████████▎| 1002/1070 [01:55<00:07,  8.96it/s] 94%|█████████▎| 1003/1070 [01:55<00:07,  8.97it/s] 94%|█████████▍| 1004/1070 [01:55<00:07,  8.96it/s] 94%|█████████▍| 1005/1070 [01:55<00:07,  8.87it/s] 94%|█████████▍| 1006/1070 [01:55<00:07,  8.91it/s] 94%|█████████▍| 1007/1070 [01:56<00:07,  8.96it/s] 94%|█████████▍| 1008/1070 [01:56<00:06,  9.12it/s] 94%|█████████▍| 1009/1070 [01:56<00:06,  9.02it/s] 94%|█████████▍| 1010/1070 [01:56<00:06,  8.93it/s] 94%|█████████▍| 1011/1070 [01:56<00:06,  8.82it/s] 95%|█████████▍| 1012/1070 [01:56<00:06,  9.01it/s] 95%|█████████▍| 1013/1070 [01:56<00:06,  8.98it/s] 95%|█████████▍| 1014/1070 [01:56<00:06,  8.91it/s] 95%|█████████▍| 1015/1070 [01:56<00:06,  8.84it/s] 95%|█████████▍| 1016/1070 [01:57<00:06,  8.85it/s] 95%|█████████▌| 1017/1070 [01:57<00:05,  8.91it/s] 95%|█████████▌| 1018/1070 [01:57<00:05,  8.95it/s] 95%|█████████▌| 1019/1070 [01:57<00:05,  8.97it/s] 95%|█████████▌| 1020/1070 [01:57<00:05,  8.97it/s] 95%|█████████▌| 1021/1070 [01:57<00:05,  8.94it/s] 96%|█████████▌| 1022/1070 [01:57<00:05,  8.99it/s] 96%|█████████▌| 1023/1070 [01:57<00:05,  9.14it/s] 96%|█████████▌| 1024/1070 [01:57<00:05,  9.01it/s] 96%|█████████▌| 1025/1070 [01:58<00:05,  8.97it/s] 96%|█████████▌| 1026/1070 [01:58<00:04,  8.97it/s] 96%|█████████▌| 1027/1070 [01:58<00:04,  9.07it/s] 96%|█████████▌| 1028/1070 [01:58<00:04,  9.02it/s] 96%|█████████▌| 1029/1070 [01:58<00:04,  9.03it/s] 96%|█████████▋| 1030/1070 [01:58<00:04,  8.99it/s] 96%|█████████▋| 1031/1070 [01:58<00:04,  8.96it/s] 96%|█████████▋| 1032/1070 [01:58<00:04,  8.98it/s] 97%|█████████▋| 1033/1070 [01:58<00:04,  9.01it/s] 97%|█████████▋| 1034/1070 [01:59<00:03,  9.06it/s] 97%|█████████▋| 1035/1070 [01:59<00:03,  8.98it/s] 97%|█████████▋| 1036/1070 [01:59<00:03,  8.97it/s] 97%|█████████▋| 1037/1070 [01:59<00:03,  8.91it/s] 97%|█████████▋| 1038/1070 [01:59<00:03,  9.09it/s] 97%|█████████▋| 1039/1070 [01:59<00:03,  8.94it/s] 97%|█████████▋| 1040/1070 [01:59<00:03,  8.91it/s] 97%|█████████▋| 1041/1070 [01:59<00:03,  8.92it/s] 97%|█████████▋| 1042/1070 [01:59<00:03,  8.91it/s] 97%|█████████▋| 1043/1070 [02:00<00:03,  8.96it/s] 98%|█████████▊| 1044/1070 [02:00<00:02,  8.93it/s] 98%|█████████▊| 1045/1070 [02:00<00:02,  8.99it/s] 98%|█████████▊| 1046/1070 [02:00<00:02,  9.00it/s] 98%|█████████▊| 1047/1070 [02:00<00:02,  8.94it/s] 98%|█████████▊| 1048/1070 [02:00<00:02,  8.98it/s] 98%|█████████▊| 1049/1070 [02:00<00:02,  9.19it/s] 98%|█████████▊| 1050/1070 [02:00<00:02,  9.04it/s] 98%|█████████▊| 1051/1070 [02:00<00:02,  8.97it/s] 98%|█████████▊| 1052/1070 [02:01<00:02,  8.92it/s] 98%|█████████▊| 1053/1070 [02:01<00:01,  9.09it/s] 99%|█████████▊| 1054/1070 [02:01<00:01,  9.09it/s] 99%|█████████▊| 1055/1070 [02:01<00:01,  9.04it/s] 99%|█████████▊| 1056/1070 [02:01<00:01,  8.92it/s] 99%|█████████▉| 1057/1070 [02:01<00:01,  8.93it/s] 99%|█████████▉| 1058/1070 [02:01<00:01,  8.92it/s] 99%|█████████▉| 1059/1070 [02:01<00:01,  8.94it/s] 99%|█████████▉| 1060/1070 [02:02<00:01,  8.87it/s] 99%|█████████▉| 1061/1070 [02:02<00:01,  8.87it/s] 99%|█████████▉| 1062/1070 [02:02<00:00,  8.81it/s] 99%|█████████▉| 1063/1070 [02:02<00:00,  8.79it/s] 99%|█████████▉| 1064/1070 [02:02<00:00,  8.97it/s]100%|█████████▉| 1065/1070 [02:02<00:00,  8.84it/s]100%|█████████▉| 1066/1070 [02:02<00:00,  8.86it/s]100%|█████████▉| 1067/1070 [02:02<00:00,  8.78it/s]100%|█████████▉| 1068/1070 [02:02<00:00,  8.93it/s]100%|█████████▉| 1069/1070 [02:03<00:00,  8.97it/s]                                                   100%|██████████| 1070/1070 [02:03<00:00,  8.97it/s][INFO|trainer.py:755] 2023-11-15 20:49:39,321 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:49:39,323 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:49:39,323 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:49:39,323 >>   Batch size = 8
{'eval_loss': 0.37000516057014465, 'eval_accuracy': 0.9013157894736842, 'eval_micro_f1': 0.9013157894736842, 'eval_macro_f1': 0.8996218604243451, 'eval_runtime': 1.3434, 'eval_samples_per_second': 565.745, 'eval_steps_per_second': 70.718, 'epoch': 4.0}
{'loss': 0.0635, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 77.96it/s][A
 18%|█▊        | 17/95 [00:00<00:01, 73.92it/s][A
 26%|██▋       | 25/95 [00:00<00:00, 73.20it/s][A
 35%|███▍      | 33/95 [00:00<00:00, 72.22it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 71.19it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 71.94it/s][A
 60%|██████    | 57/95 [00:00<00:00, 73.00it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 71.29it/s][A
 77%|███████▋  | 73/95 [00:01<00:00, 73.00it/s][A
 85%|████████▌ | 81/95 [00:01<00:00, 71.23it/s][A
 94%|█████████▎| 89/95 [00:01<00:00, 71.82it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:04<00:00,  8.97it/s]
100%|██████████| 95/95 [00:01<00:00, 71.82it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 20:49:40,691 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:04<00:00,  8.97it/s]100%|██████████| 1070/1070 [02:04<00:00,  8.60it/s]
[INFO|trainer.py:2855] 2023-11-15 20:49:40,694 >> Saving model checkpoint to ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2
[INFO|configuration_utils.py:460] 2023-11-15 20:49:40,697 >> Configuration saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:49:41,748 >> Model weights saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:49:41,750 >> tokenizer config file saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:49:41,752 >> Special tokens file saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed2/special_tokens_map.json
{'eval_loss': 0.3796307146549225, 'eval_accuracy': 0.9026315789473685, 'eval_micro_f1': 0.9026315789473685, 'eval_macro_f1': 0.9008909167202767, 'eval_runtime': 1.3641, 'eval_samples_per_second': 557.125, 'eval_steps_per_second': 69.641, 'epoch': 5.0}
{'train_runtime': 124.4902, 'train_samples_per_second': 274.72, 'train_steps_per_second': 8.595, 'train_loss': 0.21986313935752227, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2199
  train_runtime            = 0:02:04.49
  train_samples            =       6840
  train_samples_per_second =     274.72
  train_steps_per_second   =      8.595
11/15/2023 20:49:41 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:49:41,797 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:49:41,799 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:49:41,799 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 20:49:41,799 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  9%|▉         | 9/95 [00:00<00:01, 80.59it/s] 19%|█▉        | 18/95 [00:00<00:00, 77.72it/s] 27%|██▋       | 26/95 [00:00<00:00, 72.13it/s] 36%|███▌      | 34/95 [00:00<00:00, 70.18it/s] 44%|████▍     | 42/95 [00:00<00:00, 70.10it/s] 53%|█████▎    | 50/95 [00:00<00:00, 71.07it/s] 61%|██████    | 58/95 [00:00<00:00, 69.41it/s] 69%|██████▉   | 66/95 [00:00<00:00, 70.46it/s] 78%|███████▊  | 74/95 [00:01<00:00, 68.68it/s] 86%|████████▋ | 82/95 [00:01<00:00, 69.17it/s] 95%|█████████▍| 90/95 [00:01<00:00, 69.34it/s]100%|██████████| 95/95 [00:01<00:00, 69.19it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9026
  eval_loss               =     0.3796
  eval_macro_f1           =     0.9009
  eval_micro_f1           =     0.9026
  eval_runtime            = 0:00:01.39
  eval_samples            =        760
  eval_samples_per_second =     544.86
  eval_steps_per_second   =     68.107
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁█▇▆▆▆
wandb:                      eval/loss ▅▁▄▇██
wandb:                  eval/macro_f1 ▁█▇▆▇▇
wandb:                  eval/micro_f1 ▁█▇▆▆▆
wandb:                   eval/runtime ▁█▇▇▇█
wandb:        eval/samples_per_second █▁▂▂▁▁
wandb:          eval/steps_per_second █▁▂▂▁▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.90263
wandb:                      eval/loss 0.37963
wandb:                  eval/macro_f1 0.90089
wandb:                  eval/micro_f1 0.90263
wandb:                   eval/runtime 1.3949
wandb:        eval/samples_per_second 544.86
wandb:          eval/steps_per_second 68.107
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0635
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.21986
wandb:            train/train_runtime 124.4902
wandb: train/train_samples_per_second 274.72
wandb:   train/train_steps_per_second 8.595
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_204618-h38m1whk
wandb: Find logs at: ./wandb/offline-run-20231115_204618-h38m1whk/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_roberta-base_adapter__seed3/runs/Nov15_20-49-53_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_roberta-base_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_roberta-base_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:49:53 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:49:53 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_roberta-base_adapter__seed3/runs/Nov15_20-49-53_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_roberta-base_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_roberta-base_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  88%|████████▊ | 4136/4722 [00:00<00:00, 40273.01 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 39581.00 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:50:09,235 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:50:09,245 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:50:19,260 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:50:29,278 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:50:29,279 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:50:49,329 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:50:49,329 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:50:49,330 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:50:49,330 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:50:49,330 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:50:49,330 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:50:49,331 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:50:49,332 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:51:09,498 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:51:10,269 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:51:10,270 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset:  79%|███████▉  | 3000/3777 [00:00<00:00, 21201.84 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 21604.76 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 27937.19 examples/s]
11/15/2023 20:51:10 - INFO - __main__ - Sample 1265 of the training set: {'text': 'cuisine <SEP> I love when restaurants think using fancy expensive ingrediants makes the food fine cuisine, even with no idea how to use them.', 'label': 0, 'input_ids': [0, 16312, 40116, 28696, 3388, 510, 15698, 38, 657, 77, 4329, 206, 634, 13185, 3214, 49567, 40679, 817, 5, 689, 2051, 18196, 6, 190, 19, 117, 1114, 141, 7, 304, 106, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:51:10 - INFO - __main__ - Sample 1178 of the training set: {'text': "table <SEP> I went with 5 friends and we lingered at the table for a bit and didn't feel rushed at all even though there was a wait.", 'label': 1, 'input_ids': [0, 14595, 28696, 3388, 510, 15698, 38, 439, 19, 195, 964, 8, 52, 24433, 3215, 23, 5, 2103, 13, 10, 828, 8, 399, 75, 619, 6022, 23, 70, 190, 600, 89, 21, 10, 2067, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:51:10 - INFO - __main__ - Sample 54 of the training set: {'text': "Halibut <SEP> The Halibut was too salty, dessert was so so (don't waste any of your calories) and service was poor.", 'label': 2, 'input_ids': [0, 40306, 1452, 1182, 28696, 3388, 510, 15698, 20, 6579, 1452, 1182, 21, 350, 31924, 6, 17927, 21, 98, 98, 36, 7254, 75, 3844, 143, 9, 110, 12951, 43, 8, 544, 21, 2129, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:51:10 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:51:12,024 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:51:12,032 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:51:12,032 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 20:51:12,032 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:51:12,032 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:51:12,033 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:51:12,033 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:51:12,033 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 20:51:12,034 >>   Number of trainable parameters = 124,647,939
[INFO|integration_utils.py:716] 2023-11-15 20:51:12,035 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<12:58,  1.31s/it]  0%|          | 2/595 [00:01<06:01,  1.64it/s]  1%|          | 3/595 [00:01<03:44,  2.63it/s]  1%|          | 4/595 [00:01<02:40,  3.67it/s]  1%|          | 5/595 [00:01<02:05,  4.69it/s]  1%|          | 6/595 [00:01<01:44,  5.61it/s]  1%|          | 7/595 [00:01<01:32,  6.38it/s]  1%|▏         | 8/595 [00:02<01:23,  7.07it/s]  2%|▏         | 9/595 [00:02<01:17,  7.59it/s]  2%|▏         | 10/595 [00:02<01:12,  8.03it/s]  2%|▏         | 11/595 [00:02<01:09,  8.36it/s]  2%|▏         | 12/595 [00:02<01:08,  8.54it/s]  2%|▏         | 13/595 [00:02<01:06,  8.71it/s]  2%|▏         | 14/595 [00:02<01:06,  8.80it/s]  3%|▎         | 15/595 [00:02<01:05,  8.91it/s]  3%|▎         | 16/595 [00:02<01:04,  8.93it/s]  3%|▎         | 17/595 [00:03<01:04,  8.98it/s]  3%|▎         | 18/595 [00:03<01:04,  9.02it/s]  3%|▎         | 19/595 [00:03<01:03,  9.03it/s]  3%|▎         | 20/595 [00:03<01:03,  9.10it/s]  4%|▎         | 21/595 [00:03<01:02,  9.26it/s]  4%|▎         | 22/595 [00:03<01:02,  9.17it/s]  4%|▍         | 23/595 [00:03<01:02,  9.14it/s]  4%|▍         | 24/595 [00:03<01:02,  9.10it/s]  4%|▍         | 25/595 [00:03<01:02,  9.11it/s]  4%|▍         | 26/595 [00:04<01:02,  9.14it/s]  5%|▍         | 27/595 [00:04<01:02,  9.13it/s]  5%|▍         | 28/595 [00:04<01:02,  9.12it/s]  5%|▍         | 29/595 [00:04<01:02,  9.12it/s]  5%|▌         | 30/595 [00:04<01:02,  9.10it/s]  5%|▌         | 31/595 [00:04<01:01,  9.12it/s]  5%|▌         | 32/595 [00:04<01:01,  9.13it/s]  6%|▌         | 33/595 [00:04<01:01,  9.08it/s]  6%|▌         | 34/595 [00:04<01:02,  8.97it/s]  6%|▌         | 35/595 [00:05<01:02,  9.02it/s]  6%|▌         | 36/595 [00:05<01:01,  9.02it/s]  6%|▌         | 37/595 [00:05<01:01,  9.03it/s]  6%|▋         | 38/595 [00:05<01:00,  9.15it/s]  7%|▋         | 39/595 [00:05<01:00,  9.15it/s]  7%|▋         | 40/595 [00:05<01:00,  9.14it/s]  7%|▋         | 41/595 [00:05<01:01,  8.99it/s]  7%|▋         | 42/595 [00:05<01:01,  8.97it/s]  7%|▋         | 43/595 [00:05<01:01,  9.03it/s]  7%|▋         | 44/595 [00:06<01:00,  9.05it/s]  8%|▊         | 45/595 [00:06<01:00,  9.16it/s]  8%|▊         | 46/595 [00:06<01:00,  9.06it/s]  8%|▊         | 47/595 [00:06<01:00,  9.01it/s]  8%|▊         | 48/595 [00:06<01:00,  9.01it/s]  8%|▊         | 49/595 [00:06<01:00,  8.99it/s]  8%|▊         | 50/595 [00:06<01:00,  9.06it/s]  9%|▊         | 51/595 [00:06<01:00,  9.02it/s]  9%|▊         | 52/595 [00:06<00:59,  9.12it/s]  9%|▉         | 53/595 [00:07<00:59,  9.08it/s]  9%|▉         | 54/595 [00:07<00:59,  9.03it/s]  9%|▉         | 55/595 [00:07<00:59,  9.00it/s]  9%|▉         | 56/595 [00:07<00:59,  9.01it/s] 10%|▉         | 57/595 [00:07<00:59,  9.08it/s] 10%|▉         | 58/595 [00:07<00:59,  9.08it/s] 10%|▉         | 59/595 [00:07<00:58,  9.13it/s] 10%|█         | 60/595 [00:07<00:58,  9.10it/s] 10%|█         | 61/595 [00:07<00:58,  9.06it/s] 10%|█         | 62/595 [00:08<00:58,  9.05it/s] 11%|█         | 63/595 [00:08<00:58,  9.05it/s] 11%|█         | 64/595 [00:08<00:58,  9.01it/s] 11%|█         | 65/595 [00:08<00:59,  8.98it/s] 11%|█         | 66/595 [00:08<00:58,  9.03it/s] 11%|█▏        | 67/595 [00:08<00:58,  9.03it/s] 11%|█▏        | 68/595 [00:08<00:58,  9.03it/s] 12%|█▏        | 69/595 [00:08<00:57,  9.12it/s] 12%|█▏        | 70/595 [00:08<00:58,  9.02it/s] 12%|█▏        | 71/595 [00:09<00:58,  9.02it/s] 12%|█▏        | 72/595 [00:09<00:58,  8.99it/s] 12%|█▏        | 73/595 [00:09<00:58,  8.96it/s] 12%|█▏        | 74/595 [00:09<00:58,  8.97it/s] 13%|█▎        | 75/595 [00:09<00:57,  8.99it/s] 13%|█▎        | 76/595 [00:09<00:57,  9.10it/s] 13%|█▎        | 77/595 [00:09<00:57,  9.06it/s] 13%|█▎        | 78/595 [00:09<00:57,  9.05it/s] 13%|█▎        | 79/595 [00:09<00:57,  9.04it/s] 13%|█▎        | 80/595 [00:10<00:56,  9.09it/s] 14%|█▎        | 81/595 [00:10<00:56,  9.07it/s] 14%|█▍        | 82/595 [00:10<00:56,  9.09it/s] 14%|█▍        | 83/595 [00:10<00:55,  9.18it/s] 14%|█▍        | 84/595 [00:10<00:56,  9.08it/s] 14%|█▍        | 85/595 [00:10<00:56,  9.02it/s] 14%|█▍        | 86/595 [00:10<00:56,  9.00it/s] 15%|█▍        | 87/595 [00:10<00:56,  9.02it/s] 15%|█▍        | 88/595 [00:10<00:56,  9.04it/s] 15%|█▍        | 89/595 [00:11<00:56,  8.97it/s] 15%|█▌        | 90/595 [00:11<00:55,  9.09it/s] 15%|█▌        | 91/595 [00:11<00:55,  9.01it/s] 15%|█▌        | 92/595 [00:11<00:55,  9.01it/s] 16%|█▌        | 93/595 [00:11<00:55,  8.97it/s] 16%|█▌        | 94/595 [00:11<00:55,  8.98it/s] 16%|█▌        | 95/595 [00:11<00:56,  8.92it/s] 16%|█▌        | 96/595 [00:11<00:55,  9.00it/s] 16%|█▋        | 97/595 [00:11<00:55,  8.97it/s] 16%|█▋        | 98/595 [00:12<00:55,  8.92it/s] 17%|█▋        | 99/595 [00:12<00:55,  8.90it/s] 17%|█▋        | 100/595 [00:12<00:55,  8.92it/s] 17%|█▋        | 101/595 [00:12<00:54,  9.01it/s] 17%|█▋        | 102/595 [00:12<00:54,  8.98it/s] 17%|█▋        | 103/595 [00:12<00:54,  8.96it/s] 17%|█▋        | 104/595 [00:12<00:54,  8.98it/s] 18%|█▊        | 105/595 [00:12<00:54,  8.96it/s] 18%|█▊        | 106/595 [00:12<00:54,  8.99it/s] 18%|█▊        | 107/595 [00:13<00:53,  9.07it/s] 18%|█▊        | 108/595 [00:13<00:54,  8.97it/s] 18%|█▊        | 109/595 [00:13<00:54,  8.93it/s] 18%|█▊        | 110/595 [00:13<00:54,  8.92it/s] 19%|█▊        | 111/595 [00:13<00:54,  8.85it/s] 19%|█▉        | 112/595 [00:13<00:54,  8.86it/s] 19%|█▉        | 113/595 [00:13<00:54,  8.87it/s] 19%|█▉        | 114/595 [00:13<00:53,  9.00it/s] 19%|█▉        | 115/595 [00:13<00:53,  9.00it/s] 19%|█▉        | 116/595 [00:14<00:53,  8.93it/s] 20%|█▉        | 117/595 [00:14<00:53,  8.90it/s] 20%|█▉        | 118/595 [00:14<00:53,  8.93it/s]                                                  20%|██        | 119/595 [00:14<00:53,  8.93it/s][INFO|trainer.py:755] 2023-11-15 20:51:26,350 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:51:26,352 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:51:26,352 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:51:26,353 >>   Batch size = 8
{'loss': 0.7399, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 80.63it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 78.41it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 74.10it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 72.38it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 71.37it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 72.17it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 71.51it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 71.91it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 73.88it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 73.07it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 72.50it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 72.03it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 71.43it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 72.15it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:16<00:53,  8.93it/s]
100%|██████████| 119/119 [00:01<00:00, 72.15it/s][A
                                                 [A 20%|██        | 120/595 [00:16<03:51,  2.05it/s] 20%|██        | 121/595 [00:16<03:06,  2.54it/s] 21%|██        | 122/595 [00:16<02:31,  3.12it/s] 21%|██        | 123/595 [00:16<02:04,  3.80it/s] 21%|██        | 124/595 [00:16<01:43,  4.54it/s] 21%|██        | 125/595 [00:16<01:29,  5.27it/s] 21%|██        | 126/595 [00:16<01:18,  5.99it/s] 21%|██▏       | 127/595 [00:16<01:10,  6.61it/s] 22%|██▏       | 128/595 [00:17<01:05,  7.16it/s] 22%|██▏       | 129/595 [00:17<01:01,  7.63it/s] 22%|██▏       | 130/595 [00:17<00:58,  7.94it/s] 22%|██▏       | 131/595 [00:17<00:56,  8.25it/s] 22%|██▏       | 132/595 [00:17<00:54,  8.47it/s] 22%|██▏       | 133/595 [00:17<00:53,  8.62it/s] 23%|██▎       | 134/595 [00:17<00:52,  8.80it/s] 23%|██▎       | 135/595 [00:17<00:51,  8.88it/s] 23%|██▎       | 136/595 [00:17<00:51,  8.97it/s] 23%|██▎       | 137/595 [00:17<00:51,  8.93it/s] 23%|██▎       | 138/595 [00:18<00:50,  8.99it/s] 23%|██▎       | 139/595 [00:18<00:50,  9.03it/s] 24%|██▎       | 140/595 [00:18<00:50,  9.04it/s] 24%|██▎       | 141/595 [00:18<00:49,  9.17it/s] 24%|██▍       | 142/595 [00:18<00:49,  9.18it/s] 24%|██▍       | 143/595 [00:18<00:49,  9.14it/s] 24%|██▍       | 144/595 [00:18<00:49,  9.08it/s] 24%|██▍       | 145/595 [00:18<00:49,  9.08it/s] 25%|██▍       | 146/595 [00:18<00:49,  9.06it/s] 25%|██▍       | 147/595 [00:19<00:49,  8.99it/s] 25%|██▍       | 148/595 [00:19<00:49,  9.10it/s] 25%|██▌       | 149/595 [00:19<00:49,  9.08it/s] 25%|██▌       | 150/595 [00:19<00:49,  9.00it/s] 25%|██▌       | 151/595 [00:19<00:48,  9.14it/s] 26%|██▌       | 152/595 [00:19<00:48,  9.10it/s] 26%|██▌       | 153/595 [00:19<00:48,  9.06it/s] 26%|██▌       | 154/595 [00:19<00:48,  9.07it/s] 26%|██▌       | 155/595 [00:19<00:48,  9.02it/s] 26%|██▌       | 156/595 [00:20<00:48,  9.05it/s] 26%|██▋       | 157/595 [00:20<00:48,  9.09it/s] 27%|██▋       | 158/595 [00:20<00:47,  9.19it/s] 27%|██▋       | 159/595 [00:20<00:47,  9.09it/s] 27%|██▋       | 160/595 [00:20<00:47,  9.09it/s] 27%|██▋       | 161/595 [00:20<00:47,  9.12it/s] 27%|██▋       | 162/595 [00:20<00:47,  9.10it/s] 27%|██▋       | 163/595 [00:20<00:47,  9.10it/s] 28%|██▊       | 164/595 [00:20<00:47,  9.07it/s] 28%|██▊       | 165/595 [00:21<00:47,  9.13it/s] 28%|██▊       | 166/595 [00:21<00:47,  9.04it/s] 28%|██▊       | 167/595 [00:21<00:47,  9.04it/s] 28%|██▊       | 168/595 [00:21<00:46,  9.15it/s] 28%|██▊       | 169/595 [00:21<00:46,  9.09it/s] 29%|██▊       | 170/595 [00:21<00:46,  9.15it/s] 29%|██▊       | 171/595 [00:21<00:46,  9.07it/s] 29%|██▉       | 172/595 [00:21<00:46,  9.10it/s] 29%|██▉       | 173/595 [00:21<00:46,  9.07it/s] 29%|██▉       | 174/595 [00:22<00:46,  9.02it/s] 29%|██▉       | 175/595 [00:22<00:45,  9.21it/s] 30%|██▉       | 176/595 [00:22<00:46,  9.03it/s] 30%|██▉       | 177/595 [00:22<00:46,  9.03it/s] 30%|██▉       | 178/595 [00:22<00:46,  9.05it/s] 30%|███       | 179/595 [00:22<00:45,  9.08it/s] 30%|███       | 180/595 [00:22<00:45,  9.09it/s] 30%|███       | 181/595 [00:22<00:45,  9.10it/s] 31%|███       | 182/595 [00:22<00:45,  9.10it/s] 31%|███       | 183/595 [00:23<00:45,  9.06it/s] 31%|███       | 184/595 [00:23<00:45,  9.06it/s] 31%|███       | 185/595 [00:23<00:44,  9.18it/s] 31%|███▏      | 186/595 [00:23<00:44,  9.10it/s] 31%|███▏      | 187/595 [00:23<00:45,  9.04it/s] 32%|███▏      | 188/595 [00:23<00:45,  9.02it/s] 32%|███▏      | 189/595 [00:23<00:45,  9.00it/s] 32%|███▏      | 190/595 [00:23<00:45,  8.98it/s] 32%|███▏      | 191/595 [00:23<00:44,  8.98it/s] 32%|███▏      | 192/595 [00:24<00:44,  9.02it/s] 32%|███▏      | 193/595 [00:24<00:44,  9.03it/s] 33%|███▎      | 194/595 [00:24<00:44,  9.00it/s] 33%|███▎      | 195/595 [00:24<00:44,  9.03it/s] 33%|███▎      | 196/595 [00:24<00:44,  9.04it/s] 33%|███▎      | 197/595 [00:24<00:43,  9.07it/s] 33%|███▎      | 198/595 [00:24<00:43,  9.09it/s] 33%|███▎      | 199/595 [00:24<00:43,  9.11it/s] 34%|███▎      | 200/595 [00:24<00:43,  9.03it/s] 34%|███▍      | 201/595 [00:25<00:43,  9.07it/s] 34%|███▍      | 202/595 [00:25<00:42,  9.15it/s] 34%|███▍      | 203/595 [00:25<00:43,  9.05it/s] 34%|███▍      | 204/595 [00:25<00:43,  9.03it/s] 34%|███▍      | 205/595 [00:25<00:43,  9.06it/s] 35%|███▍      | 206/595 [00:25<00:42,  9.05it/s] 35%|███▍      | 207/595 [00:25<00:42,  9.07it/s] 35%|███▍      | 208/595 [00:25<00:42,  9.09it/s] 35%|███▌      | 209/595 [00:25<00:42,  9.07it/s] 35%|███▌      | 210/595 [00:26<00:42,  9.03it/s] 35%|███▌      | 211/595 [00:26<00:42,  9.01it/s] 36%|███▌      | 212/595 [00:26<00:42,  9.07it/s] 36%|███▌      | 213/595 [00:26<00:42,  9.08it/s] 36%|███▌      | 214/595 [00:26<00:42,  9.02it/s] 36%|███▌      | 215/595 [00:26<00:42,  9.03it/s] 36%|███▋      | 216/595 [00:26<00:42,  8.97it/s] 36%|███▋      | 217/595 [00:26<00:41,  9.05it/s] 37%|███▋      | 218/595 [00:26<00:42,  8.95it/s] 37%|███▋      | 219/595 [00:27<00:41,  9.07it/s] 37%|███▋      | 220/595 [00:27<00:41,  8.98it/s] 37%|███▋      | 221/595 [00:27<00:41,  8.98it/s] 37%|███▋      | 222/595 [00:27<00:41,  8.97it/s] 37%|███▋      | 223/595 [00:27<00:41,  9.04it/s] 38%|███▊      | 224/595 [00:27<00:41,  9.00it/s] 38%|███▊      | 225/595 [00:27<00:41,  8.95it/s] 38%|███▊      | 226/595 [00:27<00:40,  9.10it/s] 38%|███▊      | 227/595 [00:27<00:40,  9.05it/s] 38%|███▊      | 228/595 [00:28<00:40,  9.00it/s] 38%|███▊      | 229/595 [00:28<00:40,  8.95it/s] 39%|███▊      | 230/595 [00:28<00:40,  8.99it/s] 39%|███▉      | 231/595 [00:28<00:40,  8.97it/s] 39%|███▉      | 232/595 [00:28<00:40,  9.01it/s] 39%|███▉      | 233/595 [00:28<00:39,  9.15it/s] 39%|███▉      | 234/595 [00:28<00:39,  9.07it/s] 39%|███▉      | 235/595 [00:28<00:40,  8.99it/s] 40%|███▉      | 236/595 [00:28<00:40,  8.96it/s] 40%|███▉      | 237/595 [00:29<00:39,  9.07it/s]                                                  40%|████      | 238/595 [00:29<00:39,  9.07it/s][INFO|trainer.py:755] 2023-11-15 20:51:41,123 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:51:41,125 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:51:41,125 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:51:41,125 >>   Batch size = 8
{'eval_loss': 0.5704823732376099, 'eval_accuracy': 0.765079365079365, 'eval_micro_f1': 0.765079365079365, 'eval_macro_f1': 0.62528256755761, 'eval_runtime': 1.6877, 'eval_samples_per_second': 559.944, 'eval_steps_per_second': 70.511, 'epoch': 1.0}
{'loss': 0.4677, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 77.72it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 76.11it/s][A
 20%|██        | 24/119 [00:00<00:01, 74.72it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 73.92it/s][A
 34%|███▎      | 40/119 [00:00<00:01, 72.03it/s][A
 40%|████      | 48/119 [00:00<00:00, 72.51it/s][A
 47%|████▋     | 56/119 [00:00<00:00, 73.90it/s][A
 54%|█████▍    | 64/119 [00:00<00:00, 72.21it/s][A
 61%|██████    | 72/119 [00:00<00:00, 74.18it/s][A
 67%|██████▋   | 80/119 [00:01<00:00, 73.34it/s][A
 74%|███████▍  | 88/119 [00:01<00:00, 71.91it/s][A
 81%|████████  | 96/119 [00:01<00:00, 72.13it/s][A
 87%|████████▋ | 104/119 [00:01<00:00, 74.32it/s][A
 94%|█████████▍| 112/119 [00:01<00:00, 72.69it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:30<00:39,  9.07it/s]
100%|██████████| 119/119 [00:01<00:00, 72.69it/s][A
                                                 [A 40%|████      | 239/595 [00:30<02:51,  2.08it/s] 40%|████      | 240/595 [00:30<02:18,  2.57it/s] 41%|████      | 241/595 [00:31<01:52,  3.16it/s] 41%|████      | 242/595 [00:31<01:32,  3.82it/s] 41%|████      | 243/595 [00:31<01:16,  4.60it/s] 41%|████      | 244/595 [00:31<01:05,  5.33it/s] 41%|████      | 245/595 [00:31<00:58,  6.02it/s] 41%|████▏     | 246/595 [00:31<00:52,  6.68it/s] 42%|████▏     | 247/595 [00:31<00:48,  7.22it/s] 42%|████▏     | 248/595 [00:31<00:44,  7.72it/s] 42%|████▏     | 249/595 [00:31<00:42,  8.09it/s] 42%|████▏     | 250/595 [00:32<00:40,  8.52it/s] 42%|████▏     | 251/595 [00:32<00:40,  8.60it/s] 42%|████▏     | 252/595 [00:32<00:39,  8.72it/s] 43%|████▎     | 253/595 [00:32<00:38,  8.82it/s] 43%|████▎     | 254/595 [00:32<00:37,  9.03it/s] 43%|████▎     | 255/595 [00:32<00:37,  9.04it/s] 43%|████▎     | 256/595 [00:32<00:37,  9.02it/s] 43%|████▎     | 257/595 [00:32<00:37,  9.08it/s] 43%|████▎     | 258/595 [00:32<00:37,  9.05it/s] 44%|████▎     | 259/595 [00:33<00:37,  9.00it/s] 44%|████▎     | 260/595 [00:33<00:37,  9.02it/s] 44%|████▍     | 261/595 [00:33<00:36,  9.13it/s] 44%|████▍     | 262/595 [00:33<00:36,  9.05it/s] 44%|████▍     | 263/595 [00:33<00:36,  9.04it/s] 44%|████▍     | 264/595 [00:33<00:36,  9.15it/s] 45%|████▍     | 265/595 [00:33<00:36,  9.14it/s] 45%|████▍     | 266/595 [00:33<00:36,  9.12it/s] 45%|████▍     | 267/595 [00:33<00:36,  9.02it/s] 45%|████▌     | 268/595 [00:34<00:35,  9.23it/s] 45%|████▌     | 269/595 [00:34<00:35,  9.13it/s] 45%|████▌     | 270/595 [00:34<00:35,  9.08it/s] 46%|████▌     | 271/595 [00:34<00:35,  9.01it/s] 46%|████▌     | 272/595 [00:34<00:35,  9.00it/s] 46%|████▌     | 273/595 [00:34<00:35,  9.02it/s] 46%|████▌     | 274/595 [00:34<00:35,  8.95it/s] 46%|████▌     | 275/595 [00:34<00:34,  9.18it/s] 46%|████▋     | 276/595 [00:34<00:35,  9.07it/s] 47%|████▋     | 277/595 [00:35<00:35,  8.99it/s] 47%|████▋     | 278/595 [00:35<00:35,  8.94it/s] 47%|████▋     | 279/595 [00:35<00:35,  8.99it/s] 47%|████▋     | 280/595 [00:35<00:35,  8.99it/s] 47%|████▋     | 281/595 [00:35<00:34,  8.97it/s] 47%|████▋     | 282/595 [00:35<00:34,  9.16it/s] 48%|████▊     | 283/595 [00:35<00:34,  9.02it/s] 48%|████▊     | 284/595 [00:35<00:34,  8.94it/s] 48%|████▊     | 285/595 [00:35<00:34,  8.91it/s] 48%|████▊     | 286/595 [00:36<00:34,  8.96it/s] 48%|████▊     | 287/595 [00:36<00:34,  8.92it/s] 48%|████▊     | 288/595 [00:36<00:34,  8.98it/s] 49%|████▊     | 289/595 [00:36<00:33,  9.13it/s] 49%|████▊     | 290/595 [00:36<00:33,  9.11it/s] 49%|████▉     | 291/595 [00:36<00:33,  9.07it/s] 49%|████▉     | 292/595 [00:36<00:33,  8.97it/s] 49%|████▉     | 293/595 [00:36<00:33,  9.04it/s] 49%|████▉     | 294/595 [00:36<00:33,  8.88it/s] 50%|████▉     | 295/595 [00:37<00:33,  8.87it/s] 50%|████▉     | 296/595 [00:37<00:33,  9.01it/s] 50%|████▉     | 297/595 [00:37<00:33,  9.02it/s] 50%|█████     | 298/595 [00:37<00:32,  9.09it/s] 50%|█████     | 299/595 [00:37<00:32,  8.98it/s] 50%|█████     | 300/595 [00:37<00:32,  9.14it/s] 51%|█████     | 301/595 [00:37<00:32,  9.00it/s] 51%|█████     | 302/595 [00:37<00:32,  8.98it/s] 51%|█████     | 303/595 [00:37<00:32,  8.88it/s] 51%|█████     | 304/595 [00:38<00:32,  8.94it/s] 51%|█████▏    | 305/595 [00:38<00:32,  8.98it/s] 51%|█████▏    | 306/595 [00:38<00:32,  8.92it/s] 52%|█████▏    | 307/595 [00:38<00:31,  9.16it/s] 52%|█████▏    | 308/595 [00:38<00:31,  9.05it/s] 52%|█████▏    | 309/595 [00:38<00:31,  8.96it/s] 52%|█████▏    | 310/595 [00:38<00:32,  8.90it/s] 52%|█████▏    | 311/595 [00:38<00:31,  9.03it/s] 52%|█████▏    | 312/595 [00:38<00:31,  8.98it/s] 53%|█████▎    | 313/595 [00:39<00:31,  8.97it/s] 53%|█████▎    | 314/595 [00:39<00:30,  9.09it/s] 53%|█████▎    | 315/595 [00:39<00:30,  9.05it/s] 53%|█████▎    | 316/595 [00:39<00:31,  9.00it/s] 53%|█████▎    | 317/595 [00:39<00:30,  9.01it/s] 53%|█████▎    | 318/595 [00:39<00:30,  9.05it/s] 54%|█████▎    | 319/595 [00:39<00:30,  9.07it/s] 54%|█████▍    | 320/595 [00:39<00:30,  9.03it/s] 54%|█████▍    | 321/595 [00:39<00:29,  9.15it/s] 54%|█████▍    | 322/595 [00:40<00:29,  9.13it/s] 54%|█████▍    | 323/595 [00:40<00:29,  9.11it/s] 54%|█████▍    | 324/595 [00:40<00:30,  9.02it/s] 55%|█████▍    | 325/595 [00:40<00:29,  9.22it/s] 55%|█████▍    | 326/595 [00:40<00:29,  9.12it/s] 55%|█████▍    | 327/595 [00:40<00:29,  9.08it/s] 55%|█████▌    | 328/595 [00:40<00:29,  9.07it/s] 55%|█████▌    | 329/595 [00:40<00:29,  9.05it/s] 55%|█████▌    | 330/595 [00:40<00:29,  8.96it/s] 56%|█████▌    | 331/595 [00:41<00:29,  9.02it/s] 56%|█████▌    | 332/595 [00:41<00:28,  9.10it/s] 56%|█████▌    | 333/595 [00:41<00:28,  9.05it/s] 56%|█████▌    | 334/595 [00:41<00:29,  8.95it/s] 56%|█████▋    | 335/595 [00:41<00:28,  9.11it/s] 56%|█████▋    | 336/595 [00:41<00:28,  9.12it/s] 57%|█████▋    | 337/595 [00:41<00:28,  9.03it/s] 57%|█████▋    | 338/595 [00:41<00:28,  8.97it/s] 57%|█████▋    | 339/595 [00:41<00:28,  9.08it/s] 57%|█████▋    | 340/595 [00:42<00:28,  9.01it/s] 57%|█████▋    | 341/595 [00:42<00:28,  8.94it/s] 57%|█████▋    | 342/595 [00:42<00:27,  9.07it/s] 58%|█████▊    | 343/595 [00:42<00:27,  9.07it/s] 58%|█████▊    | 344/595 [00:42<00:27,  9.08it/s] 58%|█████▊    | 345/595 [00:42<00:27,  9.02it/s] 58%|█████▊    | 346/595 [00:42<00:27,  9.14it/s] 58%|█████▊    | 347/595 [00:42<00:27,  9.05it/s] 58%|█████▊    | 348/595 [00:42<00:27,  9.05it/s] 59%|█████▊    | 349/595 [00:43<00:27,  9.01it/s] 59%|█████▉    | 350/595 [00:43<00:27,  9.03it/s] 59%|█████▉    | 351/595 [00:43<00:26,  9.04it/s] 59%|█████▉    | 352/595 [00:43<00:27,  8.99it/s] 59%|█████▉    | 353/595 [00:43<00:26,  9.21it/s] 59%|█████▉    | 354/595 [00:43<00:26,  9.11it/s] 60%|█████▉    | 355/595 [00:43<00:26,  8.98it/s] 60%|█████▉    | 356/595 [00:43<00:26,  9.06it/s]                                                  60%|██████    | 357/595 [00:43<00:26,  9.06it/s][INFO|trainer.py:755] 2023-11-15 20:51:55,883 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:51:55,885 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:51:55,885 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:51:55,885 >>   Batch size = 8
{'eval_loss': 0.4410237967967987, 'eval_accuracy': 0.8158730158730159, 'eval_micro_f1': 0.815873015873016, 'eval_macro_f1': 0.7496390549022127, 'eval_runtime': 1.6707, 'eval_samples_per_second': 565.617, 'eval_steps_per_second': 71.226, 'epoch': 2.0}
{'loss': 0.3297, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 78.25it/s][A
 14%|█▍        | 17/119 [00:00<00:01, 73.22it/s][A
 21%|██        | 25/119 [00:00<00:01, 72.08it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 74.96it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 74.30it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 73.69it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 75.51it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 73.41it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 71.61it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 71.16it/s][A
 76%|███████▋  | 91/119 [00:01<00:00, 73.46it/s][A
 83%|████████▎ | 99/119 [00:01<00:00, 72.89it/s][A
 90%|████████▉ | 107/119 [00:01<00:00, 72.76it/s][A
 97%|█████████▋| 115/119 [00:01<00:00, 74.38it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:45<00:26,  9.06it/s]
100%|██████████| 119/119 [00:01<00:00, 74.38it/s][A
                                                 [A 60%|██████    | 358/595 [00:45<01:53,  2.09it/s] 60%|██████    | 359/595 [00:45<01:31,  2.58it/s] 61%|██████    | 360/595 [00:45<01:13,  3.19it/s] 61%|██████    | 361/595 [00:45<01:00,  3.85it/s] 61%|██████    | 362/595 [00:46<00:50,  4.58it/s] 61%|██████    | 363/595 [00:46<00:43,  5.32it/s] 61%|██████    | 364/595 [00:46<00:38,  6.06it/s] 61%|██████▏   | 365/595 [00:46<00:34,  6.67it/s] 62%|██████▏   | 366/595 [00:46<00:31,  7.17it/s] 62%|██████▏   | 367/595 [00:46<00:29,  7.70it/s] 62%|██████▏   | 368/595 [00:46<00:28,  8.02it/s] 62%|██████▏   | 369/595 [00:46<00:27,  8.30it/s] 62%|██████▏   | 370/595 [00:46<00:26,  8.52it/s] 62%|██████▏   | 371/595 [00:47<00:25,  8.84it/s] 63%|██████▎   | 372/595 [00:47<00:25,  8.83it/s] 63%|██████▎   | 373/595 [00:47<00:25,  8.84it/s] 63%|██████▎   | 374/595 [00:47<00:25,  8.84it/s] 63%|██████▎   | 375/595 [00:47<00:24,  8.84it/s] 63%|██████▎   | 376/595 [00:47<00:24,  8.84it/s] 63%|██████▎   | 377/595 [00:47<00:24,  8.86it/s] 64%|██████▎   | 378/595 [00:47<00:24,  9.04it/s] 64%|██████▎   | 379/595 [00:47<00:24,  8.95it/s] 64%|██████▍   | 380/595 [00:48<00:24,  8.88it/s] 64%|██████▍   | 381/595 [00:48<00:24,  8.83it/s] 64%|██████▍   | 382/595 [00:48<00:23,  8.99it/s] 64%|██████▍   | 383/595 [00:48<00:23,  8.91it/s] 65%|██████▍   | 384/595 [00:48<00:23,  8.85it/s] 65%|██████▍   | 385/595 [00:48<00:23,  8.91it/s] 65%|██████▍   | 386/595 [00:48<00:23,  8.97it/s] 65%|██████▌   | 387/595 [00:48<00:23,  8.92it/s] 65%|██████▌   | 388/595 [00:48<00:23,  8.97it/s] 65%|██████▌   | 389/595 [00:49<00:22,  9.14it/s] 66%|██████▌   | 390/595 [00:49<00:22,  9.03it/s] 66%|██████▌   | 391/595 [00:49<00:22,  9.01it/s] 66%|██████▌   | 392/595 [00:49<00:22,  8.98it/s] 66%|██████▌   | 393/595 [00:49<00:22,  8.98it/s] 66%|██████▌   | 394/595 [00:49<00:22,  8.92it/s] 66%|██████▋   | 395/595 [00:49<00:22,  8.94it/s] 67%|██████▋   | 396/595 [00:49<00:22,  8.99it/s] 67%|██████▋   | 397/595 [00:49<00:21,  9.01it/s] 67%|██████▋   | 398/595 [00:50<00:22,  8.94it/s] 67%|██████▋   | 399/595 [00:50<00:22,  8.89it/s] 67%|██████▋   | 400/595 [00:50<00:21,  8.95it/s] 67%|██████▋   | 401/595 [00:50<00:21,  8.88it/s] 68%|██████▊   | 402/595 [00:50<00:21,  8.84it/s] 68%|██████▊   | 403/595 [00:50<00:21,  9.00it/s] 68%|██████▊   | 404/595 [00:50<00:21,  8.97it/s] 68%|██████▊   | 405/595 [00:50<00:21,  9.00it/s] 68%|██████▊   | 406/595 [00:50<00:21,  8.95it/s] 68%|██████▊   | 407/595 [00:51<00:20,  9.02it/s] 69%|██████▊   | 408/595 [00:51<00:20,  8.96it/s] 69%|██████▊   | 409/595 [00:51<00:20,  8.86it/s] 69%|██████▉   | 410/595 [00:51<00:20,  8.97it/s] 69%|██████▉   | 411/595 [00:51<00:20,  8.98it/s] 69%|██████▉   | 412/595 [00:51<00:20,  9.04it/s] 69%|██████▉   | 413/595 [00:51<00:20,  8.97it/s] 70%|██████▉   | 414/595 [00:51<00:19,  9.17it/s] 70%|██████▉   | 415/595 [00:51<00:19,  9.09it/s] 70%|██████▉   | 416/595 [00:52<00:19,  9.06it/s] 70%|███████   | 417/595 [00:52<00:19,  8.99it/s] 70%|███████   | 418/595 [00:52<00:19,  9.01it/s] 70%|███████   | 419/595 [00:52<00:19,  9.03it/s] 71%|███████   | 420/595 [00:52<00:19,  9.05it/s] 71%|███████   | 421/595 [00:52<00:18,  9.16it/s] 71%|███████   | 422/595 [00:52<00:19,  9.08it/s] 71%|███████   | 423/595 [00:52<00:19,  8.98it/s] 71%|███████▏  | 424/595 [00:52<00:19,  8.94it/s] 71%|███████▏  | 425/595 [00:53<00:18,  9.03it/s] 72%|███████▏  | 426/595 [00:53<00:18,  8.95it/s] 72%|███████▏  | 427/595 [00:53<00:18,  8.97it/s] 72%|███████▏  | 428/595 [00:53<00:18,  9.08it/s] 72%|███████▏  | 429/595 [00:53<00:18,  9.02it/s] 72%|███████▏  | 430/595 [00:53<00:18,  8.95it/s] 72%|███████▏  | 431/595 [00:53<00:18,  8.99it/s] 73%|███████▎  | 432/595 [00:53<00:17,  9.11it/s] 73%|███████▎  | 433/595 [00:53<00:17,  9.07it/s] 73%|███████▎  | 434/595 [00:54<00:17,  9.01it/s] 73%|███████▎  | 435/595 [00:54<00:17,  9.09it/s] 73%|███████▎  | 436/595 [00:54<00:17,  9.03it/s] 73%|███████▎  | 437/595 [00:54<00:17,  8.98it/s] 74%|███████▎  | 438/595 [00:54<00:17,  8.89it/s] 74%|███████▍  | 439/595 [00:54<00:17,  9.00it/s] 74%|███████▍  | 440/595 [00:54<00:17,  9.03it/s] 74%|███████▍  | 441/595 [00:54<00:17,  8.97it/s] 74%|███████▍  | 442/595 [00:54<00:16,  9.09it/s] 74%|███████▍  | 443/595 [00:55<00:16,  9.08it/s] 75%|███████▍  | 444/595 [00:55<00:16,  9.04it/s] 75%|███████▍  | 445/595 [00:55<00:16,  8.98it/s] 75%|███████▍  | 446/595 [00:55<00:16,  9.02it/s] 75%|███████▌  | 447/595 [00:55<00:16,  9.08it/s] 75%|███████▌  | 448/595 [00:55<00:16,  8.99it/s] 75%|███████▌  | 449/595 [00:55<00:16,  9.09it/s] 76%|███████▌  | 450/595 [00:55<00:16,  9.01it/s] 76%|███████▌  | 451/595 [00:55<00:16,  8.97it/s] 76%|███████▌  | 452/595 [00:56<00:16,  8.89it/s] 76%|███████▌  | 453/595 [00:56<00:15,  8.92it/s] 76%|███████▋  | 454/595 [00:56<00:15,  8.96it/s] 76%|███████▋  | 455/595 [00:56<00:15,  8.85it/s] 77%|███████▋  | 456/595 [00:56<00:15,  8.96it/s] 77%|███████▋  | 457/595 [00:56<00:15,  8.92it/s] 77%|███████▋  | 458/595 [00:56<00:15,  8.84it/s] 77%|███████▋  | 459/595 [00:56<00:15,  8.93it/s] 77%|███████▋  | 460/595 [00:56<00:15,  8.90it/s] 77%|███████▋  | 461/595 [00:57<00:15,  8.87it/s] 78%|███████▊  | 462/595 [00:57<00:15,  8.87it/s] 78%|███████▊  | 463/595 [00:57<00:14,  8.89it/s] 78%|███████▊  | 464/595 [00:57<00:14,  8.92it/s] 78%|███████▊  | 465/595 [00:57<00:14,  8.96it/s] 78%|███████▊  | 466/595 [00:57<00:14,  9.10it/s] 78%|███████▊  | 467/595 [00:57<00:14,  9.02it/s] 79%|███████▊  | 468/595 [00:57<00:14,  9.00it/s] 79%|███████▉  | 469/595 [00:57<00:14,  8.94it/s] 79%|███████▉  | 470/595 [00:58<00:14,  8.89it/s] 79%|███████▉  | 471/595 [00:58<00:13,  8.91it/s] 79%|███████▉  | 472/595 [00:58<00:13,  8.86it/s] 79%|███████▉  | 473/595 [00:58<00:13,  8.94it/s] 80%|███████▉  | 474/595 [00:58<00:13,  8.92it/s] 80%|███████▉  | 475/595 [00:58<00:13,  8.92it/s]                                                  80%|████████  | 476/595 [00:58<00:13,  8.92it/s][INFO|trainer.py:755] 2023-11-15 20:52:10,733 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:52:10,734 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:52:10,735 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:52:10,735 >>   Batch size = 8
{'eval_loss': 0.4088943302631378, 'eval_accuracy': 0.8497354497354498, 'eval_micro_f1': 0.8497354497354498, 'eval_macro_f1': 0.791541098473965, 'eval_runtime': 1.6627, 'eval_samples_per_second': 568.339, 'eval_steps_per_second': 71.569, 'epoch': 3.0}
{'loss': 0.2313, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 81.01it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 79.00it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 75.16it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 74.31it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 73.20it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 71.44it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 73.46it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 72.55it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 72.17it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 72.02it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 72.16it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 73.17it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 72.73it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 73.30it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [01:00<00:13,  8.92it/s]
100%|██████████| 119/119 [00:01<00:00, 73.30it/s][A
                                                 [A 80%|████████  | 477/595 [01:00<00:56,  2.08it/s] 80%|████████  | 478/595 [01:00<00:45,  2.56it/s] 81%|████████  | 479/595 [01:00<00:36,  3.15it/s] 81%|████████  | 480/595 [01:00<00:30,  3.83it/s] 81%|████████  | 481/595 [01:00<00:25,  4.56it/s] 81%|████████  | 482/595 [01:01<00:21,  5.31it/s] 81%|████████  | 483/595 [01:01<00:18,  6.04it/s] 81%|████████▏ | 484/595 [01:01<00:16,  6.67it/s] 82%|████████▏ | 485/595 [01:01<00:15,  7.24it/s] 82%|████████▏ | 486/595 [01:01<00:14,  7.65it/s] 82%|████████▏ | 487/595 [01:01<00:13,  7.99it/s] 82%|████████▏ | 488/595 [01:01<00:12,  8.32it/s] 82%|████████▏ | 489/595 [01:01<00:12,  8.55it/s] 82%|████████▏ | 490/595 [01:01<00:12,  8.69it/s] 83%|████████▎ | 491/595 [01:02<00:11,  8.71it/s] 83%|████████▎ | 492/595 [01:02<00:11,  8.90it/s] 83%|████████▎ | 493/595 [01:02<00:11,  8.90it/s] 83%|████████▎ | 494/595 [01:02<00:11,  8.89it/s] 83%|████████▎ | 495/595 [01:02<00:11,  8.85it/s] 83%|████████▎ | 496/595 [01:02<00:11,  8.90it/s] 84%|████████▎ | 497/595 [01:02<00:11,  8.90it/s] 84%|████████▎ | 498/595 [01:02<00:10,  8.86it/s] 84%|████████▍ | 499/595 [01:02<00:10,  8.91it/s] 84%|████████▍ | 500/595 [01:03<00:10,  8.85it/s] 84%|████████▍ | 501/595 [01:03<00:10,  8.88it/s] 84%|████████▍ | 502/595 [01:03<00:10,  8.95it/s] 85%|████████▍ | 503/595 [01:03<00:10,  8.92it/s] 85%|████████▍ | 504/595 [01:03<00:10,  8.92it/s] 85%|████████▍ | 505/595 [01:03<00:10,  8.87it/s] 85%|████████▌ | 506/595 [01:03<00:10,  8.89it/s] 85%|████████▌ | 507/595 [01:03<00:09,  8.89it/s] 85%|████████▌ | 508/595 [01:03<00:09,  8.78it/s] 86%|████████▌ | 509/595 [01:04<00:09,  8.89it/s] 86%|████████▌ | 510/595 [01:04<00:09,  8.81it/s] 86%|████████▌ | 511/595 [01:04<00:09,  8.77it/s] 86%|████████▌ | 512/595 [01:04<00:09,  8.95it/s] 86%|████████▌ | 513/595 [01:04<00:09,  8.93it/s] 86%|████████▋ | 514/595 [01:04<00:09,  8.91it/s] 87%|████████▋ | 515/595 [01:04<00:08,  8.90it/s] 87%|████████▋ | 516/595 [01:04<00:08,  8.89it/s] 87%|████████▋ | 517/595 [01:04<00:08,  8.89it/s] 87%|████████▋ | 518/595 [01:05<00:08,  8.83it/s] 87%|████████▋ | 519/595 [01:05<00:08,  8.86it/s] 87%|████████▋ | 520/595 [01:05<00:08,  8.90it/s] 88%|████████▊ | 521/595 [01:05<00:08,  8.91it/s] 88%|████████▊ | 522/595 [01:05<00:08,  9.03it/s] 88%|████████▊ | 523/595 [01:05<00:08,  8.91it/s] 88%|████████▊ | 524/595 [01:05<00:07,  8.89it/s] 88%|████████▊ | 525/595 [01:05<00:07,  8.79it/s] 88%|████████▊ | 526/595 [01:05<00:07,  8.80it/s] 89%|████████▊ | 527/595 [01:06<00:07,  8.80it/s] 89%|████████▊ | 528/595 [01:06<00:07,  8.85it/s] 89%|████████▉ | 529/595 [01:06<00:07,  8.92it/s] 89%|████████▉ | 530/595 [01:06<00:07,  8.86it/s] 89%|████████▉ | 531/595 [01:06<00:07,  8.80it/s] 89%|████████▉ | 532/595 [01:06<00:07,  8.82it/s] 90%|████████▉ | 533/595 [01:06<00:07,  8.82it/s] 90%|████████▉ | 534/595 [01:06<00:06,  8.79it/s] 90%|████████▉ | 535/595 [01:06<00:06,  8.80it/s] 90%|█████████ | 536/595 [01:07<00:06,  8.73it/s] 90%|█████████ | 537/595 [01:07<00:06,  8.76it/s] 90%|█████████ | 538/595 [01:07<00:06,  8.79it/s] 91%|█████████ | 539/595 [01:07<00:06,  8.85it/s] 91%|█████████ | 540/595 [01:07<00:06,  8.79it/s] 91%|█████████ | 541/595 [01:07<00:06,  8.84it/s] 91%|█████████ | 542/595 [01:07<00:06,  8.81it/s] 91%|█████████▏| 543/595 [01:07<00:05,  8.82it/s] 91%|█████████▏| 544/595 [01:08<00:05,  8.83it/s] 92%|█████████▏| 545/595 [01:08<00:05,  8.78it/s] 92%|█████████▏| 546/595 [01:08<00:05,  8.72it/s] 92%|█████████▏| 547/595 [01:08<00:05,  8.68it/s] 92%|█████████▏| 548/595 [01:08<00:05,  8.66it/s] 92%|█████████▏| 549/595 [01:08<00:05,  8.76it/s] 92%|█████████▏| 550/595 [01:08<00:05,  8.77it/s] 93%|█████████▎| 551/595 [01:08<00:05,  8.65it/s] 93%|█████████▎| 552/595 [01:08<00:04,  8.71it/s] 93%|█████████▎| 553/595 [01:09<00:04,  8.73it/s] 93%|█████████▎| 554/595 [01:09<00:04,  8.72it/s] 93%|█████████▎| 555/595 [01:09<00:04,  8.62it/s] 93%|█████████▎| 556/595 [01:09<00:04,  8.75it/s] 94%|█████████▎| 557/595 [01:09<00:04,  8.69it/s] 94%|█████████▍| 558/595 [01:09<00:04,  8.72it/s] 94%|█████████▍| 559/595 [01:09<00:04,  8.82it/s] 94%|█████████▍| 560/595 [01:09<00:04,  8.71it/s] 94%|█████████▍| 561/595 [01:09<00:03,  8.75it/s] 94%|█████████▍| 562/595 [01:10<00:03,  8.69it/s] 95%|█████████▍| 563/595 [01:10<00:03,  8.77it/s] 95%|█████████▍| 564/595 [01:10<00:03,  8.79it/s] 95%|█████████▍| 565/595 [01:10<00:03,  8.76it/s] 95%|█████████▌| 566/595 [01:10<00:03,  8.82it/s] 95%|█████████▌| 567/595 [01:10<00:03,  8.78it/s] 95%|█████████▌| 568/595 [01:10<00:03,  8.86it/s] 96%|█████████▌| 569/595 [01:10<00:02,  8.89it/s] 96%|█████████▌| 570/595 [01:10<00:02,  8.79it/s] 96%|█████████▌| 571/595 [01:11<00:02,  8.77it/s] 96%|█████████▌| 572/595 [01:11<00:02,  8.78it/s] 96%|█████████▋| 573/595 [01:11<00:02,  8.74it/s] 96%|█████████▋| 574/595 [01:11<00:02,  8.67it/s] 97%|█████████▋| 575/595 [01:11<00:02,  8.70it/s] 97%|█████████▋| 576/595 [01:11<00:02,  8.72it/s] 97%|█████████▋| 577/595 [01:11<00:02,  8.73it/s] 97%|█████████▋| 578/595 [01:11<00:01,  8.74it/s] 97%|█████████▋| 579/595 [01:12<00:01,  8.77it/s] 97%|█████████▋| 580/595 [01:12<00:01,  8.76it/s] 98%|█████████▊| 581/595 [01:12<00:01,  8.78it/s] 98%|█████████▊| 582/595 [01:12<00:01,  8.75it/s] 98%|█████████▊| 583/595 [01:12<00:01,  8.82it/s] 98%|█████████▊| 584/595 [01:12<00:01,  8.78it/s] 98%|█████████▊| 585/595 [01:12<00:01,  8.74it/s] 98%|█████████▊| 586/595 [01:12<00:01,  8.75it/s] 99%|█████████▊| 587/595 [01:12<00:00,  8.74it/s] 99%|█████████▉| 588/595 [01:13<00:00,  8.71it/s] 99%|█████████▉| 589/595 [01:13<00:00,  8.74it/s] 99%|█████████▉| 590/595 [01:13<00:00,  8.69it/s] 99%|█████████▉| 591/595 [01:13<00:00,  8.75it/s] 99%|█████████▉| 592/595 [01:13<00:00,  8.79it/s]100%|█████████▉| 593/595 [01:13<00:00,  8.79it/s]100%|█████████▉| 594/595 [01:13<00:00,  8.88it/s]                                                 100%|██████████| 595/595 [01:13<00:00,  8.88it/s][INFO|trainer.py:755] 2023-11-15 20:52:25,809 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:52:25,811 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:52:25,811 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:52:25,811 >>   Batch size = 8
{'eval_loss': 0.47342589497566223, 'eval_accuracy': 0.8486772486772487, 'eval_micro_f1': 0.8486772486772488, 'eval_macro_f1': 0.7894793946840917, 'eval_runtime': 1.6667, 'eval_samples_per_second': 566.987, 'eval_steps_per_second': 71.398, 'epoch': 4.0}
{'loss': 0.1869, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 79.48it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 73.65it/s][A
 20%|██        | 24/119 [00:00<00:01, 73.00it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 71.06it/s][A
 34%|███▎      | 40/119 [00:00<00:01, 72.47it/s][A
 40%|████      | 48/119 [00:00<00:00, 71.07it/s][A
 47%|████▋     | 56/119 [00:00<00:00, 70.44it/s][A
 54%|█████▍    | 64/119 [00:00<00:00, 70.84it/s][A
 61%|██████    | 72/119 [00:01<00:00, 70.11it/s][A
 67%|██████▋   | 80/119 [00:01<00:00, 71.15it/s][A
 74%|███████▍  | 88/119 [00:01<00:00, 71.80it/s][A
 81%|████████  | 96/119 [00:01<00:00, 73.00it/s][A
 87%|████████▋ | 104/119 [00:01<00:00, 70.92it/s][A
 94%|█████████▍| 112/119 [00:01<00:00, 71.08it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:15<00:00,  8.88it/s]
100%|██████████| 119/119 [00:01<00:00, 71.08it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 20:52:27,523 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:15<00:00,  8.88it/s]100%|██████████| 595/595 [01:15<00:00,  7.88it/s]
[INFO|trainer.py:2855] 2023-11-15 20:52:27,527 >> Saving model checkpoint to ./result/restaurant_roberta-base_adapter__seed3
[INFO|configuration_utils.py:460] 2023-11-15 20:52:27,529 >> Configuration saved in ./result/restaurant_roberta-base_adapter__seed3/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:52:28,695 >> Model weights saved in ./result/restaurant_roberta-base_adapter__seed3/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:52:28,698 >> tokenizer config file saved in ./result/restaurant_roberta-base_adapter__seed3/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:52:28,700 >> Special tokens file saved in ./result/restaurant_roberta-base_adapter__seed3/special_tokens_map.json
{'eval_loss': 0.4444938600063324, 'eval_accuracy': 0.8518518518518519, 'eval_micro_f1': 0.8518518518518519, 'eval_macro_f1': 0.7978610935798188, 'eval_runtime': 1.7088, 'eval_samples_per_second': 553.009, 'eval_steps_per_second': 69.638, 'epoch': 5.0}
{'train_runtime': 75.4895, 'train_samples_per_second': 250.167, 'train_steps_per_second': 7.882, 'train_loss': 0.3911039432557691, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3911
  train_runtime            = 0:01:15.48
  train_samples            =       3777
  train_samples_per_second =    250.167
  train_steps_per_second   =      7.882
11/15/2023 20:52:28 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:52:28,795 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:52:28,797 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:52:28,797 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:52:28,797 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  8%|▊         | 9/119 [00:00<00:01, 77.92it/s] 14%|█▍        | 17/119 [00:00<00:01, 74.93it/s] 21%|██        | 25/119 [00:00<00:01, 73.09it/s] 28%|██▊       | 33/119 [00:00<00:01, 73.07it/s] 34%|███▍      | 41/119 [00:00<00:01, 72.20it/s] 41%|████      | 49/119 [00:00<00:00, 71.59it/s] 48%|████▊     | 57/119 [00:00<00:00, 70.66it/s] 55%|█████▍    | 65/119 [00:00<00:00, 70.22it/s] 61%|██████▏   | 73/119 [00:01<00:00, 71.05it/s] 68%|██████▊   | 81/119 [00:01<00:00, 71.30it/s] 75%|███████▍  | 89/119 [00:01<00:00, 70.10it/s] 82%|████████▏ | 97/119 [00:01<00:00, 69.86it/s] 88%|████████▊ | 105/119 [00:01<00:00, 70.85it/s] 95%|█████████▍| 113/119 [00:01<00:00, 71.15it/s]100%|██████████| 119/119 [00:01<00:00, 70.31it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8519
  eval_loss               =     0.4445
  eval_macro_f1           =     0.7979
  eval_micro_f1           =     0.8519
  eval_runtime            = 0:00:01.71
  eval_samples            =        945
  eval_samples_per_second =    552.092
  eval_steps_per_second   =     69.523
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▅████
wandb:                      eval/loss █▂▁▄▃▃
wandb:                  eval/macro_f1 ▁▆████
wandb:                  eval/micro_f1 ▁▅████
wandb:                   eval/runtime ▅▂▁▂██
wandb:        eval/samples_per_second ▄▇█▇▁▁
wandb:          eval/steps_per_second ▄▇█▇▁▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.85185
wandb:                      eval/loss 0.44449
wandb:                  eval/macro_f1 0.79786
wandb:                  eval/micro_f1 0.85185
wandb:                   eval/runtime 1.7117
wandb:        eval/samples_per_second 552.092
wandb:          eval/steps_per_second 69.523
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1869
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.3911
wandb:            train/train_runtime 75.4895
wandb: train/train_samples_per_second 250.167
wandb:   train/train_steps_per_second 7.882
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_204954-61j84c0o
wandb: Find logs at: ./wandb/offline-run-20231115_204954-61j84c0o/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_bert-base-cased_adapter__seed3/runs/Nov15_20-52-41_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_bert-base-cased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_bert-base-cased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:52:41 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:52:41 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_bert-base-cased_adapter__seed3/runs/Nov15_20-52-40_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_bert-base-cased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_bert-base-cased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  87%|████████▋ | 4126/4722 [00:00<00:00, 40404.80 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 39801.90 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:52:56,791 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:52:56,801 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 20:53:06,818 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:53:06,819 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:53:06,822 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:53:06,822 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:53:06,822 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:53:06,823 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:53:06,823 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 20:53:06,824 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:53:06,824 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:53:27,012 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:53:27,709 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:53:27,709 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 23825.65 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 23528.30 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 27027.55 examples/s]
11/15/2023 20:53:27 - INFO - __main__ - Sample 1265 of the training set: {'text': 'cuisine <SEP> I love when restaurants think using fancy expensive ingrediants makes the food fine cuisine, even with no idea how to use them.', 'label': 0, 'input_ids': [101, 13994, 133, 12342, 2101, 135, 146, 1567, 1165, 7724, 1341, 1606, 13305, 5865, 16664, 4359, 13789, 1116, 2228, 1103, 2094, 2503, 13994, 117, 1256, 1114, 1185, 1911, 1293, 1106, 1329, 1172, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:53:27 - INFO - __main__ - Sample 1178 of the training set: {'text': "table <SEP> I went with 5 friends and we lingered at the table for a bit and didn't feel rushed at all even though there was a wait.", 'label': 1, 'input_ids': [101, 1952, 133, 12342, 2101, 135, 146, 1355, 1114, 126, 2053, 1105, 1195, 18942, 1120, 1103, 1952, 1111, 170, 2113, 1105, 1238, 112, 189, 1631, 6169, 1120, 1155, 1256, 1463, 1175, 1108, 170, 3074, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:53:27 - INFO - __main__ - Sample 54 of the training set: {'text': "Halibut <SEP> The Halibut was too salty, dessert was so so (don't waste any of your calories) and service was poor.", 'label': 2, 'input_ids': [101, 12193, 13292, 3818, 133, 12342, 2101, 135, 1109, 12193, 13292, 3818, 1108, 1315, 6870, 1183, 117, 20392, 1108, 1177, 1177, 113, 1274, 112, 189, 5671, 1251, 1104, 1240, 11019, 10885, 1905, 114, 1105, 1555, 1108, 2869, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:53:27 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:53:29,379 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:53:29,386 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:53:29,386 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 20:53:29,386 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:53:29,386 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:53:29,387 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:53:29,387 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:53:29,387 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 20:53:29,388 >>   Number of trainable parameters = 108,312,579
[INFO|integration_utils.py:716] 2023-11-15 20:53:29,389 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<13:58,  1.41s/it]  0%|          | 2/595 [00:01<06:22,  1.55it/s]  1%|          | 3/595 [00:01<03:56,  2.50it/s]  1%|          | 4/595 [00:01<02:49,  3.49it/s]  1%|          | 5/595 [00:01<02:12,  4.46it/s]  1%|          | 6/595 [00:01<01:49,  5.37it/s]  1%|          | 7/595 [00:02<01:35,  6.17it/s]  1%|▏         | 8/595 [00:02<01:25,  6.85it/s]  2%|▏         | 9/595 [00:02<01:19,  7.41it/s]  2%|▏         | 10/595 [00:02<01:15,  7.79it/s]  2%|▏         | 11/595 [00:02<01:12,  8.04it/s]  2%|▏         | 12/595 [00:02<01:10,  8.31it/s]  2%|▏         | 13/595 [00:02<01:08,  8.53it/s]  2%|▏         | 14/595 [00:02<01:07,  8.63it/s]  3%|▎         | 15/595 [00:02<01:06,  8.71it/s]  3%|▎         | 16/595 [00:03<01:06,  8.74it/s]  3%|▎         | 17/595 [00:03<01:05,  8.82it/s]  3%|▎         | 18/595 [00:03<01:04,  8.89it/s]  3%|▎         | 19/595 [00:03<01:04,  8.97it/s]  3%|▎         | 20/595 [00:03<01:03,  9.07it/s]  4%|▎         | 21/595 [00:03<01:03,  9.05it/s]  4%|▎         | 22/595 [00:03<01:04,  8.93it/s]  4%|▍         | 23/595 [00:03<01:04,  8.92it/s]  4%|▍         | 24/595 [00:03<01:03,  8.93it/s]  4%|▍         | 25/595 [00:04<01:03,  8.98it/s]  4%|▍         | 26/595 [00:04<01:03,  8.98it/s]  5%|▍         | 27/595 [00:04<01:03,  9.00it/s]  5%|▍         | 28/595 [00:04<01:03,  8.89it/s]  5%|▍         | 29/595 [00:04<01:03,  8.92it/s]  5%|▌         | 30/595 [00:04<01:02,  8.99it/s]  5%|▌         | 31/595 [00:04<01:02,  9.04it/s]  5%|▌         | 32/595 [00:04<01:02,  9.05it/s]  6%|▌         | 33/595 [00:04<01:02,  9.00it/s]  6%|▌         | 34/595 [00:05<01:01,  9.08it/s]  6%|▌         | 35/595 [00:05<01:02,  9.02it/s]  6%|▌         | 36/595 [00:05<01:02,  8.92it/s]  6%|▌         | 37/595 [00:05<01:01,  9.02it/s]  6%|▋         | 38/595 [00:05<01:01,  9.03it/s]  7%|▋         | 39/595 [00:05<01:01,  9.01it/s]  7%|▋         | 40/595 [00:05<01:01,  8.96it/s]  7%|▋         | 41/595 [00:05<01:01,  8.94it/s]  7%|▋         | 42/595 [00:05<01:01,  8.96it/s]  7%|▋         | 43/595 [00:06<01:01,  8.95it/s]  7%|▋         | 44/595 [00:06<01:00,  9.09it/s]  8%|▊         | 45/595 [00:06<01:00,  9.03it/s]  8%|▊         | 46/595 [00:06<01:00,  9.04it/s]  8%|▊         | 47/595 [00:06<01:00,  8.99it/s]  8%|▊         | 48/595 [00:06<01:01,  8.93it/s]  8%|▊         | 49/595 [00:06<01:00,  8.98it/s]  8%|▊         | 50/595 [00:06<01:00,  9.03it/s]  9%|▊         | 51/595 [00:06<00:59,  9.15it/s]  9%|▊         | 52/595 [00:07<01:00,  9.02it/s]  9%|▉         | 53/595 [00:07<01:00,  9.00it/s]  9%|▉         | 54/595 [00:07<01:00,  8.91it/s]  9%|▉         | 55/595 [00:07<01:00,  8.95it/s]  9%|▉         | 56/595 [00:07<01:00,  8.92it/s] 10%|▉         | 57/595 [00:07<00:59,  8.97it/s] 10%|▉         | 58/595 [00:07<00:59,  9.09it/s] 10%|▉         | 59/595 [00:07<00:59,  9.03it/s] 10%|█         | 60/595 [00:07<00:59,  8.93it/s] 10%|█         | 61/595 [00:08<01:00,  8.83it/s] 10%|█         | 62/595 [00:08<00:59,  8.92it/s] 11%|█         | 63/595 [00:08<00:59,  8.95it/s] 11%|█         | 64/595 [00:08<00:59,  8.89it/s] 11%|█         | 65/595 [00:08<00:58,  9.02it/s] 11%|█         | 66/595 [00:08<00:58,  9.00it/s] 11%|█▏        | 67/595 [00:08<00:58,  9.01it/s] 11%|█▏        | 68/595 [00:08<00:58,  8.97it/s] 12%|█▏        | 69/595 [00:08<00:58,  8.99it/s] 12%|█▏        | 70/595 [00:09<00:57,  9.06it/s] 12%|█▏        | 71/595 [00:09<00:57,  9.07it/s] 12%|█▏        | 72/595 [00:09<00:57,  9.08it/s] 12%|█▏        | 73/595 [00:09<00:58,  8.96it/s] 12%|█▏        | 74/595 [00:09<00:58,  8.98it/s] 13%|█▎        | 75/595 [00:09<00:57,  9.06it/s] 13%|█▎        | 76/595 [00:09<00:57,  9.04it/s] 13%|█▎        | 77/595 [00:09<00:57,  9.06it/s] 13%|█▎        | 78/595 [00:09<00:58,  8.91it/s] 13%|█▎        | 79/595 [00:10<00:58,  8.89it/s] 13%|█▎        | 80/595 [00:10<00:57,  8.97it/s] 14%|█▎        | 81/595 [00:10<00:57,  8.93it/s] 14%|█▍        | 82/595 [00:10<00:56,  9.08it/s] 14%|█▍        | 83/595 [00:10<00:56,  9.06it/s] 14%|█▍        | 84/595 [00:10<00:56,  9.04it/s] 14%|█▍        | 85/595 [00:10<00:56,  8.98it/s] 14%|█▍        | 86/595 [00:10<00:56,  8.94it/s] 15%|█▍        | 87/595 [00:10<00:56,  8.96it/s] 15%|█▍        | 88/595 [00:11<00:56,  8.93it/s] 15%|█▍        | 89/595 [00:11<00:56,  9.03it/s] 15%|█▌        | 90/595 [00:11<00:56,  8.97it/s] 15%|█▌        | 91/595 [00:11<00:56,  8.99it/s] 15%|█▌        | 92/595 [00:11<00:56,  8.98it/s] 16%|█▌        | 93/595 [00:11<00:56,  8.94it/s] 16%|█▌        | 94/595 [00:11<00:55,  8.95it/s] 16%|█▌        | 95/595 [00:11<00:55,  8.97it/s] 16%|█▌        | 96/595 [00:11<00:54,  9.10it/s] 16%|█▋        | 97/595 [00:12<00:55,  9.00it/s] 16%|█▋        | 98/595 [00:12<00:54,  9.06it/s] 17%|█▋        | 99/595 [00:12<00:54,  9.04it/s] 17%|█▋        | 100/595 [00:12<00:54,  9.07it/s] 17%|█▋        | 101/595 [00:12<00:54,  9.09it/s] 17%|█▋        | 102/595 [00:12<00:54,  9.11it/s] 17%|█▋        | 103/595 [00:12<00:53,  9.16it/s] 17%|█▋        | 104/595 [00:12<00:53,  9.10it/s] 18%|█▊        | 105/595 [00:12<00:54,  9.07it/s] 18%|█▊        | 106/595 [00:13<00:53,  9.09it/s] 18%|█▊        | 107/595 [00:13<00:53,  9.08it/s] 18%|█▊        | 108/595 [00:13<00:54,  9.00it/s] 18%|█▊        | 109/595 [00:13<00:53,  9.00it/s] 18%|█▊        | 110/595 [00:13<00:54,  8.96it/s] 19%|█▊        | 111/595 [00:13<00:54,  8.93it/s] 19%|█▉        | 112/595 [00:13<00:53,  8.97it/s] 19%|█▉        | 113/595 [00:13<00:52,  9.10it/s] 19%|█▉        | 114/595 [00:13<00:52,  9.08it/s] 19%|█▉        | 115/595 [00:14<00:53,  9.03it/s] 19%|█▉        | 116/595 [00:14<00:53,  9.02it/s] 20%|█▉        | 117/595 [00:14<00:52,  9.03it/s] 20%|█▉        | 118/595 [00:14<00:52,  9.13it/s]                                                  20%|██        | 119/595 [00:14<00:52,  9.13it/s][INFO|trainer.py:755] 2023-11-15 20:53:43,858 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:53:43,860 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:53:43,860 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:53:43,860 >>   Batch size = 8
{'loss': 0.8186, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 87.70it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 75.04it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 71.23it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 70.78it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 71.83it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 71.11it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 69.49it/s][A
 55%|█████▍    | 65/119 [00:00<00:00, 68.99it/s][A
 61%|██████    | 72/119 [00:01<00:00, 68.80it/s][A
 66%|██████▋   | 79/119 [00:01<00:00, 69.06it/s][A
 73%|███████▎  | 87/119 [00:01<00:00, 70.55it/s][A
 80%|███████▉  | 95/119 [00:01<00:00, 70.60it/s][A
 87%|████████▋ | 103/119 [00:01<00:00, 70.65it/s][A
 93%|█████████▎| 111/119 [00:01<00:00, 69.59it/s][A
 99%|█████████▉| 118/119 [00:01<00:00, 69.57it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:16<00:52,  9.13it/s]
100%|██████████| 119/119 [00:01<00:00, 69.57it/s][A
                                                 [A 20%|██        | 120/595 [00:16<03:56,  2.01it/s] 20%|██        | 121/595 [00:16<03:10,  2.49it/s] 21%|██        | 122/595 [00:16<02:34,  3.06it/s] 21%|██        | 123/595 [00:16<02:06,  3.73it/s] 21%|██        | 124/595 [00:16<01:45,  4.45it/s] 21%|██        | 125/595 [00:16<01:29,  5.24it/s] 21%|██        | 126/595 [00:16<01:18,  5.97it/s] 21%|██▏       | 127/595 [00:17<01:10,  6.64it/s] 22%|██▏       | 128/595 [00:17<01:05,  7.16it/s] 22%|██▏       | 129/595 [00:17<01:00,  7.66it/s] 22%|██▏       | 130/595 [00:17<00:58,  8.01it/s] 22%|██▏       | 131/595 [00:17<00:56,  8.23it/s] 22%|██▏       | 132/595 [00:17<00:54,  8.51it/s] 22%|██▏       | 133/595 [00:17<00:53,  8.66it/s] 23%|██▎       | 134/595 [00:17<00:52,  8.75it/s] 23%|██▎       | 135/595 [00:17<00:51,  8.92it/s] 23%|██▎       | 136/595 [00:18<00:51,  8.91it/s] 23%|██▎       | 137/595 [00:18<00:51,  8.92it/s] 23%|██▎       | 138/595 [00:18<00:51,  8.90it/s] 23%|██▎       | 139/595 [00:18<00:51,  8.94it/s] 24%|██▎       | 140/595 [00:18<00:50,  8.99it/s] 24%|██▎       | 141/595 [00:18<00:50,  9.03it/s] 24%|██▍       | 142/595 [00:18<00:49,  9.06it/s] 24%|██▍       | 143/595 [00:18<00:49,  9.08it/s] 24%|██▍       | 144/595 [00:18<00:50,  9.02it/s] 24%|██▍       | 145/595 [00:19<00:49,  9.10it/s] 25%|██▍       | 146/595 [00:19<00:49,  9.11it/s] 25%|██▍       | 147/595 [00:19<00:49,  9.07it/s] 25%|██▍       | 148/595 [00:19<00:49,  9.05it/s] 25%|██▌       | 149/595 [00:19<00:48,  9.11it/s] 25%|██▌       | 150/595 [00:19<00:48,  9.11it/s] 25%|██▌       | 151/595 [00:19<00:48,  9.12it/s] 26%|██▌       | 152/595 [00:19<00:48,  9.17it/s] 26%|██▌       | 153/595 [00:19<00:48,  9.16it/s] 26%|██▌       | 154/595 [00:20<00:48,  9.04it/s] 26%|██▌       | 155/595 [00:20<00:48,  9.15it/s] 26%|██▌       | 156/595 [00:20<00:48,  9.08it/s] 26%|██▋       | 157/595 [00:20<00:47,  9.13it/s] 27%|██▋       | 158/595 [00:20<00:48,  9.07it/s] 27%|██▋       | 159/595 [00:20<00:48,  9.04it/s] 27%|██▋       | 160/595 [00:20<00:48,  9.01it/s] 27%|██▋       | 161/595 [00:20<00:47,  9.12it/s] 27%|██▋       | 162/595 [00:20<00:46,  9.23it/s] 27%|██▋       | 163/595 [00:21<00:47,  9.13it/s] 28%|██▊       | 164/595 [00:21<00:47,  9.13it/s] 28%|██▊       | 165/595 [00:21<00:47,  9.08it/s] 28%|██▊       | 166/595 [00:21<00:47,  9.11it/s] 28%|██▊       | 167/595 [00:21<00:47,  9.03it/s] 28%|██▊       | 168/595 [00:21<00:47,  8.99it/s] 28%|██▊       | 169/595 [00:21<00:47,  9.00it/s] 29%|██▊       | 170/595 [00:21<00:47,  9.00it/s] 29%|██▊       | 171/595 [00:21<00:46,  9.05it/s] 29%|██▉       | 172/595 [00:22<00:46,  9.13it/s] 29%|██▉       | 173/595 [00:22<00:46,  9.12it/s] 29%|██▉       | 174/595 [00:22<00:46,  8.97it/s] 29%|██▉       | 175/595 [00:22<00:46,  8.96it/s] 30%|██▉       | 176/595 [00:22<00:46,  8.94it/s] 30%|██▉       | 177/595 [00:22<00:46,  8.95it/s] 30%|██▉       | 178/595 [00:22<00:46,  8.97it/s] 30%|███       | 179/595 [00:22<00:46,  8.97it/s] 30%|███       | 180/595 [00:22<00:46,  9.01it/s] 30%|███       | 181/595 [00:23<00:45,  9.01it/s] 31%|███       | 182/595 [00:23<00:45,  9.16it/s] 31%|███       | 183/595 [00:23<00:45,  9.09it/s] 31%|███       | 184/595 [00:23<00:45,  9.03it/s] 31%|███       | 185/595 [00:23<00:45,  9.03it/s] 31%|███▏      | 186/595 [00:23<00:45,  9.07it/s] 31%|███▏      | 187/595 [00:23<00:44,  9.08it/s] 32%|███▏      | 188/595 [00:23<00:45,  9.03it/s] 32%|███▏      | 189/595 [00:23<00:44,  9.05it/s] 32%|███▏      | 190/595 [00:24<00:44,  9.02it/s] 32%|███▏      | 191/595 [00:24<00:44,  9.04it/s] 32%|███▏      | 192/595 [00:24<00:44,  9.12it/s] 32%|███▏      | 193/595 [00:24<00:44,  9.12it/s] 33%|███▎      | 194/595 [00:24<00:44,  9.10it/s] 33%|███▎      | 195/595 [00:24<00:43,  9.12it/s] 33%|███▎      | 196/595 [00:24<00:44,  9.03it/s] 33%|███▎      | 197/595 [00:24<00:44,  9.00it/s] 33%|███▎      | 198/595 [00:24<00:44,  8.99it/s] 33%|███▎      | 199/595 [00:25<00:43,  9.13it/s] 34%|███▎      | 200/595 [00:25<00:43,  9.04it/s] 34%|███▍      | 201/595 [00:25<00:43,  9.04it/s] 34%|███▍      | 202/595 [00:25<00:43,  9.03it/s] 34%|███▍      | 203/595 [00:25<00:43,  9.03it/s] 34%|███▍      | 204/595 [00:25<00:43,  8.93it/s] 34%|███▍      | 205/595 [00:25<00:43,  8.93it/s] 35%|███▍      | 206/595 [00:25<00:43,  8.95it/s] 35%|███▍      | 207/595 [00:25<00:43,  8.93it/s] 35%|███▍      | 208/595 [00:26<00:43,  8.99it/s] 35%|███▌      | 209/595 [00:26<00:42,  9.14it/s] 35%|███▌      | 210/595 [00:26<00:42,  9.05it/s] 35%|███▌      | 211/595 [00:26<00:42,  8.99it/s] 36%|███▌      | 212/595 [00:26<00:42,  8.93it/s] 36%|███▌      | 213/595 [00:26<00:42,  8.93it/s] 36%|███▌      | 214/595 [00:26<00:42,  8.97it/s] 36%|███▌      | 215/595 [00:26<00:42,  8.91it/s] 36%|███▋      | 216/595 [00:26<00:42,  8.90it/s] 36%|███▋      | 217/595 [00:27<00:42,  8.90it/s] 37%|███▋      | 218/595 [00:27<00:42,  8.90it/s] 37%|███▋      | 219/595 [00:27<00:41,  8.99it/s] 37%|███▋      | 220/595 [00:27<00:42,  8.91it/s] 37%|███▋      | 221/595 [00:27<00:42,  8.85it/s] 37%|███▋      | 222/595 [00:27<00:42,  8.87it/s] 37%|███▋      | 223/595 [00:27<00:41,  8.87it/s] 38%|███▊      | 224/595 [00:27<00:41,  8.86it/s] 38%|███▊      | 225/595 [00:27<00:41,  8.94it/s] 38%|███▊      | 226/595 [00:28<00:40,  9.07it/s] 38%|███▊      | 227/595 [00:28<00:41,  8.94it/s] 38%|███▊      | 228/595 [00:28<00:41,  8.87it/s] 38%|███▊      | 229/595 [00:28<00:41,  8.88it/s] 39%|███▊      | 230/595 [00:28<00:41,  8.90it/s] 39%|███▉      | 231/595 [00:28<00:40,  8.93it/s] 39%|███▉      | 232/595 [00:28<00:40,  8.89it/s] 39%|███▉      | 233/595 [00:28<00:40,  8.91it/s] 39%|███▉      | 234/595 [00:28<00:40,  8.85it/s] 39%|███▉      | 235/595 [00:29<00:40,  8.83it/s] 40%|███▉      | 236/595 [00:29<00:40,  8.97it/s] 40%|███▉      | 237/595 [00:29<00:39,  9.02it/s]                                                  40%|████      | 238/595 [00:29<00:39,  9.02it/s][INFO|trainer.py:755] 2023-11-15 20:53:58,726 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:53:58,728 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:53:58,729 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:53:58,729 >>   Batch size = 8
{'eval_loss': 0.6570568680763245, 'eval_accuracy': 0.726984126984127, 'eval_micro_f1': 0.726984126984127, 'eval_macro_f1': 0.528132684514722, 'eval_runtime': 1.733, 'eval_samples_per_second': 545.309, 'eval_steps_per_second': 68.669, 'epoch': 1.0}
{'loss': 0.5436, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 82.28it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 76.48it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 71.63it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 70.89it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 72.76it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 71.11it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 70.54it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 70.42it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 71.88it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 71.56it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 70.73it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 71.03it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 70.90it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 69.72it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:31<00:39,  9.02it/s]
100%|██████████| 119/119 [00:01<00:00, 69.72it/s][A
                                                 [A 40%|████      | 239/595 [00:31<02:55,  2.03it/s] 40%|████      | 240/595 [00:31<02:21,  2.51it/s] 41%|████      | 241/595 [00:31<01:54,  3.09it/s] 41%|████      | 242/595 [00:31<01:33,  3.76it/s] 41%|████      | 243/595 [00:31<01:18,  4.47it/s] 41%|████      | 244/595 [00:31<01:07,  5.23it/s] 41%|████      | 245/595 [00:31<00:58,  6.00it/s] 41%|████▏     | 246/595 [00:31<00:52,  6.64it/s] 42%|████▏     | 247/595 [00:32<00:48,  7.20it/s] 42%|████▏     | 248/595 [00:32<00:45,  7.64it/s] 42%|████▏     | 249/595 [00:32<00:43,  7.99it/s] 42%|████▏     | 250/595 [00:32<00:41,  8.27it/s] 42%|████▏     | 251/595 [00:32<00:40,  8.45it/s] 42%|████▏     | 252/595 [00:32<00:39,  8.61it/s] 43%|████▎     | 253/595 [00:32<00:39,  8.71it/s] 43%|████▎     | 254/595 [00:32<00:39,  8.73it/s] 43%|████▎     | 255/595 [00:32<00:38,  8.93it/s] 43%|████▎     | 256/595 [00:33<00:38,  8.89it/s] 43%|████▎     | 257/595 [00:33<00:38,  8.87it/s] 43%|████▎     | 258/595 [00:33<00:37,  8.89it/s] 44%|████▎     | 259/595 [00:33<00:37,  8.86it/s] 44%|████▎     | 260/595 [00:33<00:37,  8.91it/s] 44%|████▍     | 261/595 [00:33<00:37,  9.01it/s] 44%|████▍     | 262/595 [00:33<00:36,  9.10it/s] 44%|████▍     | 263/595 [00:33<00:36,  9.00it/s] 44%|████▍     | 264/595 [00:33<00:36,  8.97it/s] 45%|████▍     | 265/595 [00:34<00:36,  8.97it/s] 45%|████▍     | 266/595 [00:34<00:36,  8.97it/s] 45%|████▍     | 267/595 [00:34<00:36,  8.98it/s] 45%|████▌     | 268/595 [00:34<00:36,  8.92it/s] 45%|████▌     | 269/595 [00:34<00:36,  8.92it/s] 45%|████▌     | 270/595 [00:34<00:36,  8.94it/s] 46%|████▌     | 271/595 [00:34<00:36,  8.98it/s] 46%|████▌     | 272/595 [00:34<00:35,  9.09it/s] 46%|████▌     | 273/595 [00:34<00:35,  9.02it/s] 46%|████▌     | 274/595 [00:35<00:35,  8.94it/s] 46%|████▌     | 275/595 [00:35<00:35,  8.92it/s] 46%|████▋     | 276/595 [00:35<00:35,  8.96it/s] 47%|████▋     | 277/595 [00:35<00:35,  8.95it/s] 47%|████▋     | 278/595 [00:35<00:35,  8.88it/s] 47%|████▋     | 279/595 [00:35<00:35,  8.93it/s] 47%|████▋     | 280/595 [00:35<00:35,  8.91it/s] 47%|████▋     | 281/595 [00:35<00:35,  8.94it/s] 47%|████▋     | 282/595 [00:35<00:34,  9.04it/s] 48%|████▊     | 283/595 [00:36<00:34,  8.97it/s] 48%|████▊     | 284/595 [00:36<00:34,  8.95it/s] 48%|████▊     | 285/595 [00:36<00:34,  8.99it/s] 48%|████▊     | 286/595 [00:36<00:34,  9.02it/s] 48%|████▊     | 287/595 [00:36<00:33,  9.07it/s] 48%|████▊     | 288/595 [00:36<00:34,  9.00it/s] 49%|████▊     | 289/595 [00:36<00:34,  8.96it/s] 49%|████▊     | 290/595 [00:36<00:33,  8.99it/s] 49%|████▉     | 291/595 [00:36<00:33,  9.01it/s] 49%|████▉     | 292/595 [00:37<00:33,  9.13it/s] 49%|████▉     | 293/595 [00:37<00:33,  9.03it/s] 49%|████▉     | 294/595 [00:37<00:33,  8.98it/s] 50%|████▉     | 295/595 [00:37<00:33,  9.04it/s] 50%|████▉     | 296/595 [00:37<00:33,  9.06it/s] 50%|████▉     | 297/595 [00:37<00:32,  9.12it/s] 50%|█████     | 298/595 [00:37<00:32,  9.08it/s] 50%|█████     | 299/595 [00:37<00:32,  9.08it/s] 50%|█████     | 300/595 [00:37<00:32,  8.98it/s] 51%|█████     | 301/595 [00:38<00:32,  9.01it/s] 51%|█████     | 302/595 [00:38<00:32,  9.11it/s] 51%|█████     | 303/595 [00:38<00:32,  9.07it/s] 51%|█████     | 304/595 [00:38<00:32,  9.00it/s] 51%|█████▏    | 305/595 [00:38<00:32,  8.90it/s] 51%|█████▏    | 306/595 [00:38<00:32,  8.95it/s] 52%|█████▏    | 307/595 [00:38<00:31,  9.02it/s] 52%|█████▏    | 308/595 [00:38<00:32,  8.95it/s] 52%|█████▏    | 309/595 [00:38<00:31,  8.97it/s] 52%|█████▏    | 310/595 [00:39<00:32,  8.89it/s] 52%|█████▏    | 311/595 [00:39<00:32,  8.83it/s] 52%|█████▏    | 312/595 [00:39<00:31,  8.98it/s] 53%|█████▎    | 313/595 [00:39<00:31,  8.95it/s] 53%|█████▎    | 314/595 [00:39<00:31,  8.93it/s] 53%|█████▎    | 315/595 [00:39<00:31,  8.87it/s] 53%|█████▎    | 316/595 [00:39<00:31,  8.90it/s] 53%|█████▎    | 317/595 [00:39<00:31,  8.97it/s] 53%|█████▎    | 318/595 [00:39<00:30,  8.96it/s] 54%|█████▎    | 319/595 [00:40<00:30,  8.95it/s] 54%|█████▍    | 320/595 [00:40<00:30,  8.87it/s] 54%|█████▍    | 321/595 [00:40<00:30,  8.85it/s] 54%|█████▍    | 322/595 [00:40<00:30,  8.98it/s] 54%|█████▍    | 323/595 [00:40<00:30,  8.92it/s] 54%|█████▍    | 324/595 [00:40<00:30,  8.91it/s] 55%|█████▍    | 325/595 [00:40<00:30,  8.89it/s] 55%|█████▍    | 326/595 [00:40<00:30,  8.93it/s] 55%|█████▍    | 327/595 [00:40<00:30,  8.89it/s] 55%|█████▌    | 328/595 [00:41<00:29,  8.95it/s] 55%|█████▌    | 329/595 [00:41<00:29,  8.97it/s] 55%|█████▌    | 330/595 [00:41<00:29,  8.93it/s] 56%|█████▌    | 331/595 [00:41<00:29,  8.87it/s] 56%|█████▌    | 332/595 [00:41<00:29,  8.91it/s] 56%|█████▌    | 333/595 [00:41<00:29,  8.93it/s] 56%|█████▌    | 334/595 [00:41<00:29,  8.87it/s] 56%|█████▋    | 335/595 [00:41<00:29,  8.88it/s] 56%|█████▋    | 336/595 [00:41<00:29,  8.85it/s] 57%|█████▋    | 337/595 [00:42<00:29,  8.85it/s] 57%|█████▋    | 338/595 [00:42<00:28,  8.92it/s] 57%|█████▋    | 339/595 [00:42<00:28,  9.03it/s] 57%|█████▋    | 340/595 [00:42<00:28,  8.99it/s] 57%|█████▋    | 341/595 [00:42<00:28,  8.94it/s] 57%|█████▋    | 342/595 [00:42<00:28,  8.83it/s] 58%|█████▊    | 343/595 [00:42<00:28,  8.89it/s] 58%|█████▊    | 344/595 [00:42<00:28,  8.90it/s] 58%|█████▊    | 345/595 [00:42<00:28,  8.82it/s] 58%|█████▊    | 346/595 [00:43<00:28,  8.87it/s] 58%|█████▊    | 347/595 [00:43<00:27,  8.91it/s] 58%|█████▊    | 348/595 [00:43<00:27,  8.83it/s] 59%|█████▊    | 349/595 [00:43<00:27,  8.97it/s] 59%|█████▉    | 350/595 [00:43<00:27,  8.87it/s] 59%|█████▉    | 351/595 [00:43<00:27,  8.83it/s] 59%|█████▉    | 352/595 [00:43<00:27,  8.80it/s] 59%|█████▉    | 353/595 [00:43<00:27,  8.80it/s] 59%|█████▉    | 354/595 [00:44<00:27,  8.85it/s] 60%|█████▉    | 355/595 [00:44<00:27,  8.87it/s] 60%|█████▉    | 356/595 [00:44<00:26,  8.96it/s]                                                  60%|██████    | 357/595 [00:44<00:26,  8.96it/s][INFO|trainer.py:755] 2023-11-15 20:54:13,674 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:54:13,676 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:54:13,676 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:54:13,676 >>   Batch size = 8
{'eval_loss': 0.5512444972991943, 'eval_accuracy': 0.7714285714285715, 'eval_micro_f1': 0.7714285714285715, 'eval_macro_f1': 0.6918629331315117, 'eval_runtime': 1.7137, 'eval_samples_per_second': 551.435, 'eval_steps_per_second': 69.44, 'epoch': 2.0}
{'loss': 0.4106, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 75.74it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 69.40it/s][A
 19%|█▉        | 23/119 [00:00<00:01, 67.69it/s][A
 25%|██▌       | 30/119 [00:00<00:01, 68.04it/s][A
 31%|███       | 37/119 [00:00<00:01, 66.35it/s][A
 38%|███▊      | 45/119 [00:00<00:01, 68.91it/s][A
 44%|████▎     | 52/119 [00:00<00:00, 67.70it/s][A
 50%|████▉     | 59/119 [00:00<00:00, 67.04it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 65.10it/s][A
 61%|██████▏   | 73/119 [00:01<00:00, 66.30it/s][A
 67%|██████▋   | 80/119 [00:01<00:00, 66.72it/s][A
 73%|███████▎  | 87/119 [00:01<00:00, 67.63it/s][A
 79%|███████▉  | 94/119 [00:01<00:00, 66.26it/s][A
 85%|████████▍ | 101/119 [00:01<00:00, 67.10it/s][A
 91%|█████████ | 108/119 [00:01<00:00, 66.90it/s][A
 97%|█████████▋| 115/119 [00:01<00:00, 67.58it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:46<00:26,  8.96it/s]
100%|██████████| 119/119 [00:01<00:00, 67.58it/s][A
                                                 [A 60%|██████    | 358/595 [00:46<02:02,  1.94it/s] 60%|██████    | 359/595 [00:46<01:38,  2.40it/s] 61%|██████    | 360/595 [00:46<01:19,  2.96it/s] 61%|██████    | 361/595 [00:46<01:04,  3.62it/s] 61%|██████    | 362/595 [00:46<00:53,  4.34it/s] 61%|██████    | 363/595 [00:46<00:45,  5.07it/s] 61%|██████    | 364/595 [00:46<00:39,  5.80it/s] 61%|██████▏   | 365/595 [00:47<00:35,  6.44it/s] 62%|██████▏   | 366/595 [00:47<00:32,  7.01it/s] 62%|██████▏   | 367/595 [00:47<00:30,  7.42it/s] 62%|██████▏   | 368/595 [00:47<00:29,  7.80it/s] 62%|██████▏   | 369/595 [00:47<00:28,  8.06it/s] 62%|██████▏   | 370/595 [00:47<00:27,  8.27it/s] 62%|██████▏   | 371/595 [00:47<00:26,  8.48it/s] 63%|██████▎   | 372/595 [00:47<00:25,  8.60it/s] 63%|██████▎   | 373/595 [00:47<00:25,  8.70it/s] 63%|██████▎   | 374/595 [00:48<00:24,  8.85it/s] 63%|██████▎   | 375/595 [00:48<00:24,  8.81it/s] 63%|██████▎   | 376/595 [00:48<00:24,  8.79it/s] 63%|██████▎   | 377/595 [00:48<00:24,  8.77it/s] 64%|██████▎   | 378/595 [00:48<00:24,  8.84it/s] 64%|██████▎   | 379/595 [00:48<00:24,  8.89it/s] 64%|██████▍   | 380/595 [00:48<00:24,  8.85it/s] 64%|██████▍   | 381/595 [00:48<00:24,  8.88it/s] 64%|██████▍   | 382/595 [00:48<00:23,  8.90it/s] 64%|██████▍   | 383/595 [00:49<00:23,  8.88it/s] 65%|██████▍   | 384/595 [00:49<00:23,  9.01it/s] 65%|██████▍   | 385/595 [00:49<00:23,  8.98it/s] 65%|██████▍   | 386/595 [00:49<00:23,  8.93it/s] 65%|██████▌   | 387/595 [00:49<00:23,  8.85it/s] 65%|██████▌   | 388/595 [00:49<00:23,  8.82it/s] 65%|██████▌   | 389/595 [00:49<00:23,  8.84it/s] 66%|██████▌   | 390/595 [00:49<00:23,  8.88it/s] 66%|██████▌   | 391/595 [00:49<00:22,  9.02it/s] 66%|██████▌   | 392/595 [00:50<00:22,  8.86it/s] 66%|██████▌   | 393/595 [00:50<00:22,  8.92it/s] 66%|██████▌   | 394/595 [00:50<00:22,  8.90it/s] 66%|██████▋   | 395/595 [00:50<00:22,  8.91it/s] 67%|██████▋   | 396/595 [00:50<00:22,  8.98it/s] 67%|██████▋   | 397/595 [00:50<00:22,  8.89it/s] 67%|██████▋   | 398/595 [00:50<00:22,  8.92it/s] 67%|██████▋   | 399/595 [00:50<00:22,  8.90it/s] 67%|██████▋   | 400/595 [00:50<00:21,  8.95it/s] 67%|██████▋   | 401/595 [00:51<00:21,  9.06it/s] 68%|██████▊   | 402/595 [00:51<00:21,  9.00it/s] 68%|██████▊   | 403/595 [00:51<00:21,  8.87it/s] 68%|██████▊   | 404/595 [00:51<00:21,  8.82it/s] 68%|██████▊   | 405/595 [00:51<00:21,  8.92it/s] 68%|██████▊   | 406/595 [00:51<00:21,  8.94it/s] 68%|██████▊   | 407/595 [00:51<00:20,  8.96it/s] 69%|██████▊   | 408/595 [00:51<00:20,  8.91it/s] 69%|██████▊   | 409/595 [00:51<00:20,  8.91it/s] 69%|██████▉   | 410/595 [00:52<00:20,  8.90it/s] 69%|██████▉   | 411/595 [00:52<00:20,  9.00it/s] 69%|██████▉   | 412/595 [00:52<00:20,  8.98it/s] 69%|██████▉   | 413/595 [00:52<00:20,  8.92it/s] 70%|██████▉   | 414/595 [00:52<00:20,  8.95it/s] 70%|██████▉   | 415/595 [00:52<00:19,  9.00it/s] 70%|██████▉   | 416/595 [00:52<00:19,  9.02it/s] 70%|███████   | 417/595 [00:52<00:19,  8.97it/s] 70%|███████   | 418/595 [00:52<00:19,  9.01it/s] 70%|███████   | 419/595 [00:53<00:19,  8.96it/s] 71%|███████   | 420/595 [00:53<00:19,  8.95it/s] 71%|███████   | 421/595 [00:53<00:19,  9.05it/s] 71%|███████   | 422/595 [00:53<00:19,  8.95it/s] 71%|███████   | 423/595 [00:53<00:19,  8.89it/s] 71%|███████▏  | 424/595 [00:53<00:19,  8.87it/s] 71%|███████▏  | 425/595 [00:53<00:19,  8.89it/s] 72%|███████▏  | 426/595 [00:53<00:18,  8.95it/s] 72%|███████▏  | 427/595 [00:53<00:18,  8.95it/s] 72%|███████▏  | 428/595 [00:54<00:18,  8.96it/s] 72%|███████▏  | 429/595 [00:54<00:18,  8.91it/s] 72%|███████▏  | 430/595 [00:54<00:18,  8.93it/s] 72%|███████▏  | 431/595 [00:54<00:18,  9.07it/s] 73%|███████▎  | 432/595 [00:54<00:18,  8.96it/s] 73%|███████▎  | 433/595 [00:54<00:18,  8.96it/s] 73%|███████▎  | 434/595 [00:54<00:17,  8.96it/s] 73%|███████▎  | 435/595 [00:54<00:17,  8.93it/s] 73%|███████▎  | 436/595 [00:54<00:17,  8.98it/s] 73%|███████▎  | 437/595 [00:55<00:17,  8.97it/s] 74%|███████▎  | 438/595 [00:55<00:17,  8.95it/s] 74%|███████▍  | 439/595 [00:55<00:17,  9.03it/s] 74%|███████▍  | 440/595 [00:55<00:17,  8.97it/s] 74%|███████▍  | 441/595 [00:55<00:17,  9.05it/s] 74%|███████▍  | 442/595 [00:55<00:17,  8.96it/s] 74%|███████▍  | 443/595 [00:55<00:17,  8.93it/s] 75%|███████▍  | 444/595 [00:55<00:16,  8.95it/s] 75%|███████▍  | 445/595 [00:55<00:16,  8.98it/s] 75%|███████▍  | 446/595 [00:56<00:16,  8.92it/s] 75%|███████▌  | 447/595 [00:56<00:16,  8.98it/s] 75%|███████▌  | 448/595 [00:56<00:16,  8.87it/s] 75%|███████▌  | 449/595 [00:56<00:16,  8.96it/s] 76%|███████▌  | 450/595 [00:56<00:16,  9.04it/s] 76%|███████▌  | 451/595 [00:56<00:15,  9.03it/s] 76%|███████▌  | 452/595 [00:56<00:16,  8.91it/s] 76%|███████▌  | 453/595 [00:56<00:15,  8.98it/s] 76%|███████▋  | 454/595 [00:56<00:15,  9.08it/s] 76%|███████▋  | 455/595 [00:57<00:15,  8.97it/s] 77%|███████▋  | 456/595 [00:57<00:15,  8.96it/s] 77%|███████▋  | 457/595 [00:57<00:15,  8.94it/s] 77%|███████▋  | 458/595 [00:57<00:15,  9.02it/s] 77%|███████▋  | 459/595 [00:57<00:15,  9.02it/s] 77%|███████▋  | 460/595 [00:57<00:15,  8.98it/s] 77%|███████▋  | 461/595 [00:57<00:14,  8.96it/s] 78%|███████▊  | 462/595 [00:57<00:14,  9.02it/s] 78%|███████▊  | 463/595 [00:57<00:14,  9.03it/s] 78%|███████▊  | 464/595 [00:58<00:14,  9.13it/s] 78%|███████▊  | 465/595 [00:58<00:14,  8.97it/s] 78%|███████▊  | 466/595 [00:58<00:14,  9.07it/s] 78%|███████▊  | 467/595 [00:58<00:13,  9.16it/s] 79%|███████▊  | 468/595 [00:58<00:13,  9.17it/s] 79%|███████▉  | 469/595 [00:58<00:13,  9.09it/s] 79%|███████▉  | 470/595 [00:58<00:13,  8.98it/s] 79%|███████▉  | 471/595 [00:58<00:13,  9.02it/s] 79%|███████▉  | 472/595 [00:58<00:13,  8.97it/s] 79%|███████▉  | 473/595 [00:59<00:13,  9.01it/s] 80%|███████▉  | 474/595 [00:59<00:13,  8.89it/s] 80%|███████▉  | 475/595 [00:59<00:13,  9.03it/s]                                                  80%|████████  | 476/595 [00:59<00:13,  9.03it/s][INFO|trainer.py:755] 2023-11-15 20:54:28,728 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:54:28,729 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:54:28,730 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:54:28,730 >>   Batch size = 8
{'eval_loss': 0.523608922958374, 'eval_accuracy': 0.801058201058201, 'eval_micro_f1': 0.801058201058201, 'eval_macro_f1': 0.7091006866881774, 'eval_runtime': 1.8137, 'eval_samples_per_second': 521.034, 'eval_steps_per_second': 65.612, 'epoch': 3.0}
{'loss': 0.2836, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 84.25it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 75.94it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 74.22it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 72.90it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 73.75it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 72.05it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 71.38it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 71.20it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 72.16it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 70.82it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 71.79it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 71.89it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 72.08it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 72.72it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [01:01<00:13,  9.03it/s]
100%|██████████| 119/119 [00:01<00:00, 72.72it/s][A
                                                 [A 80%|████████  | 477/595 [01:01<00:57,  2.06it/s] 80%|████████  | 478/595 [01:01<00:46,  2.54it/s] 81%|████████  | 479/595 [01:01<00:37,  3.13it/s] 81%|████████  | 480/595 [01:01<00:30,  3.79it/s] 81%|████████  | 481/595 [01:01<00:25,  4.53it/s] 81%|████████  | 482/595 [01:01<00:21,  5.25it/s] 81%|████████  | 483/595 [01:01<00:18,  5.99it/s] 81%|████████▏ | 484/595 [01:01<00:16,  6.62it/s] 82%|████████▏ | 485/595 [01:02<00:15,  7.20it/s] 82%|████████▏ | 486/595 [01:02<00:14,  7.60it/s] 82%|████████▏ | 487/595 [01:02<00:13,  8.01it/s] 82%|████████▏ | 488/595 [01:02<00:12,  8.36it/s] 82%|████████▏ | 489/595 [01:02<00:12,  8.53it/s] 82%|████████▏ | 490/595 [01:02<00:12,  8.61it/s] 83%|████████▎ | 491/595 [01:02<00:11,  8.77it/s] 83%|████████▎ | 492/595 [01:02<00:11,  8.85it/s] 83%|████████▎ | 493/595 [01:02<00:11,  8.82it/s] 83%|████████▎ | 494/595 [01:03<00:11,  8.91it/s] 83%|████████▎ | 495/595 [01:03<00:11,  8.90it/s] 83%|████████▎ | 496/595 [01:03<00:11,  8.94it/s] 84%|████████▎ | 497/595 [01:03<00:10,  8.93it/s] 84%|████████▎ | 498/595 [01:03<00:10,  8.96it/s] 84%|████████▍ | 499/595 [01:03<00:10,  8.93it/s] 84%|████████▍ | 500/595 [01:03<00:10,  8.97it/s] 84%|████████▍ | 501/595 [01:03<00:10,  9.01it/s] 84%|████████▍ | 502/595 [01:03<00:10,  8.96it/s] 85%|████████▍ | 503/595 [01:04<00:10,  8.95it/s] 85%|████████▍ | 504/595 [01:04<00:10,  9.01it/s] 85%|████████▍ | 505/595 [01:04<00:10,  8.94it/s] 85%|████████▌ | 506/595 [01:04<00:09,  8.93it/s] 85%|████████▌ | 507/595 [01:04<00:09,  8.90it/s] 85%|████████▌ | 508/595 [01:04<00:09,  8.93it/s] 86%|████████▌ | 509/595 [01:04<00:09,  8.97it/s] 86%|████████▌ | 510/595 [01:04<00:09,  8.86it/s] 86%|████████▌ | 511/595 [01:04<00:09,  8.89it/s] 86%|████████▌ | 512/595 [01:05<00:09,  8.90it/s] 86%|████████▌ | 513/595 [01:05<00:09,  8.98it/s] 86%|████████▋ | 514/595 [01:05<00:08,  9.03it/s] 87%|████████▋ | 515/595 [01:05<00:08,  8.90it/s] 87%|████████▋ | 516/595 [01:05<00:08,  8.92it/s] 87%|████████▋ | 517/595 [01:05<00:08,  8.97it/s] 87%|████████▋ | 518/595 [01:05<00:08,  8.98it/s] 87%|████████▋ | 519/595 [01:05<00:08,  8.93it/s] 87%|████████▋ | 520/595 [01:05<00:08,  8.91it/s] 88%|████████▊ | 521/595 [01:06<00:08,  8.81it/s] 88%|████████▊ | 522/595 [01:06<00:08,  8.88it/s] 88%|████████▊ | 523/595 [01:06<00:08,  8.90it/s] 88%|████████▊ | 524/595 [01:06<00:07,  8.97it/s] 88%|████████▊ | 525/595 [01:06<00:07,  8.86it/s] 88%|████████▊ | 526/595 [01:06<00:07,  8.90it/s] 89%|████████▊ | 527/595 [01:06<00:07,  8.99it/s] 89%|████████▊ | 528/595 [01:06<00:07,  8.98it/s] 89%|████████▉ | 529/595 [01:06<00:07,  8.94it/s] 89%|████████▉ | 530/595 [01:07<00:07,  8.91it/s] 89%|████████▉ | 531/595 [01:07<00:07,  8.92it/s] 89%|████████▉ | 532/595 [01:07<00:07,  8.95it/s] 90%|████████▉ | 533/595 [01:07<00:06,  8.93it/s] 90%|████████▉ | 534/595 [01:07<00:06,  8.95it/s] 90%|████████▉ | 535/595 [01:07<00:06,  8.93it/s] 90%|█████████ | 536/595 [01:07<00:06,  8.95it/s] 90%|█████████ | 537/595 [01:07<00:06,  9.08it/s] 90%|█████████ | 538/595 [01:07<00:06,  8.98it/s] 91%|█████████ | 539/595 [01:08<00:06,  8.93it/s] 91%|█████████ | 540/595 [01:08<00:06,  8.88it/s] 91%|█████████ | 541/595 [01:08<00:06,  8.91it/s] 91%|█████████ | 542/595 [01:08<00:05,  8.85it/s] 91%|█████████▏| 543/595 [01:08<00:05,  8.86it/s] 91%|█████████▏| 544/595 [01:08<00:05,  8.81it/s] 92%|█████████▏| 545/595 [01:08<00:05,  8.64it/s] 92%|█████████▏| 546/595 [01:08<00:05,  8.68it/s] 92%|█████████▏| 547/595 [01:08<00:05,  8.77it/s] 92%|█████████▏| 548/595 [01:09<00:05,  8.75it/s] 92%|█████████▏| 549/595 [01:09<00:05,  8.86it/s] 92%|█████████▏| 550/595 [01:09<00:04,  9.01it/s] 93%|█████████▎| 551/595 [01:09<00:04,  8.92it/s] 93%|█████████▎| 552/595 [01:09<00:04,  8.92it/s] 93%|█████████▎| 553/595 [01:09<00:04,  8.85it/s] 93%|█████████▎| 554/595 [01:09<00:04,  8.90it/s] 93%|█████████▎| 555/595 [01:09<00:04,  8.95it/s] 93%|█████████▎| 556/595 [01:09<00:04,  8.89it/s] 94%|█████████▎| 557/595 [01:10<00:04,  8.94it/s] 94%|█████████▍| 558/595 [01:10<00:04,  8.93it/s] 94%|█████████▍| 559/595 [01:10<00:04,  8.94it/s] 94%|█████████▍| 560/595 [01:10<00:03,  9.04it/s] 94%|█████████▍| 561/595 [01:10<00:03,  8.98it/s] 94%|█████████▍| 562/595 [01:10<00:03,  8.91it/s] 95%|█████████▍| 563/595 [01:10<00:03,  8.97it/s] 95%|█████████▍| 564/595 [01:10<00:03,  8.97it/s] 95%|█████████▍| 565/595 [01:10<00:03,  8.93it/s] 95%|█████████▌| 566/595 [01:11<00:03,  8.92it/s] 95%|█████████▌| 567/595 [01:11<00:03,  8.87it/s] 95%|█████████▌| 568/595 [01:11<00:03,  8.90it/s] 96%|█████████▌| 569/595 [01:11<00:02,  8.84it/s] 96%|█████████▌| 570/595 [01:11<00:02,  8.94it/s] 96%|█████████▌| 571/595 [01:11<00:02,  8.94it/s] 96%|█████████▌| 572/595 [01:11<00:02,  8.87it/s] 96%|█████████▋| 573/595 [01:11<00:02,  9.00it/s] 96%|█████████▋| 574/595 [01:12<00:02,  8.94it/s] 97%|█████████▋| 575/595 [01:12<00:02,  8.96it/s] 97%|█████████▋| 576/595 [01:12<00:02,  8.93it/s] 97%|█████████▋| 577/595 [01:12<00:02,  8.98it/s] 97%|█████████▋| 578/595 [01:12<00:01,  9.02it/s] 97%|█████████▋| 579/595 [01:12<00:01,  9.00it/s] 97%|█████████▋| 580/595 [01:12<00:01,  8.96it/s] 98%|█████████▊| 581/595 [01:12<00:01,  8.93it/s] 98%|█████████▊| 582/595 [01:12<00:01,  9.01it/s] 98%|█████████▊| 583/595 [01:13<00:01,  9.10it/s] 98%|█████████▊| 584/595 [01:13<00:01,  9.01it/s] 98%|█████████▊| 585/595 [01:13<00:01,  9.01it/s] 98%|█████████▊| 586/595 [01:13<00:00,  9.04it/s] 99%|█████████▊| 587/595 [01:13<00:00,  9.04it/s] 99%|█████████▉| 588/595 [01:13<00:00,  8.98it/s] 99%|█████████▉| 589/595 [01:13<00:00,  8.86it/s] 99%|█████████▉| 590/595 [01:13<00:00,  8.91it/s] 99%|█████████▉| 591/595 [01:13<00:00,  8.97it/s] 99%|█████████▉| 592/595 [01:14<00:00,  8.96it/s]100%|█████████▉| 593/595 [01:14<00:00,  8.97it/s]100%|█████████▉| 594/595 [01:14<00:00,  9.06it/s]                                                 100%|██████████| 595/595 [01:14<00:00,  9.06it/s][INFO|trainer.py:755] 2023-11-15 20:54:43,663 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:54:43,665 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:54:43,666 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:54:43,666 >>   Batch size = 8
{'eval_loss': 0.4899246096611023, 'eval_accuracy': 0.8126984126984127, 'eval_micro_f1': 0.8126984126984127, 'eval_macro_f1': 0.7353385466511022, 'eval_runtime': 1.6905, 'eval_samples_per_second': 558.991, 'eval_steps_per_second': 70.391, 'epoch': 4.0}
{'loss': 0.2196, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 79.97it/s][A
 14%|█▍        | 17/119 [00:00<00:01, 73.94it/s][A
 21%|██        | 25/119 [00:00<00:01, 70.31it/s][A
 28%|██▊       | 33/119 [00:00<00:01, 67.31it/s][A
 34%|███▍      | 41/119 [00:00<00:01, 69.04it/s][A
 40%|████      | 48/119 [00:00<00:01, 69.26it/s][A
 46%|████▌     | 55/119 [00:00<00:00, 68.95it/s][A
 53%|█████▎    | 63/119 [00:00<00:00, 70.94it/s][A
 60%|█████▉    | 71/119 [00:01<00:00, 68.63it/s][A
 66%|██████▋   | 79/119 [00:01<00:00, 68.36it/s][A
 73%|███████▎  | 87/119 [00:01<00:00, 70.53it/s][A
 80%|███████▉  | 95/119 [00:01<00:00, 68.95it/s][A
 86%|████████▌ | 102/119 [00:01<00:00, 68.48it/s][A
 92%|█████████▏| 109/119 [00:01<00:00, 68.58it/s][A
 97%|█████████▋| 116/119 [00:01<00:00, 68.04it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:16<00:00,  9.06it/s]
100%|██████████| 119/119 [00:01<00:00, 68.04it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 20:54:45,426 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:16<00:00,  9.06it/s]100%|██████████| 595/595 [01:16<00:00,  7.83it/s]
[INFO|trainer.py:2855] 2023-11-15 20:54:45,430 >> Saving model checkpoint to ./result/restaurant_bert-base-cased_adapter__seed3
[INFO|configuration_utils.py:460] 2023-11-15 20:54:45,432 >> Configuration saved in ./result/restaurant_bert-base-cased_adapter__seed3/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:54:46,411 >> Model weights saved in ./result/restaurant_bert-base-cased_adapter__seed3/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:54:46,414 >> tokenizer config file saved in ./result/restaurant_bert-base-cased_adapter__seed3/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:54:46,416 >> Special tokens file saved in ./result/restaurant_bert-base-cased_adapter__seed3/special_tokens_map.json
{'eval_loss': 0.4822517931461334, 'eval_accuracy': 0.8264550264550264, 'eval_micro_f1': 0.8264550264550264, 'eval_macro_f1': 0.7650139006297693, 'eval_runtime': 1.7571, 'eval_samples_per_second': 537.808, 'eval_steps_per_second': 67.724, 'epoch': 5.0}
{'train_runtime': 76.0386, 'train_samples_per_second': 248.361, 'train_steps_per_second': 7.825, 'train_loss': 0.45518892432461266, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.4552
  train_runtime            = 0:01:16.03
  train_samples            =       3777
  train_samples_per_second =    248.361
  train_steps_per_second   =      7.825
11/15/2023 20:54:46 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:54:46,458 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:54:46,459 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:54:46,460 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:54:46,460 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  8%|▊         | 9/119 [00:00<00:01, 81.46it/s] 15%|█▌        | 18/119 [00:00<00:01, 74.85it/s] 22%|██▏       | 26/119 [00:00<00:01, 72.63it/s] 29%|██▊       | 34/119 [00:00<00:01, 73.07it/s] 35%|███▌      | 42/119 [00:00<00:01, 73.96it/s] 42%|████▏     | 50/119 [00:00<00:00, 72.22it/s] 49%|████▊     | 58/119 [00:00<00:00, 72.78it/s] 55%|█████▌    | 66/119 [00:00<00:00, 71.91it/s] 62%|██████▏   | 74/119 [00:01<00:00, 73.74it/s] 69%|██████▉   | 82/119 [00:01<00:00, 72.03it/s] 76%|███████▌  | 90/119 [00:01<00:00, 70.24it/s] 82%|████████▏ | 98/119 [00:01<00:00, 72.46it/s] 89%|████████▉ | 106/119 [00:01<00:00, 72.47it/s] 96%|█████████▌| 114/119 [00:01<00:00, 71.29it/s]100%|██████████| 119/119 [00:01<00:00, 71.59it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8265
  eval_loss               =     0.4823
  eval_macro_f1           =      0.765
  eval_micro_f1           =     0.8265
  eval_runtime            = 0:00:01.67
  eval_samples            =        945
  eval_samples_per_second =    563.779
  eval_steps_per_second   =     70.994
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▄▆▇██
wandb:                      eval/loss █▄▃▁▁▁
wandb:                  eval/macro_f1 ▁▆▆▇██
wandb:                  eval/micro_f1 ▁▄▆▇██
wandb:                   eval/runtime ▄▃█▂▅▁
wandb:        eval/samples_per_second ▅▆▁▇▄█
wandb:          eval/steps_per_second ▅▆▁▇▄█
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.82646
wandb:                      eval/loss 0.48225
wandb:                  eval/macro_f1 0.76501
wandb:                  eval/micro_f1 0.82646
wandb:                   eval/runtime 1.6762
wandb:        eval/samples_per_second 563.779
wandb:          eval/steps_per_second 70.994
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.2196
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.45519
wandb:            train/train_runtime 76.0386
wandb: train/train_samples_per_second 248.361
wandb:   train/train_steps_per_second 7.825
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_205242-wn56uvq5
wandb: Find logs at: ./wandb/offline-run-20231115_205242-wn56uvq5/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3/runs/Nov15_20-54-58_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:54:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:54:58 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3/runs/Nov15_20-54-58_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  87%|████████▋ | 4094/4722 [00:00<00:00, 40113.16 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 39411.43 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:55:14,527 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:55:14,537 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:55:24,554 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:55:34,572 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:55:34,573 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:55:54,610 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:55:54,610 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:55:54,611 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:55:54,611 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:55:54,611 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:55:54,612 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:55:54,613 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 20:55:54,640 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:55:54,641 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:56:14,766 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 20:56:16,223 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:56:16,224 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 22916.84 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 22601.82 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 25397.38 examples/s]
11/15/2023 20:56:16 - INFO - __main__ - Sample 1265 of the training set: {'text': 'cuisine <SEP> I love when restaurants think using fancy expensive ingrediants makes the food fine cuisine, even with no idea how to use them.', 'label': 0, 'input_ids': [102, 25049, 6177, 30107, 962, 9892, 1374, 259, 16780, 603, 23429, 773, 4960, 487, 12486, 2550, 9217, 13986, 16653, 30113, 3740, 111, 2599, 6571, 25049, 6177, 30107, 422, 1390, 190, 425, 4337, 539, 147, 626, 1445, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:56:16 - INFO - __main__ - Sample 1178 of the training set: {'text': "table <SEP> I went with 5 friends and we lingered at the table for a bit and didn't feel rushed at all even though there was a wait.", 'label': 1, 'input_ids': [102, 1020, 962, 9892, 1374, 259, 14606, 190, 305, 10487, 137, 185, 21468, 2770, 235, 111, 1020, 168, 106, 4626, 137, 20257, 2505, 105, 7286, 7069, 683, 235, 355, 1390, 2461, 461, 241, 106, 13775, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:56:16 - INFO - __main__ - Sample 54 of the training set: {'text': "Halibut <SEP> The Halibut was too salty, dessert was so so (don't waste any of your calories) and service was poor.", 'label': 2, 'input_ids': [102, 2547, 389, 181, 962, 9892, 1374, 111, 2547, 389, 181, 241, 3872, 7030, 30126, 422, 29402, 2813, 241, 564, 564, 145, 3313, 2505, 105, 6882, 843, 131, 5296, 14463, 301, 546, 137, 2289, 241, 3228, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:56:16 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:56:18,068 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:56:18,075 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:56:18,076 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 20:56:18,076 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:56:18,076 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:56:18,076 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:56:18,077 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:56:18,077 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 20:56:18,078 >>   Number of trainable parameters = 109,920,771
[INFO|integration_utils.py:716] 2023-11-15 20:56:18,079 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<14:26,  1.46s/it]  0%|          | 2/595 [00:01<06:31,  1.51it/s]  1%|          | 3/595 [00:01<04:01,  2.45it/s]  1%|          | 4/595 [00:01<02:51,  3.44it/s]  1%|          | 5/595 [00:01<02:13,  4.41it/s]  1%|          | 6/595 [00:02<01:49,  5.37it/s]  1%|          | 7/595 [00:02<01:34,  6.24it/s]  1%|▏         | 8/595 [00:02<01:24,  6.95it/s]  2%|▏         | 9/595 [00:02<01:16,  7.65it/s]  2%|▏         | 10/595 [00:02<01:12,  8.07it/s]  2%|▏         | 11/595 [00:02<01:09,  8.37it/s]  2%|▏         | 12/595 [00:02<01:07,  8.67it/s]  2%|▏         | 13/595 [00:02<01:05,  8.87it/s]  2%|▏         | 14/595 [00:02<01:04,  9.05it/s]  3%|▎         | 15/595 [00:02<01:03,  9.11it/s]  3%|▎         | 16/595 [00:03<01:02,  9.21it/s]  3%|▎         | 17/595 [00:03<01:03,  9.14it/s]  3%|▎         | 18/595 [00:03<01:03,  9.14it/s]  3%|▎         | 19/595 [00:03<01:02,  9.28it/s]  3%|▎         | 20/595 [00:03<01:02,  9.20it/s]  4%|▎         | 21/595 [00:03<01:02,  9.17it/s]  4%|▎         | 22/595 [00:03<01:02,  9.21it/s]  4%|▍         | 23/595 [00:03<01:01,  9.37it/s]  4%|▍         | 24/595 [00:03<01:02,  9.17it/s]  4%|▍         | 25/595 [00:04<01:01,  9.22it/s]  4%|▍         | 26/595 [00:04<01:01,  9.31it/s]  5%|▍         | 27/595 [00:04<01:01,  9.29it/s]  5%|▍         | 28/595 [00:04<01:01,  9.29it/s]  5%|▍         | 29/595 [00:04<01:00,  9.30it/s]  5%|▌         | 30/595 [00:04<00:59,  9.45it/s]  5%|▌         | 31/595 [00:04<01:00,  9.35it/s]  5%|▌         | 32/595 [00:04<01:00,  9.26it/s]  6%|▌         | 33/595 [00:04<01:01,  9.20it/s]  6%|▌         | 34/595 [00:05<01:00,  9.25it/s]  6%|▌         | 35/595 [00:05<01:00,  9.30it/s]  6%|▌         | 36/595 [00:05<01:00,  9.27it/s]  6%|▋         | 38/595 [00:05<00:59,  9.42it/s]  7%|▋         | 39/595 [00:05<00:59,  9.36it/s]  7%|▋         | 40/595 [00:05<00:59,  9.26it/s]  7%|▋         | 41/595 [00:05<00:58,  9.39it/s]  7%|▋         | 42/595 [00:05<00:59,  9.32it/s]  7%|▋         | 43/595 [00:05<00:59,  9.28it/s]  7%|▋         | 44/595 [00:06<00:58,  9.39it/s]  8%|▊         | 45/595 [00:06<00:58,  9.35it/s]  8%|▊         | 46/595 [00:06<00:59,  9.28it/s]  8%|▊         | 47/595 [00:06<00:59,  9.24it/s]  8%|▊         | 48/595 [00:06<00:58,  9.33it/s]  8%|▊         | 49/595 [00:06<00:58,  9.37it/s]  8%|▊         | 50/595 [00:06<00:58,  9.27it/s]  9%|▊         | 51/595 [00:06<00:58,  9.32it/s]  9%|▊         | 52/595 [00:06<00:58,  9.26it/s]  9%|▉         | 53/595 [00:07<00:58,  9.23it/s]  9%|▉         | 54/595 [00:07<00:58,  9.21it/s]  9%|▉         | 55/595 [00:07<00:58,  9.15it/s]  9%|▉         | 56/595 [00:07<00:58,  9.16it/s] 10%|▉         | 57/595 [00:07<00:58,  9.23it/s] 10%|▉         | 58/595 [00:07<00:57,  9.35it/s] 10%|▉         | 59/595 [00:07<00:57,  9.34it/s] 10%|█         | 60/595 [00:07<00:57,  9.27it/s] 10%|█         | 61/595 [00:07<00:57,  9.21it/s] 10%|█         | 62/595 [00:08<00:57,  9.19it/s] 11%|█         | 63/595 [00:08<00:57,  9.24it/s] 11%|█         | 64/595 [00:08<00:57,  9.27it/s] 11%|█         | 65/595 [00:08<00:56,  9.36it/s] 11%|█         | 66/595 [00:08<00:56,  9.30it/s] 11%|█▏        | 67/595 [00:08<00:56,  9.29it/s] 11%|█▏        | 68/595 [00:08<00:56,  9.26it/s] 12%|█▏        | 69/595 [00:08<00:56,  9.26it/s] 12%|█▏        | 70/595 [00:08<00:56,  9.31it/s] 12%|█▏        | 71/595 [00:08<00:56,  9.24it/s] 12%|█▏        | 72/595 [00:09<00:55,  9.45it/s] 12%|█▏        | 73/595 [00:09<00:55,  9.33it/s] 12%|█▏        | 74/595 [00:09<00:56,  9.28it/s] 13%|█▎        | 75/595 [00:09<00:56,  9.23it/s] 13%|█▎        | 76/595 [00:09<00:56,  9.24it/s] 13%|█▎        | 77/595 [00:09<00:56,  9.17it/s] 13%|█▎        | 78/595 [00:09<00:56,  9.13it/s] 13%|█▎        | 79/595 [00:09<00:55,  9.33it/s] 13%|█▎        | 80/595 [00:09<00:55,  9.25it/s] 14%|█▎        | 81/595 [00:10<00:55,  9.23it/s] 14%|█▍        | 82/595 [00:10<00:55,  9.24it/s] 14%|█▍        | 83/595 [00:10<00:55,  9.28it/s] 14%|█▍        | 84/595 [00:10<00:55,  9.28it/s] 14%|█▍        | 85/595 [00:10<00:54,  9.31it/s] 14%|█▍        | 86/595 [00:10<00:54,  9.39it/s] 15%|█▍        | 87/595 [00:10<00:54,  9.36it/s] 15%|█▍        | 88/595 [00:10<00:55,  9.20it/s] 15%|█▍        | 89/595 [00:10<00:54,  9.27it/s] 15%|█▌        | 90/595 [00:11<00:54,  9.29it/s] 15%|█▌        | 91/595 [00:11<00:54,  9.30it/s] 15%|█▌        | 92/595 [00:11<00:54,  9.29it/s] 16%|█▌        | 93/595 [00:11<00:53,  9.47it/s] 16%|█▌        | 94/595 [00:11<00:53,  9.40it/s] 16%|█▌        | 95/595 [00:11<00:53,  9.29it/s] 16%|█▌        | 96/595 [00:11<00:54,  9.10it/s] 16%|█▋        | 98/595 [00:11<00:53,  9.34it/s] 17%|█▋        | 99/595 [00:12<00:53,  9.27it/s] 17%|█▋        | 100/595 [00:12<00:53,  9.28it/s] 17%|█▋        | 101/595 [00:12<00:53,  9.27it/s] 17%|█▋        | 102/595 [00:12<00:52,  9.31it/s] 17%|█▋        | 103/595 [00:12<00:52,  9.29it/s] 17%|█▋        | 104/595 [00:12<00:52,  9.41it/s] 18%|█▊        | 105/595 [00:12<00:52,  9.31it/s] 18%|█▊        | 106/595 [00:12<00:52,  9.31it/s] 18%|█▊        | 107/595 [00:12<00:52,  9.23it/s] 18%|█▊        | 108/595 [00:12<00:51,  9.44it/s] 18%|█▊        | 109/595 [00:13<00:52,  9.31it/s] 18%|█▊        | 110/595 [00:13<00:53,  9.12it/s] 19%|█▊        | 111/595 [00:13<00:52,  9.20it/s] 19%|█▉        | 112/595 [00:13<00:52,  9.21it/s] 19%|█▉        | 113/595 [00:13<00:51,  9.29it/s] 19%|█▉        | 114/595 [00:13<00:52,  9.18it/s] 19%|█▉        | 115/595 [00:13<00:52,  9.18it/s] 19%|█▉        | 116/595 [00:13<00:52,  9.21it/s] 20%|█▉        | 117/595 [00:13<00:51,  9.20it/s] 20%|█▉        | 118/595 [00:14<00:51,  9.33it/s]                                                  20%|██        | 119/595 [00:14<00:51,  9.33it/s][INFO|trainer.py:755] 2023-11-15 20:56:32,195 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:56:32,197 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:56:32,197 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:56:32,197 >>   Batch size = 8
{'loss': 0.7037, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 85.15it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 76.10it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 73.93it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 73.11it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 73.34it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 73.85it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 71.92it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 71.73it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 70.93it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 72.18it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 72.43it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 71.94it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 72.40it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 72.12it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:15<00:51,  9.33it/s]
100%|██████████| 119/119 [00:01<00:00, 72.12it/s][A
                                                 [A 20%|██        | 120/595 [00:15<03:50,  2.06it/s] 20%|██        | 121/595 [00:16<03:05,  2.55it/s] 21%|██        | 122/595 [00:16<02:30,  3.15it/s] 21%|██        | 123/595 [00:16<02:03,  3.82it/s] 21%|██        | 124/595 [00:16<01:43,  4.55it/s] 21%|██        | 125/595 [00:16<01:28,  5.32it/s] 21%|██        | 126/595 [00:16<01:17,  6.08it/s] 21%|██▏       | 127/595 [00:16<01:08,  6.80it/s] 22%|██▏       | 128/595 [00:16<01:03,  7.35it/s] 22%|██▏       | 129/595 [00:16<00:59,  7.80it/s] 22%|██▏       | 130/595 [00:17<00:57,  8.10it/s] 22%|██▏       | 131/595 [00:17<00:55,  8.40it/s] 22%|██▏       | 132/595 [00:17<00:53,  8.58it/s] 22%|██▏       | 133/595 [00:17<00:52,  8.77it/s] 23%|██▎       | 134/595 [00:17<00:51,  9.01it/s] 23%|██▎       | 135/595 [00:17<00:50,  9.02it/s] 23%|██▎       | 136/595 [00:17<00:51,  9.00it/s] 23%|██▎       | 137/595 [00:17<00:50,  9.11it/s] 23%|██▎       | 138/595 [00:17<00:50,  9.13it/s] 23%|██▎       | 139/595 [00:17<00:49,  9.15it/s] 24%|██▎       | 140/595 [00:18<00:50,  9.05it/s] 24%|██▎       | 141/595 [00:18<00:49,  9.09it/s] 24%|██▍       | 142/595 [00:18<00:49,  9.10it/s] 24%|██▍       | 143/595 [00:18<00:49,  9.16it/s] 24%|██▍       | 144/595 [00:18<00:48,  9.25it/s] 24%|██▍       | 145/595 [00:18<00:49,  9.11it/s] 25%|██▍       | 146/595 [00:18<00:49,  9.06it/s] 25%|██▍       | 147/595 [00:18<00:49,  9.05it/s] 25%|██▍       | 148/595 [00:18<00:49,  9.09it/s] 25%|██▌       | 149/595 [00:19<00:48,  9.21it/s] 25%|██▌       | 150/595 [00:19<00:48,  9.13it/s] 25%|██▌       | 151/595 [00:19<00:48,  9.21it/s] 26%|██▌       | 152/595 [00:19<00:48,  9.17it/s] 26%|██▌       | 153/595 [00:19<00:48,  9.16it/s] 26%|██▌       | 154/595 [00:19<00:48,  9.18it/s] 26%|██▌       | 155/595 [00:19<00:47,  9.17it/s] 26%|██▌       | 156/595 [00:19<00:48,  9.06it/s] 26%|██▋       | 157/595 [00:19<00:48,  9.03it/s] 27%|██▋       | 158/595 [00:20<00:48,  9.03it/s] 27%|██▋       | 159/595 [00:20<00:48,  9.07it/s] 27%|██▋       | 160/595 [00:20<00:47,  9.11it/s] 27%|██▋       | 161/595 [00:20<00:46,  9.26it/s] 27%|██▋       | 162/595 [00:20<00:46,  9.22it/s] 27%|██▋       | 163/595 [00:20<00:46,  9.20it/s] 28%|██▊       | 164/595 [00:20<00:46,  9.24it/s] 28%|██▊       | 165/595 [00:20<00:46,  9.23it/s] 28%|██▊       | 166/595 [00:20<00:46,  9.22it/s] 28%|██▊       | 167/595 [00:21<00:46,  9.19it/s] 28%|██▊       | 168/595 [00:21<00:46,  9.26it/s] 28%|██▊       | 169/595 [00:21<00:46,  9.19it/s] 29%|██▊       | 170/595 [00:21<00:46,  9.14it/s] 29%|██▊       | 171/595 [00:21<00:46,  9.11it/s] 29%|██▉       | 172/595 [00:21<00:46,  9.14it/s] 29%|██▉       | 173/595 [00:21<00:46,  9.16it/s] 29%|██▉       | 174/595 [00:21<00:46,  9.10it/s] 29%|██▉       | 175/595 [00:21<00:45,  9.18it/s] 30%|██▉       | 176/595 [00:22<00:45,  9.11it/s] 30%|██▉       | 177/595 [00:22<00:45,  9.11it/s] 30%|██▉       | 178/595 [00:22<00:45,  9.15it/s] 30%|███       | 179/595 [00:22<00:45,  9.12it/s] 30%|███       | 180/595 [00:22<00:45,  9.04it/s] 30%|███       | 181/595 [00:22<00:45,  9.01it/s] 31%|███       | 182/595 [00:22<00:45,  9.02it/s] 31%|███       | 183/595 [00:22<00:45,  9.08it/s] 31%|███       | 184/595 [00:22<00:45,  9.11it/s] 31%|███       | 185/595 [00:23<00:44,  9.22it/s] 31%|███▏      | 186/595 [00:23<00:44,  9.13it/s] 31%|███▏      | 187/595 [00:23<00:45,  9.04it/s] 32%|███▏      | 188/595 [00:23<00:45,  8.99it/s] 32%|███▏      | 189/595 [00:23<00:45,  9.00it/s] 32%|███▏      | 190/595 [00:23<00:44,  9.07it/s] 32%|███▏      | 191/595 [00:23<00:44,  9.08it/s] 32%|███▏      | 192/595 [00:23<00:43,  9.23it/s] 32%|███▏      | 193/595 [00:23<00:43,  9.14it/s] 33%|███▎      | 194/595 [00:24<00:43,  9.13it/s] 33%|███▎      | 195/595 [00:24<00:43,  9.11it/s] 33%|███▎      | 196/595 [00:24<00:43,  9.07it/s] 33%|███▎      | 197/595 [00:24<00:43,  9.07it/s] 33%|███▎      | 198/595 [00:24<00:43,  9.08it/s] 33%|███▎      | 199/595 [00:24<00:43,  9.17it/s] 34%|███▎      | 200/595 [00:24<00:43,  9.12it/s] 34%|███▍      | 201/595 [00:24<00:43,  9.06it/s] 34%|███▍      | 202/595 [00:24<00:43,  9.04it/s] 34%|███▍      | 203/595 [00:24<00:43,  9.08it/s] 34%|███▍      | 204/595 [00:25<00:43,  9.07it/s] 34%|███▍      | 205/595 [00:25<00:43,  9.01it/s] 35%|███▍      | 206/595 [00:25<00:42,  9.08it/s] 35%|███▍      | 207/595 [00:25<00:42,  9.17it/s] 35%|███▍      | 208/595 [00:25<00:42,  9.09it/s] 35%|███▌      | 209/595 [00:25<00:42,  9.13it/s] 35%|███▌      | 210/595 [00:25<00:42,  9.06it/s] 35%|███▌      | 211/595 [00:25<00:42,  9.00it/s] 36%|███▌      | 212/595 [00:25<00:42,  9.01it/s] 36%|███▌      | 213/595 [00:26<00:42,  8.90it/s] 36%|███▌      | 214/595 [00:26<00:42,  8.97it/s] 36%|███▌      | 215/595 [00:26<00:42,  9.01it/s] 36%|███▋      | 216/595 [00:26<00:41,  9.19it/s] 36%|███▋      | 217/595 [00:26<00:41,  9.17it/s] 37%|███▋      | 218/595 [00:26<00:41,  9.12it/s] 37%|███▋      | 219/595 [00:26<00:41,  9.09it/s] 37%|███▋      | 220/595 [00:26<00:41,  9.10it/s] 37%|███▋      | 221/595 [00:26<00:40,  9.13it/s] 37%|███▋      | 222/595 [00:27<00:40,  9.14it/s] 37%|███▋      | 223/595 [00:27<00:40,  9.26it/s] 38%|███▊      | 224/595 [00:27<00:40,  9.21it/s] 38%|███▊      | 225/595 [00:27<00:40,  9.18it/s] 38%|███▊      | 226/595 [00:27<00:40,  9.11it/s] 38%|███▊      | 227/595 [00:27<00:40,  9.14it/s] 38%|███▊      | 228/595 [00:27<00:40,  9.14it/s] 38%|███▊      | 229/595 [00:27<00:40,  9.11it/s] 39%|███▊      | 230/595 [00:27<00:39,  9.14it/s] 39%|███▉      | 231/595 [00:28<00:39,  9.15it/s] 39%|███▉      | 232/595 [00:28<00:39,  9.09it/s] 39%|███▉      | 233/595 [00:28<00:39,  9.16it/s] 39%|███▉      | 234/595 [00:28<00:39,  9.10it/s] 39%|███▉      | 235/595 [00:28<00:39,  9.06it/s] 40%|███▉      | 236/595 [00:28<00:39,  9.05it/s] 40%|███▉      | 237/595 [00:28<00:39,  9.12it/s]                                                  40%|████      | 238/595 [00:28<00:39,  9.12it/s][INFO|trainer.py:755] 2023-11-15 20:56:46,859 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:56:46,862 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:56:46,862 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:56:46,862 >>   Batch size = 8
{'eval_loss': 0.5759119987487793, 'eval_accuracy': 0.7693121693121693, 'eval_micro_f1': 0.7693121693121693, 'eval_macro_f1': 0.6765163342153361, 'eval_runtime': 1.6858, 'eval_samples_per_second': 560.568, 'eval_steps_per_second': 70.59, 'epoch': 1.0}
{'loss': 0.4559, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 81.34it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 77.97it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 74.83it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 72.41it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 72.78it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 72.15it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 72.75it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 71.69it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 73.10it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 71.43it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 70.45it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 72.06it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 71.79it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 71.16it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:30<00:39,  9.12it/s]
100%|██████████| 119/119 [00:01<00:00, 71.16it/s][A
                                                 [A 40%|████      | 239/595 [00:30<02:52,  2.06it/s] 40%|████      | 240/595 [00:30<02:19,  2.55it/s] 41%|████      | 241/595 [00:30<01:52,  3.14it/s] 41%|████      | 242/595 [00:30<01:32,  3.83it/s] 41%|████      | 243/595 [00:31<01:17,  4.55it/s] 41%|████      | 244/595 [00:31<01:06,  5.30it/s] 41%|████      | 245/595 [00:31<00:58,  6.03it/s] 41%|████▏     | 246/595 [00:31<00:52,  6.68it/s] 42%|████▏     | 247/595 [00:31<00:47,  7.26it/s] 42%|████▏     | 248/595 [00:31<00:45,  7.67it/s] 42%|████▏     | 249/595 [00:31<00:43,  8.04it/s] 42%|████▏     | 250/595 [00:31<00:41,  8.38it/s] 42%|████▏     | 251/595 [00:31<00:40,  8.52it/s] 42%|████▏     | 252/595 [00:32<00:38,  8.81it/s] 43%|████▎     | 253/595 [00:32<00:38,  8.87it/s] 43%|████▎     | 254/595 [00:32<00:38,  8.87it/s] 43%|████▎     | 255/595 [00:32<00:37,  8.95it/s] 43%|████▎     | 256/595 [00:32<00:37,  8.95it/s] 43%|████▎     | 257/595 [00:32<00:37,  8.99it/s] 43%|████▎     | 258/595 [00:32<00:37,  9.03it/s] 44%|████▎     | 259/595 [00:32<00:36,  9.14it/s] 44%|████▎     | 260/595 [00:32<00:37,  9.04it/s] 44%|████▍     | 261/595 [00:33<00:37,  9.02it/s] 44%|████▍     | 262/595 [00:33<00:36,  9.08it/s] 44%|████▍     | 263/595 [00:33<00:36,  9.10it/s] 44%|████▍     | 264/595 [00:33<00:36,  9.03it/s] 45%|████▍     | 265/595 [00:33<00:36,  9.01it/s] 45%|████▍     | 266/595 [00:33<00:36,  9.01it/s] 45%|████▍     | 267/595 [00:33<00:36,  9.04it/s] 45%|████▌     | 268/595 [00:33<00:36,  9.02it/s] 45%|████▌     | 269/595 [00:33<00:35,  9.13it/s] 45%|████▌     | 270/595 [00:33<00:35,  9.09it/s] 46%|████▌     | 271/595 [00:34<00:35,  9.08it/s] 46%|████▌     | 272/595 [00:34<00:35,  9.04it/s] 46%|████▌     | 273/595 [00:34<00:35,  9.10it/s] 46%|████▌     | 274/595 [00:34<00:35,  9.04it/s] 46%|████▌     | 275/595 [00:34<00:35,  9.05it/s] 46%|████▋     | 276/595 [00:34<00:35,  8.98it/s] 47%|████▋     | 277/595 [00:34<00:35,  9.01it/s] 47%|████▋     | 278/595 [00:34<00:35,  9.05it/s] 47%|████▋     | 279/595 [00:34<00:34,  9.13it/s] 47%|████▋     | 280/595 [00:35<00:34,  9.09it/s] 47%|████▋     | 281/595 [00:35<00:34,  9.13it/s] 47%|████▋     | 282/595 [00:35<00:34,  9.06it/s] 48%|████▊     | 283/595 [00:35<00:34,  9.08it/s] 48%|████▊     | 284/595 [00:35<00:34,  9.08it/s] 48%|████▊     | 285/595 [00:35<00:34,  9.02it/s] 48%|████▊     | 286/595 [00:35<00:34,  9.02it/s] 48%|████▊     | 287/595 [00:35<00:33,  9.07it/s] 48%|████▊     | 288/595 [00:35<00:33,  9.06it/s] 49%|████▊     | 289/595 [00:36<00:33,  9.13it/s] 49%|████▊     | 290/595 [00:36<00:33,  9.06it/s] 49%|████▉     | 291/595 [00:36<00:33,  9.07it/s] 49%|████▉     | 292/595 [00:36<00:33,  9.07it/s] 49%|████▉     | 293/595 [00:36<00:33,  9.05it/s] 49%|████▉     | 294/595 [00:36<00:33,  9.05it/s] 50%|████▉     | 295/595 [00:36<00:33,  9.01it/s] 50%|████▉     | 296/595 [00:36<00:33,  9.04it/s] 50%|████▉     | 297/595 [00:36<00:32,  9.06it/s] 50%|█████     | 298/595 [00:37<00:32,  9.01it/s] 50%|█████     | 299/595 [00:37<00:32,  9.11it/s] 50%|█████     | 300/595 [00:37<00:32,  9.11it/s] 51%|█████     | 301/595 [00:37<00:32,  9.00it/s] 51%|█████     | 302/595 [00:37<00:32,  8.96it/s] 51%|█████     | 303/595 [00:37<00:32,  8.90it/s] 51%|█████     | 304/595 [00:37<00:32,  8.92it/s] 51%|█████▏    | 305/595 [00:37<00:32,  8.91it/s] 51%|█████▏    | 306/595 [00:37<00:32,  8.99it/s] 52%|█████▏    | 307/595 [00:38<00:32,  8.98it/s] 52%|█████▏    | 308/595 [00:38<00:32,  8.92it/s] 52%|█████▏    | 309/595 [00:38<00:31,  9.00it/s] 52%|█████▏    | 310/595 [00:38<00:31,  8.98it/s] 52%|█████▏    | 311/595 [00:38<00:31,  8.92it/s] 52%|█████▏    | 312/595 [00:38<00:31,  8.94it/s] 53%|█████▎    | 313/595 [00:38<00:31,  8.91it/s] 53%|█████▎    | 314/595 [00:38<00:31,  9.04it/s] 53%|█████▎    | 315/595 [00:38<00:31,  8.97it/s] 53%|█████▎    | 316/595 [00:39<00:30,  9.10it/s] 53%|█████▎    | 317/595 [00:39<00:30,  9.02it/s] 53%|█████▎    | 318/595 [00:39<00:30,  8.98it/s] 54%|█████▎    | 319/595 [00:39<00:30,  9.01it/s] 54%|█████▍    | 320/595 [00:39<00:30,  9.01it/s] 54%|█████▍    | 321/595 [00:39<00:30,  9.04it/s] 54%|█████▍    | 322/595 [00:39<00:30,  8.93it/s] 54%|█████▍    | 323/595 [00:39<00:30,  8.97it/s] 54%|█████▍    | 324/595 [00:39<00:30,  8.98it/s] 55%|█████▍    | 325/595 [00:40<00:30,  8.97it/s] 55%|█████▍    | 326/595 [00:40<00:29,  9.08it/s] 55%|█████▍    | 327/595 [00:40<00:29,  9.00it/s] 55%|█████▌    | 328/595 [00:40<00:29,  9.02it/s] 55%|█████▌    | 329/595 [00:40<00:29,  9.00it/s] 55%|█████▌    | 330/595 [00:40<00:29,  9.06it/s] 56%|█████▌    | 331/595 [00:40<00:29,  9.03it/s] 56%|█████▌    | 332/595 [00:40<00:29,  9.02it/s] 56%|█████▌    | 333/595 [00:40<00:29,  8.97it/s] 56%|█████▌    | 334/595 [00:41<00:29,  8.96it/s] 56%|█████▋    | 335/595 [00:41<00:28,  9.01it/s] 56%|█████▋    | 336/595 [00:41<00:28,  9.12it/s] 57%|█████▋    | 337/595 [00:41<00:28,  9.08it/s] 57%|█████▋    | 338/595 [00:41<00:28,  9.04it/s] 57%|█████▋    | 339/595 [00:41<00:28,  8.91it/s] 57%|█████▋    | 340/595 [00:41<00:28,  8.94it/s] 57%|█████▋    | 341/595 [00:41<00:28,  8.93it/s] 57%|█████▋    | 342/595 [00:41<00:28,  8.89it/s] 58%|█████▊    | 343/595 [00:42<00:28,  8.90it/s] 58%|█████▊    | 344/595 [00:42<00:28,  8.93it/s] 58%|█████▊    | 345/595 [00:42<00:27,  8.93it/s] 58%|█████▊    | 346/595 [00:42<00:27,  9.04it/s] 58%|█████▊    | 347/595 [00:42<00:27,  9.01it/s] 58%|█████▊    | 348/595 [00:42<00:27,  8.98it/s] 59%|█████▊    | 349/595 [00:42<00:27,  8.93it/s] 59%|█████▉    | 350/595 [00:42<00:27,  8.89it/s] 59%|█████▉    | 351/595 [00:42<00:27,  8.94it/s] 59%|█████▉    | 352/595 [00:43<00:26,  9.02it/s] 59%|█████▉    | 353/595 [00:43<00:26,  9.02it/s] 59%|█████▉    | 354/595 [00:43<00:26,  9.01it/s] 60%|█████▉    | 355/595 [00:43<00:26,  8.94it/s] 60%|█████▉    | 356/595 [00:43<00:26,  8.99it/s]                                                  60%|██████    | 357/595 [00:43<00:26,  8.99it/s][INFO|trainer.py:755] 2023-11-15 20:57:01,673 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:57:01,675 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:57:01,675 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:57:01,676 >>   Batch size = 8
{'eval_loss': 0.4776591360569, 'eval_accuracy': 0.8116402116402116, 'eval_micro_f1': 0.8116402116402115, 'eval_macro_f1': 0.7454041051486748, 'eval_runtime': 1.6905, 'eval_samples_per_second': 559.015, 'eval_steps_per_second': 70.394, 'epoch': 2.0}
{'loss': 0.3102, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 77.43it/s][A
 14%|█▍        | 17/119 [00:00<00:01, 73.76it/s][A
 21%|██        | 25/119 [00:00<00:01, 74.70it/s][A
 28%|██▊       | 33/119 [00:00<00:01, 70.99it/s][A
 34%|███▍      | 41/119 [00:00<00:01, 70.88it/s][A
 41%|████      | 49/119 [00:00<00:01, 69.49it/s][A
 47%|████▋     | 56/119 [00:00<00:00, 69.59it/s][A
 53%|█████▎    | 63/119 [00:00<00:00, 69.67it/s][A
 59%|█████▉    | 70/119 [00:00<00:00, 68.86it/s][A
 66%|██████▌   | 78/119 [00:01<00:00, 69.95it/s][A
 71%|███████▏  | 85/119 [00:01<00:00, 68.51it/s][A
 77%|███████▋  | 92/119 [00:01<00:00, 66.66it/s][A
 83%|████████▎ | 99/119 [00:01<00:00, 66.87it/s][A
 90%|████████▉ | 107/119 [00:01<00:00, 68.93it/s][A
 97%|█████████▋| 115/119 [00:01<00:00, 70.51it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:45<00:26,  8.99it/s]
100%|██████████| 119/119 [00:01<00:00, 70.51it/s][A
                                                 [A 60%|██████    | 358/595 [00:45<01:58,  2.00it/s] 60%|██████    | 359/595 [00:45<01:35,  2.47it/s] 61%|██████    | 360/595 [00:45<01:17,  3.05it/s] 61%|██████    | 361/595 [00:45<01:03,  3.71it/s] 61%|██████    | 362/595 [00:45<00:52,  4.44it/s] 61%|██████    | 363/595 [00:46<00:44,  5.21it/s] 61%|██████    | 364/595 [00:46<00:38,  5.93it/s] 61%|██████▏   | 365/595 [00:46<00:34,  6.59it/s] 62%|██████▏   | 366/595 [00:46<00:31,  7.22it/s] 62%|██████▏   | 367/595 [00:46<00:29,  7.65it/s] 62%|██████▏   | 368/595 [00:46<00:28,  8.09it/s] 62%|██████▏   | 369/595 [00:46<00:27,  8.34it/s] 62%|██████▏   | 370/595 [00:46<00:26,  8.52it/s] 62%|██████▏   | 371/595 [00:46<00:25,  8.69it/s] 63%|██████▎   | 372/595 [00:47<00:25,  8.79it/s] 63%|██████▎   | 373/595 [00:47<00:24,  8.90it/s] 63%|██████▎   | 374/595 [00:47<00:24,  8.95it/s] 63%|██████▎   | 375/595 [00:47<00:24,  9.08it/s] 63%|██████▎   | 376/595 [00:47<00:24,  9.05it/s] 63%|██████▎   | 377/595 [00:47<00:23,  9.10it/s] 64%|██████▎   | 378/595 [00:47<00:23,  9.12it/s] 64%|██████▎   | 379/595 [00:47<00:23,  9.10it/s] 64%|██████▍   | 380/595 [00:47<00:23,  9.12it/s] 64%|██████▍   | 381/595 [00:47<00:23,  9.08it/s] 64%|██████▍   | 382/595 [00:48<00:23,  9.00it/s] 64%|██████▍   | 383/595 [00:48<00:23,  9.05it/s] 65%|██████▍   | 384/595 [00:48<00:23,  9.10it/s] 65%|██████▍   | 385/595 [00:48<00:22,  9.22it/s] 65%|██████▍   | 386/595 [00:48<00:22,  9.17it/s] 65%|██████▌   | 387/595 [00:48<00:22,  9.15it/s] 65%|██████▌   | 388/595 [00:48<00:22,  9.08it/s] 65%|██████▌   | 389/595 [00:48<00:22,  9.13it/s] 66%|██████▌   | 390/595 [00:48<00:22,  9.11it/s] 66%|██████▌   | 391/595 [00:49<00:22,  9.07it/s] 66%|██████▌   | 392/595 [00:49<00:22,  9.08it/s] 66%|██████▌   | 393/595 [00:49<00:22,  9.09it/s] 66%|██████▌   | 394/595 [00:49<00:22,  9.11it/s] 66%|██████▋   | 395/595 [00:49<00:21,  9.18it/s] 67%|██████▋   | 396/595 [00:49<00:21,  9.11it/s] 67%|██████▋   | 397/595 [00:49<00:21,  9.11it/s] 67%|██████▋   | 398/595 [00:49<00:21,  9.08it/s] 67%|██████▋   | 399/595 [00:49<00:21,  9.06it/s] 67%|██████▋   | 400/595 [00:50<00:21,  9.04it/s] 67%|██████▋   | 401/595 [00:50<00:21,  9.01it/s] 68%|██████▊   | 402/595 [00:50<00:21,  9.05it/s] 68%|██████▊   | 403/595 [00:50<00:21,  8.94it/s] 68%|██████▊   | 404/595 [00:50<00:21,  9.02it/s] 68%|██████▊   | 405/595 [00:50<00:20,  9.17it/s] 68%|██████▊   | 406/595 [00:50<00:20,  9.09it/s] 68%|██████▊   | 407/595 [00:50<00:20,  9.01it/s] 69%|██████▊   | 408/595 [00:50<00:20,  8.97it/s] 69%|██████▊   | 409/595 [00:51<00:20,  8.99it/s] 69%|██████▉   | 410/595 [00:51<00:20,  9.03it/s] 69%|██████▉   | 411/595 [00:51<00:20,  8.99it/s] 69%|██████▉   | 412/595 [00:51<00:20,  9.09it/s] 69%|██████▉   | 413/595 [00:51<00:20,  8.94it/s] 70%|██████▉   | 414/595 [00:51<00:20,  8.98it/s] 70%|██████▉   | 415/595 [00:51<00:19,  9.11it/s] 70%|██████▉   | 416/595 [00:51<00:19,  9.01it/s] 70%|███████   | 417/595 [00:51<00:19,  9.01it/s] 70%|███████   | 418/595 [00:52<00:19,  9.01it/s] 70%|███████   | 419/595 [00:52<00:19,  9.01it/s] 71%|███████   | 420/595 [00:52<00:19,  9.06it/s] 71%|███████   | 421/595 [00:52<00:19,  9.06it/s] 71%|███████   | 422/595 [00:52<00:19,  9.05it/s] 71%|███████   | 423/595 [00:52<00:19,  9.03it/s] 71%|███████▏  | 424/595 [00:52<00:18,  9.06it/s] 71%|███████▏  | 425/595 [00:52<00:18,  9.11it/s] 72%|███████▏  | 426/595 [00:52<00:18,  9.06it/s] 72%|███████▏  | 427/595 [00:53<00:18,  9.04it/s] 72%|███████▏  | 428/595 [00:53<00:18,  9.00it/s] 72%|███████▏  | 429/595 [00:53<00:18,  8.94it/s] 72%|███████▏  | 430/595 [00:53<00:18,  9.02it/s] 72%|███████▏  | 431/595 [00:53<00:18,  8.96it/s] 73%|███████▎  | 432/595 [00:53<00:17,  9.08it/s] 73%|███████▎  | 433/595 [00:53<00:17,  9.05it/s] 73%|███████▎  | 434/595 [00:53<00:17,  8.98it/s] 73%|███████▎  | 435/595 [00:53<00:17,  9.06it/s] 73%|███████▎  | 436/595 [00:54<00:17,  9.03it/s] 73%|███████▎  | 437/595 [00:54<00:17,  8.98it/s] 74%|███████▎  | 438/595 [00:54<00:17,  9.03it/s] 74%|███████▍  | 439/595 [00:54<00:17,  8.98it/s] 74%|███████▍  | 440/595 [00:54<00:17,  8.98it/s] 74%|███████▍  | 441/595 [00:54<00:17,  9.06it/s] 74%|███████▍  | 442/595 [00:54<00:16,  9.09it/s] 74%|███████▍  | 443/595 [00:54<00:16,  9.03it/s] 75%|███████▍  | 444/595 [00:54<00:16,  9.03it/s] 75%|███████▍  | 445/595 [00:55<00:16,  8.95it/s] 75%|███████▍  | 446/595 [00:55<00:16,  9.01it/s] 75%|███████▌  | 447/595 [00:55<00:16,  8.96it/s] 75%|███████▌  | 448/595 [00:55<00:16,  8.97it/s] 75%|███████▌  | 449/595 [00:55<00:16,  8.88it/s] 76%|███████▌  | 450/595 [00:55<00:16,  8.94it/s] 76%|███████▌  | 451/595 [00:55<00:16,  8.99it/s] 76%|███████▌  | 452/595 [00:55<00:15,  9.06it/s] 76%|███████▌  | 453/595 [00:55<00:15,  9.03it/s] 76%|███████▋  | 454/595 [00:56<00:15,  9.03it/s] 76%|███████▋  | 455/595 [00:56<00:15,  8.98it/s] 77%|███████▋  | 456/595 [00:56<00:15,  9.01it/s] 77%|███████▋  | 457/595 [00:56<00:15,  9.01it/s] 77%|███████▋  | 458/595 [00:56<00:15,  8.97it/s] 77%|███████▋  | 459/595 [00:56<00:15,  8.89it/s] 77%|███████▋  | 460/595 [00:56<00:15,  8.95it/s] 77%|███████▋  | 461/595 [00:56<00:14,  9.01it/s] 78%|███████▊  | 462/595 [00:56<00:14,  9.01it/s] 78%|███████▊  | 463/595 [00:57<00:14,  8.95it/s] 78%|███████▊  | 464/595 [00:57<00:14,  8.91it/s] 78%|███████▊  | 465/595 [00:57<00:14,  8.98it/s] 78%|███████▊  | 466/595 [00:57<00:14,  8.93it/s] 78%|███████▊  | 467/595 [00:57<00:14,  8.94it/s] 79%|███████▊  | 468/595 [00:57<00:14,  8.90it/s] 79%|███████▉  | 469/595 [00:57<00:14,  8.92it/s] 79%|███████▉  | 470/595 [00:57<00:13,  8.98it/s] 79%|███████▉  | 471/595 [00:57<00:13,  8.98it/s] 79%|███████▉  | 472/595 [00:58<00:13,  9.06it/s] 79%|███████▉  | 473/595 [00:58<00:13,  9.07it/s] 80%|███████▉  | 474/595 [00:58<00:13,  8.97it/s] 80%|███████▉  | 475/595 [00:58<00:13,  9.12it/s]                                                  80%|████████  | 476/595 [00:58<00:13,  9.12it/s][INFO|trainer.py:755] 2023-11-15 20:57:16,534 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:57:16,536 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:57:16,536 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:57:16,536 >>   Batch size = 8
{'eval_loss': 0.5130592584609985, 'eval_accuracy': 0.8275132275132275, 'eval_micro_f1': 0.8275132275132275, 'eval_macro_f1': 0.7627254058940371, 'eval_runtime': 1.7562, 'eval_samples_per_second': 538.088, 'eval_steps_per_second': 67.759, 'epoch': 3.0}
{'loss': 0.2094, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 84.23it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 75.76it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 75.34it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 71.55it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 72.90it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 73.07it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 71.46it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 70.39it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 70.35it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 71.79it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 71.20it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 69.99it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 70.15it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 70.78it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [01:00<00:13,  9.12it/s]
100%|██████████| 119/119 [00:01<00:00, 70.78it/s][A
                                                 [A 80%|████████  | 477/595 [01:00<00:57,  2.04it/s] 80%|████████  | 478/595 [01:00<00:46,  2.52it/s] 81%|████████  | 479/595 [01:00<00:37,  3.10it/s] 81%|████████  | 480/595 [01:00<00:30,  3.76it/s] 81%|████████  | 481/595 [01:00<00:25,  4.49it/s] 81%|████████  | 482/595 [01:00<00:21,  5.24it/s] 81%|████████  | 483/595 [01:00<00:18,  5.96it/s] 81%|████████▏ | 484/595 [01:01<00:16,  6.63it/s] 82%|████████▏ | 485/595 [01:01<00:15,  7.20it/s] 82%|████████▏ | 486/595 [01:01<00:14,  7.65it/s] 82%|████████▏ | 487/595 [01:01<00:13,  8.09it/s] 82%|████████▏ | 488/595 [01:01<00:12,  8.35it/s] 82%|████████▏ | 489/595 [01:01<00:12,  8.47it/s] 82%|████████▏ | 490/595 [01:01<00:12,  8.62it/s] 83%|████████▎ | 491/595 [01:01<00:11,  8.78it/s] 83%|████████▎ | 492/595 [01:01<00:11,  8.88it/s] 83%|████████▎ | 493/595 [01:02<00:11,  8.96it/s] 83%|████████▎ | 494/595 [01:02<00:11,  9.10it/s] 83%|████████▎ | 495/595 [01:02<00:11,  8.95it/s] 83%|████████▎ | 496/595 [01:02<00:11,  8.94it/s] 84%|████████▎ | 497/595 [01:02<00:10,  9.06it/s] 84%|████████▎ | 498/595 [01:02<00:10,  9.01it/s] 84%|████████▍ | 499/595 [01:02<00:10,  8.91it/s] 84%|████████▍ | 500/595 [01:02<00:10,  8.98it/s] 84%|████████▍ | 501/595 [01:02<00:10,  8.94it/s] 84%|████████▍ | 502/595 [01:03<00:10,  9.04it/s] 85%|████████▍ | 503/595 [01:03<00:10,  8.98it/s] 85%|████████▍ | 504/595 [01:03<00:10,  9.01it/s] 85%|████████▍ | 505/595 [01:03<00:09,  9.03it/s] 85%|████████▌ | 506/595 [01:03<00:09,  9.01it/s] 85%|████████▌ | 507/595 [01:03<00:09,  9.10it/s] 85%|████████▌ | 508/595 [01:03<00:09,  9.08it/s] 86%|████████▌ | 509/595 [01:03<00:09,  9.05it/s] 86%|████████▌ | 510/595 [01:03<00:09,  9.06it/s] 86%|████████▌ | 511/595 [01:04<00:09,  9.09it/s] 86%|████████▌ | 512/595 [01:04<00:09,  9.06it/s] 86%|████████▌ | 513/595 [01:04<00:09,  9.09it/s] 86%|████████▋ | 514/595 [01:04<00:08,  9.07it/s] 87%|████████▋ | 515/595 [01:04<00:08,  9.00it/s] 87%|████████▋ | 516/595 [01:04<00:08,  8.94it/s] 87%|████████▋ | 517/595 [01:04<00:08,  9.05it/s] 87%|████████▋ | 518/595 [01:04<00:08,  9.04it/s] 87%|████████▋ | 519/595 [01:04<00:08,  8.95it/s] 87%|████████▋ | 520/595 [01:05<00:08,  8.99it/s] 88%|████████▊ | 521/595 [01:05<00:08,  8.92it/s] 88%|████████▊ | 522/595 [01:05<00:08,  8.90it/s] 88%|████████▊ | 523/595 [01:05<00:08,  8.94it/s] 88%|████████▊ | 524/595 [01:05<00:07,  8.98it/s] 88%|████████▊ | 525/595 [01:05<00:07,  8.98it/s] 88%|████████▊ | 526/595 [01:05<00:07,  9.00it/s] 89%|████████▊ | 527/595 [01:05<00:07,  9.04it/s] 89%|████████▊ | 528/595 [01:05<00:07,  9.02it/s] 89%|████████▉ | 529/595 [01:06<00:07,  9.01it/s] 89%|████████▉ | 530/595 [01:06<00:07,  9.01it/s] 89%|████████▉ | 531/595 [01:06<00:07,  8.99it/s] 89%|████████▉ | 532/595 [01:06<00:07,  8.95it/s] 90%|████████▉ | 533/595 [01:06<00:06,  8.93it/s] 90%|████████▉ | 534/595 [01:06<00:06,  9.04it/s] 90%|████████▉ | 535/595 [01:06<00:06,  8.99it/s] 90%|█████████ | 536/595 [01:06<00:06,  8.98it/s] 90%|█████████ | 537/595 [01:06<00:06,  8.99it/s] 90%|█████████ | 538/595 [01:07<00:06,  9.05it/s] 91%|█████████ | 539/595 [01:07<00:06,  9.06it/s] 91%|█████████ | 540/595 [01:07<00:06,  9.02it/s] 91%|█████████ | 541/595 [01:07<00:06,  8.95it/s] 91%|█████████ | 542/595 [01:07<00:05,  8.94it/s] 91%|█████████▏| 543/595 [01:07<00:05,  9.00it/s] 91%|█████████▏| 544/595 [01:07<00:05,  9.07it/s] 92%|█████████▏| 545/595 [01:07<00:05,  8.99it/s] 92%|█████████▏| 546/595 [01:07<00:05,  8.88it/s] 92%|█████████▏| 547/595 [01:08<00:05,  8.94it/s] 92%|█████████▏| 548/595 [01:08<00:05,  8.99it/s] 92%|█████████▏| 549/595 [01:08<00:05,  8.78it/s] 92%|█████████▏| 550/595 [01:08<00:05,  8.87it/s] 93%|█████████▎| 551/595 [01:08<00:04,  8.81it/s] 93%|█████████▎| 552/595 [01:08<00:04,  8.86it/s] 93%|█████████▎| 553/595 [01:08<00:04,  8.91it/s] 93%|█████████▎| 554/595 [01:08<00:04,  8.99it/s] 93%|█████████▎| 555/595 [01:08<00:04,  8.98it/s] 93%|█████████▎| 556/595 [01:09<00:04,  8.97it/s] 94%|█████████▎| 557/595 [01:09<00:04,  9.01it/s] 94%|█████████▍| 558/595 [01:09<00:04,  9.02it/s] 94%|█████████▍| 559/595 [01:09<00:04,  8.97it/s] 94%|█████████▍| 560/595 [01:09<00:03,  8.90it/s] 94%|█████████▍| 561/595 [01:09<00:03,  9.00it/s] 94%|█████████▍| 562/595 [01:09<00:03,  9.05it/s] 95%|█████████▍| 563/595 [01:09<00:03,  9.05it/s] 95%|█████████▍| 564/595 [01:09<00:03,  9.15it/s] 95%|█████████▍| 565/595 [01:10<00:03,  9.06it/s] 95%|█████████▌| 566/595 [01:10<00:03,  9.04it/s] 95%|█████████▌| 567/595 [01:10<00:03,  8.94it/s] 95%|█████████▌| 568/595 [01:10<00:02,  9.01it/s] 96%|█████████▌| 569/595 [01:10<00:02,  9.01it/s] 96%|█████████▌| 570/595 [01:10<00:02,  9.02it/s] 96%|█████████▌| 571/595 [01:10<00:02,  9.04it/s] 96%|█████████▌| 572/595 [01:10<00:02,  8.94it/s] 96%|█████████▋| 573/595 [01:10<00:02,  8.96it/s] 96%|█████████▋| 574/595 [01:11<00:02,  9.04it/s] 97%|█████████▋| 575/595 [01:11<00:02,  8.97it/s] 97%|█████████▋| 576/595 [01:11<00:02,  8.97it/s] 97%|█████████▋| 577/595 [01:11<00:02,  8.91it/s] 97%|█████████▋| 578/595 [01:11<00:01,  9.01it/s] 97%|█████████▋| 579/595 [01:11<00:01,  8.99it/s] 97%|█████████▋| 580/595 [01:11<00:01,  8.98it/s] 98%|█████████▊| 581/595 [01:11<00:01,  9.00it/s] 98%|█████████▊| 582/595 [01:11<00:01,  8.97it/s] 98%|█████████▊| 583/595 [01:12<00:01,  9.01it/s] 98%|█████████▊| 584/595 [01:12<00:01,  9.11it/s] 98%|█████████▊| 585/595 [01:12<00:01,  9.05it/s] 98%|█████████▊| 586/595 [01:12<00:00,  9.04it/s] 99%|█████████▊| 587/595 [01:12<00:00,  8.92it/s] 99%|█████████▉| 588/595 [01:12<00:00,  8.97it/s] 99%|█████████▉| 589/595 [01:12<00:00,  8.92it/s] 99%|█████████▉| 590/595 [01:12<00:00,  8.92it/s] 99%|█████████▉| 591/595 [01:12<00:00,  8.92it/s] 99%|█████████▉| 592/595 [01:13<00:00,  8.91it/s]100%|█████████▉| 593/595 [01:13<00:00,  8.93it/s]100%|█████████▉| 594/595 [01:13<00:00,  9.06it/s]                                                 100%|██████████| 595/595 [01:13<00:00,  9.06it/s][INFO|trainer.py:755] 2023-11-15 20:57:31,410 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:57:31,412 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:57:31,412 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:57:31,412 >>   Batch size = 8
{'eval_loss': 0.5290617942810059, 'eval_accuracy': 0.8253968253968254, 'eval_micro_f1': 0.8253968253968254, 'eval_macro_f1': 0.7627100452516368, 'eval_runtime': 1.7107, 'eval_samples_per_second': 552.414, 'eval_steps_per_second': 69.563, 'epoch': 4.0}
{'loss': 0.1434, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 79.78it/s][A
 14%|█▍        | 17/119 [00:00<00:01, 71.33it/s][A
 21%|██        | 25/119 [00:00<00:01, 69.51it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 68.83it/s][A
 34%|███▎      | 40/119 [00:00<00:01, 70.64it/s][A
 40%|████      | 48/119 [00:00<00:00, 71.02it/s][A
 47%|████▋     | 56/119 [00:00<00:00, 68.41it/s][A
 53%|█████▎    | 63/119 [00:00<00:00, 68.37it/s][A
 59%|█████▉    | 70/119 [00:01<00:00, 67.11it/s][A
 66%|██████▌   | 78/119 [00:01<00:00, 69.39it/s][A
 71%|███████▏  | 85/119 [00:01<00:00, 69.45it/s][A
 77%|███████▋  | 92/119 [00:01<00:00, 67.70it/s][A
 83%|████████▎ | 99/119 [00:01<00:00, 68.24it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 68.26it/s][A
 95%|█████████▍| 113/119 [00:01<00:00, 66.94it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:15<00:00,  9.06it/s]
100%|██████████| 119/119 [00:01<00:00, 66.94it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 20:57:33,187 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:15<00:00,  9.06it/s]100%|██████████| 595/595 [01:15<00:00,  7.92it/s]
[INFO|trainer.py:2855] 2023-11-15 20:57:33,191 >> Saving model checkpoint to ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3
[INFO|configuration_utils.py:460] 2023-11-15 20:57:33,194 >> Configuration saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 20:57:34,376 >> Model weights saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 20:57:34,380 >> tokenizer config file saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 20:57:34,382 >> Special tokens file saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed3/special_tokens_map.json
{'eval_loss': 0.5455018877983093, 'eval_accuracy': 0.8211640211640212, 'eval_micro_f1': 0.8211640211640212, 'eval_macro_f1': 0.7623568591064173, 'eval_runtime': 1.7718, 'eval_samples_per_second': 533.349, 'eval_steps_per_second': 67.162, 'epoch': 5.0}
{'train_runtime': 75.11, 'train_samples_per_second': 251.431, 'train_steps_per_second': 7.922, 'train_loss': 0.3644970998042772, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3645
  train_runtime            = 0:01:15.10
  train_samples            =       3777
  train_samples_per_second =    251.431
  train_steps_per_second   =      7.922
11/15/2023 20:57:34 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 20:57:34,432 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:57:34,434 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:57:34,434 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 20:57:34,434 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  7%|▋         | 8/119 [00:00<00:01, 78.11it/s] 13%|█▎        | 16/119 [00:00<00:01, 73.60it/s] 20%|██        | 24/119 [00:00<00:01, 73.36it/s] 27%|██▋       | 32/119 [00:00<00:01, 72.80it/s] 34%|███▎      | 40/119 [00:00<00:01, 69.93it/s] 40%|████      | 48/119 [00:00<00:01, 70.71it/s] 47%|████▋     | 56/119 [00:00<00:00, 70.96it/s] 54%|█████▍    | 64/119 [00:00<00:00, 71.13it/s] 61%|██████    | 72/119 [00:01<00:00, 71.46it/s] 67%|██████▋   | 80/119 [00:01<00:00, 68.40it/s] 73%|███████▎  | 87/119 [00:01<00:00, 68.58it/s] 80%|███████▉  | 95/119 [00:01<00:00, 70.20it/s] 87%|████████▋ | 103/119 [00:01<00:00, 70.32it/s] 93%|█████████▎| 111/119 [00:01<00:00, 70.35it/s]100%|██████████| 119/119 [00:01<00:00, 71.09it/s]100%|██████████| 119/119 [00:01<00:00, 69.47it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8212
  eval_loss               =     0.5455
  eval_macro_f1           =     0.7624
  eval_micro_f1           =     0.8212
  eval_runtime            = 0:00:01.73
  eval_samples            =        945
  eval_samples_per_second =    544.834
  eval_steps_per_second   =     68.609
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▆██▇▇
wandb:                      eval/loss █▁▄▅▆▆
wandb:                  eval/macro_f1 ▁▇████
wandb:                  eval/micro_f1 ▁▆██▇▇
wandb:                   eval/runtime ▁▁▇▃█▅
wandb:        eval/samples_per_second ██▂▆▁▄
wandb:          eval/steps_per_second ██▂▆▁▄
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.82116
wandb:                      eval/loss 0.5455
wandb:                  eval/macro_f1 0.76236
wandb:                  eval/micro_f1 0.82116
wandb:                   eval/runtime 1.7345
wandb:        eval/samples_per_second 544.834
wandb:          eval/steps_per_second 68.609
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1434
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.3645
wandb:            train/train_runtime 75.11
wandb: train/train_samples_per_second 251.431
wandb:   train/train_steps_per_second 7.922
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_205459-1mq03046
wandb: Find logs at: ./wandb/offline-run-20231115_205459-1mq03046/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_roberta-base_adapter__seed3/runs/Nov15_20-57-46_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_roberta-base_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_roberta-base_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 20:57:46 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 20:57:46 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_roberta-base_adapter__seed3/runs/Nov15_20-57-45_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_roberta-base_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_roberta-base_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  36%|███▋      | 4000/11020 [00:00<00:00, 38511.12 examples/s]Map:  73%|███████▎  | 8032/11020 [00:00<00:00, 39480.52 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 38847.02 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 20:58:02,784 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:58:02,795 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 20:58:12,811 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 20:58:22,824 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:58:22,825 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:58:42,875 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:58:42,875 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:58:42,876 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:58:42,876 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:58:42,876 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 20:58:42,876 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 20:58:42,877 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 20:58:42,878 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 20:59:03,052 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 20:59:03,847 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 20:59:03,847 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  23%|██▎       | 2000/8816 [00:00<00:00, 16392.04 examples/s]Running tokenizer on dataset:  45%|████▌     | 4000/8816 [00:00<00:00, 17724.56 examples/s]Running tokenizer on dataset:  68%|██████▊   | 6000/8816 [00:00<00:00, 17935.72 examples/s]Running tokenizer on dataset:  91%|█████████ | 8000/8816 [00:00<00:00, 18059.53 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 17902.79 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset:  91%|█████████ | 2000/2204 [00:00<00:00, 19994.20 examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 19223.00 examples/s]
11/15/2023 20:59:04 - INFO - __main__ - Sample 5060 of the training set: {'text': 'After GABA immunostaining, as elaborated in earlier studies (Domenici et al. 1988; Granda and Crossland 1989), the cell bodies, fibers, and numerous terminals showed GABA-like immunoreactivity in the Imc nucleus.', 'label': 0, 'input_ids': [0, 4993, 47644, 13998, 2603, 8173, 6, 25, 35838, 11, 656, 3218, 36, 495, 14900, 13850, 4400, 1076, 4, 11151, 131, 2974, 5219, 8, 4415, 1245, 10206, 238, 5, 3551, 3738, 6, 32902, 6, 8, 3617, 20531, 969, 47644, 12, 3341, 13998, 1688, 30280, 11, 5, 5902, 438, 38531, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:59:04 - INFO - __main__ - Sample 4715 of the training set: {'text': 'The dynamic nature of the Dlg ‘supertertiary’ core structure suggest precise regulatory inputs have likely evolved to control its signaling output [25, 26].', 'label': 0, 'input_ids': [0, 133, 6878, 2574, 9, 5, 211, 462, 571, 44, 711, 16101, 1334, 90, 17174, 17, 27, 2731, 3184, 3608, 12548, 4099, 16584, 33, 533, 12236, 7, 797, 63, 22436, 4195, 646, 1244, 6, 973, 8174, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 20:59:04 - INFO - __main__ - Sample 216 of the training set: {'text': 'C57 mice, however, have been reported to be more sensitive to the incentive properties of other drugs of abuse including amphetamine, cocaine, methamphetamine, or nicotine than DBA mice (for review see Crawley et al. 1997; Cabib et al. 2000; Orsini et al. 2004; 2005; Grabus et al. 2006).', 'label': 0, 'input_ids': [0, 347, 4390, 15540, 6, 959, 6, 33, 57, 431, 7, 28, 55, 5685, 7, 5, 10814, 3611, 9, 97, 2196, 9, 2134, 217, 28127, 45634, 6, 9890, 6, 19118, 6, 50, 27730, 87, 211, 3813, 15540, 36, 1990, 1551, 192, 28040, 607, 4400, 1076, 4, 7528, 131, 8434, 1452, 4400, 1076, 4, 3788, 131, 1793, 29, 2531, 4400, 1076, 4, 4482, 131, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 20:59:04 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 20:59:05,660 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 20:59:05,669 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 20:59:05,669 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 20:59:05,669 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 20:59:05,670 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 20:59:05,670 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 20:59:05,670 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 20:59:05,670 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 20:59:05,671 >>   Number of trainable parameters = 124,647,939
[INFO|integration_utils.py:716] 2023-11-15 20:59:05,672 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<25:07,  1.09s/it]  0%|          | 3/1380 [00:01<08:03,  2.85it/s]  0%|          | 5/1380 [00:01<04:59,  4.60it/s]  1%|          | 7/1380 [00:01<03:43,  6.15it/s]  1%|          | 9/1380 [00:01<03:05,  7.41it/s]  1%|          | 11/1380 [00:01<02:43,  8.37it/s]  1%|          | 13/1380 [00:02<02:30,  9.11it/s]  1%|          | 15/1380 [00:02<02:21,  9.64it/s]  1%|          | 17/1380 [00:02<02:15, 10.05it/s]  1%|▏         | 19/1380 [00:02<02:11, 10.36it/s]  2%|▏         | 21/1380 [00:02<02:08, 10.60it/s]  2%|▏         | 23/1380 [00:03<02:06, 10.75it/s]  2%|▏         | 25/1380 [00:03<02:05, 10.83it/s]  2%|▏         | 27/1380 [00:03<02:04, 10.90it/s]  2%|▏         | 29/1380 [00:03<02:03, 10.96it/s]  2%|▏         | 31/1380 [00:03<02:02, 11.00it/s]  2%|▏         | 33/1380 [00:03<02:02, 11.02it/s]  3%|▎         | 35/1380 [00:04<02:01, 11.05it/s]  3%|▎         | 37/1380 [00:04<02:01, 11.07it/s]  3%|▎         | 39/1380 [00:04<02:01, 11.07it/s]  3%|▎         | 41/1380 [00:04<02:01, 11.06it/s]  3%|▎         | 43/1380 [00:04<02:00, 11.08it/s]  3%|▎         | 45/1380 [00:05<02:00, 11.07it/s]  3%|▎         | 47/1380 [00:05<02:00, 11.08it/s]  4%|▎         | 49/1380 [00:05<01:59, 11.09it/s]  4%|▎         | 51/1380 [00:05<01:59, 11.14it/s]  4%|▍         | 53/1380 [00:05<01:58, 11.15it/s]  4%|▍         | 55/1380 [00:05<01:58, 11.14it/s]  4%|▍         | 57/1380 [00:06<01:58, 11.15it/s]  4%|▍         | 59/1380 [00:06<01:58, 11.16it/s]  4%|▍         | 61/1380 [00:06<01:58, 11.18it/s]  5%|▍         | 63/1380 [00:06<01:57, 11.16it/s]  5%|▍         | 65/1380 [00:06<01:57, 11.16it/s]  5%|▍         | 67/1380 [00:07<01:57, 11.17it/s]  5%|▌         | 69/1380 [00:07<01:57, 11.16it/s]  5%|▌         | 71/1380 [00:07<01:57, 11.15it/s]  5%|▌         | 73/1380 [00:07<01:57, 11.13it/s]  5%|▌         | 75/1380 [00:07<01:56, 11.16it/s]  6%|▌         | 77/1380 [00:07<01:56, 11.15it/s]  6%|▌         | 79/1380 [00:08<01:56, 11.16it/s]  6%|▌         | 81/1380 [00:08<01:56, 11.17it/s]  6%|▌         | 83/1380 [00:08<01:56, 11.18it/s]  6%|▌         | 85/1380 [00:08<01:55, 11.17it/s]  6%|▋         | 87/1380 [00:08<01:55, 11.18it/s]  6%|▋         | 89/1380 [00:09<01:55, 11.16it/s]  7%|▋         | 91/1380 [00:09<01:55, 11.15it/s]  7%|▋         | 93/1380 [00:09<01:55, 11.15it/s]  7%|▋         | 95/1380 [00:09<01:55, 11.16it/s]  7%|▋         | 97/1380 [00:09<01:54, 11.18it/s]  7%|▋         | 99/1380 [00:09<01:54, 11.15it/s]  7%|▋         | 101/1380 [00:10<01:54, 11.15it/s]  7%|▋         | 103/1380 [00:10<01:54, 11.15it/s]  8%|▊         | 105/1380 [00:10<01:54, 11.17it/s]  8%|▊         | 107/1380 [00:10<01:54, 11.15it/s]  8%|▊         | 109/1380 [00:10<01:53, 11.16it/s]  8%|▊         | 111/1380 [00:10<01:53, 11.16it/s]  8%|▊         | 113/1380 [00:11<01:53, 11.14it/s]  8%|▊         | 115/1380 [00:11<01:53, 11.14it/s]  8%|▊         | 117/1380 [00:11<01:53, 11.16it/s]  9%|▊         | 119/1380 [00:11<01:52, 11.16it/s]  9%|▉         | 121/1380 [00:11<01:53, 11.14it/s]  9%|▉         | 123/1380 [00:12<01:52, 11.14it/s]  9%|▉         | 125/1380 [00:12<01:52, 11.13it/s]  9%|▉         | 127/1380 [00:12<01:52, 11.15it/s]  9%|▉         | 129/1380 [00:12<01:52, 11.11it/s]  9%|▉         | 131/1380 [00:12<01:52, 11.12it/s] 10%|▉         | 133/1380 [00:12<01:52, 11.12it/s] 10%|▉         | 135/1380 [00:13<01:51, 11.12it/s] 10%|▉         | 137/1380 [00:13<01:51, 11.10it/s] 10%|█         | 139/1380 [00:13<01:51, 11.12it/s] 10%|█         | 141/1380 [00:13<01:51, 11.14it/s] 10%|█         | 143/1380 [00:13<01:51, 11.13it/s] 11%|█         | 145/1380 [00:14<01:50, 11.14it/s] 11%|█         | 147/1380 [00:14<01:50, 11.15it/s] 11%|█         | 149/1380 [00:14<01:50, 11.12it/s] 11%|█         | 151/1380 [00:14<01:50, 11.11it/s] 11%|█         | 153/1380 [00:14<01:50, 11.13it/s] 11%|█         | 155/1380 [00:14<01:50, 11.13it/s] 11%|█▏        | 157/1380 [00:15<01:49, 11.14it/s] 12%|█▏        | 159/1380 [00:15<01:49, 11.12it/s] 12%|█▏        | 161/1380 [00:15<01:49, 11.12it/s] 12%|█▏        | 163/1380 [00:15<01:49, 11.13it/s] 12%|█▏        | 165/1380 [00:15<01:49, 11.10it/s] 12%|█▏        | 167/1380 [00:16<01:49, 11.11it/s] 12%|█▏        | 169/1380 [00:16<01:48, 11.12it/s] 12%|█▏        | 171/1380 [00:16<01:48, 11.10it/s] 13%|█▎        | 173/1380 [00:16<01:48, 11.10it/s] 13%|█▎        | 175/1380 [00:16<01:48, 11.12it/s] 13%|█▎        | 177/1380 [00:16<01:48, 11.12it/s] 13%|█▎        | 179/1380 [00:17<01:48, 11.12it/s] 13%|█▎        | 181/1380 [00:17<01:47, 11.11it/s] 13%|█▎        | 183/1380 [00:17<01:47, 11.12it/s] 13%|█▎        | 185/1380 [00:17<01:47, 11.12it/s] 14%|█▎        | 187/1380 [00:17<01:47, 11.11it/s] 14%|█▎        | 189/1380 [00:17<01:47, 11.12it/s] 14%|█▍        | 191/1380 [00:18<01:46, 11.12it/s] 14%|█▍        | 193/1380 [00:18<01:46, 11.10it/s] 14%|█▍        | 195/1380 [00:18<01:46, 11.12it/s] 14%|█▍        | 197/1380 [00:18<01:46, 11.12it/s] 14%|█▍        | 199/1380 [00:18<01:46, 11.12it/s] 15%|█▍        | 201/1380 [00:19<01:46, 11.12it/s] 15%|█▍        | 203/1380 [00:19<01:45, 11.10it/s] 15%|█▍        | 205/1380 [00:19<01:45, 11.11it/s] 15%|█▌        | 207/1380 [00:19<01:45, 11.12it/s] 15%|█▌        | 209/1380 [00:19<01:45, 11.11it/s] 15%|█▌        | 211/1380 [00:19<01:45, 11.11it/s] 15%|█▌        | 213/1380 [00:20<01:44, 11.12it/s] 16%|█▌        | 215/1380 [00:20<01:44, 11.11it/s] 16%|█▌        | 217/1380 [00:20<01:44, 11.10it/s] 16%|█▌        | 219/1380 [00:20<01:44, 11.11it/s] 16%|█▌        | 221/1380 [00:20<01:44, 11.12it/s] 16%|█▌        | 223/1380 [00:21<01:44, 11.12it/s] 16%|█▋        | 225/1380 [00:21<01:43, 11.12it/s] 16%|█▋        | 227/1380 [00:21<01:43, 11.13it/s] 17%|█▋        | 229/1380 [00:21<01:43, 11.12it/s] 17%|█▋        | 231/1380 [00:21<01:43, 11.11it/s] 17%|█▋        | 233/1380 [00:21<01:43, 11.13it/s] 17%|█▋        | 235/1380 [00:22<01:42, 11.13it/s] 17%|█▋        | 237/1380 [00:22<01:42, 11.12it/s] 17%|█▋        | 239/1380 [00:22<01:42, 11.11it/s] 17%|█▋        | 241/1380 [00:22<01:42, 11.11it/s] 18%|█▊        | 243/1380 [00:22<01:42, 11.12it/s] 18%|█▊        | 245/1380 [00:23<01:42, 11.11it/s] 18%|█▊        | 247/1380 [00:23<01:42, 11.10it/s] 18%|█▊        | 249/1380 [00:23<01:41, 11.10it/s] 18%|█▊        | 251/1380 [00:23<01:41, 11.09it/s] 18%|█▊        | 253/1380 [00:23<01:41, 11.08it/s] 18%|█▊        | 255/1380 [00:23<01:41, 11.09it/s] 19%|█▊        | 257/1380 [00:24<01:41, 11.10it/s] 19%|█▉        | 259/1380 [00:24<01:40, 11.11it/s] 19%|█▉        | 261/1380 [00:24<01:40, 11.08it/s] 19%|█▉        | 263/1380 [00:24<01:40, 11.08it/s] 19%|█▉        | 265/1380 [00:24<01:40, 11.09it/s] 19%|█▉        | 267/1380 [00:25<01:40, 11.08it/s] 19%|█▉        | 269/1380 [00:25<01:40, 11.08it/s] 20%|█▉        | 271/1380 [00:25<01:39, 11.09it/s] 20%|█▉        | 273/1380 [00:25<01:39, 11.08it/s] 20%|█▉        | 275/1380 [00:25<01:39, 11.08it/s]                                                   20%|██        | 276/1380 [00:25<01:39, 11.08it/s][INFO|trainer.py:755] 2023-11-15 20:59:31,475 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:59:31,477 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:59:31,477 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:59:31,478 >>   Batch size = 8
{'loss': 0.494, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 124.27it/s][A
  9%|▉         | 26/276 [00:00<00:02, 117.71it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 115.71it/s][A
 18%|█▊        | 50/276 [00:00<00:01, 114.48it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 113.38it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 112.61it/s][A
 31%|███       | 86/276 [00:00<00:01, 112.18it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 111.60it/s][A
 40%|███▉      | 110/276 [00:00<00:01, 110.84it/s][A
 44%|████▍     | 122/276 [00:01<00:01, 110.64it/s][A
 49%|████▊     | 134/276 [00:01<00:01, 110.81it/s][A
 53%|█████▎    | 146/276 [00:01<00:01, 111.02it/s][A
 57%|█████▋    | 158/276 [00:01<00:01, 111.26it/s][A
 62%|██████▏   | 170/276 [00:01<00:00, 111.13it/s][A
 66%|██████▌   | 182/276 [00:01<00:00, 111.02it/s][A
 70%|███████   | 194/276 [00:01<00:00, 110.73it/s][A
 75%|███████▍  | 206/276 [00:01<00:00, 110.38it/s][A
 79%|███████▉  | 218/276 [00:01<00:00, 109.94it/s][A
 83%|████████▎ | 229/276 [00:02<00:00, 109.77it/s][A
 87%|████████▋ | 241/276 [00:02<00:00, 109.98it/s][A
 92%|█████████▏| 253/276 [00:02<00:00, 110.21it/s][A
 96%|█████████▌| 265/276 [00:02<00:00, 110.40it/s][A                                                  
                                                  [A 20%|██        | 276/1380 [00:28<01:39, 11.08it/s]
100%|██████████| 276/276 [00:02<00:00, 110.40it/s][A
                                                  [A 20%|██        | 277/1380 [00:28<08:34,  2.14it/s] 20%|██        | 279/1380 [00:28<06:29,  2.83it/s] 20%|██        | 281/1380 [00:28<05:02,  3.64it/s] 21%|██        | 283/1380 [00:28<04:00,  4.56it/s] 21%|██        | 285/1380 [00:29<03:17,  5.54it/s] 21%|██        | 287/1380 [00:29<02:47,  6.51it/s] 21%|██        | 289/1380 [00:29<02:27,  7.42it/s] 21%|██        | 291/1380 [00:29<02:12,  8.23it/s] 21%|██        | 293/1380 [00:29<02:01,  8.92it/s] 21%|██▏       | 295/1380 [00:30<01:54,  9.48it/s] 22%|██▏       | 297/1380 [00:30<01:49,  9.92it/s] 22%|██▏       | 299/1380 [00:30<01:45, 10.21it/s] 22%|██▏       | 301/1380 [00:30<01:43, 10.46it/s] 22%|██▏       | 303/1380 [00:30<01:41, 10.62it/s] 22%|██▏       | 305/1380 [00:30<01:39, 10.76it/s] 22%|██▏       | 307/1380 [00:31<01:38, 10.86it/s] 22%|██▏       | 309/1380 [00:31<01:37, 10.93it/s] 23%|██▎       | 311/1380 [00:31<01:37, 10.98it/s] 23%|██▎       | 313/1380 [00:31<01:37, 11.00it/s] 23%|██▎       | 315/1380 [00:31<01:36, 11.03it/s] 23%|██▎       | 317/1380 [00:32<01:36, 11.07it/s] 23%|██▎       | 319/1380 [00:32<01:35, 11.10it/s] 23%|██▎       | 321/1380 [00:32<01:35, 11.06it/s] 23%|██▎       | 323/1380 [00:32<01:35, 11.08it/s] 24%|██▎       | 325/1380 [00:32<01:35, 11.08it/s] 24%|██▎       | 327/1380 [00:32<01:35, 11.08it/s] 24%|██▍       | 329/1380 [00:33<01:34, 11.07it/s] 24%|██▍       | 331/1380 [00:33<01:34, 11.07it/s] 24%|██▍       | 333/1380 [00:33<01:34, 11.07it/s] 24%|██▍       | 335/1380 [00:33<01:34, 11.07it/s] 24%|██▍       | 337/1380 [00:33<01:34, 11.05it/s] 25%|██▍       | 339/1380 [00:34<01:33, 11.08it/s] 25%|██▍       | 341/1380 [00:34<01:33, 11.09it/s] 25%|██▍       | 343/1380 [00:34<01:33, 11.06it/s] 25%|██▌       | 345/1380 [00:34<01:33, 11.07it/s] 25%|██▌       | 347/1380 [00:34<01:33, 11.09it/s] 25%|██▌       | 349/1380 [00:34<01:33, 11.08it/s] 25%|██▌       | 351/1380 [00:35<01:33, 11.06it/s] 26%|██▌       | 353/1380 [00:35<01:32, 11.07it/s] 26%|██▌       | 355/1380 [00:35<01:32, 11.07it/s] 26%|██▌       | 357/1380 [00:35<01:32, 11.06it/s] 26%|██▌       | 359/1380 [00:35<01:32, 11.06it/s] 26%|██▌       | 361/1380 [00:36<01:32, 11.07it/s] 26%|██▋       | 363/1380 [00:36<01:31, 11.07it/s] 26%|██▋       | 365/1380 [00:36<01:31, 11.06it/s] 27%|██▋       | 367/1380 [00:36<01:31, 11.05it/s] 27%|██▋       | 369/1380 [00:36<01:31, 11.09it/s] 27%|██▋       | 371/1380 [00:36<01:30, 11.09it/s] 27%|██▋       | 373/1380 [00:37<01:30, 11.08it/s] 27%|██▋       | 375/1380 [00:37<01:30, 11.08it/s] 27%|██▋       | 377/1380 [00:37<01:30, 11.09it/s] 27%|██▋       | 379/1380 [00:37<01:30, 11.07it/s] 28%|██▊       | 381/1380 [00:37<01:30, 11.06it/s] 28%|██▊       | 383/1380 [00:37<01:30, 11.07it/s] 28%|██▊       | 385/1380 [00:38<01:29, 11.07it/s] 28%|██▊       | 387/1380 [00:38<01:29, 11.06it/s] 28%|██▊       | 389/1380 [00:38<01:29, 11.07it/s] 28%|██▊       | 391/1380 [00:38<01:29, 11.09it/s] 28%|██▊       | 393/1380 [00:38<01:29, 11.06it/s] 29%|██▊       | 395/1380 [00:39<01:29, 11.06it/s] 29%|██▉       | 397/1380 [00:39<01:28, 11.07it/s] 29%|██▉       | 399/1380 [00:39<01:28, 11.08it/s] 29%|██▉       | 401/1380 [00:39<01:28, 11.04it/s] 29%|██▉       | 403/1380 [00:39<01:28, 11.07it/s] 29%|██▉       | 405/1380 [00:39<01:28, 11.05it/s] 29%|██▉       | 407/1380 [00:40<01:28, 11.04it/s] 30%|██▉       | 409/1380 [00:40<01:28, 11.03it/s] 30%|██▉       | 411/1380 [00:40<01:27, 11.04it/s] 30%|██▉       | 413/1380 [00:40<01:27, 11.05it/s] 30%|███       | 415/1380 [00:40<01:27, 11.04it/s] 30%|███       | 417/1380 [00:41<01:27, 11.04it/s] 30%|███       | 419/1380 [00:41<01:27, 11.04it/s] 31%|███       | 421/1380 [00:41<01:26, 11.05it/s] 31%|███       | 423/1380 [00:41<01:26, 11.03it/s] 31%|███       | 425/1380 [00:41<01:26, 11.04it/s] 31%|███       | 427/1380 [00:41<01:26, 11.06it/s] 31%|███       | 429/1380 [00:42<01:26, 11.03it/s] 31%|███       | 431/1380 [00:42<01:26, 11.03it/s] 31%|███▏      | 433/1380 [00:42<01:25, 11.05it/s] 32%|███▏      | 435/1380 [00:42<01:25, 11.05it/s] 32%|███▏      | 437/1380 [00:42<01:25, 11.04it/s] 32%|███▏      | 439/1380 [00:43<01:25, 11.02it/s] 32%|███▏      | 441/1380 [00:43<01:25, 11.02it/s] 32%|███▏      | 443/1380 [00:43<01:24, 11.03it/s] 32%|███▏      | 445/1380 [00:43<01:24, 11.02it/s] 32%|███▏      | 447/1380 [00:43<01:24, 11.02it/s] 33%|███▎      | 449/1380 [00:43<01:24, 11.02it/s] 33%|███▎      | 451/1380 [00:44<01:24, 11.04it/s] 33%|███▎      | 453/1380 [00:44<01:24, 11.00it/s] 33%|███▎      | 455/1380 [00:44<01:24, 11.01it/s] 33%|███▎      | 457/1380 [00:44<01:23, 11.03it/s] 33%|███▎      | 459/1380 [00:44<01:23, 11.05it/s] 33%|███▎      | 461/1380 [00:45<01:23, 11.04it/s] 34%|███▎      | 463/1380 [00:45<01:22, 11.05it/s] 34%|███▎      | 465/1380 [00:45<01:22, 11.06it/s] 34%|███▍      | 467/1380 [00:45<01:22, 11.04it/s] 34%|███▍      | 469/1380 [00:45<01:22, 11.04it/s] 34%|███▍      | 471/1380 [00:45<01:22, 11.04it/s] 34%|███▍      | 473/1380 [00:46<01:22, 11.03it/s] 34%|███▍      | 475/1380 [00:46<01:22, 11.00it/s] 35%|███▍      | 477/1380 [00:46<01:21, 11.02it/s] 35%|███▍      | 479/1380 [00:46<01:21, 11.02it/s] 35%|███▍      | 481/1380 [00:46<01:21, 11.03it/s] 35%|███▌      | 483/1380 [00:47<01:21, 10.99it/s] 35%|███▌      | 485/1380 [00:47<01:21, 11.00it/s] 35%|███▌      | 487/1380 [00:47<01:20, 11.03it/s] 35%|███▌      | 489/1380 [00:47<01:20, 11.04it/s] 36%|███▌      | 491/1380 [00:47<01:20, 11.01it/s] 36%|███▌      | 493/1380 [00:47<01:20, 11.02it/s] 36%|███▌      | 495/1380 [00:48<01:20, 11.01it/s] 36%|███▌      | 497/1380 [00:48<01:20, 11.01it/s] 36%|███▌      | 499/1380 [00:48<01:20, 11.01it/s] 36%|███▋      | 501/1380 [00:48<01:19, 11.04it/s] 36%|███▋      | 503/1380 [00:48<01:19, 11.04it/s] 37%|███▋      | 505/1380 [00:49<01:19, 11.01it/s] 37%|███▋      | 507/1380 [00:49<01:19, 11.01it/s] 37%|███▋      | 509/1380 [00:49<01:19, 11.02it/s] 37%|███▋      | 511/1380 [00:49<01:18, 11.03it/s] 37%|███▋      | 513/1380 [00:49<01:18, 11.01it/s] 37%|███▋      | 515/1380 [00:49<01:18, 11.01it/s] 37%|███▋      | 517/1380 [00:50<01:18, 11.02it/s] 38%|███▊      | 519/1380 [00:50<01:18, 11.02it/s] 38%|███▊      | 521/1380 [00:50<01:18, 10.99it/s] 38%|███▊      | 523/1380 [00:50<01:17, 11.01it/s] 38%|███▊      | 525/1380 [00:50<01:17, 11.03it/s] 38%|███▊      | 527/1380 [00:51<01:17, 11.03it/s] 38%|███▊      | 529/1380 [00:51<01:17, 11.00it/s] 38%|███▊      | 531/1380 [00:51<01:17, 11.01it/s] 39%|███▊      | 533/1380 [00:51<01:16, 11.01it/s] 39%|███▉      | 535/1380 [00:51<01:16, 10.99it/s] 39%|███▉      | 537/1380 [00:51<01:16, 11.01it/s] 39%|███▉      | 539/1380 [00:52<01:16, 11.03it/s] 39%|███▉      | 541/1380 [00:52<01:16, 11.03it/s] 39%|███▉      | 543/1380 [00:52<01:15, 11.02it/s] 39%|███▉      | 545/1380 [00:52<01:15, 11.00it/s] 40%|███▉      | 547/1380 [00:52<01:15, 10.97it/s] 40%|███▉      | 549/1380 [00:53<01:15, 11.02it/s] 40%|███▉      | 551/1380 [00:53<01:15, 11.02it/s]                                                   40%|████      | 552/1380 [00:53<01:15, 11.02it/s][INFO|trainer.py:755] 2023-11-15 20:59:58,969 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 20:59:58,971 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 20:59:58,972 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 20:59:58,972 >>   Batch size = 8
{'eval_loss': 0.38160237669944763, 'eval_accuracy': 0.8656987295825771, 'eval_micro_f1': 0.8656987295825771, 'eval_macro_f1': 0.8443450470234288, 'eval_runtime': 2.5319, 'eval_samples_per_second': 870.478, 'eval_steps_per_second': 109.007, 'epoch': 1.0}
{'loss': 0.3329, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 123.70it/s][A
  9%|▉         | 26/276 [00:00<00:02, 116.62it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 114.35it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 112.69it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.26it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.64it/s][A
 31%|███       | 86/276 [00:00<00:01, 110.35it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 109.82it/s][A
 39%|███▉      | 109/276 [00:00<00:01, 109.07it/s][A
 43%|████▎     | 120/276 [00:01<00:01, 108.52it/s][A
 47%|████▋     | 131/276 [00:01<00:01, 108.24it/s][A
 51%|█████▏    | 142/276 [00:01<00:01, 108.28it/s][A
 55%|█████▌    | 153/276 [00:01<00:01, 108.45it/s][A
 59%|█████▉    | 164/276 [00:01<00:01, 108.31it/s][A
 63%|██████▎   | 175/276 [00:01<00:00, 108.20it/s][A
 67%|██████▋   | 186/276 [00:01<00:00, 108.43it/s][A
 71%|███████▏  | 197/276 [00:01<00:00, 108.37it/s][A
 75%|███████▌  | 208/276 [00:01<00:00, 107.95it/s][A
 79%|███████▉  | 219/276 [00:01<00:00, 107.70it/s][A
 83%|████████▎ | 230/276 [00:02<00:00, 107.51it/s][A
 87%|████████▋ | 241/276 [00:02<00:00, 107.73it/s][A
 91%|█████████▏| 252/276 [00:02<00:00, 107.91it/s][A
 95%|█████████▌| 263/276 [00:02<00:00, 108.09it/s][A
 99%|█████████▉| 274/276 [00:02<00:00, 108.04it/s][A                                                  
                                                  [A 40%|████      | 552/1380 [00:55<01:15, 11.02it/s]
100%|██████████| 276/276 [00:02<00:00, 108.04it/s][A
                                                  [A 40%|████      | 553/1380 [00:55<06:32,  2.10it/s] 40%|████      | 555/1380 [00:56<04:57,  2.78it/s] 40%|████      | 557/1380 [00:56<03:50,  3.58it/s] 41%|████      | 559/1380 [00:56<03:03,  4.49it/s] 41%|████      | 561/1380 [00:56<02:30,  5.45it/s] 41%|████      | 563/1380 [00:56<02:07,  6.42it/s] 41%|████      | 565/1380 [00:57<01:51,  7.34it/s] 41%|████      | 567/1380 [00:57<01:39,  8.15it/s] 41%|████      | 569/1380 [00:57<01:31,  8.84it/s] 41%|████▏     | 571/1380 [00:57<01:26,  9.39it/s] 42%|████▏     | 573/1380 [00:57<01:22,  9.83it/s] 42%|████▏     | 575/1380 [00:57<01:19, 10.15it/s] 42%|████▏     | 577/1380 [00:58<01:17, 10.40it/s] 42%|████▏     | 579/1380 [00:58<01:15, 10.56it/s] 42%|████▏     | 581/1380 [00:58<01:14, 10.66it/s] 42%|████▏     | 583/1380 [00:58<01:14, 10.75it/s] 42%|████▏     | 585/1380 [00:58<01:13, 10.83it/s] 43%|████▎     | 587/1380 [00:59<01:12, 10.88it/s] 43%|████▎     | 589/1380 [00:59<01:12, 10.90it/s] 43%|████▎     | 591/1380 [00:59<01:12, 10.93it/s] 43%|████▎     | 593/1380 [00:59<01:11, 10.97it/s] 43%|████▎     | 595/1380 [00:59<01:11, 10.99it/s] 43%|████▎     | 597/1380 [00:59<01:11, 10.98it/s] 43%|████▎     | 599/1380 [01:00<01:11, 10.98it/s] 44%|████▎     | 601/1380 [01:00<01:10, 10.98it/s] 44%|████▎     | 603/1380 [01:00<01:10, 11.00it/s] 44%|████▍     | 605/1380 [01:00<01:10, 10.97it/s] 44%|████▍     | 607/1380 [01:00<01:10, 10.98it/s] 44%|████▍     | 609/1380 [01:01<01:10, 10.99it/s] 44%|████▍     | 611/1380 [01:01<01:09, 11.00it/s] 44%|████▍     | 613/1380 [01:01<01:09, 11.00it/s] 45%|████▍     | 615/1380 [01:01<01:09, 11.01it/s] 45%|████▍     | 617/1380 [01:01<01:09, 11.01it/s] 45%|████▍     | 619/1380 [01:01<01:09, 10.99it/s] 45%|████▌     | 621/1380 [01:02<01:09, 10.98it/s] 45%|████▌     | 623/1380 [01:02<01:08, 10.98it/s] 45%|████▌     | 625/1380 [01:02<01:08, 11.00it/s] 45%|████▌     | 627/1380 [01:02<01:08, 10.98it/s] 46%|████▌     | 629/1380 [01:02<01:08, 10.99it/s] 46%|████▌     | 631/1380 [01:03<01:08, 11.00it/s] 46%|████▌     | 633/1380 [01:03<01:07, 11.02it/s] 46%|████▌     | 635/1380 [01:03<01:07, 10.99it/s] 46%|████▌     | 637/1380 [01:03<01:07, 10.98it/s] 46%|████▋     | 639/1380 [01:03<01:07, 11.00it/s] 46%|████▋     | 641/1380 [01:03<01:07, 10.98it/s] 47%|████▋     | 643/1380 [01:04<01:07, 10.99it/s] 47%|████▋     | 645/1380 [01:04<01:06, 11.00it/s] 47%|████▋     | 647/1380 [01:04<01:06, 11.02it/s] 47%|████▋     | 649/1380 [01:04<01:06, 11.00it/s] 47%|████▋     | 651/1380 [01:04<01:06, 11.00it/s] 47%|████▋     | 653/1380 [01:05<01:06, 11.00it/s] 47%|████▋     | 655/1380 [01:05<01:05, 11.02it/s] 48%|████▊     | 657/1380 [01:05<01:05, 11.00it/s] 48%|████▊     | 659/1380 [01:05<01:05, 10.99it/s] 48%|████▊     | 661/1380 [01:05<01:05, 10.99it/s] 48%|████▊     | 663/1380 [01:05<01:05, 10.96it/s] 48%|████▊     | 665/1380 [01:06<01:05, 10.95it/s] 48%|████▊     | 667/1380 [01:06<01:05, 10.95it/s] 48%|████▊     | 669/1380 [01:06<01:04, 10.96it/s] 49%|████▊     | 671/1380 [01:06<01:04, 10.96it/s] 49%|████▉     | 673/1380 [01:06<01:04, 10.96it/s] 49%|████▉     | 675/1380 [01:07<01:04, 10.97it/s] 49%|████▉     | 677/1380 [01:07<01:04, 10.97it/s] 49%|████▉     | 679/1380 [01:07<01:03, 10.96it/s] 49%|████▉     | 681/1380 [01:07<01:03, 10.98it/s] 49%|████▉     | 683/1380 [01:07<01:03, 10.99it/s] 50%|████▉     | 685/1380 [01:07<01:03, 10.99it/s] 50%|████▉     | 687/1380 [01:08<01:03, 10.98it/s] 50%|████▉     | 689/1380 [01:08<01:02, 10.99it/s] 50%|█████     | 691/1380 [01:08<01:02, 11.00it/s] 50%|█████     | 693/1380 [01:08<01:02, 11.00it/s] 50%|█████     | 695/1380 [01:08<01:02, 10.98it/s] 51%|█████     | 697/1380 [01:09<01:02, 10.99it/s] 51%|█████     | 699/1380 [01:09<01:01, 11.00it/s] 51%|█████     | 701/1380 [01:09<01:01, 10.98it/s] 51%|█████     | 703/1380 [01:09<01:01, 10.98it/s] 51%|█████     | 705/1380 [01:09<01:01, 10.98it/s] 51%|█████     | 707/1380 [01:09<01:01, 10.99it/s] 51%|█████▏    | 709/1380 [01:10<01:01, 10.99it/s] 52%|█████▏    | 711/1380 [01:10<01:00, 10.98it/s] 52%|█████▏    | 713/1380 [01:10<01:00, 10.98it/s] 52%|█████▏    | 715/1380 [01:10<01:00, 10.95it/s] 52%|█████▏    | 717/1380 [01:10<01:00, 10.99it/s] 52%|█████▏    | 719/1380 [01:11<01:00, 11.00it/s] 52%|█████▏    | 721/1380 [01:11<00:59, 11.00it/s] 52%|█████▏    | 723/1380 [01:11<00:59, 10.97it/s] 53%|█████▎    | 725/1380 [01:11<00:59, 10.98it/s] 53%|█████▎    | 727/1380 [01:11<00:59, 10.99it/s] 53%|█████▎    | 729/1380 [01:11<00:59, 11.00it/s] 53%|█████▎    | 731/1380 [01:12<00:59, 10.98it/s] 53%|█████▎    | 733/1380 [01:12<00:58, 10.99it/s] 53%|█████▎    | 735/1380 [01:12<00:58, 10.99it/s] 53%|█████▎    | 737/1380 [01:12<00:58, 11.00it/s] 54%|█████▎    | 739/1380 [01:12<00:58, 10.99it/s] 54%|█████▎    | 741/1380 [01:13<00:58, 10.98it/s] 54%|█████▍    | 743/1380 [01:13<00:58, 10.98it/s] 54%|█████▍    | 745/1380 [01:13<00:57, 10.99it/s] 54%|█████▍    | 747/1380 [01:13<00:57, 10.98it/s] 54%|█████▍    | 749/1380 [01:13<00:57, 10.99it/s] 54%|█████▍    | 751/1380 [01:13<00:57, 10.99it/s] 55%|█████▍    | 753/1380 [01:14<00:57, 10.97it/s] 55%|█████▍    | 755/1380 [01:14<00:56, 10.99it/s] 55%|█████▍    | 757/1380 [01:14<00:56, 10.99it/s] 55%|█████▌    | 759/1380 [01:14<00:56, 10.99it/s] 55%|█████▌    | 761/1380 [01:14<00:56, 10.97it/s] 55%|█████▌    | 763/1380 [01:15<00:56, 10.98it/s] 55%|█████▌    | 765/1380 [01:15<00:55, 10.99it/s] 56%|█████▌    | 767/1380 [01:15<00:55, 10.98it/s] 56%|█████▌    | 769/1380 [01:15<00:55, 10.96it/s] 56%|█████▌    | 771/1380 [01:15<00:55, 10.97it/s] 56%|█████▌    | 773/1380 [01:16<00:55, 10.97it/s] 56%|█████▌    | 775/1380 [01:16<00:55, 10.96it/s] 56%|█████▋    | 777/1380 [01:16<00:54, 10.97it/s] 56%|█████▋    | 779/1380 [01:16<00:54, 10.98it/s] 57%|█████▋    | 781/1380 [01:16<00:54, 10.98it/s] 57%|█████▋    | 783/1380 [01:16<00:54, 10.97it/s] 57%|█████▋    | 785/1380 [01:17<00:54, 10.97it/s] 57%|█████▋    | 787/1380 [01:17<00:54, 10.97it/s] 57%|█████▋    | 789/1380 [01:17<00:53, 10.96it/s] 57%|█████▋    | 791/1380 [01:17<00:53, 10.96it/s] 57%|█████▋    | 793/1380 [01:17<00:53, 10.97it/s] 58%|█████▊    | 795/1380 [01:18<00:53, 10.97it/s] 58%|█████▊    | 797/1380 [01:18<00:53, 10.96it/s] 58%|█████▊    | 799/1380 [01:18<00:52, 10.97it/s] 58%|█████▊    | 801/1380 [01:18<00:52, 10.98it/s] 58%|█████▊    | 803/1380 [01:18<00:52, 10.97it/s] 58%|█████▊    | 805/1380 [01:18<00:52, 10.94it/s] 58%|█████▊    | 807/1380 [01:19<00:52, 10.96it/s] 59%|█████▊    | 809/1380 [01:19<00:52, 10.97it/s] 59%|█████▉    | 811/1380 [01:19<00:51, 10.97it/s] 59%|█████▉    | 813/1380 [01:19<00:51, 10.96it/s] 59%|█████▉    | 815/1380 [01:19<00:51, 10.97it/s] 59%|█████▉    | 817/1380 [01:20<00:51, 10.97it/s] 59%|█████▉    | 819/1380 [01:20<00:51, 10.94it/s] 59%|█████▉    | 821/1380 [01:20<00:51, 10.96it/s] 60%|█████▉    | 823/1380 [01:20<00:50, 10.97it/s] 60%|█████▉    | 825/1380 [01:20<00:50, 10.97it/s] 60%|█████▉    | 827/1380 [01:20<00:50, 10.97it/s]                                                   60%|██████    | 828/1380 [01:20<00:50, 10.97it/s][INFO|trainer.py:755] 2023-11-15 21:00:26,666 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:00:26,668 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:00:26,668 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:00:26,669 >>   Batch size = 8
{'eval_loss': 0.3782508075237274, 'eval_accuracy': 0.8661524500907442, 'eval_micro_f1': 0.8661524500907442, 'eval_macro_f1': 0.8425739608086285, 'eval_runtime': 2.5857, 'eval_samples_per_second': 852.367, 'eval_steps_per_second': 106.739, 'epoch': 2.0}
{'loss': 0.2577, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 122.65it/s][A
  9%|▉         | 26/276 [00:00<00:02, 115.96it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 113.77it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 112.35it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.04it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.36it/s][A
 31%|███       | 86/276 [00:00<00:01, 109.57it/s][A
 35%|███▌      | 97/276 [00:00<00:01, 108.91it/s][A
 39%|███▉      | 108/276 [00:00<00:01, 108.12it/s][A
 43%|████▎     | 119/276 [00:01<00:01, 107.84it/s][A
 47%|████▋     | 130/276 [00:01<00:01, 107.96it/s][A
 51%|█████     | 141/276 [00:01<00:01, 108.09it/s][A
 55%|█████▌    | 152/276 [00:01<00:01, 108.10it/s][A
 59%|█████▉    | 163/276 [00:01<00:01, 108.20it/s][A
 63%|██████▎   | 174/276 [00:01<00:00, 107.99it/s][A
 67%|██████▋   | 185/276 [00:01<00:00, 107.77it/s][A
 71%|███████   | 196/276 [00:01<00:00, 106.87it/s][A
 75%|███████▌  | 207/276 [00:01<00:00, 106.38it/s][A
 79%|███████▉  | 218/276 [00:02<00:00, 106.24it/s][A
 83%|████████▎ | 229/276 [00:02<00:00, 106.24it/s][A
 87%|████████▋ | 240/276 [00:02<00:00, 106.57it/s][A
 91%|█████████ | 251/276 [00:02<00:00, 106.87it/s][A
 95%|█████████▍| 262/276 [00:02<00:00, 106.99it/s][A
 99%|█████████▉| 273/276 [00:02<00:00, 106.66it/s][A                                                  
                                                  [A 60%|██████    | 828/1380 [01:23<00:50, 10.97it/s]
100%|██████████| 276/276 [00:02<00:00, 106.66it/s][A
                                                  [A 60%|██████    | 829/1380 [01:23<04:23,  2.09it/s] 60%|██████    | 831/1380 [01:23<03:18,  2.76it/s] 60%|██████    | 833/1380 [01:24<02:33,  3.56it/s] 61%|██████    | 835/1380 [01:24<02:02,  4.46it/s] 61%|██████    | 837/1380 [01:24<01:40,  5.42it/s] 61%|██████    | 839/1380 [01:24<01:24,  6.39it/s] 61%|██████    | 841/1380 [01:24<01:13,  7.30it/s] 61%|██████    | 843/1380 [01:24<01:06,  8.11it/s] 61%|██████    | 845/1380 [01:25<01:00,  8.80it/s] 61%|██████▏   | 847/1380 [01:25<00:56,  9.36it/s] 62%|██████▏   | 849/1380 [01:25<00:54,  9.77it/s] 62%|██████▏   | 851/1380 [01:25<00:52, 10.09it/s] 62%|██████▏   | 853/1380 [01:25<00:50, 10.35it/s] 62%|██████▏   | 855/1380 [01:26<00:49, 10.53it/s] 62%|██████▏   | 857/1380 [01:26<00:49, 10.65it/s] 62%|██████▏   | 859/1380 [01:26<00:48, 10.75it/s] 62%|██████▏   | 861/1380 [01:26<00:47, 10.82it/s] 63%|██████▎   | 863/1380 [01:26<00:47, 10.84it/s] 63%|██████▎   | 865/1380 [01:26<00:47, 10.88it/s] 63%|██████▎   | 867/1380 [01:27<00:47, 10.91it/s] 63%|██████▎   | 869/1380 [01:27<00:46, 10.93it/s] 63%|██████▎   | 871/1380 [01:27<00:46, 10.91it/s] 63%|██████▎   | 873/1380 [01:27<00:46, 10.93it/s] 63%|██████▎   | 875/1380 [01:27<00:46, 10.93it/s] 64%|██████▎   | 877/1380 [01:28<00:45, 10.94it/s] 64%|██████▎   | 879/1380 [01:28<00:45, 10.91it/s] 64%|██████▍   | 881/1380 [01:28<00:45, 10.93it/s] 64%|██████▍   | 883/1380 [01:28<00:45, 10.92it/s] 64%|██████▍   | 885/1380 [01:28<00:45, 10.92it/s] 64%|██████▍   | 887/1380 [01:28<00:45, 10.93it/s] 64%|██████▍   | 889/1380 [01:29<00:44, 10.94it/s] 65%|██████▍   | 891/1380 [01:29<00:44, 10.94it/s] 65%|██████▍   | 893/1380 [01:29<00:44, 10.92it/s] 65%|██████▍   | 895/1380 [01:29<00:44, 10.93it/s] 65%|██████▌   | 897/1380 [01:29<00:44, 10.92it/s] 65%|██████▌   | 899/1380 [01:30<00:43, 10.96it/s] 65%|██████▌   | 901/1380 [01:30<00:43, 10.94it/s] 65%|██████▌   | 903/1380 [01:30<00:43, 10.95it/s] 66%|██████▌   | 905/1380 [01:30<00:43, 10.95it/s] 66%|██████▌   | 907/1380 [01:30<00:43, 10.94it/s] 66%|██████▌   | 909/1380 [01:30<00:42, 10.95it/s] 66%|██████▌   | 911/1380 [01:31<00:42, 10.95it/s] 66%|██████▌   | 913/1380 [01:31<00:42, 10.95it/s] 66%|██████▋   | 915/1380 [01:31<00:42, 10.95it/s] 66%|██████▋   | 917/1380 [01:31<00:42, 10.95it/s] 67%|██████▋   | 919/1380 [01:31<00:42, 10.96it/s] 67%|██████▋   | 921/1380 [01:32<00:41, 10.96it/s] 67%|██████▋   | 923/1380 [01:32<00:41, 10.95it/s] 67%|██████▋   | 925/1380 [01:32<00:41, 10.95it/s] 67%|██████▋   | 927/1380 [01:32<00:41, 10.96it/s] 67%|██████▋   | 929/1380 [01:32<00:41, 10.94it/s] 67%|██████▋   | 931/1380 [01:33<00:41, 10.94it/s] 68%|██████▊   | 933/1380 [01:33<00:40, 10.95it/s] 68%|██████▊   | 935/1380 [01:33<00:40, 10.95it/s] 68%|██████▊   | 937/1380 [01:33<00:40, 10.95it/s] 68%|██████▊   | 939/1380 [01:33<00:40, 10.95it/s] 68%|██████▊   | 941/1380 [01:33<00:40, 10.95it/s] 68%|██████▊   | 943/1380 [01:34<00:39, 10.97it/s] 68%|██████▊   | 945/1380 [01:34<00:39, 10.96it/s] 69%|██████▊   | 947/1380 [01:34<00:39, 10.96it/s] 69%|██████▉   | 949/1380 [01:34<00:39, 10.96it/s] 69%|██████▉   | 951/1380 [01:34<00:39, 10.94it/s] 69%|██████▉   | 953/1380 [01:35<00:39, 10.95it/s] 69%|██████▉   | 955/1380 [01:35<00:38, 10.94it/s] 69%|██████▉   | 957/1380 [01:35<00:38, 10.96it/s] 69%|██████▉   | 959/1380 [01:35<00:38, 10.94it/s] 70%|██████▉   | 961/1380 [01:35<00:38, 10.95it/s] 70%|██████▉   | 963/1380 [01:35<00:38, 10.95it/s] 70%|██████▉   | 965/1380 [01:36<00:37, 10.96it/s] 70%|███████   | 967/1380 [01:36<00:37, 10.94it/s] 70%|███████   | 969/1380 [01:36<00:37, 10.95it/s] 70%|███████   | 971/1380 [01:36<00:37, 10.95it/s] 71%|███████   | 973/1380 [01:36<00:37, 10.94it/s] 71%|███████   | 975/1380 [01:37<00:36, 10.95it/s] 71%|███████   | 977/1380 [01:37<00:36, 10.95it/s] 71%|███████   | 979/1380 [01:37<00:36, 10.95it/s] 71%|███████   | 981/1380 [01:37<00:36, 10.94it/s] 71%|███████   | 983/1380 [01:37<00:36, 10.95it/s] 71%|███████▏  | 985/1380 [01:37<00:36, 10.94it/s] 72%|███████▏  | 987/1380 [01:38<00:35, 10.95it/s] 72%|███████▏  | 989/1380 [01:38<00:35, 10.93it/s] 72%|███████▏  | 991/1380 [01:38<00:35, 10.94it/s] 72%|███████▏  | 993/1380 [01:38<00:35, 10.93it/s] 72%|███████▏  | 995/1380 [01:38<00:35, 10.93it/s] 72%|███████▏  | 997/1380 [01:39<00:35, 10.94it/s] 72%|███████▏  | 999/1380 [01:39<00:34, 10.95it/s] 73%|███████▎  | 1001/1380 [01:39<00:34, 10.96it/s] 73%|███████▎  | 1003/1380 [01:39<00:34, 10.94it/s] 73%|███████▎  | 1005/1380 [01:39<00:34, 10.93it/s] 73%|███████▎  | 1007/1380 [01:39<00:34, 10.93it/s] 73%|███████▎  | 1009/1380 [01:40<00:33, 10.94it/s] 73%|███████▎  | 1011/1380 [01:40<00:33, 10.92it/s] 73%|███████▎  | 1013/1380 [01:40<00:33, 10.94it/s] 74%|███████▎  | 1015/1380 [01:40<00:33, 10.95it/s] 74%|███████▎  | 1017/1380 [01:40<00:33, 10.92it/s] 74%|███████▍  | 1019/1380 [01:41<00:33, 10.91it/s] 74%|███████▍  | 1021/1380 [01:41<00:32, 10.91it/s] 74%|███████▍  | 1023/1380 [01:41<00:32, 10.92it/s] 74%|███████▍  | 1025/1380 [01:41<00:32, 10.92it/s] 74%|███████▍  | 1027/1380 [01:41<00:32, 10.95it/s] 75%|███████▍  | 1029/1380 [01:41<00:32, 10.97it/s] 75%|███████▍  | 1031/1380 [01:42<00:31, 10.97it/s] 75%|███████▍  | 1033/1380 [01:42<00:31, 10.94it/s] 75%|███████▌  | 1035/1380 [01:42<00:31, 10.95it/s] 75%|███████▌  | 1037/1380 [01:42<00:31, 10.96it/s] 75%|███████▌  | 1039/1380 [01:42<00:31, 10.95it/s] 75%|███████▌  | 1041/1380 [01:43<00:30, 10.95it/s] 76%|███████▌  | 1043/1380 [01:43<00:30, 10.95it/s] 76%|███████▌  | 1045/1380 [01:43<00:30, 10.96it/s] 76%|███████▌  | 1047/1380 [01:43<00:30, 10.93it/s] 76%|███████▌  | 1049/1380 [01:43<00:30, 10.94it/s] 76%|███████▌  | 1051/1380 [01:43<00:30, 10.95it/s] 76%|███████▋  | 1053/1380 [01:44<00:29, 10.93it/s] 76%|███████▋  | 1055/1380 [01:44<00:29, 10.94it/s] 77%|███████▋  | 1057/1380 [01:44<00:29, 10.96it/s] 77%|███████▋  | 1059/1380 [01:44<00:29, 10.97it/s] 77%|███████▋  | 1061/1380 [01:44<00:29, 10.95it/s] 77%|███████▋  | 1063/1380 [01:45<00:28, 10.95it/s] 77%|███████▋  | 1065/1380 [01:45<00:28, 10.95it/s] 77%|███████▋  | 1067/1380 [01:45<00:28, 10.97it/s] 77%|███████▋  | 1069/1380 [01:45<00:28, 10.93it/s] 78%|███████▊  | 1071/1380 [01:45<00:28, 10.96it/s] 78%|███████▊  | 1073/1380 [01:45<00:28, 10.87it/s] 78%|███████▊  | 1075/1380 [01:46<00:27, 10.90it/s] 78%|███████▊  | 1077/1380 [01:46<00:27, 10.91it/s] 78%|███████▊  | 1079/1380 [01:46<00:27, 10.92it/s] 78%|███████▊  | 1081/1380 [01:46<00:27, 10.92it/s] 78%|███████▊  | 1083/1380 [01:46<00:27, 10.93it/s] 79%|███████▊  | 1085/1380 [01:47<00:26, 10.93it/s] 79%|███████▉  | 1087/1380 [01:47<00:26, 10.92it/s] 79%|███████▉  | 1089/1380 [01:47<00:26, 10.94it/s] 79%|███████▉  | 1091/1380 [01:47<00:26, 10.91it/s] 79%|███████▉  | 1093/1380 [01:47<00:26, 10.90it/s] 79%|███████▉  | 1095/1380 [01:48<00:26, 10.93it/s] 79%|███████▉  | 1097/1380 [01:48<00:25, 10.93it/s] 80%|███████▉  | 1099/1380 [01:48<00:25, 10.91it/s] 80%|███████▉  | 1101/1380 [01:48<00:25, 10.93it/s] 80%|███████▉  | 1103/1380 [01:48<00:25, 10.94it/s]                                                    80%|████████  | 1104/1380 [01:48<00:25, 10.94it/s][INFO|trainer.py:755] 2023-11-15 21:00:54,473 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:00:54,474 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:00:54,475 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:00:54,475 >>   Batch size = 8
{'eval_loss': 0.42337971925735474, 'eval_accuracy': 0.8652450090744102, 'eval_micro_f1': 0.8652450090744102, 'eval_macro_f1': 0.8515176529379543, 'eval_runtime': 2.6019, 'eval_samples_per_second': 847.072, 'eval_steps_per_second': 106.076, 'epoch': 3.0}
{'loss': 0.1956, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 122.12it/s][A
  9%|▉         | 26/276 [00:00<00:02, 115.49it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 113.55it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 112.09it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.15it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.30it/s][A
 31%|███       | 86/276 [00:00<00:01, 109.59it/s][A
 35%|███▌      | 97/276 [00:00<00:01, 108.99it/s][A
 39%|███▉      | 108/276 [00:00<00:01, 108.10it/s][A
 43%|████▎     | 119/276 [00:01<00:01, 107.78it/s][A
 47%|████▋     | 130/276 [00:01<00:01, 107.86it/s][A
 51%|█████     | 141/276 [00:01<00:01, 108.18it/s][A
 55%|█████▌    | 152/276 [00:01<00:01, 108.19it/s][A
 59%|█████▉    | 163/276 [00:01<00:01, 108.06it/s][A
 63%|██████▎   | 174/276 [00:01<00:00, 107.83it/s][A
 67%|██████▋   | 185/276 [00:01<00:00, 107.61it/s][A
 71%|███████   | 196/276 [00:01<00:00, 107.21it/s][A
 75%|███████▌  | 207/276 [00:01<00:00, 106.67it/s][A
 79%|███████▉  | 218/276 [00:02<00:00, 106.11it/s][A
 83%|████████▎ | 229/276 [00:02<00:00, 106.06it/s][A
 87%|████████▋ | 240/276 [00:02<00:00, 106.39it/s][A
 91%|█████████ | 251/276 [00:02<00:00, 106.63it/s][A
 95%|█████████▍| 262/276 [00:02<00:00, 106.70it/s][A
 99%|█████████▉| 273/276 [00:02<00:00, 106.68it/s][A                                                   
                                                  [A 80%|████████  | 1104/1380 [01:51<00:25, 10.94it/s]
100%|██████████| 276/276 [00:02<00:00, 106.68it/s][A
                                                  [A 80%|████████  | 1105/1380 [01:51<02:11,  2.09it/s] 80%|████████  | 1107/1380 [01:51<01:39,  2.75it/s] 80%|████████  | 1109/1380 [01:51<01:16,  3.55it/s] 81%|████████  | 1111/1380 [01:52<01:00,  4.45it/s] 81%|████████  | 1113/1380 [01:52<00:49,  5.42it/s] 81%|████████  | 1115/1380 [01:52<00:41,  6.38it/s] 81%|████████  | 1117/1380 [01:52<00:36,  7.29it/s] 81%|████████  | 1119/1380 [01:52<00:32,  8.11it/s] 81%|████████  | 1121/1380 [01:52<00:29,  8.80it/s] 81%|████████▏ | 1123/1380 [01:53<00:27,  9.36it/s] 82%|████████▏ | 1125/1380 [01:53<00:26,  9.77it/s] 82%|████████▏ | 1127/1380 [01:53<00:25, 10.09it/s] 82%|████████▏ | 1129/1380 [01:53<00:24, 10.33it/s] 82%|████████▏ | 1131/1380 [01:53<00:23, 10.50it/s] 82%|████████▏ | 1133/1380 [01:54<00:23, 10.65it/s] 82%|████████▏ | 1135/1380 [01:54<00:22, 10.74it/s] 82%|████████▏ | 1137/1380 [01:54<00:22, 10.79it/s] 83%|████████▎ | 1139/1380 [01:54<00:22, 10.82it/s] 83%|████████▎ | 1141/1380 [01:54<00:21, 10.88it/s] 83%|████████▎ | 1143/1380 [01:54<00:21, 10.89it/s] 83%|████████▎ | 1145/1380 [01:55<00:21, 10.92it/s] 83%|████████▎ | 1147/1380 [01:55<00:21, 10.93it/s] 83%|████████▎ | 1149/1380 [01:55<00:21, 10.92it/s] 83%|████████▎ | 1151/1380 [01:55<00:20, 10.93it/s] 84%|████████▎ | 1153/1380 [01:55<00:20, 10.93it/s] 84%|████████▎ | 1155/1380 [01:56<00:20, 10.94it/s] 84%|████████▍ | 1157/1380 [01:56<00:20, 10.93it/s] 84%|████████▍ | 1159/1380 [01:56<00:20, 10.92it/s] 84%|████████▍ | 1161/1380 [01:56<00:19, 10.95it/s] 84%|████████▍ | 1163/1380 [01:56<00:19, 10.94it/s] 84%|████████▍ | 1165/1380 [01:56<00:19, 10.96it/s] 85%|████████▍ | 1167/1380 [01:57<00:19, 10.95it/s] 85%|████████▍ | 1169/1380 [01:57<00:19, 10.96it/s] 85%|████████▍ | 1171/1380 [01:57<00:19, 10.95it/s] 85%|████████▌ | 1173/1380 [01:57<00:18, 10.94it/s] 85%|████████▌ | 1175/1380 [01:57<00:18, 10.94it/s] 85%|████████▌ | 1177/1380 [01:58<00:18, 10.94it/s] 85%|████████▌ | 1179/1380 [01:58<00:18, 10.94it/s] 86%|████████▌ | 1181/1380 [01:58<00:18, 10.94it/s] 86%|████████▌ | 1183/1380 [01:58<00:17, 10.95it/s] 86%|████████▌ | 1185/1380 [01:58<00:17, 10.93it/s] 86%|████████▌ | 1187/1380 [01:58<00:17, 10.94it/s] 86%|████████▌ | 1189/1380 [01:59<00:17, 10.95it/s] 86%|████████▋ | 1191/1380 [01:59<00:17, 10.94it/s] 86%|████████▋ | 1193/1380 [01:59<00:17, 10.93it/s] 87%|████████▋ | 1195/1380 [01:59<00:16, 10.93it/s] 87%|████████▋ | 1197/1380 [01:59<00:16, 10.95it/s] 87%|████████▋ | 1199/1380 [02:00<00:16, 10.94it/s] 87%|████████▋ | 1201/1380 [02:00<00:16, 10.95it/s] 87%|████████▋ | 1203/1380 [02:00<00:16, 10.94it/s] 87%|████████▋ | 1205/1380 [02:00<00:15, 10.97it/s] 87%|████████▋ | 1207/1380 [02:00<00:15, 10.95it/s] 88%|████████▊ | 1209/1380 [02:01<00:15, 10.96it/s] 88%|████████▊ | 1211/1380 [02:01<00:15, 10.96it/s] 88%|████████▊ | 1213/1380 [02:01<00:15, 10.96it/s] 88%|████████▊ | 1215/1380 [02:01<00:15, 10.96it/s] 88%|████████▊ | 1217/1380 [02:01<00:14, 10.94it/s] 88%|████████▊ | 1219/1380 [02:01<00:14, 10.97it/s] 88%|████████▊ | 1221/1380 [02:02<00:14, 10.95it/s] 89%|████████▊ | 1223/1380 [02:02<00:14, 10.96it/s] 89%|████████▉ | 1225/1380 [02:02<00:14, 10.95it/s] 89%|████████▉ | 1227/1380 [02:02<00:13, 10.96it/s] 89%|████████▉ | 1229/1380 [02:02<00:13, 10.95it/s] 89%|████████▉ | 1231/1380 [02:03<00:13, 10.93it/s] 89%|████████▉ | 1233/1380 [02:03<00:13, 10.95it/s] 89%|████████▉ | 1235/1380 [02:03<00:13, 10.95it/s] 90%|████████▉ | 1237/1380 [02:03<00:13, 10.96it/s] 90%|████████▉ | 1239/1380 [02:03<00:12, 10.95it/s] 90%|████████▉ | 1241/1380 [02:03<00:12, 10.95it/s] 90%|█████████ | 1243/1380 [02:04<00:12, 10.94it/s] 90%|█████████ | 1245/1380 [02:04<00:12, 10.95it/s] 90%|█████████ | 1247/1380 [02:04<00:12, 10.95it/s] 91%|█████████ | 1249/1380 [02:04<00:11, 10.95it/s] 91%|█████████ | 1251/1380 [02:04<00:11, 10.96it/s] 91%|█████████ | 1253/1380 [02:05<00:11, 10.96it/s] 91%|█████████ | 1255/1380 [02:05<00:11, 10.96it/s] 91%|█████████ | 1257/1380 [02:05<00:11, 10.95it/s] 91%|█████████ | 1259/1380 [02:05<00:11, 10.96it/s] 91%|█████████▏| 1261/1380 [02:05<00:10, 10.97it/s] 92%|█████████▏| 1263/1380 [02:05<00:10, 10.95it/s] 92%|█████████▏| 1265/1380 [02:06<00:10, 10.96it/s] 92%|█████████▏| 1267/1380 [02:06<00:10, 10.96it/s] 92%|█████████▏| 1269/1380 [02:06<00:10, 10.96it/s] 92%|█████████▏| 1271/1380 [02:06<00:09, 10.93it/s] 92%|█████████▏| 1273/1380 [02:06<00:09, 10.95it/s] 92%|█████████▏| 1275/1380 [02:07<00:09, 10.97it/s] 93%|█████████▎| 1277/1380 [02:07<00:09, 10.96it/s] 93%|█████████▎| 1279/1380 [02:07<00:09, 10.95it/s] 93%|█████████▎| 1281/1380 [02:07<00:09, 10.96it/s] 93%|█████████▎| 1283/1380 [02:07<00:08, 10.97it/s] 93%|█████████▎| 1285/1380 [02:07<00:08, 10.95it/s] 93%|█████████▎| 1287/1380 [02:08<00:08, 10.95it/s] 93%|█████████▎| 1289/1380 [02:08<00:08, 10.95it/s] 94%|█████████▎| 1291/1380 [02:08<00:08, 10.96it/s] 94%|█████████▎| 1293/1380 [02:08<00:07, 10.94it/s] 94%|█████████▍| 1295/1380 [02:08<00:07, 10.96it/s] 94%|█████████▍| 1297/1380 [02:09<00:07, 10.97it/s] 94%|█████████▍| 1299/1380 [02:09<00:07, 10.96it/s] 94%|█████████▍| 1301/1380 [02:09<00:07, 10.94it/s] 94%|█████████▍| 1303/1380 [02:09<00:07, 10.95it/s] 95%|█████████▍| 1305/1380 [02:09<00:06, 10.96it/s] 95%|█████████▍| 1307/1380 [02:09<00:06, 10.94it/s] 95%|█████████▍| 1309/1380 [02:10<00:06, 10.95it/s] 95%|█████████▌| 1311/1380 [02:10<00:06, 10.97it/s] 95%|█████████▌| 1313/1380 [02:10<00:06, 10.97it/s] 95%|█████████▌| 1315/1380 [02:10<00:05, 10.95it/s] 95%|█████████▌| 1317/1380 [02:10<00:05, 10.95it/s] 96%|█████████▌| 1319/1380 [02:11<00:05, 10.97it/s] 96%|█████████▌| 1321/1380 [02:11<00:05, 10.95it/s] 96%|█████████▌| 1323/1380 [02:11<00:05, 10.94it/s] 96%|█████████▌| 1325/1380 [02:11<00:05, 10.96it/s] 96%|█████████▌| 1327/1380 [02:11<00:04, 10.97it/s] 96%|█████████▋| 1329/1380 [02:11<00:04, 10.94it/s] 96%|█████████▋| 1331/1380 [02:12<00:04, 10.94it/s] 97%|█████████▋| 1333/1380 [02:12<00:04, 10.95it/s] 97%|█████████▋| 1335/1380 [02:12<00:04, 10.98it/s] 97%|█████████▋| 1337/1380 [02:12<00:03, 10.96it/s] 97%|█████████▋| 1339/1380 [02:12<00:03, 10.94it/s] 97%|█████████▋| 1341/1380 [02:13<00:03, 10.96it/s] 97%|█████████▋| 1343/1380 [02:13<00:03, 10.96it/s] 97%|█████████▋| 1345/1380 [02:13<00:03, 10.94it/s] 98%|█████████▊| 1347/1380 [02:13<00:03, 10.95it/s] 98%|█████████▊| 1349/1380 [02:13<00:02, 10.96it/s] 98%|█████████▊| 1351/1380 [02:13<00:02, 10.95it/s] 98%|█████████▊| 1353/1380 [02:14<00:02, 10.95it/s] 98%|█████████▊| 1355/1380 [02:14<00:02, 10.96it/s] 98%|█████████▊| 1357/1380 [02:14<00:02, 10.96it/s] 98%|█████████▊| 1359/1380 [02:14<00:01, 10.95it/s] 99%|█████████▊| 1361/1380 [02:14<00:01, 10.94it/s] 99%|█████████▉| 1363/1380 [02:15<00:01, 10.95it/s] 99%|█████████▉| 1365/1380 [02:15<00:01, 10.92it/s] 99%|█████████▉| 1367/1380 [02:15<00:01, 10.91it/s] 99%|█████████▉| 1369/1380 [02:15<00:01, 10.94it/s] 99%|█████████▉| 1371/1380 [02:15<00:00, 10.94it/s] 99%|█████████▉| 1373/1380 [02:15<00:00, 10.91it/s]100%|█████████▉| 1375/1380 [02:16<00:00, 10.91it/s]100%|█████████▉| 1377/1380 [02:16<00:00, 10.92it/s]100%|█████████▉| 1379/1380 [02:16<00:00, 10.91it/s]                                                   100%|██████████| 1380/1380 [02:16<00:00, 10.91it/s][INFO|trainer.py:755] 2023-11-15 21:01:22,268 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:01:22,270 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:01:22,270 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:01:22,270 >>   Batch size = 8
{'eval_loss': 0.46646445989608765, 'eval_accuracy': 0.8611615245009074, 'eval_micro_f1': 0.8611615245009075, 'eval_macro_f1': 0.8457718573436992, 'eval_runtime': 2.604, 'eval_samples_per_second': 846.388, 'eval_steps_per_second': 105.991, 'epoch': 4.0}
{'loss': 0.1541, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 122.05it/s][A
  9%|▉         | 26/276 [00:00<00:02, 115.72it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 113.33it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 111.90it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 110.64it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 109.74it/s][A
 31%|███       | 85/276 [00:00<00:01, 109.16it/s][A
 35%|███▍      | 96/276 [00:00<00:01, 108.89it/s][A
 39%|███▉      | 107/276 [00:00<00:01, 108.09it/s][A
 43%|████▎     | 118/276 [00:01<00:01, 107.70it/s][A
 47%|████▋     | 129/276 [00:01<00:01, 107.78it/s][A
 51%|█████     | 140/276 [00:01<00:01, 107.69it/s][A
 55%|█████▍    | 151/276 [00:01<00:01, 107.90it/s][A
 59%|█████▊    | 162/276 [00:01<00:01, 107.87it/s][A
 63%|██████▎   | 173/276 [00:01<00:00, 107.71it/s][A
 67%|██████▋   | 184/276 [00:01<00:00, 107.46it/s][A
 71%|███████   | 195/276 [00:01<00:00, 106.82it/s][A
 75%|███████▍  | 206/276 [00:01<00:00, 106.40it/s][A
 79%|███████▊  | 217/276 [00:02<00:00, 105.87it/s][A
 83%|████████▎ | 228/276 [00:02<00:00, 105.85it/s][A
 87%|████████▋ | 239/276 [00:02<00:00, 106.05it/s][A
 91%|█████████ | 250/276 [00:02<00:00, 106.18it/s][A
 95%|█████████▍| 261/276 [00:02<00:00, 106.36it/s][A
 99%|█████████▊| 272/276 [00:02<00:00, 106.47it/s][A                                                   
                                                  [A100%|██████████| 1380/1380 [02:19<00:00, 10.91it/s]
100%|██████████| 276/276 [00:02<00:00, 106.47it/s][A
                                                  [A[INFO|trainer.py:1963] 2023-11-15 21:01:24,883 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:19<00:00, 10.91it/s]100%|██████████| 1380/1380 [02:19<00:00,  9.91it/s]
[INFO|trainer.py:2855] 2023-11-15 21:01:24,886 >> Saving model checkpoint to ./result/acl_roberta-base_adapter__seed3
[INFO|configuration_utils.py:460] 2023-11-15 21:01:24,889 >> Configuration saved in ./result/acl_roberta-base_adapter__seed3/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:01:26,012 >> Model weights saved in ./result/acl_roberta-base_adapter__seed3/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:01:26,014 >> tokenizer config file saved in ./result/acl_roberta-base_adapter__seed3/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:01:26,017 >> Special tokens file saved in ./result/acl_roberta-base_adapter__seed3/special_tokens_map.json
{'eval_loss': 0.4874170124530792, 'eval_accuracy': 0.8593466424682396, 'eval_micro_f1': 0.8593466424682396, 'eval_macro_f1': 0.8428811564670605, 'eval_runtime': 2.6088, 'eval_samples_per_second': 844.833, 'eval_steps_per_second': 105.796, 'epoch': 5.0}
{'train_runtime': 139.2119, 'train_samples_per_second': 316.64, 'train_steps_per_second': 9.913, 'train_loss': 0.28689542853313943, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2869
  train_runtime            = 0:02:19.21
  train_samples            =       8816
  train_samples_per_second =     316.64
  train_steps_per_second   =      9.913
11/15/2023 21:01:26 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:01:26,107 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:01:26,108 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:01:26,109 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:01:26,109 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  5%|▍         | 13/276 [00:00<00:02, 120.13it/s]  9%|▉         | 26/276 [00:00<00:02, 112.67it/s] 14%|█▍        | 38/276 [00:00<00:02, 110.61it/s] 18%|█▊        | 50/276 [00:00<00:02, 109.61it/s] 22%|██▏       | 61/276 [00:00<00:01, 108.90it/s] 26%|██▌       | 72/276 [00:00<00:01, 108.50it/s] 30%|███       | 83/276 [00:00<00:01, 108.15it/s] 34%|███▍      | 94/276 [00:00<00:01, 107.56it/s] 38%|███▊      | 105/276 [00:00<00:01, 106.65it/s] 42%|████▏     | 116/276 [00:01<00:01, 106.43it/s] 46%|████▌     | 127/276 [00:01<00:01, 106.60it/s] 50%|█████     | 138/276 [00:01<00:01, 106.72it/s] 54%|█████▍    | 149/276 [00:01<00:01, 106.81it/s] 58%|█████▊    | 160/276 [00:01<00:01, 106.74it/s] 62%|██████▏   | 171/276 [00:01<00:00, 106.84it/s] 66%|██████▌   | 182/276 [00:01<00:00, 107.00it/s] 70%|██████▉   | 193/276 [00:01<00:00, 107.03it/s] 74%|███████▍  | 204/276 [00:01<00:00, 106.83it/s] 78%|███████▊  | 215/276 [00:01<00:00, 106.57it/s] 82%|████████▏ | 226/276 [00:02<00:00, 106.12it/s] 86%|████████▌ | 237/276 [00:02<00:00, 106.39it/s] 90%|████████▉ | 248/276 [00:02<00:00, 106.61it/s] 94%|█████████▍| 259/276 [00:02<00:00, 106.87it/s] 98%|█████████▊| 270/276 [00:02<00:00, 106.92it/s]100%|██████████| 276/276 [00:02<00:00, 105.89it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8593
  eval_loss               =     0.4874
  eval_macro_f1           =     0.8429
  eval_micro_f1           =     0.8593
  eval_runtime            = 0:00:02.61
  eval_samples            =       2204
  eval_samples_per_second =     841.74
  eval_steps_per_second   =    105.408
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ██▇▃▁▁
wandb:                      eval/loss ▁▁▄▇██
wandb:                  eval/macro_f1 ▂▁█▄▁▁
wandb:                  eval/micro_f1 ██▇▃▁▁
wandb:                   eval/runtime ▁▅▇▇▇█
wandb:        eval/samples_per_second █▄▂▂▂▁
wandb:          eval/steps_per_second █▄▂▂▂▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.85935
wandb:                      eval/loss 0.48742
wandb:                  eval/macro_f1 0.84288
wandb:                  eval/micro_f1 0.85935
wandb:                   eval/runtime 2.6184
wandb:        eval/samples_per_second 841.74
wandb:          eval/steps_per_second 105.408
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1541
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.2869
wandb:            train/train_runtime 139.2119
wandb: train/train_samples_per_second 316.64
wandb:   train/train_steps_per_second 9.913
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_205747-elyu1sph
wandb: Find logs at: ./wandb/offline-run-20231115_205747-elyu1sph/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_bert-base-cased_adapter__seed3/runs/Nov15_21-01-39_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_bert-base-cased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_bert-base-cased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:01:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:01:39 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_bert-base-cased_adapter__seed3/runs/Nov15_21-01-38_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_bert-base-cased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_bert-base-cased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  37%|███▋      | 4101/11020 [00:00<00:00, 40781.06 examples/s]Map:  75%|███████▍  | 8223/11020 [00:00<00:00, 41031.86 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 40672.59 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 21:01:54,865 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:01:54,875 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 21:02:04,892 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:02:04,893 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:02:04,895 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:02:04,896 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:02:04,896 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:02:04,896 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:02:04,896 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 21:02:04,897 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:02:04,898 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:02:25,039 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 21:02:25,723 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:02:25,724 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  34%|███▍      | 3000/8816 [00:00<00:00, 21968.14 examples/s]Running tokenizer on dataset:  79%|███████▉  | 7000/8816 [00:00<00:00, 22532.66 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 22549.91 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 23883.24 examples/s]
11/15/2023 21:02:26 - INFO - __main__ - Sample 5060 of the training set: {'text': 'After GABA immunostaining, as elaborated in earlier studies (Domenici et al. 1988; Granda and Crossland 1989), the cell bodies, fibers, and numerous terminals showed GABA-like immunoreactivity in the Imc nucleus.', 'label': 0, 'input_ids': [101, 1258, 20173, 8215, 13280, 13601, 14226, 26174, 117, 1112, 9427, 1181, 1107, 2206, 2527, 113, 17917, 7770, 1182, 3084, 2393, 119, 2115, 132, 2224, 1161, 1105, 3156, 1931, 2056, 114, 117, 1103, 2765, 3470, 117, 18064, 117, 1105, 2567, 20618, 2799, 20173, 8215, 118, 1176, 13280, 13601, 13523, 4490, 5822, 6366, 1107, 1103, 146, 1306, 1665, 14297, 119, 102, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]}.
11/15/2023 21:02:26 - INFO - __main__ - Sample 4715 of the training set: {'text': 'The dynamic nature of the Dlg ‘supertertiary’ core structure suggest precise regulatory inputs have likely evolved to control its signaling output [25, 26].', 'label': 0, 'input_ids': [101, 1109, 9652, 2731, 1104, 1103, 141, 1233, 1403, 786, 7688, 2083, 10691, 1616, 787, 4160, 2401, 5996, 10515, 12638, 22743, 1138, 2620, 7601, 1106, 1654, 1157, 16085, 5964, 164, 1512, 117, 1744, 166, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:02:26 - INFO - __main__ - Sample 216 of the training set: {'text': 'C57 mice, however, have been reported to be more sensitive to the incentive properties of other drugs of abuse including amphetamine, cocaine, methamphetamine, or nicotine than DBA mice (for review see Crawley et al. 1997; Cabib et al. 2000; Orsini et al. 2004; 2005; Grabus et al. 2006).', 'label': 0, 'input_ids': [101, 140, 1571, 1559, 14105, 117, 1649, 117, 1138, 1151, 2103, 1106, 1129, 1167, 7246, 1106, 1103, 23692, 4625, 1104, 1168, 5557, 1104, 6704, 1259, 1821, 27801, 27621, 117, 18316, 117, 1899, 2522, 27801, 27621, 117, 1137, 11437, 18982, 2042, 1190, 24044, 1592, 14105, 113, 1111, 3189, 1267, 140, 28115, 1926, 3084, 2393, 119, 1816, 132, 140, 23156, 1830, 3084, 2393, 119, 1539, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 21:02:26 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:02:27,390 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:02:27,397 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:02:27,397 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 21:02:27,398 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:02:27,398 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:02:27,398 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:02:27,399 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:02:27,399 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 21:02:27,400 >>   Number of trainable parameters = 108,312,579
[INFO|integration_utils.py:716] 2023-11-15 21:02:27,400 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<24:55,  1.08s/it]  0%|          | 3/1380 [00:01<07:58,  2.88it/s]  0%|          | 5/1380 [00:01<04:55,  4.65it/s]  1%|          | 7/1380 [00:01<03:42,  6.17it/s]  1%|          | 9/1380 [00:01<03:04,  7.43it/s]  1%|          | 11/1380 [00:01<02:42,  8.40it/s]  1%|          | 13/1380 [00:02<02:29,  9.16it/s]  1%|          | 15/1380 [00:02<02:20,  9.70it/s]  1%|          | 17/1380 [00:02<02:14, 10.14it/s]  1%|▏         | 19/1380 [00:02<02:10, 10.44it/s]  2%|▏         | 21/1380 [00:02<02:07, 10.66it/s]  2%|▏         | 23/1380 [00:03<02:05, 10.82it/s]  2%|▏         | 25/1380 [00:03<02:03, 10.95it/s]  2%|▏         | 27/1380 [00:03<02:02, 11.05it/s]  2%|▏         | 29/1380 [00:03<02:01, 11.12it/s]  2%|▏         | 31/1380 [00:03<02:00, 11.16it/s]  2%|▏         | 33/1380 [00:03<02:00, 11.18it/s]  3%|▎         | 35/1380 [00:04<01:59, 11.21it/s]  3%|▎         | 37/1380 [00:04<01:59, 11.24it/s]  3%|▎         | 39/1380 [00:04<01:59, 11.22it/s]  3%|▎         | 41/1380 [00:04<01:59, 11.24it/s]  3%|▎         | 43/1380 [00:04<01:59, 11.22it/s]  3%|▎         | 45/1380 [00:05<01:58, 11.24it/s]  3%|▎         | 47/1380 [00:05<01:58, 11.23it/s]  4%|▎         | 49/1380 [00:05<01:58, 11.24it/s]  4%|▎         | 51/1380 [00:05<01:58, 11.25it/s]  4%|▍         | 53/1380 [00:05<01:57, 11.27it/s]  4%|▍         | 55/1380 [00:05<01:57, 11.26it/s]  4%|▍         | 57/1380 [00:06<01:57, 11.25it/s]  4%|▍         | 59/1380 [00:06<01:57, 11.25it/s]  4%|▍         | 61/1380 [00:06<01:57, 11.24it/s]  5%|▍         | 63/1380 [00:06<01:57, 11.24it/s]  5%|▍         | 65/1380 [00:06<01:56, 11.24it/s]  5%|▍         | 67/1380 [00:06<01:56, 11.26it/s]  5%|▌         | 69/1380 [00:07<01:56, 11.25it/s]  5%|▌         | 71/1380 [00:07<01:56, 11.26it/s]  5%|▌         | 73/1380 [00:07<01:56, 11.25it/s]  5%|▌         | 75/1380 [00:07<01:55, 11.26it/s]  6%|▌         | 77/1380 [00:07<01:55, 11.24it/s]  6%|▌         | 79/1380 [00:08<01:55, 11.25it/s]  6%|▌         | 81/1380 [00:08<01:55, 11.26it/s]  6%|▌         | 83/1380 [00:08<01:55, 11.27it/s]  6%|▌         | 85/1380 [00:08<01:55, 11.25it/s]  6%|▋         | 87/1380 [00:08<01:54, 11.26it/s]  6%|▋         | 89/1380 [00:08<01:54, 11.26it/s]  7%|▋         | 91/1380 [00:09<01:54, 11.25it/s]  7%|▋         | 93/1380 [00:09<01:54, 11.26it/s]  7%|▋         | 95/1380 [00:09<01:54, 11.26it/s]  7%|▋         | 97/1380 [00:09<01:53, 11.27it/s]  7%|▋         | 99/1380 [00:09<01:53, 11.26it/s]  7%|▋         | 101/1380 [00:09<01:53, 11.27it/s]  7%|▋         | 103/1380 [00:10<01:53, 11.27it/s]  8%|▊         | 105/1380 [00:10<01:53, 11.28it/s]  8%|▊         | 107/1380 [00:10<01:53, 11.25it/s]  8%|▊         | 109/1380 [00:10<01:52, 11.25it/s]  8%|▊         | 111/1380 [00:10<01:52, 11.26it/s]  8%|▊         | 113/1380 [00:11<01:52, 11.25it/s]  8%|▊         | 115/1380 [00:11<01:52, 11.23it/s]  8%|▊         | 117/1380 [00:11<01:52, 11.24it/s]  9%|▊         | 119/1380 [00:11<01:52, 11.24it/s]  9%|▉         | 121/1380 [00:11<01:52, 11.24it/s]  9%|▉         | 123/1380 [00:11<01:52, 11.22it/s]  9%|▉         | 125/1380 [00:12<01:51, 11.22it/s]  9%|▉         | 127/1380 [00:12<01:51, 11.24it/s]  9%|▉         | 129/1380 [00:12<01:51, 11.24it/s]  9%|▉         | 131/1380 [00:12<01:51, 11.24it/s] 10%|▉         | 133/1380 [00:12<01:50, 11.24it/s] 10%|▉         | 135/1380 [00:13<01:50, 11.22it/s] 10%|▉         | 137/1380 [00:13<01:50, 11.20it/s] 10%|█         | 139/1380 [00:13<01:50, 11.21it/s] 10%|█         | 141/1380 [00:13<01:50, 11.22it/s] 10%|█         | 143/1380 [00:13<01:50, 11.22it/s] 11%|█         | 145/1380 [00:13<01:50, 11.22it/s] 11%|█         | 147/1380 [00:14<01:49, 11.22it/s] 11%|█         | 149/1380 [00:14<01:49, 11.23it/s] 11%|█         | 151/1380 [00:14<01:49, 11.21it/s] 11%|█         | 153/1380 [00:14<01:49, 11.22it/s] 11%|█         | 155/1380 [00:14<01:49, 11.22it/s] 11%|█▏        | 157/1380 [00:14<01:48, 11.23it/s] 12%|█▏        | 159/1380 [00:15<01:48, 11.21it/s] 12%|█▏        | 161/1380 [00:15<01:48, 11.21it/s] 12%|█▏        | 163/1380 [00:15<01:48, 11.21it/s] 12%|█▏        | 165/1380 [00:15<01:48, 11.22it/s] 12%|█▏        | 167/1380 [00:15<01:48, 11.20it/s] 12%|█▏        | 169/1380 [00:16<01:47, 11.24it/s] 12%|█▏        | 171/1380 [00:16<01:47, 11.24it/s] 13%|█▎        | 173/1380 [00:16<01:47, 11.22it/s] 13%|█▎        | 175/1380 [00:16<01:47, 11.20it/s] 13%|█▎        | 177/1380 [00:16<01:47, 11.20it/s] 13%|█▎        | 179/1380 [00:16<01:47, 11.21it/s] 13%|█▎        | 181/1380 [00:17<01:47, 11.19it/s] 13%|█▎        | 183/1380 [00:17<01:46, 11.19it/s] 13%|█▎        | 185/1380 [00:17<01:46, 11.18it/s] 14%|█▎        | 187/1380 [00:17<01:46, 11.19it/s] 14%|█▎        | 189/1380 [00:17<01:46, 11.18it/s] 14%|█▍        | 191/1380 [00:18<01:46, 11.17it/s] 14%|█▍        | 193/1380 [00:18<01:46, 11.18it/s] 14%|█▍        | 195/1380 [00:18<01:45, 11.18it/s] 14%|█▍        | 197/1380 [00:18<01:45, 11.18it/s] 14%|█▍        | 199/1380 [00:18<01:45, 11.20it/s] 15%|█▍        | 201/1380 [00:18<01:45, 11.22it/s] 15%|█▍        | 203/1380 [00:19<01:45, 11.19it/s] 15%|█▍        | 205/1380 [00:19<01:44, 11.21it/s] 15%|█▌        | 207/1380 [00:19<01:44, 11.20it/s] 15%|█▌        | 209/1380 [00:19<01:44, 11.21it/s] 15%|█▌        | 211/1380 [00:19<01:44, 11.21it/s] 15%|█▌        | 213/1380 [00:19<01:44, 11.19it/s] 16%|█▌        | 215/1380 [00:20<01:44, 11.19it/s] 16%|█▌        | 217/1380 [00:20<01:43, 11.20it/s] 16%|█▌        | 219/1380 [00:20<01:43, 11.19it/s] 16%|█▌        | 221/1380 [00:20<01:43, 11.20it/s] 16%|█▌        | 223/1380 [00:20<01:43, 11.20it/s] 16%|█▋        | 225/1380 [00:21<01:43, 11.20it/s] 16%|█▋        | 227/1380 [00:21<01:43, 11.19it/s] 17%|█▋        | 229/1380 [00:21<01:42, 11.21it/s] 17%|█▋        | 231/1380 [00:21<01:42, 11.21it/s] 17%|█▋        | 233/1380 [00:21<01:42, 11.21it/s] 17%|█▋        | 235/1380 [00:21<01:42, 11.20it/s] 17%|█▋        | 237/1380 [00:22<01:42, 11.19it/s] 17%|█▋        | 239/1380 [00:22<01:41, 11.20it/s] 17%|█▋        | 241/1380 [00:22<01:41, 11.21it/s] 18%|█▊        | 243/1380 [00:22<01:41, 11.21it/s] 18%|█▊        | 245/1380 [00:22<01:41, 11.22it/s] 18%|█▊        | 247/1380 [00:23<01:40, 11.22it/s] 18%|█▊        | 249/1380 [00:23<01:41, 11.19it/s] 18%|█▊        | 251/1380 [00:23<01:40, 11.19it/s] 18%|█▊        | 253/1380 [00:23<01:40, 11.20it/s] 18%|█▊        | 255/1380 [00:23<01:40, 11.20it/s] 19%|█▊        | 257/1380 [00:23<01:40, 11.19it/s] 19%|█▉        | 259/1380 [00:24<01:40, 11.18it/s] 19%|█▉        | 261/1380 [00:24<01:40, 11.18it/s] 19%|█▉        | 263/1380 [00:24<01:39, 11.18it/s] 19%|█▉        | 265/1380 [00:24<01:39, 11.18it/s] 19%|█▉        | 267/1380 [00:24<01:39, 11.19it/s] 19%|█▉        | 269/1380 [00:24<01:39, 11.18it/s] 20%|█▉        | 271/1380 [00:25<01:39, 11.17it/s] 20%|█▉        | 273/1380 [00:25<01:39, 11.17it/s] 20%|█▉        | 275/1380 [00:25<01:38, 11.20it/s]                                                   20%|██        | 276/1380 [00:25<01:38, 11.20it/s][INFO|trainer.py:755] 2023-11-15 21:02:52,977 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:02:52,979 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:02:52,979 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:02:52,979 >>   Batch size = 8
{'loss': 0.5099, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 121.53it/s][A
  9%|▉         | 26/276 [00:00<00:02, 114.12it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 112.45it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 111.78it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.32it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.97it/s][A
 31%|███       | 86/276 [00:00<00:01, 110.59it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 110.16it/s][A
 40%|███▉      | 110/276 [00:00<00:01, 109.39it/s][A
 44%|████▍     | 121/276 [00:01<00:01, 109.13it/s][A
 48%|████▊     | 132/276 [00:01<00:01, 109.17it/s][A
 52%|█████▏    | 143/276 [00:01<00:01, 109.30it/s][A
 56%|█████▌    | 154/276 [00:01<00:01, 109.16it/s][A
 60%|█████▉    | 165/276 [00:01<00:01, 109.05it/s][A
 64%|██████▍   | 176/276 [00:01<00:00, 109.18it/s][A
 68%|██████▊   | 187/276 [00:01<00:00, 109.07it/s][A
 72%|███████▏  | 198/276 [00:01<00:00, 108.94it/s][A
 76%|███████▌  | 209/276 [00:01<00:00, 108.76it/s][A
 80%|███████▉  | 220/276 [00:02<00:00, 108.65it/s][A
 84%|████████▎ | 231/276 [00:02<00:00, 108.54it/s][A
 88%|████████▊ | 242/276 [00:02<00:00, 108.42it/s][A
 92%|█████████▏| 253/276 [00:02<00:00, 108.58it/s][A
 96%|█████████▌| 264/276 [00:02<00:00, 108.52it/s][A
100%|█████████▉| 275/276 [00:02<00:00, 108.77it/s][A                                                  
                                                  [A 20%|██        | 276/1380 [00:28<01:38, 11.20it/s]
100%|██████████| 276/276 [00:02<00:00, 108.77it/s][A
                                                  [A 20%|██        | 277/1380 [00:28<08:40,  2.12it/s] 20%|██        | 279/1380 [00:28<06:33,  2.80it/s] 20%|██        | 281/1380 [00:28<05:04,  3.61it/s] 21%|██        | 283/1380 [00:28<04:02,  4.53it/s] 21%|██        | 285/1380 [00:28<03:18,  5.51it/s] 21%|██        | 287/1380 [00:29<02:48,  6.50it/s] 21%|██        | 289/1380 [00:29<02:26,  7.44it/s] 21%|██        | 291/1380 [00:29<02:11,  8.27it/s] 21%|██        | 293/1380 [00:29<02:01,  8.98it/s] 21%|██▏       | 295/1380 [00:29<01:53,  9.53it/s] 22%|██▏       | 297/1380 [00:30<01:48,  9.97it/s] 22%|██▏       | 299/1380 [00:30<01:44, 10.30it/s] 22%|██▏       | 301/1380 [00:30<01:42, 10.54it/s] 22%|██▏       | 303/1380 [00:30<01:40, 10.71it/s] 22%|██▏       | 305/1380 [00:30<01:39, 10.84it/s] 22%|██▏       | 307/1380 [00:30<01:38, 10.94it/s] 22%|██▏       | 309/1380 [00:31<01:37, 10.98it/s] 23%|██▎       | 311/1380 [00:31<01:36, 11.04it/s] 23%|██▎       | 313/1380 [00:31<01:36, 11.09it/s] 23%|██▎       | 315/1380 [00:31<01:35, 11.11it/s] 23%|██▎       | 317/1380 [00:31<01:35, 11.14it/s] 23%|██▎       | 319/1380 [00:32<01:35, 11.16it/s] 23%|██▎       | 321/1380 [00:32<01:34, 11.18it/s] 23%|██▎       | 323/1380 [00:32<01:34, 11.19it/s] 24%|██▎       | 325/1380 [00:32<01:34, 11.19it/s] 24%|██▎       | 327/1380 [00:32<01:34, 11.19it/s] 24%|██▍       | 329/1380 [00:32<01:33, 11.20it/s] 24%|██▍       | 331/1380 [00:33<01:33, 11.18it/s] 24%|██▍       | 333/1380 [00:33<01:33, 11.18it/s] 24%|██▍       | 335/1380 [00:33<01:33, 11.18it/s] 24%|██▍       | 337/1380 [00:33<01:33, 11.17it/s] 25%|██▍       | 339/1380 [00:33<01:33, 11.16it/s] 25%|██▍       | 341/1380 [00:33<01:33, 11.17it/s] 25%|██▍       | 343/1380 [00:34<01:32, 11.17it/s] 25%|██▌       | 345/1380 [00:34<01:32, 11.16it/s] 25%|██▌       | 347/1380 [00:34<01:32, 11.17it/s] 25%|██▌       | 349/1380 [00:34<01:32, 11.18it/s] 25%|██▌       | 351/1380 [00:34<01:32, 11.18it/s] 26%|██▌       | 353/1380 [00:35<01:32, 11.16it/s] 26%|██▌       | 355/1380 [00:35<01:31, 11.16it/s] 26%|██▌       | 357/1380 [00:35<01:31, 11.18it/s] 26%|██▌       | 359/1380 [00:35<01:31, 11.18it/s] 26%|██▌       | 361/1380 [00:35<01:31, 11.17it/s] 26%|██▋       | 363/1380 [00:35<01:30, 11.19it/s] 26%|██▋       | 365/1380 [00:36<01:30, 11.18it/s] 27%|██▋       | 367/1380 [00:36<01:30, 11.17it/s] 27%|██▋       | 369/1380 [00:36<01:30, 11.16it/s] 27%|██▋       | 371/1380 [00:36<01:30, 11.17it/s] 27%|██▋       | 373/1380 [00:36<01:30, 11.18it/s] 27%|██▋       | 375/1380 [00:37<01:29, 11.17it/s] 27%|██▋       | 377/1380 [00:37<01:29, 11.17it/s] 27%|██▋       | 379/1380 [00:37<01:29, 11.17it/s] 28%|██▊       | 381/1380 [00:37<01:29, 11.18it/s] 28%|██▊       | 383/1380 [00:37<01:29, 11.17it/s] 28%|██▊       | 385/1380 [00:37<01:29, 11.18it/s] 28%|██▊       | 387/1380 [00:38<01:28, 11.18it/s] 28%|██▊       | 389/1380 [00:38<01:28, 11.17it/s] 28%|██▊       | 391/1380 [00:38<01:28, 11.17it/s] 28%|██▊       | 393/1380 [00:38<01:28, 11.18it/s] 29%|██▊       | 395/1380 [00:38<01:28, 11.19it/s] 29%|██▉       | 397/1380 [00:38<01:27, 11.19it/s] 29%|██▉       | 399/1380 [00:39<01:27, 11.18it/s] 29%|██▉       | 401/1380 [00:39<01:27, 11.18it/s] 29%|██▉       | 403/1380 [00:39<01:27, 11.18it/s] 29%|██▉       | 405/1380 [00:39<01:27, 11.16it/s] 29%|██▉       | 407/1380 [00:39<01:27, 11.16it/s] 30%|██▉       | 409/1380 [00:40<01:26, 11.17it/s] 30%|██▉       | 411/1380 [00:40<01:26, 11.17it/s] 30%|██▉       | 413/1380 [00:40<01:26, 11.16it/s] 30%|███       | 415/1380 [00:40<01:26, 11.17it/s] 30%|███       | 417/1380 [00:40<01:26, 11.18it/s] 30%|███       | 419/1380 [00:40<01:26, 11.16it/s] 31%|███       | 421/1380 [00:41<01:25, 11.16it/s] 31%|███       | 423/1380 [00:41<01:25, 11.17it/s] 31%|███       | 425/1380 [00:41<01:25, 11.18it/s] 31%|███       | 427/1380 [00:41<01:25, 11.16it/s] 31%|███       | 429/1380 [00:41<01:25, 11.15it/s] 31%|███       | 431/1380 [00:42<01:25, 11.15it/s] 31%|███▏      | 433/1380 [00:42<01:24, 11.16it/s] 32%|███▏      | 435/1380 [00:42<01:24, 11.16it/s] 32%|███▏      | 437/1380 [00:42<01:24, 11.17it/s] 32%|███▏      | 439/1380 [00:42<01:24, 11.14it/s] 32%|███▏      | 441/1380 [00:42<01:24, 11.14it/s] 32%|███▏      | 443/1380 [00:43<01:24, 11.15it/s] 32%|███▏      | 445/1380 [00:43<01:23, 11.14it/s] 32%|███▏      | 447/1380 [00:43<01:23, 11.14it/s] 33%|███▎      | 449/1380 [00:43<01:23, 11.14it/s] 33%|███▎      | 451/1380 [00:43<01:23, 11.13it/s] 33%|███▎      | 453/1380 [00:43<01:23, 11.12it/s] 33%|███▎      | 455/1380 [00:44<01:23, 11.13it/s] 33%|███▎      | 457/1380 [00:44<01:22, 11.12it/s] 33%|███▎      | 459/1380 [00:44<01:22, 11.13it/s] 33%|███▎      | 461/1380 [00:44<01:22, 11.14it/s] 34%|███▎      | 463/1380 [00:44<01:22, 11.15it/s] 34%|███▎      | 465/1380 [00:45<01:21, 11.16it/s] 34%|███▍      | 467/1380 [00:45<01:21, 11.14it/s] 34%|███▍      | 469/1380 [00:45<01:21, 11.15it/s] 34%|███▍      | 471/1380 [00:45<01:21, 11.15it/s] 34%|███▍      | 473/1380 [00:45<01:21, 11.16it/s] 34%|███▍      | 475/1380 [00:45<01:21, 11.13it/s] 35%|███▍      | 477/1380 [00:46<01:21, 11.15it/s] 35%|███▍      | 479/1380 [00:46<01:20, 11.15it/s] 35%|███▍      | 481/1380 [00:46<01:20, 11.15it/s] 35%|███▌      | 483/1380 [00:46<01:20, 11.14it/s] 35%|███▌      | 485/1380 [00:46<01:20, 11.14it/s] 35%|███▌      | 487/1380 [00:47<01:20, 11.14it/s] 35%|███▌      | 489/1380 [00:47<01:20, 11.14it/s] 36%|███▌      | 491/1380 [00:47<01:19, 11.14it/s] 36%|███▌      | 493/1380 [00:47<01:19, 11.13it/s] 36%|███▌      | 495/1380 [00:47<01:19, 11.13it/s] 36%|███▌      | 497/1380 [00:47<01:19, 11.11it/s] 36%|███▌      | 499/1380 [00:48<01:19, 11.10it/s] 36%|███▋      | 501/1380 [00:48<01:19, 11.12it/s] 36%|███▋      | 503/1380 [00:48<01:19, 11.10it/s] 37%|███▋      | 505/1380 [00:48<01:18, 11.11it/s] 37%|███▋      | 507/1380 [00:48<01:18, 11.11it/s] 37%|███▋      | 509/1380 [00:49<01:18, 11.11it/s] 37%|███▋      | 511/1380 [00:49<01:18, 11.12it/s] 37%|███▋      | 513/1380 [00:49<01:17, 11.12it/s] 37%|███▋      | 515/1380 [00:49<01:17, 11.13it/s] 37%|███▋      | 517/1380 [00:49<01:17, 11.12it/s] 38%|███▊      | 519/1380 [00:49<01:17, 11.12it/s] 38%|███▊      | 521/1380 [00:50<01:17, 11.13it/s] 38%|███▊      | 523/1380 [00:50<01:17, 11.11it/s] 38%|███▊      | 525/1380 [00:50<01:17, 11.10it/s] 38%|███▊      | 527/1380 [00:50<01:16, 11.10it/s] 38%|███▊      | 529/1380 [00:50<01:16, 11.10it/s] 38%|███▊      | 531/1380 [00:51<01:16, 11.11it/s] 39%|███▊      | 533/1380 [00:51<01:16, 11.10it/s] 39%|███▉      | 535/1380 [00:51<01:16, 11.10it/s] 39%|███▉      | 537/1380 [00:51<01:15, 11.11it/s] 39%|███▉      | 539/1380 [00:51<01:15, 11.10it/s] 39%|███▉      | 541/1380 [00:51<01:15, 11.09it/s] 39%|███▉      | 543/1380 [00:52<01:15, 11.11it/s] 39%|███▉      | 545/1380 [00:52<01:15, 11.11it/s] 40%|███▉      | 547/1380 [00:52<01:15, 11.10it/s] 40%|███▉      | 549/1380 [00:52<01:14, 11.11it/s] 40%|███▉      | 551/1380 [00:52<01:14, 11.14it/s]                                                   40%|████      | 552/1380 [00:52<01:14, 11.14it/s][INFO|trainer.py:755] 2023-11-15 21:03:20,274 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:03:20,276 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:03:20,276 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:03:20,276 >>   Batch size = 8
{'eval_loss': 0.3774370849132538, 'eval_accuracy': 0.8579854809437386, 'eval_micro_f1': 0.8579854809437386, 'eval_macro_f1': 0.8358681322574197, 'eval_runtime': 2.5729, 'eval_samples_per_second': 856.615, 'eval_steps_per_second': 107.271, 'epoch': 1.0}
{'loss': 0.3123, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 120.90it/s][A
  9%|▉         | 26/276 [00:00<00:02, 114.68it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 112.74it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 111.47it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 110.76it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.07it/s][A
 31%|███       | 86/276 [00:00<00:01, 109.49it/s][A
 35%|███▌      | 97/276 [00:00<00:01, 108.67it/s][A
 39%|███▉      | 108/276 [00:00<00:01, 107.79it/s][A
 43%|████▎     | 119/276 [00:01<00:01, 107.31it/s][A
 47%|████▋     | 130/276 [00:01<00:01, 107.28it/s][A
 51%|█████     | 141/276 [00:01<00:01, 107.47it/s][A
 55%|█████▌    | 152/276 [00:01<00:01, 107.50it/s][A
 59%|█████▉    | 163/276 [00:01<00:01, 107.66it/s][A
 63%|██████▎   | 174/276 [00:01<00:00, 107.68it/s][A
 67%|██████▋   | 185/276 [00:01<00:00, 107.49it/s][A
 71%|███████   | 196/276 [00:01<00:00, 107.20it/s][A
 75%|███████▌  | 207/276 [00:01<00:00, 106.52it/s][A
 79%|███████▉  | 218/276 [00:02<00:00, 106.36it/s][A
 83%|████████▎ | 229/276 [00:02<00:00, 106.13it/s][A
 87%|████████▋ | 240/276 [00:02<00:00, 105.94it/s][A
 91%|█████████ | 251/276 [00:02<00:00, 106.03it/s][A
 95%|█████████▍| 262/276 [00:02<00:00, 106.00it/s][A
 99%|█████████▉| 273/276 [00:02<00:00, 106.31it/s][A                                                  
                                                  [A 40%|████      | 552/1380 [00:55<01:14, 11.14it/s]
100%|██████████| 276/276 [00:02<00:00, 106.31it/s][A
                                                  [A 40%|████      | 553/1380 [00:55<06:35,  2.09it/s] 40%|████      | 555/1380 [00:55<04:58,  2.76it/s] 40%|████      | 557/1380 [00:55<03:51,  3.56it/s] 41%|████      | 559/1380 [00:56<03:03,  4.47it/s] 41%|████      | 561/1380 [00:56<02:30,  5.45it/s] 41%|████      | 563/1380 [00:56<02:07,  6.43it/s] 41%|████      | 565/1380 [00:56<01:50,  7.35it/s] 41%|████      | 567/1380 [00:56<01:39,  8.18it/s] 41%|████      | 569/1380 [00:57<01:31,  8.88it/s] 41%|████▏     | 571/1380 [00:57<01:25,  9.43it/s] 42%|████▏     | 573/1380 [00:57<01:21,  9.86it/s] 42%|████▏     | 575/1380 [00:57<01:18, 10.20it/s] 42%|████▏     | 577/1380 [00:57<01:16, 10.43it/s] 42%|████▏     | 579/1380 [00:57<01:15, 10.62it/s] 42%|████▏     | 581/1380 [00:58<01:14, 10.77it/s] 42%|████▏     | 583/1380 [00:58<01:13, 10.86it/s] 42%|████▏     | 585/1380 [00:58<01:12, 10.91it/s] 43%|████▎     | 587/1380 [00:58<01:12, 10.97it/s] 43%|████▎     | 589/1380 [00:58<01:11, 11.01it/s] 43%|████▎     | 591/1380 [00:59<01:11, 11.04it/s] 43%|████▎     | 593/1380 [00:59<01:11, 11.05it/s] 43%|████▎     | 595/1380 [00:59<01:10, 11.07it/s] 43%|████▎     | 597/1380 [00:59<01:10, 11.08it/s] 43%|████▎     | 599/1380 [00:59<01:10, 11.08it/s] 44%|████▎     | 601/1380 [00:59<01:10, 11.08it/s] 44%|████▎     | 603/1380 [01:00<01:10, 11.09it/s] 44%|████▍     | 605/1380 [01:00<01:09, 11.10it/s] 44%|████▍     | 607/1380 [01:00<01:09, 11.08it/s] 44%|████▍     | 609/1380 [01:00<01:09, 11.08it/s] 44%|████▍     | 611/1380 [01:00<01:09, 11.07it/s] 44%|████▍     | 613/1380 [01:00<01:09, 11.07it/s] 45%|████▍     | 615/1380 [01:01<01:09, 11.06it/s] 45%|████▍     | 617/1380 [01:01<01:08, 11.06it/s] 45%|████▍     | 619/1380 [01:01<01:08, 11.07it/s] 45%|████▌     | 621/1380 [01:01<01:08, 11.07it/s] 45%|████▌     | 623/1380 [01:01<01:08, 11.08it/s] 45%|████▌     | 625/1380 [01:02<01:08, 11.08it/s] 45%|████▌     | 627/1380 [01:02<01:07, 11.09it/s] 46%|████▌     | 629/1380 [01:02<01:07, 11.08it/s] 46%|████▌     | 631/1380 [01:02<01:07, 11.09it/s] 46%|████▌     | 633/1380 [01:02<01:07, 11.10it/s] 46%|████▌     | 635/1380 [01:02<01:07, 11.11it/s] 46%|████▌     | 637/1380 [01:03<01:07, 11.07it/s] 46%|████▋     | 639/1380 [01:03<01:06, 11.08it/s] 46%|████▋     | 641/1380 [01:03<01:06, 11.09it/s] 47%|████▋     | 643/1380 [01:03<01:06, 11.09it/s] 47%|████▋     | 645/1380 [01:03<01:06, 11.08it/s] 47%|████▋     | 647/1380 [01:04<01:06, 11.08it/s] 47%|████▋     | 649/1380 [01:04<01:05, 11.09it/s] 47%|████▋     | 651/1380 [01:04<01:05, 11.08it/s] 47%|████▋     | 653/1380 [01:04<01:05, 11.08it/s] 47%|████▋     | 655/1380 [01:04<01:05, 11.08it/s] 48%|████▊     | 657/1380 [01:04<01:05, 11.08it/s] 48%|████▊     | 659/1380 [01:05<01:05, 11.05it/s] 48%|████▊     | 661/1380 [01:05<01:04, 11.07it/s] 48%|████▊     | 663/1380 [01:05<01:04, 11.07it/s] 48%|████▊     | 665/1380 [01:05<01:04, 11.08it/s] 48%|████▊     | 667/1380 [01:05<01:04, 11.07it/s] 48%|████▊     | 669/1380 [01:06<01:04, 11.08it/s] 49%|████▊     | 671/1380 [01:06<01:03, 11.08it/s] 49%|████▉     | 673/1380 [01:06<01:03, 11.07it/s] 49%|████▉     | 675/1380 [01:06<01:03, 11.07it/s] 49%|████▉     | 677/1380 [01:06<01:03, 11.07it/s] 49%|████▉     | 679/1380 [01:06<01:03, 11.08it/s] 49%|████▉     | 681/1380 [01:07<01:03, 11.05it/s] 49%|████▉     | 683/1380 [01:07<01:03, 11.05it/s] 50%|████▉     | 685/1380 [01:07<01:02, 11.07it/s] 50%|████▉     | 687/1380 [01:07<01:02, 11.06it/s] 50%|████▉     | 689/1380 [01:07<01:02, 11.07it/s] 50%|█████     | 691/1380 [01:08<01:02, 11.08it/s] 50%|█████     | 693/1380 [01:08<01:01, 11.09it/s] 50%|█████     | 695/1380 [01:08<01:01, 11.07it/s] 51%|█████     | 697/1380 [01:08<01:01, 11.09it/s] 51%|█████     | 699/1380 [01:08<01:01, 11.08it/s] 51%|█████     | 701/1380 [01:08<01:01, 11.08it/s] 51%|█████     | 703/1380 [01:09<01:01, 11.05it/s] 51%|█████     | 705/1380 [01:09<01:01, 11.04it/s] 51%|█████     | 707/1380 [01:09<01:01, 11.03it/s] 51%|█████▏    | 709/1380 [01:09<01:00, 11.01it/s] 52%|█████▏    | 711/1380 [01:09<01:00, 11.02it/s] 52%|█████▏    | 713/1380 [01:10<01:00, 11.02it/s] 52%|█████▏    | 715/1380 [01:10<01:00, 11.03it/s] 52%|█████▏    | 717/1380 [01:10<01:00, 11.02it/s] 52%|█████▏    | 719/1380 [01:10<00:59, 11.02it/s] 52%|█████▏    | 721/1380 [01:10<00:59, 11.03it/s] 52%|█████▏    | 723/1380 [01:10<00:59, 11.05it/s] 53%|█████▎    | 725/1380 [01:11<00:59, 11.02it/s] 53%|█████▎    | 727/1380 [01:11<00:59, 11.03it/s] 53%|█████▎    | 729/1380 [01:11<00:58, 11.04it/s] 53%|█████▎    | 731/1380 [01:11<00:58, 11.04it/s] 53%|█████▎    | 733/1380 [01:11<00:58, 11.02it/s] 53%|█████▎    | 735/1380 [01:12<00:58, 11.04it/s] 53%|█████▎    | 737/1380 [01:12<00:58, 11.04it/s] 54%|█████▎    | 739/1380 [01:12<00:58, 11.04it/s] 54%|█████▎    | 741/1380 [01:12<00:57, 11.06it/s] 54%|█████▍    | 743/1380 [01:12<00:57, 11.07it/s] 54%|█████▍    | 745/1380 [01:12<00:57, 11.08it/s] 54%|█████▍    | 747/1380 [01:13<00:57, 11.04it/s] 54%|█████▍    | 749/1380 [01:13<00:57, 11.06it/s] 54%|█████▍    | 751/1380 [01:13<00:56, 11.06it/s] 55%|█████▍    | 753/1380 [01:13<00:56, 11.06it/s] 55%|█████▍    | 755/1380 [01:13<00:56, 11.04it/s] 55%|█████▍    | 757/1380 [01:14<00:56, 11.04it/s] 55%|█████▌    | 759/1380 [01:14<00:56, 11.05it/s] 55%|█████▌    | 761/1380 [01:14<00:56, 11.04it/s] 55%|█████▌    | 763/1380 [01:14<00:55, 11.05it/s] 55%|█████▌    | 765/1380 [01:14<00:55, 11.07it/s] 56%|█████▌    | 767/1380 [01:14<00:55, 11.08it/s] 56%|█████▌    | 769/1380 [01:15<00:55, 11.05it/s] 56%|█████▌    | 771/1380 [01:15<00:55, 11.05it/s] 56%|█████▌    | 773/1380 [01:15<00:54, 11.06it/s] 56%|█████▌    | 775/1380 [01:15<00:54, 11.05it/s] 56%|█████▋    | 777/1380 [01:15<00:54, 11.04it/s] 56%|█████▋    | 779/1380 [01:16<00:54, 11.05it/s] 57%|█████▋    | 781/1380 [01:16<00:54, 11.07it/s] 57%|█████▋    | 783/1380 [01:16<00:53, 11.06it/s] 57%|█████▋    | 785/1380 [01:16<00:53, 11.07it/s] 57%|█████▋    | 787/1380 [01:16<00:53, 11.09it/s] 57%|█████▋    | 789/1380 [01:16<00:53, 11.09it/s] 57%|█████▋    | 791/1380 [01:17<00:53, 11.07it/s] 57%|█████▋    | 793/1380 [01:17<00:52, 11.08it/s] 58%|█████▊    | 795/1380 [01:17<00:52, 11.08it/s] 58%|█████▊    | 797/1380 [01:17<00:52, 11.09it/s] 58%|█████▊    | 799/1380 [01:17<00:52, 11.06it/s] 58%|█████▊    | 801/1380 [01:17<00:52, 11.07it/s] 58%|█████▊    | 803/1380 [01:18<00:52, 11.06it/s] 58%|█████▊    | 805/1380 [01:18<00:52, 11.05it/s] 58%|█████▊    | 807/1380 [01:18<00:51, 11.05it/s] 59%|█████▊    | 809/1380 [01:18<00:51, 11.07it/s] 59%|█████▉    | 811/1380 [01:18<00:51, 11.09it/s] 59%|█████▉    | 813/1380 [01:19<00:51, 11.07it/s] 59%|█████▉    | 815/1380 [01:19<00:50, 11.09it/s] 59%|█████▉    | 817/1380 [01:19<00:50, 11.09it/s] 59%|█████▉    | 819/1380 [01:19<00:50, 11.09it/s] 59%|█████▉    | 821/1380 [01:19<00:50, 11.08it/s] 60%|█████▉    | 823/1380 [01:19<00:50, 11.07it/s] 60%|█████▉    | 825/1380 [01:20<00:50, 11.08it/s] 60%|█████▉    | 827/1380 [01:20<00:49, 11.08it/s]                                                   60%|██████    | 828/1380 [01:20<00:49, 11.08it/s][INFO|trainer.py:755] 2023-11-15 21:03:47,804 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:03:47,806 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:03:47,806 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:03:47,806 >>   Batch size = 8
{'eval_loss': 0.3914954662322998, 'eval_accuracy': 0.8561705989110708, 'eval_micro_f1': 0.8561705989110708, 'eval_macro_f1': 0.836433407256625, 'eval_runtime': 2.6117, 'eval_samples_per_second': 843.883, 'eval_steps_per_second': 105.677, 'epoch': 2.0}
{'loss': 0.2084, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 120.51it/s][A
  9%|▉         | 26/276 [00:00<00:02, 114.29it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 112.25it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 111.22it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 110.42it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 109.24it/s][A
 31%|███       | 85/276 [00:00<00:01, 108.66it/s][A
 35%|███▍      | 96/276 [00:00<00:01, 108.03it/s][A
 39%|███▉      | 107/276 [00:00<00:01, 106.99it/s][A
 43%|████▎     | 118/276 [00:01<00:01, 106.53it/s][A
 47%|████▋     | 129/276 [00:01<00:01, 106.62it/s][A
 51%|█████     | 140/276 [00:01<00:01, 106.57it/s][A
 55%|█████▍    | 151/276 [00:01<00:01, 106.51it/s][A
 59%|█████▊    | 162/276 [00:01<00:01, 106.65it/s][A
 63%|██████▎   | 173/276 [00:01<00:00, 106.65it/s][A
 67%|██████▋   | 184/276 [00:01<00:00, 106.57it/s][A
 71%|███████   | 195/276 [00:01<00:00, 106.28it/s][A
 75%|███████▍  | 206/276 [00:01<00:00, 105.72it/s][A
 79%|███████▊  | 217/276 [00:02<00:00, 105.05it/s][A
 83%|████████▎ | 228/276 [00:02<00:00, 104.83it/s][A
 87%|████████▋ | 239/276 [00:02<00:00, 104.97it/s][A
 91%|█████████ | 250/276 [00:02<00:00, 105.33it/s][A
 95%|█████████▍| 261/276 [00:02<00:00, 105.46it/s][A
 99%|█████████▊| 272/276 [00:02<00:00, 105.57it/s][A                                                  
                                                  [A 60%|██████    | 828/1380 [01:23<00:49, 11.08it/s]
100%|██████████| 276/276 [00:02<00:00, 105.57it/s][A
                                                  [A 60%|██████    | 829/1380 [01:23<04:25,  2.08it/s] 60%|██████    | 831/1380 [01:23<03:20,  2.74it/s] 60%|██████    | 833/1380 [01:23<02:34,  3.54it/s] 61%|██████    | 835/1380 [01:23<02:02,  4.44it/s] 61%|██████    | 837/1380 [01:23<01:40,  5.41it/s] 61%|██████    | 839/1380 [01:24<01:24,  6.38it/s] 61%|██████    | 841/1380 [01:24<01:13,  7.30it/s] 61%|██████    | 843/1380 [01:24<01:06,  8.12it/s] 61%|██████    | 845/1380 [01:24<01:00,  8.84it/s] 61%|██████▏   | 847/1380 [01:24<00:56,  9.41it/s] 62%|██████▏   | 849/1380 [01:24<00:53,  9.85it/s] 62%|██████▏   | 851/1380 [01:25<00:52, 10.16it/s] 62%|██████▏   | 853/1380 [01:25<00:50, 10.41it/s] 62%|██████▏   | 855/1380 [01:25<00:49, 10.60it/s] 62%|██████▏   | 857/1380 [01:25<00:48, 10.72it/s] 62%|██████▏   | 859/1380 [01:25<00:48, 10.83it/s] 62%|██████▏   | 861/1380 [01:26<00:47, 10.91it/s] 63%|██████▎   | 863/1380 [01:26<00:47, 10.97it/s] 63%|██████▎   | 865/1380 [01:26<00:46, 11.00it/s] 63%|██████▎   | 867/1380 [01:26<00:46, 11.02it/s] 63%|██████▎   | 869/1380 [01:26<00:46, 11.04it/s] 63%|██████▎   | 871/1380 [01:26<00:46, 11.05it/s] 63%|██████▎   | 873/1380 [01:27<00:45, 11.03it/s] 63%|██████▎   | 875/1380 [01:27<00:45, 11.04it/s] 64%|██████▎   | 877/1380 [01:27<00:45, 11.04it/s] 64%|██████▎   | 879/1380 [01:27<00:45, 11.05it/s] 64%|██████▍   | 881/1380 [01:27<00:45, 11.04it/s] 64%|██████▍   | 883/1380 [01:28<00:45, 11.04it/s] 64%|██████▍   | 885/1380 [01:28<00:44, 11.06it/s] 64%|██████▍   | 887/1380 [01:28<00:44, 11.04it/s] 64%|██████▍   | 889/1380 [01:28<00:44, 11.06it/s] 65%|██████▍   | 891/1380 [01:28<00:44, 11.07it/s] 65%|██████▍   | 893/1380 [01:28<00:43, 11.09it/s] 65%|██████▍   | 895/1380 [01:29<00:43, 11.07it/s] 65%|██████▌   | 897/1380 [01:29<00:43, 11.08it/s] 65%|██████▌   | 899/1380 [01:29<00:43, 11.09it/s] 65%|██████▌   | 901/1380 [01:29<00:43, 11.09it/s] 65%|██████▌   | 903/1380 [01:29<00:43, 11.07it/s] 66%|██████▌   | 905/1380 [01:30<00:42, 11.08it/s] 66%|██████▌   | 907/1380 [01:30<00:42, 11.08it/s] 66%|██████▌   | 909/1380 [01:30<00:42, 11.07it/s] 66%|██████▌   | 911/1380 [01:30<00:42, 11.08it/s] 66%|██████▌   | 913/1380 [01:30<00:42, 11.09it/s] 66%|██████▋   | 915/1380 [01:30<00:41, 11.09it/s] 66%|██████▋   | 917/1380 [01:31<00:41, 11.07it/s] 67%|██████▋   | 919/1380 [01:31<00:41, 11.09it/s] 67%|██████▋   | 921/1380 [01:31<00:41, 11.10it/s] 67%|██████▋   | 923/1380 [01:31<00:41, 11.08it/s] 67%|██████▋   | 925/1380 [01:31<00:41, 11.09it/s] 67%|██████▋   | 927/1380 [01:31<00:40, 11.09it/s] 67%|██████▋   | 929/1380 [01:32<00:40, 11.09it/s] 67%|██████▋   | 931/1380 [01:32<00:40, 11.08it/s] 68%|██████▊   | 933/1380 [01:32<00:40, 11.07it/s] 68%|██████▊   | 935/1380 [01:32<00:40, 11.05it/s] 68%|██████▊   | 937/1380 [01:32<00:40, 11.06it/s] 68%|██████▊   | 939/1380 [01:33<00:39, 11.04it/s] 68%|██████▊   | 941/1380 [01:33<00:39, 11.06it/s] 68%|██████▊   | 943/1380 [01:33<00:39, 11.07it/s] 68%|██████▊   | 945/1380 [01:33<00:39, 11.06it/s] 69%|██████▊   | 947/1380 [01:33<00:39, 11.06it/s] 69%|██████▉   | 949/1380 [01:33<00:38, 11.07it/s] 69%|██████▉   | 951/1380 [01:34<00:38, 11.08it/s] 69%|██████▉   | 953/1380 [01:34<00:38, 11.07it/s] 69%|██████▉   | 955/1380 [01:34<00:38, 11.07it/s] 69%|██████▉   | 957/1380 [01:34<00:38, 11.08it/s] 69%|██████▉   | 959/1380 [01:34<00:37, 11.09it/s] 70%|██████▉   | 961/1380 [01:35<00:37, 11.06it/s] 70%|██████▉   | 963/1380 [01:35<00:37, 11.07it/s] 70%|██████▉   | 965/1380 [01:35<00:37, 11.08it/s] 70%|███████   | 967/1380 [01:35<00:37, 11.07it/s] 70%|███████   | 969/1380 [01:35<00:37, 11.06it/s] 70%|███████   | 971/1380 [01:35<00:36, 11.06it/s] 71%|███████   | 973/1380 [01:36<00:36, 11.07it/s] 71%|███████   | 975/1380 [01:36<00:36, 11.06it/s] 71%|███████   | 977/1380 [01:36<00:36, 11.07it/s] 71%|███████   | 979/1380 [01:36<00:36, 11.07it/s] 71%|███████   | 981/1380 [01:36<00:36, 11.07it/s] 71%|███████   | 983/1380 [01:37<00:35, 11.04it/s] 71%|███████▏  | 985/1380 [01:37<00:35, 11.05it/s] 72%|███████▏  | 987/1380 [01:37<00:35, 11.06it/s] 72%|███████▏  | 989/1380 [01:37<00:35, 11.03it/s] 72%|███████▏  | 991/1380 [01:37<00:35, 11.03it/s] 72%|███████▏  | 993/1380 [01:37<00:35, 11.05it/s] 72%|███████▏  | 995/1380 [01:38<00:34, 11.05it/s] 72%|███████▏  | 997/1380 [01:38<00:34, 11.03it/s] 72%|███████▏  | 999/1380 [01:38<00:34, 11.02it/s] 73%|███████▎  | 1001/1380 [01:38<00:34, 11.03it/s] 73%|███████▎  | 1003/1380 [01:38<00:34, 11.04it/s] 73%|███████▎  | 1005/1380 [01:39<00:34, 11.02it/s] 73%|███████▎  | 1007/1380 [01:39<00:33, 11.05it/s] 73%|███████▎  | 1009/1380 [01:39<00:33, 11.06it/s] 73%|███████▎  | 1011/1380 [01:39<00:33, 11.06it/s] 73%|███████▎  | 1013/1380 [01:39<00:33, 11.06it/s] 74%|███████▎  | 1015/1380 [01:39<00:32, 11.07it/s] 74%|███████▎  | 1017/1380 [01:40<00:32, 11.09it/s] 74%|███████▍  | 1019/1380 [01:40<00:32, 11.10it/s] 74%|███████▍  | 1021/1380 [01:40<00:32, 11.08it/s] 74%|███████▍  | 1023/1380 [01:40<00:32, 11.08it/s] 74%|███████▍  | 1025/1380 [01:40<00:32, 11.08it/s] 74%|███████▍  | 1027/1380 [01:41<00:31, 11.04it/s] 75%|███████▍  | 1029/1380 [01:41<00:31, 11.06it/s] 75%|███████▍  | 1031/1380 [01:41<00:31, 11.04it/s] 75%|███████▍  | 1033/1380 [01:41<00:31, 11.05it/s] 75%|███████▌  | 1035/1380 [01:41<00:31, 11.05it/s] 75%|███████▌  | 1037/1380 [01:41<00:31, 11.06it/s] 75%|███████▌  | 1039/1380 [01:42<00:30, 11.07it/s] 75%|███████▌  | 1041/1380 [01:42<00:30, 11.05it/s] 76%|███████▌  | 1043/1380 [01:42<00:30, 11.06it/s] 76%|███████▌  | 1045/1380 [01:42<00:30, 11.06it/s] 76%|███████▌  | 1047/1380 [01:42<00:30, 11.04it/s] 76%|███████▌  | 1049/1380 [01:43<00:29, 11.04it/s] 76%|███████▌  | 1051/1380 [01:43<00:29, 11.03it/s] 76%|███████▋  | 1053/1380 [01:43<00:29, 11.04it/s] 76%|███████▋  | 1055/1380 [01:43<00:29, 11.02it/s] 77%|███████▋  | 1057/1380 [01:43<00:29, 11.03it/s] 77%|███████▋  | 1059/1380 [01:43<00:29, 11.05it/s] 77%|███████▋  | 1061/1380 [01:44<00:28, 11.05it/s] 77%|███████▋  | 1063/1380 [01:44<00:28, 11.03it/s] 77%|███████▋  | 1065/1380 [01:44<00:28, 11.03it/s] 77%|███████▋  | 1067/1380 [01:44<00:28, 11.05it/s] 77%|███████▋  | 1069/1380 [01:44<00:28, 11.07it/s] 78%|███████▊  | 1071/1380 [01:45<00:27, 11.05it/s] 78%|███████▊  | 1073/1380 [01:45<00:27, 10.97it/s] 78%|███████▊  | 1075/1380 [01:45<00:27, 11.00it/s] 78%|███████▊  | 1077/1380 [01:45<00:27, 11.01it/s] 78%|███████▊  | 1079/1380 [01:45<00:27, 11.03it/s] 78%|███████▊  | 1081/1380 [01:45<00:27, 11.05it/s] 78%|███████▊  | 1083/1380 [01:46<00:26, 11.06it/s] 79%|███████▊  | 1085/1380 [01:46<00:26, 11.04it/s] 79%|███████▉  | 1087/1380 [01:46<00:26, 11.04it/s] 79%|███████▉  | 1089/1380 [01:46<00:26, 11.06it/s] 79%|███████▉  | 1091/1380 [01:46<00:26, 11.07it/s] 79%|███████▉  | 1093/1380 [01:47<00:26, 11.02it/s] 79%|███████▉  | 1095/1380 [01:47<00:25, 11.03it/s] 79%|███████▉  | 1097/1380 [01:47<00:25, 11.04it/s] 80%|███████▉  | 1099/1380 [01:47<00:25, 11.02it/s] 80%|███████▉  | 1101/1380 [01:47<00:25, 11.04it/s] 80%|███████▉  | 1103/1380 [01:47<00:25, 11.07it/s]                                                    80%|████████  | 1104/1380 [01:47<00:24, 11.07it/s][INFO|trainer.py:755] 2023-11-15 21:04:15,382 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:04:15,384 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:04:15,384 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:04:15,384 >>   Batch size = 8
{'eval_loss': 0.412049800157547, 'eval_accuracy': 0.8661524500907442, 'eval_micro_f1': 0.8661524500907442, 'eval_macro_f1': 0.8468613649471438, 'eval_runtime': 2.6333, 'eval_samples_per_second': 836.974, 'eval_steps_per_second': 104.812, 'epoch': 3.0}
{'loss': 0.1446, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 120.56it/s][A
  9%|▉         | 26/276 [00:00<00:02, 113.65it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 110.81it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 109.57it/s][A
 22%|██▏       | 61/276 [00:00<00:01, 108.91it/s][A
 26%|██▌       | 72/276 [00:00<00:01, 108.22it/s][A
 30%|███       | 83/276 [00:00<00:01, 107.76it/s][A
 34%|███▍      | 94/276 [00:00<00:01, 107.16it/s][A
 38%|███▊      | 105/276 [00:00<00:01, 106.24it/s][A
 42%|████▏     | 116/276 [00:01<00:01, 105.76it/s][A
 46%|████▌     | 127/276 [00:01<00:01, 105.87it/s][A
 50%|█████     | 138/276 [00:01<00:01, 106.00it/s][A
 54%|█████▍    | 149/276 [00:01<00:01, 106.12it/s][A
 58%|█████▊    | 160/276 [00:01<00:01, 106.09it/s][A
 62%|██████▏   | 171/276 [00:01<00:00, 105.77it/s][A
 66%|██████▌   | 182/276 [00:01<00:00, 105.35it/s][A
 70%|██████▉   | 193/276 [00:01<00:00, 105.16it/s][A
 74%|███████▍  | 204/276 [00:01<00:00, 104.83it/s][A
 78%|███████▊  | 215/276 [00:02<00:00, 104.58it/s][A
 82%|████████▏ | 226/276 [00:02<00:00, 104.39it/s][A
 86%|████████▌ | 237/276 [00:02<00:00, 104.47it/s][A
 90%|████████▉ | 248/276 [00:02<00:00, 104.57it/s][A
 94%|█████████▍| 259/276 [00:02<00:00, 104.72it/s][A
 98%|█████████▊| 270/276 [00:02<00:00, 104.63it/s][A                                                   
                                                  [A 80%|████████  | 1104/1380 [01:50<00:24, 11.07it/s]
100%|██████████| 276/276 [00:02<00:00, 104.63it/s][A
                                                  [A 80%|████████  | 1105/1380 [01:50<02:13,  2.06it/s] 80%|████████  | 1107/1380 [01:50<01:40,  2.72it/s] 80%|████████  | 1109/1380 [01:51<01:17,  3.52it/s] 81%|████████  | 1111/1380 [01:51<01:00,  4.42it/s] 81%|████████  | 1113/1380 [01:51<00:49,  5.39it/s] 81%|████████  | 1115/1380 [01:51<00:41,  6.36it/s] 81%|████████  | 1117/1380 [01:51<00:36,  7.29it/s] 81%|████████  | 1119/1380 [01:51<00:32,  8.12it/s] 81%|████████  | 1121/1380 [01:52<00:29,  8.82it/s] 81%|████████▏ | 1123/1380 [01:52<00:27,  9.39it/s] 82%|████████▏ | 1125/1380 [01:52<00:25,  9.84it/s] 82%|████████▏ | 1127/1380 [01:52<00:24, 10.18it/s] 82%|████████▏ | 1129/1380 [01:52<00:24, 10.42it/s] 82%|████████▏ | 1131/1380 [01:53<00:23, 10.62it/s] 82%|████████▏ | 1133/1380 [01:53<00:22, 10.76it/s] 82%|████████▏ | 1135/1380 [01:53<00:22, 10.86it/s] 82%|████████▏ | 1137/1380 [01:53<00:22, 10.91it/s] 83%|████████▎ | 1139/1380 [01:53<00:22, 10.95it/s] 83%|████████▎ | 1141/1380 [01:53<00:21, 10.99it/s] 83%|████████▎ | 1143/1380 [01:54<00:21, 11.00it/s] 83%|████████▎ | 1145/1380 [01:54<00:21, 11.00it/s] 83%|████████▎ | 1147/1380 [01:54<00:21, 11.01it/s] 83%|████████▎ | 1149/1380 [01:54<00:20, 11.03it/s] 83%|████████▎ | 1151/1380 [01:54<00:20, 11.03it/s] 84%|████████▎ | 1153/1380 [01:55<00:20, 11.05it/s] 84%|████████▎ | 1155/1380 [01:55<00:20, 11.06it/s] 84%|████████▍ | 1157/1380 [01:55<00:20, 11.04it/s] 84%|████████▍ | 1159/1380 [01:55<00:20, 11.04it/s] 84%|████████▍ | 1161/1380 [01:55<00:19, 11.05it/s] 84%|████████▍ | 1163/1380 [01:55<00:19, 11.05it/s] 84%|████████▍ | 1165/1380 [01:56<00:19, 11.04it/s] 85%|████████▍ | 1167/1380 [01:56<00:19, 11.04it/s] 85%|████████▍ | 1169/1380 [01:56<00:19, 11.05it/s] 85%|████████▍ | 1171/1380 [01:56<00:18, 11.06it/s] 85%|████████▌ | 1173/1380 [01:56<00:18, 11.03it/s] 85%|████████▌ | 1175/1380 [01:57<00:18, 11.05it/s] 85%|████████▌ | 1177/1380 [01:57<00:18, 11.04it/s] 85%|████████▌ | 1179/1380 [01:57<00:18, 11.03it/s] 86%|████████▌ | 1181/1380 [01:57<00:18, 11.03it/s] 86%|████████▌ | 1183/1380 [01:57<00:17, 11.04it/s] 86%|████████▌ | 1185/1380 [01:57<00:17, 11.03it/s] 86%|████████▌ | 1187/1380 [01:58<00:17, 11.02it/s] 86%|████████▌ | 1189/1380 [01:58<00:17, 11.03it/s] 86%|████████▋ | 1191/1380 [01:58<00:17, 11.04it/s] 86%|████████▋ | 1193/1380 [01:58<00:16, 11.05it/s] 87%|████████▋ | 1195/1380 [01:58<00:16, 11.03it/s] 87%|████████▋ | 1197/1380 [01:59<00:16, 11.03it/s] 87%|████████▋ | 1199/1380 [01:59<00:16, 11.04it/s] 87%|████████▋ | 1201/1380 [01:59<00:16, 11.06it/s] 87%|████████▋ | 1203/1380 [01:59<00:16, 11.05it/s] 87%|████████▋ | 1205/1380 [01:59<00:15, 11.05it/s] 87%|████████▋ | 1207/1380 [01:59<00:15, 11.05it/s] 88%|████████▊ | 1209/1380 [02:00<00:15, 11.04it/s] 88%|████████▊ | 1211/1380 [02:00<00:15, 11.01it/s] 88%|████████▊ | 1213/1380 [02:00<00:15, 11.03it/s] 88%|████████▊ | 1215/1380 [02:00<00:14, 11.04it/s] 88%|████████▊ | 1217/1380 [02:00<00:14, 11.03it/s] 88%|████████▊ | 1219/1380 [02:01<00:14, 11.04it/s] 88%|████████▊ | 1221/1380 [02:01<00:14, 11.06it/s] 89%|████████▊ | 1223/1380 [02:01<00:14, 11.05it/s] 89%|████████▉ | 1225/1380 [02:01<00:14, 11.04it/s] 89%|████████▉ | 1227/1380 [02:01<00:13, 11.04it/s] 89%|████████▉ | 1229/1380 [02:01<00:13, 11.05it/s] 89%|████████▉ | 1231/1380 [02:02<00:13, 11.05it/s] 89%|████████▉ | 1233/1380 [02:02<00:13, 11.04it/s] 89%|████████▉ | 1235/1380 [02:02<00:13, 11.06it/s] 90%|████████▉ | 1237/1380 [02:02<00:12, 11.06it/s] 90%|████████▉ | 1239/1380 [02:02<00:12, 11.05it/s] 90%|████████▉ | 1241/1380 [02:03<00:12, 11.06it/s] 90%|█████████ | 1243/1380 [02:03<00:12, 11.06it/s] 90%|█████████ | 1245/1380 [02:03<00:12, 11.07it/s] 90%|█████████ | 1247/1380 [02:03<00:12, 11.04it/s] 91%|█████████ | 1249/1380 [02:03<00:11, 11.05it/s] 91%|█████████ | 1251/1380 [02:03<00:11, 11.04it/s] 91%|█████████ | 1253/1380 [02:04<00:11, 11.04it/s] 91%|█████████ | 1255/1380 [02:04<00:11, 11.05it/s] 91%|█████████ | 1257/1380 [02:04<00:11, 11.06it/s] 91%|█████████ | 1259/1380 [02:04<00:10, 11.07it/s] 91%|█████████▏| 1261/1380 [02:04<00:10, 11.06it/s] 92%|█████████▏| 1263/1380 [02:05<00:10, 11.04it/s] 92%|█████████▏| 1265/1380 [02:05<00:10, 11.04it/s] 92%|█████████▏| 1267/1380 [02:05<00:10, 11.04it/s] 92%|█████████▏| 1269/1380 [02:05<00:10, 11.02it/s] 92%|█████████▏| 1271/1380 [02:05<00:09, 11.03it/s] 92%|█████████▏| 1273/1380 [02:05<00:09, 11.05it/s] 92%|█████████▏| 1275/1380 [02:06<00:09, 11.05it/s] 93%|█████████▎| 1277/1380 [02:06<00:09, 11.03it/s] 93%|█████████▎| 1279/1380 [02:06<00:09, 11.04it/s] 93%|█████████▎| 1281/1380 [02:06<00:08, 11.05it/s] 93%|█████████▎| 1283/1380 [02:06<00:08, 11.04it/s] 93%|█████████▎| 1285/1380 [02:07<00:08, 11.02it/s] 93%|█████████▎| 1287/1380 [02:07<00:08, 11.05it/s] 93%|█████████▎| 1289/1380 [02:07<00:08, 11.05it/s] 94%|█████████▎| 1291/1380 [02:07<00:08, 11.04it/s] 94%|█████████▎| 1293/1380 [02:07<00:07, 11.07it/s] 94%|█████████▍| 1295/1380 [02:07<00:07, 11.07it/s] 94%|█████████▍| 1297/1380 [02:08<00:07, 11.07it/s] 94%|█████████▍| 1299/1380 [02:08<00:07, 11.05it/s] 94%|█████████▍| 1301/1380 [02:08<00:07, 11.05it/s] 94%|█████████▍| 1303/1380 [02:08<00:06, 11.06it/s] 95%|█████████▍| 1305/1380 [02:08<00:06, 11.04it/s] 95%|█████████▍| 1307/1380 [02:09<00:06, 11.03it/s] 95%|█████████▍| 1309/1380 [02:09<00:06, 11.05it/s] 95%|█████████▌| 1311/1380 [02:09<00:06, 11.04it/s] 95%|█████████▌| 1313/1380 [02:09<00:06, 11.04it/s] 95%|█████████▌| 1315/1380 [02:09<00:05, 11.05it/s] 95%|█████████▌| 1317/1380 [02:09<00:05, 11.05it/s] 96%|█████████▌| 1319/1380 [02:10<00:05, 11.03it/s] 96%|█████████▌| 1321/1380 [02:10<00:05, 11.03it/s] 96%|█████████▌| 1323/1380 [02:10<00:05, 11.03it/s] 96%|█████████▌| 1325/1380 [02:10<00:04, 11.05it/s] 96%|█████████▌| 1327/1380 [02:10<00:04, 11.04it/s] 96%|█████████▋| 1329/1380 [02:11<00:04, 11.07it/s] 96%|█████████▋| 1331/1380 [02:11<00:04, 11.07it/s] 97%|█████████▋| 1333/1380 [02:11<00:04, 11.05it/s] 97%|█████████▋| 1335/1380 [02:11<00:04, 11.05it/s] 97%|█████████▋| 1337/1380 [02:11<00:03, 11.05it/s] 97%|█████████▋| 1339/1380 [02:11<00:03, 11.05it/s] 97%|█████████▋| 1341/1380 [02:12<00:03, 11.02it/s] 97%|█████████▋| 1343/1380 [02:12<00:03, 11.03it/s] 97%|█████████▋| 1345/1380 [02:12<00:03, 11.05it/s] 98%|█████████▊| 1347/1380 [02:12<00:02, 11.07it/s] 98%|█████████▊| 1349/1380 [02:12<00:02, 11.06it/s] 98%|█████████▊| 1351/1380 [02:12<00:02, 11.06it/s] 98%|█████████▊| 1353/1380 [02:13<00:02, 11.07it/s] 98%|█████████▊| 1355/1380 [02:13<00:02, 11.06it/s] 98%|█████████▊| 1357/1380 [02:13<00:02, 11.03it/s] 98%|█████████▊| 1359/1380 [02:13<00:01, 11.04it/s] 99%|█████████▊| 1361/1380 [02:13<00:01, 11.03it/s] 99%|█████████▉| 1363/1380 [02:14<00:01, 11.03it/s] 99%|█████████▉| 1365/1380 [02:14<00:01, 11.04it/s] 99%|█████████▉| 1367/1380 [02:14<00:01, 11.05it/s] 99%|█████████▉| 1369/1380 [02:14<00:00, 11.06it/s] 99%|█████████▉| 1371/1380 [02:14<00:00, 11.05it/s] 99%|█████████▉| 1373/1380 [02:14<00:00, 11.05it/s]100%|█████████▉| 1375/1380 [02:15<00:00, 11.05it/s]100%|█████████▉| 1377/1380 [02:15<00:00, 11.05it/s]100%|█████████▉| 1379/1380 [02:15<00:00, 11.04it/s]                                                   100%|██████████| 1380/1380 [02:15<00:00, 11.04it/s][INFO|trainer.py:755] 2023-11-15 21:04:43,000 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:04:43,002 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:04:43,002 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:04:43,002 >>   Batch size = 8
{'eval_loss': 0.46053028106689453, 'eval_accuracy': 0.8734119782214156, 'eval_micro_f1': 0.8734119782214156, 'eval_macro_f1': 0.8550241827778727, 'eval_runtime': 2.6517, 'eval_samples_per_second': 831.18, 'eval_steps_per_second': 104.086, 'epoch': 4.0}
{'loss': 0.0987, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 119.92it/s][A
  9%|▉         | 25/276 [00:00<00:02, 113.73it/s][A
 13%|█▎        | 37/276 [00:00<00:02, 111.66it/s][A
 18%|█▊        | 49/276 [00:00<00:02, 110.36it/s][A
 22%|██▏       | 61/276 [00:00<00:01, 108.94it/s][A
 26%|██▌       | 72/276 [00:00<00:01, 108.15it/s][A
 30%|███       | 83/276 [00:00<00:01, 107.61it/s][A
 34%|███▍      | 94/276 [00:00<00:01, 106.83it/s][A
 38%|███▊      | 105/276 [00:00<00:01, 106.16it/s][A
 42%|████▏     | 116/276 [00:01<00:01, 105.68it/s][A
 46%|████▌     | 127/276 [00:01<00:01, 105.64it/s][A
 50%|█████     | 138/276 [00:01<00:01, 105.93it/s][A
 54%|█████▍    | 149/276 [00:01<00:01, 106.09it/s][A
 58%|█████▊    | 160/276 [00:01<00:01, 106.15it/s][A
 62%|██████▏   | 171/276 [00:01<00:00, 105.98it/s][A
 66%|██████▌   | 182/276 [00:01<00:00, 105.69it/s][A
 70%|██████▉   | 193/276 [00:01<00:00, 105.18it/s][A
 74%|███████▍  | 204/276 [00:01<00:00, 104.52it/s][A
 78%|███████▊  | 215/276 [00:02<00:00, 104.21it/s][A
 82%|████████▏ | 226/276 [00:02<00:00, 104.26it/s][A
 86%|████████▌ | 237/276 [00:02<00:00, 104.24it/s][A
 90%|████████▉ | 248/276 [00:02<00:00, 104.21it/s][A
 94%|█████████▍| 259/276 [00:02<00:00, 104.42it/s][A
 98%|█████████▊| 270/276 [00:02<00:00, 104.40it/s][A                                                   
                                                  [A100%|██████████| 1380/1380 [02:18<00:00, 11.04it/s]
100%|██████████| 276/276 [00:02<00:00, 104.40it/s][A
                                                  [A[INFO|trainer.py:1963] 2023-11-15 21:04:45,657 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:18<00:00, 11.04it/s]100%|██████████| 1380/1380 [02:18<00:00,  9.98it/s]
[INFO|trainer.py:2855] 2023-11-15 21:04:45,660 >> Saving model checkpoint to ./result/acl_bert-base-cased_adapter__seed3
[INFO|configuration_utils.py:460] 2023-11-15 21:04:45,663 >> Configuration saved in ./result/acl_bert-base-cased_adapter__seed3/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:04:46,591 >> Model weights saved in ./result/acl_bert-base-cased_adapter__seed3/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:04:46,594 >> tokenizer config file saved in ./result/acl_bert-base-cased_adapter__seed3/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:04:46,596 >> Special tokens file saved in ./result/acl_bert-base-cased_adapter__seed3/special_tokens_map.json
{'eval_loss': 0.5022537708282471, 'eval_accuracy': 0.8679673321234119, 'eval_micro_f1': 0.8679673321234119, 'eval_macro_f1': 0.8497733358404057, 'eval_runtime': 2.6509, 'eval_samples_per_second': 831.401, 'eval_steps_per_second': 104.114, 'epoch': 5.0}
{'train_runtime': 138.2574, 'train_samples_per_second': 318.826, 'train_steps_per_second': 9.981, 'train_loss': 0.25475223651830703, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2548
  train_runtime            = 0:02:18.25
  train_samples            =       8816
  train_samples_per_second =    318.826
  train_steps_per_second   =      9.981
11/15/2023 21:04:46 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:04:46,638 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:04:46,639 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:04:46,640 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:04:46,640 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  5%|▍         | 13/276 [00:00<00:02, 121.09it/s]  9%|▉         | 26/276 [00:00<00:02, 112.02it/s] 14%|█▍        | 38/276 [00:00<00:02, 109.42it/s] 18%|█▊        | 49/276 [00:00<00:02, 108.23it/s] 22%|██▏       | 60/276 [00:00<00:02, 107.59it/s] 26%|██▌       | 71/276 [00:00<00:01, 107.33it/s] 30%|██▉       | 82/276 [00:00<00:01, 106.98it/s] 34%|███▎      | 93/276 [00:00<00:01, 106.38it/s] 38%|███▊      | 104/276 [00:00<00:01, 105.44it/s] 42%|████▏     | 115/276 [00:01<00:01, 105.23it/s] 46%|████▌     | 126/276 [00:01<00:01, 105.46it/s] 50%|████▉     | 137/276 [00:01<00:01, 105.66it/s] 54%|█████▎    | 148/276 [00:01<00:01, 105.86it/s] 58%|█████▊    | 159/276 [00:01<00:01, 105.89it/s] 62%|██████▏   | 170/276 [00:01<00:01, 105.26it/s] 66%|██████▌   | 181/276 [00:01<00:00, 105.36it/s] 70%|██████▉   | 192/276 [00:01<00:00, 105.18it/s] 74%|███████▎  | 203/276 [00:01<00:00, 104.92it/s] 78%|███████▊  | 214/276 [00:02<00:00, 104.80it/s] 82%|████████▏ | 225/276 [00:02<00:00, 104.79it/s] 86%|████████▌ | 236/276 [00:02<00:00, 104.68it/s] 89%|████████▉ | 247/276 [00:02<00:00, 104.91it/s] 93%|█████████▎| 258/276 [00:02<00:00, 105.16it/s] 97%|█████████▋| 269/276 [00:02<00:00, 105.12it/s]100%|██████████| 276/276 [00:02<00:00, 104.48it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.868
  eval_loss               =     0.5023
  eval_macro_f1           =     0.8498
  eval_micro_f1           =      0.868
  eval_runtime            = 0:00:02.65
  eval_samples            =       2204
  eval_samples_per_second =    830.483
  eval_steps_per_second   =    103.999
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▂▁▅█▆▆
wandb:                      eval/loss ▁▂▃▆██
wandb:                  eval/macro_f1 ▁▁▅█▆▆
wandb:                  eval/micro_f1 ▂▁▅█▆▆
wandb:                   eval/runtime ▁▄▆███
wandb:        eval/samples_per_second █▅▃▁▁▁
wandb:          eval/steps_per_second █▅▃▁▁▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.86797
wandb:                      eval/loss 0.50225
wandb:                  eval/macro_f1 0.84977
wandb:                  eval/micro_f1 0.86797
wandb:                   eval/runtime 2.6539
wandb:        eval/samples_per_second 830.483
wandb:          eval/steps_per_second 103.999
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0987
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.25475
wandb:            train/train_runtime 138.2574
wandb: train/train_samples_per_second 318.826
wandb:   train/train_steps_per_second 9.981
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_210140-h8n6ziwb
wandb: Find logs at: ./wandb/offline-run-20231115_210140-h8n6ziwb/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3/runs/Nov15_21-04-58_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:04:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:04:58 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3/runs/Nov15_21-04-58_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  38%|███▊      | 4133/11020 [00:00<00:00, 40941.83 examples/s]Map:  76%|███████▌  | 8356/11020 [00:00<00:00, 41689.43 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 41126.85 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 21:05:14,972 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:05:14,982 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 21:05:24,998 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 21:05:35,016 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:05:35,017 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:05:55,054 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:05:55,055 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:05:55,055 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:05:55,055 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:05:55,056 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 21:05:55,057 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:05:55,058 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 21:05:55,077 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:05:55,078 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:06:15,213 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 21:06:16,607 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:06:16,608 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  34%|███▍      | 3000/8816 [00:00<00:00, 21676.18 examples/s]Running tokenizer on dataset:  79%|███████▉  | 7000/8816 [00:00<00:00, 23327.41 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 23279.35 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 24944.87 examples/s]
11/15/2023 21:06:17 - INFO - __main__ - Sample 5060 of the training set: {'text': 'After GABA immunostaining, as elaborated in earlier studies (Domenici et al. 1988; Granda and Crossland 1989), the cell bodies, fibers, and numerous terminals showed GABA-like immunoreactivity in the Imc nucleus.', 'label': 0, 'input_ids': [102, 647, 12310, 18343, 422, 188, 23886, 121, 3923, 826, 145, 1152, 12585, 30109, 365, 186, 205, 18811, 1814, 10097, 30110, 137, 2057, 1881, 17848, 546, 422, 111, 377, 8198, 422, 7172, 422, 137, 5876, 13596, 1367, 12310, 579, 1967, 12734, 5219, 121, 111, 264, 30116, 6438, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:06:17 - INFO - __main__ - Sample 4715 of the training set: {'text': 'The dynamic nature of the Dlg ‘supertertiary’ core structure suggest precise regulatory inputs have likely evolved to control its signaling output [25, 26].', 'label': 0, 'input_ids': [102, 111, 2749, 2540, 131, 111, 6512, 30123, 1384, 2389, 22594, 426, 1212, 5459, 3077, 1187, 1739, 6447, 5418, 5671, 360, 1987, 11150, 147, 602, 633, 3354, 1892, 260, 1552, 422, 2381, 1901, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:06:17 - INFO - __main__ - Sample 216 of the training set: {'text': 'C57 mice, however, have been reported to be more sensitive to the incentive properties of other drugs of abuse including amphetamine, cocaine, methamphetamine, or nicotine than DBA mice (for review see Crawley et al. 1997; Cabib et al. 2000; Orsini et al. 2004; 2005; Grabus et al. 2006).', 'label': 0, 'input_ids': [102, 115, 5020, 1682, 422, 694, 422, 360, 528, 1214, 147, 195, 475, 4232, 147, 111, 13118, 1784, 131, 494, 3845, 131, 8470, 1471, 11659, 7972, 22229, 422, 14083, 422, 513, 29314, 422, 234, 14006, 506, 4630, 30110, 1682, 145, 168, 1579, 1461, 17305, 3162, 365, 186, 205, 10812, 1814, 10993, 389, 365, 186, 205, 4708, 1814, 26951, 4983, 365, 186, 205, 6706, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 21:06:17 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:06:18,257 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:06:18,264 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:06:18,264 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 21:06:18,264 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:06:18,265 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:06:18,265 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:06:18,265 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:06:18,266 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 21:06:18,267 >>   Number of trainable parameters = 109,920,771
[INFO|integration_utils.py:716] 2023-11-15 21:06:18,268 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<28:10,  1.23s/it]  0%|          | 3/1380 [00:01<08:47,  2.61it/s]  0%|          | 5/1380 [00:01<05:18,  4.31it/s]  1%|          | 7/1380 [00:01<03:55,  5.84it/s]  1%|          | 9/1380 [00:01<03:12,  7.11it/s]  1%|          | 11/1380 [00:02<02:47,  8.15it/s]  1%|          | 13/1380 [00:02<02:32,  8.97it/s]  1%|          | 15/1380 [00:02<02:22,  9.59it/s]  1%|          | 17/1380 [00:02<02:15, 10.04it/s]  1%|▏         | 19/1380 [00:02<02:11, 10.38it/s]  2%|▏         | 21/1380 [00:03<02:08, 10.61it/s]  2%|▏         | 23/1380 [00:03<02:05, 10.78it/s]  2%|▏         | 25/1380 [00:03<02:04, 10.91it/s]  2%|▏         | 27/1380 [00:03<02:03, 10.99it/s]  2%|▏         | 29/1380 [00:03<02:02, 11.05it/s]  2%|▏         | 31/1380 [00:03<02:01, 11.08it/s]  2%|▏         | 33/1380 [00:04<02:01, 11.11it/s]  3%|▎         | 35/1380 [00:04<02:00, 11.15it/s]  3%|▎         | 37/1380 [00:04<02:00, 11.13it/s]  3%|▎         | 39/1380 [00:04<02:00, 11.14it/s]  3%|▎         | 41/1380 [00:04<01:59, 11.16it/s]  3%|▎         | 43/1380 [00:04<01:59, 11.17it/s]  3%|▎         | 45/1380 [00:05<01:59, 11.17it/s]  3%|▎         | 47/1380 [00:05<01:59, 11.17it/s]  4%|▎         | 49/1380 [00:05<01:59, 11.18it/s]  4%|▎         | 51/1380 [00:05<01:58, 11.18it/s]  4%|▍         | 53/1380 [00:05<01:59, 11.11it/s]  4%|▍         | 55/1380 [00:06<01:59, 11.13it/s]  4%|▍         | 57/1380 [00:06<01:58, 11.14it/s]  4%|▍         | 59/1380 [00:06<01:58, 11.14it/s]  4%|▍         | 61/1380 [00:06<01:58, 11.15it/s]  5%|▍         | 63/1380 [00:06<01:58, 11.16it/s]  5%|▍         | 65/1380 [00:06<01:57, 11.17it/s]  5%|▍         | 67/1380 [00:07<01:57, 11.18it/s]  5%|▌         | 69/1380 [00:07<01:58, 11.11it/s]  5%|▌         | 71/1380 [00:07<01:57, 11.16it/s]  5%|▌         | 73/1380 [00:07<01:56, 11.20it/s]  5%|▌         | 75/1380 [00:07<01:56, 11.22it/s]  6%|▌         | 77/1380 [00:08<01:55, 11.24it/s]  6%|▌         | 79/1380 [00:08<01:55, 11.25it/s]  6%|▌         | 81/1380 [00:08<01:55, 11.27it/s]  6%|▌         | 83/1380 [00:08<01:55, 11.27it/s]  6%|▌         | 85/1380 [00:08<01:54, 11.26it/s]  6%|▋         | 87/1380 [00:08<01:54, 11.27it/s]  6%|▋         | 89/1380 [00:09<01:54, 11.28it/s]  7%|▋         | 91/1380 [00:09<01:54, 11.27it/s]  7%|▋         | 93/1380 [00:09<01:54, 11.28it/s]  7%|▋         | 95/1380 [00:09<01:53, 11.27it/s]  7%|▋         | 97/1380 [00:09<01:53, 11.29it/s]  7%|▋         | 99/1380 [00:09<01:53, 11.28it/s]  7%|▋         | 101/1380 [00:10<01:53, 11.28it/s]  7%|▋         | 103/1380 [00:10<01:53, 11.27it/s]  8%|▊         | 105/1380 [00:10<01:53, 11.27it/s]  8%|▊         | 107/1380 [00:10<01:53, 11.26it/s]  8%|▊         | 109/1380 [00:10<01:52, 11.27it/s]  8%|▊         | 111/1380 [00:11<01:52, 11.27it/s]  8%|▊         | 113/1380 [00:11<01:52, 11.28it/s]  8%|▊         | 115/1380 [00:11<01:52, 11.22it/s]  8%|▊         | 117/1380 [00:11<01:52, 11.24it/s]  9%|▊         | 119/1380 [00:11<01:52, 11.25it/s]  9%|▉         | 121/1380 [00:11<01:51, 11.26it/s]  9%|▉         | 123/1380 [00:12<01:51, 11.25it/s]  9%|▉         | 125/1380 [00:12<01:51, 11.25it/s]  9%|▉         | 127/1380 [00:12<01:51, 11.25it/s]  9%|▉         | 129/1380 [00:12<01:52, 11.17it/s]  9%|▉         | 131/1380 [00:12<01:51, 11.24it/s] 10%|▉         | 133/1380 [00:12<01:50, 11.25it/s] 10%|▉         | 135/1380 [00:13<01:50, 11.25it/s] 10%|▉         | 137/1380 [00:13<01:50, 11.25it/s] 10%|█         | 139/1380 [00:13<01:50, 11.26it/s] 10%|█         | 141/1380 [00:13<01:49, 11.27it/s] 10%|█         | 143/1380 [00:13<01:49, 11.27it/s] 11%|█         | 145/1380 [00:14<01:49, 11.26it/s] 11%|█         | 147/1380 [00:14<01:49, 11.27it/s] 11%|█         | 149/1380 [00:14<01:49, 11.28it/s] 11%|█         | 151/1380 [00:14<01:49, 11.27it/s] 11%|█         | 153/1380 [00:14<01:48, 11.26it/s] 11%|█         | 155/1380 [00:14<01:48, 11.25it/s] 11%|█▏        | 157/1380 [00:15<01:48, 11.27it/s] 12%|█▏        | 159/1380 [00:15<01:48, 11.26it/s] 12%|█▏        | 161/1380 [00:15<01:48, 11.21it/s] 12%|█▏        | 163/1380 [00:15<01:48, 11.22it/s] 12%|█▏        | 165/1380 [00:15<01:48, 11.24it/s] 12%|█▏        | 167/1380 [00:16<01:47, 11.25it/s] 12%|█▏        | 169/1380 [00:16<01:47, 11.24it/s] 12%|█▏        | 171/1380 [00:16<01:47, 11.23it/s] 13%|█▎        | 173/1380 [00:16<01:47, 11.23it/s] 13%|█▎        | 175/1380 [00:16<01:47, 11.22it/s] 13%|█▎        | 177/1380 [00:16<01:47, 11.22it/s] 13%|█▎        | 179/1380 [00:17<01:46, 11.24it/s] 13%|█▎        | 181/1380 [00:17<01:46, 11.25it/s] 13%|█▎        | 183/1380 [00:17<01:46, 11.24it/s] 13%|█▎        | 185/1380 [00:17<01:46, 11.24it/s] 14%|█▎        | 187/1380 [00:17<01:46, 11.24it/s] 14%|█▎        | 189/1380 [00:17<01:45, 11.25it/s] 14%|█▍        | 191/1380 [00:18<01:45, 11.24it/s] 14%|█▍        | 193/1380 [00:18<01:45, 11.25it/s] 14%|█▍        | 195/1380 [00:18<01:45, 11.25it/s] 14%|█▍        | 197/1380 [00:18<01:45, 11.23it/s] 14%|█▍        | 199/1380 [00:18<01:45, 11.22it/s] 15%|█▍        | 201/1380 [00:19<01:44, 11.25it/s] 15%|█▍        | 203/1380 [00:19<01:44, 11.25it/s] 15%|█▍        | 205/1380 [00:19<01:45, 11.15it/s] 15%|█▌        | 207/1380 [00:19<01:45, 11.17it/s] 15%|█▌        | 209/1380 [00:19<01:44, 11.17it/s] 15%|█▌        | 211/1380 [00:19<01:44, 11.18it/s] 15%|█▌        | 213/1380 [00:20<01:44, 11.19it/s] 16%|█▌        | 215/1380 [00:20<01:43, 11.21it/s] 16%|█▌        | 217/1380 [00:20<01:43, 11.21it/s] 16%|█▌        | 219/1380 [00:20<01:43, 11.22it/s] 16%|█▌        | 221/1380 [00:20<01:43, 11.20it/s] 16%|█▌        | 223/1380 [00:21<01:42, 11.26it/s] 16%|█▋        | 225/1380 [00:21<01:42, 11.27it/s] 16%|█▋        | 227/1380 [00:21<01:42, 11.26it/s] 17%|█▋        | 229/1380 [00:21<01:42, 11.23it/s] 17%|█▋        | 231/1380 [00:21<01:42, 11.22it/s] 17%|█▋        | 233/1380 [00:21<01:42, 11.23it/s] 17%|█▋        | 235/1380 [00:22<01:42, 11.22it/s] 17%|█▋        | 237/1380 [00:22<01:41, 11.21it/s] 17%|█▋        | 239/1380 [00:22<01:41, 11.22it/s] 17%|█▋        | 241/1380 [00:22<01:41, 11.22it/s] 18%|█▊        | 243/1380 [00:22<01:42, 11.13it/s] 18%|█▊        | 245/1380 [00:22<01:41, 11.15it/s] 18%|█▊        | 247/1380 [00:23<01:41, 11.17it/s] 18%|█▊        | 249/1380 [00:23<01:41, 11.18it/s] 18%|█▊        | 251/1380 [00:23<01:40, 11.18it/s] 18%|█▊        | 253/1380 [00:23<01:40, 11.20it/s] 18%|█▊        | 255/1380 [00:23<01:40, 11.21it/s] 19%|█▊        | 257/1380 [00:24<01:40, 11.22it/s] 19%|█▉        | 259/1380 [00:24<01:40, 11.21it/s] 19%|█▉        | 261/1380 [00:24<01:40, 11.17it/s] 19%|█▉        | 263/1380 [00:24<01:39, 11.24it/s] 19%|█▉        | 265/1380 [00:24<01:39, 11.24it/s] 19%|█▉        | 267/1380 [00:24<01:39, 11.22it/s] 19%|█▉        | 269/1380 [00:25<01:39, 11.22it/s] 20%|█▉        | 271/1380 [00:25<01:38, 11.22it/s] 20%|█▉        | 273/1380 [00:25<01:38, 11.21it/s] 20%|█▉        | 275/1380 [00:25<01:38, 11.23it/s]                                                   20%|██        | 276/1380 [00:25<01:38, 11.23it/s][INFO|trainer.py:755] 2023-11-15 21:06:43,975 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:06:43,977 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:06:43,977 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:06:43,977 >>   Batch size = 8
{'loss': 0.4457, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 121.92it/s][A
  9%|▉         | 26/276 [00:00<00:02, 115.73it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 113.71it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 112.43it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 111.71it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 111.39it/s][A
 31%|███       | 86/276 [00:00<00:01, 110.91it/s][A
 36%|███▌      | 98/276 [00:00<00:01, 110.54it/s][A
 40%|███▉      | 110/276 [00:00<00:01, 109.86it/s][A
 44%|████▍     | 121/276 [00:01<00:01, 109.60it/s][A
 48%|████▊     | 132/276 [00:01<00:01, 102.49it/s][A
 52%|█████▏    | 143/276 [00:01<00:01, 104.55it/s][A
 56%|█████▌    | 154/276 [00:01<00:01, 105.84it/s][A
 60%|█████▉    | 165/276 [00:01<00:01, 107.00it/s][A
 64%|██████▍   | 177/276 [00:01<00:00, 108.04it/s][A
 68%|██████▊   | 188/276 [00:01<00:00, 108.55it/s][A
 72%|███████▏  | 199/276 [00:01<00:00, 108.82it/s][A
 76%|███████▌  | 210/276 [00:01<00:00, 108.70it/s][A
 80%|████████  | 221/276 [00:02<00:00, 108.50it/s][A
 84%|████████▍ | 232/276 [00:02<00:00, 108.01it/s][A
 88%|████████▊ | 243/276 [00:02<00:00, 108.17it/s][A
 92%|█████████▏| 254/276 [00:02<00:00, 108.42it/s][A
 96%|█████████▌| 265/276 [00:02<00:00, 108.75it/s][A                                                  
                                                  [A 20%|██        | 276/1380 [00:28<01:38, 11.23it/s]
100%|██████████| 276/276 [00:02<00:00, 108.75it/s][A
                                                  [A 20%|██        | 277/1380 [00:28<08:41,  2.11it/s] 20%|██        | 279/1380 [00:28<06:34,  2.79it/s] 20%|██        | 281/1380 [00:28<05:05,  3.60it/s] 21%|██        | 283/1380 [00:28<04:02,  4.52it/s] 21%|██        | 285/1380 [00:29<03:18,  5.51it/s] 21%|██        | 287/1380 [00:29<02:48,  6.50it/s] 21%|██        | 289/1380 [00:29<02:27,  7.42it/s] 21%|██        | 291/1380 [00:29<02:11,  8.25it/s] 21%|██        | 293/1380 [00:29<02:01,  8.96it/s] 21%|██▏       | 295/1380 [00:29<01:53,  9.54it/s] 22%|██▏       | 297/1380 [00:30<01:48,  9.99it/s] 22%|██▏       | 299/1380 [00:30<01:44, 10.32it/s] 22%|██▏       | 301/1380 [00:30<01:42, 10.58it/s] 22%|██▏       | 303/1380 [00:30<01:40, 10.77it/s] 22%|██▏       | 305/1380 [00:30<01:38, 10.90it/s] 22%|██▏       | 307/1380 [00:31<01:37, 10.97it/s] 22%|██▏       | 309/1380 [00:31<01:37, 11.03it/s] 23%|██▎       | 311/1380 [00:31<01:36, 11.07it/s] 23%|██▎       | 313/1380 [00:31<01:36, 11.11it/s] 23%|██▎       | 315/1380 [00:31<01:35, 11.14it/s] 23%|██▎       | 317/1380 [00:31<01:35, 11.16it/s] 23%|██▎       | 319/1380 [00:32<01:34, 11.18it/s] 23%|██▎       | 321/1380 [00:32<01:34, 11.15it/s] 23%|██▎       | 323/1380 [00:32<01:34, 11.17it/s] 24%|██▎       | 325/1380 [00:32<01:34, 11.18it/s] 24%|██▎       | 327/1380 [00:32<01:34, 11.18it/s] 24%|██▍       | 329/1380 [00:33<01:34, 11.17it/s] 24%|██▍       | 331/1380 [00:33<01:33, 11.18it/s] 24%|██▍       | 333/1380 [00:33<01:33, 11.19it/s] 24%|██▍       | 335/1380 [00:33<01:33, 11.20it/s] 24%|██▍       | 337/1380 [00:33<01:33, 11.19it/s] 25%|██▍       | 339/1380 [00:33<01:32, 11.20it/s] 25%|██▍       | 341/1380 [00:34<01:32, 11.20it/s] 25%|██▍       | 343/1380 [00:34<01:32, 11.20it/s] 25%|██▌       | 345/1380 [00:34<01:32, 11.18it/s] 25%|██▌       | 347/1380 [00:34<01:32, 11.20it/s] 25%|██▌       | 349/1380 [00:34<01:32, 11.20it/s] 25%|██▌       | 351/1380 [00:34<01:31, 11.19it/s] 26%|██▌       | 353/1380 [00:35<01:31, 11.17it/s] 26%|██▌       | 355/1380 [00:35<01:31, 11.18it/s] 26%|██▌       | 357/1380 [00:35<01:31, 11.18it/s] 26%|██▌       | 359/1380 [00:35<01:31, 11.18it/s] 26%|██▌       | 361/1380 [00:35<01:31, 11.18it/s] 26%|██▋       | 363/1380 [00:36<01:30, 11.19it/s] 26%|██▋       | 365/1380 [00:36<01:30, 11.19it/s] 27%|██▋       | 367/1380 [00:36<01:30, 11.19it/s] 27%|██▋       | 369/1380 [00:36<01:30, 11.19it/s] 27%|██▋       | 371/1380 [00:36<01:30, 11.20it/s] 27%|██▋       | 373/1380 [00:36<01:29, 11.19it/s] 27%|██▋       | 375/1380 [00:37<01:29, 11.18it/s] 27%|██▋       | 377/1380 [00:37<01:29, 11.19it/s] 27%|██▋       | 379/1380 [00:37<01:29, 11.19it/s] 28%|██▊       | 381/1380 [00:37<01:29, 11.19it/s] 28%|██▊       | 383/1380 [00:37<01:29, 11.19it/s] 28%|██▊       | 385/1380 [00:38<01:28, 11.19it/s] 28%|██▊       | 387/1380 [00:38<01:28, 11.19it/s] 28%|██▊       | 389/1380 [00:38<01:28, 11.19it/s] 28%|██▊       | 391/1380 [00:38<01:28, 11.18it/s] 28%|██▊       | 393/1380 [00:38<01:28, 11.17it/s] 29%|██▊       | 395/1380 [00:38<01:28, 11.17it/s] 29%|██▉       | 397/1380 [00:39<01:27, 11.17it/s] 29%|██▉       | 399/1380 [00:39<01:27, 11.18it/s] 29%|██▉       | 401/1380 [00:39<01:27, 11.17it/s] 29%|██▉       | 403/1380 [00:39<01:27, 11.17it/s] 29%|██▉       | 405/1380 [00:39<01:27, 11.16it/s] 29%|██▉       | 407/1380 [00:40<01:27, 11.16it/s] 30%|██▉       | 409/1380 [00:40<01:26, 11.16it/s] 30%|██▉       | 411/1380 [00:40<01:26, 11.16it/s] 30%|██▉       | 413/1380 [00:40<01:26, 11.16it/s] 30%|███       | 415/1380 [00:40<01:26, 11.16it/s] 30%|███       | 417/1380 [00:40<01:26, 11.17it/s] 30%|███       | 419/1380 [00:41<01:26, 11.17it/s] 31%|███       | 421/1380 [00:41<01:25, 11.17it/s] 31%|███       | 423/1380 [00:41<01:25, 11.17it/s] 31%|███       | 425/1380 [00:41<01:25, 11.16it/s] 31%|███       | 427/1380 [00:41<01:25, 11.16it/s] 31%|███       | 429/1380 [00:41<01:25, 11.08it/s] 31%|███       | 431/1380 [00:42<01:25, 11.09it/s] 31%|███▏      | 433/1380 [00:42<01:25, 11.13it/s] 32%|███▏      | 435/1380 [00:42<01:24, 11.13it/s] 32%|███▏      | 437/1380 [00:42<01:24, 11.14it/s] 32%|███▏      | 439/1380 [00:42<01:24, 11.14it/s] 32%|███▏      | 441/1380 [00:43<01:24, 11.15it/s] 32%|███▏      | 443/1380 [00:43<01:23, 11.16it/s] 32%|███▏      | 445/1380 [00:43<01:23, 11.16it/s] 32%|███▏      | 447/1380 [00:43<01:23, 11.14it/s] 33%|███▎      | 449/1380 [00:43<01:23, 11.16it/s] 33%|███▎      | 451/1380 [00:43<01:23, 11.16it/s] 33%|███▎      | 453/1380 [00:44<01:23, 11.16it/s] 33%|███▎      | 455/1380 [00:44<01:22, 11.16it/s] 33%|███▎      | 457/1380 [00:44<01:22, 11.17it/s] 33%|███▎      | 459/1380 [00:44<01:22, 11.16it/s] 33%|███▎      | 461/1380 [00:44<01:22, 11.17it/s] 34%|███▎      | 463/1380 [00:45<01:22, 11.16it/s] 34%|███▎      | 465/1380 [00:45<01:21, 11.18it/s] 34%|███▍      | 467/1380 [00:45<01:21, 11.15it/s] 34%|███▍      | 469/1380 [00:45<01:21, 11.16it/s] 34%|███▍      | 471/1380 [00:45<01:21, 11.17it/s] 34%|███▍      | 473/1380 [00:45<01:21, 11.17it/s] 34%|███▍      | 475/1380 [00:46<01:21, 11.17it/s] 35%|███▍      | 477/1380 [00:46<01:20, 11.17it/s] 35%|███▍      | 479/1380 [00:46<01:20, 11.16it/s] 35%|███▍      | 481/1380 [00:46<01:20, 11.12it/s] 35%|███▌      | 483/1380 [00:46<01:20, 11.16it/s] 35%|███▌      | 485/1380 [00:46<01:20, 11.15it/s] 35%|███▌      | 487/1380 [00:47<01:20, 11.15it/s] 35%|███▌      | 489/1380 [00:47<01:20, 11.13it/s] 36%|███▌      | 491/1380 [00:47<01:19, 11.13it/s] 36%|███▌      | 493/1380 [00:47<01:19, 11.16it/s] 36%|███▌      | 495/1380 [00:47<01:19, 11.16it/s] 36%|███▌      | 497/1380 [00:48<01:19, 11.10it/s] 36%|███▌      | 499/1380 [00:48<01:19, 11.11it/s] 36%|███▋      | 501/1380 [00:48<01:19, 11.12it/s] 36%|███▋      | 503/1380 [00:48<01:18, 11.13it/s] 37%|███▋      | 505/1380 [00:48<01:18, 11.14it/s] 37%|███▋      | 507/1380 [00:48<01:18, 11.14it/s] 37%|███▋      | 509/1380 [00:49<01:18, 11.15it/s] 37%|███▋      | 511/1380 [00:49<01:18, 11.14it/s] 37%|███▋      | 513/1380 [00:49<01:17, 11.15it/s] 37%|███▋      | 515/1380 [00:49<01:17, 11.16it/s] 37%|███▋      | 517/1380 [00:49<01:17, 11.16it/s] 38%|███▊      | 519/1380 [00:50<01:17, 11.09it/s] 38%|███▊      | 521/1380 [00:50<01:16, 11.17it/s] 38%|███▊      | 523/1380 [00:50<01:16, 11.16it/s] 38%|███▊      | 525/1380 [00:50<01:16, 11.15it/s] 38%|███▊      | 527/1380 [00:50<01:16, 11.13it/s] 38%|███▊      | 529/1380 [00:50<01:16, 11.13it/s] 38%|███▊      | 531/1380 [00:51<01:16, 11.13it/s] 39%|███▊      | 533/1380 [00:51<01:15, 11.15it/s] 39%|███▉      | 535/1380 [00:51<01:15, 11.14it/s] 39%|███▉      | 537/1380 [00:51<01:15, 11.15it/s] 39%|███▉      | 539/1380 [00:51<01:15, 11.16it/s] 39%|███▉      | 541/1380 [00:52<01:15, 11.15it/s] 39%|███▉      | 543/1380 [00:52<01:15, 11.15it/s] 39%|███▉      | 545/1380 [00:52<01:14, 11.15it/s] 40%|███▉      | 547/1380 [00:52<01:14, 11.14it/s] 40%|███▉      | 549/1380 [00:52<01:14, 11.13it/s] 40%|███▉      | 551/1380 [00:52<01:14, 11.15it/s]                                                   40%|████      | 552/1380 [00:52<01:14, 11.15it/s][INFO|trainer.py:755] 2023-11-15 21:07:11,255 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:07:11,257 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:07:11,257 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:07:11,257 >>   Batch size = 8
{'eval_loss': 0.34776028990745544, 'eval_accuracy': 0.8756805807622504, 'eval_micro_f1': 0.8756805807622504, 'eval_macro_f1': 0.8575990404210082, 'eval_runtime': 2.5856, 'eval_samples_per_second': 852.415, 'eval_steps_per_second': 106.745, 'epoch': 1.0}
{'loss': 0.2939, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 121.31it/s][A
  9%|▉         | 26/276 [00:00<00:02, 114.43it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 112.58it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 111.36it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 110.64it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 110.26it/s][A
 31%|███       | 86/276 [00:00<00:01, 109.90it/s][A
 35%|███▌      | 97/276 [00:00<00:01, 109.28it/s][A
 39%|███▉      | 108/276 [00:00<00:01, 108.28it/s][A
 43%|████▎     | 119/276 [00:01<00:01, 107.86it/s][A
 47%|████▋     | 130/276 [00:01<00:01, 107.68it/s][A
 51%|█████     | 141/276 [00:01<00:01, 107.62it/s][A
 55%|█████▌    | 152/276 [00:01<00:01, 107.62it/s][A
 59%|█████▉    | 163/276 [00:01<00:01, 107.70it/s][A
 63%|██████▎   | 174/276 [00:01<00:00, 107.75it/s][A
 67%|██████▋   | 185/276 [00:01<00:00, 107.84it/s][A
 71%|███████   | 196/276 [00:01<00:00, 107.50it/s][A
 75%|███████▌  | 207/276 [00:01<00:00, 107.17it/s][A
 79%|███████▉  | 218/276 [00:02<00:00, 106.96it/s][A
 83%|████████▎ | 229/276 [00:02<00:00, 106.95it/s][A
 87%|████████▋ | 240/276 [00:02<00:00, 107.04it/s][A
 91%|█████████ | 251/276 [00:02<00:00, 106.95it/s][A
 95%|█████████▍| 262/276 [00:02<00:00, 107.02it/s][A
 99%|█████████▉| 273/276 [00:02<00:00, 107.12it/s][A                                                  
                                                  [A 40%|████      | 552/1380 [00:55<01:14, 11.15it/s]
100%|██████████| 276/276 [00:02<00:00, 107.12it/s][A
                                                  [A 40%|████      | 553/1380 [00:55<06:33,  2.10it/s] 40%|████      | 555/1380 [00:55<04:57,  2.77it/s] 40%|████      | 557/1380 [00:56<03:50,  3.57it/s] 41%|████      | 559/1380 [00:56<03:03,  4.48it/s] 41%|████      | 561/1380 [00:56<02:29,  5.46it/s] 41%|████      | 563/1380 [00:56<02:06,  6.45it/s] 41%|████      | 565/1380 [00:56<01:50,  7.38it/s] 41%|████      | 567/1380 [00:56<01:39,  8.20it/s] 41%|████      | 569/1380 [00:57<01:31,  8.91it/s] 41%|████▏     | 571/1380 [00:57<01:25,  9.48it/s] 42%|████▏     | 573/1380 [00:57<01:21,  9.92it/s] 42%|████▏     | 575/1380 [00:57<01:18, 10.24it/s] 42%|████▏     | 577/1380 [00:57<01:16, 10.49it/s] 42%|████▏     | 579/1380 [00:58<01:15, 10.67it/s] 42%|████▏     | 581/1380 [00:58<01:14, 10.80it/s] 42%|████▏     | 583/1380 [00:58<01:13, 10.89it/s] 42%|████▏     | 585/1380 [00:58<01:12, 10.96it/s] 43%|████▎     | 587/1380 [00:58<01:11, 11.01it/s] 43%|████▎     | 589/1380 [00:58<01:11, 11.04it/s] 43%|████▎     | 591/1380 [00:59<01:11, 11.06it/s] 43%|████▎     | 593/1380 [00:59<01:10, 11.09it/s] 43%|████▎     | 595/1380 [00:59<01:10, 11.10it/s] 43%|████▎     | 597/1380 [00:59<01:10, 11.10it/s] 43%|████▎     | 599/1380 [00:59<01:10, 11.11it/s] 44%|████▎     | 601/1380 [01:00<01:10, 11.13it/s] 44%|████▎     | 603/1380 [01:00<01:09, 11.11it/s] 44%|████▍     | 605/1380 [01:00<01:09, 11.11it/s] 44%|████▍     | 607/1380 [01:00<01:09, 11.12it/s] 44%|████▍     | 609/1380 [01:00<01:09, 11.11it/s] 44%|████▍     | 611/1380 [01:00<01:09, 11.11it/s] 44%|████▍     | 613/1380 [01:01<01:08, 11.12it/s] 45%|████▍     | 615/1380 [01:01<01:08, 11.11it/s] 45%|████▍     | 617/1380 [01:01<01:08, 11.12it/s] 45%|████▍     | 619/1380 [01:01<01:08, 11.11it/s] 45%|████▌     | 621/1380 [01:01<01:08, 11.12it/s] 45%|████▌     | 623/1380 [01:01<01:08, 11.12it/s] 45%|████▌     | 625/1380 [01:02<01:07, 11.12it/s] 45%|████▌     | 627/1380 [01:02<01:07, 11.10it/s] 46%|████▌     | 629/1380 [01:02<01:07, 11.12it/s] 46%|████▌     | 631/1380 [01:02<01:07, 11.11it/s] 46%|████▌     | 633/1380 [01:02<01:07, 11.11it/s] 46%|████▌     | 635/1380 [01:03<01:07, 11.11it/s] 46%|████▌     | 637/1380 [01:03<01:06, 11.12it/s] 46%|████▋     | 639/1380 [01:03<01:06, 11.11it/s] 46%|████▋     | 641/1380 [01:03<01:07, 11.02it/s] 47%|████▋     | 643/1380 [01:03<01:06, 11.05it/s] 47%|████▋     | 645/1380 [01:03<01:06, 11.06it/s] 47%|████▋     | 647/1380 [01:04<01:06, 11.07it/s] 47%|████▋     | 649/1380 [01:04<01:05, 11.08it/s] 47%|████▋     | 651/1380 [01:04<01:05, 11.09it/s] 47%|████▋     | 653/1380 [01:04<01:05, 11.09it/s] 47%|████▋     | 655/1380 [01:04<01:05, 11.12it/s] 48%|████▊     | 657/1380 [01:05<01:05, 11.11it/s] 48%|████▊     | 659/1380 [01:05<01:04, 11.13it/s] 48%|████▊     | 661/1380 [01:05<01:04, 11.12it/s] 48%|████▊     | 663/1380 [01:05<01:04, 11.11it/s] 48%|████▊     | 665/1380 [01:05<01:04, 11.11it/s] 48%|████▊     | 667/1380 [01:05<01:04, 11.11it/s] 48%|████▊     | 669/1380 [01:06<01:03, 11.12it/s] 49%|████▊     | 671/1380 [01:06<01:03, 11.11it/s] 49%|████▉     | 673/1380 [01:06<01:03, 11.10it/s] 49%|████▉     | 675/1380 [01:06<01:03, 11.12it/s] 49%|████▉     | 677/1380 [01:06<01:03, 11.12it/s] 49%|████▉     | 679/1380 [01:07<01:03, 11.01it/s] 49%|████▉     | 681/1380 [01:07<01:03, 11.05it/s] 49%|████▉     | 683/1380 [01:07<01:02, 11.08it/s] 50%|████▉     | 685/1380 [01:07<01:02, 11.09it/s] 50%|████▉     | 687/1380 [01:07<01:02, 11.09it/s] 50%|████▉     | 689/1380 [01:07<01:02, 11.10it/s] 50%|█████     | 691/1380 [01:08<01:02, 11.11it/s] 50%|█████     | 693/1380 [01:08<01:01, 11.11it/s] 50%|█████     | 695/1380 [01:08<01:01, 11.09it/s] 51%|█████     | 697/1380 [01:08<01:01, 11.11it/s] 51%|█████     | 699/1380 [01:08<01:01, 11.12it/s] 51%|█████     | 701/1380 [01:09<01:01, 11.13it/s] 51%|█████     | 703/1380 [01:09<01:00, 11.11it/s] 51%|█████     | 705/1380 [01:09<01:00, 11.10it/s] 51%|█████     | 707/1380 [01:09<01:00, 11.10it/s] 51%|█████▏    | 709/1380 [01:09<01:00, 11.11it/s] 52%|█████▏    | 711/1380 [01:09<01:00, 11.12it/s] 52%|█████▏    | 713/1380 [01:10<00:59, 11.13it/s] 52%|█████▏    | 715/1380 [01:10<00:59, 11.13it/s] 52%|█████▏    | 717/1380 [01:10<00:59, 11.12it/s] 52%|█████▏    | 719/1380 [01:10<00:59, 11.13it/s] 52%|█████▏    | 721/1380 [01:10<00:59, 11.12it/s] 52%|█████▏    | 723/1380 [01:10<00:59, 11.11it/s] 53%|█████▎    | 725/1380 [01:11<00:58, 11.11it/s] 53%|█████▎    | 727/1380 [01:11<00:58, 11.11it/s] 53%|█████▎    | 729/1380 [01:11<00:58, 11.11it/s] 53%|█████▎    | 731/1380 [01:11<00:58, 11.11it/s] 53%|█████▎    | 733/1380 [01:11<00:58, 11.11it/s] 53%|█████▎    | 735/1380 [01:12<00:58, 11.11it/s] 53%|█████▎    | 737/1380 [01:12<00:57, 11.12it/s] 54%|█████▎    | 739/1380 [01:12<00:57, 11.11it/s] 54%|█████▎    | 741/1380 [01:12<00:57, 11.09it/s] 54%|█████▍    | 743/1380 [01:12<00:57, 11.08it/s] 54%|█████▍    | 745/1380 [01:12<00:57, 11.08it/s] 54%|█████▍    | 747/1380 [01:13<00:57, 11.07it/s] 54%|█████▍    | 749/1380 [01:13<00:56, 11.08it/s] 54%|█████▍    | 751/1380 [01:13<00:56, 11.08it/s] 55%|█████▍    | 753/1380 [01:13<00:56, 11.09it/s] 55%|█████▍    | 755/1380 [01:13<00:56, 11.08it/s] 55%|█████▍    | 757/1380 [01:14<00:56, 11.09it/s] 55%|█████▌    | 759/1380 [01:14<00:56, 11.09it/s] 55%|█████▌    | 761/1380 [01:14<00:55, 11.10it/s] 55%|█████▌    | 763/1380 [01:14<00:55, 11.09it/s] 55%|█████▌    | 765/1380 [01:14<00:55, 11.10it/s] 56%|█████▌    | 767/1380 [01:14<00:55, 11.10it/s] 56%|█████▌    | 769/1380 [01:15<00:54, 11.11it/s] 56%|█████▌    | 771/1380 [01:15<00:54, 11.10it/s] 56%|█████▌    | 773/1380 [01:15<00:54, 11.11it/s] 56%|█████▌    | 775/1380 [01:15<00:54, 11.11it/s] 56%|█████▋    | 777/1380 [01:15<00:54, 11.11it/s] 56%|█████▋    | 779/1380 [01:16<00:54, 11.10it/s] 57%|█████▋    | 781/1380 [01:16<00:53, 11.10it/s] 57%|█████▋    | 783/1380 [01:16<00:53, 11.12it/s] 57%|█████▋    | 785/1380 [01:16<00:53, 11.11it/s] 57%|█████▋    | 787/1380 [01:16<00:53, 11.11it/s] 57%|█████▋    | 789/1380 [01:16<00:53, 11.11it/s] 57%|█████▋    | 791/1380 [01:17<00:52, 11.12it/s] 57%|█████▋    | 793/1380 [01:17<00:53, 11.04it/s] 58%|█████▊    | 795/1380 [01:17<00:52, 11.06it/s] 58%|█████▊    | 797/1380 [01:17<00:52, 11.08it/s] 58%|█████▊    | 799/1380 [01:17<00:52, 11.09it/s] 58%|█████▊    | 801/1380 [01:18<00:52, 11.08it/s] 58%|█████▊    | 803/1380 [01:18<00:52, 11.09it/s] 58%|█████▊    | 805/1380 [01:18<00:51, 11.10it/s] 58%|█████▊    | 807/1380 [01:18<00:51, 11.10it/s] 59%|█████▊    | 809/1380 [01:18<00:51, 11.08it/s] 59%|█████▉    | 811/1380 [01:18<00:51, 11.09it/s] 59%|█████▉    | 813/1380 [01:19<00:51, 11.09it/s] 59%|█████▉    | 815/1380 [01:19<00:50, 11.09it/s] 59%|█████▉    | 817/1380 [01:19<00:50, 11.08it/s] 59%|█████▉    | 819/1380 [01:19<00:50, 11.08it/s] 59%|█████▉    | 821/1380 [01:19<00:50, 11.09it/s] 60%|█████▉    | 823/1380 [01:19<00:50, 11.10it/s] 60%|█████▉    | 825/1380 [01:20<00:50, 11.08it/s] 60%|█████▉    | 827/1380 [01:20<00:49, 11.13it/s]                                                   60%|██████    | 828/1380 [01:20<00:49, 11.13it/s][INFO|trainer.py:755] 2023-11-15 21:07:38,692 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:07:38,693 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:07:38,693 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:07:38,694 >>   Batch size = 8
{'eval_loss': 0.36263078451156616, 'eval_accuracy': 0.8706896551724138, 'eval_micro_f1': 0.8706896551724138, 'eval_macro_f1': 0.8527666771559822, 'eval_runtime': 2.6008, 'eval_samples_per_second': 847.437, 'eval_steps_per_second': 106.122, 'epoch': 2.0}
{'loss': 0.1952, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 120.96it/s][A
  9%|▉         | 26/276 [00:00<00:02, 114.29it/s][A
 14%|█▍        | 38/276 [00:00<00:02, 112.00it/s][A
 18%|█▊        | 50/276 [00:00<00:02, 110.67it/s][A
 22%|██▏       | 62/276 [00:00<00:01, 110.02it/s][A
 27%|██▋       | 74/276 [00:00<00:01, 109.09it/s][A
 31%|███       | 85/276 [00:00<00:01, 108.53it/s][A
 35%|███▍      | 96/276 [00:00<00:01, 107.76it/s][A
 39%|███▉      | 107/276 [00:00<00:01, 107.11it/s][A
 43%|████▎     | 118/276 [00:01<00:01, 106.50it/s][A
 47%|████▋     | 129/276 [00:01<00:01, 106.63it/s][A
 51%|█████     | 140/276 [00:01<00:01, 106.77it/s][A
 55%|█████▍    | 151/276 [00:01<00:01, 106.82it/s][A
 59%|█████▊    | 162/276 [00:01<00:01, 106.85it/s][A
 63%|██████▎   | 173/276 [00:01<00:00, 106.86it/s][A
 67%|██████▋   | 184/276 [00:01<00:00, 106.54it/s][A
 71%|███████   | 195/276 [00:01<00:00, 106.18it/s][A
 75%|███████▍  | 206/276 [00:01<00:00, 105.94it/s][A
 79%|███████▊  | 217/276 [00:02<00:00, 105.51it/s][A
 83%|████████▎ | 228/276 [00:02<00:00, 105.34it/s][A
 87%|████████▋ | 239/276 [00:02<00:00, 105.46it/s][A
 91%|█████████ | 250/276 [00:02<00:00, 105.52it/s][A
 95%|█████████▍| 261/276 [00:02<00:00, 105.39it/s][A
 99%|█████████▊| 272/276 [00:02<00:00, 105.59it/s][A                                                  
                                                  [A 60%|██████    | 828/1380 [01:23<00:49, 11.13it/s]
100%|██████████| 276/276 [00:02<00:00, 105.59it/s][A
                                                  [A 60%|██████    | 829/1380 [01:23<04:24,  2.08it/s] 60%|██████    | 831/1380 [01:23<03:19,  2.75it/s] 60%|██████    | 833/1380 [01:23<02:34,  3.54it/s] 61%|██████    | 835/1380 [01:23<02:02,  4.45it/s] 61%|██████    | 837/1380 [01:23<01:40,  5.42it/s] 61%|██████    | 839/1380 [01:24<01:24,  6.41it/s] 61%|██████    | 841/1380 [01:24<01:13,  7.32it/s] 61%|██████    | 843/1380 [01:24<01:05,  8.15it/s] 61%|██████    | 845/1380 [01:24<01:00,  8.86it/s] 61%|██████▏   | 847/1380 [01:24<00:56,  9.42it/s] 62%|██████▏   | 849/1380 [01:24<00:53,  9.86it/s] 62%|██████▏   | 851/1380 [01:25<00:51, 10.19it/s] 62%|██████▏   | 853/1380 [01:25<00:50, 10.43it/s] 62%|██████▏   | 855/1380 [01:25<00:49, 10.60it/s] 62%|██████▏   | 857/1380 [01:25<00:48, 10.73it/s] 62%|██████▏   | 859/1380 [01:25<00:48, 10.84it/s] 62%|██████▏   | 861/1380 [01:26<00:47, 10.93it/s] 63%|██████▎   | 863/1380 [01:26<00:47, 10.98it/s] 63%|██████▎   | 865/1380 [01:26<00:46, 11.02it/s] 63%|██████▎   | 867/1380 [01:26<00:46, 11.04it/s] 63%|██████▎   | 869/1380 [01:26<00:46, 11.06it/s] 63%|██████▎   | 871/1380 [01:26<00:45, 11.07it/s] 63%|██████▎   | 873/1380 [01:27<00:45, 11.07it/s] 63%|██████▎   | 875/1380 [01:27<00:45, 11.07it/s] 64%|██████▎   | 877/1380 [01:27<00:45, 11.08it/s] 64%|██████▎   | 879/1380 [01:27<00:45, 11.07it/s] 64%|██████▍   | 881/1380 [01:27<00:45, 11.08it/s] 64%|██████▍   | 883/1380 [01:28<00:44, 11.08it/s] 64%|██████▍   | 885/1380 [01:28<00:44, 11.07it/s] 64%|██████▍   | 887/1380 [01:28<00:44, 11.06it/s] 64%|██████▍   | 889/1380 [01:28<00:44, 11.05it/s] 65%|██████▍   | 891/1380 [01:28<00:44, 11.05it/s] 65%|██████▍   | 893/1380 [01:28<00:44, 11.05it/s] 65%|██████▍   | 895/1380 [01:29<00:43, 11.06it/s] 65%|██████▌   | 897/1380 [01:29<00:43, 11.07it/s] 65%|██████▌   | 899/1380 [01:29<00:43, 11.08it/s] 65%|██████▌   | 901/1380 [01:29<00:43, 11.07it/s] 65%|██████▌   | 903/1380 [01:29<00:43, 11.08it/s] 66%|██████▌   | 905/1380 [01:30<00:42, 11.07it/s] 66%|██████▌   | 907/1380 [01:30<00:42, 11.08it/s] 66%|██████▌   | 909/1380 [01:30<00:42, 11.07it/s] 66%|██████▌   | 911/1380 [01:30<00:42, 11.07it/s] 66%|██████▌   | 913/1380 [01:30<00:42, 11.06it/s] 66%|██████▋   | 915/1380 [01:30<00:42, 11.06it/s] 66%|██████▋   | 917/1380 [01:31<00:41, 11.05it/s] 67%|██████▋   | 919/1380 [01:31<00:41, 11.06it/s] 67%|██████▋   | 921/1380 [01:31<00:41, 11.06it/s] 67%|██████▋   | 923/1380 [01:31<00:41, 11.07it/s] 67%|██████▋   | 925/1380 [01:31<00:41, 11.08it/s] 67%|██████▋   | 927/1380 [01:31<00:40, 11.09it/s] 67%|██████▋   | 929/1380 [01:32<00:40, 11.09it/s] 67%|██████▋   | 931/1380 [01:32<00:40, 11.10it/s] 68%|██████▊   | 933/1380 [01:32<00:40, 11.10it/s] 68%|██████▊   | 935/1380 [01:32<00:40, 11.09it/s] 68%|██████▊   | 937/1380 [01:32<00:39, 11.10it/s] 68%|██████▊   | 939/1380 [01:33<00:39, 11.07it/s] 68%|██████▊   | 941/1380 [01:33<00:39, 11.08it/s] 68%|██████▊   | 943/1380 [01:33<00:39, 11.07it/s] 68%|██████▊   | 945/1380 [01:33<00:39, 11.06it/s] 69%|██████▊   | 947/1380 [01:33<00:39, 11.01it/s] 69%|██████▉   | 949/1380 [01:33<00:39, 11.04it/s] 69%|██████▉   | 951/1380 [01:34<00:38, 11.05it/s] 69%|██████▉   | 953/1380 [01:34<00:38, 11.07it/s] 69%|██████▉   | 955/1380 [01:34<00:38, 11.06it/s] 69%|██████▉   | 957/1380 [01:34<00:38, 11.06it/s] 69%|██████▉   | 959/1380 [01:34<00:38, 11.06it/s] 70%|██████▉   | 961/1380 [01:35<00:37, 11.06it/s] 70%|██████▉   | 963/1380 [01:35<00:37, 11.05it/s] 70%|██████▉   | 965/1380 [01:35<00:37, 11.06it/s] 70%|███████   | 967/1380 [01:35<00:37, 11.05it/s] 70%|███████   | 969/1380 [01:35<00:37, 11.05it/s] 70%|███████   | 971/1380 [01:35<00:36, 11.07it/s] 71%|███████   | 973/1380 [01:36<00:36, 11.06it/s] 71%|███████   | 975/1380 [01:36<00:36, 11.09it/s] 71%|███████   | 977/1380 [01:36<00:36, 11.07it/s] 71%|███████   | 979/1380 [01:36<00:36, 11.07it/s] 71%|███████   | 981/1380 [01:36<00:36, 11.07it/s] 71%|███████   | 983/1380 [01:37<00:35, 11.07it/s] 71%|███████▏  | 985/1380 [01:37<00:35, 11.05it/s] 72%|███████▏  | 987/1380 [01:37<00:35, 11.05it/s] 72%|███████▏  | 989/1380 [01:37<00:35, 11.04it/s] 72%|███████▏  | 991/1380 [01:37<00:35, 11.03it/s] 72%|███████▏  | 993/1380 [01:37<00:35, 11.05it/s] 72%|███████▏  | 995/1380 [01:38<00:34, 11.06it/s] 72%|███████▏  | 997/1380 [01:38<00:34, 11.08it/s] 72%|███████▏  | 999/1380 [01:38<00:34, 11.07it/s] 73%|███████▎  | 1001/1380 [01:38<00:34, 11.08it/s] 73%|███████▎  | 1003/1380 [01:38<00:34, 11.08it/s] 73%|███████▎  | 1005/1380 [01:39<00:33, 11.08it/s] 73%|███████▎  | 1007/1380 [01:39<00:33, 11.06it/s] 73%|███████▎  | 1009/1380 [01:39<00:33, 11.06it/s] 73%|███████▎  | 1011/1380 [01:39<00:33, 11.05it/s] 73%|███████▎  | 1013/1380 [01:39<00:33, 11.05it/s] 74%|███████▎  | 1015/1380 [01:39<00:33, 11.03it/s] 74%|███████▎  | 1017/1380 [01:40<00:32, 11.04it/s] 74%|███████▍  | 1019/1380 [01:40<00:32, 11.05it/s] 74%|███████▍  | 1021/1380 [01:40<00:32, 11.07it/s] 74%|███████▍  | 1023/1380 [01:40<00:32, 11.04it/s] 74%|███████▍  | 1025/1380 [01:40<00:32, 11.03it/s] 74%|███████▍  | 1027/1380 [01:41<00:31, 11.04it/s] 75%|███████▍  | 1029/1380 [01:41<00:31, 11.04it/s] 75%|███████▍  | 1031/1380 [01:41<00:31, 11.03it/s] 75%|███████▍  | 1033/1380 [01:41<00:31, 11.04it/s] 75%|███████▌  | 1035/1380 [01:41<00:31, 11.04it/s] 75%|███████▌  | 1037/1380 [01:41<00:31, 11.02it/s] 75%|███████▌  | 1039/1380 [01:42<00:31, 10.91it/s] 75%|███████▌  | 1041/1380 [01:42<00:30, 10.94it/s] 76%|███████▌  | 1043/1380 [01:42<00:30, 10.96it/s] 76%|███████▌  | 1045/1380 [01:42<00:30, 10.97it/s] 76%|███████▌  | 1047/1380 [01:42<00:30, 10.98it/s] 76%|███████▌  | 1049/1380 [01:43<00:30, 11.00it/s] 76%|███████▌  | 1051/1380 [01:43<00:29, 11.02it/s] 76%|███████▋  | 1053/1380 [01:43<00:29, 11.01it/s] 76%|███████▋  | 1055/1380 [01:43<00:29, 11.02it/s] 77%|███████▋  | 1057/1380 [01:43<00:29, 11.01it/s] 77%|███████▋  | 1059/1380 [01:43<00:29, 11.02it/s] 77%|███████▋  | 1061/1380 [01:44<00:28, 11.01it/s] 77%|███████▋  | 1063/1380 [01:44<00:28, 11.03it/s] 77%|███████▋  | 1065/1380 [01:44<00:28, 11.04it/s] 77%|███████▋  | 1067/1380 [01:44<00:28, 11.05it/s] 77%|███████▋  | 1069/1380 [01:44<00:28, 11.03it/s] 78%|███████▊  | 1071/1380 [01:45<00:28, 10.93it/s] 78%|███████▊  | 1073/1380 [01:45<00:27, 10.97it/s] 78%|███████▊  | 1075/1380 [01:45<00:27, 10.98it/s] 78%|███████▊  | 1077/1380 [01:45<00:27, 11.00it/s] 78%|███████▊  | 1079/1380 [01:45<00:27, 11.01it/s] 78%|███████▊  | 1081/1380 [01:45<00:27, 11.01it/s] 78%|███████▊  | 1083/1380 [01:46<00:27, 10.99it/s] 79%|███████▊  | 1085/1380 [01:46<00:26, 11.01it/s] 79%|███████▉  | 1087/1380 [01:46<00:26, 11.03it/s] 79%|███████▉  | 1089/1380 [01:46<00:26, 11.03it/s] 79%|███████▉  | 1091/1380 [01:46<00:26, 10.99it/s] 79%|███████▉  | 1093/1380 [01:47<00:26, 11.00it/s] 79%|███████▉  | 1095/1380 [01:47<00:25, 11.02it/s] 79%|███████▉  | 1097/1380 [01:47<00:25, 11.02it/s] 80%|███████▉  | 1099/1380 [01:47<00:25, 11.03it/s] 80%|███████▉  | 1101/1380 [01:47<00:25, 11.03it/s] 80%|███████▉  | 1103/1380 [01:47<00:25, 11.05it/s]                                                    80%|████████  | 1104/1380 [01:48<00:24, 11.05it/s][INFO|trainer.py:755] 2023-11-15 21:08:06,279 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:08:06,281 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:08:06,281 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:08:06,281 >>   Batch size = 8
{'eval_loss': 0.4335089325904846, 'eval_accuracy': 0.8598003629764065, 'eval_micro_f1': 0.8598003629764064, 'eval_macro_f1': 0.8484506093788479, 'eval_runtime': 2.6257, 'eval_samples_per_second': 839.384, 'eval_steps_per_second': 105.113, 'epoch': 3.0}
{'loss': 0.1285, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  4%|▍         | 12/276 [00:00<00:02, 119.31it/s][A
  9%|▊         | 24/276 [00:00<00:02, 113.15it/s][A
 13%|█▎        | 36/276 [00:00<00:02, 111.13it/s][A
 17%|█▋        | 48/276 [00:00<00:02, 110.16it/s][A
 22%|██▏       | 60/276 [00:00<00:01, 109.45it/s][A
 26%|██▌       | 71/276 [00:00<00:01, 108.90it/s][A
 30%|██▉       | 82/276 [00:00<00:01, 108.19it/s][A
 34%|███▎      | 93/276 [00:00<00:01, 107.36it/s][A
 38%|███▊      | 104/276 [00:00<00:01, 106.18it/s][A
 42%|████▏     | 115/276 [00:01<00:01, 105.79it/s][A
 46%|████▌     | 126/276 [00:01<00:01, 105.90it/s][A
 50%|████▉     | 137/276 [00:01<00:01, 106.15it/s][A
 54%|█████▎    | 148/276 [00:01<00:01, 106.30it/s][A
 58%|█████▊    | 159/276 [00:01<00:01, 106.19it/s][A
 62%|██████▏   | 170/276 [00:01<00:00, 106.17it/s][A
 66%|██████▌   | 181/276 [00:01<00:00, 106.08it/s][A
 70%|██████▉   | 192/276 [00:01<00:00, 105.61it/s][A
 74%|███████▎  | 203/276 [00:01<00:00, 105.06it/s][A
 78%|███████▊  | 214/276 [00:02<00:00, 104.54it/s][A
 82%|████████▏ | 225/276 [00:02<00:00, 104.24it/s][A
 86%|████████▌ | 236/276 [00:02<00:00, 104.37it/s][A
 89%|████████▉ | 247/276 [00:02<00:00, 104.59it/s][A
 93%|█████████▎| 258/276 [00:02<00:00, 104.93it/s][A
 97%|█████████▋| 269/276 [00:02<00:00, 105.04it/s][A                                                   
                                                  [A 80%|████████  | 1104/1380 [01:50<00:24, 11.05it/s]
100%|██████████| 276/276 [00:02<00:00, 105.04it/s][A
                                                  [A 80%|████████  | 1105/1380 [01:50<02:13,  2.07it/s] 80%|████████  | 1107/1380 [01:50<01:40,  2.73it/s] 80%|████████  | 1109/1380 [01:51<01:17,  3.52it/s] 81%|████████  | 1111/1380 [01:51<01:00,  4.42it/s] 81%|████████  | 1113/1380 [01:51<00:49,  5.39it/s] 81%|████████  | 1115/1380 [01:51<00:41,  6.37it/s] 81%|████████  | 1117/1380 [01:51<00:36,  7.30it/s] 81%|████████  | 1119/1380 [01:52<00:32,  8.13it/s] 81%|████████  | 1121/1380 [01:52<00:29,  8.83it/s] 81%|████████▏ | 1123/1380 [01:52<00:27,  9.37it/s] 82%|████████▏ | 1125/1380 [01:52<00:25,  9.81it/s] 82%|████████▏ | 1127/1380 [01:52<00:24, 10.15it/s] 82%|████████▏ | 1129/1380 [01:52<00:24, 10.41it/s] 82%|████████▏ | 1131/1380 [01:53<00:23, 10.59it/s] 82%|████████▏ | 1133/1380 [01:53<00:23, 10.74it/s] 82%|████████▏ | 1135/1380 [01:53<00:22, 10.82it/s] 82%|████████▏ | 1137/1380 [01:53<00:22, 10.89it/s] 83%|████████▎ | 1139/1380 [01:53<00:22, 10.92it/s] 83%|████████▎ | 1141/1380 [01:54<00:21, 10.95it/s] 83%|████████▎ | 1143/1380 [01:54<00:21, 10.98it/s] 83%|████████▎ | 1145/1380 [01:54<00:21, 10.99it/s] 83%|████████▎ | 1147/1380 [01:54<00:21, 10.99it/s] 83%|████████▎ | 1149/1380 [01:54<00:20, 11.01it/s] 83%|████████▎ | 1151/1380 [01:54<00:20, 11.01it/s] 84%|████████▎ | 1153/1380 [01:55<00:20, 11.01it/s] 84%|████████▎ | 1155/1380 [01:55<00:20, 10.99it/s] 84%|████████▍ | 1157/1380 [01:55<00:20, 11.01it/s] 84%|████████▍ | 1159/1380 [01:55<00:20, 11.02it/s] 84%|████████▍ | 1161/1380 [01:55<00:19, 11.00it/s] 84%|████████▍ | 1163/1380 [01:56<00:19, 11.01it/s] 84%|████████▍ | 1165/1380 [01:56<00:19, 10.99it/s] 85%|████████▍ | 1167/1380 [01:56<00:19, 11.01it/s] 85%|████████▍ | 1169/1380 [01:56<00:19, 11.02it/s] 85%|████████▍ | 1171/1380 [01:56<00:18, 11.01it/s] 85%|████████▌ | 1173/1380 [01:56<00:18, 11.01it/s] 85%|████████▌ | 1175/1380 [01:57<00:18, 10.99it/s] 85%|████████▌ | 1177/1380 [01:57<00:18, 10.99it/s] 85%|████████▌ | 1179/1380 [01:57<00:18, 11.03it/s] 86%|████████▌ | 1181/1380 [01:57<00:18, 11.03it/s] 86%|████████▌ | 1183/1380 [01:57<00:17, 11.02it/s] 86%|████████▌ | 1185/1380 [01:58<00:17, 11.02it/s] 86%|████████▌ | 1187/1380 [01:58<00:17, 11.01it/s] 86%|████████▌ | 1189/1380 [01:58<00:17, 11.03it/s] 86%|████████▋ | 1191/1380 [01:58<00:17, 10.97it/s] 86%|████████▋ | 1193/1380 [01:58<00:17, 10.98it/s] 87%|████████▋ | 1195/1380 [01:58<00:16, 10.99it/s] 87%|████████▋ | 1197/1380 [01:59<00:16, 11.01it/s] 87%|████████▋ | 1199/1380 [01:59<00:16, 11.00it/s] 87%|████████▋ | 1201/1380 [01:59<00:16, 11.01it/s] 87%|████████▋ | 1203/1380 [01:59<00:16, 11.03it/s] 87%|████████▋ | 1205/1380 [01:59<00:15, 11.02it/s] 87%|████████▋ | 1207/1380 [02:00<00:15, 11.03it/s] 88%|████████▊ | 1209/1380 [02:00<00:15, 11.04it/s] 88%|████████▊ | 1211/1380 [02:00<00:15, 11.04it/s] 88%|████████▊ | 1213/1380 [02:00<00:15, 11.03it/s] 88%|████████▊ | 1215/1380 [02:00<00:14, 11.03it/s] 88%|████████▊ | 1217/1380 [02:00<00:14, 11.03it/s] 88%|████████▊ | 1219/1380 [02:01<00:14, 11.04it/s] 88%|████████▊ | 1221/1380 [02:01<00:14, 11.04it/s] 89%|████████▊ | 1223/1380 [02:01<00:14, 11.04it/s] 89%|████████▉ | 1225/1380 [02:01<00:14, 11.04it/s] 89%|████████▉ | 1227/1380 [02:01<00:13, 11.03it/s] 89%|████████▉ | 1229/1380 [02:02<00:13, 11.03it/s] 89%|████████▉ | 1231/1380 [02:02<00:13, 11.02it/s] 89%|████████▉ | 1233/1380 [02:02<00:13, 11.04it/s] 89%|████████▉ | 1235/1380 [02:02<00:13, 11.03it/s] 90%|████████▉ | 1237/1380 [02:02<00:12, 11.03it/s] 90%|████████▉ | 1239/1380 [02:02<00:12, 11.03it/s] 90%|████████▉ | 1241/1380 [02:03<00:12, 11.04it/s] 90%|█████████ | 1243/1380 [02:03<00:12, 11.01it/s] 90%|█████████ | 1245/1380 [02:03<00:12, 11.02it/s] 90%|█████████ | 1247/1380 [02:03<00:12, 11.03it/s] 91%|█████████ | 1249/1380 [02:03<00:11, 11.05it/s] 91%|█████████ | 1251/1380 [02:04<00:11, 11.02it/s] 91%|█████████ | 1253/1380 [02:04<00:11, 11.01it/s] 91%|█████████ | 1255/1380 [02:04<00:11, 11.01it/s] 91%|█████████ | 1257/1380 [02:04<00:11, 11.01it/s] 91%|█████████ | 1259/1380 [02:04<00:10, 11.01it/s] 91%|█████████▏| 1261/1380 [02:04<00:10, 11.03it/s] 92%|█████████▏| 1263/1380 [02:05<00:10, 11.03it/s] 92%|█████████▏| 1265/1380 [02:05<00:10, 11.01it/s] 92%|█████████▏| 1267/1380 [02:05<00:10, 11.01it/s] 92%|█████████▏| 1269/1380 [02:05<00:10, 11.01it/s] 92%|█████████▏| 1271/1380 [02:05<00:09, 11.03it/s] 92%|█████████▏| 1273/1380 [02:05<00:09, 11.00it/s] 92%|█████████▏| 1275/1380 [02:06<00:09, 11.01it/s] 93%|█████████▎| 1277/1380 [02:06<00:09, 10.99it/s] 93%|█████████▎| 1279/1380 [02:06<00:09, 10.99it/s] 93%|█████████▎| 1281/1380 [02:06<00:09, 10.99it/s] 93%|█████████▎| 1283/1380 [02:06<00:08, 11.01it/s] 93%|█████████▎| 1285/1380 [02:07<00:08, 11.00it/s] 93%|█████████▎| 1287/1380 [02:07<00:08, 11.01it/s] 93%|█████████▎| 1289/1380 [02:07<00:08, 11.02it/s] 94%|█████████▎| 1291/1380 [02:07<00:08, 11.02it/s] 94%|█████████▎| 1293/1380 [02:07<00:07, 11.02it/s] 94%|█████████▍| 1295/1380 [02:07<00:07, 11.02it/s] 94%|█████████▍| 1297/1380 [02:08<00:07, 11.01it/s] 94%|█████████▍| 1299/1380 [02:08<00:07, 11.03it/s] 94%|█████████▍| 1301/1380 [02:08<00:07, 11.03it/s] 94%|█████████▍| 1303/1380 [02:08<00:06, 11.02it/s] 95%|█████████▍| 1305/1380 [02:08<00:06, 11.01it/s] 95%|█████████▍| 1307/1380 [02:09<00:06, 11.02it/s] 95%|█████████▍| 1309/1380 [02:09<00:06, 10.93it/s] 95%|█████████▌| 1311/1380 [02:09<00:06, 10.98it/s] 95%|█████████▌| 1313/1380 [02:09<00:06, 11.00it/s] 95%|█████████▌| 1315/1380 [02:09<00:05, 11.02it/s] 95%|█████████▌| 1317/1380 [02:09<00:05, 11.02it/s] 96%|█████████▌| 1319/1380 [02:10<00:05, 11.03it/s] 96%|█████████▌| 1321/1380 [02:10<00:05, 11.02it/s] 96%|█████████▌| 1323/1380 [02:10<00:05, 11.03it/s] 96%|█████████▌| 1325/1380 [02:10<00:04, 11.02it/s] 96%|█████████▌| 1327/1380 [02:10<00:04, 11.02it/s] 96%|█████████▋| 1329/1380 [02:11<00:04, 11.00it/s] 96%|█████████▋| 1331/1380 [02:11<00:04, 11.01it/s] 97%|█████████▋| 1333/1380 [02:11<00:04, 11.01it/s] 97%|█████████▋| 1335/1380 [02:11<00:04, 11.02it/s] 97%|█████████▋| 1337/1380 [02:11<00:03, 11.03it/s] 97%|█████████▋| 1339/1380 [02:11<00:03, 11.01it/s] 97%|█████████▋| 1341/1380 [02:12<00:03, 11.02it/s] 97%|█████████▋| 1343/1380 [02:12<00:03, 11.02it/s] 97%|█████████▋| 1345/1380 [02:12<00:03, 11.03it/s] 98%|█████████▊| 1347/1380 [02:12<00:02, 11.02it/s] 98%|█████████▊| 1349/1380 [02:12<00:02, 11.02it/s] 98%|█████████▊| 1351/1380 [02:13<00:02, 11.02it/s] 98%|█████████▊| 1353/1380 [02:13<00:02, 11.02it/s] 98%|█████████▊| 1355/1380 [02:13<00:02, 11.01it/s] 98%|█████████▊| 1357/1380 [02:13<00:02, 11.03it/s] 98%|█████████▊| 1359/1380 [02:13<00:01, 11.03it/s] 99%|█████████▊| 1361/1380 [02:13<00:01, 10.94it/s] 99%|█████████▉| 1363/1380 [02:14<00:01, 10.96it/s] 99%|█████████▉| 1365/1380 [02:14<00:01, 10.98it/s] 99%|█████████▉| 1367/1380 [02:14<00:01, 11.00it/s] 99%|█████████▉| 1369/1380 [02:14<00:01, 11.00it/s] 99%|█████████▉| 1371/1380 [02:14<00:00, 10.99it/s] 99%|█████████▉| 1373/1380 [02:15<00:00, 10.99it/s]100%|█████████▉| 1375/1380 [02:15<00:00, 10.98it/s]100%|█████████▉| 1377/1380 [02:15<00:00, 10.99it/s]100%|█████████▉| 1379/1380 [02:15<00:00, 11.02it/s]                                                   100%|██████████| 1380/1380 [02:15<00:00, 11.02it/s][INFO|trainer.py:755] 2023-11-15 21:08:33,961 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:08:33,962 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:08:33,963 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:08:33,963 >>   Batch size = 8
{'eval_loss': 0.4737524390220642, 'eval_accuracy': 0.8734119782214156, 'eval_micro_f1': 0.8734119782214156, 'eval_macro_f1': 0.8571383241388708, 'eval_runtime': 2.6465, 'eval_samples_per_second': 832.794, 'eval_steps_per_second': 104.288, 'epoch': 4.0}
{'loss': 0.0863, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  5%|▍         | 13/276 [00:00<00:02, 119.94it/s][A
  9%|▉         | 25/276 [00:00<00:02, 113.92it/s][A
 13%|█▎        | 37/276 [00:00<00:02, 111.75it/s][A
 18%|█▊        | 49/276 [00:00<00:02, 110.60it/s][A
 22%|██▏       | 61/276 [00:00<00:01, 109.88it/s][A
 26%|██▌       | 72/276 [00:00<00:01, 109.16it/s][A
 30%|███       | 83/276 [00:00<00:01, 108.30it/s][A
 34%|███▍      | 94/276 [00:00<00:01, 107.70it/s][A
 38%|███▊      | 105/276 [00:00<00:01, 106.52it/s][A
 42%|████▏     | 116/276 [00:01<00:01, 105.89it/s][A
 46%|████▌     | 127/276 [00:01<00:01, 105.88it/s][A
 50%|█████     | 138/276 [00:01<00:01, 105.95it/s][A
 54%|█████▍    | 149/276 [00:01<00:01, 106.03it/s][A
 58%|█████▊    | 160/276 [00:01<00:01, 106.11it/s][A
 62%|██████▏   | 171/276 [00:01<00:00, 105.87it/s][A
 66%|██████▌   | 182/276 [00:01<00:00, 105.67it/s][A
 70%|██████▉   | 193/276 [00:01<00:00, 105.41it/s][A
 74%|███████▍  | 204/276 [00:01<00:00, 104.96it/s][A
 78%|███████▊  | 215/276 [00:02<00:00, 104.32it/s][A
 82%|████████▏ | 226/276 [00:02<00:00, 104.15it/s][A
 86%|████████▌ | 237/276 [00:02<00:00, 104.33it/s][A
 90%|████████▉ | 248/276 [00:02<00:00, 104.38it/s][A
 94%|█████████▍| 259/276 [00:02<00:00, 104.64it/s][A
 98%|█████████▊| 270/276 [00:02<00:00, 104.62it/s][A                                                   
                                                  [A100%|██████████| 1380/1380 [02:18<00:00, 11.02it/s]
100%|██████████| 276/276 [00:02<00:00, 104.62it/s][A
                                                  [A[INFO|trainer.py:1963] 2023-11-15 21:08:36,611 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:18<00:00, 11.02it/s]100%|██████████| 1380/1380 [02:18<00:00,  9.98it/s]
[INFO|trainer.py:2855] 2023-11-15 21:08:36,614 >> Saving model checkpoint to ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3
[INFO|configuration_utils.py:460] 2023-11-15 21:08:36,617 >> Configuration saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:08:37,619 >> Model weights saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:08:37,622 >> tokenizer config file saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:08:37,624 >> Special tokens file saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed3/special_tokens_map.json
{'eval_loss': 0.532170295715332, 'eval_accuracy': 0.8634301270417423, 'eval_micro_f1': 0.8634301270417423, 'eval_macro_f1': 0.846529373236005, 'eval_runtime': 2.6449, 'eval_samples_per_second': 833.313, 'eval_steps_per_second': 104.353, 'epoch': 5.0}
{'train_runtime': 138.3442, 'train_samples_per_second': 318.626, 'train_steps_per_second': 9.975, 'train_loss': 0.22992114467897276, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2299
  train_runtime            = 0:02:18.34
  train_samples            =       8816
  train_samples_per_second =    318.626
  train_steps_per_second   =      9.975
11/15/2023 21:08:37 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:08:37,667 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:08:37,669 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:08:37,669 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:08:37,669 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  4%|▍         | 12/276 [00:00<00:02, 119.75it/s]  9%|▊         | 24/276 [00:00<00:02, 111.73it/s] 13%|█▎        | 36/276 [00:00<00:02, 109.05it/s] 17%|█▋        | 47/276 [00:00<00:02, 107.67it/s] 21%|██        | 58/276 [00:00<00:02, 107.08it/s] 25%|██▌       | 69/276 [00:00<00:01, 106.53it/s] 29%|██▉       | 80/276 [00:00<00:01, 106.25it/s] 33%|███▎      | 91/276 [00:00<00:01, 106.05it/s] 37%|███▋      | 102/276 [00:00<00:01, 105.13it/s] 41%|████      | 113/276 [00:01<00:01, 104.85it/s] 45%|████▍     | 124/276 [00:01<00:01, 105.10it/s] 49%|████▉     | 135/276 [00:01<00:01, 105.26it/s] 53%|█████▎    | 146/276 [00:01<00:01, 105.19it/s] 57%|█████▋    | 157/276 [00:01<00:01, 105.31it/s] 61%|██████    | 168/276 [00:01<00:01, 105.16it/s] 65%|██████▍   | 179/276 [00:01<00:00, 105.18it/s] 69%|██████▉   | 190/276 [00:01<00:00, 105.01it/s] 73%|███████▎  | 201/276 [00:01<00:00, 104.75it/s] 77%|███████▋  | 212/276 [00:02<00:00, 104.35it/s] 81%|████████  | 223/276 [00:02<00:00, 104.18it/s] 85%|████████▍ | 234/276 [00:02<00:00, 104.33it/s] 89%|████████▉ | 245/276 [00:02<00:00, 104.53it/s] 93%|█████████▎| 256/276 [00:02<00:00, 104.67it/s] 97%|█████████▋| 267/276 [00:02<00:00, 104.86it/s]100%|██████████| 276/276 [00:02<00:00, 103.98it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8634
  eval_loss               =     0.5322
  eval_macro_f1           =     0.8465
  eval_micro_f1           =     0.8634
  eval_runtime            = 0:00:02.66
  eval_samples            =       2204
  eval_samples_per_second =    826.607
  eval_steps_per_second   =    103.513
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy █▆▁▇▃▃
wandb:                      eval/loss ▁▂▄▆██
wandb:                  eval/macro_f1 █▅▂█▁▁
wandb:                  eval/micro_f1 █▆▁▇▃▃
wandb:                   eval/runtime ▁▂▄▆▆█
wandb:        eval/samples_per_second █▇▄▃▃▁
wandb:          eval/steps_per_second █▇▄▃▃▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.86343
wandb:                      eval/loss 0.53217
wandb:                  eval/macro_f1 0.84653
wandb:                  eval/micro_f1 0.86343
wandb:                   eval/runtime 2.6663
wandb:        eval/samples_per_second 826.607
wandb:          eval/steps_per_second 103.513
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0863
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.22992
wandb:            train/train_runtime 138.3442
wandb: train/train_samples_per_second 318.626
wandb:   train/train_steps_per_second 9.975
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_210500-naxjfjo6
wandb: Find logs at: ./wandb/offline-run-20231115_210500-naxjfjo6/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_roberta-base_adapter__seed3/runs/Nov15_21-08-50_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_roberta-base_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_roberta-base_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:08:50 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:08:50 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_roberta-base_adapter__seed3/runs/Nov15_21-08-49_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_roberta-base_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_roberta-base_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 21:09:05,877 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:09:05,887 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 21:09:15,902 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 21:09:25,920 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:09:25,921 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:09:45,953 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:09:45,953 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:09:45,953 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:09:45,953 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:09:45,954 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:09:45,954 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 21:09:45,955 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:09:45,956 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:10:06,120 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 21:10:06,890 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:10:06,890 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  29%|██▉       | 2000/6840 [00:00<00:00, 16660.79 examples/s]Running tokenizer on dataset:  58%|█████▊    | 4000/6840 [00:00<00:00, 17628.60 examples/s]Running tokenizer on dataset:  88%|████████▊ | 6000/6840 [00:00<00:00, 18065.04 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 17862.89 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 18421.90 examples/s]
11/15/2023 21:10:07 - INFO - __main__ - Sample 2530 of the training set: {'text': 'Invasion of the Data Snatchers (washingtonpost.com) washingtonpost.com - Think your PC is safe? Think again. A new study indicates your home computer is likely bogged down with spyware, viruses and other scourges wrought by hackers and PC pranksters. Ignorance may be bliss for some people, but for computer users, not knowing can be costly and inefficient.', 'label': 2, 'input_ids': [0, 42782, 27720, 9, 5, 5423, 7500, 415, 7873, 36, 605, 40886, 7049, 4, 175, 43, 14784, 1054, 7049, 4, 175, 111, 9387, 110, 4985, 16, 1522, 116, 9387, 456, 4, 83, 92, 892, 8711, 110, 184, 3034, 16, 533, 28423, 4462, 159, 19, 10258, 10680, 6, 21717, 8, 97, 2850, 2126, 5641, 37058, 30, 11344, 8, 4985, 25828, 9230, 4, 18762, 368, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 21:10:07 - INFO - __main__ - Sample 2357 of the training set: {'text': 'Corning begins work on Taiwan LCD facility Encouraged by the demand for LCDs, glass maker Corning on Thursday said it has broken ground for a second manufacturing facility in Taiwan.', 'label': 2, 'input_ids': [0, 15228, 3509, 3772, 173, 15, 6951, 20808, 2122, 14813, 2126, 4628, 30, 5, 1077, 13, 20808, 29, 6, 4049, 4403, 2812, 3509, 15, 296, 26, 24, 34, 3187, 1255, 13, 10, 200, 3021, 2122, 11, 6951, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:10:07 - INFO - __main__ - Sample 108 of the training set: {'text': "In Asia, Powell defends N. Korea policy SEOUL -- Secretary of State Colin L. Powell yesterday sought to fend off complaints from key partners in the effort to end North Korea's nuclear programs that the Bush administration has not been sufficiently creative or willing to compromise in the negotiations.", 'label': 3, 'input_ids': [0, 1121, 1817, 6, 8274, 24951, 234, 4, 1101, 714, 6324, 5061, 574, 480, 1863, 9, 331, 8718, 226, 4, 8274, 2350, 2952, 7, 26885, 160, 4496, 31, 762, 2567, 11, 5, 1351, 7, 253, 369, 1101, 18, 1748, 1767, 14, 5, 3516, 942, 34, 45, 57, 21547, 3904, 50, 2882, 7, 7932, 11, 5, 3377, 4, 2, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:10:07 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:10:08,525 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:10:08,532 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:10:08,532 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 21:10:08,532 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:10:08,533 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:10:08,533 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:10:08,533 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:10:08,534 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 21:10:08,534 >>   Number of trainable parameters = 124,648,708
[INFO|integration_utils.py:716] 2023-11-15 21:10:08,535 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<19:43,  1.11s/it]  0%|          | 3/1070 [00:01<06:16,  2.84it/s]  0%|          | 5/1070 [00:01<03:51,  4.59it/s]  1%|          | 7/1070 [00:01<02:54,  6.11it/s]  1%|          | 9/1070 [00:01<02:24,  7.35it/s]  1%|          | 11/1070 [00:02<02:06,  8.35it/s]  1%|          | 13/1070 [00:02<01:56,  9.10it/s]  1%|▏         | 15/1070 [00:02<01:49,  9.67it/s]  2%|▏         | 17/1070 [00:02<01:44, 10.08it/s]  2%|▏         | 19/1070 [00:02<01:41, 10.36it/s]  2%|▏         | 21/1070 [00:02<01:39, 10.57it/s]  2%|▏         | 23/1070 [00:03<01:37, 10.73it/s]  2%|▏         | 25/1070 [00:03<01:36, 10.85it/s]  3%|▎         | 27/1070 [00:03<01:35, 10.93it/s]  3%|▎         | 29/1070 [00:03<01:34, 10.96it/s]  3%|▎         | 31/1070 [00:03<01:34, 10.99it/s]  3%|▎         | 33/1070 [00:03<01:34, 11.02it/s]  3%|▎         | 35/1070 [00:04<01:33, 11.05it/s]  3%|▎         | 37/1070 [00:04<01:33, 11.05it/s]  4%|▎         | 39/1070 [00:04<01:33, 11.07it/s]  4%|▍         | 41/1070 [00:04<01:32, 11.08it/s]  4%|▍         | 43/1070 [00:04<01:32, 11.08it/s]  4%|▍         | 45/1070 [00:05<01:31, 11.15it/s]  4%|▍         | 47/1070 [00:05<01:31, 11.17it/s]  5%|▍         | 49/1070 [00:05<01:31, 11.18it/s]  5%|▍         | 51/1070 [00:05<01:31, 11.18it/s]  5%|▍         | 53/1070 [00:05<01:30, 11.18it/s]  5%|▌         | 55/1070 [00:05<01:30, 11.19it/s]  5%|▌         | 57/1070 [00:06<01:30, 11.20it/s]  6%|▌         | 59/1070 [00:06<01:30, 11.19it/s]  6%|▌         | 61/1070 [00:06<01:29, 11.21it/s]  6%|▌         | 63/1070 [00:06<01:29, 11.22it/s]  6%|▌         | 65/1070 [00:06<01:29, 11.21it/s]  6%|▋         | 67/1070 [00:07<01:29, 11.19it/s]  6%|▋         | 69/1070 [00:07<01:29, 11.20it/s]  7%|▋         | 71/1070 [00:07<01:29, 11.20it/s]  7%|▋         | 73/1070 [00:07<01:29, 11.19it/s]  7%|▋         | 75/1070 [00:07<01:28, 11.20it/s]  7%|▋         | 77/1070 [00:07<01:28, 11.19it/s]  7%|▋         | 79/1070 [00:08<01:28, 11.20it/s]  8%|▊         | 81/1070 [00:08<01:28, 11.18it/s]  8%|▊         | 83/1070 [00:08<01:28, 11.18it/s]  8%|▊         | 85/1070 [00:08<01:28, 11.18it/s]  8%|▊         | 87/1070 [00:08<01:28, 11.15it/s]  8%|▊         | 89/1070 [00:08<01:27, 11.15it/s]  9%|▊         | 91/1070 [00:09<01:27, 11.16it/s]  9%|▊         | 93/1070 [00:09<01:27, 11.17it/s]  9%|▉         | 95/1070 [00:09<01:27, 11.17it/s]  9%|▉         | 97/1070 [00:09<01:26, 11.19it/s]  9%|▉         | 99/1070 [00:09<01:26, 11.19it/s]  9%|▉         | 101/1070 [00:10<01:26, 11.16it/s] 10%|▉         | 103/1070 [00:10<01:26, 11.16it/s] 10%|▉         | 105/1070 [00:10<01:26, 11.17it/s] 10%|█         | 107/1070 [00:10<01:26, 11.18it/s] 10%|█         | 109/1070 [00:10<01:26, 11.16it/s] 10%|█         | 111/1070 [00:10<01:25, 11.16it/s] 11%|█         | 113/1070 [00:11<01:25, 11.16it/s] 11%|█         | 115/1070 [00:11<01:25, 11.15it/s] 11%|█         | 117/1070 [00:11<01:25, 11.15it/s] 11%|█         | 119/1070 [00:11<01:25, 11.15it/s] 11%|█▏        | 121/1070 [00:11<01:24, 11.17it/s] 11%|█▏        | 123/1070 [00:12<01:24, 11.15it/s] 12%|█▏        | 125/1070 [00:12<01:24, 11.14it/s] 12%|█▏        | 127/1070 [00:12<01:24, 11.15it/s] 12%|█▏        | 129/1070 [00:12<01:24, 11.19it/s] 12%|█▏        | 131/1070 [00:12<01:23, 11.18it/s] 12%|█▏        | 133/1070 [00:12<01:23, 11.17it/s] 13%|█▎        | 135/1070 [00:13<01:23, 11.16it/s] 13%|█▎        | 137/1070 [00:13<01:23, 11.14it/s] 13%|█▎        | 139/1070 [00:13<01:23, 11.13it/s] 13%|█▎        | 141/1070 [00:13<01:23, 11.14it/s] 13%|█▎        | 143/1070 [00:13<01:23, 11.15it/s] 14%|█▎        | 145/1070 [00:14<01:23, 11.14it/s] 14%|█▎        | 147/1070 [00:14<01:22, 11.13it/s] 14%|█▍        | 149/1070 [00:14<01:22, 11.14it/s] 14%|█▍        | 151/1070 [00:14<01:22, 11.15it/s] 14%|█▍        | 153/1070 [00:14<01:22, 11.14it/s] 14%|█▍        | 155/1070 [00:14<01:22, 11.14it/s] 15%|█▍        | 157/1070 [00:15<01:21, 11.15it/s] 15%|█▍        | 159/1070 [00:15<01:21, 11.16it/s] 15%|█▌        | 161/1070 [00:15<01:21, 11.13it/s] 15%|█▌        | 163/1070 [00:15<01:21, 11.14it/s] 15%|█▌        | 165/1070 [00:15<01:21, 11.15it/s] 16%|█▌        | 167/1070 [00:15<01:21, 11.14it/s] 16%|█▌        | 169/1070 [00:16<01:20, 11.14it/s] 16%|█▌        | 171/1070 [00:16<01:20, 11.15it/s] 16%|█▌        | 173/1070 [00:16<01:20, 11.16it/s] 16%|█▋        | 175/1070 [00:16<01:20, 11.15it/s] 17%|█▋        | 177/1070 [00:16<01:20, 11.15it/s] 17%|█▋        | 179/1070 [00:17<01:19, 11.16it/s] 17%|█▋        | 181/1070 [00:17<01:19, 11.16it/s] 17%|█▋        | 183/1070 [00:17<01:19, 11.14it/s] 17%|█▋        | 185/1070 [00:17<01:19, 11.15it/s] 17%|█▋        | 187/1070 [00:17<01:19, 11.15it/s] 18%|█▊        | 189/1070 [00:17<01:18, 11.15it/s] 18%|█▊        | 191/1070 [00:18<01:18, 11.14it/s] 18%|█▊        | 193/1070 [00:18<01:18, 11.15it/s] 18%|█▊        | 195/1070 [00:18<01:18, 11.15it/s] 18%|█▊        | 197/1070 [00:18<01:18, 11.14it/s] 19%|█▊        | 199/1070 [00:18<01:18, 11.13it/s] 19%|█▉        | 201/1070 [00:19<01:18, 11.14it/s] 19%|█▉        | 203/1070 [00:19<01:17, 11.15it/s] 19%|█▉        | 205/1070 [00:19<01:17, 11.13it/s] 19%|█▉        | 207/1070 [00:19<01:17, 11.14it/s] 20%|█▉        | 209/1070 [00:19<01:17, 11.14it/s] 20%|█▉        | 211/1070 [00:19<01:17, 11.14it/s] 20%|█▉        | 213/1070 [00:20<01:16, 11.14it/s]                                                   20%|██        | 214/1070 [00:20<01:16, 11.14it/s][INFO|trainer.py:755] 2023-11-15 21:10:28,739 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:10:28,741 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:10:28,741 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:10:28,741 >>   Batch size = 8
{'loss': 0.446, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 124.80it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 118.14it/s][A
 40%|████      | 38/95 [00:00<00:00, 116.38it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 115.25it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 114.51it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 113.99it/s][A
 91%|█████████ | 86/95 [00:00<00:00, 113.58it/s][A                                                  
                                                [A 20%|██        | 214/1070 [00:21<01:16, 11.14it/s]
100%|██████████| 95/95 [00:00<00:00, 113.58it/s][A
                                                [A 20%|██        | 215/1070 [00:21<03:06,  4.57it/s] 20%|██        | 217/1070 [00:21<02:34,  5.54it/s] 20%|██        | 219/1070 [00:21<02:10,  6.52it/s] 21%|██        | 221/1070 [00:21<01:54,  7.44it/s] 21%|██        | 223/1070 [00:21<01:42,  8.27it/s] 21%|██        | 225/1070 [00:22<01:34,  8.96it/s] 21%|██        | 227/1070 [00:22<01:28,  9.52it/s] 21%|██▏       | 229/1070 [00:22<01:24,  9.96it/s] 22%|██▏       | 231/1070 [00:22<01:21, 10.27it/s] 22%|██▏       | 233/1070 [00:22<01:19, 10.52it/s] 22%|██▏       | 235/1070 [00:22<01:17, 10.71it/s] 22%|██▏       | 237/1070 [00:23<01:16, 10.84it/s] 22%|██▏       | 239/1070 [00:23<01:16, 10.91it/s] 23%|██▎       | 241/1070 [00:23<01:15, 10.99it/s] 23%|██▎       | 243/1070 [00:23<01:14, 11.04it/s] 23%|██▎       | 245/1070 [00:23<01:14, 11.07it/s] 23%|██▎       | 247/1070 [00:24<01:14, 11.08it/s] 23%|██▎       | 249/1070 [00:24<01:13, 11.10it/s] 23%|██▎       | 251/1070 [00:24<01:13, 11.12it/s] 24%|██▎       | 253/1070 [00:24<01:13, 11.10it/s] 24%|██▍       | 255/1070 [00:24<01:13, 11.11it/s] 24%|██▍       | 257/1070 [00:24<01:13, 11.12it/s] 24%|██▍       | 259/1070 [00:25<01:12, 11.13it/s] 24%|██▍       | 261/1070 [00:25<01:12, 11.12it/s] 25%|██▍       | 263/1070 [00:25<01:12, 11.13it/s] 25%|██▍       | 265/1070 [00:25<01:12, 11.14it/s] 25%|██▍       | 267/1070 [00:25<01:12, 11.15it/s] 25%|██▌       | 269/1070 [00:26<01:11, 11.15it/s] 25%|██▌       | 271/1070 [00:26<01:11, 11.15it/s] 26%|██▌       | 273/1070 [00:26<01:11, 11.15it/s] 26%|██▌       | 275/1070 [00:26<01:11, 11.14it/s] 26%|██▌       | 277/1070 [00:26<01:11, 11.15it/s] 26%|██▌       | 279/1070 [00:26<01:10, 11.15it/s] 26%|██▋       | 281/1070 [00:27<01:10, 11.15it/s] 26%|██▋       | 283/1070 [00:27<01:10, 11.14it/s] 27%|██▋       | 285/1070 [00:27<01:10, 11.13it/s] 27%|██▋       | 287/1070 [00:27<01:10, 11.14it/s] 27%|██▋       | 289/1070 [00:27<01:10, 11.14it/s] 27%|██▋       | 291/1070 [00:27<01:09, 11.13it/s] 27%|██▋       | 293/1070 [00:28<01:09, 11.14it/s] 28%|██▊       | 295/1070 [00:28<01:09, 11.14it/s] 28%|██▊       | 297/1070 [00:28<01:09, 11.14it/s] 28%|██▊       | 299/1070 [00:28<01:09, 11.12it/s] 28%|██▊       | 301/1070 [00:28<01:09, 11.13it/s] 28%|██▊       | 303/1070 [00:29<01:08, 11.14it/s] 29%|██▊       | 305/1070 [00:29<01:08, 11.14it/s] 29%|██▊       | 307/1070 [00:29<01:08, 11.12it/s] 29%|██▉       | 309/1070 [00:29<01:08, 11.12it/s] 29%|██▉       | 311/1070 [00:29<01:08, 11.11it/s] 29%|██▉       | 313/1070 [00:29<01:08, 11.12it/s] 29%|██▉       | 315/1070 [00:30<01:07, 11.12it/s] 30%|██▉       | 317/1070 [00:30<01:07, 11.11it/s] 30%|██▉       | 319/1070 [00:30<01:07, 11.13it/s] 30%|███       | 321/1070 [00:30<01:07, 11.12it/s] 30%|███       | 323/1070 [00:30<01:07, 11.13it/s] 30%|███       | 325/1070 [00:31<01:06, 11.14it/s] 31%|███       | 327/1070 [00:31<01:06, 11.14it/s] 31%|███       | 329/1070 [00:31<01:06, 11.12it/s] 31%|███       | 331/1070 [00:31<01:06, 11.13it/s] 31%|███       | 333/1070 [00:31<01:06, 11.12it/s] 31%|███▏      | 335/1070 [00:31<01:06, 11.11it/s] 31%|███▏      | 337/1070 [00:32<01:06, 11.11it/s] 32%|███▏      | 339/1070 [00:32<01:05, 11.09it/s] 32%|███▏      | 341/1070 [00:32<01:05, 11.10it/s] 32%|███▏      | 343/1070 [00:32<01:05, 11.10it/s] 32%|███▏      | 345/1070 [00:32<01:05, 11.11it/s] 32%|███▏      | 347/1070 [00:33<01:05, 11.12it/s] 33%|███▎      | 349/1070 [00:33<01:04, 11.12it/s] 33%|███▎      | 351/1070 [00:33<01:04, 11.11it/s] 33%|███▎      | 353/1070 [00:33<01:04, 11.12it/s] 33%|███▎      | 355/1070 [00:33<01:04, 11.11it/s] 33%|███▎      | 357/1070 [00:33<01:04, 11.11it/s] 34%|███▎      | 359/1070 [00:34<01:04, 11.08it/s] 34%|███▎      | 361/1070 [00:34<01:03, 11.09it/s] 34%|███▍      | 363/1070 [00:34<01:03, 11.09it/s] 34%|███▍      | 365/1070 [00:34<01:03, 11.11it/s] 34%|███▍      | 367/1070 [00:34<01:03, 11.10it/s] 34%|███▍      | 369/1070 [00:35<01:03, 11.10it/s] 35%|███▍      | 371/1070 [00:35<01:03, 11.08it/s] 35%|███▍      | 373/1070 [00:35<01:02, 11.06it/s] 35%|███▌      | 375/1070 [00:35<01:02, 11.07it/s] 35%|███▌      | 377/1070 [00:35<01:02, 11.08it/s] 35%|███▌      | 379/1070 [00:35<01:02, 11.08it/s] 36%|███▌      | 381/1070 [00:36<01:02, 11.07it/s] 36%|███▌      | 383/1070 [00:36<01:02, 11.06it/s] 36%|███▌      | 385/1070 [00:36<01:01, 11.07it/s] 36%|███▌      | 387/1070 [00:36<01:01, 11.06it/s] 36%|███▋      | 389/1070 [00:36<01:01, 11.07it/s] 37%|███▋      | 391/1070 [00:36<01:01, 11.07it/s] 37%|███▋      | 393/1070 [00:37<01:01, 11.06it/s] 37%|███▋      | 395/1070 [00:37<01:00, 11.08it/s] 37%|███▋      | 397/1070 [00:37<01:00, 11.07it/s] 37%|███▋      | 399/1070 [00:37<01:00, 11.08it/s] 37%|███▋      | 401/1070 [00:37<01:00, 11.07it/s] 38%|███▊      | 403/1070 [00:38<01:00, 11.07it/s] 38%|███▊      | 405/1070 [00:38<01:00, 11.06it/s] 38%|███▊      | 407/1070 [00:38<00:59, 11.06it/s] 38%|███▊      | 409/1070 [00:38<00:59, 11.07it/s] 38%|███▊      | 411/1070 [00:38<00:59, 11.05it/s] 39%|███▊      | 413/1070 [00:38<00:59, 11.06it/s] 39%|███▉      | 415/1070 [00:39<00:59, 11.07it/s] 39%|███▉      | 417/1070 [00:39<00:58, 11.09it/s] 39%|███▉      | 419/1070 [00:39<00:58, 11.08it/s] 39%|███▉      | 421/1070 [00:39<00:58, 11.09it/s] 40%|███▉      | 423/1070 [00:39<00:58, 11.09it/s] 40%|███▉      | 425/1070 [00:40<00:58, 11.08it/s] 40%|███▉      | 427/1070 [00:40<00:58, 11.08it/s]                                                   40%|████      | 428/1070 [00:40<00:57, 11.08it/s][INFO|trainer.py:755] 2023-11-15 21:10:48,863 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:10:48,865 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:10:48,865 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:10:48,866 >>   Batch size = 8
{'eval_loss': 0.3055146336555481, 'eval_accuracy': 0.9078947368421053, 'eval_micro_f1': 0.9078947368421053, 'eval_macro_f1': 0.9045165455648037, 'eval_runtime': 0.8692, 'eval_samples_per_second': 874.378, 'eval_steps_per_second': 109.297, 'epoch': 1.0}
{'loss': 0.2374, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 124.15it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 117.20it/s][A
 40%|████      | 38/95 [00:00<00:00, 115.38it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 114.24it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 113.37it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 112.78it/s][A
 91%|█████████ | 86/95 [00:00<00:00, 112.06it/s][A                                                  
                                                [A 40%|████      | 428/1070 [00:41<00:57, 11.08it/s]
100%|██████████| 95/95 [00:00<00:00, 112.06it/s][A
                                                [A 40%|████      | 429/1070 [00:41<02:21,  4.52it/s] 40%|████      | 431/1070 [00:41<01:56,  5.48it/s] 40%|████      | 433/1070 [00:41<01:38,  6.45it/s] 41%|████      | 435/1070 [00:41<01:26,  7.37it/s] 41%|████      | 437/1070 [00:42<01:17,  8.19it/s] 41%|████      | 439/1070 [00:42<01:11,  8.88it/s] 41%|████      | 441/1070 [00:42<01:06,  9.44it/s] 41%|████▏     | 443/1070 [00:42<01:03,  9.87it/s] 42%|████▏     | 445/1070 [00:42<01:01, 10.20it/s] 42%|████▏     | 447/1070 [00:42<00:59, 10.44it/s] 42%|████▏     | 449/1070 [00:43<00:58, 10.63it/s] 42%|████▏     | 451/1070 [00:43<00:57, 10.76it/s] 42%|████▏     | 453/1070 [00:43<00:56, 10.83it/s] 43%|████▎     | 455/1070 [00:43<00:56, 10.89it/s] 43%|████▎     | 457/1070 [00:43<00:56, 10.93it/s] 43%|████▎     | 459/1070 [00:44<00:55, 10.97it/s] 43%|████▎     | 461/1070 [00:44<00:55, 10.98it/s] 43%|████▎     | 463/1070 [00:44<00:55, 11.01it/s] 43%|████▎     | 465/1070 [00:44<00:54, 11.02it/s] 44%|████▎     | 467/1070 [00:44<00:54, 11.05it/s] 44%|████▍     | 469/1070 [00:44<00:54, 11.04it/s] 44%|████▍     | 471/1070 [00:45<00:54, 11.04it/s] 44%|████▍     | 473/1070 [00:45<00:54, 11.05it/s] 44%|████▍     | 475/1070 [00:45<00:53, 11.05it/s] 45%|████▍     | 477/1070 [00:45<00:53, 11.05it/s] 45%|████▍     | 479/1070 [00:45<00:53, 11.06it/s] 45%|████▍     | 481/1070 [00:46<00:53, 11.05it/s] 45%|████▌     | 483/1070 [00:46<00:53, 11.04it/s] 45%|████▌     | 485/1070 [00:46<00:52, 11.05it/s] 46%|████▌     | 487/1070 [00:46<00:52, 11.07it/s] 46%|████▌     | 489/1070 [00:46<00:52, 11.07it/s] 46%|████▌     | 491/1070 [00:46<00:52, 11.05it/s] 46%|████▌     | 493/1070 [00:47<00:52, 11.06it/s] 46%|████▋     | 495/1070 [00:47<00:52, 11.06it/s] 46%|████▋     | 497/1070 [00:47<00:51, 11.07it/s] 47%|████▋     | 499/1070 [00:47<00:51, 11.05it/s] 47%|████▋     | 501/1070 [00:47<00:51, 11.06it/s] 47%|████▋     | 503/1070 [00:47<00:51, 11.05it/s] 47%|████▋     | 505/1070 [00:48<00:51, 11.02it/s] 47%|████▋     | 507/1070 [00:48<00:51, 11.03it/s] 48%|████▊     | 509/1070 [00:48<00:50, 11.04it/s] 48%|████▊     | 511/1070 [00:48<00:50, 11.05it/s] 48%|████▊     | 513/1070 [00:48<00:50, 11.04it/s] 48%|████▊     | 515/1070 [00:49<00:50, 11.03it/s] 48%|████▊     | 517/1070 [00:49<00:50, 11.02it/s] 49%|████▊     | 519/1070 [00:49<00:49, 11.04it/s] 49%|████▊     | 521/1070 [00:49<00:49, 11.01it/s] 49%|████▉     | 523/1070 [00:49<00:49, 11.03it/s] 49%|████▉     | 525/1070 [00:49<00:49, 11.03it/s] 49%|████▉     | 527/1070 [00:50<00:49, 11.03it/s] 49%|████▉     | 529/1070 [00:50<00:49, 11.01it/s] 50%|████▉     | 531/1070 [00:50<00:48, 11.03it/s] 50%|████▉     | 533/1070 [00:50<00:48, 11.04it/s] 50%|█████     | 535/1070 [00:50<00:48, 11.03it/s] 50%|█████     | 537/1070 [00:51<00:48, 11.04it/s] 50%|█████     | 539/1070 [00:51<00:48, 11.04it/s] 51%|█████     | 541/1070 [00:51<00:47, 11.04it/s] 51%|█████     | 543/1070 [00:51<00:47, 11.03it/s] 51%|█████     | 545/1070 [00:51<00:47, 11.03it/s] 51%|█████     | 547/1070 [00:51<00:47, 11.04it/s] 51%|█████▏    | 549/1070 [00:52<00:47, 11.03it/s] 51%|█████▏    | 551/1070 [00:52<00:47, 11.02it/s] 52%|█████▏    | 553/1070 [00:52<00:46, 11.03it/s] 52%|█████▏    | 555/1070 [00:52<00:46, 11.04it/s] 52%|█████▏    | 557/1070 [00:52<00:46, 11.03it/s] 52%|█████▏    | 559/1070 [00:53<00:46, 11.02it/s] 52%|█████▏    | 561/1070 [00:53<00:46, 11.02it/s] 53%|█████▎    | 563/1070 [00:53<00:45, 11.03it/s] 53%|█████▎    | 565/1070 [00:53<00:45, 11.03it/s] 53%|█████▎    | 567/1070 [00:53<00:45, 11.02it/s] 53%|█████▎    | 569/1070 [00:53<00:45, 11.02it/s] 53%|█████▎    | 571/1070 [00:54<00:45, 11.02it/s] 54%|█████▎    | 573/1070 [00:54<00:45, 11.02it/s] 54%|█████▎    | 575/1070 [00:54<00:44, 11.01it/s] 54%|█████▍    | 577/1070 [00:54<00:44, 11.02it/s] 54%|█████▍    | 579/1070 [00:54<00:44, 11.01it/s] 54%|█████▍    | 581/1070 [00:55<00:44, 11.01it/s] 54%|█████▍    | 583/1070 [00:55<00:44, 11.01it/s] 55%|█████▍    | 585/1070 [00:55<00:44, 11.00it/s] 55%|█████▍    | 587/1070 [00:55<00:43, 10.99it/s] 55%|█████▌    | 589/1070 [00:55<00:43, 11.01it/s] 55%|█████▌    | 591/1070 [00:55<00:43, 11.03it/s] 55%|█████▌    | 593/1070 [00:56<00:43, 11.01it/s] 56%|█████▌    | 595/1070 [00:56<00:43, 11.01it/s] 56%|█████▌    | 597/1070 [00:56<00:42, 11.02it/s] 56%|█████▌    | 599/1070 [00:56<00:42, 11.01it/s] 56%|█████▌    | 601/1070 [00:56<00:42, 11.02it/s] 56%|█████▋    | 603/1070 [00:57<00:42, 11.02it/s] 57%|█████▋    | 605/1070 [00:57<00:42, 11.02it/s] 57%|█████▋    | 607/1070 [00:57<00:42, 11.01it/s] 57%|█████▋    | 609/1070 [00:57<00:41, 10.99it/s] 57%|█████▋    | 611/1070 [00:57<00:41, 10.99it/s] 57%|█████▋    | 613/1070 [00:57<00:41, 11.00it/s] 57%|█████▋    | 615/1070 [00:58<00:41, 11.00it/s] 58%|█████▊    | 617/1070 [00:58<00:41, 10.98it/s] 58%|█████▊    | 619/1070 [00:58<00:41, 10.99it/s] 58%|█████▊    | 621/1070 [00:58<00:40, 11.00it/s] 58%|█████▊    | 623/1070 [00:58<00:40, 11.01it/s] 58%|█████▊    | 625/1070 [00:59<00:40, 11.00it/s] 59%|█████▊    | 627/1070 [00:59<00:40, 11.00it/s] 59%|█████▉    | 629/1070 [00:59<00:40, 10.99it/s] 59%|█████▉    | 631/1070 [00:59<00:39, 11.00it/s] 59%|█████▉    | 633/1070 [00:59<00:39, 11.00it/s] 59%|█████▉    | 635/1070 [00:59<00:39, 11.02it/s] 60%|█████▉    | 637/1070 [01:00<00:39, 11.02it/s] 60%|█████▉    | 639/1070 [01:00<00:39, 10.98it/s] 60%|█████▉    | 641/1070 [01:00<00:39, 10.98it/s]                                                   60%|██████    | 642/1070 [01:00<00:38, 10.98it/s][INFO|trainer.py:755] 2023-11-15 21:11:09,145 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:11:09,146 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:11:09,147 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:11:09,147 >>   Batch size = 8
{'eval_loss': 0.2763316035270691, 'eval_accuracy': 0.9078947368421053, 'eval_micro_f1': 0.9078947368421053, 'eval_macro_f1': 0.9051375434265525, 'eval_runtime': 0.8806, 'eval_samples_per_second': 863.092, 'eval_steps_per_second': 107.886, 'epoch': 2.0}
{'loss': 0.1676, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 123.51it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 116.36it/s][A
 40%|████      | 38/95 [00:00<00:00, 114.35it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 113.05it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 112.36it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 111.86it/s][A
 91%|█████████ | 86/95 [00:00<00:00, 111.24it/s][A                                                  
                                                [A 60%|██████    | 642/1070 [01:01<00:38, 10.98it/s]
100%|██████████| 95/95 [00:00<00:00, 111.24it/s][A
                                                [A 60%|██████    | 643/1070 [01:01<01:35,  4.49it/s] 60%|██████    | 645/1070 [01:01<01:18,  5.44it/s] 60%|██████    | 647/1070 [01:01<01:06,  6.41it/s] 61%|██████    | 649/1070 [01:02<00:57,  7.33it/s] 61%|██████    | 651/1070 [01:02<00:51,  8.15it/s] 61%|██████    | 653/1070 [01:02<00:47,  8.84it/s] 61%|██████    | 655/1070 [01:02<00:44,  9.40it/s] 61%|██████▏   | 657/1070 [01:02<00:41,  9.84it/s] 62%|██████▏   | 659/1070 [01:03<00:40, 10.16it/s] 62%|██████▏   | 661/1070 [01:03<00:39, 10.38it/s] 62%|██████▏   | 663/1070 [01:03<00:38, 10.58it/s] 62%|██████▏   | 665/1070 [01:03<00:37, 10.72it/s] 62%|██████▏   | 667/1070 [01:03<00:37, 10.80it/s] 63%|██████▎   | 669/1070 [01:03<00:36, 10.87it/s] 63%|██████▎   | 671/1070 [01:04<00:36, 10.92it/s] 63%|██████▎   | 673/1070 [01:04<00:36, 10.96it/s] 63%|██████▎   | 675/1070 [01:04<00:36, 10.97it/s] 63%|██████▎   | 677/1070 [01:04<00:35, 10.99it/s] 63%|██████▎   | 679/1070 [01:04<00:35, 11.01it/s] 64%|██████▎   | 681/1070 [01:05<00:35, 11.01it/s] 64%|██████▍   | 683/1070 [01:05<00:35, 11.01it/s] 64%|██████▍   | 685/1070 [01:05<00:34, 11.01it/s] 64%|██████▍   | 687/1070 [01:05<00:34, 11.01it/s] 64%|██████▍   | 689/1070 [01:05<00:34, 10.99it/s] 65%|██████▍   | 691/1070 [01:05<00:34, 11.01it/s] 65%|██████▍   | 693/1070 [01:06<00:34, 11.02it/s] 65%|██████▍   | 695/1070 [01:06<00:34, 11.02it/s] 65%|██████▌   | 697/1070 [01:06<00:33, 11.01it/s] 65%|██████▌   | 699/1070 [01:06<00:33, 11.01it/s] 66%|██████▌   | 701/1070 [01:06<00:33, 11.02it/s] 66%|██████▌   | 703/1070 [01:07<00:33, 11.03it/s] 66%|██████▌   | 705/1070 [01:07<00:33, 11.01it/s] 66%|██████▌   | 707/1070 [01:07<00:32, 11.00it/s] 66%|██████▋   | 709/1070 [01:07<00:32, 11.00it/s] 66%|██████▋   | 711/1070 [01:07<00:32, 10.97it/s] 67%|██████▋   | 713/1070 [01:07<00:32, 10.99it/s] 67%|██████▋   | 715/1070 [01:08<00:32, 11.00it/s] 67%|██████▋   | 717/1070 [01:08<00:32, 11.00it/s] 67%|██████▋   | 719/1070 [01:08<00:31, 10.99it/s] 67%|██████▋   | 721/1070 [01:08<00:31, 10.99it/s] 68%|██████▊   | 723/1070 [01:08<00:31, 11.00it/s] 68%|██████▊   | 725/1070 [01:09<00:31, 10.99it/s] 68%|██████▊   | 727/1070 [01:09<00:31, 11.00it/s] 68%|██████▊   | 729/1070 [01:09<00:31, 11.00it/s] 68%|██████▊   | 731/1070 [01:09<00:30, 11.01it/s] 69%|██████▊   | 733/1070 [01:09<00:30, 10.99it/s] 69%|██████▊   | 735/1070 [01:09<00:30, 10.98it/s] 69%|██████▉   | 737/1070 [01:10<00:30, 11.00it/s] 69%|██████▉   | 739/1070 [01:10<00:30, 11.00it/s] 69%|██████▉   | 741/1070 [01:10<00:29, 11.00it/s] 69%|██████▉   | 743/1070 [01:10<00:29, 11.01it/s] 70%|██████▉   | 745/1070 [01:10<00:29, 11.02it/s] 70%|██████▉   | 747/1070 [01:11<00:29, 11.02it/s] 70%|███████   | 749/1070 [01:11<00:29, 11.00it/s] 70%|███████   | 751/1070 [01:11<00:28, 11.00it/s] 70%|███████   | 753/1070 [01:11<00:28, 11.00it/s] 71%|███████   | 755/1070 [01:11<00:28, 11.00it/s] 71%|███████   | 757/1070 [01:11<00:28, 11.01it/s] 71%|███████   | 759/1070 [01:12<00:28, 11.01it/s] 71%|███████   | 761/1070 [01:12<00:28, 11.01it/s] 71%|███████▏  | 763/1070 [01:12<00:27, 11.00it/s] 71%|███████▏  | 765/1070 [01:12<00:27, 11.01it/s] 72%|███████▏  | 767/1070 [01:12<00:27, 11.02it/s] 72%|███████▏  | 769/1070 [01:13<00:27, 11.00it/s] 72%|███████▏  | 771/1070 [01:13<00:27, 10.99it/s] 72%|███████▏  | 773/1070 [01:13<00:27, 11.00it/s] 72%|███████▏  | 775/1070 [01:13<00:26, 11.00it/s] 73%|███████▎  | 777/1070 [01:13<00:26, 10.99it/s] 73%|███████▎  | 779/1070 [01:13<00:26, 10.99it/s] 73%|███████▎  | 781/1070 [01:14<00:26, 11.00it/s] 73%|███████▎  | 783/1070 [01:14<00:26, 10.99it/s] 73%|███████▎  | 785/1070 [01:14<00:25, 10.98it/s] 74%|███████▎  | 787/1070 [01:14<00:25, 10.99it/s] 74%|███████▎  | 789/1070 [01:14<00:25, 10.99it/s] 74%|███████▍  | 791/1070 [01:15<00:25, 10.99it/s] 74%|███████▍  | 793/1070 [01:15<00:25, 10.98it/s] 74%|███████▍  | 795/1070 [01:15<00:25, 10.99it/s] 74%|███████▍  | 797/1070 [01:15<00:24, 11.00it/s] 75%|███████▍  | 799/1070 [01:15<00:24, 10.98it/s] 75%|███████▍  | 801/1070 [01:15<00:24, 10.97it/s] 75%|███████▌  | 803/1070 [01:16<00:24, 10.98it/s] 75%|███████▌  | 805/1070 [01:16<00:24, 10.99it/s] 75%|███████▌  | 807/1070 [01:16<00:23, 11.00it/s] 76%|███████▌  | 809/1070 [01:16<00:23, 11.00it/s] 76%|███████▌  | 811/1070 [01:16<00:23, 10.99it/s] 76%|███████▌  | 813/1070 [01:17<00:23, 10.99it/s] 76%|███████▌  | 815/1070 [01:17<00:23, 10.99it/s] 76%|███████▋  | 817/1070 [01:17<00:23, 11.00it/s] 77%|███████▋  | 819/1070 [01:17<00:22, 11.00it/s] 77%|███████▋  | 821/1070 [01:17<00:22, 10.99it/s] 77%|███████▋  | 823/1070 [01:17<00:22, 10.99it/s] 77%|███████▋  | 825/1070 [01:18<00:22, 11.00it/s] 77%|███████▋  | 827/1070 [01:18<00:22, 11.00it/s] 77%|███████▋  | 829/1070 [01:18<00:21, 10.99it/s] 78%|███████▊  | 831/1070 [01:18<00:21, 10.98it/s] 78%|███████▊  | 833/1070 [01:18<00:21, 10.96it/s] 78%|███████▊  | 835/1070 [01:19<00:21, 10.97it/s] 78%|███████▊  | 837/1070 [01:19<00:21, 10.98it/s] 78%|███████▊  | 839/1070 [01:19<00:21, 10.99it/s] 79%|███████▊  | 841/1070 [01:19<00:20, 10.99it/s] 79%|███████▉  | 843/1070 [01:19<00:20, 10.99it/s] 79%|███████▉  | 845/1070 [01:19<00:20, 10.99it/s] 79%|███████▉  | 847/1070 [01:20<00:20, 11.00it/s] 79%|███████▉  | 849/1070 [01:20<00:20, 11.00it/s] 80%|███████▉  | 851/1070 [01:20<00:19, 10.99it/s] 80%|███████▉  | 853/1070 [01:20<00:19, 10.99it/s] 80%|███████▉  | 855/1070 [01:20<00:19, 11.00it/s]                                                   80%|████████  | 856/1070 [01:20<00:19, 11.00it/s][INFO|trainer.py:755] 2023-11-15 21:11:29,480 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:11:29,481 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:11:29,482 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:11:29,482 >>   Batch size = 8
{'eval_loss': 0.30563756823539734, 'eval_accuracy': 0.9105263157894737, 'eval_micro_f1': 0.9105263157894739, 'eval_macro_f1': 0.9084996583723386, 'eval_runtime': 0.8859, 'eval_samples_per_second': 857.888, 'eval_steps_per_second': 107.236, 'epoch': 3.0}
{'loss': 0.1141, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 122.52it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 115.94it/s][A
 40%|████      | 38/95 [00:00<00:00, 113.89it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 112.69it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 112.18it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 111.62it/s][A
 91%|█████████ | 86/95 [00:00<00:00, 110.82it/s][A                                                  
                                                [A 80%|████████  | 856/1070 [01:21<00:19, 11.00it/s]
100%|██████████| 95/95 [00:00<00:00, 110.82it/s][A
                                                [A 80%|████████  | 857/1070 [01:21<00:47,  4.48it/s] 80%|████████  | 859/1070 [01:22<00:38,  5.44it/s] 80%|████████  | 861/1070 [01:22<00:32,  6.41it/s] 81%|████████  | 863/1070 [01:22<00:28,  7.32it/s] 81%|████████  | 865/1070 [01:22<00:25,  8.14it/s] 81%|████████  | 867/1070 [01:22<00:22,  8.83it/s] 81%|████████  | 869/1070 [01:23<00:21,  9.37it/s] 81%|████████▏ | 871/1070 [01:23<00:20,  9.81it/s] 82%|████████▏ | 873/1070 [01:23<00:19, 10.15it/s] 82%|████████▏ | 875/1070 [01:23<00:18, 10.39it/s] 82%|████████▏ | 877/1070 [01:23<00:18, 10.56it/s] 82%|████████▏ | 879/1070 [01:23<00:17, 10.69it/s] 82%|████████▏ | 881/1070 [01:24<00:17, 10.79it/s] 83%|████████▎ | 883/1070 [01:24<00:17, 10.86it/s] 83%|████████▎ | 885/1070 [01:24<00:16, 10.90it/s] 83%|████████▎ | 887/1070 [01:24<00:16, 10.93it/s] 83%|████████▎ | 889/1070 [01:24<00:16, 10.95it/s] 83%|████████▎ | 891/1070 [01:25<00:16, 10.95it/s] 83%|████████▎ | 893/1070 [01:25<00:16, 10.97it/s] 84%|████████▎ | 895/1070 [01:25<00:15, 10.98it/s] 84%|████████▍ | 897/1070 [01:25<00:15, 10.99it/s] 84%|████████▍ | 899/1070 [01:25<00:15, 10.98it/s] 84%|████████▍ | 901/1070 [01:25<00:15, 10.99it/s] 84%|████████▍ | 903/1070 [01:26<00:15, 11.00it/s] 85%|████████▍ | 905/1070 [01:26<00:15, 11.00it/s] 85%|████████▍ | 907/1070 [01:26<00:14, 10.99it/s] 85%|████████▍ | 909/1070 [01:26<00:14, 10.99it/s] 85%|████████▌ | 911/1070 [01:26<00:14, 10.99it/s] 85%|████████▌ | 913/1070 [01:27<00:14, 11.00it/s] 86%|████████▌ | 915/1070 [01:27<00:14, 11.00it/s] 86%|████████▌ | 917/1070 [01:27<00:13, 11.00it/s] 86%|████████▌ | 919/1070 [01:27<00:13, 11.00it/s] 86%|████████▌ | 921/1070 [01:27<00:13, 11.00it/s] 86%|████████▋ | 923/1070 [01:27<00:13, 10.99it/s] 86%|████████▋ | 925/1070 [01:28<00:13, 11.01it/s] 87%|████████▋ | 927/1070 [01:28<00:12, 11.01it/s] 87%|████████▋ | 929/1070 [01:28<00:12, 11.00it/s] 87%|████████▋ | 931/1070 [01:28<00:12, 10.99it/s] 87%|████████▋ | 933/1070 [01:28<00:12, 11.00it/s] 87%|████████▋ | 935/1070 [01:29<00:12, 11.00it/s] 88%|████████▊ | 937/1070 [01:29<00:12, 11.00it/s] 88%|████████▊ | 939/1070 [01:29<00:11, 11.00it/s] 88%|████████▊ | 941/1070 [01:29<00:11, 11.00it/s] 88%|████████▊ | 943/1070 [01:29<00:11, 11.00it/s] 88%|████████▊ | 945/1070 [01:29<00:11, 10.99it/s] 89%|████████▊ | 947/1070 [01:30<00:11, 10.98it/s] 89%|████████▊ | 949/1070 [01:30<00:11, 10.99it/s] 89%|████████▉ | 951/1070 [01:30<00:10, 10.98it/s] 89%|████████▉ | 953/1070 [01:30<00:10, 10.98it/s] 89%|████████▉ | 955/1070 [01:30<00:10, 10.97it/s] 89%|████████▉ | 957/1070 [01:31<00:10, 10.98it/s] 90%|████████▉ | 959/1070 [01:31<00:10, 10.98it/s] 90%|████████▉ | 961/1070 [01:31<00:09, 10.99it/s] 90%|█████████ | 963/1070 [01:31<00:09, 11.00it/s] 90%|█████████ | 965/1070 [01:31<00:09, 11.00it/s] 90%|█████████ | 967/1070 [01:31<00:09, 10.99it/s] 91%|█████████ | 969/1070 [01:32<00:09, 10.99it/s] 91%|█████████ | 971/1070 [01:32<00:09, 10.99it/s] 91%|█████████ | 973/1070 [01:32<00:08, 10.99it/s] 91%|█████████ | 975/1070 [01:32<00:08, 10.99it/s] 91%|█████████▏| 977/1070 [01:32<00:08, 11.00it/s] 91%|█████████▏| 979/1070 [01:33<00:08, 11.00it/s] 92%|█████████▏| 981/1070 [01:33<00:08, 10.99it/s] 92%|█████████▏| 983/1070 [01:33<00:07, 10.99it/s] 92%|█████████▏| 985/1070 [01:33<00:07, 10.99it/s] 92%|█████████▏| 987/1070 [01:33<00:07, 10.98it/s] 92%|█████████▏| 989/1070 [01:33<00:07, 10.99it/s] 93%|█████████▎| 991/1070 [01:34<00:07, 10.98it/s] 93%|█████████▎| 993/1070 [01:34<00:07, 10.98it/s] 93%|█████████▎| 995/1070 [01:34<00:06, 10.99it/s] 93%|█████████▎| 997/1070 [01:34<00:06, 10.99it/s] 93%|█████████▎| 999/1070 [01:34<00:06, 10.98it/s] 94%|█████████▎| 1001/1070 [01:35<00:06, 10.99it/s] 94%|█████████▎| 1003/1070 [01:35<00:06, 10.99it/s] 94%|█████████▍| 1005/1070 [01:35<00:05, 10.98it/s] 94%|█████████▍| 1007/1070 [01:35<00:05, 10.98it/s] 94%|█████████▍| 1009/1070 [01:35<00:05, 10.98it/s] 94%|█████████▍| 1011/1070 [01:35<00:05, 10.99it/s] 95%|█████████▍| 1013/1070 [01:36<00:05, 11.00it/s] 95%|█████████▍| 1015/1070 [01:36<00:05, 10.99it/s] 95%|█████████▌| 1017/1070 [01:36<00:04, 10.97it/s] 95%|█████████▌| 1019/1070 [01:36<00:04, 10.98it/s] 95%|█████████▌| 1021/1070 [01:36<00:04, 10.99it/s] 96%|█████████▌| 1023/1070 [01:37<00:04, 10.99it/s] 96%|█████████▌| 1025/1070 [01:37<00:04, 10.97it/s] 96%|█████████▌| 1027/1070 [01:37<00:03, 10.96it/s] 96%|█████████▌| 1029/1070 [01:37<00:03, 10.97it/s] 96%|█████████▋| 1031/1070 [01:37<00:03, 10.97it/s] 97%|█████████▋| 1033/1070 [01:37<00:03, 10.95it/s] 97%|█████████▋| 1035/1070 [01:38<00:03, 10.97it/s] 97%|█████████▋| 1037/1070 [01:38<00:03, 10.97it/s] 97%|█████████▋| 1039/1070 [01:38<00:02, 10.97it/s] 97%|█████████▋| 1041/1070 [01:38<00:02, 10.96it/s] 97%|█████████▋| 1043/1070 [01:38<00:02, 10.96it/s] 98%|█████████▊| 1045/1070 [01:39<00:02, 10.97it/s] 98%|█████████▊| 1047/1070 [01:39<00:02, 10.97it/s] 98%|█████████▊| 1049/1070 [01:39<00:01, 10.96it/s] 98%|█████████▊| 1051/1070 [01:39<00:01, 10.97it/s] 98%|█████████▊| 1053/1070 [01:39<00:01, 10.98it/s] 99%|█████████▊| 1055/1070 [01:39<00:01, 10.97it/s] 99%|█████████▉| 1057/1070 [01:40<00:01, 10.96it/s] 99%|█████████▉| 1059/1070 [01:40<00:01, 10.96it/s] 99%|█████████▉| 1061/1070 [01:40<00:00, 10.97it/s] 99%|█████████▉| 1063/1070 [01:40<00:00, 10.96it/s]100%|█████████▉| 1065/1070 [01:40<00:00, 10.97it/s]100%|█████████▉| 1067/1070 [01:41<00:00, 10.99it/s]100%|█████████▉| 1069/1070 [01:41<00:00, 10.99it/s]                                                   100%|██████████| 1070/1070 [01:41<00:00, 10.99it/s][INFO|trainer.py:755] 2023-11-15 21:11:49,841 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:11:49,843 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:11:49,843 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:11:49,843 >>   Batch size = 8
{'eval_loss': 0.3420467674732208, 'eval_accuracy': 0.9092105263157895, 'eval_micro_f1': 0.9092105263157895, 'eval_macro_f1': 0.9065303144043253, 'eval_runtime': 0.8891, 'eval_samples_per_second': 854.765, 'eval_steps_per_second': 106.846, 'epoch': 4.0}
{'loss': 0.0744, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
 14%|█▎        | 13/95 [00:00<00:00, 121.33it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 115.47it/s][A
 40%|████      | 38/95 [00:00<00:00, 113.50it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 112.26it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 111.30it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 110.16it/s][A
 91%|█████████ | 86/95 [00:00<00:00, 109.65it/s][A                                                   
                                                [A100%|██████████| 1070/1070 [01:42<00:00, 10.99it/s]
100%|██████████| 95/95 [00:00<00:00, 109.65it/s][A
                                                [A[INFO|trainer.py:1963] 2023-11-15 21:11:50,745 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [01:42<00:00, 10.99it/s]100%|██████████| 1070/1070 [01:42<00:00, 10.47it/s]
[INFO|trainer.py:2855] 2023-11-15 21:11:50,748 >> Saving model checkpoint to ./result/agnews_sup_roberta-base_adapter__seed3
[INFO|configuration_utils.py:460] 2023-11-15 21:11:50,751 >> Configuration saved in ./result/agnews_sup_roberta-base_adapter__seed3/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:11:51,859 >> Model weights saved in ./result/agnews_sup_roberta-base_adapter__seed3/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:11:51,862 >> tokenizer config file saved in ./result/agnews_sup_roberta-base_adapter__seed3/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:11:51,863 >> Special tokens file saved in ./result/agnews_sup_roberta-base_adapter__seed3/special_tokens_map.json
{'eval_loss': 0.3681185245513916, 'eval_accuracy': 0.9105263157894737, 'eval_micro_f1': 0.9105263157894739, 'eval_macro_f1': 0.9081641548065629, 'eval_runtime': 0.8987, 'eval_samples_per_second': 845.685, 'eval_steps_per_second': 105.711, 'epoch': 5.0}
{'train_runtime': 102.2111, 'train_samples_per_second': 334.602, 'train_steps_per_second': 10.469, 'train_loss': 0.20792432945465372, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2079
  train_runtime            = 0:01:42.21
  train_samples            =       6840
  train_samples_per_second =    334.602
  train_steps_per_second   =     10.469
11/15/2023 21:11:51 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:11:51,951 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:11:51,952 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:11:51,953 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:11:51,953 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s] 14%|█▎        | 13/95 [00:00<00:00, 121.52it/s] 27%|██▋       | 26/95 [00:00<00:00, 113.76it/s] 40%|████      | 38/95 [00:00<00:00, 111.16it/s] 53%|█████▎    | 50/95 [00:00<00:00, 104.66it/s] 64%|██████▍   | 61/95 [00:00<00:00, 105.55it/s] 76%|███████▌  | 72/95 [00:00<00:00, 106.19it/s] 87%|████████▋ | 83/95 [00:00<00:00, 106.43it/s] 99%|█████████▉| 94/95 [00:00<00:00, 106.58it/s]100%|██████████| 95/95 [00:00<00:00, 104.43it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9105
  eval_loss               =     0.3681
  eval_macro_f1           =     0.9082
  eval_micro_f1           =     0.9105
  eval_runtime            = 0:00:00.92
  eval_samples            =        760
  eval_samples_per_second =    824.881
  eval_steps_per_second   =     103.11
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▁█▄██
wandb:                      eval/loss ▃▁▃▆██
wandb:                  eval/macro_f1 ▁▂█▅▇▇
wandb:                  eval/micro_f1 ▁▁█▄██
wandb:                   eval/runtime ▁▃▃▄▅█
wandb:        eval/samples_per_second █▆▆▅▄▁
wandb:          eval/steps_per_second █▆▆▅▄▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.91053
wandb:                      eval/loss 0.36812
wandb:                  eval/macro_f1 0.90816
wandb:                  eval/micro_f1 0.91053
wandb:                   eval/runtime 0.9213
wandb:        eval/samples_per_second 824.881
wandb:          eval/steps_per_second 103.11
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0744
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.20792
wandb:            train/train_runtime 102.2111
wandb: train/train_samples_per_second 334.602
wandb:   train/train_steps_per_second 10.469
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_210851-ous25057
wandb: Find logs at: ./wandb/offline-run-20231115_210851-ous25057/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_bert-base-cased_adapter__seed3/runs/Nov15_21-12-03_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_bert-base-cased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_bert-base-cased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:12:03 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:12:03 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_bert-base-cased_adapter__seed3/runs/Nov15_21-12-02_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_bert-base-cased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_bert-base-cased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 21:12:18,993 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:12:19,003 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 21:12:29,020 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:12:29,021 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:12:29,023 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:12:29,023 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:12:29,024 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:12:29,024 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:12:29,024 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 21:12:29,025 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:12:29,026 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:12:49,235 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 21:12:49,895 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:12:49,895 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  44%|████▍     | 3000/6840 [00:00<00:00, 19225.61 examples/s]Running tokenizer on dataset:  88%|████████▊ | 6000/6840 [00:00<00:00, 18714.47 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 18657.62 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 22072.07 examples/s]
11/15/2023 21:12:50 - INFO - __main__ - Sample 2530 of the training set: {'text': 'Invasion of the Data Snatchers (washingtonpost.com) washingtonpost.com - Think your PC is safe? Think again. A new study indicates your home computer is likely bogged down with spyware, viruses and other scourges wrought by hackers and PC pranksters. Ignorance may be bliss for some people, but for computer users, not knowing can be costly and inefficient.', 'label': 2, 'input_ids': [101, 20209, 1104, 1103, 7154, 156, 25703, 1468, 113, 13445, 1633, 21341, 119, 3254, 114, 13445, 1633, 21341, 119, 3254, 118, 9471, 1240, 7054, 1110, 2914, 136, 9471, 1254, 119, 138, 1207, 2025, 6653, 1240, 1313, 2775, 1110, 2620, 171, 24009, 1205, 1114, 10669, 7109, 117, 20942, 1105, 1168, 188, 2528, 27793, 1116, 20533, 1118, 5871, 24138, 1105, 7054, 185, 14687, 12429, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 21:12:50 - INFO - __main__ - Sample 2357 of the training set: {'text': 'Corning begins work on Taiwan LCD facility Encouraged by the demand for LCDs, glass maker Corning on Thursday said it has broken ground for a second manufacturing facility in Taiwan.', 'label': 2, 'input_ids': [101, 3291, 4558, 1158, 3471, 1250, 1113, 6036, 149, 14107, 3695, 13832, 2528, 26800, 1181, 1118, 1103, 4555, 1111, 149, 14107, 1116, 117, 2525, 11166, 3291, 4558, 1158, 1113, 9170, 1163, 1122, 1144, 3088, 1747, 1111, 170, 1248, 5863, 3695, 1107, 6036, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:12:50 - INFO - __main__ - Sample 108 of the training set: {'text': "In Asia, Powell defends N. Korea policy SEOUL -- Secretary of State Colin L. Powell yesterday sought to fend off complaints from key partners in the effort to end North Korea's nuclear programs that the Bush administration has not been sufficiently creative or willing to compromise in the negotiations.", 'label': 3, 'input_ids': [101, 1130, 3165, 117, 8635, 6472, 1116, 151, 119, 3577, 2818, 12342, 2346, 2591, 2162, 118, 118, 2909, 1104, 1426, 6381, 149, 119, 8635, 8128, 4110, 1106, 175, 6696, 1228, 11344, 1121, 2501, 6449, 1107, 1103, 3098, 1106, 1322, 1456, 3577, 112, 188, 4272, 2648, 1115, 1103, 6096, 3469, 1144, 1136, 1151, 13230, 6228, 1137, 4988, 1106, 13018, 1107, 1103, 7624, 119, 102, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]}.
11/15/2023 21:12:50 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:12:51,671 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:12:51,679 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:12:51,679 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 21:12:51,679 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:12:51,680 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:12:51,680 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:12:51,680 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:12:51,680 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 21:12:51,681 >>   Number of trainable parameters = 108,313,348
[INFO|integration_utils.py:716] 2023-11-15 21:12:51,682 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<20:36,  1.16s/it]  0%|          | 2/1070 [00:01<09:32,  1.86it/s]  0%|          | 3/1070 [00:01<06:02,  2.94it/s]  0%|          | 4/1070 [00:01<04:22,  4.06it/s]  0%|          | 5/1070 [00:01<03:27,  5.14it/s]  1%|          | 6/1070 [00:01<02:54,  6.08it/s]  1%|          | 7/1070 [00:01<02:33,  6.91it/s]  1%|          | 9/1070 [00:01<02:11,  8.09it/s]  1%|          | 10/1070 [00:02<02:06,  8.37it/s]  1%|          | 11/1070 [00:02<02:01,  8.71it/s]  1%|          | 13/1070 [00:02<01:54,  9.20it/s]  1%|▏         | 14/1070 [00:02<01:53,  9.31it/s]  1%|▏         | 15/1070 [00:02<01:52,  9.37it/s]  1%|▏         | 16/1070 [00:02<01:52,  9.35it/s]  2%|▏         | 17/1070 [00:02<01:51,  9.43it/s]  2%|▏         | 18/1070 [00:02<01:51,  9.42it/s]  2%|▏         | 20/1070 [00:03<01:50,  9.54it/s]  2%|▏         | 21/1070 [00:03<01:49,  9.59it/s]  2%|▏         | 22/1070 [00:03<01:50,  9.50it/s]  2%|▏         | 23/1070 [00:03<01:49,  9.52it/s]  2%|▏         | 24/1070 [00:03<01:50,  9.51it/s]  2%|▏         | 25/1070 [00:03<01:49,  9.54it/s]  3%|▎         | 27/1070 [00:03<01:47,  9.67it/s]  3%|▎         | 28/1070 [00:03<01:48,  9.62it/s]  3%|▎         | 29/1070 [00:04<01:47,  9.64it/s]  3%|▎         | 30/1070 [00:04<01:48,  9.59it/s]  3%|▎         | 31/1070 [00:04<01:48,  9.58it/s]  3%|▎         | 32/1070 [00:04<01:47,  9.62it/s]  3%|▎         | 34/1070 [00:04<01:46,  9.69it/s]  3%|▎         | 35/1070 [00:04<01:47,  9.64it/s]  3%|▎         | 36/1070 [00:04<01:47,  9.62it/s]  3%|▎         | 37/1070 [00:04<01:46,  9.71it/s]  4%|▎         | 38/1070 [00:04<01:46,  9.68it/s]  4%|▎         | 39/1070 [00:05<01:46,  9.64it/s]  4%|▎         | 40/1070 [00:05<01:47,  9.61it/s]  4%|▍         | 41/1070 [00:05<01:47,  9.56it/s]  4%|▍         | 42/1070 [00:05<01:47,  9.59it/s]  4%|▍         | 43/1070 [00:05<01:48,  9.50it/s]  4%|▍         | 45/1070 [00:05<01:47,  9.56it/s]  4%|▍         | 46/1070 [00:05<01:47,  9.55it/s]  4%|▍         | 47/1070 [00:05<01:47,  9.51it/s]  4%|▍         | 48/1070 [00:06<01:47,  9.49it/s]  5%|▍         | 49/1070 [00:06<01:47,  9.49it/s]  5%|▍         | 50/1070 [00:06<01:47,  9.46it/s]  5%|▍         | 52/1070 [00:06<01:46,  9.60it/s]  5%|▍         | 53/1070 [00:06<01:46,  9.51it/s]  5%|▌         | 54/1070 [00:06<01:46,  9.54it/s]  5%|▌         | 55/1070 [00:06<01:45,  9.63it/s]  5%|▌         | 56/1070 [00:06<01:45,  9.60it/s]  5%|▌         | 57/1070 [00:06<01:45,  9.60it/s]  5%|▌         | 58/1070 [00:07<01:44,  9.66it/s]  6%|▌         | 59/1070 [00:07<01:45,  9.59it/s]  6%|▌         | 60/1070 [00:07<01:46,  9.48it/s]  6%|▌         | 61/1070 [00:07<01:46,  9.47it/s]  6%|▌         | 63/1070 [00:07<01:45,  9.59it/s]  6%|▌         | 64/1070 [00:07<01:45,  9.53it/s]  6%|▌         | 65/1070 [00:07<01:45,  9.57it/s]  6%|▌         | 66/1070 [00:07<01:45,  9.55it/s]  6%|▋         | 67/1070 [00:08<01:44,  9.61it/s]  6%|▋         | 68/1070 [00:08<01:44,  9.60it/s]  7%|▋         | 70/1070 [00:08<01:43,  9.66it/s]  7%|▋         | 71/1070 [00:08<01:43,  9.61it/s]  7%|▋         | 72/1070 [00:08<01:43,  9.65it/s]  7%|▋         | 73/1070 [00:08<01:43,  9.66it/s]  7%|▋         | 74/1070 [00:08<01:43,  9.66it/s]  7%|▋         | 75/1070 [00:08<01:43,  9.65it/s]  7%|▋         | 77/1070 [00:09<01:42,  9.70it/s]  7%|▋         | 78/1070 [00:09<01:43,  9.61it/s]  7%|▋         | 79/1070 [00:09<01:43,  9.61it/s]  7%|▋         | 80/1070 [00:09<01:42,  9.63it/s]  8%|▊         | 81/1070 [00:09<01:42,  9.67it/s]  8%|▊         | 82/1070 [00:09<01:42,  9.65it/s]  8%|▊         | 83/1070 [00:09<01:41,  9.70it/s]  8%|▊         | 84/1070 [00:09<01:41,  9.67it/s]  8%|▊         | 85/1070 [00:09<01:42,  9.57it/s]  8%|▊         | 86/1070 [00:10<01:43,  9.54it/s]  8%|▊         | 87/1070 [00:10<01:42,  9.58it/s]  8%|▊         | 88/1070 [00:10<01:41,  9.67it/s]  8%|▊         | 89/1070 [00:10<01:42,  9.62it/s]  8%|▊         | 90/1070 [00:10<01:41,  9.67it/s]  9%|▊         | 91/1070 [00:10<01:41,  9.63it/s]  9%|▊         | 92/1070 [00:10<01:42,  9.58it/s]  9%|▊         | 93/1070 [00:10<01:41,  9.59it/s]  9%|▉         | 95/1070 [00:10<01:40,  9.69it/s]  9%|▉         | 96/1070 [00:11<01:40,  9.67it/s]  9%|▉         | 97/1070 [00:11<01:40,  9.65it/s]  9%|▉         | 98/1070 [00:11<01:40,  9.64it/s]  9%|▉         | 99/1070 [00:11<01:41,  9.55it/s]  9%|▉         | 100/1070 [00:11<01:42,  9.48it/s] 10%|▉         | 102/1070 [00:11<01:40,  9.65it/s] 10%|▉         | 103/1070 [00:11<01:40,  9.66it/s] 10%|▉         | 104/1070 [00:11<01:40,  9.63it/s] 10%|▉         | 105/1070 [00:11<01:40,  9.62it/s] 10%|▉         | 106/1070 [00:12<01:40,  9.57it/s] 10%|█         | 107/1070 [00:12<01:40,  9.57it/s] 10%|█         | 109/1070 [00:12<01:39,  9.62it/s] 10%|█         | 110/1070 [00:12<01:40,  9.59it/s] 10%|█         | 111/1070 [00:12<01:40,  9.55it/s] 10%|█         | 112/1070 [00:12<01:40,  9.50it/s] 11%|█         | 113/1070 [00:12<01:40,  9.49it/s] 11%|█         | 114/1070 [00:12<01:41,  9.46it/s] 11%|█         | 115/1070 [00:13<01:39,  9.60it/s] 11%|█         | 116/1070 [00:13<01:39,  9.59it/s] 11%|█         | 117/1070 [00:13<01:41,  9.43it/s] 11%|█         | 118/1070 [00:13<01:41,  9.38it/s] 11%|█         | 119/1070 [00:13<01:40,  9.50it/s] 11%|█         | 120/1070 [00:13<01:40,  9.44it/s] 11%|█▏        | 121/1070 [00:13<01:40,  9.40it/s] 11%|█▏        | 122/1070 [00:13<01:40,  9.43it/s] 11%|█▏        | 123/1070 [00:13<01:40,  9.41it/s] 12%|█▏        | 124/1070 [00:13<01:41,  9.33it/s] 12%|█▏        | 125/1070 [00:14<01:41,  9.29it/s] 12%|█▏        | 126/1070 [00:14<01:39,  9.45it/s] 12%|█▏        | 127/1070 [00:14<01:40,  9.41it/s] 12%|█▏        | 128/1070 [00:14<01:40,  9.39it/s] 12%|█▏        | 129/1070 [00:14<01:40,  9.40it/s] 12%|█▏        | 130/1070 [00:14<01:39,  9.46it/s] 12%|█▏        | 131/1070 [00:14<01:39,  9.43it/s] 12%|█▏        | 132/1070 [00:14<01:41,  9.28it/s] 12%|█▏        | 133/1070 [00:14<01:39,  9.43it/s] 13%|█▎        | 134/1070 [00:15<01:39,  9.37it/s] 13%|█▎        | 135/1070 [00:15<01:40,  9.29it/s] 13%|█▎        | 136/1070 [00:15<01:40,  9.31it/s] 13%|█▎        | 138/1070 [00:15<01:38,  9.50it/s] 13%|█▎        | 139/1070 [00:15<01:38,  9.42it/s] 13%|█▎        | 140/1070 [00:15<01:38,  9.40it/s] 13%|█▎        | 141/1070 [00:15<01:37,  9.52it/s] 13%|█▎        | 142/1070 [00:15<01:37,  9.49it/s] 13%|█▎        | 143/1070 [00:15<01:37,  9.49it/s] 13%|█▎        | 144/1070 [00:16<01:37,  9.53it/s] 14%|█▎        | 145/1070 [00:16<01:37,  9.53it/s] 14%|█▎        | 146/1070 [00:16<01:38,  9.35it/s] 14%|█▎        | 147/1070 [00:16<01:39,  9.31it/s] 14%|█▍        | 149/1070 [00:16<01:37,  9.40it/s] 14%|█▍        | 150/1070 [00:16<01:38,  9.35it/s] 14%|█▍        | 151/1070 [00:16<01:38,  9.32it/s] 14%|█▍        | 152/1070 [00:16<01:37,  9.45it/s] 14%|█▍        | 153/1070 [00:17<01:38,  9.35it/s] 14%|█▍        | 154/1070 [00:17<01:37,  9.37it/s] 14%|█▍        | 155/1070 [00:17<01:37,  9.38it/s] 15%|█▍        | 156/1070 [00:17<01:36,  9.47it/s] 15%|█▍        | 157/1070 [00:17<01:37,  9.41it/s] 15%|█▍        | 158/1070 [00:17<01:37,  9.37it/s] 15%|█▍        | 160/1070 [00:17<01:36,  9.45it/s] 15%|█▌        | 161/1070 [00:17<01:37,  9.36it/s] 15%|█▌        | 162/1070 [00:18<01:37,  9.35it/s] 15%|█▌        | 163/1070 [00:18<01:35,  9.50it/s] 15%|█▌        | 164/1070 [00:18<01:36,  9.37it/s] 15%|█▌        | 165/1070 [00:18<01:36,  9.36it/s] 16%|█▌        | 166/1070 [00:18<01:36,  9.37it/s] 16%|█▌        | 167/1070 [00:18<01:36,  9.39it/s] 16%|█▌        | 168/1070 [00:18<01:37,  9.26it/s] 16%|█▌        | 169/1070 [00:18<01:37,  9.26it/s] 16%|█▌        | 171/1070 [00:18<01:35,  9.38it/s] 16%|█▌        | 172/1070 [00:19<01:35,  9.37it/s] 16%|█▌        | 173/1070 [00:19<01:35,  9.35it/s] 16%|█▋        | 174/1070 [00:19<01:34,  9.45it/s] 16%|█▋        | 175/1070 [00:19<01:35,  9.38it/s] 16%|█▋        | 176/1070 [00:19<01:35,  9.33it/s] 17%|█▋        | 177/1070 [00:19<01:34,  9.45it/s] 17%|█▋        | 178/1070 [00:19<01:34,  9.44it/s] 17%|█▋        | 179/1070 [00:19<01:35,  9.32it/s] 17%|█▋        | 180/1070 [00:19<01:35,  9.27it/s] 17%|█▋        | 181/1070 [00:20<01:34,  9.41it/s] 17%|█▋        | 182/1070 [00:20<01:34,  9.38it/s] 17%|█▋        | 183/1070 [00:20<01:35,  9.30it/s] 17%|█▋        | 184/1070 [00:20<01:35,  9.31it/s] 17%|█▋        | 185/1070 [00:20<01:34,  9.39it/s] 17%|█▋        | 186/1070 [00:20<01:34,  9.39it/s] 17%|█▋        | 187/1070 [00:20<01:35,  9.29it/s] 18%|█▊        | 188/1070 [00:20<01:33,  9.39it/s] 18%|█▊        | 189/1070 [00:20<01:34,  9.35it/s] 18%|█▊        | 190/1070 [00:21<01:35,  9.23it/s] 18%|█▊        | 191/1070 [00:21<01:35,  9.24it/s] 18%|█▊        | 192/1070 [00:21<01:34,  9.33it/s] 18%|█▊        | 193/1070 [00:21<01:34,  9.25it/s] 18%|█▊        | 194/1070 [00:21<01:35,  9.21it/s] 18%|█▊        | 195/1070 [00:21<01:34,  9.22it/s] 18%|█▊        | 196/1070 [00:21<01:34,  9.28it/s] 18%|█▊        | 197/1070 [00:21<01:34,  9.24it/s] 19%|█▊        | 198/1070 [00:21<01:34,  9.24it/s] 19%|█▊        | 199/1070 [00:21<01:33,  9.31it/s] 19%|█▊        | 200/1070 [00:22<01:34,  9.21it/s] 19%|█▉        | 201/1070 [00:22<01:34,  9.16it/s] 19%|█▉        | 202/1070 [00:22<01:35,  9.13it/s] 19%|█▉        | 203/1070 [00:22<01:32,  9.36it/s] 19%|█▉        | 204/1070 [00:22<01:33,  9.25it/s] 19%|█▉        | 205/1070 [00:22<01:33,  9.23it/s] 19%|█▉        | 206/1070 [00:22<01:33,  9.21it/s] 19%|█▉        | 207/1070 [00:22<01:32,  9.33it/s] 19%|█▉        | 208/1070 [00:22<01:32,  9.34it/s] 20%|█▉        | 209/1070 [00:23<01:33,  9.23it/s] 20%|█▉        | 210/1070 [00:23<01:32,  9.31it/s] 20%|█▉        | 211/1070 [00:23<01:32,  9.28it/s] 20%|█▉        | 212/1070 [00:23<01:32,  9.27it/s] 20%|█▉        | 213/1070 [00:23<01:32,  9.29it/s]                                                   20%|██        | 214/1070 [00:23<01:32,  9.29it/s][INFO|trainer.py:755] 2023-11-15 21:13:15,277 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:13:15,279 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:13:15,279 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:13:15,279 >>   Batch size = 8
{'loss': 0.5068, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 81.33it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 77.17it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 76.36it/s][A
 37%|███▋      | 35/95 [00:00<00:00, 78.32it/s][A
 45%|████▌     | 43/95 [00:00<00:00, 76.42it/s][A
 54%|█████▎    | 51/95 [00:00<00:00, 73.63it/s][A
 62%|██████▏   | 59/95 [00:00<00:00, 75.19it/s][A
 71%|███████   | 67/95 [00:00<00:00, 75.67it/s][A
 79%|███████▉  | 75/95 [00:00<00:00, 74.67it/s][A
 87%|████████▋ | 83/95 [00:01<00:00, 74.04it/s][A
 97%|█████████▋| 92/95 [00:01<00:00, 76.20it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:24<01:32,  9.29it/s]
100%|██████████| 95/95 [00:01<00:00, 76.20it/s][A
                                               [A 20%|██        | 215/1070 [00:25<05:46,  2.47it/s] 20%|██        | 216/1070 [00:25<04:43,  3.01it/s] 20%|██        | 217/1070 [00:25<03:52,  3.67it/s] 20%|██        | 218/1070 [00:25<03:14,  4.37it/s] 20%|██        | 219/1070 [00:25<02:46,  5.12it/s] 21%|██        | 220/1070 [00:25<02:24,  5.88it/s] 21%|██        | 221/1070 [00:25<02:09,  6.56it/s] 21%|██        | 222/1070 [00:25<01:57,  7.19it/s] 21%|██        | 223/1070 [00:25<01:50,  7.65it/s] 21%|██        | 224/1070 [00:25<01:44,  8.13it/s] 21%|██        | 225/1070 [00:26<01:40,  8.39it/s] 21%|██        | 226/1070 [00:26<01:38,  8.56it/s] 21%|██        | 227/1070 [00:26<01:36,  8.69it/s] 21%|██▏       | 228/1070 [00:26<01:34,  8.94it/s] 21%|██▏       | 229/1070 [00:26<01:33,  8.99it/s] 21%|██▏       | 230/1070 [00:26<01:33,  8.95it/s] 22%|██▏       | 231/1070 [00:26<01:33,  8.98it/s] 22%|██▏       | 232/1070 [00:26<01:32,  9.06it/s] 22%|██▏       | 233/1070 [00:26<01:33,  8.97it/s] 22%|██▏       | 234/1070 [00:27<01:32,  9.07it/s] 22%|██▏       | 235/1070 [00:27<01:30,  9.19it/s] 22%|██▏       | 236/1070 [00:27<01:31,  9.07it/s] 22%|██▏       | 237/1070 [00:27<01:30,  9.17it/s] 22%|██▏       | 238/1070 [00:27<01:31,  9.08it/s] 22%|██▏       | 239/1070 [00:27<01:29,  9.30it/s] 22%|██▏       | 240/1070 [00:27<01:30,  9.19it/s] 23%|██▎       | 241/1070 [00:27<01:30,  9.15it/s] 23%|██▎       | 242/1070 [00:27<01:29,  9.22it/s] 23%|██▎       | 243/1070 [00:28<01:29,  9.25it/s] 23%|██▎       | 244/1070 [00:28<01:28,  9.29it/s] 23%|██▎       | 245/1070 [00:28<01:30,  9.16it/s] 23%|██▎       | 246/1070 [00:28<01:29,  9.22it/s] 23%|██▎       | 247/1070 [00:28<01:29,  9.18it/s] 23%|██▎       | 248/1070 [00:28<01:30,  9.13it/s] 23%|██▎       | 249/1070 [00:28<01:29,  9.13it/s] 23%|██▎       | 250/1070 [00:28<01:28,  9.29it/s] 23%|██▎       | 251/1070 [00:28<01:28,  9.29it/s] 24%|██▎       | 252/1070 [00:29<01:29,  9.17it/s] 24%|██▎       | 253/1070 [00:29<01:27,  9.30it/s] 24%|██▎       | 254/1070 [00:29<01:27,  9.33it/s] 24%|██▍       | 255/1070 [00:29<01:27,  9.32it/s] 24%|██▍       | 256/1070 [00:29<01:27,  9.26it/s] 24%|██▍       | 257/1070 [00:29<01:26,  9.36it/s] 24%|██▍       | 258/1070 [00:29<01:27,  9.32it/s] 24%|██▍       | 259/1070 [00:29<01:27,  9.29it/s] 24%|██▍       | 260/1070 [00:29<01:26,  9.32it/s] 24%|██▍       | 261/1070 [00:29<01:25,  9.47it/s] 24%|██▍       | 262/1070 [00:30<01:26,  9.38it/s] 25%|██▍       | 263/1070 [00:30<01:26,  9.35it/s] 25%|██▍       | 264/1070 [00:30<01:26,  9.31it/s] 25%|██▍       | 265/1070 [00:30<01:26,  9.33it/s] 25%|██▍       | 266/1070 [00:30<01:25,  9.35it/s] 25%|██▍       | 267/1070 [00:30<01:26,  9.30it/s] 25%|██▌       | 268/1070 [00:30<01:24,  9.47it/s] 25%|██▌       | 269/1070 [00:30<01:25,  9.37it/s] 25%|██▌       | 270/1070 [00:30<01:25,  9.31it/s] 25%|██▌       | 271/1070 [00:31<01:25,  9.29it/s] 25%|██▌       | 272/1070 [00:31<01:24,  9.45it/s] 26%|██▌       | 273/1070 [00:31<01:25,  9.34it/s] 26%|██▌       | 274/1070 [00:31<01:25,  9.30it/s] 26%|██▌       | 275/1070 [00:31<01:25,  9.27it/s] 26%|██▌       | 276/1070 [00:31<01:24,  9.39it/s] 26%|██▌       | 277/1070 [00:31<01:24,  9.35it/s] 26%|██▌       | 278/1070 [00:31<01:25,  9.25it/s] 26%|██▌       | 279/1070 [00:31<01:25,  9.25it/s] 26%|██▌       | 280/1070 [00:32<01:25,  9.22it/s] 26%|██▋       | 281/1070 [00:32<01:25,  9.18it/s] 26%|██▋       | 282/1070 [00:32<01:26,  9.13it/s] 26%|██▋       | 283/1070 [00:32<01:24,  9.33it/s] 27%|██▋       | 284/1070 [00:32<01:25,  9.23it/s] 27%|██▋       | 285/1070 [00:32<01:25,  9.18it/s] 27%|██▋       | 286/1070 [00:32<01:25,  9.17it/s] 27%|██▋       | 287/1070 [00:32<01:23,  9.33it/s] 27%|██▋       | 288/1070 [00:32<01:25,  9.19it/s] 27%|██▋       | 289/1070 [00:33<01:25,  9.19it/s] 27%|██▋       | 290/1070 [00:33<01:24,  9.21it/s] 27%|██▋       | 291/1070 [00:33<01:23,  9.36it/s] 27%|██▋       | 292/1070 [00:33<01:23,  9.32it/s] 27%|██▋       | 293/1070 [00:33<01:23,  9.34it/s] 27%|██▋       | 294/1070 [00:33<01:23,  9.33it/s] 28%|██▊       | 295/1070 [00:33<01:23,  9.28it/s] 28%|██▊       | 296/1070 [00:33<01:23,  9.30it/s] 28%|██▊       | 297/1070 [00:33<01:23,  9.30it/s] 28%|██▊       | 298/1070 [00:33<01:22,  9.31it/s] 28%|██▊       | 299/1070 [00:34<01:23,  9.23it/s] 28%|██▊       | 300/1070 [00:34<01:24,  9.12it/s] 28%|██▊       | 301/1070 [00:34<01:23,  9.17it/s] 28%|██▊       | 302/1070 [00:34<01:22,  9.33it/s] 28%|██▊       | 303/1070 [00:34<01:22,  9.26it/s] 28%|██▊       | 304/1070 [00:34<01:22,  9.26it/s] 29%|██▊       | 305/1070 [00:34<01:23,  9.21it/s] 29%|██▊       | 306/1070 [00:34<01:22,  9.31it/s] 29%|██▊       | 307/1070 [00:34<01:22,  9.29it/s] 29%|██▉       | 308/1070 [00:35<01:22,  9.26it/s] 29%|██▉       | 309/1070 [00:35<01:22,  9.26it/s] 29%|██▉       | 310/1070 [00:35<01:22,  9.23it/s] 29%|██▉       | 311/1070 [00:35<01:21,  9.29it/s] 29%|██▉       | 312/1070 [00:35<01:22,  9.22it/s] 29%|██▉       | 313/1070 [00:35<01:21,  9.33it/s] 29%|██▉       | 314/1070 [00:35<01:21,  9.23it/s] 29%|██▉       | 315/1070 [00:35<01:21,  9.28it/s] 30%|██▉       | 316/1070 [00:35<01:21,  9.27it/s] 30%|██▉       | 317/1070 [00:36<01:21,  9.28it/s] 30%|██▉       | 318/1070 [00:36<01:20,  9.37it/s] 30%|██▉       | 319/1070 [00:36<01:20,  9.34it/s] 30%|██▉       | 320/1070 [00:36<01:19,  9.40it/s] 30%|███       | 321/1070 [00:36<01:20,  9.25it/s] 30%|███       | 322/1070 [00:36<01:20,  9.25it/s] 30%|███       | 323/1070 [00:36<01:20,  9.29it/s] 30%|███       | 324/1070 [00:36<01:18,  9.44it/s] 30%|███       | 325/1070 [00:36<01:19,  9.33it/s] 30%|███       | 326/1070 [00:36<01:19,  9.31it/s] 31%|███       | 327/1070 [00:37<01:19,  9.35it/s] 31%|███       | 328/1070 [00:37<01:19,  9.32it/s] 31%|███       | 329/1070 [00:37<01:19,  9.32it/s] 31%|███       | 330/1070 [00:37<01:19,  9.25it/s] 31%|███       | 331/1070 [00:37<01:18,  9.45it/s] 31%|███       | 332/1070 [00:37<01:19,  9.31it/s] 31%|███       | 333/1070 [00:37<01:19,  9.26it/s] 31%|███       | 334/1070 [00:37<01:19,  9.26it/s] 31%|███▏      | 335/1070 [00:37<01:18,  9.39it/s] 31%|███▏      | 336/1070 [00:38<01:19,  9.27it/s] 31%|███▏      | 337/1070 [00:38<01:18,  9.30it/s] 32%|███▏      | 338/1070 [00:38<01:19,  9.26it/s] 32%|███▏      | 339/1070 [00:38<01:18,  9.32it/s] 32%|███▏      | 340/1070 [00:38<01:18,  9.35it/s] 32%|███▏      | 341/1070 [00:38<01:17,  9.36it/s] 32%|███▏      | 342/1070 [00:38<01:17,  9.44it/s] 32%|███▏      | 343/1070 [00:38<01:17,  9.34it/s] 32%|███▏      | 344/1070 [00:38<01:18,  9.28it/s] 32%|███▏      | 345/1070 [00:39<01:18,  9.26it/s] 32%|███▏      | 347/1070 [00:39<01:16,  9.40it/s] 33%|███▎      | 348/1070 [00:39<01:16,  9.40it/s] 33%|███▎      | 349/1070 [00:39<01:16,  9.45it/s] 33%|███▎      | 350/1070 [00:39<01:16,  9.41it/s] 33%|███▎      | 351/1070 [00:39<01:16,  9.41it/s] 33%|███▎      | 352/1070 [00:39<01:16,  9.40it/s] 33%|███▎      | 353/1070 [00:39<01:15,  9.55it/s] 33%|███▎      | 354/1070 [00:39<01:15,  9.49it/s] 33%|███▎      | 355/1070 [00:40<01:15,  9.44it/s] 33%|███▎      | 356/1070 [00:40<01:15,  9.40it/s] 33%|███▎      | 357/1070 [00:40<01:15,  9.48it/s] 33%|███▎      | 358/1070 [00:40<01:15,  9.44it/s] 34%|███▎      | 359/1070 [00:40<01:15,  9.41it/s] 34%|███▎      | 360/1070 [00:40<01:14,  9.47it/s] 34%|███▎      | 361/1070 [00:40<01:14,  9.46it/s] 34%|███▍      | 362/1070 [00:40<01:15,  9.39it/s] 34%|███▍      | 363/1070 [00:40<01:15,  9.39it/s] 34%|███▍      | 364/1070 [00:41<01:14,  9.51it/s] 34%|███▍      | 365/1070 [00:41<01:14,  9.42it/s] 34%|███▍      | 366/1070 [00:41<01:15,  9.35it/s] 34%|███▍      | 367/1070 [00:41<01:15,  9.26it/s] 34%|███▍      | 368/1070 [00:41<01:16,  9.22it/s] 34%|███▍      | 369/1070 [00:41<01:15,  9.25it/s] 35%|███▍      | 370/1070 [00:41<01:16,  9.12it/s] 35%|███▍      | 371/1070 [00:41<01:15,  9.28it/s] 35%|███▍      | 372/1070 [00:41<01:15,  9.24it/s] 35%|███▍      | 373/1070 [00:42<01:15,  9.27it/s] 35%|███▍      | 374/1070 [00:42<01:14,  9.30it/s] 35%|███▌      | 375/1070 [00:42<01:13,  9.47it/s] 35%|███▌      | 376/1070 [00:42<01:13,  9.39it/s] 35%|███▌      | 377/1070 [00:42<01:13,  9.39it/s] 35%|███▌      | 378/1070 [00:42<01:12,  9.50it/s] 35%|███▌      | 379/1070 [00:42<01:13,  9.46it/s] 36%|███▌      | 380/1070 [00:42<01:12,  9.46it/s] 36%|███▌      | 381/1070 [00:42<01:13,  9.43it/s] 36%|███▌      | 382/1070 [00:42<01:12,  9.54it/s] 36%|███▌      | 383/1070 [00:43<01:13,  9.39it/s] 36%|███▌      | 384/1070 [00:43<01:12,  9.42it/s] 36%|███▌      | 385/1070 [00:43<01:12,  9.46it/s] 36%|███▌      | 386/1070 [00:43<01:12,  9.43it/s] 36%|███▌      | 387/1070 [00:43<01:12,  9.42it/s] 36%|███▋      | 388/1070 [00:43<01:12,  9.41it/s] 36%|███▋      | 389/1070 [00:43<01:11,  9.58it/s] 36%|███▋      | 390/1070 [00:43<01:12,  9.44it/s] 37%|███▋      | 391/1070 [00:43<01:11,  9.44it/s] 37%|███▋      | 392/1070 [00:44<01:11,  9.49it/s] 37%|███▋      | 393/1070 [00:44<01:11,  9.43it/s] 37%|███▋      | 394/1070 [00:44<01:11,  9.39it/s] 37%|███▋      | 395/1070 [00:44<01:11,  9.38it/s] 37%|███▋      | 396/1070 [00:44<01:10,  9.52it/s] 37%|███▋      | 397/1070 [00:44<01:11,  9.38it/s] 37%|███▋      | 398/1070 [00:44<01:11,  9.36it/s] 37%|███▋      | 399/1070 [00:44<01:11,  9.38it/s] 37%|███▋      | 400/1070 [00:44<01:11,  9.37it/s] 37%|███▋      | 401/1070 [00:44<01:11,  9.39it/s] 38%|███▊      | 402/1070 [00:45<01:11,  9.40it/s] 38%|███▊      | 403/1070 [00:45<01:10,  9.50it/s] 38%|███▊      | 404/1070 [00:45<01:10,  9.45it/s] 38%|███▊      | 405/1070 [00:45<01:11,  9.33it/s] 38%|███▊      | 406/1070 [00:45<01:10,  9.36it/s] 38%|███▊      | 407/1070 [00:45<01:10,  9.41it/s] 38%|███▊      | 408/1070 [00:45<01:10,  9.45it/s] 38%|███▊      | 409/1070 [00:45<01:09,  9.47it/s] 38%|███▊      | 410/1070 [00:45<01:08,  9.59it/s] 38%|███▊      | 411/1070 [00:46<01:08,  9.58it/s] 39%|███▊      | 412/1070 [00:46<01:09,  9.50it/s] 39%|███▊      | 413/1070 [00:46<01:09,  9.48it/s] 39%|███▊      | 414/1070 [00:46<01:09,  9.49it/s] 39%|███▉      | 415/1070 [00:46<01:08,  9.59it/s] 39%|███▉      | 416/1070 [00:46<01:09,  9.47it/s] 39%|███▉      | 417/1070 [00:46<01:08,  9.59it/s] 39%|███▉      | 418/1070 [00:46<01:08,  9.49it/s] 39%|███▉      | 419/1070 [00:46<01:08,  9.46it/s] 39%|███▉      | 420/1070 [00:46<01:08,  9.46it/s] 39%|███▉      | 421/1070 [00:47<01:08,  9.42it/s] 39%|███▉      | 422/1070 [00:47<01:08,  9.45it/s] 40%|███▉      | 423/1070 [00:47<01:08,  9.41it/s] 40%|███▉      | 424/1070 [00:47<01:08,  9.49it/s] 40%|███▉      | 425/1070 [00:47<01:08,  9.40it/s] 40%|███▉      | 426/1070 [00:47<01:08,  9.40it/s] 40%|███▉      | 427/1070 [00:47<01:08,  9.44it/s]                                                   40%|████      | 428/1070 [00:47<01:08,  9.44it/s][INFO|trainer.py:755] 2023-11-15 21:13:39,510 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:13:39,512 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:13:39,513 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:13:39,513 >>   Batch size = 8
{'eval_loss': 0.3045596182346344, 'eval_accuracy': 0.8973684210526316, 'eval_micro_f1': 0.8973684210526317, 'eval_macro_f1': 0.8937371486459671, 'eval_runtime': 1.3003, 'eval_samples_per_second': 584.484, 'eval_steps_per_second': 73.06, 'epoch': 1.0}
{'loss': 0.2305, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 84.72it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 79.88it/s][A
 28%|██▊       | 27/95 [00:00<00:00, 81.11it/s][A
 38%|███▊      | 36/95 [00:00<00:00, 78.26it/s][A
 46%|████▋     | 44/95 [00:00<00:00, 76.95it/s][A
 56%|█████▌    | 53/95 [00:00<00:00, 79.30it/s][A
 64%|██████▍   | 61/95 [00:00<00:00, 78.06it/s][A
 73%|███████▎  | 69/95 [00:00<00:00, 76.62it/s][A
 81%|████████  | 77/95 [00:00<00:00, 76.04it/s][A
 91%|█████████ | 86/95 [00:01<00:00, 78.08it/s][A
 99%|█████████▉| 94/95 [00:01<00:00, 76.34it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:49<01:08,  9.44it/s]
100%|██████████| 95/95 [00:01<00:00, 76.34it/s][A
                                               [A 40%|████      | 429/1070 [00:49<04:13,  2.52it/s] 40%|████      | 430/1070 [00:49<03:26,  3.09it/s] 40%|████      | 431/1070 [00:49<02:50,  3.74it/s] 40%|████      | 432/1070 [00:49<02:22,  4.46it/s] 40%|████      | 433/1070 [00:49<02:01,  5.24it/s] 41%|████      | 434/1070 [00:49<01:46,  5.98it/s] 41%|████      | 435/1070 [00:49<01:35,  6.68it/s] 41%|████      | 436/1070 [00:49<01:27,  7.22it/s] 41%|████      | 437/1070 [00:50<01:20,  7.83it/s] 41%|████      | 438/1070 [00:50<01:17,  8.19it/s] 41%|████      | 439/1070 [00:50<01:14,  8.47it/s] 41%|████      | 440/1070 [00:50<01:12,  8.70it/s] 41%|████      | 441/1070 [00:50<01:11,  8.83it/s] 41%|████▏     | 442/1070 [00:50<01:09,  8.99it/s] 41%|████▏     | 443/1070 [00:50<01:09,  9.06it/s] 41%|████▏     | 444/1070 [00:50<01:07,  9.27it/s] 42%|████▏     | 445/1070 [00:50<01:07,  9.20it/s] 42%|████▏     | 446/1070 [00:51<01:08,  9.16it/s] 42%|████▏     | 447/1070 [00:51<01:07,  9.24it/s] 42%|████▏     | 448/1070 [00:51<01:06,  9.37it/s] 42%|████▏     | 449/1070 [00:51<01:06,  9.33it/s] 42%|████▏     | 450/1070 [00:51<01:06,  9.34it/s] 42%|████▏     | 451/1070 [00:51<01:05,  9.43it/s] 42%|████▏     | 452/1070 [00:51<01:05,  9.42it/s] 42%|████▏     | 453/1070 [00:51<01:06,  9.32it/s] 42%|████▏     | 454/1070 [00:51<01:05,  9.35it/s] 43%|████▎     | 455/1070 [00:51<01:04,  9.48it/s] 43%|████▎     | 456/1070 [00:52<01:05,  9.34it/s] 43%|████▎     | 457/1070 [00:52<01:05,  9.36it/s] 43%|████▎     | 458/1070 [00:52<01:04,  9.44it/s] 43%|████▎     | 459/1070 [00:52<01:05,  9.39it/s] 43%|████▎     | 460/1070 [00:52<01:04,  9.40it/s] 43%|████▎     | 461/1070 [00:52<01:05,  9.36it/s] 43%|████▎     | 462/1070 [00:52<01:03,  9.52it/s] 43%|████▎     | 463/1070 [00:52<01:04,  9.37it/s] 43%|████▎     | 464/1070 [00:52<01:04,  9.36it/s] 43%|████▎     | 465/1070 [00:53<01:04,  9.35it/s] 44%|████▎     | 466/1070 [00:53<01:04,  9.34it/s] 44%|████▎     | 467/1070 [00:53<01:03,  9.45it/s] 44%|████▎     | 468/1070 [00:53<01:04,  9.34it/s] 44%|████▍     | 469/1070 [00:53<01:03,  9.51it/s] 44%|████▍     | 470/1070 [00:53<01:03,  9.45it/s] 44%|████▍     | 471/1070 [00:53<01:03,  9.39it/s] 44%|████▍     | 472/1070 [00:53<01:03,  9.38it/s] 44%|████▍     | 473/1070 [00:53<01:03,  9.39it/s] 44%|████▍     | 474/1070 [00:54<01:03,  9.43it/s] 44%|████▍     | 475/1070 [00:54<01:03,  9.37it/s] 44%|████▍     | 476/1070 [00:54<01:02,  9.52it/s] 45%|████▍     | 477/1070 [00:54<01:02,  9.46it/s] 45%|████▍     | 478/1070 [00:54<01:02,  9.45it/s] 45%|████▍     | 479/1070 [00:54<01:02,  9.40it/s] 45%|████▍     | 480/1070 [00:54<01:02,  9.46it/s] 45%|████▍     | 481/1070 [00:54<01:02,  9.49it/s] 45%|████▌     | 482/1070 [00:54<01:02,  9.46it/s] 45%|████▌     | 483/1070 [00:54<01:01,  9.54it/s] 45%|████▌     | 484/1070 [00:55<01:01,  9.46it/s] 45%|████▌     | 485/1070 [00:55<01:02,  9.40it/s] 45%|████▌     | 486/1070 [00:55<01:02,  9.35it/s] 46%|████▌     | 487/1070 [00:55<01:02,  9.39it/s] 46%|████▌     | 488/1070 [00:55<01:01,  9.44it/s] 46%|████▌     | 489/1070 [00:55<01:01,  9.43it/s] 46%|████▌     | 490/1070 [00:55<01:00,  9.55it/s] 46%|████▌     | 491/1070 [00:55<01:01,  9.43it/s] 46%|████▌     | 492/1070 [00:55<01:01,  9.44it/s] 46%|████▌     | 493/1070 [00:56<01:00,  9.47it/s] 46%|████▌     | 494/1070 [00:56<01:00,  9.49it/s] 46%|████▋     | 495/1070 [00:56<01:01,  9.42it/s] 46%|████▋     | 496/1070 [00:56<01:00,  9.45it/s] 46%|████▋     | 497/1070 [00:56<01:00,  9.50it/s] 47%|████▋     | 498/1070 [00:56<01:00,  9.48it/s] 47%|████▋     | 499/1070 [00:56<00:59,  9.53it/s] 47%|████▋     | 500/1070 [00:56<00:59,  9.61it/s] 47%|████▋     | 501/1070 [00:56<00:59,  9.58it/s] 47%|████▋     | 502/1070 [00:56<00:59,  9.56it/s] 47%|████▋     | 503/1070 [00:57<00:59,  9.56it/s] 47%|████▋     | 504/1070 [00:57<00:59,  9.52it/s] 47%|████▋     | 505/1070 [00:57<00:59,  9.49it/s] 47%|████▋     | 506/1070 [00:57<00:59,  9.53it/s] 47%|████▋     | 507/1070 [00:57<00:58,  9.56it/s] 47%|████▋     | 508/1070 [00:57<00:59,  9.50it/s] 48%|████▊     | 509/1070 [00:57<00:59,  9.45it/s] 48%|████▊     | 510/1070 [00:57<00:58,  9.50it/s] 48%|████▊     | 511/1070 [00:57<00:59,  9.44it/s] 48%|████▊     | 512/1070 [00:58<00:59,  9.42it/s] 48%|████▊     | 513/1070 [00:58<00:59,  9.41it/s] 48%|████▊     | 514/1070 [00:58<00:59,  9.40it/s] 48%|████▊     | 515/1070 [00:58<00:59,  9.32it/s] 48%|████▊     | 516/1070 [00:58<00:59,  9.32it/s] 48%|████▊     | 517/1070 [00:58<00:59,  9.32it/s] 48%|████▊     | 518/1070 [00:58<00:58,  9.36it/s] 49%|████▊     | 519/1070 [00:58<00:58,  9.38it/s] 49%|████▊     | 520/1070 [00:58<00:57,  9.48it/s] 49%|████▊     | 521/1070 [00:58<00:58,  9.40it/s] 49%|████▉     | 522/1070 [00:59<00:57,  9.46it/s] 49%|████▉     | 523/1070 [00:59<00:58,  9.40it/s] 49%|████▉     | 524/1070 [00:59<00:58,  9.39it/s] 49%|████▉     | 525/1070 [00:59<00:57,  9.43it/s] 49%|████▉     | 526/1070 [00:59<00:58,  9.38it/s] 49%|████▉     | 527/1070 [00:59<00:57,  9.50it/s] 49%|████▉     | 528/1070 [00:59<00:57,  9.42it/s] 49%|████▉     | 529/1070 [00:59<00:57,  9.36it/s] 50%|████▉     | 530/1070 [00:59<00:57,  9.41it/s] 50%|████▉     | 531/1070 [01:00<00:57,  9.37it/s] 50%|████▉     | 532/1070 [01:00<00:57,  9.32it/s] 50%|████▉     | 533/1070 [01:00<00:57,  9.37it/s] 50%|████▉     | 534/1070 [01:00<00:57,  9.40it/s] 50%|█████     | 535/1070 [01:00<00:57,  9.37it/s] 50%|█████     | 536/1070 [01:00<00:56,  9.39it/s] 50%|█████     | 537/1070 [01:00<00:56,  9.37it/s] 50%|█████     | 538/1070 [01:00<00:56,  9.38it/s] 50%|█████     | 539/1070 [01:00<00:56,  9.35it/s] 50%|█████     | 540/1070 [01:00<00:56,  9.37it/s] 51%|█████     | 541/1070 [01:01<00:56,  9.41it/s] 51%|█████     | 542/1070 [01:01<00:56,  9.34it/s] 51%|█████     | 543/1070 [01:01<00:56,  9.36it/s] 51%|█████     | 544/1070 [01:01<00:56,  9.39it/s] 51%|█████     | 545/1070 [01:01<00:55,  9.38it/s] 51%|█████     | 546/1070 [01:01<00:55,  9.39it/s] 51%|█████     | 547/1070 [01:01<00:55,  9.44it/s] 51%|█████     | 548/1070 [01:01<00:55,  9.40it/s] 51%|█████▏    | 549/1070 [01:01<00:55,  9.38it/s] 51%|█████▏    | 550/1070 [01:02<00:56,  9.27it/s] 51%|█████▏    | 551/1070 [01:02<00:56,  9.26it/s] 52%|█████▏    | 552/1070 [01:02<00:55,  9.29it/s] 52%|█████▏    | 553/1070 [01:02<00:55,  9.23it/s] 52%|█████▏    | 554/1070 [01:02<00:54,  9.39it/s] 52%|█████▏    | 555/1070 [01:02<00:55,  9.25it/s] 52%|█████▏    | 556/1070 [01:02<00:55,  9.26it/s] 52%|█████▏    | 557/1070 [01:02<00:54,  9.38it/s] 52%|█████▏    | 558/1070 [01:02<00:55,  9.28it/s] 52%|█████▏    | 559/1070 [01:03<00:55,  9.22it/s] 52%|█████▏    | 560/1070 [01:03<00:55,  9.26it/s] 52%|█████▏    | 561/1070 [01:03<00:54,  9.26it/s] 53%|█████▎    | 562/1070 [01:03<00:54,  9.28it/s] 53%|█████▎    | 563/1070 [01:03<00:54,  9.23it/s] 53%|█████▎    | 564/1070 [01:03<00:54,  9.35it/s] 53%|█████▎    | 565/1070 [01:03<00:54,  9.28it/s] 53%|█████▎    | 566/1070 [01:03<00:54,  9.29it/s] 53%|█████▎    | 567/1070 [01:03<00:54,  9.23it/s] 53%|█████▎    | 568/1070 [01:04<00:54,  9.23it/s] 53%|█████▎    | 569/1070 [01:04<00:54,  9.25it/s] 53%|█████▎    | 570/1070 [01:04<00:54,  9.21it/s] 53%|█████▎    | 571/1070 [01:04<00:53,  9.34it/s] 53%|█████▎    | 572/1070 [01:04<00:53,  9.25it/s] 54%|█████▎    | 573/1070 [01:04<00:53,  9.22it/s] 54%|█████▎    | 574/1070 [01:04<00:53,  9.26it/s] 54%|█████▎    | 575/1070 [01:04<00:53,  9.25it/s] 54%|█████▍    | 576/1070 [01:04<00:53,  9.17it/s] 54%|█████▍    | 577/1070 [01:04<00:53,  9.17it/s] 54%|█████▍    | 578/1070 [01:05<00:53,  9.17it/s] 54%|█████▍    | 579/1070 [01:05<00:53,  9.22it/s] 54%|█████▍    | 580/1070 [01:05<00:53,  9.22it/s] 54%|█████▍    | 581/1070 [01:05<00:52,  9.25it/s] 54%|█████▍    | 582/1070 [01:05<00:52,  9.26it/s] 54%|█████▍    | 583/1070 [01:05<00:52,  9.25it/s] 55%|█████▍    | 584/1070 [01:05<00:52,  9.24it/s] 55%|█████▍    | 585/1070 [01:05<00:52,  9.22it/s] 55%|█████▍    | 586/1070 [01:05<00:52,  9.30it/s] 55%|█████▍    | 587/1070 [01:06<00:52,  9.24it/s] 55%|█████▍    | 588/1070 [01:06<00:51,  9.36it/s] 55%|█████▌    | 589/1070 [01:06<00:51,  9.26it/s] 55%|█████▌    | 590/1070 [01:06<00:51,  9.23it/s] 55%|█████▌    | 591/1070 [01:06<00:51,  9.30it/s] 55%|█████▌    | 592/1070 [01:06<00:51,  9.30it/s] 55%|█████▌    | 593/1070 [01:06<00:51,  9.26it/s] 56%|█████▌    | 594/1070 [01:06<00:51,  9.25it/s] 56%|█████▌    | 595/1070 [01:06<00:51,  9.30it/s] 56%|█████▌    | 596/1070 [01:07<00:50,  9.33it/s] 56%|█████▌    | 597/1070 [01:07<00:50,  9.35it/s] 56%|█████▌    | 598/1070 [01:07<00:50,  9.41it/s] 56%|█████▌    | 599/1070 [01:07<00:50,  9.42it/s] 56%|█████▌    | 600/1070 [01:07<00:49,  9.48it/s] 56%|█████▌    | 601/1070 [01:07<00:49,  9.44it/s] 56%|█████▋    | 602/1070 [01:07<00:49,  9.44it/s] 56%|█████▋    | 603/1070 [01:07<00:49,  9.38it/s] 56%|█████▋    | 604/1070 [01:07<00:49,  9.42it/s] 57%|█████▋    | 605/1070 [01:07<00:49,  9.46it/s] 57%|█████▋    | 606/1070 [01:08<00:48,  9.48it/s] 57%|█████▋    | 607/1070 [01:08<00:48,  9.46it/s] 57%|█████▋    | 608/1070 [01:08<00:48,  9.56it/s] 57%|█████▋    | 609/1070 [01:08<00:48,  9.51it/s] 57%|█████▋    | 610/1070 [01:08<00:48,  9.41it/s] 57%|█████▋    | 611/1070 [01:08<00:48,  9.46it/s] 57%|█████▋    | 612/1070 [01:08<00:48,  9.44it/s] 57%|█████▋    | 613/1070 [01:08<00:48,  9.39it/s] 57%|█████▋    | 614/1070 [01:08<00:48,  9.42it/s] 57%|█████▋    | 615/1070 [01:09<00:48,  9.41it/s] 58%|█████▊    | 616/1070 [01:09<00:48,  9.40it/s] 58%|█████▊    | 617/1070 [01:09<00:47,  9.46it/s] 58%|█████▊    | 618/1070 [01:09<00:47,  9.47it/s] 58%|█████▊    | 619/1070 [01:09<00:47,  9.43it/s] 58%|█████▊    | 620/1070 [01:09<00:47,  9.43it/s] 58%|█████▊    | 621/1070 [01:09<00:47,  9.46it/s] 58%|█████▊    | 622/1070 [01:09<00:47,  9.46it/s] 58%|█████▊    | 623/1070 [01:09<00:47,  9.39it/s] 58%|█████▊    | 624/1070 [01:10<00:48,  9.27it/s] 58%|█████▊    | 625/1070 [01:10<00:47,  9.38it/s] 59%|█████▊    | 626/1070 [01:10<00:47,  9.35it/s] 59%|█████▊    | 627/1070 [01:10<00:47,  9.29it/s] 59%|█████▊    | 628/1070 [01:10<00:46,  9.43it/s] 59%|█████▉    | 629/1070 [01:10<00:47,  9.33it/s] 59%|█████▉    | 630/1070 [01:10<00:47,  9.28it/s] 59%|█████▉    | 631/1070 [01:10<00:47,  9.33it/s] 59%|█████▉    | 632/1070 [01:10<00:46,  9.38it/s] 59%|█████▉    | 633/1070 [01:10<00:46,  9.35it/s] 59%|█████▉    | 634/1070 [01:11<00:46,  9.32it/s] 59%|█████▉    | 635/1070 [01:11<00:46,  9.33it/s] 59%|█████▉    | 636/1070 [01:11<00:46,  9.32it/s] 60%|█████▉    | 637/1070 [01:11<00:46,  9.33it/s] 60%|█████▉    | 638/1070 [01:11<00:46,  9.39it/s] 60%|█████▉    | 639/1070 [01:11<00:46,  9.35it/s] 60%|█████▉    | 640/1070 [01:11<00:45,  9.37it/s] 60%|█████▉    | 641/1070 [01:11<00:45,  9.39it/s]                                                   60%|██████    | 642/1070 [01:11<00:45,  9.39it/s][INFO|trainer.py:755] 2023-11-15 21:14:03,599 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:14:03,601 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:14:03,601 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:14:03,602 >>   Batch size = 8
{'eval_loss': 0.29143717885017395, 'eval_accuracy': 0.906578947368421, 'eval_micro_f1': 0.906578947368421, 'eval_macro_f1': 0.9040923924480088, 'eval_runtime': 1.2672, 'eval_samples_per_second': 599.733, 'eval_steps_per_second': 74.967, 'epoch': 2.0}
{'loss': 0.1365, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 82.34it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 79.77it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 78.40it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 77.80it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 77.28it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 76.72it/s][A
 61%|██████    | 58/95 [00:00<00:00, 77.09it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 76.32it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 77.27it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 76.83it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 76.11it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:13<00:45,  9.39it/s]
100%|██████████| 95/95 [00:01<00:00, 76.11it/s][A
                                               [A 60%|██████    | 643/1070 [01:13<02:50,  2.50it/s] 60%|██████    | 644/1070 [01:13<02:19,  3.05it/s] 60%|██████    | 645/1070 [01:13<01:54,  3.71it/s] 60%|██████    | 646/1070 [01:13<01:35,  4.44it/s] 60%|██████    | 647/1070 [01:13<01:21,  5.20it/s] 61%|██████    | 648/1070 [01:13<01:10,  5.96it/s] 61%|██████    | 649/1070 [01:13<01:02,  6.70it/s] 61%|██████    | 650/1070 [01:14<00:57,  7.30it/s] 61%|██████    | 651/1070 [01:14<00:53,  7.82it/s] 61%|██████    | 652/1070 [01:14<00:50,  8.24it/s] 61%|██████    | 653/1070 [01:14<00:48,  8.58it/s] 61%|██████    | 654/1070 [01:14<00:47,  8.76it/s] 61%|██████    | 655/1070 [01:14<00:46,  8.89it/s] 61%|██████▏   | 656/1070 [01:14<00:45,  9.07it/s] 61%|██████▏   | 657/1070 [01:14<00:45,  9.16it/s] 61%|██████▏   | 658/1070 [01:14<00:45,  9.13it/s] 62%|██████▏   | 659/1070 [01:15<00:44,  9.24it/s] 62%|██████▏   | 660/1070 [01:15<00:44,  9.21it/s] 62%|██████▏   | 661/1070 [01:15<00:44,  9.29it/s] 62%|██████▏   | 662/1070 [01:15<00:43,  9.38it/s] 62%|██████▏   | 663/1070 [01:15<00:43,  9.38it/s] 62%|██████▏   | 664/1070 [01:15<00:43,  9.27it/s] 62%|██████▏   | 665/1070 [01:15<00:43,  9.36it/s] 62%|██████▏   | 666/1070 [01:15<00:45,  8.93it/s] 62%|██████▏   | 667/1070 [01:15<00:44,  9.05it/s] 62%|██████▏   | 668/1070 [01:15<00:44,  9.07it/s] 63%|██████▎   | 669/1070 [01:16<00:43,  9.21it/s] 63%|██████▎   | 670/1070 [01:16<00:43,  9.26it/s] 63%|██████▎   | 671/1070 [01:16<00:42,  9.30it/s] 63%|██████▎   | 672/1070 [01:16<00:42,  9.38it/s] 63%|██████▎   | 673/1070 [01:16<00:42,  9.35it/s] 63%|██████▎   | 674/1070 [01:16<00:42,  9.43it/s] 63%|██████▎   | 675/1070 [01:16<00:41,  9.41it/s] 63%|██████▎   | 676/1070 [01:16<00:41,  9.40it/s] 63%|██████▎   | 677/1070 [01:16<00:41,  9.37it/s] 63%|██████▎   | 678/1070 [01:17<00:41,  9.42it/s] 63%|██████▎   | 679/1070 [01:17<00:41,  9.40it/s] 64%|██████▎   | 680/1070 [01:17<00:41,  9.38it/s] 64%|██████▎   | 681/1070 [01:17<00:41,  9.38it/s] 64%|██████▎   | 682/1070 [01:17<00:41,  9.42it/s] 64%|██████▍   | 683/1070 [01:17<00:41,  9.36it/s] 64%|██████▍   | 684/1070 [01:17<00:41,  9.33it/s] 64%|██████▍   | 685/1070 [01:17<00:41,  9.33it/s] 64%|██████▍   | 686/1070 [01:17<00:41,  9.35it/s] 64%|██████▍   | 687/1070 [01:18<00:41,  9.32it/s] 64%|██████▍   | 688/1070 [01:18<00:40,  9.42it/s] 64%|██████▍   | 689/1070 [01:18<00:40,  9.32it/s] 64%|██████▍   | 690/1070 [01:18<00:40,  9.35it/s] 65%|██████▍   | 691/1070 [01:18<00:40,  9.41it/s] 65%|██████▍   | 692/1070 [01:18<00:40,  9.40it/s] 65%|██████▍   | 693/1070 [01:18<00:40,  9.32it/s] 65%|██████▍   | 694/1070 [01:18<00:40,  9.33it/s] 65%|██████▍   | 695/1070 [01:18<00:40,  9.37it/s] 65%|██████▌   | 696/1070 [01:18<00:40,  9.31it/s] 65%|██████▌   | 697/1070 [01:19<00:40,  9.28it/s] 65%|██████▌   | 698/1070 [01:19<00:40,  9.27it/s] 65%|██████▌   | 699/1070 [01:19<00:39,  9.32it/s] 65%|██████▌   | 700/1070 [01:19<00:39,  9.29it/s] 66%|██████▌   | 701/1070 [01:19<00:39,  9.30it/s] 66%|██████▌   | 702/1070 [01:19<00:39,  9.30it/s] 66%|██████▌   | 703/1070 [01:19<00:39,  9.32it/s] 66%|██████▌   | 704/1070 [01:19<00:38,  9.39it/s] 66%|██████▌   | 705/1070 [01:19<00:39,  9.32it/s] 66%|██████▌   | 706/1070 [01:20<00:39,  9.31it/s] 66%|██████▌   | 707/1070 [01:20<00:38,  9.38it/s] 66%|██████▌   | 708/1070 [01:20<00:38,  9.31it/s] 66%|██████▋   | 709/1070 [01:20<00:38,  9.33it/s] 66%|██████▋   | 710/1070 [01:20<00:38,  9.32it/s] 66%|██████▋   | 711/1070 [01:20<00:38,  9.37it/s] 67%|██████▋   | 712/1070 [01:20<00:38,  9.40it/s] 67%|██████▋   | 713/1070 [01:20<00:38,  9.33it/s] 67%|██████▋   | 714/1070 [01:20<00:37,  9.40it/s] 67%|██████▋   | 715/1070 [01:21<00:37,  9.35it/s] 67%|██████▋   | 716/1070 [01:21<00:37,  9.32it/s] 67%|██████▋   | 717/1070 [01:21<00:37,  9.37it/s] 67%|██████▋   | 718/1070 [01:21<00:37,  9.27it/s] 67%|██████▋   | 719/1070 [01:21<00:37,  9.29it/s] 67%|██████▋   | 720/1070 [01:21<00:37,  9.33it/s] 67%|██████▋   | 721/1070 [01:21<00:37,  9.34it/s] 67%|██████▋   | 722/1070 [01:21<00:37,  9.23it/s] 68%|██████▊   | 723/1070 [01:21<00:37,  9.30it/s] 68%|██████▊   | 724/1070 [01:21<00:37,  9.28it/s] 68%|██████▊   | 725/1070 [01:22<00:37,  9.31it/s] 68%|██████▊   | 726/1070 [01:22<00:37,  9.25it/s] 68%|██████▊   | 727/1070 [01:22<00:36,  9.30it/s] 68%|██████▊   | 728/1070 [01:22<00:36,  9.27it/s] 68%|██████▊   | 729/1070 [01:22<00:36,  9.29it/s] 68%|██████▊   | 730/1070 [01:22<00:36,  9.35it/s] 68%|██████▊   | 731/1070 [01:22<00:36,  9.30it/s] 68%|██████▊   | 732/1070 [01:22<00:36,  9.35it/s] 69%|██████▊   | 733/1070 [01:22<00:35,  9.43it/s] 69%|██████▊   | 734/1070 [01:23<00:35,  9.38it/s] 69%|██████▊   | 735/1070 [01:23<00:36,  9.29it/s] 69%|██████▉   | 736/1070 [01:23<00:35,  9.35it/s] 69%|██████▉   | 737/1070 [01:23<00:35,  9.33it/s] 69%|██████▉   | 738/1070 [01:23<00:35,  9.29it/s] 69%|██████▉   | 739/1070 [01:23<00:35,  9.33it/s] 69%|██████▉   | 740/1070 [01:23<00:35,  9.33it/s] 69%|██████▉   | 741/1070 [01:23<00:35,  9.36it/s] 69%|██████▉   | 742/1070 [01:23<00:35,  9.32it/s] 69%|██████▉   | 743/1070 [01:24<00:34,  9.37it/s] 70%|██████▉   | 744/1070 [01:24<00:34,  9.36it/s] 70%|██████▉   | 745/1070 [01:24<00:34,  9.37it/s] 70%|██████▉   | 746/1070 [01:24<00:34,  9.45it/s] 70%|██████▉   | 747/1070 [01:24<00:34,  9.35it/s] 70%|██████▉   | 748/1070 [01:24<00:34,  9.38it/s] 70%|███████   | 749/1070 [01:24<00:34,  9.40it/s] 70%|███████   | 750/1070 [01:24<00:34,  9.38it/s] 70%|███████   | 751/1070 [01:24<00:34,  9.33it/s] 70%|███████   | 752/1070 [01:24<00:34,  9.29it/s] 70%|███████   | 753/1070 [01:25<00:33,  9.34it/s] 70%|███████   | 754/1070 [01:25<00:33,  9.34it/s] 71%|███████   | 755/1070 [01:25<00:33,  9.29it/s] 71%|███████   | 756/1070 [01:25<00:33,  9.27it/s] 71%|███████   | 757/1070 [01:25<00:33,  9.31it/s] 71%|███████   | 758/1070 [01:25<00:33,  9.32it/s] 71%|███████   | 759/1070 [01:25<00:33,  9.38it/s] 71%|███████   | 760/1070 [01:25<00:33,  9.35it/s] 71%|███████   | 761/1070 [01:25<00:33,  9.35it/s] 71%|███████   | 762/1070 [01:26<00:32,  9.44it/s] 71%|███████▏  | 763/1070 [01:26<00:32,  9.41it/s] 71%|███████▏  | 764/1070 [01:26<00:32,  9.35it/s] 71%|███████▏  | 765/1070 [01:26<00:32,  9.37it/s] 72%|███████▏  | 766/1070 [01:26<00:32,  9.35it/s] 72%|███████▏  | 767/1070 [01:26<00:32,  9.32it/s] 72%|███████▏  | 768/1070 [01:26<00:32,  9.32it/s] 72%|███████▏  | 769/1070 [01:26<00:32,  9.34it/s] 72%|███████▏  | 770/1070 [01:26<00:32,  9.36it/s] 72%|███████▏  | 771/1070 [01:27<00:32,  9.26it/s] 72%|███████▏  | 772/1070 [01:27<00:32,  9.28it/s] 72%|███████▏  | 773/1070 [01:27<00:31,  9.35it/s] 72%|███████▏  | 774/1070 [01:27<00:31,  9.37it/s] 72%|███████▏  | 775/1070 [01:27<00:31,  9.48it/s] 73%|███████▎  | 776/1070 [01:27<00:31,  9.36it/s] 73%|███████▎  | 777/1070 [01:27<00:31,  9.35it/s] 73%|███████▎  | 778/1070 [01:27<00:30,  9.42it/s] 73%|███████▎  | 779/1070 [01:27<00:30,  9.41it/s] 73%|███████▎  | 780/1070 [01:27<00:30,  9.39it/s] 73%|███████▎  | 781/1070 [01:28<00:30,  9.39it/s] 73%|███████▎  | 782/1070 [01:28<00:30,  9.40it/s] 73%|███████▎  | 783/1070 [01:28<00:30,  9.36it/s] 73%|███████▎  | 784/1070 [01:28<00:30,  9.35it/s] 73%|███████▎  | 785/1070 [01:28<00:30,  9.39it/s] 73%|███████▎  | 786/1070 [01:28<00:30,  9.38it/s] 74%|███████▎  | 787/1070 [01:28<00:30,  9.40it/s] 74%|███████▎  | 788/1070 [01:28<00:30,  9.38it/s] 74%|███████▎  | 789/1070 [01:28<00:30,  9.36it/s] 74%|███████▍  | 790/1070 [01:29<00:29,  9.34it/s] 74%|███████▍  | 791/1070 [01:29<00:29,  9.36it/s] 74%|███████▍  | 792/1070 [01:29<00:29,  9.35it/s] 74%|███████▍  | 793/1070 [01:29<00:29,  9.30it/s] 74%|███████▍  | 794/1070 [01:29<00:29,  9.39it/s] 74%|███████▍  | 795/1070 [01:29<00:29,  9.37it/s] 74%|███████▍  | 796/1070 [01:29<00:29,  9.33it/s] 74%|███████▍  | 797/1070 [01:29<00:29,  9.41it/s] 75%|███████▍  | 798/1070 [01:29<00:29,  9.33it/s] 75%|███████▍  | 799/1070 [01:30<00:29,  9.31it/s] 75%|███████▍  | 800/1070 [01:30<00:28,  9.33it/s] 75%|███████▍  | 801/1070 [01:30<00:28,  9.29it/s] 75%|███████▍  | 802/1070 [01:30<00:28,  9.36it/s] 75%|███████▌  | 803/1070 [01:30<00:28,  9.23it/s] 75%|███████▌  | 804/1070 [01:30<00:28,  9.26it/s] 75%|███████▌  | 805/1070 [01:30<00:28,  9.26it/s] 75%|███████▌  | 806/1070 [01:30<00:28,  9.29it/s] 75%|███████▌  | 807/1070 [01:30<00:28,  9.30it/s] 76%|███████▌  | 808/1070 [01:30<00:28,  9.26it/s] 76%|███████▌  | 809/1070 [01:31<00:28,  9.25it/s] 76%|███████▌  | 810/1070 [01:31<00:27,  9.34it/s] 76%|███████▌  | 811/1070 [01:31<00:27,  9.32it/s] 76%|███████▌  | 812/1070 [01:31<00:27,  9.24it/s] 76%|███████▌  | 813/1070 [01:31<00:27,  9.29it/s] 76%|███████▌  | 814/1070 [01:31<00:27,  9.32it/s] 76%|███████▌  | 815/1070 [01:31<00:27,  9.32it/s] 76%|███████▋  | 816/1070 [01:31<00:27,  9.33it/s] 76%|███████▋  | 817/1070 [01:31<00:27,  9.34it/s] 76%|███████▋  | 818/1070 [01:32<00:27,  9.33it/s] 77%|███████▋  | 819/1070 [01:32<00:26,  9.32it/s] 77%|███████▋  | 820/1070 [01:32<00:26,  9.33it/s] 77%|███████▋  | 821/1070 [01:32<00:26,  9.36it/s] 77%|███████▋  | 822/1070 [01:32<00:26,  9.35it/s] 77%|███████▋  | 823/1070 [01:32<00:26,  9.38it/s] 77%|███████▋  | 824/1070 [01:32<00:26,  9.29it/s] 77%|███████▋  | 825/1070 [01:32<00:26,  9.32it/s] 77%|███████▋  | 826/1070 [01:32<00:26,  9.35it/s] 77%|███████▋  | 827/1070 [01:33<00:26,  9.31it/s] 77%|███████▋  | 828/1070 [01:33<00:26,  9.25it/s] 77%|███████▋  | 829/1070 [01:33<00:26,  9.26it/s] 78%|███████▊  | 830/1070 [01:33<00:25,  9.25it/s] 78%|███████▊  | 831/1070 [01:33<00:25,  9.31it/s] 78%|███████▊  | 832/1070 [01:33<00:25,  9.26it/s] 78%|███████▊  | 833/1070 [01:33<00:25,  9.27it/s] 78%|███████▊  | 834/1070 [01:33<00:25,  9.19it/s] 78%|███████▊  | 835/1070 [01:33<00:25,  9.20it/s] 78%|███████▊  | 836/1070 [01:33<00:25,  9.33it/s] 78%|███████▊  | 837/1070 [01:34<00:24,  9.33it/s] 78%|███████▊  | 838/1070 [01:34<00:25,  9.21it/s] 78%|███████▊  | 839/1070 [01:34<00:25,  9.23it/s] 79%|███████▊  | 840/1070 [01:34<00:24,  9.21it/s] 79%|███████▊  | 841/1070 [01:34<00:24,  9.26it/s] 79%|███████▊  | 842/1070 [01:34<00:24,  9.19it/s] 79%|███████▉  | 843/1070 [01:34<00:24,  9.23it/s] 79%|███████▉  | 844/1070 [01:34<00:24,  9.25it/s] 79%|███████▉  | 845/1070 [01:34<00:24,  9.22it/s] 79%|███████▉  | 846/1070 [01:35<00:24,  9.29it/s] 79%|███████▉  | 847/1070 [01:35<00:24,  9.25it/s] 79%|███████▉  | 848/1070 [01:35<00:24,  9.21it/s] 79%|███████▉  | 849/1070 [01:35<00:23,  9.26it/s] 79%|███████▉  | 850/1070 [01:35<00:23,  9.29it/s] 80%|███████▉  | 851/1070 [01:35<00:23,  9.28it/s] 80%|███████▉  | 852/1070 [01:35<00:23,  9.23it/s] 80%|███████▉  | 853/1070 [01:35<00:23,  9.30it/s] 80%|███████▉  | 854/1070 [01:35<00:23,  9.30it/s] 80%|███████▉  | 855/1070 [01:36<00:23,  9.33it/s]                                                   80%|████████  | 856/1070 [01:36<00:22,  9.33it/s][INFO|trainer.py:755] 2023-11-15 21:14:27,810 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:14:27,812 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:14:27,812 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:14:27,813 >>   Batch size = 8
{'eval_loss': 0.32333046197891235, 'eval_accuracy': 0.9039473684210526, 'eval_micro_f1': 0.9039473684210526, 'eval_macro_f1': 0.9007675764702734, 'eval_runtime': 1.2781, 'eval_samples_per_second': 594.655, 'eval_steps_per_second': 74.332, 'epoch': 3.0}
{'loss': 0.0806, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 83.07it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 80.37it/s][A
 28%|██▊       | 27/95 [00:00<00:00, 79.60it/s][A
 37%|███▋      | 35/95 [00:00<00:00, 75.38it/s][A
 45%|████▌     | 43/95 [00:00<00:00, 75.52it/s][A
 54%|█████▎    | 51/95 [00:00<00:00, 75.47it/s][A
 62%|██████▏   | 59/95 [00:00<00:00, 76.20it/s][A
 71%|███████   | 67/95 [00:00<00:00, 75.61it/s][A
 79%|███████▉  | 75/95 [00:00<00:00, 74.74it/s][A
 87%|████████▋ | 83/95 [00:01<00:00, 74.67it/s][A
 96%|█████████▌| 91/95 [00:01<00:00, 75.28it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:37<00:22,  9.33it/s]
100%|██████████| 95/95 [00:01<00:00, 75.28it/s][A
                                               [A 80%|████████  | 857/1070 [01:37<01:25,  2.48it/s] 80%|████████  | 858/1070 [01:37<01:10,  3.02it/s] 80%|████████  | 859/1070 [01:37<00:57,  3.65it/s] 80%|████████  | 860/1070 [01:37<00:48,  4.37it/s] 80%|████████  | 861/1070 [01:37<00:40,  5.13it/s] 81%|████████  | 862/1070 [01:38<00:35,  5.89it/s] 81%|████████  | 863/1070 [01:38<00:31,  6.56it/s] 81%|████████  | 864/1070 [01:38<00:28,  7.17it/s] 81%|████████  | 865/1070 [01:38<00:26,  7.69it/s] 81%|████████  | 866/1070 [01:38<00:25,  8.09it/s] 81%|████████  | 867/1070 [01:38<00:24,  8.45it/s] 81%|████████  | 868/1070 [01:38<00:23,  8.63it/s] 81%|████████  | 869/1070 [01:38<00:22,  8.76it/s] 81%|████████▏ | 870/1070 [01:38<00:22,  8.97it/s] 81%|████████▏ | 871/1070 [01:39<00:21,  9.07it/s] 81%|████████▏ | 872/1070 [01:39<00:21,  9.05it/s] 82%|████████▏ | 873/1070 [01:39<00:21,  9.10it/s] 82%|████████▏ | 874/1070 [01:39<00:21,  9.16it/s] 82%|████████▏ | 875/1070 [01:39<00:21,  9.16it/s] 82%|████████▏ | 876/1070 [01:39<00:21,  9.14it/s] 82%|████████▏ | 877/1070 [01:39<00:20,  9.21it/s] 82%|████████▏ | 878/1070 [01:39<00:20,  9.17it/s] 82%|████████▏ | 879/1070 [01:39<00:20,  9.21it/s] 82%|████████▏ | 880/1070 [01:40<00:20,  9.31it/s] 82%|████████▏ | 881/1070 [01:40<00:20,  9.23it/s] 82%|████████▏ | 882/1070 [01:40<00:20,  9.28it/s] 83%|████████▎ | 883/1070 [01:40<00:20,  9.27it/s] 83%|████████▎ | 884/1070 [01:40<00:20,  9.27it/s] 83%|████████▎ | 885/1070 [01:40<00:19,  9.30it/s] 83%|████████▎ | 886/1070 [01:40<00:19,  9.31it/s] 83%|████████▎ | 887/1070 [01:40<00:19,  9.29it/s] 83%|████████▎ | 888/1070 [01:40<00:19,  9.26it/s] 83%|████████▎ | 889/1070 [01:40<00:19,  9.27it/s] 83%|████████▎ | 890/1070 [01:41<00:19,  9.31it/s] 83%|████████▎ | 891/1070 [01:41<00:19,  9.22it/s] 83%|████████▎ | 892/1070 [01:41<00:19,  9.26it/s] 83%|████████▎ | 893/1070 [01:41<00:19,  9.31it/s] 84%|████████▎ | 894/1070 [01:41<00:18,  9.31it/s] 84%|████████▎ | 895/1070 [01:41<00:18,  9.23it/s] 84%|████████▎ | 896/1070 [01:41<00:18,  9.24it/s] 84%|████████▍ | 897/1070 [01:41<00:18,  9.29it/s] 84%|████████▍ | 898/1070 [01:41<00:18,  9.25it/s] 84%|████████▍ | 899/1070 [01:42<00:18,  9.29it/s] 84%|████████▍ | 900/1070 [01:42<00:18,  9.22it/s] 84%|████████▍ | 901/1070 [01:42<00:18,  9.28it/s] 84%|████████▍ | 902/1070 [01:42<00:18,  9.30it/s] 84%|████████▍ | 903/1070 [01:42<00:17,  9.32it/s] 84%|████████▍ | 904/1070 [01:42<00:17,  9.27it/s] 85%|████████▍ | 905/1070 [01:42<00:17,  9.29it/s] 85%|████████▍ | 906/1070 [01:42<00:17,  9.35it/s] 85%|████████▍ | 907/1070 [01:42<00:17,  9.31it/s] 85%|████████▍ | 908/1070 [01:43<00:17,  9.20it/s] 85%|████████▍ | 909/1070 [01:43<00:17,  9.24it/s] 85%|████████▌ | 910/1070 [01:43<00:17,  9.24it/s] 85%|████████▌ | 911/1070 [01:43<00:17,  9.24it/s] 85%|████████▌ | 912/1070 [01:43<00:17,  9.25it/s] 85%|████████▌ | 913/1070 [01:43<00:17,  9.23it/s] 85%|████████▌ | 914/1070 [01:43<00:16,  9.20it/s] 86%|████████▌ | 915/1070 [01:43<00:16,  9.20it/s] 86%|████████▌ | 916/1070 [01:43<00:16,  9.23it/s] 86%|████████▌ | 917/1070 [01:44<00:16,  9.14it/s] 86%|████████▌ | 918/1070 [01:44<00:16,  9.16it/s] 86%|████████▌ | 919/1070 [01:44<00:16,  9.19it/s] 86%|████████▌ | 920/1070 [01:44<00:16,  9.17it/s] 86%|████████▌ | 921/1070 [01:44<00:16,  9.18it/s] 86%|████████▋ | 923/1070 [01:44<00:15,  9.73it/s] 86%|████████▋ | 925/1070 [01:44<00:14, 10.18it/s] 87%|████████▋ | 927/1070 [01:45<00:13, 10.45it/s] 87%|████████▋ | 929/1070 [01:45<00:13, 10.61it/s] 87%|████████▋ | 931/1070 [01:45<00:13, 10.07it/s] 87%|████████▋ | 933/1070 [01:45<00:14,  9.77it/s] 87%|████████▋ | 934/1070 [01:45<00:14,  9.68it/s] 87%|████████▋ | 935/1070 [01:45<00:14,  9.56it/s] 87%|████████▋ | 936/1070 [01:45<00:14,  9.48it/s] 88%|████████▊ | 937/1070 [01:46<00:14,  9.40it/s] 88%|████████▊ | 938/1070 [01:46<00:14,  9.37it/s] 88%|████████▊ | 939/1070 [01:46<00:14,  9.35it/s] 88%|████████▊ | 940/1070 [01:46<00:13,  9.30it/s] 88%|████████▊ | 941/1070 [01:46<00:13,  9.29it/s] 88%|████████▊ | 942/1070 [01:46<00:13,  9.28it/s] 88%|████████▊ | 943/1070 [01:46<00:13,  9.22it/s] 88%|████████▊ | 944/1070 [01:46<00:13,  9.19it/s] 88%|████████▊ | 945/1070 [01:46<00:13,  9.33it/s] 88%|████████▊ | 946/1070 [01:47<00:13,  9.33it/s] 89%|████████▊ | 947/1070 [01:47<00:13,  9.29it/s] 89%|████████▊ | 948/1070 [01:47<00:13,  9.24it/s] 89%|████████▊ | 949/1070 [01:47<00:13,  9.27it/s] 89%|████████▉ | 950/1070 [01:47<00:12,  9.24it/s] 89%|████████▉ | 951/1070 [01:47<00:12,  9.23it/s] 89%|████████▉ | 952/1070 [01:47<00:12,  9.19it/s] 89%|████████▉ | 953/1070 [01:47<00:12,  9.27it/s] 89%|████████▉ | 954/1070 [01:47<00:12,  9.24it/s] 89%|████████▉ | 955/1070 [01:48<00:12,  9.26it/s] 89%|████████▉ | 956/1070 [01:48<00:12,  9.21it/s] 89%|████████▉ | 957/1070 [01:48<00:12,  9.24it/s] 90%|████████▉ | 958/1070 [01:48<00:12,  9.24it/s] 90%|████████▉ | 959/1070 [01:48<00:12,  9.20it/s] 90%|████████▉ | 960/1070 [01:48<00:11,  9.21it/s] 90%|████████▉ | 961/1070 [01:48<00:11,  9.30it/s] 90%|████████▉ | 962/1070 [01:48<00:11,  9.27it/s] 90%|█████████ | 963/1070 [01:48<00:11,  9.22it/s] 90%|█████████ | 964/1070 [01:48<00:11,  9.23it/s] 90%|█████████ | 965/1070 [01:49<00:11,  9.25it/s] 90%|█████████ | 966/1070 [01:49<00:11,  9.24it/s] 90%|█████████ | 967/1070 [01:49<00:11,  9.21it/s] 90%|█████████ | 968/1070 [01:49<00:11,  9.23it/s] 91%|█████████ | 969/1070 [01:49<00:10,  9.23it/s] 91%|█████████ | 970/1070 [01:49<00:10,  9.17it/s] 91%|█████████ | 971/1070 [01:49<00:10,  9.16it/s] 91%|█████████ | 972/1070 [01:49<00:10,  9.21it/s] 91%|█████████ | 973/1070 [01:49<00:10,  9.15it/s] 91%|█████████ | 974/1070 [01:50<00:10,  9.30it/s] 91%|█████████ | 975/1070 [01:50<00:10,  9.18it/s] 91%|█████████ | 976/1070 [01:50<00:10,  9.26it/s] 91%|█████████▏| 977/1070 [01:50<00:09,  9.38it/s] 91%|█████████▏| 978/1070 [01:50<00:09,  9.24it/s] 91%|█████████▏| 979/1070 [01:50<00:09,  9.22it/s] 92%|█████████▏| 980/1070 [01:50<00:09,  9.28it/s] 92%|█████████▏| 981/1070 [01:50<00:09,  9.20it/s] 92%|█████████▏| 982/1070 [01:50<00:09,  9.15it/s] 92%|█████████▏| 983/1070 [01:51<00:09,  9.16it/s] 92%|█████████▏| 984/1070 [01:51<00:09,  9.19it/s] 92%|█████████▏| 985/1070 [01:51<00:09,  9.17it/s] 92%|█████████▏| 986/1070 [01:51<00:09,  9.17it/s] 92%|█████████▏| 987/1070 [01:51<00:09,  9.17it/s] 92%|█████████▏| 988/1070 [01:51<00:08,  9.18it/s] 92%|█████████▏| 989/1070 [01:51<00:08,  9.22it/s] 93%|█████████▎| 990/1070 [01:51<00:08,  9.19it/s] 93%|█████████▎| 991/1070 [01:51<00:08,  9.20it/s] 93%|█████████▎| 992/1070 [01:52<00:08,  9.23it/s] 93%|█████████▎| 993/1070 [01:52<00:08,  9.21it/s] 93%|█████████▎| 994/1070 [01:52<00:08,  9.15it/s] 93%|█████████▎| 995/1070 [01:52<00:08,  9.13it/s] 93%|█████████▎| 996/1070 [01:52<00:08,  9.18it/s] 93%|█████████▎| 997/1070 [01:52<00:07,  9.18it/s] 93%|█████████▎| 998/1070 [01:52<00:07,  9.15it/s] 93%|█████████▎| 999/1070 [01:52<00:07,  9.17it/s] 93%|█████████▎| 1000/1070 [01:52<00:07,  9.22it/s] 94%|█████████▎| 1001/1070 [01:53<00:07,  9.23it/s] 94%|█████████▎| 1002/1070 [01:53<00:07,  9.16it/s] 94%|█████████▎| 1003/1070 [01:53<00:07,  9.17it/s] 94%|█████████▍| 1004/1070 [01:53<00:07,  9.19it/s] 94%|█████████▍| 1005/1070 [01:53<00:07,  9.18it/s] 94%|█████████▍| 1006/1070 [01:53<00:06,  9.20it/s] 94%|█████████▍| 1007/1070 [01:53<00:06,  9.24it/s] 94%|█████████▍| 1008/1070 [01:53<00:06,  9.20it/s] 94%|█████████▍| 1009/1070 [01:53<00:06,  9.27it/s] 94%|█████████▍| 1010/1070 [01:53<00:06,  9.23it/s] 94%|█████████▍| 1011/1070 [01:54<00:06,  9.25it/s] 95%|█████████▍| 1012/1070 [01:54<00:06,  9.35it/s] 95%|█████████▍| 1013/1070 [01:54<00:06,  9.32it/s] 95%|█████████▍| 1014/1070 [01:54<00:06,  9.23it/s] 95%|█████████▍| 1015/1070 [01:54<00:05,  9.25it/s] 95%|█████████▍| 1016/1070 [01:54<00:05,  9.30it/s] 95%|█████████▌| 1017/1070 [01:54<00:05,  9.21it/s] 95%|█████████▌| 1018/1070 [01:54<00:05,  9.21it/s] 95%|█████████▌| 1019/1070 [01:54<00:05,  9.22it/s] 95%|█████████▌| 1020/1070 [01:55<00:05,  9.22it/s] 95%|█████████▌| 1021/1070 [01:55<00:05,  9.21it/s] 96%|█████████▌| 1022/1070 [01:55<00:05,  9.23it/s] 96%|█████████▌| 1023/1070 [01:55<00:05,  9.27it/s] 96%|█████████▌| 1024/1070 [01:55<00:04,  9.27it/s] 96%|█████████▌| 1025/1070 [01:55<00:04,  9.24it/s] 96%|█████████▌| 1026/1070 [01:55<00:04,  9.24it/s] 96%|█████████▌| 1027/1070 [01:55<00:04,  9.23it/s] 96%|█████████▌| 1028/1070 [01:55<00:04,  9.27it/s] 96%|█████████▌| 1029/1070 [01:56<00:04,  9.26it/s] 96%|█████████▋| 1030/1070 [01:56<00:04,  9.24it/s] 96%|█████████▋| 1031/1070 [01:56<00:04,  9.33it/s] 96%|█████████▋| 1032/1070 [01:56<00:04,  9.26it/s] 97%|█████████▋| 1033/1070 [01:56<00:04,  9.24it/s] 97%|█████████▋| 1034/1070 [01:56<00:03,  9.36it/s] 97%|█████████▋| 1035/1070 [01:56<00:03,  9.27it/s] 97%|█████████▋| 1036/1070 [01:56<00:03,  9.28it/s] 97%|█████████▋| 1037/1070 [01:56<00:03,  9.25it/s] 97%|█████████▋| 1038/1070 [01:57<00:03,  9.30it/s] 97%|█████████▋| 1039/1070 [01:57<00:03,  9.33it/s] 97%|█████████▋| 1040/1070 [01:57<00:03,  9.20it/s] 97%|█████████▋| 1041/1070 [01:57<00:03,  9.21it/s] 97%|█████████▋| 1042/1070 [01:57<00:03,  9.25it/s] 97%|█████████▋| 1043/1070 [01:57<00:02,  9.26it/s] 98%|█████████▊| 1044/1070 [01:57<00:02,  9.22it/s] 98%|█████████▊| 1045/1070 [01:57<00:02,  9.18it/s] 98%|█████████▊| 1046/1070 [01:57<00:02,  9.23it/s] 98%|█████████▊| 1047/1070 [01:57<00:02,  9.28it/s] 98%|█████████▊| 1048/1070 [01:58<00:02,  9.23it/s] 98%|█████████▊| 1049/1070 [01:58<00:02,  9.20it/s] 98%|█████████▊| 1050/1070 [01:58<00:02,  9.33it/s] 98%|█████████▊| 1051/1070 [01:58<00:02,  9.22it/s] 98%|█████████▊| 1052/1070 [01:58<00:01,  9.14it/s] 98%|█████████▊| 1053/1070 [01:58<00:01,  9.17it/s] 99%|█████████▊| 1054/1070 [01:58<00:01,  9.18it/s] 99%|█████████▊| 1055/1070 [01:58<00:01,  9.13it/s] 99%|█████████▊| 1056/1070 [01:58<00:01,  9.15it/s] 99%|█████████▉| 1057/1070 [01:59<00:01,  9.16it/s] 99%|█████████▉| 1058/1070 [01:59<00:01,  9.25it/s] 99%|█████████▉| 1059/1070 [01:59<00:01,  9.18it/s] 99%|█████████▉| 1060/1070 [01:59<00:01,  9.22it/s] 99%|█████████▉| 1061/1070 [01:59<00:00,  9.17it/s] 99%|█████████▉| 1062/1070 [01:59<00:00,  9.14it/s] 99%|█████████▉| 1063/1070 [01:59<00:00,  9.27it/s] 99%|█████████▉| 1064/1070 [01:59<00:00,  9.17it/s]100%|█████████▉| 1065/1070 [01:59<00:00,  9.07it/s]100%|█████████▉| 1066/1070 [02:00<00:00,  9.12it/s]100%|█████████▉| 1067/1070 [02:00<00:00,  9.09it/s]100%|█████████▉| 1068/1070 [02:00<00:00,  9.10it/s]100%|█████████▉| 1069/1070 [02:00<00:00,  8.99it/s]                                                   100%|██████████| 1070/1070 [02:00<00:00,  8.99it/s][INFO|trainer.py:755] 2023-11-15 21:14:52,175 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:14:52,177 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:14:52,177 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:14:52,178 >>   Batch size = 8
{'eval_loss': 0.3662801682949066, 'eval_accuracy': 0.9013157894736842, 'eval_micro_f1': 0.9013157894736842, 'eval_macro_f1': 0.8983934177880255, 'eval_runtime': 1.2993, 'eval_samples_per_second': 584.908, 'eval_steps_per_second': 73.114, 'epoch': 4.0}
{'loss': 0.051, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 83.96it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 74.71it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 74.38it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 75.09it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 74.16it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 74.64it/s][A
 61%|██████    | 58/95 [00:00<00:00, 73.00it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 73.30it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 74.44it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 73.40it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 72.62it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:01<00:00,  8.99it/s]
100%|██████████| 95/95 [00:01<00:00, 72.62it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 21:14:53,512 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:01<00:00,  8.99it/s]100%|██████████| 1070/1070 [02:01<00:00,  8.78it/s]
[INFO|trainer.py:2855] 2023-11-15 21:14:53,515 >> Saving model checkpoint to ./result/agnews_sup_bert-base-cased_adapter__seed3
[INFO|configuration_utils.py:460] 2023-11-15 21:14:53,517 >> Configuration saved in ./result/agnews_sup_bert-base-cased_adapter__seed3/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:14:54,506 >> Model weights saved in ./result/agnews_sup_bert-base-cased_adapter__seed3/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:14:54,510 >> tokenizer config file saved in ./result/agnews_sup_bert-base-cased_adapter__seed3/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:14:54,512 >> Special tokens file saved in ./result/agnews_sup_bert-base-cased_adapter__seed3/special_tokens_map.json
{'eval_loss': 0.37936389446258545, 'eval_accuracy': 0.9052631578947369, 'eval_micro_f1': 0.9052631578947369, 'eval_macro_f1': 0.9024045048103008, 'eval_runtime': 1.3305, 'eval_samples_per_second': 571.221, 'eval_steps_per_second': 71.403, 'epoch': 5.0}
{'train_runtime': 121.8305, 'train_samples_per_second': 280.718, 'train_steps_per_second': 8.783, 'train_loss': 0.20106610360546648, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2011
  train_runtime            = 0:02:01.83
  train_samples            =       6840
  train_samples_per_second =    280.718
  train_steps_per_second   =      8.783
11/15/2023 21:14:54 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:14:54,556 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:14:54,557 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:14:54,557 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:14:54,557 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  9%|▉         | 9/95 [00:00<00:00, 87.70it/s] 19%|█▉        | 18/95 [00:00<00:00, 77.65it/s] 27%|██▋       | 26/95 [00:00<00:00, 74.71it/s] 36%|███▌      | 34/95 [00:00<00:00, 74.71it/s] 44%|████▍     | 42/95 [00:00<00:00, 74.30it/s] 53%|█████▎    | 50/95 [00:00<00:00, 73.25it/s] 61%|██████    | 58/95 [00:00<00:00, 73.88it/s] 69%|██████▉   | 66/95 [00:00<00:00, 73.34it/s] 78%|███████▊  | 74/95 [00:00<00:00, 74.38it/s] 86%|████████▋ | 82/95 [00:01<00:00, 74.78it/s] 95%|█████████▍| 90/95 [00:01<00:00, 73.35it/s]100%|██████████| 95/95 [00:01<00:00, 72.64it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9053
  eval_loss               =     0.3794
  eval_macro_f1           =     0.9024
  eval_micro_f1           =     0.9053
  eval_runtime            = 0:00:01.32
  eval_samples            =        760
  eval_samples_per_second =    573.356
  eval_steps_per_second   =      71.67
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁█▆▄▇▇
wandb:                      eval/loss ▂▁▄▇██
wandb:                  eval/macro_f1 ▁█▆▄▇▇
wandb:                  eval/micro_f1 ▁█▆▄▇▇
wandb:                   eval/runtime ▅▁▂▅█▇
wandb:        eval/samples_per_second ▄█▇▄▁▂
wandb:          eval/steps_per_second ▄█▇▄▁▂
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▂▁▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.90526
wandb:                      eval/loss 0.37936
wandb:                  eval/macro_f1 0.9024
wandb:                  eval/micro_f1 0.90526
wandb:                   eval/runtime 1.3255
wandb:        eval/samples_per_second 573.356
wandb:          eval/steps_per_second 71.67
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.051
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.20107
wandb:            train/train_runtime 121.8305
wandb: train/train_samples_per_second 280.718
wandb:   train/train_steps_per_second 8.783
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_211204-e0q7hcvg
wandb: Find logs at: ./wandb/offline-run-20231115_211204-e0q7hcvg/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3/runs/Nov15_21-15-06_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:15:06 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:15:06 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3/runs/Nov15_21-15-05_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=444,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 21:15:22,042 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:15:22,052 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 21:15:32,068 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 21:15:42,086 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:15:42,087 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:16:02,124 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:16:02,125 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:16:02,125 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:16:02,125 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:16:02,126 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 21:16:02,127 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:16:02,128 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 21:16:02,153 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:16:02,153 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:16:22,293 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 21:16:23,703 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:16:23,704 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  29%|██▉       | 2000/6840 [00:00<00:00, 17872.13 examples/s]Running tokenizer on dataset:  58%|█████▊    | 4000/6840 [00:00<00:00, 17806.86 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 18793.61 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 18424.28 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 18669.41 examples/s]
11/15/2023 21:16:24 - INFO - __main__ - Sample 2530 of the training set: {'text': 'Invasion of the Data Snatchers (washingtonpost.com) washingtonpost.com - Think your PC is safe? Think again. A new study indicates your home computer is likely bogged down with spyware, viruses and other scourges wrought by hackers and PC pranksters. Ignorance may be bliss for some people, but for computer users, not knowing can be costly and inefficient.', 'label': 2, 'input_ids': [102, 8268, 131, 111, 453, 2308, 7396, 270, 145, 9224, 13999, 205, 209, 546, 9224, 13999, 205, 209, 579, 4960, 5296, 3658, 165, 6828, 3912, 4960, 1573, 205, 106, 758, 527, 3322, 5296, 3417, 2556, 165, 1987, 17742, 6097, 1922, 190, 273, 30126, 1526, 422, 8313, 137, 494, 337, 387, 2150, 1800, 27795, 214, 23387, 270, 137, 3658, 19933, 8090, 25889, 205, 28152, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 21:16:24 - INFO - __main__ - Sample 2357 of the training set: {'text': 'Corning begins work on Taiwan LCD facility Encouraged by the demand for LCDs, glass maker Corning on Thursday said it has broken ground for a second manufacturing facility in Taiwan.', 'label': 2, 'input_ids': [102, 10823, 140, 11415, 697, 191, 11338, 6087, 30118, 8516, 15306, 214, 111, 3880, 168, 6087, 1591, 422, 5860, 23157, 10823, 140, 191, 149, 2669, 3113, 6032, 256, 434, 12265, 3443, 168, 106, 971, 7887, 8516, 121, 11338, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:16:24 - INFO - __main__ - Sample 108 of the training set: {'text': "In Asia, Powell defends N. Korea policy SEOUL -- Secretary of State Colin L. Powell yesterday sought to fend off complaints from key partners in the effort to end North Korea's nuclear programs that the Bush administration has not been sufficiently creative or willing to compromise in the negotiations.", 'label': 3, 'input_ids': [102, 121, 10705, 422, 29458, 16806, 30113, 146, 205, 9112, 2951, 19229, 579, 579, 29880, 131, 1098, 5703, 30111, 152, 205, 29458, 7870, 192, 3113, 10637, 147, 19234, 30118, 1874, 17999, 263, 1519, 6830, 121, 111, 5264, 147, 864, 4656, 9112, 2505, 112, 4097, 3996, 198, 111, 26384, 3762, 434, 302, 528, 7094, 7153, 234, 10279, 147, 14382, 121, 111, 27966, 205, 103, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]}.
11/15/2023 21:16:24 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:16:25,711 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:16:25,719 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:16:25,719 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 21:16:25,720 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:16:25,720 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:16:25,720 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:16:25,720 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:16:25,721 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 21:16:25,721 >>   Number of trainable parameters = 109,921,540
[INFO|integration_utils.py:716] 2023-11-15 21:16:25,722 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<26:53,  1.51s/it]  0%|          | 2/1070 [00:01<12:15,  1.45it/s]  0%|          | 3/1070 [00:01<07:34,  2.35it/s]  0%|          | 4/1070 [00:01<05:22,  3.30it/s]  0%|          | 5/1070 [00:01<04:09,  4.27it/s]  1%|          | 6/1070 [00:02<03:24,  5.19it/s]  1%|          | 7/1070 [00:02<02:57,  6.00it/s]  1%|          | 8/1070 [00:02<02:38,  6.69it/s]  1%|          | 9/1070 [00:02<02:26,  7.23it/s]  1%|          | 10/1070 [00:02<02:18,  7.64it/s]  1%|          | 11/1070 [00:02<02:11,  8.03it/s]  1%|          | 12/1070 [00:02<02:07,  8.33it/s]  1%|          | 13/1070 [00:02<02:04,  8.46it/s]  1%|▏         | 14/1070 [00:02<02:03,  8.57it/s]  1%|▏         | 15/1070 [00:03<02:03,  8.57it/s]  1%|▏         | 16/1070 [00:03<02:01,  8.68it/s]  2%|▏         | 17/1070 [00:03<02:00,  8.75it/s]  2%|▏         | 18/1070 [00:03<01:57,  8.95it/s]  2%|▏         | 19/1070 [00:03<01:58,  8.85it/s]  2%|▏         | 20/1070 [00:03<01:57,  8.92it/s]  2%|▏         | 21/1070 [00:03<01:58,  8.87it/s]  2%|▏         | 22/1070 [00:03<01:58,  8.86it/s]  2%|▏         | 23/1070 [00:03<01:57,  8.88it/s]  2%|▏         | 24/1070 [00:04<01:58,  8.86it/s]  2%|▏         | 25/1070 [00:04<01:58,  8.85it/s]  2%|▏         | 26/1070 [00:04<01:57,  8.88it/s]  3%|▎         | 27/1070 [00:04<01:57,  8.90it/s]  3%|▎         | 28/1070 [00:04<01:55,  9.00it/s]  3%|▎         | 29/1070 [00:04<01:57,  8.89it/s]  3%|▎         | 30/1070 [00:04<01:56,  8.89it/s]  3%|▎         | 31/1070 [00:04<01:57,  8.84it/s]  3%|▎         | 32/1070 [00:04<01:56,  8.94it/s]  3%|▎         | 33/1070 [00:05<01:55,  8.97it/s]  3%|▎         | 34/1070 [00:05<01:56,  8.93it/s]  3%|▎         | 35/1070 [00:05<01:55,  8.93it/s]  3%|▎         | 36/1070 [00:05<01:56,  8.89it/s]  3%|▎         | 37/1070 [00:05<01:56,  8.86it/s]  4%|▎         | 38/1070 [00:05<01:54,  8.99it/s]  4%|▎         | 39/1070 [00:05<01:55,  8.95it/s]  4%|▎         | 40/1070 [00:05<01:54,  8.96it/s]  4%|▍         | 41/1070 [00:06<01:55,  8.91it/s]  4%|▍         | 42/1070 [00:06<01:54,  8.99it/s]  4%|▍         | 43/1070 [00:06<01:54,  8.97it/s]  4%|▍         | 44/1070 [00:06<01:54,  8.95it/s]  4%|▍         | 45/1070 [00:06<01:54,  8.93it/s]  4%|▍         | 46/1070 [00:06<01:54,  8.93it/s]  4%|▍         | 47/1070 [00:06<01:54,  8.93it/s]  4%|▍         | 48/1070 [00:06<01:53,  9.04it/s]  5%|▍         | 49/1070 [00:06<01:53,  9.00it/s]  5%|▍         | 50/1070 [00:07<01:54,  8.94it/s]  5%|▍         | 51/1070 [00:07<01:55,  8.86it/s]  5%|▍         | 52/1070 [00:07<01:54,  8.87it/s]  5%|▍         | 53/1070 [00:07<01:53,  8.93it/s]  5%|▌         | 54/1070 [00:07<01:53,  8.93it/s]  5%|▌         | 55/1070 [00:07<01:52,  9.01it/s]  5%|▌         | 56/1070 [00:07<01:53,  8.91it/s]  5%|▌         | 57/1070 [00:07<01:52,  8.98it/s]  5%|▌         | 58/1070 [00:07<01:51,  9.06it/s]  6%|▌         | 59/1070 [00:08<01:52,  8.99it/s]  6%|▌         | 60/1070 [00:08<01:52,  8.96it/s]  6%|▌         | 61/1070 [00:08<01:53,  8.87it/s]  6%|▌         | 62/1070 [00:08<01:52,  8.94it/s]  6%|▌         | 63/1070 [00:08<01:52,  8.94it/s]  6%|▌         | 64/1070 [00:08<01:52,  8.93it/s]  6%|▌         | 65/1070 [00:08<01:51,  9.01it/s]  6%|▌         | 66/1070 [00:08<01:52,  8.91it/s]  6%|▋         | 67/1070 [00:08<01:52,  8.95it/s]  6%|▋         | 68/1070 [00:09<01:50,  9.07it/s]  6%|▋         | 69/1070 [00:09<01:50,  9.05it/s]  7%|▋         | 70/1070 [00:09<01:51,  8.98it/s]  7%|▋         | 71/1070 [00:09<01:52,  8.90it/s]  7%|▋         | 72/1070 [00:09<01:51,  8.97it/s]  7%|▋         | 73/1070 [00:09<01:50,  9.00it/s]  7%|▋         | 74/1070 [00:09<01:51,  8.94it/s]  7%|▋         | 75/1070 [00:09<01:50,  8.97it/s]  7%|▋         | 76/1070 [00:09<01:50,  9.01it/s]  7%|▋         | 77/1070 [00:10<01:51,  8.94it/s]  7%|▋         | 78/1070 [00:10<01:49,  9.06it/s]  7%|▋         | 79/1070 [00:10<01:48,  9.10it/s]  7%|▋         | 80/1070 [00:10<01:50,  9.00it/s]  8%|▊         | 81/1070 [00:10<01:50,  8.94it/s]  8%|▊         | 82/1070 [00:10<01:49,  9.03it/s]  8%|▊         | 83/1070 [00:10<01:49,  9.01it/s]  8%|▊         | 84/1070 [00:10<01:49,  9.03it/s]  8%|▊         | 85/1070 [00:10<01:47,  9.18it/s]  8%|▊         | 86/1070 [00:11<01:48,  9.09it/s]  8%|▊         | 87/1070 [00:11<01:48,  9.10it/s]  8%|▊         | 88/1070 [00:11<01:48,  9.06it/s]  8%|▊         | 89/1070 [00:11<01:48,  9.07it/s]  8%|▊         | 90/1070 [00:11<01:48,  9.04it/s]  9%|▊         | 91/1070 [00:11<01:48,  9.01it/s]  9%|▊         | 92/1070 [00:11<01:48,  9.03it/s]  9%|▊         | 93/1070 [00:11<01:48,  8.99it/s]  9%|▉         | 94/1070 [00:11<01:47,  9.07it/s]  9%|▉         | 95/1070 [00:12<01:46,  9.15it/s]  9%|▉         | 96/1070 [00:12<01:46,  9.16it/s]  9%|▉         | 97/1070 [00:12<01:47,  9.02it/s]  9%|▉         | 98/1070 [00:12<01:47,  9.03it/s]  9%|▉         | 99/1070 [00:12<01:46,  9.09it/s]  9%|▉         | 100/1070 [00:12<01:46,  9.09it/s]  9%|▉         | 101/1070 [00:12<01:47,  9.04it/s] 10%|▉         | 102/1070 [00:12<01:46,  9.08it/s] 10%|▉         | 103/1070 [00:12<01:47,  8.98it/s] 10%|▉         | 104/1070 [00:13<01:46,  9.04it/s] 10%|▉         | 105/1070 [00:13<01:46,  9.10it/s] 10%|▉         | 106/1070 [00:13<01:46,  9.09it/s] 10%|█         | 107/1070 [00:13<01:46,  9.07it/s] 10%|█         | 108/1070 [00:13<01:47,  8.98it/s] 10%|█         | 109/1070 [00:13<01:46,  9.01it/s] 10%|█         | 110/1070 [00:13<01:46,  9.05it/s] 10%|█         | 111/1070 [00:13<01:46,  8.99it/s] 10%|█         | 112/1070 [00:13<01:45,  9.05it/s] 11%|█         | 113/1070 [00:13<01:46,  9.02it/s] 11%|█         | 114/1070 [00:14<01:46,  8.98it/s] 11%|█         | 115/1070 [00:14<01:45,  9.08it/s] 11%|█         | 116/1070 [00:14<01:44,  9.10it/s] 11%|█         | 117/1070 [00:14<01:45,  9.03it/s] 11%|█         | 118/1070 [00:14<01:45,  8.99it/s] 11%|█         | 119/1070 [00:14<01:46,  8.95it/s] 11%|█         | 120/1070 [00:14<01:45,  9.02it/s] 11%|█▏        | 121/1070 [00:14<01:45,  9.02it/s] 11%|█▏        | 122/1070 [00:14<01:43,  9.13it/s] 11%|█▏        | 123/1070 [00:15<01:45,  8.94it/s] 12%|█▏        | 124/1070 [00:15<01:46,  8.92it/s] 12%|█▏        | 125/1070 [00:15<01:45,  8.97it/s] 12%|█▏        | 126/1070 [00:15<01:45,  8.98it/s] 12%|█▏        | 127/1070 [00:15<01:46,  8.89it/s] 12%|█▏        | 128/1070 [00:15<01:46,  8.88it/s] 12%|█▏        | 129/1070 [00:15<01:45,  8.93it/s] 12%|█▏        | 130/1070 [00:15<01:45,  8.93it/s] 12%|█▏        | 131/1070 [00:16<01:45,  8.89it/s] 12%|█▏        | 132/1070 [00:16<01:43,  9.08it/s] 12%|█▏        | 133/1070 [00:16<01:44,  9.00it/s] 13%|█▎        | 134/1070 [00:16<01:44,  8.97it/s] 13%|█▎        | 135/1070 [00:16<01:44,  8.96it/s] 13%|█▎        | 136/1070 [00:16<01:43,  9.02it/s] 13%|█▎        | 137/1070 [00:16<01:44,  8.96it/s] 13%|█▎        | 138/1070 [00:16<01:44,  8.93it/s] 13%|█▎        | 139/1070 [00:16<01:43,  8.97it/s] 13%|█▎        | 140/1070 [00:17<01:44,  8.93it/s] 13%|█▎        | 141/1070 [00:17<01:43,  8.96it/s] 13%|█▎        | 142/1070 [00:17<01:42,  9.08it/s] 13%|█▎        | 143/1070 [00:17<01:43,  8.97it/s] 13%|█▎        | 144/1070 [00:17<01:42,  9.00it/s] 14%|█▎        | 145/1070 [00:17<01:42,  8.99it/s] 14%|█▎        | 146/1070 [00:17<01:42,  9.01it/s] 14%|█▎        | 147/1070 [00:17<01:42,  9.04it/s] 14%|█▍        | 148/1070 [00:17<01:43,  8.95it/s] 14%|█▍        | 149/1070 [00:18<01:42,  8.95it/s] 14%|█▍        | 150/1070 [00:18<01:42,  8.96it/s] 14%|█▍        | 151/1070 [00:18<01:43,  8.88it/s] 14%|█▍        | 152/1070 [00:18<01:41,  9.02it/s] 14%|█▍        | 153/1070 [00:18<01:42,  8.96it/s] 14%|█▍        | 154/1070 [00:18<01:42,  8.91it/s] 14%|█▍        | 155/1070 [00:18<01:42,  8.89it/s] 15%|█▍        | 156/1070 [00:18<01:42,  8.90it/s] 15%|█▍        | 157/1070 [00:18<01:41,  8.96it/s] 15%|█▍        | 158/1070 [00:19<01:42,  8.91it/s] 15%|█▍        | 159/1070 [00:19<01:41,  9.00it/s] 15%|█▍        | 160/1070 [00:19<01:41,  8.93it/s] 15%|█▌        | 161/1070 [00:19<01:42,  8.84it/s] 15%|█▌        | 162/1070 [00:19<01:41,  8.93it/s] 15%|█▌        | 163/1070 [00:19<01:41,  8.93it/s] 15%|█▌        | 164/1070 [00:19<01:42,  8.87it/s] 15%|█▌        | 165/1070 [00:19<01:41,  8.92it/s] 16%|█▌        | 166/1070 [00:19<01:41,  8.87it/s] 16%|█▌        | 167/1070 [00:20<01:41,  8.87it/s] 16%|█▌        | 168/1070 [00:20<01:41,  8.87it/s] 16%|█▌        | 169/1070 [00:20<01:41,  8.92it/s] 16%|█▌        | 170/1070 [00:20<01:41,  8.84it/s] 16%|█▌        | 171/1070 [00:20<01:42,  8.75it/s] 16%|█▌        | 172/1070 [00:20<01:42,  8.78it/s] 16%|█▌        | 173/1070 [00:20<01:42,  8.77it/s] 16%|█▋        | 174/1070 [00:20<01:42,  8.77it/s] 16%|█▋        | 175/1070 [00:20<01:42,  8.76it/s] 16%|█▋        | 176/1070 [00:21<01:41,  8.78it/s] 17%|█▋        | 177/1070 [00:21<01:42,  8.71it/s] 17%|█▋        | 178/1070 [00:21<01:41,  8.77it/s] 17%|█▋        | 179/1070 [00:21<01:40,  8.87it/s] 17%|█▋        | 180/1070 [00:21<01:39,  8.90it/s] 17%|█▋        | 181/1070 [00:21<01:40,  8.83it/s] 17%|█▋        | 182/1070 [00:21<01:41,  8.77it/s] 17%|█▋        | 183/1070 [00:21<01:40,  8.79it/s] 17%|█▋        | 184/1070 [00:21<01:40,  8.84it/s] 17%|█▋        | 185/1070 [00:22<01:39,  8.91it/s] 17%|█▋        | 186/1070 [00:22<01:37,  9.02it/s] 17%|█▋        | 187/1070 [00:22<01:39,  8.90it/s] 18%|█▊        | 188/1070 [00:22<01:38,  8.93it/s] 18%|█▊        | 189/1070 [00:22<01:39,  8.85it/s] 18%|█▊        | 190/1070 [00:22<01:39,  8.89it/s] 18%|█▊        | 191/1070 [00:22<01:39,  8.83it/s] 18%|█▊        | 192/1070 [00:22<01:39,  8.79it/s] 18%|█▊        | 193/1070 [00:22<01:38,  8.92it/s] 18%|█▊        | 194/1070 [00:23<01:39,  8.81it/s] 18%|█▊        | 195/1070 [00:23<01:39,  8.82it/s] 18%|█▊        | 196/1070 [00:23<01:39,  8.80it/s] 18%|█▊        | 197/1070 [00:23<01:39,  8.81it/s] 19%|█▊        | 198/1070 [00:23<01:39,  8.75it/s] 19%|█▊        | 199/1070 [00:23<01:39,  8.73it/s] 19%|█▊        | 200/1070 [00:23<01:38,  8.79it/s] 19%|█▉        | 201/1070 [00:23<01:38,  8.85it/s] 19%|█▉        | 202/1070 [00:23<01:38,  8.81it/s] 19%|█▉        | 203/1070 [00:24<01:38,  8.85it/s] 19%|█▉        | 204/1070 [00:24<01:38,  8.77it/s] 19%|█▉        | 205/1070 [00:24<01:39,  8.71it/s] 19%|█▉        | 206/1070 [00:24<01:39,  8.65it/s] 19%|█▉        | 207/1070 [00:24<01:38,  8.74it/s] 19%|█▉        | 208/1070 [00:24<01:38,  8.71it/s] 20%|█▉        | 209/1070 [00:24<01:37,  8.79it/s] 20%|█▉        | 210/1070 [00:24<01:36,  8.89it/s] 20%|█▉        | 211/1070 [00:25<01:37,  8.84it/s] 20%|█▉        | 212/1070 [00:25<01:37,  8.78it/s] 20%|█▉        | 213/1070 [00:25<01:37,  8.75it/s]                                                   20%|██        | 214/1070 [00:25<01:37,  8.75it/s][INFO|trainer.py:755] 2023-11-15 21:16:51,080 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:16:51,082 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:16:51,082 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:16:51,082 >>   Batch size = 8
{'loss': 0.5018, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 75.70it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 72.99it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 73.64it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 68.19it/s][A
 41%|████      | 39/95 [00:00<00:00, 67.82it/s][A
 48%|████▊     | 46/95 [00:00<00:00, 67.09it/s][A
 56%|█████▌    | 53/95 [00:00<00:00, 67.73it/s][A
 63%|██████▎   | 60/95 [00:00<00:00, 67.42it/s][A
 71%|███████   | 67/95 [00:00<00:00, 65.76it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 65.73it/s][A
 85%|████████▌ | 81/95 [00:01<00:00, 64.99it/s][A
 93%|█████████▎| 88/95 [00:01<00:00, 65.93it/s][A
100%|██████████| 95/95 [00:01<00:00, 66.48it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:26<01:37,  8.75it/s]
100%|██████████| 95/95 [00:01<00:00, 66.48it/s][A
                                               [A 20%|██        | 215/1070 [00:26<06:22,  2.24it/s] 20%|██        | 216/1070 [00:27<05:11,  2.74it/s] 20%|██        | 217/1070 [00:27<04:16,  3.33it/s] 20%|██        | 218/1070 [00:27<03:32,  4.01it/s] 20%|██        | 219/1070 [00:27<02:59,  4.73it/s] 21%|██        | 220/1070 [00:27<02:36,  5.44it/s] 21%|██        | 221/1070 [00:27<02:19,  6.07it/s] 21%|██        | 222/1070 [00:27<02:07,  6.63it/s] 21%|██        | 223/1070 [00:27<01:58,  7.16it/s] 21%|██        | 224/1070 [00:27<01:51,  7.59it/s] 21%|██        | 225/1070 [00:28<01:46,  7.96it/s] 21%|██        | 226/1070 [00:28<01:43,  8.13it/s] 21%|██        | 227/1070 [00:28<01:42,  8.23it/s] 21%|██▏       | 228/1070 [00:28<01:40,  8.42it/s] 21%|██▏       | 229/1070 [00:28<01:38,  8.54it/s] 21%|██▏       | 230/1070 [00:28<01:38,  8.53it/s] 22%|██▏       | 231/1070 [00:28<01:37,  8.59it/s] 22%|██▏       | 232/1070 [00:28<01:37,  8.60it/s] 22%|██▏       | 233/1070 [00:28<01:36,  8.71it/s] 22%|██▏       | 234/1070 [00:29<01:35,  8.72it/s] 22%|██▏       | 235/1070 [00:29<01:34,  8.83it/s] 22%|██▏       | 236/1070 [00:29<01:35,  8.77it/s] 22%|██▏       | 237/1070 [00:29<01:35,  8.74it/s] 22%|██▏       | 238/1070 [00:29<01:34,  8.81it/s] 22%|██▏       | 239/1070 [00:29<01:33,  8.86it/s] 22%|██▏       | 240/1070 [00:29<01:34,  8.77it/s] 23%|██▎       | 241/1070 [00:29<01:35,  8.67it/s] 23%|██▎       | 242/1070 [00:30<01:35,  8.67it/s] 23%|██▎       | 243/1070 [00:30<01:34,  8.75it/s] 23%|██▎       | 244/1070 [00:30<01:34,  8.70it/s] 23%|██▎       | 245/1070 [00:30<01:33,  8.83it/s] 23%|██▎       | 246/1070 [00:30<01:34,  8.76it/s] 23%|██▎       | 247/1070 [00:30<01:34,  8.71it/s] 23%|██▎       | 248/1070 [00:30<01:33,  8.81it/s] 23%|██▎       | 249/1070 [00:30<01:32,  8.84it/s] 23%|██▎       | 250/1070 [00:30<01:33,  8.80it/s] 23%|██▎       | 251/1070 [00:31<01:33,  8.74it/s] 24%|██▎       | 252/1070 [00:31<01:33,  8.77it/s] 24%|██▎       | 253/1070 [00:31<01:32,  8.80it/s] 24%|██▎       | 254/1070 [00:31<01:32,  8.87it/s] 24%|██▍       | 255/1070 [00:31<01:30,  8.96it/s] 24%|██▍       | 256/1070 [00:31<01:32,  8.82it/s] 24%|██▍       | 257/1070 [00:31<01:32,  8.76it/s] 24%|██▍       | 258/1070 [00:31<01:32,  8.78it/s] 24%|██▍       | 259/1070 [00:31<01:31,  8.86it/s] 24%|██▍       | 260/1070 [00:32<01:30,  8.91it/s] 24%|██▍       | 261/1070 [00:32<01:31,  8.83it/s] 24%|██▍       | 262/1070 [00:32<01:32,  8.75it/s] 25%|██▍       | 263/1070 [00:32<01:32,  8.76it/s] 25%|██▍       | 264/1070 [00:32<01:31,  8.81it/s] 25%|██▍       | 265/1070 [00:32<01:30,  8.88it/s] 25%|██▍       | 266/1070 [00:32<01:31,  8.80it/s] 25%|██▍       | 267/1070 [00:32<01:31,  8.76it/s] 25%|██▌       | 268/1070 [00:32<01:30,  8.83it/s] 25%|██▌       | 269/1070 [00:33<01:30,  8.83it/s] 25%|██▌       | 270/1070 [00:33<01:30,  8.81it/s] 25%|██▌       | 271/1070 [00:33<01:32,  8.68it/s] 25%|██▌       | 272/1070 [00:33<01:31,  8.71it/s] 26%|██▌       | 273/1070 [00:33<01:30,  8.76it/s] 26%|██▌       | 274/1070 [00:33<01:30,  8.78it/s] 26%|██▌       | 275/1070 [00:33<01:29,  8.85it/s] 26%|██▌       | 276/1070 [00:33<01:30,  8.82it/s] 26%|██▌       | 277/1070 [00:33<01:30,  8.77it/s] 26%|██▌       | 278/1070 [00:34<01:29,  8.85it/s] 26%|██▌       | 279/1070 [00:34<01:29,  8.85it/s] 26%|██▌       | 280/1070 [00:34<01:29,  8.84it/s] 26%|██▋       | 281/1070 [00:34<01:30,  8.74it/s] 26%|██▋       | 282/1070 [00:34<01:30,  8.73it/s] 26%|██▋       | 283/1070 [00:34<01:29,  8.80it/s] 27%|██▋       | 284/1070 [00:34<01:29,  8.78it/s] 27%|██▋       | 285/1070 [00:34<01:28,  8.86it/s] 27%|██▋       | 286/1070 [00:35<01:29,  8.75it/s] 27%|██▋       | 287/1070 [00:35<01:29,  8.75it/s] 27%|██▋       | 288/1070 [00:35<01:28,  8.84it/s] 27%|██▋       | 289/1070 [00:35<01:28,  8.87it/s] 27%|██▋       | 290/1070 [00:35<01:28,  8.85it/s] 27%|██▋       | 291/1070 [00:35<01:28,  8.78it/s] 27%|██▋       | 292/1070 [00:35<01:28,  8.79it/s] 27%|██▋       | 293/1070 [00:35<01:28,  8.80it/s] 27%|██▋       | 294/1070 [00:35<01:27,  8.82it/s] 28%|██▊       | 295/1070 [00:36<01:28,  8.76it/s] 28%|██▊       | 296/1070 [00:36<01:28,  8.71it/s] 28%|██▊       | 297/1070 [00:36<01:29,  8.68it/s] 28%|██▊       | 298/1070 [00:36<01:27,  8.80it/s] 28%|██▊       | 299/1070 [00:36<01:28,  8.75it/s] 28%|██▊       | 300/1070 [00:36<01:28,  8.75it/s] 28%|██▊       | 301/1070 [00:36<01:28,  8.67it/s] 28%|██▊       | 302/1070 [00:36<01:27,  8.75it/s] 28%|██▊       | 303/1070 [00:36<01:27,  8.79it/s] 28%|██▊       | 304/1070 [00:37<01:27,  8.71it/s] 29%|██▊       | 305/1070 [00:37<01:27,  8.74it/s] 29%|██▊       | 306/1070 [00:37<01:27,  8.72it/s] 29%|██▊       | 307/1070 [00:37<01:26,  8.82it/s] 29%|██▉       | 308/1070 [00:37<01:25,  8.92it/s] 29%|██▉       | 309/1070 [00:37<01:25,  8.89it/s] 29%|██▉       | 310/1070 [00:37<01:26,  8.79it/s] 29%|██▉       | 311/1070 [00:37<01:26,  8.81it/s] 29%|██▉       | 312/1070 [00:37<01:25,  8.87it/s] 29%|██▉       | 313/1070 [00:38<01:25,  8.89it/s] 29%|██▉       | 314/1070 [00:38<01:25,  8.83it/s] 29%|██▉       | 315/1070 [00:38<01:25,  8.84it/s] 30%|██▉       | 316/1070 [00:38<01:25,  8.86it/s] 30%|██▉       | 317/1070 [00:38<01:24,  8.90it/s] 30%|██▉       | 318/1070 [00:38<01:23,  9.01it/s] 30%|██▉       | 319/1070 [00:38<01:24,  8.90it/s] 30%|██▉       | 320/1070 [00:38<01:24,  8.84it/s] 30%|███       | 321/1070 [00:38<01:23,  8.97it/s] 30%|███       | 322/1070 [00:39<01:23,  9.00it/s] 30%|███       | 323/1070 [00:39<01:24,  8.89it/s] 30%|███       | 324/1070 [00:39<01:24,  8.81it/s] 30%|███       | 325/1070 [00:39<01:23,  8.88it/s] 30%|███       | 326/1070 [00:39<01:23,  8.92it/s] 31%|███       | 327/1070 [00:39<01:24,  8.84it/s] 31%|███       | 328/1070 [00:39<01:23,  8.92it/s] 31%|███       | 329/1070 [00:39<01:23,  8.86it/s] 31%|███       | 330/1070 [00:39<01:23,  8.88it/s] 31%|███       | 331/1070 [00:40<01:22,  9.01it/s] 31%|███       | 332/1070 [00:40<01:23,  8.86it/s] 31%|███       | 333/1070 [00:40<01:23,  8.81it/s] 31%|███       | 334/1070 [00:40<01:22,  8.87it/s] 31%|███▏      | 335/1070 [00:40<01:22,  8.94it/s] 31%|███▏      | 336/1070 [00:40<01:23,  8.84it/s] 31%|███▏      | 337/1070 [00:40<01:23,  8.83it/s] 32%|███▏      | 338/1070 [00:40<01:23,  8.81it/s] 32%|███▏      | 339/1070 [00:41<01:22,  8.88it/s] 32%|███▏      | 340/1070 [00:41<01:22,  8.85it/s] 32%|███▏      | 341/1070 [00:41<01:22,  8.83it/s] 32%|███▏      | 342/1070 [00:41<01:22,  8.84it/s] 32%|███▏      | 343/1070 [00:41<01:22,  8.86it/s] 32%|███▏      | 344/1070 [00:41<01:21,  8.95it/s] 32%|███▏      | 345/1070 [00:41<01:22,  8.81it/s] 32%|███▏      | 346/1070 [00:41<01:22,  8.79it/s] 32%|███▏      | 347/1070 [00:41<01:21,  8.85it/s] 33%|███▎      | 348/1070 [00:42<01:21,  8.89it/s] 33%|███▎      | 349/1070 [00:42<01:21,  8.81it/s] 33%|███▎      | 350/1070 [00:42<01:21,  8.80it/s] 33%|███▎      | 351/1070 [00:42<01:21,  8.85it/s] 33%|███▎      | 352/1070 [00:42<01:21,  8.86it/s] 33%|███▎      | 353/1070 [00:42<01:21,  8.84it/s] 33%|███▎      | 354/1070 [00:42<01:20,  8.87it/s] 33%|███▎      | 355/1070 [00:42<01:21,  8.78it/s] 33%|███▎      | 356/1070 [00:42<01:20,  8.85it/s] 33%|███▎      | 357/1070 [00:43<01:19,  8.98it/s] 33%|███▎      | 358/1070 [00:43<01:19,  8.91it/s] 34%|███▎      | 359/1070 [00:43<01:20,  8.86it/s] 34%|███▎      | 360/1070 [00:43<01:20,  8.86it/s] 34%|███▎      | 361/1070 [00:43<01:19,  8.89it/s] 34%|███▍      | 362/1070 [00:43<01:19,  8.87it/s] 34%|███▍      | 363/1070 [00:43<01:20,  8.77it/s] 34%|███▍      | 364/1070 [00:43<01:20,  8.75it/s] 34%|███▍      | 365/1070 [00:43<01:19,  8.82it/s] 34%|███▍      | 366/1070 [00:44<01:20,  8.69it/s] 34%|███▍      | 367/1070 [00:44<01:20,  8.72it/s] 34%|███▍      | 368/1070 [00:44<01:20,  8.72it/s] 34%|███▍      | 369/1070 [00:44<01:19,  8.83it/s] 35%|███▍      | 370/1070 [00:44<01:18,  8.97it/s] 35%|███▍      | 371/1070 [00:44<01:18,  8.93it/s] 35%|███▍      | 372/1070 [00:44<01:19,  8.83it/s] 35%|███▍      | 373/1070 [00:44<01:18,  8.83it/s] 35%|███▍      | 374/1070 [00:44<01:18,  8.88it/s] 35%|███▌      | 375/1070 [00:45<01:18,  8.84it/s] 35%|███▌      | 376/1070 [00:45<01:19,  8.77it/s] 35%|███▌      | 377/1070 [00:45<01:18,  8.78it/s] 35%|███▌      | 378/1070 [00:45<01:18,  8.85it/s] 35%|███▌      | 379/1070 [00:45<01:18,  8.84it/s] 36%|███▌      | 380/1070 [00:45<01:17,  8.89it/s] 36%|███▌      | 381/1070 [00:45<01:18,  8.80it/s] 36%|███▌      | 382/1070 [00:45<01:17,  8.91it/s] 36%|███▌      | 383/1070 [00:45<01:16,  9.01it/s] 36%|███▌      | 384/1070 [00:46<01:17,  8.90it/s] 36%|███▌      | 385/1070 [00:46<01:16,  8.91it/s] 36%|███▌      | 386/1070 [00:46<01:16,  8.91it/s] 36%|███▌      | 387/1070 [00:46<01:16,  8.95it/s] 36%|███▋      | 388/1070 [00:46<01:16,  8.94it/s] 36%|███▋      | 389/1070 [00:46<01:16,  8.88it/s] 36%|███▋      | 390/1070 [00:46<01:16,  8.88it/s] 37%|███▋      | 391/1070 [00:46<01:16,  8.92it/s] 37%|███▋      | 392/1070 [00:46<01:16,  8.92it/s] 37%|███▋      | 393/1070 [00:47<01:16,  8.88it/s] 37%|███▋      | 394/1070 [00:47<01:16,  8.86it/s] 37%|███▋      | 395/1070 [00:47<01:15,  8.88it/s] 37%|███▋      | 396/1070 [00:47<01:15,  8.97it/s] 37%|███▋      | 397/1070 [00:47<01:16,  8.86it/s] 37%|███▋      | 398/1070 [00:47<01:16,  8.84it/s] 37%|███▋      | 399/1070 [00:47<01:14,  8.96it/s] 37%|███▋      | 400/1070 [00:47<01:14,  9.02it/s] 37%|███▋      | 401/1070 [00:48<01:15,  8.91it/s] 38%|███▊      | 402/1070 [00:48<01:15,  8.86it/s] 38%|███▊      | 403/1070 [00:48<01:14,  8.94it/s] 38%|███▊      | 404/1070 [00:48<01:14,  8.98it/s] 38%|███▊      | 405/1070 [00:48<01:15,  8.86it/s] 38%|███▊      | 406/1070 [00:48<01:14,  8.90it/s] 38%|███▊      | 407/1070 [00:48<01:14,  8.89it/s] 38%|███▊      | 408/1070 [00:48<01:13,  8.96it/s] 38%|███▊      | 409/1070 [00:48<01:12,  9.07it/s] 38%|███▊      | 410/1070 [00:49<01:13,  8.97it/s] 38%|███▊      | 411/1070 [00:49<01:13,  8.93it/s] 39%|███▊      | 412/1070 [00:49<01:12,  9.02it/s] 39%|███▊      | 413/1070 [00:49<01:12,  9.03it/s] 39%|███▊      | 414/1070 [00:49<01:13,  8.90it/s] 39%|███▉      | 415/1070 [00:49<01:13,  8.90it/s] 39%|███▉      | 416/1070 [00:49<01:12,  8.97it/s] 39%|███▉      | 417/1070 [00:49<01:12,  9.02it/s] 39%|███▉      | 418/1070 [00:49<01:13,  8.91it/s] 39%|███▉      | 419/1070 [00:50<01:13,  8.90it/s] 39%|███▉      | 420/1070 [00:50<01:12,  8.95it/s] 39%|███▉      | 421/1070 [00:50<01:12,  8.93it/s] 39%|███▉      | 422/1070 [00:50<01:12,  8.88it/s] 40%|███▉      | 423/1070 [00:50<01:13,  8.85it/s] 40%|███▉      | 424/1070 [00:50<01:12,  8.94it/s] 40%|███▉      | 425/1070 [00:50<01:11,  9.07it/s] 40%|███▉      | 426/1070 [00:50<01:11,  9.01it/s] 40%|███▉      | 427/1070 [00:50<01:11,  8.97it/s]                                                   40%|████      | 428/1070 [00:51<01:11,  8.97it/s][INFO|trainer.py:755] 2023-11-15 21:17:16,739 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:17:16,741 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:17:16,741 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:17:16,742 >>   Batch size = 8
{'eval_loss': 0.33042779564857483, 'eval_accuracy': 0.8921052631578947, 'eval_micro_f1': 0.8921052631578947, 'eval_macro_f1': 0.8890317553087863, 'eval_runtime': 1.4584, 'eval_samples_per_second': 521.133, 'eval_steps_per_second': 65.142, 'epoch': 1.0}
{'loss': 0.2573, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 77.18it/s][A
 18%|█▊        | 17/95 [00:00<00:01, 71.42it/s][A
 26%|██▋       | 25/95 [00:00<00:00, 70.92it/s][A
 35%|███▍      | 33/95 [00:00<00:00, 72.57it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 69.96it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 69.02it/s][A
 59%|█████▉    | 56/95 [00:00<00:00, 69.11it/s][A
 67%|██████▋   | 64/95 [00:00<00:00, 70.98it/s][A
 76%|███████▌  | 72/95 [00:01<00:00, 69.98it/s][A
 84%|████████▍ | 80/95 [00:01<00:00, 69.06it/s][A
 92%|█████████▏| 87/95 [00:01<00:00, 68.99it/s][A
100%|██████████| 95/95 [00:01<00:00, 70.61it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:52<01:11,  8.97it/s]
100%|██████████| 95/95 [00:01<00:00, 70.61it/s][A
                                               [A 40%|████      | 429/1070 [00:52<04:36,  2.32it/s] 40%|████      | 430/1070 [00:52<03:46,  2.83it/s] 40%|████      | 431/1070 [00:52<03:05,  3.45it/s] 40%|████      | 432/1070 [00:52<02:33,  4.16it/s] 40%|████      | 433/1070 [00:52<02:10,  4.86it/s] 41%|████      | 434/1070 [00:53<01:53,  5.59it/s] 41%|████      | 435/1070 [00:53<01:41,  6.29it/s] 41%|████      | 436/1070 [00:53<01:31,  6.92it/s] 41%|████      | 437/1070 [00:53<01:25,  7.39it/s] 41%|████      | 438/1070 [00:53<01:21,  7.73it/s] 41%|████      | 439/1070 [00:53<01:17,  8.10it/s] 41%|████      | 440/1070 [00:53<01:15,  8.36it/s] 41%|████      | 441/1070 [00:53<01:13,  8.50it/s] 41%|████▏     | 442/1070 [00:53<01:13,  8.59it/s] 41%|████▏     | 443/1070 [00:54<01:11,  8.71it/s] 41%|████▏     | 444/1070 [00:54<01:10,  8.83it/s] 42%|████▏     | 445/1070 [00:54<01:09,  8.94it/s] 42%|████▏     | 446/1070 [00:54<01:10,  8.82it/s] 42%|████▏     | 447/1070 [00:54<01:10,  8.80it/s] 42%|████▏     | 448/1070 [00:54<01:09,  8.93it/s] 42%|████▏     | 449/1070 [00:54<01:09,  8.98it/s] 42%|████▏     | 450/1070 [00:54<01:09,  8.86it/s] 42%|████▏     | 451/1070 [00:54<01:09,  8.89it/s] 42%|████▏     | 452/1070 [00:55<01:09,  8.92it/s] 42%|████▏     | 453/1070 [00:55<01:08,  8.99it/s] 42%|████▏     | 454/1070 [00:55<01:09,  8.85it/s] 43%|████▎     | 455/1070 [00:55<01:10,  8.78it/s] 43%|████▎     | 456/1070 [00:55<01:09,  8.86it/s] 43%|████▎     | 457/1070 [00:55<01:08,  8.89it/s] 43%|████▎     | 458/1070 [00:55<01:08,  8.91it/s] 43%|████▎     | 459/1070 [00:55<01:09,  8.84it/s] 43%|████▎     | 460/1070 [00:56<01:09,  8.83it/s] 43%|████▎     | 461/1070 [00:56<01:07,  8.97it/s] 43%|████▎     | 462/1070 [00:56<01:08,  8.90it/s] 43%|████▎     | 463/1070 [00:56<01:08,  8.82it/s] 43%|████▎     | 464/1070 [00:56<01:08,  8.82it/s] 43%|████▎     | 465/1070 [00:56<01:07,  8.92it/s] 44%|████▎     | 466/1070 [00:56<01:07,  8.90it/s] 44%|████▎     | 467/1070 [00:56<01:08,  8.82it/s] 44%|████▎     | 468/1070 [00:56<01:07,  8.86it/s] 44%|████▍     | 469/1070 [00:57<01:07,  8.92it/s] 44%|████▍     | 470/1070 [00:57<01:07,  8.92it/s] 44%|████▍     | 471/1070 [00:57<01:06,  8.96it/s] 44%|████▍     | 472/1070 [00:57<01:07,  8.92it/s] 44%|████▍     | 473/1070 [00:57<01:07,  8.90it/s] 44%|████▍     | 474/1070 [00:57<01:05,  9.03it/s] 44%|████▍     | 475/1070 [00:57<01:06,  8.95it/s] 44%|████▍     | 476/1070 [00:57<01:06,  8.92it/s] 45%|████▍     | 477/1070 [00:57<01:06,  8.88it/s] 45%|████▍     | 478/1070 [00:58<01:06,  8.93it/s] 45%|████▍     | 479/1070 [00:58<01:06,  8.89it/s] 45%|████▍     | 480/1070 [00:58<01:07,  8.77it/s] 45%|████▍     | 481/1070 [00:58<01:07,  8.77it/s] 45%|████▌     | 482/1070 [00:58<01:06,  8.84it/s] 45%|████▌     | 483/1070 [00:58<01:06,  8.79it/s] 45%|████▌     | 484/1070 [00:58<01:06,  8.87it/s] 45%|████▌     | 485/1070 [00:58<01:06,  8.78it/s] 45%|████▌     | 486/1070 [00:58<01:05,  8.88it/s] 46%|████▌     | 487/1070 [00:59<01:04,  8.97it/s] 46%|████▌     | 488/1070 [00:59<01:05,  8.85it/s] 46%|████▌     | 489/1070 [00:59<01:05,  8.91it/s] 46%|████▌     | 490/1070 [00:59<01:05,  8.86it/s] 46%|████▌     | 491/1070 [00:59<01:04,  8.92it/s] 46%|████▌     | 492/1070 [00:59<01:04,  8.98it/s] 46%|████▌     | 493/1070 [00:59<01:05,  8.87it/s] 46%|████▌     | 494/1070 [00:59<01:05,  8.84it/s] 46%|████▋     | 495/1070 [00:59<01:04,  8.90it/s] 46%|████▋     | 496/1070 [01:00<01:04,  8.86it/s] 46%|████▋     | 497/1070 [01:00<01:04,  8.87it/s] 47%|████▋     | 498/1070 [01:00<01:04,  8.86it/s] 47%|████▋     | 499/1070 [01:00<01:04,  8.82it/s] 47%|████▋     | 500/1070 [01:00<01:03,  8.97it/s] 47%|████▋     | 501/1070 [01:00<01:03,  8.91it/s] 47%|████▋     | 502/1070 [01:00<01:04,  8.82it/s] 47%|████▋     | 503/1070 [01:00<01:03,  8.91it/s] 47%|████▋     | 504/1070 [01:00<01:03,  8.94it/s] 47%|████▋     | 505/1070 [01:01<01:04,  8.81it/s] 47%|████▋     | 506/1070 [01:01<01:04,  8.78it/s] 47%|████▋     | 507/1070 [01:01<01:03,  8.87it/s] 47%|████▋     | 508/1070 [01:01<01:02,  8.93it/s] 48%|████▊     | 509/1070 [01:01<01:03,  8.79it/s] 48%|████▊     | 510/1070 [01:01<01:03,  8.83it/s] 48%|████▊     | 511/1070 [01:01<01:03,  8.84it/s] 48%|████▊     | 512/1070 [01:01<01:02,  8.88it/s] 48%|████▊     | 513/1070 [01:01<01:02,  8.97it/s] 48%|████▊     | 514/1070 [01:02<01:03,  8.82it/s] 48%|████▊     | 515/1070 [01:02<01:02,  8.85it/s] 48%|████▊     | 516/1070 [01:02<01:01,  8.99it/s] 48%|████▊     | 517/1070 [01:02<01:01,  8.95it/s] 48%|████▊     | 518/1070 [01:02<01:02,  8.86it/s] 49%|████▊     | 519/1070 [01:02<01:01,  8.91it/s] 49%|████▊     | 520/1070 [01:02<01:01,  8.94it/s] 49%|████▊     | 521/1070 [01:02<01:00,  9.00it/s] 49%|████▉     | 522/1070 [01:02<01:01,  8.86it/s] 49%|████▉     | 523/1070 [01:03<01:01,  8.85it/s] 49%|████▉     | 524/1070 [01:03<01:01,  8.93it/s] 49%|████▉     | 525/1070 [01:03<01:00,  8.96it/s] 49%|████▉     | 526/1070 [01:03<01:00,  8.98it/s] 49%|████▉     | 527/1070 [01:03<01:01,  8.87it/s] 49%|████▉     | 528/1070 [01:03<01:01,  8.88it/s] 49%|████▉     | 529/1070 [01:03<01:00,  9.01it/s] 50%|████▉     | 530/1070 [01:03<01:00,  8.88it/s] 50%|████▉     | 531/1070 [01:03<01:00,  8.84it/s] 50%|████▉     | 532/1070 [01:04<01:00,  8.91it/s] 50%|████▉     | 533/1070 [01:04<01:00,  8.95it/s] 50%|████▉     | 534/1070 [01:04<01:00,  8.83it/s] 50%|█████     | 535/1070 [01:04<01:00,  8.83it/s] 50%|█████     | 536/1070 [01:04<01:00,  8.87it/s] 50%|█████     | 537/1070 [01:04<00:59,  8.90it/s] 50%|█████     | 538/1070 [01:04<01:00,  8.82it/s] 50%|█████     | 539/1070 [01:04<01:00,  8.82it/s] 50%|█████     | 540/1070 [01:05<01:00,  8.82it/s] 51%|█████     | 541/1070 [01:05<00:59,  8.86it/s] 51%|█████     | 542/1070 [01:05<00:59,  8.90it/s] 51%|█████     | 543/1070 [01:05<00:59,  8.86it/s] 51%|█████     | 544/1070 [01:05<00:59,  8.85it/s] 51%|█████     | 545/1070 [01:05<00:58,  9.00it/s] 51%|█████     | 546/1070 [01:05<00:58,  8.93it/s] 51%|█████     | 547/1070 [01:05<00:59,  8.86it/s] 51%|█████     | 548/1070 [01:05<00:58,  8.90it/s] 51%|█████▏    | 549/1070 [01:06<00:58,  8.95it/s] 51%|█████▏    | 550/1070 [01:06<00:58,  8.93it/s] 51%|█████▏    | 551/1070 [01:06<00:58,  8.85it/s] 52%|█████▏    | 552/1070 [01:06<00:58,  8.85it/s] 52%|█████▏    | 553/1070 [01:06<00:58,  8.90it/s] 52%|█████▏    | 554/1070 [01:06<00:57,  8.92it/s] 52%|█████▏    | 555/1070 [01:06<00:57,  8.89it/s] 52%|█████▏    | 556/1070 [01:06<00:57,  8.90it/s] 52%|█████▏    | 557/1070 [01:06<00:57,  8.94it/s] 52%|█████▏    | 558/1070 [01:07<00:56,  9.01it/s] 52%|█████▏    | 559/1070 [01:07<00:56,  8.99it/s] 52%|█████▏    | 560/1070 [01:07<00:57,  8.84it/s] 52%|█████▏    | 561/1070 [01:07<00:56,  8.98it/s] 53%|█████▎    | 562/1070 [01:07<00:56,  8.99it/s] 53%|█████▎    | 563/1070 [01:07<00:56,  8.89it/s] 53%|█████▎    | 564/1070 [01:07<00:57,  8.81it/s] 53%|█████▎    | 565/1070 [01:07<00:56,  8.91it/s] 53%|█████▎    | 566/1070 [01:07<00:56,  8.91it/s] 53%|█████▎    | 567/1070 [01:08<00:56,  8.84it/s] 53%|█████▎    | 568/1070 [01:08<00:57,  8.77it/s] 53%|█████▎    | 569/1070 [01:08<00:56,  8.86it/s] 53%|█████▎    | 570/1070 [01:08<00:56,  8.89it/s] 53%|█████▎    | 571/1070 [01:08<00:54,  9.10it/s] 53%|█████▎    | 572/1070 [01:08<00:55,  8.95it/s] 54%|█████▎    | 573/1070 [01:08<00:55,  8.90it/s] 54%|█████▎    | 574/1070 [01:08<00:55,  8.98it/s] 54%|█████▎    | 575/1070 [01:08<00:54,  9.01it/s] 54%|█████▍    | 576/1070 [01:09<00:55,  8.83it/s] 54%|█████▍    | 577/1070 [01:09<00:55,  8.89it/s] 54%|█████▍    | 578/1070 [01:09<00:54,  8.98it/s] 54%|█████▍    | 579/1070 [01:09<00:54,  9.03it/s] 54%|█████▍    | 580/1070 [01:09<00:55,  8.87it/s] 54%|█████▍    | 581/1070 [01:09<00:55,  8.88it/s] 54%|█████▍    | 582/1070 [01:09<00:55,  8.86it/s] 54%|█████▍    | 583/1070 [01:09<00:54,  8.98it/s] 55%|█████▍    | 584/1070 [01:09<00:54,  8.98it/s] 55%|█████▍    | 585/1070 [01:10<00:54,  8.90it/s] 55%|█████▍    | 586/1070 [01:10<00:54,  8.91it/s] 55%|█████▍    | 587/1070 [01:10<00:53,  9.02it/s] 55%|█████▍    | 588/1070 [01:10<00:53,  8.98it/s] 55%|█████▌    | 589/1070 [01:10<00:54,  8.90it/s] 55%|█████▌    | 590/1070 [01:10<00:53,  8.93it/s] 55%|█████▌    | 591/1070 [01:10<00:53,  8.95it/s] 55%|█████▌    | 592/1070 [01:10<00:53,  8.85it/s] 55%|█████▌    | 593/1070 [01:10<00:54,  8.80it/s] 56%|█████▌    | 594/1070 [01:11<00:53,  8.89it/s] 56%|█████▌    | 595/1070 [01:11<00:53,  8.90it/s] 56%|█████▌    | 596/1070 [01:11<00:53,  8.80it/s] 56%|█████▌    | 597/1070 [01:11<00:53,  8.83it/s] 56%|█████▌    | 598/1070 [01:11<00:53,  8.87it/s] 56%|█████▌    | 599/1070 [01:11<00:52,  8.91it/s] 56%|█████▌    | 600/1070 [01:11<00:52,  8.95it/s] 56%|█████▌    | 601/1070 [01:11<00:53,  8.82it/s] 56%|█████▋    | 602/1070 [01:11<00:52,  8.92it/s] 56%|█████▋    | 603/1070 [01:12<00:52,  8.97it/s] 56%|█████▋    | 604/1070 [01:12<00:52,  8.84it/s] 57%|█████▋    | 605/1070 [01:12<00:52,  8.80it/s] 57%|█████▋    | 606/1070 [01:12<00:52,  8.91it/s] 57%|█████▋    | 607/1070 [01:12<00:51,  8.94it/s] 57%|█████▋    | 608/1070 [01:12<00:51,  8.91it/s] 57%|█████▋    | 609/1070 [01:12<00:51,  8.87it/s] 57%|█████▋    | 610/1070 [01:12<00:51,  8.94it/s] 57%|█████▋    | 611/1070 [01:12<00:51,  8.93it/s] 57%|█████▋    | 612/1070 [01:13<00:52,  8.81it/s] 57%|█████▋    | 613/1070 [01:13<00:51,  8.82it/s] 57%|█████▋    | 614/1070 [01:13<00:51,  8.88it/s] 57%|█████▋    | 615/1070 [01:13<00:51,  8.89it/s] 58%|█████▊    | 616/1070 [01:13<00:50,  8.93it/s] 58%|█████▊    | 617/1070 [01:13<00:51,  8.82it/s] 58%|█████▊    | 618/1070 [01:13<00:50,  8.89it/s] 58%|█████▊    | 619/1070 [01:13<00:50,  8.97it/s] 58%|█████▊    | 620/1070 [01:13<00:50,  8.90it/s] 58%|█████▊    | 621/1070 [01:14<00:51,  8.77it/s] 58%|█████▊    | 622/1070 [01:14<00:50,  8.88it/s] 58%|█████▊    | 623/1070 [01:14<00:50,  8.90it/s] 58%|█████▊    | 624/1070 [01:14<00:50,  8.82it/s] 58%|█████▊    | 625/1070 [01:14<00:50,  8.84it/s] 59%|█████▊    | 626/1070 [01:14<00:49,  8.88it/s] 59%|█████▊    | 627/1070 [01:14<00:49,  8.90it/s] 59%|█████▊    | 628/1070 [01:14<00:49,  8.84it/s] 59%|█████▉    | 629/1070 [01:15<00:50,  8.81it/s] 59%|█████▉    | 630/1070 [01:15<00:49,  8.83it/s] 59%|█████▉    | 631/1070 [01:15<00:49,  8.91it/s] 59%|█████▉    | 632/1070 [01:15<00:48,  8.95it/s] 59%|█████▉    | 633/1070 [01:15<00:49,  8.79it/s] 59%|█████▉    | 634/1070 [01:15<00:49,  8.84it/s] 59%|█████▉    | 635/1070 [01:15<00:48,  8.95it/s] 59%|█████▉    | 636/1070 [01:15<00:48,  8.94it/s] 60%|█████▉    | 637/1070 [01:15<00:49,  8.78it/s] 60%|█████▉    | 638/1070 [01:16<00:48,  8.90it/s] 60%|█████▉    | 639/1070 [01:16<00:48,  8.95it/s] 60%|█████▉    | 640/1070 [01:16<00:48,  8.88it/s] 60%|█████▉    | 641/1070 [01:16<00:48,  8.82it/s]                                                   60%|██████    | 642/1070 [01:16<00:48,  8.82it/s][INFO|trainer.py:755] 2023-11-15 21:17:42,187 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:17:42,189 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:17:42,189 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:17:42,189 >>   Batch size = 8
{'eval_loss': 0.3067358434200287, 'eval_accuracy': 0.9026315789473685, 'eval_micro_f1': 0.9026315789473685, 'eval_macro_f1': 0.8997278047452706, 'eval_runtime': 1.3969, 'eval_samples_per_second': 544.044, 'eval_steps_per_second': 68.005, 'epoch': 2.0}
{'loss': 0.157, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 79.25it/s][A
 18%|█▊        | 17/95 [00:00<00:01, 69.26it/s][A
 25%|██▌       | 24/95 [00:00<00:01, 69.34it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 70.91it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 71.03it/s][A
 51%|█████     | 48/95 [00:00<00:00, 69.45it/s][A
 58%|█████▊    | 55/95 [00:00<00:00, 68.13it/s][A
 65%|██████▌   | 62/95 [00:00<00:00, 68.22it/s][A
 74%|███████▎  | 70/95 [00:00<00:00, 70.24it/s][A
 82%|████████▏ | 78/95 [00:01<00:00, 70.69it/s][A
 91%|█████████ | 86/95 [00:01<00:00, 67.93it/s][A
 98%|█████████▊| 93/95 [00:01<00:00, 68.36it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:17<00:48,  8.82it/s]
100%|██████████| 95/95 [00:01<00:00, 68.36it/s][A
                                               [A 60%|██████    | 643/1070 [01:18<03:07,  2.28it/s] 60%|██████    | 644/1070 [01:18<02:32,  2.79it/s] 60%|██████    | 645/1070 [01:18<02:05,  3.40it/s] 60%|██████    | 646/1070 [01:18<01:44,  4.05it/s] 60%|██████    | 647/1070 [01:18<01:28,  4.77it/s] 61%|██████    | 648/1070 [01:18<01:16,  5.53it/s] 61%|██████    | 649/1070 [01:18<01:07,  6.23it/s] 61%|██████    | 650/1070 [01:18<01:02,  6.75it/s] 61%|██████    | 651/1070 [01:18<00:57,  7.27it/s] 61%|██████    | 652/1070 [01:19<00:54,  7.70it/s] 61%|██████    | 653/1070 [01:19<00:51,  8.04it/s] 61%|██████    | 654/1070 [01:19<00:50,  8.20it/s] 61%|██████    | 655/1070 [01:19<00:49,  8.39it/s] 61%|██████▏   | 656/1070 [01:19<00:48,  8.58it/s] 61%|██████▏   | 657/1070 [01:19<00:47,  8.63it/s] 61%|██████▏   | 658/1070 [01:19<00:47,  8.71it/s] 62%|██████▏   | 659/1070 [01:19<00:47,  8.73it/s] 62%|██████▏   | 660/1070 [01:19<00:46,  8.85it/s] 62%|██████▏   | 661/1070 [01:20<00:45,  8.91it/s] 62%|██████▏   | 662/1070 [01:20<00:46,  8.84it/s] 62%|██████▏   | 663/1070 [01:20<00:45,  8.91it/s] 62%|██████▏   | 664/1070 [01:20<00:45,  8.99it/s] 62%|██████▏   | 665/1070 [01:20<00:45,  8.99it/s] 62%|██████▏   | 666/1070 [01:20<00:45,  8.89it/s] 62%|██████▏   | 667/1070 [01:20<00:45,  8.88it/s] 62%|██████▏   | 668/1070 [01:20<00:44,  8.96it/s] 63%|██████▎   | 669/1070 [01:20<00:44,  9.06it/s] 63%|██████▎   | 670/1070 [01:21<00:44,  8.90it/s] 63%|██████▎   | 671/1070 [01:21<00:44,  8.89it/s] 63%|██████▎   | 672/1070 [01:21<00:44,  8.95it/s] 63%|██████▎   | 673/1070 [01:21<00:44,  8.95it/s] 63%|██████▎   | 674/1070 [01:21<00:43,  9.05it/s] 63%|██████▎   | 675/1070 [01:21<00:44,  8.93it/s] 63%|██████▎   | 676/1070 [01:21<00:44,  8.94it/s] 63%|██████▎   | 677/1070 [01:21<00:43,  9.01it/s] 63%|██████▎   | 678/1070 [01:21<00:43,  8.94it/s] 63%|██████▎   | 679/1070 [01:22<00:44,  8.86it/s] 64%|██████▎   | 680/1070 [01:22<00:43,  8.97it/s] 64%|██████▎   | 681/1070 [01:22<00:43,  9.04it/s] 64%|██████▎   | 682/1070 [01:22<00:43,  8.91it/s] 64%|██████▍   | 683/1070 [01:22<00:43,  8.92it/s] 64%|██████▍   | 684/1070 [01:22<00:42,  9.00it/s] 64%|██████▍   | 685/1070 [01:22<00:42,  9.04it/s] 64%|██████▍   | 686/1070 [01:22<00:43,  8.92it/s] 64%|██████▍   | 687/1070 [01:22<00:42,  8.95it/s] 64%|██████▍   | 688/1070 [01:23<00:42,  9.00it/s] 64%|██████▍   | 689/1070 [01:23<00:42,  8.99it/s] 64%|██████▍   | 690/1070 [01:23<00:42,  8.98it/s] 65%|██████▍   | 691/1070 [01:23<00:42,  8.88it/s] 65%|██████▍   | 692/1070 [01:23<00:42,  8.95it/s] 65%|██████▍   | 693/1070 [01:23<00:41,  9.00it/s] 65%|██████▍   | 694/1070 [01:23<00:42,  8.90it/s] 65%|██████▍   | 695/1070 [01:23<00:42,  8.89it/s] 65%|██████▌   | 696/1070 [01:23<00:41,  8.97it/s] 65%|██████▌   | 697/1070 [01:24<00:41,  8.97it/s] 65%|██████▌   | 698/1070 [01:24<00:42,  8.82it/s] 65%|██████▌   | 699/1070 [01:24<00:41,  8.92it/s] 65%|██████▌   | 700/1070 [01:24<00:41,  8.93it/s] 66%|██████▌   | 701/1070 [01:24<00:41,  8.83it/s] 66%|██████▌   | 702/1070 [01:24<00:41,  8.79it/s] 66%|██████▌   | 703/1070 [01:24<00:41,  8.86it/s] 66%|██████▌   | 704/1070 [01:24<00:41,  8.82it/s] 66%|██████▌   | 705/1070 [01:24<00:41,  8.79it/s] 66%|██████▌   | 706/1070 [01:25<00:41,  8.83it/s] 66%|██████▌   | 707/1070 [01:25<00:40,  8.93it/s] 66%|██████▌   | 708/1070 [01:25<00:40,  8.93it/s] 66%|██████▋   | 709/1070 [01:25<00:40,  8.93it/s] 66%|██████▋   | 710/1070 [01:25<00:40,  8.93it/s] 66%|██████▋   | 711/1070 [01:25<00:39,  8.99it/s] 67%|██████▋   | 712/1070 [01:25<00:39,  9.02it/s] 67%|██████▋   | 713/1070 [01:25<00:40,  8.90it/s] 67%|██████▋   | 714/1070 [01:25<00:40,  8.89it/s] 67%|██████▋   | 715/1070 [01:26<00:39,  8.99it/s] 67%|██████▋   | 716/1070 [01:26<00:39,  8.87it/s] 67%|██████▋   | 717/1070 [01:26<00:39,  8.85it/s] 67%|██████▋   | 718/1070 [01:26<00:39,  8.93it/s] 67%|██████▋   | 719/1070 [01:26<00:38,  9.01it/s] 67%|██████▋   | 720/1070 [01:26<00:39,  8.89it/s] 67%|██████▋   | 721/1070 [01:26<00:39,  8.84it/s] 67%|██████▋   | 722/1070 [01:26<00:39,  8.92it/s] 68%|██████▊   | 723/1070 [01:26<00:38,  8.98it/s] 68%|██████▊   | 724/1070 [01:27<00:38,  8.93it/s] 68%|██████▊   | 725/1070 [01:27<00:38,  8.89it/s] 68%|██████▊   | 726/1070 [01:27<00:38,  8.94it/s] 68%|██████▊   | 727/1070 [01:27<00:38,  8.97it/s] 68%|██████▊   | 728/1070 [01:27<00:38,  8.98it/s] 68%|██████▊   | 729/1070 [01:27<00:38,  8.89it/s] 68%|██████▊   | 730/1070 [01:27<00:37,  8.99it/s] 68%|██████▊   | 731/1070 [01:27<00:37,  8.99it/s] 68%|██████▊   | 732/1070 [01:27<00:38,  8.85it/s] 69%|██████▊   | 733/1070 [01:28<00:37,  8.91it/s] 69%|██████▊   | 734/1070 [01:28<00:37,  9.02it/s] 69%|██████▊   | 735/1070 [01:28<00:37,  9.05it/s] 69%|██████▉   | 736/1070 [01:28<00:37,  8.93it/s] 69%|██████▉   | 737/1070 [01:28<00:37,  8.97it/s] 69%|██████▉   | 738/1070 [01:28<00:36,  9.04it/s] 69%|██████▉   | 739/1070 [01:28<00:36,  8.99it/s] 69%|██████▉   | 740/1070 [01:28<00:36,  8.92it/s] 69%|██████▉   | 741/1070 [01:28<00:36,  8.97it/s] 69%|██████▉   | 742/1070 [01:29<00:36,  9.03it/s] 69%|██████▉   | 743/1070 [01:29<00:36,  8.92it/s] 70%|██████▉   | 744/1070 [01:29<00:36,  8.90it/s] 70%|██████▉   | 745/1070 [01:29<00:36,  8.97it/s] 70%|██████▉   | 746/1070 [01:29<00:36,  8.97it/s] 70%|██████▉   | 747/1070 [01:29<00:35,  8.98it/s] 70%|██████▉   | 748/1070 [01:29<00:36,  8.85it/s] 70%|███████   | 749/1070 [01:29<00:35,  8.94it/s] 70%|███████   | 750/1070 [01:29<00:35,  8.93it/s] 70%|███████   | 751/1070 [01:30<00:35,  8.87it/s] 70%|███████   | 752/1070 [01:30<00:35,  8.93it/s] 70%|███████   | 753/1070 [01:30<00:34,  9.07it/s] 70%|███████   | 754/1070 [01:30<00:34,  9.05it/s] 71%|███████   | 755/1070 [01:30<00:35,  8.96it/s] 71%|███████   | 756/1070 [01:30<00:34,  9.01it/s] 71%|███████   | 757/1070 [01:30<00:34,  9.09it/s] 71%|███████   | 758/1070 [01:30<00:34,  8.92it/s] 71%|███████   | 759/1070 [01:30<00:34,  8.89it/s] 71%|███████   | 760/1070 [01:31<00:34,  8.94it/s] 71%|███████   | 761/1070 [01:31<00:34,  8.97it/s] 71%|███████   | 762/1070 [01:31<00:34,  8.85it/s] 71%|███████▏  | 763/1070 [01:31<00:34,  8.88it/s] 71%|███████▏  | 764/1070 [01:31<00:34,  8.97it/s] 71%|███████▏  | 765/1070 [01:31<00:34,  8.96it/s] 72%|███████▏  | 766/1070 [01:31<00:33,  8.96it/s] 72%|███████▏  | 767/1070 [01:31<00:33,  8.95it/s] 72%|███████▏  | 768/1070 [01:32<00:33,  9.01it/s] 72%|███████▏  | 769/1070 [01:32<00:33,  9.05it/s] 72%|███████▏  | 770/1070 [01:32<00:33,  8.88it/s] 72%|███████▏  | 771/1070 [01:32<00:33,  8.94it/s] 72%|███████▏  | 772/1070 [01:32<00:33,  8.98it/s] 72%|███████▏  | 773/1070 [01:32<00:33,  8.87it/s] 72%|███████▏  | 774/1070 [01:32<00:33,  8.89it/s] 72%|███████▏  | 775/1070 [01:32<00:32,  9.00it/s] 73%|███████▎  | 776/1070 [01:32<00:32,  9.02it/s] 73%|███████▎  | 777/1070 [01:33<00:33,  8.86it/s] 73%|███████▎  | 778/1070 [01:33<00:32,  8.92it/s] 73%|███████▎  | 779/1070 [01:33<00:32,  9.03it/s] 73%|███████▎  | 780/1070 [01:33<00:32,  9.01it/s] 73%|███████▎  | 781/1070 [01:33<00:32,  8.90it/s] 73%|███████▎  | 782/1070 [01:33<00:32,  8.91it/s] 73%|███████▎  | 783/1070 [01:33<00:31,  9.03it/s] 73%|███████▎  | 784/1070 [01:33<00:32,  8.87it/s] 73%|███████▎  | 785/1070 [01:33<00:32,  8.90it/s] 73%|███████▎  | 786/1070 [01:34<00:31,  8.94it/s] 74%|███████▎  | 787/1070 [01:34<00:31,  9.00it/s] 74%|███████▎  | 788/1070 [01:34<00:31,  8.97it/s] 74%|███████▎  | 789/1070 [01:34<00:31,  8.87it/s] 74%|███████▍  | 790/1070 [01:34<00:31,  8.93it/s] 74%|███████▍  | 791/1070 [01:34<00:31,  9.00it/s] 74%|███████▍  | 792/1070 [01:34<00:31,  8.87it/s] 74%|███████▍  | 793/1070 [01:34<00:31,  8.87it/s] 74%|███████▍  | 794/1070 [01:34<00:30,  8.99it/s] 74%|███████▍  | 795/1070 [01:35<00:30,  8.99it/s] 74%|███████▍  | 796/1070 [01:35<00:30,  8.85it/s] 74%|███████▍  | 797/1070 [01:35<00:30,  8.87it/s] 75%|███████▍  | 798/1070 [01:35<00:30,  8.93it/s] 75%|███████▍  | 799/1070 [01:35<00:30,  8.86it/s] 75%|███████▍  | 800/1070 [01:35<00:30,  8.79it/s] 75%|███████▍  | 801/1070 [01:35<00:30,  8.90it/s] 75%|███████▍  | 802/1070 [01:35<00:29,  8.95it/s] 75%|███████▌  | 803/1070 [01:35<00:30,  8.79it/s] 75%|███████▌  | 804/1070 [01:36<00:30,  8.81it/s] 75%|███████▌  | 805/1070 [01:36<00:29,  8.91it/s] 75%|███████▌  | 806/1070 [01:36<00:29,  8.92it/s] 75%|███████▌  | 807/1070 [01:36<00:29,  8.91it/s] 76%|███████▌  | 808/1070 [01:36<00:29,  8.78it/s] 76%|███████▌  | 809/1070 [01:36<00:29,  8.86it/s] 76%|███████▌  | 810/1070 [01:36<00:29,  8.88it/s] 76%|███████▌  | 811/1070 [01:36<00:29,  8.85it/s] 76%|███████▌  | 812/1070 [01:36<00:29,  8.87it/s] 76%|███████▌  | 813/1070 [01:37<00:28,  8.95it/s] 76%|███████▌  | 814/1070 [01:37<00:28,  8.92it/s] 76%|███████▌  | 815/1070 [01:37<00:28,  8.81it/s] 76%|███████▋  | 816/1070 [01:37<00:28,  8.87it/s] 76%|███████▋  | 817/1070 [01:37<00:28,  8.98it/s] 76%|███████▋  | 818/1070 [01:37<00:28,  8.97it/s] 77%|███████▋  | 819/1070 [01:37<00:28,  8.93it/s] 77%|███████▋  | 820/1070 [01:37<00:28,  8.90it/s] 77%|███████▋  | 821/1070 [01:37<00:27,  8.97it/s] 77%|███████▋  | 822/1070 [01:38<00:28,  8.83it/s] 77%|███████▋  | 823/1070 [01:38<00:27,  8.89it/s] 77%|███████▋  | 824/1070 [01:38<00:27,  8.89it/s] 77%|███████▋  | 825/1070 [01:38<00:27,  9.00it/s] 77%|███████▋  | 826/1070 [01:38<00:27,  8.99it/s] 77%|███████▋  | 827/1070 [01:38<00:27,  8.90it/s] 77%|███████▋  | 828/1070 [01:38<00:27,  8.96it/s] 77%|███████▋  | 829/1070 [01:38<00:26,  9.04it/s] 78%|███████▊  | 830/1070 [01:38<00:26,  8.95it/s] 78%|███████▊  | 831/1070 [01:39<00:26,  8.89it/s] 78%|███████▊  | 832/1070 [01:39<00:26,  8.95it/s] 78%|███████▊  | 833/1070 [01:39<00:26,  9.01it/s] 78%|███████▊  | 834/1070 [01:39<00:26,  8.84it/s] 78%|███████▊  | 835/1070 [01:39<00:26,  8.83it/s] 78%|███████▊  | 836/1070 [01:39<00:26,  8.90it/s] 78%|███████▊  | 837/1070 [01:39<00:25,  8.97it/s] 78%|███████▊  | 838/1070 [01:39<00:26,  8.81it/s] 78%|███████▊  | 839/1070 [01:39<00:26,  8.81it/s] 79%|███████▊  | 840/1070 [01:40<00:25,  8.93it/s] 79%|███████▊  | 841/1070 [01:40<00:25,  8.97it/s] 79%|███████▊  | 842/1070 [01:40<00:25,  8.93it/s] 79%|███████▉  | 843/1070 [01:40<00:25,  8.88it/s] 79%|███████▉  | 844/1070 [01:40<00:25,  8.96it/s] 79%|███████▉  | 845/1070 [01:40<00:24,  9.02it/s] 79%|███████▉  | 846/1070 [01:40<00:25,  8.90it/s] 79%|███████▉  | 847/1070 [01:40<00:25,  8.86it/s] 79%|███████▉  | 848/1070 [01:40<00:24,  8.96it/s] 79%|███████▉  | 849/1070 [01:41<00:24,  9.00it/s] 79%|███████▉  | 850/1070 [01:41<00:25,  8.78it/s] 80%|███████▉  | 851/1070 [01:41<00:24,  8.81it/s] 80%|███████▉  | 852/1070 [01:41<00:24,  8.87it/s] 80%|███████▉  | 853/1070 [01:41<00:24,  8.89it/s] 80%|███████▉  | 854/1070 [01:41<00:24,  8.77it/s] 80%|███████▉  | 855/1070 [01:41<00:24,  8.81it/s]                                                   80%|████████  | 856/1070 [01:41<00:24,  8.81it/s][INFO|trainer.py:755] 2023-11-15 21:18:07,598 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:18:07,600 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:18:07,601 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:18:07,601 >>   Batch size = 8
{'eval_loss': 0.309457927942276, 'eval_accuracy': 0.9092105263157895, 'eval_micro_f1': 0.9092105263157895, 'eval_macro_f1': 0.9067150315700209, 'eval_runtime': 1.4049, 'eval_samples_per_second': 540.976, 'eval_steps_per_second': 67.622, 'epoch': 3.0}
{'loss': 0.0928, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 76.29it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 71.84it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 72.72it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 73.20it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 71.18it/s][A
 51%|█████     | 48/95 [00:00<00:00, 69.52it/s][A
 59%|█████▉    | 56/95 [00:00<00:00, 70.88it/s][A
 67%|██████▋   | 64/95 [00:00<00:00, 71.41it/s][A
 76%|███████▌  | 72/95 [00:01<00:00, 68.71it/s][A
 83%|████████▎ | 79/95 [00:01<00:00, 68.72it/s][A
 92%|█████████▏| 87/95 [00:01<00:00, 70.52it/s][A
100%|██████████| 95/95 [00:01<00:00, 71.19it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:43<00:24,  8.81it/s]
100%|██████████| 95/95 [00:01<00:00, 71.19it/s][A
                                               [A 80%|████████  | 857/1070 [01:43<01:32,  2.32it/s] 80%|████████  | 858/1070 [01:43<01:14,  2.84it/s] 80%|████████  | 859/1070 [01:43<01:01,  3.45it/s] 80%|████████  | 860/1070 [01:43<00:51,  4.10it/s] 80%|████████  | 861/1070 [01:43<00:43,  4.83it/s] 81%|████████  | 862/1070 [01:43<00:37,  5.57it/s] 81%|████████  | 863/1070 [01:44<00:33,  6.26it/s] 81%|████████  | 864/1070 [01:44<00:30,  6.80it/s] 81%|████████  | 865/1070 [01:44<00:28,  7.30it/s] 81%|████████  | 866/1070 [01:44<00:26,  7.73it/s] 81%|████████  | 867/1070 [01:44<00:25,  7.98it/s] 81%|████████  | 868/1070 [01:44<00:24,  8.24it/s] 81%|████████  | 869/1070 [01:44<00:23,  8.42it/s] 81%|████████▏ | 870/1070 [01:44<00:23,  8.61it/s] 81%|████████▏ | 871/1070 [01:44<00:22,  8.70it/s] 81%|████████▏ | 872/1070 [01:45<00:22,  8.63it/s] 82%|████████▏ | 873/1070 [01:45<00:22,  8.71it/s] 82%|████████▏ | 874/1070 [01:45<00:22,  8.84it/s] 82%|████████▏ | 875/1070 [01:45<00:21,  8.88it/s] 82%|████████▏ | 876/1070 [01:45<00:22,  8.72it/s] 82%|████████▏ | 877/1070 [01:45<00:22,  8.77it/s] 82%|████████▏ | 878/1070 [01:45<00:21,  8.84it/s] 82%|████████▏ | 879/1070 [01:45<00:21,  8.86it/s] 82%|████████▏ | 880/1070 [01:45<00:21,  8.82it/s] 82%|████████▏ | 881/1070 [01:46<00:21,  8.90it/s] 82%|████████▏ | 882/1070 [01:46<00:21,  8.90it/s] 83%|████████▎ | 883/1070 [01:46<00:21,  8.75it/s] 83%|████████▎ | 884/1070 [01:46<00:21,  8.75it/s] 83%|████████▎ | 885/1070 [01:46<00:20,  8.81it/s] 83%|████████▎ | 886/1070 [01:46<00:20,  8.81it/s] 83%|████████▎ | 887/1070 [01:46<00:20,  8.90it/s] 83%|████████▎ | 888/1070 [01:46<00:20,  8.82it/s] 83%|████████▎ | 889/1070 [01:46<00:20,  8.84it/s] 83%|████████▎ | 890/1070 [01:47<00:20,  8.90it/s] 83%|████████▎ | 891/1070 [01:47<00:20,  8.80it/s] 83%|████████▎ | 892/1070 [01:47<00:20,  8.73it/s] 83%|████████▎ | 893/1070 [01:47<00:20,  8.83it/s] 84%|████████▎ | 894/1070 [01:47<00:19,  8.86it/s] 84%|████████▎ | 895/1070 [01:47<00:19,  8.76it/s] 84%|████████▎ | 896/1070 [01:47<00:19,  8.75it/s] 84%|████████▍ | 897/1070 [01:47<00:19,  8.80it/s] 84%|████████▍ | 898/1070 [01:48<00:19,  8.84it/s] 84%|████████▍ | 899/1070 [01:48<00:19,  8.76it/s] 84%|████████▍ | 900/1070 [01:48<00:19,  8.75it/s] 84%|████████▍ | 901/1070 [01:48<00:19,  8.83it/s] 84%|████████▍ | 902/1070 [01:48<00:18,  8.86it/s] 84%|████████▍ | 903/1070 [01:48<00:18,  8.82it/s] 84%|████████▍ | 904/1070 [01:48<00:18,  8.78it/s] 85%|████████▍ | 905/1070 [01:48<00:18,  8.86it/s] 85%|████████▍ | 906/1070 [01:48<00:18,  8.94it/s] 85%|████████▍ | 907/1070 [01:49<00:18,  8.84it/s] 85%|████████▍ | 908/1070 [01:49<00:18,  8.83it/s] 85%|████████▍ | 909/1070 [01:49<00:18,  8.90it/s] 85%|████████▌ | 910/1070 [01:49<00:18,  8.89it/s] 85%|████████▌ | 911/1070 [01:49<00:18,  8.73it/s] 85%|████████▌ | 912/1070 [01:49<00:17,  8.82it/s] 85%|████████▌ | 913/1070 [01:49<00:17,  8.87it/s] 85%|████████▌ | 914/1070 [01:49<00:17,  8.98it/s] 86%|████████▌ | 915/1070 [01:49<00:17,  8.77it/s] 86%|████████▌ | 916/1070 [01:50<00:17,  8.76it/s] 86%|████████▌ | 917/1070 [01:50<00:17,  8.81it/s] 86%|████████▌ | 918/1070 [01:50<00:17,  8.83it/s] 86%|████████▌ | 919/1070 [01:50<00:17,  8.78it/s] 86%|████████▌ | 920/1070 [01:50<00:17,  8.80it/s] 86%|████████▌ | 921/1070 [01:50<00:16,  8.89it/s] 86%|████████▌ | 922/1070 [01:50<00:16,  8.91it/s] 86%|████████▋ | 923/1070 [01:50<00:16,  8.87it/s] 86%|████████▋ | 924/1070 [01:50<00:16,  8.86it/s] 86%|████████▋ | 925/1070 [01:51<00:16,  8.95it/s] 87%|████████▋ | 926/1070 [01:51<00:16,  8.95it/s] 87%|████████▋ | 927/1070 [01:51<00:16,  8.81it/s] 87%|████████▋ | 928/1070 [01:51<00:16,  8.82it/s] 87%|████████▋ | 929/1070 [01:51<00:15,  8.89it/s] 87%|████████▋ | 930/1070 [01:51<00:15,  8.90it/s] 87%|████████▋ | 931/1070 [01:51<00:15,  8.82it/s] 87%|████████▋ | 932/1070 [01:51<00:15,  8.81it/s] 87%|████████▋ | 933/1070 [01:51<00:15,  8.89it/s] 87%|████████▋ | 934/1070 [01:52<00:15,  8.86it/s] 87%|████████▋ | 935/1070 [01:52<00:15,  8.81it/s] 87%|████████▋ | 936/1070 [01:52<00:15,  8.79it/s] 88%|████████▊ | 937/1070 [01:52<00:14,  8.88it/s] 88%|████████▊ | 938/1070 [01:52<00:14,  8.89it/s] 88%|████████▊ | 939/1070 [01:52<00:14,  8.80it/s] 88%|████████▊ | 940/1070 [01:52<00:14,  8.86it/s] 88%|████████▊ | 941/1070 [01:52<00:14,  8.95it/s] 88%|████████▊ | 942/1070 [01:52<00:14,  8.91it/s] 88%|████████▊ | 943/1070 [01:53<00:14,  8.84it/s] 88%|████████▊ | 944/1070 [01:53<00:14,  8.87it/s] 88%|████████▊ | 945/1070 [01:53<00:14,  8.92it/s] 88%|████████▊ | 946/1070 [01:53<00:14,  8.80it/s] 89%|████████▊ | 947/1070 [01:53<00:13,  8.79it/s] 89%|████████▊ | 948/1070 [01:53<00:13,  8.88it/s] 89%|████████▊ | 949/1070 [01:53<00:13,  8.94it/s] 89%|████████▉ | 950/1070 [01:53<00:13,  8.85it/s] 89%|████████▉ | 951/1070 [01:54<00:13,  8.85it/s] 89%|████████▉ | 952/1070 [01:54<00:13,  8.91it/s] 89%|████████▉ | 953/1070 [01:54<00:13,  8.95it/s] 89%|████████▉ | 954/1070 [01:54<00:12,  8.96it/s] 89%|████████▉ | 955/1070 [01:54<00:12,  8.88it/s] 89%|████████▉ | 956/1070 [01:54<00:12,  8.92it/s] 89%|████████▉ | 957/1070 [01:54<00:12,  9.01it/s] 90%|████████▉ | 958/1070 [01:54<00:12,  8.88it/s] 90%|████████▉ | 959/1070 [01:54<00:12,  8.89it/s] 90%|████████▉ | 960/1070 [01:55<00:12,  8.96it/s] 90%|████████▉ | 961/1070 [01:55<00:12,  9.00it/s] 90%|████████▉ | 962/1070 [01:55<00:12,  8.85it/s] 90%|█████████ | 963/1070 [01:55<00:12,  8.89it/s] 90%|█████████ | 964/1070 [01:55<00:11,  8.95it/s] 90%|█████████ | 965/1070 [01:55<00:11,  8.97it/s] 90%|█████████ | 966/1070 [01:55<00:11,  8.87it/s] 90%|█████████ | 967/1070 [01:55<00:11,  8.87it/s] 90%|█████████ | 968/1070 [01:55<00:11,  8.95it/s] 91%|█████████ | 969/1070 [01:56<00:11,  8.82it/s] 91%|█████████ | 970/1070 [01:56<00:11,  8.79it/s] 91%|█████████ | 971/1070 [01:56<00:11,  8.91it/s] 91%|█████████ | 972/1070 [01:56<00:11,  8.84it/s] 91%|█████████ | 973/1070 [01:56<00:10,  8.96it/s] 91%|█████████ | 974/1070 [01:56<00:10,  8.91it/s] 91%|█████████ | 975/1070 [01:56<00:10,  8.94it/s] 91%|█████████ | 976/1070 [01:56<00:10,  9.02it/s] 91%|█████████▏| 977/1070 [01:56<00:10,  8.87it/s] 91%|█████████▏| 978/1070 [01:57<00:10,  8.89it/s] 91%|█████████▏| 979/1070 [01:57<00:10,  9.02it/s] 92%|█████████▏| 980/1070 [01:57<00:09,  9.01it/s] 92%|█████████▏| 981/1070 [01:57<00:09,  8.93it/s] 92%|█████████▏| 982/1070 [01:57<00:09,  8.95it/s] 92%|█████████▏| 983/1070 [01:57<00:09,  9.01it/s] 92%|█████████▏| 984/1070 [01:57<00:09,  9.04it/s] 92%|█████████▏| 985/1070 [01:57<00:09,  8.91it/s] 92%|█████████▏| 986/1070 [01:57<00:09,  8.95it/s] 92%|█████████▏| 987/1070 [01:58<00:09,  8.98it/s] 92%|█████████▏| 988/1070 [01:58<00:09,  8.84it/s] 92%|█████████▏| 989/1070 [01:58<00:09,  8.84it/s] 93%|█████████▎| 990/1070 [01:58<00:09,  8.87it/s] 93%|█████████▎| 991/1070 [01:58<00:08,  8.91it/s] 93%|█████████▎| 992/1070 [01:58<00:08,  8.99it/s] 93%|█████████▎| 993/1070 [01:58<00:08,  8.86it/s] 93%|█████████▎| 994/1070 [01:58<00:08,  8.94it/s] 93%|█████████▎| 995/1070 [01:58<00:08,  9.00it/s] 93%|█████████▎| 996/1070 [01:59<00:08,  8.89it/s] 93%|█████████▎| 997/1070 [01:59<00:08,  8.88it/s] 93%|█████████▎| 998/1070 [01:59<00:08,  8.99it/s] 93%|█████████▎| 999/1070 [01:59<00:07,  9.02it/s] 93%|█████████▎| 1000/1070 [01:59<00:07,  8.91it/s] 94%|█████████▎| 1001/1070 [01:59<00:07,  8.91it/s] 94%|█████████▎| 1002/1070 [01:59<00:07,  8.98it/s] 94%|█████████▎| 1003/1070 [01:59<00:07,  8.98it/s] 94%|█████████▍| 1004/1070 [01:59<00:07,  8.82it/s] 94%|█████████▍| 1005/1070 [02:00<00:07,  8.90it/s] 94%|█████████▍| 1006/1070 [02:00<00:07,  8.97it/s] 94%|█████████▍| 1007/1070 [02:00<00:07,  8.87it/s] 94%|█████████▍| 1008/1070 [02:00<00:06,  8.91it/s] 94%|█████████▍| 1009/1070 [02:00<00:06,  8.98it/s] 94%|█████████▍| 1010/1070 [02:00<00:06,  9.01it/s] 94%|█████████▍| 1011/1070 [02:00<00:06,  8.97it/s] 95%|█████████▍| 1012/1070 [02:00<00:06,  8.93it/s] 95%|█████████▍| 1013/1070 [02:00<00:06,  8.99it/s] 95%|█████████▍| 1014/1070 [02:01<00:06,  9.03it/s] 95%|█████████▍| 1015/1070 [02:01<00:06,  8.90it/s] 95%|█████████▍| 1016/1070 [02:01<00:06,  8.95it/s] 95%|█████████▌| 1017/1070 [02:01<00:05,  9.03it/s] 95%|█████████▌| 1018/1070 [02:01<00:05,  9.00it/s] 95%|█████████▌| 1019/1070 [02:01<00:05,  8.86it/s] 95%|█████████▌| 1020/1070 [02:01<00:05,  8.93it/s] 95%|█████████▌| 1021/1070 [02:01<00:05,  9.01it/s] 96%|█████████▌| 1022/1070 [02:01<00:05,  8.93it/s] 96%|█████████▌| 1023/1070 [02:02<00:05,  8.91it/s] 96%|█████████▌| 1024/1070 [02:02<00:05,  8.98it/s] 96%|█████████▌| 1025/1070 [02:02<00:05,  8.96it/s] 96%|█████████▌| 1026/1070 [02:02<00:04,  8.91it/s] 96%|█████████▌| 1027/1070 [02:02<00:04,  8.86it/s] 96%|█████████▌| 1028/1070 [02:02<00:04,  8.96it/s] 96%|█████████▌| 1029/1070 [02:02<00:04,  8.99it/s] 96%|█████████▋| 1030/1070 [02:02<00:04,  8.99it/s] 96%|█████████▋| 1031/1070 [02:02<00:04,  8.93it/s] 96%|█████████▋| 1032/1070 [02:03<00:04,  9.01it/s] 97%|█████████▋| 1033/1070 [02:03<00:04,  9.04it/s] 97%|█████████▋| 1034/1070 [02:03<00:04,  8.90it/s] 97%|█████████▋| 1035/1070 [02:03<00:03,  8.96it/s] 97%|█████████▋| 1036/1070 [02:03<00:03,  9.07it/s] 97%|█████████▋| 1037/1070 [02:03<00:03,  9.02it/s] 97%|█████████▋| 1038/1070 [02:03<00:03,  8.89it/s] 97%|█████████▋| 1039/1070 [02:03<00:03,  8.93it/s] 97%|█████████▋| 1040/1070 [02:03<00:03,  9.00it/s] 97%|█████████▋| 1041/1070 [02:04<00:03,  8.95it/s] 97%|█████████▋| 1042/1070 [02:04<00:03,  8.92it/s] 97%|█████████▋| 1043/1070 [02:04<00:03,  8.89it/s] 98%|█████████▊| 1044/1070 [02:04<00:02,  8.89it/s] 98%|█████████▊| 1045/1070 [02:04<00:02,  8.85it/s] 98%|█████████▊| 1046/1070 [02:04<00:02,  8.80it/s] 98%|█████████▊| 1047/1070 [02:04<00:02,  8.86it/s] 98%|█████████▊| 1048/1070 [02:04<00:02,  8.92it/s] 98%|█████████▊| 1049/1070 [02:04<00:02,  8.98it/s] 98%|█████████▊| 1050/1070 [02:05<00:02,  8.88it/s] 98%|█████████▊| 1051/1070 [02:05<00:02,  8.95it/s] 98%|█████████▊| 1052/1070 [02:05<00:02,  9.00it/s] 98%|█████████▊| 1053/1070 [02:05<00:01,  8.93it/s] 99%|█████████▊| 1054/1070 [02:05<00:01,  8.86it/s] 99%|█████████▊| 1055/1070 [02:05<00:01,  8.98it/s] 99%|█████████▊| 1056/1070 [02:05<00:01,  8.97it/s] 99%|█████████▉| 1057/1070 [02:05<00:01,  8.84it/s] 99%|█████████▉| 1058/1070 [02:05<00:01,  8.86it/s] 99%|█████████▉| 1059/1070 [02:06<00:01,  8.93it/s] 99%|█████████▉| 1060/1070 [02:06<00:01,  8.99it/s] 99%|█████████▉| 1061/1070 [02:06<00:01,  8.93it/s] 99%|█████████▉| 1062/1070 [02:06<00:00,  8.92it/s] 99%|█████████▉| 1063/1070 [02:06<00:00,  8.97it/s] 99%|█████████▉| 1064/1070 [02:06<00:00,  8.87it/s]100%|█████████▉| 1065/1070 [02:06<00:00,  8.86it/s]100%|█████████▉| 1066/1070 [02:06<00:00,  8.89it/s]100%|█████████▉| 1067/1070 [02:06<00:00,  8.99it/s]100%|█████████▉| 1068/1070 [02:07<00:00,  8.99it/s]100%|█████████▉| 1069/1070 [02:07<00:00,  8.84it/s]                                                   100%|██████████| 1070/1070 [02:07<00:00,  8.84it/s][INFO|trainer.py:755] 2023-11-15 21:18:33,047 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:18:33,049 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:18:33,049 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:18:33,049 >>   Batch size = 8
{'eval_loss': 0.37685540318489075, 'eval_accuracy': 0.9039473684210526, 'eval_micro_f1': 0.9039473684210526, 'eval_macro_f1': 0.9020349325222388, 'eval_runtime': 1.3888, 'eval_samples_per_second': 547.255, 'eval_steps_per_second': 68.407, 'epoch': 4.0}
{'loss': 0.0524, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 83.58it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 72.77it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 74.13it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 74.35it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 71.70it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 71.79it/s][A
 61%|██████    | 58/95 [00:00<00:00, 73.39it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 73.16it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 70.66it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 72.22it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 73.82it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:08<00:00,  8.84it/s]
100%|██████████| 95/95 [00:01<00:00, 73.82it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 21:18:34,400 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:08<00:00,  8.84it/s]100%|██████████| 1070/1070 [02:08<00:00,  8.32it/s]
[INFO|trainer.py:2855] 2023-11-15 21:18:34,403 >> Saving model checkpoint to ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3
[INFO|configuration_utils.py:460] 2023-11-15 21:18:34,406 >> Configuration saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:18:35,477 >> Model weights saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:18:35,480 >> tokenizer config file saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:18:35,482 >> Special tokens file saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed3/special_tokens_map.json
{'eval_loss': 0.3911794126033783, 'eval_accuracy': 0.9, 'eval_micro_f1': 0.9, 'eval_macro_f1': 0.8973095617314925, 'eval_runtime': 1.3468, 'eval_samples_per_second': 564.281, 'eval_steps_per_second': 70.535, 'epoch': 5.0}
{'train_runtime': 128.6784, 'train_samples_per_second': 265.779, 'train_steps_per_second': 8.315, 'train_loss': 0.21225244842957114, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2123
  train_runtime            = 0:02:08.67
  train_samples            =       6840
  train_samples_per_second =    265.779
  train_steps_per_second   =      8.315
11/15/2023 21:18:35 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:18:35,524 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:18:35,526 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:18:35,526 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:18:35,526 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  9%|▉         | 9/95 [00:00<00:01, 83.57it/s] 19%|█▉        | 18/95 [00:00<00:00, 79.73it/s] 27%|██▋       | 26/95 [00:00<00:00, 72.30it/s] 36%|███▌      | 34/95 [00:00<00:00, 72.78it/s] 44%|████▍     | 42/95 [00:00<00:00, 73.78it/s] 53%|█████▎    | 50/95 [00:00<00:00, 72.30it/s] 61%|██████    | 58/95 [00:00<00:00, 70.57it/s] 69%|██████▉   | 66/95 [00:00<00:00, 72.03it/s] 78%|███████▊  | 74/95 [00:01<00:00, 71.94it/s] 86%|████████▋ | 82/95 [00:01<00:00, 71.63it/s] 95%|█████████▍| 90/95 [00:01<00:00, 70.56it/s]100%|██████████| 95/95 [00:01<00:00, 70.66it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =        0.9
  eval_loss               =     0.3912
  eval_macro_f1           =     0.8973
  eval_micro_f1           =        0.9
  eval_runtime            = 0:00:01.36
  eval_samples            =        760
  eval_samples_per_second =    556.892
  eval_steps_per_second   =     69.611
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▅█▆▄▄
wandb:                      eval/loss ▃▁▁▇██
wandb:                  eval/macro_f1 ▁▅█▆▄▄
wandb:                  eval/micro_f1 ▁▅█▆▄▄
wandb:                   eval/runtime █▄▅▄▁▂
wandb:        eval/samples_per_second ▁▅▄▅█▇
wandb:          eval/steps_per_second ▁▅▄▅█▇
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.9
wandb:                      eval/loss 0.39118
wandb:                  eval/macro_f1 0.89731
wandb:                  eval/micro_f1 0.9
wandb:                   eval/runtime 1.3647
wandb:        eval/samples_per_second 556.892
wandb:          eval/steps_per_second 69.611
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0524
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.21225
wandb:            train/train_runtime 128.6784
wandb: train/train_samples_per_second 265.779
wandb:   train/train_steps_per_second 8.315
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_211507-xvtnyy4q
wandb: Find logs at: ./wandb/offline-run-20231115_211507-xvtnyy4q/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_roberta-base_adapter__seed4/runs/Nov15_21-18-46_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_roberta-base_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_roberta-base_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:18:46 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:18:46 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_roberta-base_adapter__seed4/runs/Nov15_21-18-46_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_roberta-base_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_roberta-base_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  85%|████████▍ | 4001/4722 [00:00<00:00, 38707.51 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 38192.76 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 21:19:02,250 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:19:02,261 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 21:19:12,277 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 21:19:22,295 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:19:22,296 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:19:42,348 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:19:42,349 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:19:42,349 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:19:42,349 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:19:42,349 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:19:42,350 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 21:19:42,351 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:19:42,352 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:20:02,528 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 21:20:03,261 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:20:03,262 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset:  79%|███████▉  | 3000/3777 [00:00<00:00, 22208.22 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 20736.10 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 28704.18 examples/s]
11/15/2023 21:20:03 - INFO - __main__ - Sample 791 of the training set: {'text': 'plain pizza <SEP> The plain pizza was soggy and the creative wild mushroom(third generation-Fornini) pizza we had was drenched with truffle oil in the middle( again making it soggy) and nothingon the rest.', 'label': 2, 'input_ids': [0, 21306, 9366, 28696, 3388, 510, 15698, 20, 10798, 9366, 21, 579, 2154, 4740, 8, 5, 3904, 3418, 30004, 1640, 12347, 2706, 12, 597, 4244, 2531, 43, 9366, 52, 56, 21, 385, 30388, 19, 2664, 15315, 681, 11, 5, 1692, 1640, 456, 442, 24, 579, 2154, 4740, 43, 8, 1085, 261, 5, 1079, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:20:03 - INFO - __main__ - Sample 1124 of the training set: {'text': "lamb sausages <SEP> The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).", 'label': 0, 'input_ids': [0, 5112, 428, 2241, 687, 3443, 28696, 3388, 510, 15698, 20, 10230, 1661, 58, 2216, 6, 182, 22307, 8, 2310, 31, 5, 17988, 2241, 687, 3443, 6, 579, 1120, 3141, 19, 31729, 6, 739, 1086, 22126, 7, 5, 2770, 32617, 1488, 1020, 2480, 6353, 36, 627, 275, 8, 21862, 20921, 38, 348, 655, 56, 322, 2, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:20:03 - INFO - __main__ - Sample 659 of the training set: {'text': 'ingredients <SEP> Great value for the quality ingredients.', 'label': 0, 'input_ids': [0, 154, 48205, 28696, 3388, 510, 15698, 2860, 923, 13, 5, 1318, 7075, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:20:03 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:20:04,993 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:20:05,000 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:20:05,001 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 21:20:05,001 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:20:05,001 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:20:05,002 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:20:05,002 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:20:05,002 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 21:20:05,003 >>   Number of trainable parameters = 124,647,939
[INFO|integration_utils.py:716] 2023-11-15 21:20:05,004 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<12:52,  1.30s/it]  0%|          | 2/595 [00:01<05:54,  1.67it/s]  1%|          | 3/595 [00:01<03:41,  2.68it/s]  1%|          | 4/595 [00:01<02:38,  3.72it/s]  1%|          | 5/595 [00:01<02:04,  4.73it/s]  1%|          | 6/595 [00:01<01:44,  5.65it/s]  1%|          | 7/595 [00:01<01:30,  6.48it/s]  1%|▏         | 8/595 [00:02<01:21,  7.18it/s]  2%|▏         | 9/595 [00:02<01:15,  7.73it/s]  2%|▏         | 10/595 [00:02<01:12,  8.12it/s]  2%|▏         | 11/595 [00:02<01:08,  8.49it/s]  2%|▏         | 12/595 [00:02<01:06,  8.71it/s]  2%|▏         | 13/595 [00:02<01:06,  8.79it/s]  2%|▏         | 14/595 [00:02<01:05,  8.91it/s]  3%|▎         | 15/595 [00:02<01:03,  9.07it/s]  3%|▎         | 16/595 [00:02<01:02,  9.21it/s]  3%|▎         | 17/595 [00:03<01:03,  9.14it/s]  3%|▎         | 18/595 [00:03<01:03,  9.16it/s]  3%|▎         | 19/595 [00:03<01:02,  9.25it/s]  3%|▎         | 20/595 [00:03<01:02,  9.24it/s]  4%|▎         | 21/595 [00:03<01:02,  9.17it/s]  4%|▎         | 22/595 [00:03<01:02,  9.21it/s]  4%|▍         | 23/595 [00:03<01:01,  9.27it/s]  4%|▍         | 24/595 [00:03<01:01,  9.25it/s]  4%|▍         | 25/595 [00:03<01:02,  9.19it/s]  4%|▍         | 26/595 [00:04<01:01,  9.20it/s]  5%|▍         | 27/595 [00:04<01:01,  9.26it/s]  5%|▍         | 28/595 [00:04<01:00,  9.36it/s]  5%|▍         | 29/595 [00:04<01:01,  9.20it/s]  5%|▌         | 30/595 [00:04<01:01,  9.25it/s]  5%|▌         | 31/595 [00:04<01:00,  9.36it/s]  5%|▌         | 32/595 [00:04<01:00,  9.34it/s]  6%|▌         | 33/595 [00:04<01:01,  9.12it/s]  6%|▌         | 34/595 [00:04<01:01,  9.19it/s]  6%|▌         | 35/595 [00:04<01:00,  9.26it/s]  6%|▌         | 36/595 [00:05<01:00,  9.28it/s]  6%|▌         | 37/595 [00:05<01:00,  9.16it/s]  6%|▋         | 38/595 [00:05<01:00,  9.20it/s]  7%|▋         | 39/595 [00:05<00:59,  9.27it/s]  7%|▋         | 40/595 [00:05<01:00,  9.22it/s]  7%|▋         | 41/595 [00:05<00:59,  9.27it/s]  7%|▋         | 42/595 [00:05<00:59,  9.31it/s]  7%|▋         | 43/595 [00:05<00:59,  9.32it/s]  7%|▋         | 44/595 [00:05<00:59,  9.31it/s]  8%|▊         | 45/595 [00:06<00:59,  9.21it/s]  8%|▊         | 46/595 [00:06<00:59,  9.24it/s]  8%|▊         | 47/595 [00:06<00:58,  9.33it/s]  8%|▊         | 48/595 [00:06<00:58,  9.32it/s]  8%|▊         | 49/595 [00:06<00:59,  9.19it/s]  8%|▊         | 50/595 [00:06<00:58,  9.26it/s]  9%|▊         | 51/595 [00:06<00:58,  9.31it/s]  9%|▊         | 52/595 [00:06<00:58,  9.29it/s]  9%|▉         | 53/595 [00:06<00:58,  9.27it/s]  9%|▉         | 54/595 [00:07<00:58,  9.29it/s]  9%|▉         | 55/595 [00:07<00:57,  9.31it/s]  9%|▉         | 56/595 [00:07<00:58,  9.21it/s] 10%|▉         | 57/595 [00:07<00:58,  9.21it/s] 10%|▉         | 58/595 [00:07<00:58,  9.26it/s] 10%|▉         | 59/595 [00:07<00:58,  9.20it/s] 10%|█         | 60/595 [00:07<00:57,  9.26it/s] 10%|█         | 61/595 [00:07<00:57,  9.24it/s] 10%|█         | 62/595 [00:07<00:57,  9.31it/s] 11%|█         | 63/595 [00:07<00:56,  9.38it/s] 11%|█         | 64/595 [00:08<00:57,  9.29it/s] 11%|█         | 65/595 [00:08<00:57,  9.20it/s] 11%|█         | 66/595 [00:08<00:57,  9.26it/s] 11%|█▏        | 67/595 [00:08<00:56,  9.34it/s] 11%|█▏        | 68/595 [00:08<00:56,  9.25it/s] 12%|█▏        | 69/595 [00:08<00:56,  9.30it/s] 12%|█▏        | 70/595 [00:08<00:56,  9.33it/s] 12%|█▏        | 71/595 [00:08<00:56,  9.30it/s] 12%|█▏        | 72/595 [00:08<00:56,  9.23it/s] 12%|█▏        | 73/595 [00:09<00:56,  9.18it/s] 12%|█▏        | 74/595 [00:09<00:56,  9.22it/s] 13%|█▎        | 75/595 [00:09<00:56,  9.28it/s] 13%|█▎        | 76/595 [00:09<00:56,  9.27it/s] 13%|█▎        | 77/595 [00:09<00:55,  9.26it/s] 13%|█▎        | 78/595 [00:09<00:55,  9.33it/s] 13%|█▎        | 79/595 [00:09<00:54,  9.42it/s] 13%|█▎        | 80/595 [00:09<00:55,  9.31it/s] 14%|█▎        | 81/595 [00:09<00:55,  9.29it/s] 14%|█▍        | 82/595 [00:10<00:54,  9.41it/s] 14%|█▍        | 83/595 [00:10<00:54,  9.40it/s] 14%|█▍        | 84/595 [00:10<00:55,  9.22it/s] 14%|█▍        | 85/595 [00:10<00:54,  9.27it/s] 14%|█▍        | 86/595 [00:10<00:54,  9.32it/s] 15%|█▍        | 87/595 [00:10<00:54,  9.27it/s] 15%|█▍        | 88/595 [00:10<00:54,  9.27it/s] 15%|█▍        | 89/595 [00:10<00:54,  9.25it/s] 15%|█▌        | 90/595 [00:10<00:54,  9.31it/s] 15%|█▌        | 91/595 [00:11<00:54,  9.24it/s] 15%|█▌        | 92/595 [00:11<00:54,  9.20it/s] 16%|█▌        | 93/595 [00:11<00:54,  9.27it/s] 16%|█▌        | 94/595 [00:11<00:54,  9.25it/s] 16%|█▌        | 95/595 [00:11<00:53,  9.27it/s] 16%|█▌        | 96/595 [00:11<00:54,  9.17it/s] 16%|█▋        | 97/595 [00:11<00:54,  9.18it/s] 16%|█▋        | 98/595 [00:11<00:53,  9.25it/s] 17%|█▋        | 99/595 [00:11<00:53,  9.20it/s] 17%|█▋        | 100/595 [00:11<00:53,  9.24it/s] 17%|█▋        | 101/595 [00:12<00:53,  9.27it/s] 17%|█▋        | 102/595 [00:12<00:53,  9.30it/s] 17%|█▋        | 103/595 [00:12<00:53,  9.18it/s] 17%|█▋        | 104/595 [00:12<00:53,  9.21it/s] 18%|█▊        | 105/595 [00:12<00:52,  9.29it/s] 18%|█▊        | 106/595 [00:12<00:52,  9.27it/s] 18%|█▊        | 107/595 [00:12<00:53,  9.14it/s] 18%|█▊        | 108/595 [00:12<00:52,  9.19it/s] 18%|█▊        | 109/595 [00:12<00:52,  9.30it/s] 18%|█▊        | 110/595 [00:13<00:52,  9.21it/s] 19%|█▊        | 111/595 [00:13<00:52,  9.16it/s] 19%|█▉        | 112/595 [00:13<00:52,  9.21it/s] 19%|█▉        | 113/595 [00:13<00:52,  9.25it/s] 19%|█▉        | 114/595 [00:13<00:51,  9.28it/s] 19%|█▉        | 115/595 [00:13<00:52,  9.18it/s] 19%|█▉        | 116/595 [00:13<00:52,  9.20it/s] 20%|█▉        | 117/595 [00:13<00:50,  9.39it/s] 20%|█▉        | 118/595 [00:13<00:50,  9.35it/s]                                                  20%|██        | 119/595 [00:13<00:50,  9.35it/s][INFO|trainer.py:755] 2023-11-15 21:20:18,996 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:20:18,998 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:20:18,998 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:20:18,998 >>   Batch size = 8
{'loss': 0.745, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 77.64it/s][A
 14%|█▍        | 17/119 [00:00<00:01, 76.93it/s][A
 21%|██        | 25/119 [00:00<00:01, 77.41it/s][A
 28%|██▊       | 33/119 [00:00<00:01, 74.54it/s][A
 34%|███▍      | 41/119 [00:00<00:01, 74.73it/s][A
 41%|████      | 49/119 [00:00<00:00, 73.97it/s][A
 48%|████▊     | 57/119 [00:00<00:00, 75.05it/s][A
 55%|█████▍    | 65/119 [00:00<00:00, 76.35it/s][A
 61%|██████▏   | 73/119 [00:00<00:00, 73.03it/s][A
 68%|██████▊   | 81/119 [00:01<00:00, 73.75it/s][A
 75%|███████▍  | 89/119 [00:01<00:00, 75.43it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 75.81it/s][A
 88%|████████▊ | 105/119 [00:01<00:00, 72.91it/s][A
 95%|█████████▍| 113/119 [00:01<00:00, 73.55it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:15<00:50,  9.35it/s]
100%|██████████| 119/119 [00:01<00:00, 73.55it/s][A
                                                 [A 20%|██        | 120/595 [00:15<03:44,  2.11it/s] 20%|██        | 121/595 [00:15<03:02,  2.60it/s] 21%|██        | 122/595 [00:15<02:28,  3.19it/s] 21%|██        | 123/595 [00:16<02:01,  3.89it/s] 21%|██        | 124/595 [00:16<01:41,  4.63it/s] 21%|██        | 125/595 [00:16<01:26,  5.42it/s] 21%|██        | 126/595 [00:16<01:16,  6.13it/s] 21%|██▏       | 127/595 [00:16<01:08,  6.78it/s] 22%|██▏       | 128/595 [00:16<01:03,  7.40it/s] 22%|██▏       | 129/595 [00:16<00:59,  7.82it/s] 22%|██▏       | 130/595 [00:16<00:57,  8.16it/s] 22%|██▏       | 131/595 [00:16<00:55,  8.42it/s] 22%|██▏       | 132/595 [00:17<00:53,  8.62it/s] 22%|██▏       | 133/595 [00:17<00:52,  8.77it/s] 23%|██▎       | 134/595 [00:17<00:51,  8.89it/s] 23%|██▎       | 135/595 [00:17<00:51,  8.99it/s] 23%|██▎       | 136/595 [00:17<00:50,  9.06it/s] 23%|██▎       | 137/595 [00:17<00:50,  9.02it/s] 23%|██▎       | 138/595 [00:17<00:50,  9.06it/s] 23%|██▎       | 139/595 [00:17<00:49,  9.14it/s] 24%|██▎       | 140/595 [00:17<00:49,  9.20it/s] 24%|██▎       | 141/595 [00:18<00:48,  9.30it/s] 24%|██▍       | 142/595 [00:18<00:49,  9.17it/s] 24%|██▍       | 143/595 [00:18<00:49,  9.22it/s] 24%|██▍       | 144/595 [00:18<00:48,  9.32it/s] 24%|██▍       | 145/595 [00:18<00:48,  9.21it/s] 25%|██▍       | 146/595 [00:18<00:48,  9.17it/s] 25%|██▍       | 147/595 [00:18<00:48,  9.17it/s] 25%|██▍       | 148/595 [00:18<00:48,  9.25it/s] 25%|██▌       | 149/595 [00:18<00:48,  9.21it/s] 25%|██▌       | 150/595 [00:19<00:48,  9.18it/s] 25%|██▌       | 151/595 [00:19<00:48,  9.16it/s] 26%|██▌       | 152/595 [00:19<00:47,  9.23it/s] 26%|██▌       | 153/595 [00:19<00:47,  9.25it/s] 26%|██▌       | 154/595 [00:19<00:47,  9.20it/s] 26%|██▌       | 155/595 [00:19<00:47,  9.18it/s] 26%|██▌       | 156/595 [00:19<00:47,  9.26it/s] 26%|██▋       | 157/595 [00:19<00:47,  9.26it/s] 27%|██▋       | 158/595 [00:19<00:47,  9.20it/s] 27%|██▋       | 159/595 [00:19<00:47,  9.20it/s] 27%|██▋       | 160/595 [00:20<00:46,  9.32it/s] 27%|██▋       | 161/595 [00:20<00:46,  9.25it/s] 27%|██▋       | 162/595 [00:20<00:46,  9.22it/s] 27%|██▋       | 163/595 [00:20<00:46,  9.28it/s] 28%|██▊       | 164/595 [00:20<00:46,  9.30it/s] 28%|██▊       | 165/595 [00:20<00:46,  9.26it/s] 28%|██▊       | 166/595 [00:20<00:46,  9.19it/s] 28%|██▊       | 167/595 [00:20<00:46,  9.25it/s] 28%|██▊       | 168/595 [00:20<00:46,  9.23it/s] 28%|██▊       | 169/595 [00:21<00:46,  9.19it/s] 29%|██▊       | 170/595 [00:21<00:46,  9.16it/s] 29%|██▊       | 171/595 [00:21<00:46,  9.21it/s] 29%|██▉       | 172/595 [00:21<00:46,  9.17it/s] 29%|██▉       | 173/595 [00:21<00:46,  9.12it/s] 29%|██▉       | 174/595 [00:21<00:46,  9.13it/s] 29%|██▉       | 175/595 [00:21<00:45,  9.14it/s] 30%|██▉       | 176/595 [00:21<00:45,  9.29it/s] 30%|██▉       | 177/595 [00:21<00:45,  9.14it/s] 30%|██▉       | 178/595 [00:22<00:45,  9.13it/s] 30%|███       | 179/595 [00:22<00:45,  9.22it/s] 30%|███       | 180/595 [00:22<00:45,  9.16it/s] 30%|███       | 181/595 [00:22<00:45,  9.18it/s] 31%|███       | 182/595 [00:22<00:44,  9.23it/s] 31%|███       | 183/595 [00:22<00:44,  9.23it/s] 31%|███       | 184/595 [00:22<00:44,  9.21it/s] 31%|███       | 185/595 [00:22<00:44,  9.21it/s] 31%|███▏      | 186/595 [00:22<00:44,  9.27it/s] 31%|███▏      | 187/595 [00:23<00:44,  9.27it/s] 32%|███▏      | 188/595 [00:23<00:44,  9.22it/s] 32%|███▏      | 189/595 [00:23<00:44,  9.16it/s] 32%|███▏      | 190/595 [00:23<00:43,  9.23it/s] 32%|███▏      | 191/595 [00:23<00:44,  9.14it/s] 32%|███▏      | 192/595 [00:23<00:44,  9.14it/s] 32%|███▏      | 193/595 [00:23<00:43,  9.18it/s] 33%|███▎      | 194/595 [00:23<00:43,  9.17it/s] 33%|███▎      | 195/595 [00:23<00:43,  9.19it/s] 33%|███▎      | 196/595 [00:24<00:43,  9.13it/s] 33%|███▎      | 197/595 [00:24<00:43,  9.19it/s] 33%|███▎      | 198/595 [00:24<00:42,  9.38it/s] 33%|███▎      | 199/595 [00:24<00:42,  9.28it/s] 34%|███▎      | 200/595 [00:24<00:42,  9.26it/s] 34%|███▍      | 201/595 [00:24<00:42,  9.33it/s] 34%|███▍      | 202/595 [00:24<00:42,  9.32it/s] 34%|███▍      | 203/595 [00:24<00:42,  9.17it/s] 34%|███▍      | 204/595 [00:24<00:42,  9.18it/s] 34%|███▍      | 205/595 [00:24<00:42,  9.14it/s] 35%|███▍      | 206/595 [00:25<00:42,  9.16it/s] 35%|███▍      | 207/595 [00:25<00:42,  9.13it/s] 35%|███▍      | 208/595 [00:25<00:41,  9.22it/s] 35%|███▌      | 209/595 [00:25<00:41,  9.28it/s] 35%|███▌      | 210/595 [00:25<00:41,  9.20it/s] 35%|███▌      | 211/595 [00:25<00:42,  9.12it/s] 36%|███▌      | 212/595 [00:25<00:41,  9.22it/s] 36%|███▌      | 213/595 [00:25<00:41,  9.16it/s] 36%|███▌      | 214/595 [00:25<00:41,  9.19it/s] 36%|███▌      | 215/595 [00:26<00:41,  9.25it/s] 36%|███▋      | 216/595 [00:26<00:40,  9.26it/s] 36%|███▋      | 217/595 [00:26<00:40,  9.36it/s] 37%|███▋      | 218/595 [00:26<00:40,  9.34it/s] 37%|███▋      | 219/595 [00:26<00:40,  9.26it/s] 37%|███▋      | 220/595 [00:26<00:40,  9.33it/s] 37%|███▋      | 221/595 [00:26<00:40,  9.32it/s] 37%|███▋      | 222/595 [00:26<00:40,  9.20it/s] 37%|███▋      | 223/595 [00:26<00:40,  9.22it/s] 38%|███▊      | 224/595 [00:27<00:40,  9.23it/s] 38%|███▊      | 225/595 [00:27<00:40,  9.19it/s] 38%|███▊      | 226/595 [00:27<00:40,  9.20it/s] 38%|███▊      | 227/595 [00:27<00:39,  9.23it/s] 38%|███▊      | 228/595 [00:27<00:39,  9.19it/s] 38%|███▊      | 229/595 [00:27<00:40,  9.10it/s] 39%|███▊      | 230/595 [00:27<00:39,  9.18it/s] 39%|███▉      | 231/595 [00:27<00:39,  9.19it/s] 39%|███▉      | 232/595 [00:27<00:39,  9.16it/s] 39%|███▉      | 233/595 [00:28<00:39,  9.10it/s] 39%|███▉      | 234/595 [00:28<00:39,  9.19it/s] 39%|███▉      | 235/595 [00:28<00:39,  9.14it/s] 40%|███▉      | 236/595 [00:28<00:39,  9.17it/s] 40%|███▉      | 237/595 [00:28<00:38,  9.25it/s]                                                  40%|████      | 238/595 [00:28<00:38,  9.25it/s][INFO|trainer.py:755] 2023-11-15 21:20:33,507 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:20:33,509 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:20:33,509 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:20:33,509 >>   Batch size = 8
{'eval_loss': 0.579871416091919, 'eval_accuracy': 0.7682539682539683, 'eval_micro_f1': 0.7682539682539683, 'eval_macro_f1': 0.6450145324359582, 'eval_runtime': 1.639, 'eval_samples_per_second': 576.566, 'eval_steps_per_second': 72.605, 'epoch': 1.0}
{'loss': 0.4801, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 10/119 [00:00<00:01, 92.72it/s][A
 17%|█▋        | 20/119 [00:00<00:01, 77.69it/s][A
 24%|██▎       | 28/119 [00:00<00:01, 78.38it/s][A
 31%|███       | 37/119 [00:00<00:01, 80.13it/s][A
 39%|███▊      | 46/119 [00:00<00:00, 75.31it/s][A
 45%|████▌     | 54/119 [00:00<00:00, 76.14it/s][A
 53%|█████▎    | 63/119 [00:00<00:00, 76.27it/s][A
 60%|█████▉    | 71/119 [00:00<00:00, 74.24it/s][A
 66%|██████▋   | 79/119 [00:01<00:00, 75.53it/s][A
 74%|███████▍  | 88/119 [00:01<00:00, 76.58it/s][A
 81%|████████  | 96/119 [00:01<00:00, 74.28it/s][A
 87%|████████▋ | 104/119 [00:01<00:00, 74.86it/s][A
 94%|█████████▍| 112/119 [00:01<00:00, 75.88it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:30<00:38,  9.25it/s]
100%|██████████| 119/119 [00:01<00:00, 75.88it/s][A
                                                 [A 40%|████      | 239/595 [00:30<02:45,  2.15it/s] 40%|████      | 240/595 [00:30<02:13,  2.66it/s] 41%|████      | 241/595 [00:30<01:48,  3.27it/s] 41%|████      | 242/595 [00:30<01:29,  3.95it/s] 41%|████      | 243/595 [00:30<01:14,  4.71it/s] 41%|████      | 244/595 [00:30<01:04,  5.48it/s] 41%|████      | 245/595 [00:30<00:56,  6.23it/s] 41%|████▏     | 246/595 [00:30<00:51,  6.82it/s] 42%|████▏     | 247/595 [00:31<00:47,  7.38it/s] 42%|████▏     | 248/595 [00:31<00:44,  7.87it/s] 42%|████▏     | 249/595 [00:31<00:42,  8.17it/s] 42%|████▏     | 250/595 [00:31<00:40,  8.44it/s] 42%|████▏     | 251/595 [00:31<00:39,  8.67it/s] 42%|████▏     | 252/595 [00:31<00:39,  8.75it/s] 43%|████▎     | 253/595 [00:31<00:38,  8.90it/s] 43%|████▎     | 254/595 [00:31<00:37,  9.01it/s] 43%|████▎     | 255/595 [00:31<00:37,  9.06it/s] 43%|████▎     | 256/595 [00:32<00:36,  9.19it/s] 43%|████▎     | 257/595 [00:32<00:37,  9.13it/s] 43%|████▎     | 258/595 [00:32<00:36,  9.15it/s] 44%|████▎     | 259/595 [00:32<00:36,  9.24it/s] 44%|████▎     | 260/595 [00:32<00:36,  9.21it/s] 44%|████▍     | 261/595 [00:32<00:36,  9.17it/s] 44%|████▍     | 262/595 [00:32<00:36,  9.22it/s] 44%|████▍     | 263/595 [00:32<00:35,  9.25it/s] 44%|████▍     | 264/595 [00:32<00:36,  9.09it/s] 45%|████▍     | 265/595 [00:33<00:36,  9.08it/s] 45%|████▍     | 266/595 [00:33<00:36,  9.12it/s] 45%|████▍     | 267/595 [00:33<00:35,  9.11it/s] 45%|████▌     | 268/595 [00:33<00:35,  9.09it/s] 45%|████▌     | 269/595 [00:33<00:35,  9.12it/s] 45%|████▌     | 270/595 [00:33<00:35,  9.20it/s] 46%|████▌     | 271/595 [00:33<00:35,  9.17it/s] 46%|████▌     | 272/595 [00:33<00:35,  9.15it/s] 46%|████▌     | 273/595 [00:33<00:35,  9.16it/s] 46%|████▌     | 274/595 [00:34<00:34,  9.23it/s] 46%|████▌     | 275/595 [00:34<00:34,  9.26it/s] 46%|████▋     | 276/595 [00:34<00:35,  9.09it/s] 47%|████▋     | 277/595 [00:34<00:34,  9.16it/s] 47%|████▋     | 278/595 [00:34<00:34,  9.26it/s] 47%|████▋     | 279/595 [00:34<00:34,  9.16it/s] 47%|████▋     | 280/595 [00:34<00:34,  9.19it/s] 47%|████▋     | 281/595 [00:34<00:33,  9.25it/s] 47%|████▋     | 282/595 [00:34<00:33,  9.29it/s] 48%|████▊     | 283/595 [00:35<00:33,  9.18it/s] 48%|████▊     | 284/595 [00:35<00:33,  9.18it/s] 48%|████▊     | 285/595 [00:35<00:33,  9.21it/s] 48%|████▊     | 286/595 [00:35<00:33,  9.12it/s] 48%|████▊     | 287/595 [00:35<00:33,  9.11it/s] 48%|████▊     | 288/595 [00:35<00:33,  9.16it/s] 49%|████▊     | 289/595 [00:35<00:33,  9.13it/s] 49%|████▊     | 290/595 [00:35<00:33,  9.03it/s] 49%|████▉     | 292/595 [00:35<00:30,  9.88it/s] 49%|████▉     | 294/595 [00:36<00:29, 10.30it/s] 50%|████▉     | 296/595 [00:36<00:28, 10.54it/s] 50%|█████     | 298/595 [00:36<00:27, 10.71it/s] 50%|█████     | 300/595 [00:36<00:28, 10.25it/s] 51%|█████     | 302/595 [00:36<00:29,  9.96it/s] 51%|█████     | 303/595 [00:37<00:29,  9.74it/s] 51%|█████     | 304/595 [00:37<00:30,  9.59it/s] 51%|█████▏    | 305/595 [00:37<00:30,  9.49it/s] 51%|█████▏    | 306/595 [00:37<00:30,  9.41it/s] 52%|█████▏    | 307/595 [00:37<00:30,  9.30it/s] 52%|█████▏    | 308/595 [00:37<00:31,  9.23it/s] 52%|█████▏    | 309/595 [00:37<00:31,  9.17it/s] 52%|█████▏    | 310/595 [00:37<00:30,  9.24it/s] 52%|█████▏    | 311/595 [00:37<00:30,  9.20it/s] 52%|█████▏    | 312/595 [00:38<00:30,  9.16it/s] 53%|█████▎    | 313/595 [00:38<00:30,  9.12it/s] 53%|█████▎    | 314/595 [00:38<00:30,  9.13it/s] 53%|█████▎    | 315/595 [00:38<00:30,  9.22it/s] 53%|█████▎    | 316/595 [00:38<00:30,  9.09it/s] 53%|█████▎    | 317/595 [00:38<00:30,  9.07it/s] 53%|█████▎    | 318/595 [00:38<00:30,  9.18it/s] 54%|█████▎    | 319/595 [00:38<00:30,  9.14it/s] 54%|█████▍    | 320/595 [00:38<00:30,  9.12it/s] 54%|█████▍    | 321/595 [00:39<00:30,  9.05it/s] 54%|█████▍    | 322/595 [00:39<00:29,  9.14it/s] 54%|█████▍    | 323/595 [00:39<00:29,  9.17it/s] 54%|█████▍    | 324/595 [00:39<00:29,  9.07it/s] 55%|█████▍    | 325/595 [00:39<00:29,  9.00it/s] 55%|█████▍    | 326/595 [00:39<00:29,  9.07it/s] 55%|█████▍    | 327/595 [00:39<00:29,  9.00it/s] 55%|█████▌    | 328/595 [00:39<00:29,  9.06it/s] 55%|█████▌    | 329/595 [00:39<00:29,  8.98it/s] 55%|█████▌    | 330/595 [00:40<00:29,  9.09it/s] 56%|█████▌    | 331/595 [00:40<00:28,  9.23it/s] 56%|█████▌    | 332/595 [00:40<00:28,  9.16it/s] 56%|█████▌    | 333/595 [00:40<00:28,  9.09it/s] 56%|█████▌    | 334/595 [00:40<00:28,  9.13it/s] 56%|█████▋    | 335/595 [00:40<00:28,  9.18it/s] 56%|█████▋    | 336/595 [00:40<00:28,  9.13it/s] 57%|█████▋    | 337/595 [00:40<00:28,  9.01it/s] 57%|█████▋    | 338/595 [00:40<00:28,  9.07it/s] 57%|█████▋    | 339/595 [00:40<00:27,  9.15it/s] 57%|█████▋    | 340/595 [00:41<00:27,  9.12it/s] 57%|█████▋    | 341/595 [00:41<00:27,  9.11it/s] 57%|█████▋    | 342/595 [00:41<00:27,  9.12it/s] 58%|█████▊    | 343/595 [00:41<00:27,  9.16it/s] 58%|█████▊    | 344/595 [00:41<00:27,  9.23it/s] 58%|█████▊    | 345/595 [00:41<00:27,  9.08it/s] 58%|█████▊    | 346/595 [00:41<00:27,  9.13it/s] 58%|█████▊    | 347/595 [00:41<00:26,  9.23it/s] 58%|█████▊    | 348/595 [00:41<00:26,  9.23it/s] 59%|█████▊    | 349/595 [00:42<00:27,  9.10it/s] 59%|█████▉    | 350/595 [00:42<00:26,  9.09it/s] 59%|█████▉    | 351/595 [00:42<00:26,  9.18it/s] 59%|█████▉    | 352/595 [00:42<00:26,  9.17it/s] 59%|█████▉    | 353/595 [00:42<00:26,  9.09it/s] 59%|█████▉    | 354/595 [00:42<00:26,  9.12it/s] 60%|█████▉    | 355/595 [00:42<00:26,  9.15it/s] 60%|█████▉    | 356/595 [00:42<00:25,  9.20it/s]                                                  60%|██████    | 357/595 [00:42<00:25,  9.20it/s][INFO|trainer.py:755] 2023-11-15 21:20:47,900 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:20:47,902 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:20:47,902 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:20:47,902 >>   Batch size = 8
{'eval_loss': 0.4609498381614685, 'eval_accuracy': 0.8201058201058201, 'eval_micro_f1': 0.8201058201058201, 'eval_macro_f1': 0.7505509077597754, 'eval_runtime': 1.6033, 'eval_samples_per_second': 589.411, 'eval_steps_per_second': 74.222, 'epoch': 2.0}
{'loss': 0.3258, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 84.10it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 73.42it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 75.61it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 76.25it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 74.51it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 73.83it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 74.41it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 74.97it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 74.94it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 74.86it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 72.84it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 74.00it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 75.01it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 72.66it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:44<00:25,  9.20it/s]
100%|██████████| 119/119 [00:01<00:00, 72.66it/s][A
                                                 [A 60%|██████    | 358/595 [00:44<01:51,  2.12it/s] 60%|██████    | 359/595 [00:44<01:30,  2.62it/s] 61%|██████    | 360/595 [00:44<01:12,  3.23it/s] 61%|██████    | 361/595 [00:44<00:59,  3.91it/s] 61%|██████    | 362/595 [00:45<00:50,  4.65it/s] 61%|██████    | 363/595 [00:45<00:42,  5.41it/s] 61%|██████    | 364/595 [00:45<00:37,  6.12it/s] 61%|██████▏   | 365/595 [00:45<00:33,  6.84it/s] 62%|██████▏   | 366/595 [00:45<00:31,  7.34it/s] 62%|██████▏   | 367/595 [00:45<00:29,  7.82it/s] 62%|██████▏   | 368/595 [00:45<00:27,  8.24it/s] 62%|██████▏   | 369/595 [00:45<00:26,  8.46it/s] 62%|██████▏   | 370/595 [00:45<00:26,  8.62it/s] 62%|██████▏   | 371/595 [00:46<00:25,  8.79it/s] 63%|██████▎   | 372/595 [00:46<00:24,  8.98it/s] 63%|██████▎   | 373/595 [00:46<00:24,  9.01it/s] 63%|██████▎   | 374/595 [00:46<00:24,  9.01it/s] 63%|██████▎   | 375/595 [00:46<00:24,  9.07it/s] 63%|██████▎   | 376/595 [00:46<00:23,  9.16it/s] 63%|██████▎   | 377/595 [00:46<00:23,  9.10it/s] 64%|██████▎   | 378/595 [00:46<00:23,  9.06it/s] 64%|██████▎   | 379/595 [00:46<00:23,  9.09it/s] 64%|██████▍   | 380/595 [00:47<00:23,  9.08it/s] 64%|██████▍   | 381/595 [00:47<00:23,  9.13it/s] 64%|██████▍   | 382/595 [00:47<00:23,  9.09it/s] 64%|██████▍   | 383/595 [00:47<00:23,  9.14it/s] 65%|██████▍   | 384/595 [00:47<00:22,  9.26it/s] 65%|██████▍   | 385/595 [00:47<00:22,  9.17it/s] 65%|██████▍   | 386/595 [00:47<00:23,  9.09it/s] 65%|██████▌   | 387/595 [00:47<00:22,  9.18it/s] 65%|██████▌   | 388/595 [00:47<00:22,  9.20it/s] 65%|██████▌   | 389/595 [00:48<00:22,  9.07it/s] 66%|██████▌   | 390/595 [00:48<00:22,  9.10it/s] 66%|██████▌   | 391/595 [00:48<00:22,  9.14it/s] 66%|██████▌   | 392/595 [00:48<00:22,  9.09it/s] 66%|██████▌   | 393/595 [00:48<00:22,  9.07it/s] 66%|██████▌   | 394/595 [00:48<00:22,  9.04it/s] 66%|██████▋   | 395/595 [00:48<00:21,  9.16it/s] 67%|██████▋   | 396/595 [00:48<00:21,  9.18it/s] 67%|██████▋   | 397/595 [00:48<00:21,  9.15it/s] 67%|██████▋   | 398/595 [00:49<00:21,  9.14it/s] 67%|██████▋   | 399/595 [00:49<00:21,  9.14it/s] 67%|██████▋   | 400/595 [00:49<00:21,  9.26it/s] 67%|██████▋   | 401/595 [00:49<00:21,  9.14it/s] 68%|██████▊   | 402/595 [00:49<00:21,  9.12it/s] 68%|██████▊   | 403/595 [00:49<00:20,  9.24it/s] 68%|██████▊   | 404/595 [00:49<00:20,  9.16it/s] 68%|██████▊   | 405/595 [00:49<00:20,  9.17it/s] 68%|██████▊   | 406/595 [00:49<00:20,  9.17it/s] 68%|██████▊   | 407/595 [00:49<00:20,  9.23it/s] 69%|██████▊   | 408/595 [00:50<00:20,  9.20it/s] 69%|██████▊   | 409/595 [00:50<00:20,  9.17it/s] 69%|██████▉   | 410/595 [00:50<00:20,  9.14it/s] 69%|██████▉   | 411/595 [00:50<00:20,  9.19it/s] 69%|██████▉   | 412/595 [00:50<00:20,  9.12it/s] 69%|██████▉   | 413/595 [00:50<00:19,  9.15it/s] 70%|██████▉   | 414/595 [00:50<00:19,  9.11it/s] 70%|██████▉   | 415/595 [00:50<00:19,  9.16it/s] 70%|██████▉   | 416/595 [00:50<00:19,  9.28it/s] 70%|███████   | 417/595 [00:51<00:19,  9.20it/s] 70%|███████   | 418/595 [00:51<00:19,  9.14it/s] 70%|███████   | 419/595 [00:51<00:19,  9.21it/s] 71%|███████   | 420/595 [00:51<00:18,  9.25it/s] 71%|███████   | 421/595 [00:51<00:18,  9.20it/s] 71%|███████   | 422/595 [00:51<00:18,  9.16it/s] 71%|███████   | 423/595 [00:51<00:18,  9.16it/s] 71%|███████▏  | 424/595 [00:51<00:18,  9.19it/s] 71%|███████▏  | 425/595 [00:51<00:18,  9.08it/s] 72%|███████▏  | 426/595 [00:52<00:18,  9.04it/s] 72%|███████▏  | 427/595 [00:52<00:18,  9.10it/s] 72%|███████▏  | 428/595 [00:52<00:18,  9.10it/s] 72%|███████▏  | 429/595 [00:52<00:18,  9.17it/s] 72%|███████▏  | 430/595 [00:52<00:18,  9.07it/s] 72%|███████▏  | 431/595 [00:52<00:18,  9.05it/s] 73%|███████▎  | 432/595 [00:52<00:17,  9.15it/s] 73%|███████▎  | 433/595 [00:52<00:17,  9.08it/s] 73%|███████▎  | 434/595 [00:52<00:17,  9.08it/s] 73%|███████▎  | 435/595 [00:53<00:17,  9.10it/s] 73%|███████▎  | 436/595 [00:53<00:17,  9.11it/s] 73%|███████▎  | 437/595 [00:53<00:17,  9.08it/s] 74%|███████▎  | 438/595 [00:53<00:17,  9.03it/s] 74%|███████▍  | 439/595 [00:53<00:17,  9.01it/s] 74%|███████▍  | 440/595 [00:53<00:17,  9.03it/s] 74%|███████▍  | 441/595 [00:53<00:16,  9.06it/s] 74%|███████▍  | 442/595 [00:53<00:16,  9.09it/s] 74%|███████▍  | 443/595 [00:53<00:16,  9.06it/s] 75%|███████▍  | 444/595 [00:54<00:16,  9.07it/s] 75%|███████▍  | 445/595 [00:54<00:16,  9.16it/s] 75%|███████▍  | 446/595 [00:54<00:16,  9.18it/s] 75%|███████▌  | 447/595 [00:54<00:16,  9.15it/s] 75%|███████▌  | 448/595 [00:54<00:16,  9.05it/s] 75%|███████▌  | 449/595 [00:54<00:16,  9.06it/s] 76%|███████▌  | 450/595 [00:54<00:15,  9.07it/s] 76%|███████▌  | 451/595 [00:54<00:15,  9.06it/s] 76%|███████▌  | 452/595 [00:54<00:15,  9.02it/s] 76%|███████▌  | 453/595 [00:55<00:15,  9.05it/s] 76%|███████▋  | 454/595 [00:55<00:15,  8.99it/s] 76%|███████▋  | 455/595 [00:55<00:15,  9.07it/s] 77%|███████▋  | 456/595 [00:55<00:15,  9.02it/s] 77%|███████▋  | 457/595 [00:55<00:15,  9.10it/s] 77%|███████▋  | 458/595 [00:55<00:14,  9.19it/s] 77%|███████▋  | 459/595 [00:55<00:14,  9.10it/s] 77%|███████▋  | 460/595 [00:55<00:14,  9.07it/s] 77%|███████▋  | 461/595 [00:55<00:14,  9.04it/s] 78%|███████▊  | 462/595 [00:56<00:14,  9.09it/s] 78%|███████▊  | 463/595 [00:56<00:14,  9.09it/s] 78%|███████▊  | 464/595 [00:56<00:14,  9.05it/s] 78%|███████▊  | 465/595 [00:56<00:14,  9.05it/s] 78%|███████▊  | 466/595 [00:56<00:14,  9.11it/s] 78%|███████▊  | 467/595 [00:56<00:14,  9.07it/s] 79%|███████▊  | 468/595 [00:56<00:13,  9.10it/s] 79%|███████▉  | 469/595 [00:56<00:14,  8.92it/s] 79%|███████▉  | 470/595 [00:56<00:13,  9.02it/s] 79%|███████▉  | 471/595 [00:57<00:13,  9.17it/s] 79%|███████▉  | 472/595 [00:57<00:13,  9.07it/s] 79%|███████▉  | 473/595 [00:57<00:13,  9.01it/s] 80%|███████▉  | 474/595 [00:57<00:13,  9.06it/s] 80%|███████▉  | 475/595 [00:57<00:13,  9.17it/s]                                                  80%|████████  | 476/595 [00:57<00:12,  9.17it/s][INFO|trainer.py:755] 2023-11-15 21:21:02,513 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:21:02,515 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:21:02,515 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:21:02,515 >>   Batch size = 8
{'eval_loss': 0.46851593255996704, 'eval_accuracy': 0.8412698412698413, 'eval_micro_f1': 0.8412698412698413, 'eval_macro_f1': 0.7610114637096087, 'eval_runtime': 1.6312, 'eval_samples_per_second': 579.312, 'eval_steps_per_second': 72.95, 'epoch': 3.0}
{'loss': 0.2376, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 85.82it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 75.50it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 72.50it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 74.02it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 75.17it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 73.27it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 71.66it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 72.89it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 73.95it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 71.85it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 71.16it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 72.09it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 73.32it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 72.04it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [00:59<00:12,  9.17it/s]
100%|██████████| 119/119 [00:01<00:00, 72.04it/s][A
                                                 [A 80%|████████  | 477/595 [00:59<00:56,  2.08it/s] 80%|████████  | 478/595 [00:59<00:45,  2.57it/s] 81%|████████  | 479/595 [00:59<00:36,  3.16it/s] 81%|████████  | 480/595 [00:59<00:29,  3.84it/s] 81%|████████  | 481/595 [00:59<00:24,  4.57it/s] 81%|████████  | 482/595 [00:59<00:21,  5.31it/s] 81%|████████  | 483/595 [00:59<00:18,  6.04it/s] 81%|████████▏ | 484/595 [01:00<00:16,  6.71it/s] 82%|████████▏ | 485/595 [01:00<00:15,  7.24it/s] 82%|████████▏ | 486/595 [01:00<00:14,  7.69it/s] 82%|████████▏ | 487/595 [01:00<00:13,  8.08it/s] 82%|████████▏ | 488/595 [01:00<00:12,  8.40it/s] 82%|████████▏ | 489/595 [01:00<00:12,  8.69it/s] 82%|████████▏ | 490/595 [01:00<00:11,  8.76it/s] 83%|████████▎ | 491/595 [01:00<00:11,  8.81it/s] 83%|████████▎ | 492/595 [01:00<00:11,  8.91it/s] 83%|████████▎ | 493/595 [01:01<00:11,  9.00it/s] 83%|████████▎ | 494/595 [01:01<00:11,  8.91it/s] 83%|████████▎ | 495/595 [01:01<00:11,  8.86it/s] 83%|████████▎ | 496/595 [01:01<00:11,  8.92it/s] 84%|████████▎ | 497/595 [01:01<00:10,  8.99it/s] 84%|████████▎ | 498/595 [01:01<00:10,  8.97it/s] 84%|████████▍ | 499/595 [01:01<00:10,  8.94it/s] 84%|████████▍ | 500/595 [01:01<00:10,  8.95it/s] 84%|████████▍ | 501/595 [01:01<00:10,  8.99it/s] 84%|████████▍ | 502/595 [01:02<00:10,  9.06it/s] 85%|████████▍ | 503/595 [01:02<00:10,  8.95it/s] 85%|████████▍ | 504/595 [01:02<00:10,  8.91it/s] 85%|████████▍ | 505/595 [01:02<00:09,  9.03it/s] 85%|████████▌ | 506/595 [01:02<00:09,  9.02it/s] 85%|████████▌ | 507/595 [01:02<00:09,  8.97it/s] 85%|████████▌ | 508/595 [01:02<00:09,  8.91it/s] 86%|████████▌ | 509/595 [01:02<00:09,  8.98it/s] 86%|████████▌ | 510/595 [01:02<00:09,  8.98it/s] 86%|████████▌ | 511/595 [01:03<00:09,  8.95it/s] 86%|████████▌ | 512/595 [01:03<00:09,  8.96it/s] 86%|████████▌ | 513/595 [01:03<00:09,  9.00it/s] 86%|████████▋ | 514/595 [01:03<00:08,  9.02it/s] 87%|████████▋ | 515/595 [01:03<00:08,  9.13it/s] 87%|████████▋ | 516/595 [01:03<00:08,  9.03it/s] 87%|████████▋ | 517/595 [01:03<00:08,  8.94it/s] 87%|████████▋ | 518/595 [01:03<00:08,  9.06it/s] 87%|████████▋ | 519/595 [01:03<00:08,  8.98it/s] 87%|████████▋ | 520/595 [01:04<00:08,  8.95it/s] 88%|████████▊ | 521/595 [01:04<00:08,  8.96it/s] 88%|████████▊ | 522/595 [01:04<00:08,  9.04it/s] 88%|████████▊ | 523/595 [01:04<00:08,  8.97it/s] 88%|████████▊ | 524/595 [01:04<00:07,  8.93it/s] 88%|████████▊ | 525/595 [01:04<00:07,  8.90it/s] 88%|████████▊ | 526/595 [01:04<00:07,  8.97it/s] 89%|████████▊ | 527/595 [01:04<00:07,  9.02it/s] 89%|████████▊ | 528/595 [01:04<00:07,  9.04it/s] 89%|████████▉ | 529/595 [01:05<00:07,  8.97it/s] 89%|████████▉ | 530/595 [01:05<00:07,  9.00it/s] 89%|████████▉ | 531/595 [01:05<00:07,  9.11it/s] 89%|████████▉ | 532/595 [01:05<00:06,  9.09it/s] 90%|████████▉ | 533/595 [01:05<00:06,  9.05it/s] 90%|████████▉ | 534/595 [01:05<00:06,  9.05it/s] 90%|████████▉ | 535/595 [01:05<00:06,  9.09it/s] 90%|█████████ | 536/595 [01:05<00:06,  9.06it/s] 90%|█████████ | 537/595 [01:05<00:06,  8.98it/s] 90%|█████████ | 538/595 [01:06<00:06,  9.02it/s] 91%|█████████ | 539/595 [01:06<00:06,  9.10it/s] 91%|█████████ | 540/595 [01:06<00:06,  9.06it/s] 91%|█████████ | 541/595 [01:06<00:06,  8.99it/s] 91%|█████████ | 542/595 [01:06<00:05,  9.01it/s] 91%|█████████▏| 543/595 [01:06<00:05,  9.06it/s] 91%|█████████▏| 544/595 [01:06<00:05,  9.12it/s] 92%|█████████▏| 545/595 [01:06<00:05,  8.99it/s] 92%|█████████▏| 546/595 [01:06<00:05,  9.01it/s] 92%|█████████▏| 547/595 [01:07<00:05,  9.11it/s] 92%|█████████▏| 548/595 [01:07<00:05,  9.06it/s] 92%|█████████▏| 549/595 [01:07<00:05,  8.97it/s] 92%|█████████▏| 550/595 [01:07<00:05,  8.97it/s] 93%|█████████▎| 551/595 [01:07<00:04,  9.05it/s] 93%|█████████▎| 552/595 [01:07<00:04,  9.07it/s] 93%|█████████▎| 553/595 [01:07<00:04,  9.03it/s] 93%|█████████▎| 554/595 [01:07<00:04,  8.99it/s] 93%|█████████▎| 555/595 [01:07<00:04,  9.05it/s] 93%|█████████▎| 556/595 [01:08<00:04,  9.09it/s] 94%|█████████▎| 557/595 [01:08<00:04,  9.01it/s] 94%|█████████▍| 558/595 [01:08<00:04,  8.95it/s] 94%|█████████▍| 559/595 [01:08<00:03,  9.00it/s] 94%|█████████▍| 560/595 [01:08<00:03,  9.04it/s] 94%|█████████▍| 561/595 [01:08<00:03,  8.90it/s] 94%|█████████▍| 562/595 [01:08<00:03,  8.97it/s] 95%|█████████▍| 563/595 [01:08<00:03,  9.06it/s] 95%|█████████▍| 564/595 [01:08<00:03,  9.06it/s] 95%|█████████▍| 565/595 [01:09<00:03,  8.99it/s] 95%|█████████▌| 566/595 [01:09<00:03,  8.97it/s] 95%|█████████▌| 567/595 [01:09<00:03,  9.05it/s] 95%|█████████▌| 568/595 [01:09<00:02,  9.05it/s] 96%|█████████▌| 569/595 [01:09<00:02,  8.98it/s] 96%|█████████▌| 570/595 [01:09<00:02,  8.91it/s] 96%|█████████▌| 571/595 [01:09<00:02,  9.02it/s] 96%|█████████▌| 572/595 [01:09<00:02,  8.99it/s] 96%|█████████▋| 573/595 [01:09<00:02,  9.05it/s] 96%|█████████▋| 574/595 [01:10<00:02,  9.01it/s] 97%|█████████▋| 575/595 [01:10<00:02,  9.07it/s] 97%|█████████▋| 576/595 [01:10<00:02,  9.09it/s] 97%|█████████▋| 577/595 [01:10<00:02,  8.94it/s] 97%|█████████▋| 578/595 [01:10<00:01,  9.01it/s] 97%|█████████▋| 579/595 [01:10<00:01,  9.08it/s] 97%|█████████▋| 580/595 [01:10<00:01,  9.07it/s] 98%|█████████▊| 581/595 [01:10<00:01,  9.03it/s] 98%|█████████▊| 582/595 [01:10<00:01,  9.05it/s] 98%|█████████▊| 583/595 [01:11<00:01,  9.07it/s] 98%|█████████▊| 584/595 [01:11<00:01,  9.07it/s] 98%|█████████▊| 585/595 [01:11<00:01,  9.03it/s] 98%|█████████▊| 586/595 [01:11<00:00,  9.06it/s] 99%|█████████▊| 587/595 [01:11<00:00,  9.11it/s] 99%|█████████▉| 588/595 [01:11<00:00,  9.08it/s] 99%|█████████▉| 589/595 [01:11<00:00,  9.02it/s] 99%|█████████▉| 590/595 [01:11<00:00,  9.06it/s] 99%|█████████▉| 591/595 [01:11<00:00,  9.14it/s] 99%|█████████▉| 592/595 [01:12<00:00,  9.15it/s]100%|█████████▉| 593/595 [01:12<00:00,  8.99it/s]100%|█████████▉| 594/595 [01:12<00:00,  9.10it/s]                                                 100%|██████████| 595/595 [01:12<00:00,  9.10it/s][INFO|trainer.py:755] 2023-11-15 21:21:17,307 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:21:17,308 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:21:17,308 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:21:17,309 >>   Batch size = 8
{'eval_loss': 0.47337883710861206, 'eval_accuracy': 0.8507936507936508, 'eval_micro_f1': 0.8507936507936508, 'eval_macro_f1': 0.7856676253589474, 'eval_runtime': 1.6713, 'eval_samples_per_second': 565.416, 'eval_steps_per_second': 71.2, 'epoch': 4.0}
{'loss': 0.1802, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 85.69it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 77.00it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 73.90it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 74.82it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 75.30it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 72.59it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 72.37it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 73.70it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 73.66it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 73.18it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 72.01it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 73.33it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 74.21it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 71.71it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:13<00:00,  9.10it/s]
100%|██████████| 119/119 [00:01<00:00, 71.71it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 21:21:18,970 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:13<00:00,  9.10it/s]100%|██████████| 595/595 [01:13<00:00,  8.04it/s]
[INFO|trainer.py:2855] 2023-11-15 21:21:18,973 >> Saving model checkpoint to ./result/restaurant_roberta-base_adapter__seed4
[INFO|configuration_utils.py:460] 2023-11-15 21:21:18,976 >> Configuration saved in ./result/restaurant_roberta-base_adapter__seed4/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:21:20,153 >> Model weights saved in ./result/restaurant_roberta-base_adapter__seed4/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:21:20,156 >> tokenizer config file saved in ./result/restaurant_roberta-base_adapter__seed4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:21:20,159 >> Special tokens file saved in ./result/restaurant_roberta-base_adapter__seed4/special_tokens_map.json
{'eval_loss': 0.4771670997142792, 'eval_accuracy': 0.8539682539682539, 'eval_micro_f1': 0.8539682539682539, 'eval_macro_f1': 0.7960042688688516, 'eval_runtime': 1.6573, 'eval_samples_per_second': 570.204, 'eval_steps_per_second': 71.804, 'epoch': 5.0}
{'train_runtime': 73.9668, 'train_samples_per_second': 255.317, 'train_steps_per_second': 8.044, 'train_loss': 0.39372991032961036, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3937
  train_runtime            = 0:01:13.96
  train_samples            =       3777
  train_samples_per_second =    255.317
  train_steps_per_second   =      8.044
11/15/2023 21:21:20 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:21:20,259 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:21:20,260 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:21:20,260 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:21:20,261 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  7%|▋         | 8/119 [00:00<00:01, 79.86it/s] 13%|█▎        | 16/119 [00:00<00:01, 72.89it/s] 20%|██        | 24/119 [00:00<00:01, 74.75it/s] 27%|██▋       | 32/119 [00:00<00:01, 74.63it/s] 34%|███▎      | 40/119 [00:00<00:01, 72.04it/s] 40%|████      | 48/119 [00:00<00:00, 71.23it/s] 47%|████▋     | 56/119 [00:00<00:00, 72.48it/s] 54%|█████▍    | 64/119 [00:00<00:00, 71.45it/s] 61%|██████    | 72/119 [00:00<00:00, 72.48it/s] 67%|██████▋   | 80/119 [00:01<00:00, 70.62it/s] 74%|███████▍  | 88/119 [00:01<00:00, 72.48it/s] 81%|████████  | 96/119 [00:01<00:00, 73.60it/s] 87%|████████▋ | 104/119 [00:01<00:00, 72.49it/s] 94%|█████████▍| 112/119 [00:01<00:00, 70.71it/s]100%|██████████| 119/119 [00:01<00:00, 71.16it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.854
  eval_loss               =     0.4772
  eval_macro_f1           =      0.796
  eval_micro_f1           =      0.854
  eval_runtime            = 0:00:01.69
  eval_samples            =        945
  eval_samples_per_second =    557.838
  eval_steps_per_second   =     70.246
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▅▇███
wandb:                      eval/loss █▁▁▂▂▂
wandb:                  eval/macro_f1 ▁▆▆███
wandb:                  eval/micro_f1 ▁▅▇███
wandb:                   eval/runtime ▄▁▃▆▅█
wandb:        eval/samples_per_second ▅█▆▃▄▁
wandb:          eval/steps_per_second ▅█▆▃▄▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.85397
wandb:                      eval/loss 0.47717
wandb:                  eval/macro_f1 0.796
wandb:                  eval/micro_f1 0.85397
wandb:                   eval/runtime 1.694
wandb:        eval/samples_per_second 557.838
wandb:          eval/steps_per_second 70.246
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1802
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.39373
wandb:            train/train_runtime 73.9668
wandb: train/train_samples_per_second 255.317
wandb:   train/train_steps_per_second 8.044
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_211848-tl8eeg6y
wandb: Find logs at: ./wandb/offline-run-20231115_211848-tl8eeg6y/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_bert-base-cased_adapter__seed4/runs/Nov15_21-21-31_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_bert-base-cased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_bert-base-cased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:21:31 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:21:31 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_bert-base-cased_adapter__seed4/runs/Nov15_21-21-31_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_bert-base-cased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_bert-base-cased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  85%|████████▍ | 4000/4722 [00:00<00:00, 38646.32 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 38219.95 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 21:21:47,726 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:21:47,736 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 21:21:57,744 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:21:57,745 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:21:57,748 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:21:57,748 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:21:57,748 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:21:57,749 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:21:57,749 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 21:21:57,750 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:21:57,751 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:22:17,891 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 21:22:18,552 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:22:18,553 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 23409.29 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 23103.97 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 27492.85 examples/s]
11/15/2023 21:22:18 - INFO - __main__ - Sample 791 of the training set: {'text': 'plain pizza <SEP> The plain pizza was soggy and the creative wild mushroom(third generation-Fornini) pizza we had was drenched with truffle oil in the middle( again making it soggy) and nothingon the rest.', 'label': 2, 'input_ids': [101, 6188, 13473, 133, 12342, 2101, 135, 1109, 6188, 13473, 1108, 1177, 14720, 1105, 1103, 6228, 4098, 25590, 113, 1503, 3964, 118, 1370, 10430, 1182, 114, 13473, 1195, 1125, 1108, 173, 17902, 1114, 189, 17669, 1513, 2949, 1107, 1103, 2243, 113, 1254, 1543, 1122, 1177, 14720, 114, 1105, 1720, 1320, 1103, 1832, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:22:18 - INFO - __main__ - Sample 1124 of the training set: {'text': "lamb sausages <SEP> The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).", 'label': 0, 'input_ids': [101, 2495, 12913, 21718, 27130, 1116, 133, 12342, 2101, 135, 1109, 10514, 2356, 1127, 3527, 117, 1304, 27629, 13913, 1105, 4489, 1121, 1103, 2495, 12913, 21718, 27130, 1116, 117, 21718, 16936, 3965, 1114, 16516, 1116, 10182, 6439, 117, 1415, 2006, 23982, 1106, 1103, 6929, 185, 11663, 4313, 1186, 2854, 7081, 113, 1103, 1436, 1105, 4489, 2556, 146, 112, 1396, 1518, 1125, 114, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 21:22:18 - INFO - __main__ - Sample 659 of the training set: {'text': 'ingredients <SEP> Great value for the quality ingredients.', 'label': 0, 'input_ids': [101, 13288, 133, 12342, 2101, 135, 2038, 2860, 1111, 1103, 3068, 13288, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:22:18 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:22:20,262 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:22:20,270 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:22:20,270 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 21:22:20,271 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:22:20,271 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:22:20,271 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:22:20,271 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:22:20,272 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 21:22:20,273 >>   Number of trainable parameters = 108,312,579
[INFO|integration_utils.py:716] 2023-11-15 21:22:20,274 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<13:07,  1.32s/it]  0%|          | 2/595 [00:01<06:01,  1.64it/s]  1%|          | 3/595 [00:01<03:46,  2.62it/s]  1%|          | 4/595 [00:01<02:42,  3.63it/s]  1%|          | 5/595 [00:01<02:06,  4.65it/s]  1%|          | 6/595 [00:01<01:46,  5.53it/s]  1%|          | 7/595 [00:01<01:32,  6.37it/s]  1%|▏         | 8/595 [00:02<01:24,  6.93it/s]  2%|▏         | 9/595 [00:02<01:18,  7.44it/s]  2%|▏         | 10/595 [00:02<01:13,  7.96it/s]  2%|▏         | 11/595 [00:02<01:10,  8.29it/s]  2%|▏         | 12/595 [00:02<01:09,  8.45it/s]  2%|▏         | 13/595 [00:02<01:08,  8.54it/s]  2%|▏         | 14/595 [00:02<01:07,  8.66it/s]  3%|▎         | 15/595 [00:02<01:06,  8.77it/s]  3%|▎         | 16/595 [00:02<01:05,  8.85it/s]  3%|▎         | 17/595 [00:03<01:04,  8.95it/s]  3%|▎         | 18/595 [00:03<01:04,  8.88it/s]  3%|▎         | 19/595 [00:03<01:05,  8.83it/s]  3%|▎         | 20/595 [00:03<01:04,  8.95it/s]  4%|▎         | 21/595 [00:03<01:03,  9.00it/s]  4%|▎         | 22/595 [00:03<01:04,  8.95it/s]  4%|▍         | 23/595 [00:03<01:04,  8.92it/s]  4%|▍         | 24/595 [00:03<01:04,  8.90it/s]  4%|▍         | 25/595 [00:04<01:03,  8.91it/s]  4%|▍         | 26/595 [00:04<01:03,  8.99it/s]  5%|▍         | 27/595 [00:04<01:02,  9.06it/s]  5%|▍         | 28/595 [00:04<01:03,  8.97it/s]  5%|▍         | 29/595 [00:04<01:04,  8.81it/s]  5%|▌         | 30/595 [00:04<01:03,  8.91it/s]  5%|▌         | 31/595 [00:04<01:03,  8.95it/s]  5%|▌         | 32/595 [00:04<01:03,  8.89it/s]  6%|▌         | 33/595 [00:04<01:03,  8.90it/s]  6%|▌         | 34/595 [00:05<01:02,  8.93it/s]  6%|▌         | 35/595 [00:05<01:02,  8.93it/s]  6%|▌         | 36/595 [00:05<01:02,  8.97it/s]  6%|▌         | 37/595 [00:05<01:01,  9.06it/s]  6%|▋         | 38/595 [00:05<01:02,  8.96it/s]  7%|▋         | 39/595 [00:05<01:02,  8.96it/s]  7%|▋         | 40/595 [00:05<01:02,  8.93it/s]  7%|▋         | 41/595 [00:05<01:01,  9.00it/s]  7%|▋         | 42/595 [00:05<01:01,  9.04it/s]  7%|▋         | 43/595 [00:06<01:01,  8.93it/s]  7%|▋         | 44/595 [00:06<01:01,  9.01it/s]  8%|▊         | 45/595 [00:06<01:01,  8.89it/s]  8%|▊         | 46/595 [00:06<01:01,  8.97it/s]  8%|▊         | 47/595 [00:06<01:00,  9.06it/s]  8%|▊         | 48/595 [00:06<01:00,  9.03it/s]  8%|▊         | 49/595 [00:06<01:00,  9.01it/s]  8%|▊         | 50/595 [00:06<01:01,  8.93it/s]  9%|▊         | 51/595 [00:06<01:00,  8.96it/s]  9%|▊         | 52/595 [00:07<00:59,  9.05it/s]  9%|▉         | 53/595 [00:07<01:00,  9.00it/s]  9%|▉         | 54/595 [00:07<00:59,  9.13it/s]  9%|▉         | 55/595 [00:07<01:00,  8.92it/s]  9%|▉         | 56/595 [00:07<01:00,  8.93it/s] 10%|▉         | 57/595 [00:07<00:59,  9.02it/s] 10%|▉         | 58/595 [00:07<00:59,  9.06it/s] 10%|▉         | 59/595 [00:07<00:59,  9.03it/s] 10%|█         | 60/595 [00:07<01:00,  8.88it/s] 10%|█         | 61/595 [00:08<01:00,  8.85it/s] 10%|█         | 62/595 [00:08<00:59,  8.95it/s] 11%|█         | 63/595 [00:08<00:59,  9.02it/s] 11%|█         | 64/595 [00:08<00:58,  9.14it/s] 11%|█         | 65/595 [00:08<00:58,  9.08it/s] 11%|█         | 66/595 [00:08<00:58,  9.07it/s] 11%|█▏        | 67/595 [00:08<00:58,  8.99it/s] 11%|█▏        | 68/595 [00:08<00:58,  9.00it/s] 12%|█▏        | 69/595 [00:08<00:57,  9.08it/s] 12%|█▏        | 70/595 [00:09<00:58,  9.04it/s] 12%|█▏        | 71/595 [00:09<00:57,  9.04it/s] 12%|█▏        | 72/595 [00:09<00:58,  8.93it/s] 12%|█▏        | 73/595 [00:09<00:57,  9.00it/s] 12%|█▏        | 74/595 [00:09<00:57,  9.09it/s] 13%|█▎        | 75/595 [00:09<00:57,  9.05it/s] 13%|█▎        | 76/595 [00:09<00:57,  9.02it/s] 13%|█▎        | 77/595 [00:09<00:58,  8.92it/s] 13%|█▎        | 78/595 [00:09<00:57,  8.96it/s] 13%|█▎        | 79/595 [00:10<00:57,  8.97it/s] 13%|█▎        | 80/595 [00:10<00:57,  9.02it/s] 14%|█▎        | 81/595 [00:10<00:57,  9.01it/s] 14%|█▍        | 82/595 [00:10<00:57,  8.94it/s] 14%|█▍        | 83/595 [00:10<00:57,  8.88it/s] 14%|█▍        | 84/595 [00:10<00:57,  8.96it/s] 14%|█▍        | 85/595 [00:10<00:56,  8.99it/s] 14%|█▍        | 86/595 [00:10<00:56,  8.94it/s] 15%|█▍        | 87/595 [00:10<00:57,  8.90it/s] 15%|█▍        | 88/595 [00:11<00:57,  8.84it/s] 15%|█▍        | 89/595 [00:11<00:56,  8.90it/s] 15%|█▌        | 90/595 [00:11<00:56,  8.91it/s] 15%|█▌        | 91/595 [00:11<00:55,  9.03it/s] 15%|█▌        | 92/595 [00:11<00:56,  8.92it/s] 16%|█▌        | 93/595 [00:11<00:56,  8.93it/s] 16%|█▌        | 94/595 [00:11<00:56,  8.85it/s] 16%|█▌        | 95/595 [00:11<00:55,  8.93it/s] 16%|█▌        | 96/595 [00:11<00:55,  8.99it/s] 16%|█▋        | 97/595 [00:12<00:55,  8.93it/s] 16%|█▋        | 98/595 [00:12<00:55,  8.91it/s] 17%|█▋        | 99/595 [00:12<00:56,  8.85it/s] 17%|█▋        | 100/595 [00:12<00:55,  8.91it/s] 17%|█▋        | 101/595 [00:12<00:54,  9.03it/s] 17%|█▋        | 102/595 [00:12<00:54,  8.98it/s] 17%|█▋        | 103/595 [00:12<00:54,  8.95it/s] 17%|█▋        | 104/595 [00:12<00:55,  8.90it/s] 18%|█▊        | 105/595 [00:12<00:54,  8.95it/s] 18%|█▊        | 106/595 [00:13<00:54,  8.90it/s] 18%|█▊        | 107/595 [00:13<00:54,  8.94it/s] 18%|█▊        | 108/595 [00:13<00:53,  9.03it/s] 18%|█▊        | 109/595 [00:13<00:54,  8.92it/s] 18%|█▊        | 110/595 [00:13<00:54,  8.93it/s] 19%|█▊        | 111/595 [00:13<00:54,  8.94it/s] 19%|█▉        | 112/595 [00:13<00:53,  9.02it/s] 19%|█▉        | 113/595 [00:13<00:53,  9.09it/s] 19%|█▉        | 114/595 [00:13<00:53,  8.98it/s] 19%|█▉        | 115/595 [00:14<00:53,  8.99it/s] 19%|█▉        | 116/595 [00:14<00:53,  8.94it/s] 20%|█▉        | 117/595 [00:14<00:53,  8.97it/s] 20%|█▉        | 118/595 [00:14<00:52,  9.16it/s]                                                  20%|██        | 119/595 [00:14<00:51,  9.16it/s][INFO|trainer.py:755] 2023-11-15 21:22:34,697 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:22:34,699 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:22:34,699 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:22:34,699 >>   Batch size = 8
{'loss': 0.8155, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 80.82it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 69.62it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 69.84it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 71.20it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 69.07it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 70.13it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 69.00it/s][A
 55%|█████▍    | 65/119 [00:00<00:00, 69.26it/s][A
 61%|██████▏   | 73/119 [00:01<00:00, 70.75it/s][A
 68%|██████▊   | 81/119 [00:01<00:00, 70.11it/s][A
 75%|███████▍  | 89/119 [00:01<00:00, 67.57it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 69.45it/s][A
 88%|████████▊ | 105/119 [00:01<00:00, 70.63it/s][A
 95%|█████████▍| 113/119 [00:01<00:00, 68.57it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:16<00:51,  9.16it/s]
100%|██████████| 119/119 [00:01<00:00, 68.57it/s][A
                                                 [A 20%|██        | 120/595 [00:16<03:58,  1.99it/s] 20%|██        | 121/595 [00:16<03:11,  2.47it/s] 21%|██        | 122/595 [00:16<02:35,  3.04it/s] 21%|██        | 123/595 [00:16<02:06,  3.72it/s] 21%|██        | 124/595 [00:16<01:46,  4.43it/s] 21%|██        | 125/595 [00:16<01:30,  5.20it/s] 21%|██        | 126/595 [00:16<01:18,  5.98it/s] 21%|██▏       | 127/595 [00:17<01:10,  6.64it/s] 22%|██▏       | 128/595 [00:17<01:05,  7.17it/s] 22%|██▏       | 129/595 [00:17<01:01,  7.62it/s] 22%|██▏       | 130/595 [00:17<00:58,  7.97it/s] 22%|██▏       | 131/595 [00:17<00:55,  8.33it/s] 22%|██▏       | 132/595 [00:17<00:54,  8.45it/s] 22%|██▏       | 133/595 [00:17<00:53,  8.69it/s] 23%|██▎       | 134/595 [00:17<00:52,  8.70it/s] 23%|██▎       | 135/595 [00:17<00:52,  8.81it/s] 23%|██▎       | 136/595 [00:18<00:51,  8.96it/s] 23%|██▎       | 137/595 [00:18<00:51,  8.90it/s] 23%|██▎       | 138/595 [00:18<00:51,  8.95it/s] 23%|██▎       | 139/595 [00:18<00:50,  8.95it/s] 24%|██▎       | 140/595 [00:18<00:50,  9.00it/s] 24%|██▎       | 141/595 [00:18<00:50,  9.01it/s] 24%|██▍       | 142/595 [00:18<00:50,  8.96it/s] 24%|██▍       | 143/595 [00:18<00:50,  8.99it/s] 24%|██▍       | 144/595 [00:18<00:50,  8.99it/s] 24%|██▍       | 145/595 [00:19<00:49,  9.09it/s] 25%|██▍       | 146/595 [00:19<00:48,  9.18it/s] 25%|██▍       | 147/595 [00:19<00:49,  9.06it/s] 25%|██▍       | 148/595 [00:19<00:49,  9.09it/s] 25%|██▌       | 149/595 [00:19<00:49,  9.08it/s] 25%|██▌       | 150/595 [00:19<00:48,  9.10it/s] 25%|██▌       | 151/595 [00:19<00:48,  9.08it/s] 26%|██▌       | 152/595 [00:19<00:48,  9.05it/s] 26%|██▌       | 153/595 [00:19<00:49,  8.99it/s] 26%|██▌       | 154/595 [00:20<00:49,  8.94it/s] 26%|██▌       | 155/595 [00:20<00:48,  9.05it/s] 26%|██▌       | 156/595 [00:20<00:47,  9.15it/s] 26%|██▋       | 157/595 [00:20<00:48,  9.02it/s] 27%|██▋       | 158/595 [00:20<00:48,  8.98it/s] 27%|██▋       | 159/595 [00:20<00:48,  8.98it/s] 27%|██▋       | 160/595 [00:20<00:48,  8.99it/s] 27%|██▋       | 161/595 [00:20<00:47,  9.05it/s] 27%|██▋       | 162/595 [00:20<00:47,  9.05it/s] 27%|██▋       | 163/595 [00:21<00:47,  9.13it/s] 28%|██▊       | 164/595 [00:21<00:48,  8.96it/s] 28%|██▊       | 165/595 [00:21<00:47,  8.96it/s] 28%|██▊       | 166/595 [00:21<00:47,  8.99it/s] 28%|██▊       | 167/595 [00:21<00:47,  9.01it/s] 28%|██▊       | 168/595 [00:21<00:47,  8.93it/s] 28%|██▊       | 169/595 [00:21<00:47,  8.95it/s] 29%|██▊       | 170/595 [00:21<00:47,  8.94it/s] 29%|██▊       | 171/595 [00:21<00:47,  8.92it/s] 29%|██▉       | 172/595 [00:22<00:47,  8.93it/s] 29%|██▉       | 173/595 [00:22<00:46,  9.04it/s] 29%|██▉       | 174/595 [00:22<00:47,  8.93it/s] 29%|██▉       | 175/595 [00:22<00:47,  8.90it/s] 30%|██▉       | 176/595 [00:22<00:47,  8.91it/s] 30%|██▉       | 177/595 [00:22<00:46,  8.97it/s] 30%|██▉       | 178/595 [00:22<00:46,  8.99it/s] 30%|███       | 179/595 [00:22<00:46,  8.88it/s] 30%|███       | 180/595 [00:22<00:46,  8.90it/s] 30%|███       | 181/595 [00:23<00:46,  8.87it/s] 31%|███       | 182/595 [00:23<00:46,  8.80it/s] 31%|███       | 183/595 [00:23<00:46,  8.89it/s] 31%|███       | 184/595 [00:23<00:46,  8.89it/s] 31%|███       | 185/595 [00:23<00:46,  8.87it/s] 31%|███▏      | 186/595 [00:23<00:46,  8.70it/s] 31%|███▏      | 187/595 [00:23<00:46,  8.75it/s] 32%|███▏      | 188/595 [00:23<00:46,  8.84it/s] 32%|███▏      | 189/595 [00:23<00:45,  8.90it/s] 32%|███▏      | 190/595 [00:24<00:45,  8.94it/s] 32%|███▏      | 191/595 [00:24<00:45,  8.95it/s] 32%|███▏      | 192/595 [00:24<00:45,  8.85it/s] 32%|███▏      | 193/595 [00:24<00:45,  8.79it/s] 33%|███▎      | 194/595 [00:24<00:45,  8.79it/s] 33%|███▎      | 195/595 [00:24<00:45,  8.85it/s] 33%|███▎      | 196/595 [00:24<00:44,  8.90it/s] 33%|███▎      | 197/595 [00:24<00:44,  8.89it/s] 33%|███▎      | 198/595 [00:24<00:44,  8.84it/s] 33%|███▎      | 199/595 [00:25<00:45,  8.77it/s] 34%|███▎      | 200/595 [00:25<00:45,  8.77it/s] 34%|███▍      | 201/595 [00:25<00:44,  8.83it/s] 34%|███▍      | 202/595 [00:25<00:44,  8.87it/s] 34%|███▍      | 203/595 [00:25<00:44,  8.79it/s] 34%|███▍      | 204/595 [00:25<00:44,  8.83it/s] 34%|███▍      | 205/595 [00:25<00:44,  8.81it/s] 35%|███▍      | 206/595 [00:25<00:44,  8.78it/s] 35%|███▍      | 207/595 [00:25<00:43,  8.85it/s] 35%|███▍      | 208/595 [00:26<00:43,  8.86it/s] 35%|███▌      | 209/595 [00:26<00:43,  8.80it/s] 35%|███▌      | 210/595 [00:26<00:43,  8.79it/s] 35%|███▌      | 211/595 [00:26<00:43,  8.82it/s] 36%|███▌      | 212/595 [00:26<00:43,  8.76it/s] 36%|███▌      | 213/595 [00:26<00:43,  8.76it/s] 36%|███▌      | 214/595 [00:26<00:43,  8.85it/s] 36%|███▌      | 215/595 [00:26<00:43,  8.78it/s] 36%|███▋      | 216/595 [00:27<00:43,  8.76it/s] 36%|███▋      | 217/595 [00:27<00:43,  8.71it/s] 37%|███▋      | 218/595 [00:27<00:43,  8.76it/s] 37%|███▋      | 219/595 [00:27<00:42,  8.81it/s] 37%|███▋      | 220/595 [00:27<00:42,  8.82it/s] 37%|███▋      | 221/595 [00:27<00:41,  8.96it/s] 37%|███▋      | 222/595 [00:27<00:42,  8.74it/s] 37%|███▋      | 223/595 [00:27<00:42,  8.72it/s] 38%|███▊      | 224/595 [00:27<00:42,  8.76it/s] 38%|███▊      | 225/595 [00:28<00:41,  8.84it/s] 38%|███▊      | 226/595 [00:28<00:41,  8.83it/s] 38%|███▊      | 227/595 [00:28<00:41,  8.80it/s] 38%|███▊      | 228/595 [00:28<00:41,  8.89it/s] 38%|███▊      | 229/595 [00:28<00:41,  8.78it/s] 39%|███▊      | 230/595 [00:28<00:41,  8.82it/s] 39%|███▉      | 231/595 [00:28<00:41,  8.87it/s] 39%|███▉      | 232/595 [00:28<00:40,  8.92it/s] 39%|███▉      | 233/595 [00:28<00:40,  8.89it/s] 39%|███▉      | 234/595 [00:29<00:40,  8.85it/s] 39%|███▉      | 235/595 [00:29<00:40,  8.85it/s] 40%|███▉      | 236/595 [00:29<00:40,  8.82it/s] 40%|███▉      | 237/595 [00:29<00:40,  8.91it/s]                                                  40%|████      | 238/595 [00:29<00:40,  8.91it/s][INFO|trainer.py:755] 2023-11-15 21:22:49,725 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:22:49,727 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:22:49,727 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:22:49,728 >>   Batch size = 8
{'eval_loss': 0.7001029253005981, 'eval_accuracy': 0.6846560846560846, 'eval_micro_f1': 0.6846560846560846, 'eval_macro_f1': 0.476057293732453, 'eval_runtime': 1.7484, 'eval_samples_per_second': 540.48, 'eval_steps_per_second': 68.06, 'epoch': 1.0}
{'loss': 0.6032, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 77.20it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 74.47it/s][A
 20%|██        | 24/119 [00:00<00:01, 71.75it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 70.72it/s][A
 34%|███▎      | 40/119 [00:00<00:01, 67.41it/s][A
 40%|████      | 48/119 [00:00<00:01, 67.87it/s][A
 46%|████▌     | 55/119 [00:00<00:00, 68.03it/s][A
 52%|█████▏    | 62/119 [00:00<00:00, 68.45it/s][A
 58%|█████▊    | 69/119 [00:00<00:00, 68.19it/s][A
 64%|██████▍   | 76/119 [00:01<00:00, 67.89it/s][A
 71%|███████   | 84/119 [00:01<00:00, 68.63it/s][A
 76%|███████▋  | 91/119 [00:01<00:00, 68.73it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 66.93it/s][A
 88%|████████▊ | 105/119 [00:01<00:00, 66.66it/s][A
 95%|█████████▍| 113/119 [00:01<00:00, 66.90it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:31<00:40,  8.91it/s]
100%|██████████| 119/119 [00:01<00:00, 66.90it/s][A
                                                 [A 40%|████      | 239/595 [00:31<03:01,  1.96it/s] 40%|████      | 240/595 [00:31<02:25,  2.43it/s] 41%|████      | 241/595 [00:31<01:58,  3.00it/s] 41%|████      | 242/595 [00:31<01:36,  3.64it/s] 41%|████      | 243/595 [00:31<01:20,  4.35it/s] 41%|████      | 244/595 [00:31<01:08,  5.09it/s] 41%|████      | 245/595 [00:32<01:00,  5.81it/s] 41%|████▏     | 246/595 [00:32<00:53,  6.46it/s] 42%|████▏     | 247/595 [00:32<00:49,  7.05it/s] 42%|████▏     | 248/595 [00:32<00:46,  7.45it/s] 42%|████▏     | 249/595 [00:32<00:44,  7.72it/s] 42%|████▏     | 250/595 [00:32<00:43,  8.02it/s] 42%|████▏     | 251/595 [00:32<00:41,  8.27it/s] 42%|████▏     | 252/595 [00:32<00:40,  8.43it/s] 43%|████▎     | 253/595 [00:32<00:40,  8.48it/s] 43%|████▎     | 254/595 [00:33<00:39,  8.56it/s] 43%|████▎     | 255/595 [00:33<00:39,  8.58it/s] 43%|████▎     | 256/595 [00:33<00:39,  8.68it/s] 43%|████▎     | 257/595 [00:33<00:38,  8.86it/s] 43%|████▎     | 258/595 [00:33<00:38,  8.81it/s] 44%|████▎     | 259/595 [00:33<00:38,  8.78it/s] 44%|████▎     | 260/595 [00:33<00:38,  8.67it/s] 44%|████▍     | 261/595 [00:33<00:38,  8.72it/s] 44%|████▍     | 262/595 [00:33<00:37,  8.80it/s] 44%|████▍     | 263/595 [00:34<00:37,  8.80it/s] 44%|████▍     | 264/595 [00:34<00:37,  8.92it/s] 45%|████▍     | 265/595 [00:34<00:37,  8.78it/s] 45%|████▍     | 266/595 [00:34<00:37,  8.66it/s] 45%|████▍     | 267/595 [00:34<00:37,  8.79it/s] 45%|████▌     | 268/595 [00:34<00:37,  8.82it/s] 45%|████▌     | 269/595 [00:34<00:37,  8.81it/s] 45%|████▌     | 270/595 [00:34<00:37,  8.78it/s] 46%|████▌     | 271/595 [00:34<00:36,  8.77it/s] 46%|████▌     | 272/595 [00:35<00:36,  8.73it/s] 46%|████▌     | 273/595 [00:35<00:36,  8.77it/s] 46%|████▌     | 274/595 [00:35<00:36,  8.84it/s] 46%|████▌     | 275/595 [00:35<00:36,  8.82it/s] 46%|████▋     | 276/595 [00:35<00:36,  8.74it/s] 47%|████▋     | 277/595 [00:35<00:36,  8.74it/s] 47%|████▋     | 278/595 [00:35<00:36,  8.75it/s] 47%|████▋     | 279/595 [00:35<00:35,  8.83it/s] 47%|████▋     | 280/595 [00:36<00:35,  8.89it/s] 47%|████▋     | 281/595 [00:36<00:34,  9.06it/s] 47%|████▋     | 282/595 [00:36<00:35,  8.90it/s] 48%|████▊     | 283/595 [00:36<00:35,  8.87it/s] 48%|████▊     | 284/595 [00:36<00:34,  8.91it/s] 48%|████▊     | 285/595 [00:36<00:34,  8.92it/s] 48%|████▊     | 286/595 [00:36<00:34,  8.92it/s] 48%|████▊     | 287/595 [00:36<00:34,  8.84it/s] 48%|████▊     | 288/595 [00:36<00:34,  8.82it/s] 49%|████▊     | 289/595 [00:37<00:34,  8.82it/s] 49%|████▊     | 290/595 [00:37<00:34,  8.86it/s] 49%|████▉     | 291/595 [00:37<00:33,  9.02it/s] 49%|████▉     | 292/595 [00:37<00:33,  8.91it/s] 49%|████▉     | 293/595 [00:37<00:34,  8.82it/s] 49%|████▉     | 294/595 [00:37<00:33,  8.88it/s] 50%|████▉     | 295/595 [00:37<00:33,  8.91it/s] 50%|████▉     | 296/595 [00:37<00:33,  8.95it/s] 50%|████▉     | 297/595 [00:37<00:33,  8.86it/s] 50%|█████     | 298/595 [00:38<00:33,  8.89it/s] 50%|█████     | 299/595 [00:38<00:33,  8.86it/s] 50%|█████     | 300/595 [00:38<00:33,  8.85it/s] 51%|█████     | 301/595 [00:38<00:32,  8.96it/s] 51%|█████     | 302/595 [00:38<00:32,  8.94it/s] 51%|█████     | 303/595 [00:38<00:33,  8.82it/s] 51%|█████     | 304/595 [00:38<00:33,  8.79it/s] 51%|█████▏    | 305/595 [00:38<00:32,  8.79it/s] 51%|█████▏    | 306/595 [00:38<00:32,  8.85it/s] 52%|█████▏    | 307/595 [00:39<00:32,  8.93it/s] 52%|█████▏    | 308/595 [00:39<00:31,  9.03it/s] 52%|█████▏    | 309/595 [00:39<00:31,  8.96it/s] 52%|█████▏    | 310/595 [00:39<00:32,  8.90it/s] 52%|█████▏    | 311/595 [00:39<00:32,  8.85it/s] 52%|█████▏    | 312/595 [00:39<00:31,  8.90it/s] 53%|█████▎    | 313/595 [00:39<00:31,  8.94it/s] 53%|█████▎    | 314/595 [00:39<00:31,  8.84it/s] 53%|█████▎    | 315/595 [00:39<00:31,  8.86it/s] 53%|█████▎    | 316/595 [00:40<00:31,  8.83it/s] 53%|█████▎    | 317/595 [00:40<00:31,  8.84it/s] 53%|█████▎    | 318/595 [00:40<00:31,  8.92it/s] 54%|█████▎    | 319/595 [00:40<00:30,  8.98it/s] 54%|█████▍    | 320/595 [00:40<00:30,  8.88it/s] 54%|█████▍    | 321/595 [00:40<00:31,  8.73it/s] 54%|█████▍    | 322/595 [00:40<00:31,  8.75it/s] 54%|█████▍    | 323/595 [00:40<00:30,  8.80it/s] 54%|█████▍    | 324/595 [00:40<00:30,  8.83it/s] 55%|█████▍    | 325/595 [00:41<00:30,  8.88it/s] 55%|█████▍    | 326/595 [00:41<00:30,  8.79it/s] 55%|█████▍    | 327/595 [00:41<00:30,  8.77it/s] 55%|█████▌    | 328/595 [00:41<00:30,  8.86it/s] 55%|█████▌    | 329/595 [00:41<00:29,  8.88it/s] 55%|█████▌    | 330/595 [00:41<00:29,  8.85it/s] 56%|█████▌    | 331/595 [00:41<00:30,  8.73it/s] 56%|█████▌    | 332/595 [00:41<00:30,  8.66it/s] 56%|█████▌    | 333/595 [00:41<00:29,  8.76it/s] 56%|█████▌    | 334/595 [00:42<00:29,  8.86it/s] 56%|█████▋    | 335/595 [00:42<00:28,  9.00it/s] 56%|█████▋    | 336/595 [00:42<00:29,  8.83it/s] 57%|█████▋    | 337/595 [00:42<00:29,  8.79it/s] 57%|█████▋    | 338/595 [00:42<00:29,  8.76it/s] 57%|█████▋    | 339/595 [00:42<00:28,  8.85it/s] 57%|█████▋    | 340/595 [00:42<00:28,  8.86it/s] 57%|█████▋    | 341/595 [00:42<00:28,  8.83it/s] 57%|█████▋    | 342/595 [00:43<00:28,  8.83it/s] 58%|█████▊    | 343/595 [00:43<00:28,  8.78it/s] 58%|█████▊    | 344/595 [00:43<00:28,  8.78it/s] 58%|█████▊    | 345/595 [00:43<00:28,  8.84it/s] 58%|█████▊    | 346/595 [00:43<00:28,  8.84it/s] 58%|█████▊    | 347/595 [00:43<00:28,  8.82it/s] 58%|█████▊    | 348/595 [00:43<00:28,  8.79it/s] 59%|█████▊    | 349/595 [00:43<00:27,  8.79it/s] 59%|█████▉    | 350/595 [00:43<00:27,  8.80it/s] 59%|█████▉    | 351/595 [00:44<00:27,  8.89it/s] 59%|█████▉    | 352/595 [00:44<00:27,  8.96it/s] 59%|█████▉    | 353/595 [00:44<00:27,  8.90it/s] 59%|█████▉    | 354/595 [00:44<00:27,  8.77it/s] 60%|█████▉    | 355/595 [00:44<00:27,  8.80it/s] 60%|█████▉    | 356/595 [00:44<00:26,  8.89it/s]                                                  60%|██████    | 357/595 [00:44<00:26,  8.89it/s][INFO|trainer.py:755] 2023-11-15 21:23:04,916 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:23:04,918 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:23:04,918 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:23:04,918 >>   Batch size = 8
{'eval_loss': 0.6445690393447876, 'eval_accuracy': 0.7417989417989418, 'eval_micro_f1': 0.7417989417989418, 'eval_macro_f1': 0.5901000888634704, 'eval_runtime': 1.7862, 'eval_samples_per_second': 529.051, 'eval_steps_per_second': 66.621, 'epoch': 2.0}
{'loss': 0.4887, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  7%|▋         | 8/119 [00:00<00:01, 78.41it/s][A
 13%|█▎        | 16/119 [00:00<00:01, 74.96it/s][A
 20%|██        | 24/119 [00:00<00:01, 70.93it/s][A
 27%|██▋       | 32/119 [00:00<00:01, 67.23it/s][A
 33%|███▎      | 39/119 [00:00<00:01, 65.49it/s][A
 39%|███▊      | 46/119 [00:00<00:01, 66.30it/s][A
 45%|████▍     | 53/119 [00:00<00:00, 66.71it/s][A
 50%|█████     | 60/119 [00:00<00:00, 67.24it/s][A
 56%|█████▋    | 67/119 [00:00<00:00, 68.02it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 67.89it/s][A
 68%|██████▊   | 81/119 [00:01<00:00, 67.57it/s][A
 74%|███████▍  | 88/119 [00:01<00:00, 65.29it/s][A
 80%|███████▉  | 95/119 [00:01<00:00, 66.16it/s][A
 86%|████████▌ | 102/119 [00:01<00:00, 65.41it/s][A
 92%|█████████▏| 109/119 [00:01<00:00, 65.16it/s][A
 97%|█████████▋| 116/119 [00:01<00:00, 66.22it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:46<00:26,  8.89it/s]
100%|██████████| 119/119 [00:01<00:00, 66.22it/s][A
                                                 [A 60%|██████    | 358/595 [00:46<02:02,  1.94it/s] 60%|██████    | 359/595 [00:46<01:38,  2.41it/s] 61%|██████    | 360/595 [00:46<01:18,  2.98it/s] 61%|██████    | 361/595 [00:46<01:04,  3.65it/s] 61%|██████    | 362/595 [00:47<00:53,  4.37it/s] 61%|██████    | 363/595 [00:47<00:45,  5.07it/s] 61%|██████    | 364/595 [00:47<00:39,  5.79it/s] 61%|██████▏   | 365/595 [00:47<00:35,  6.48it/s] 62%|██████▏   | 366/595 [00:47<00:32,  7.02it/s] 62%|██████▏   | 367/595 [00:47<00:30,  7.50it/s] 62%|██████▏   | 368/595 [00:47<00:29,  7.82it/s] 62%|██████▏   | 369/595 [00:47<00:28,  8.07it/s] 62%|██████▏   | 370/595 [00:47<00:26,  8.38it/s] 62%|██████▏   | 371/595 [00:48<00:26,  8.54it/s] 63%|██████▎   | 372/595 [00:48<00:26,  8.57it/s] 63%|██████▎   | 373/595 [00:48<00:25,  8.55it/s] 63%|██████▎   | 374/595 [00:48<00:25,  8.66it/s] 63%|██████▎   | 375/595 [00:48<00:25,  8.75it/s] 63%|██████▎   | 376/595 [00:48<00:25,  8.75it/s] 63%|██████▎   | 377/595 [00:48<00:24,  8.83it/s] 64%|██████▎   | 378/595 [00:48<00:24,  8.76it/s] 64%|██████▎   | 379/595 [00:48<00:24,  8.77it/s] 64%|██████▍   | 380/595 [00:49<00:24,  8.88it/s] 64%|██████▍   | 381/595 [00:49<00:23,  8.92it/s] 64%|██████▍   | 382/595 [00:49<00:23,  8.91it/s] 64%|██████▍   | 383/595 [00:49<00:23,  8.84it/s] 65%|██████▍   | 384/595 [00:49<00:23,  8.81it/s] 65%|██████▍   | 385/595 [00:49<00:23,  8.80it/s] 65%|██████▍   | 386/595 [00:49<00:23,  8.82it/s] 65%|██████▌   | 387/595 [00:49<00:23,  8.93it/s] 65%|██████▌   | 388/595 [00:49<00:23,  8.89it/s] 65%|██████▌   | 389/595 [00:50<00:23,  8.82it/s] 66%|██████▌   | 390/595 [00:50<00:23,  8.79it/s] 66%|██████▌   | 391/595 [00:50<00:22,  8.92it/s] 66%|██████▌   | 392/595 [00:50<00:22,  8.94it/s] 66%|██████▌   | 393/595 [00:50<00:22,  8.87it/s] 66%|██████▋   | 395/595 [00:50<00:20,  9.76it/s] 67%|██████▋   | 397/595 [00:50<00:19, 10.24it/s] 67%|██████▋   | 399/595 [00:51<00:18, 10.52it/s] 67%|██████▋   | 401/595 [00:51<00:18, 10.70it/s] 68%|██████▊   | 403/595 [00:51<00:19, 10.09it/s] 68%|██████▊   | 405/595 [00:51<00:19,  9.79it/s] 68%|██████▊   | 406/595 [00:51<00:19,  9.62it/s] 68%|██████▊   | 407/595 [00:51<00:19,  9.47it/s] 69%|██████▊   | 408/595 [00:52<00:19,  9.42it/s] 69%|██████▊   | 409/595 [00:52<00:20,  9.30it/s] 69%|██████▉   | 410/595 [00:52<00:20,  9.19it/s] 69%|██████▉   | 411/595 [00:52<00:20,  9.11it/s] 69%|██████▉   | 412/595 [00:52<00:20,  9.15it/s] 69%|██████▉   | 413/595 [00:52<00:20,  9.09it/s] 70%|██████▉   | 414/595 [00:52<00:19,  9.08it/s] 70%|██████▉   | 415/595 [00:52<00:19,  9.18it/s] 70%|██████▉   | 416/595 [00:52<00:19,  8.97it/s] 70%|███████   | 417/595 [00:53<00:19,  8.92it/s] 70%|███████   | 418/595 [00:53<00:19,  8.98it/s] 70%|███████   | 419/595 [00:53<00:19,  9.00it/s] 71%|███████   | 420/595 [00:53<00:19,  8.97it/s] 71%|███████   | 421/595 [00:53<00:19,  8.92it/s] 71%|███████   | 422/595 [00:53<00:19,  9.02it/s] 71%|███████   | 423/595 [00:53<00:19,  9.04it/s] 71%|███████▏  | 424/595 [00:53<00:18,  9.02it/s] 71%|███████▏  | 425/595 [00:53<00:18,  9.04it/s] 72%|███████▏  | 426/595 [00:54<00:18,  9.03it/s] 72%|███████▏  | 427/595 [00:54<00:18,  9.00it/s] 72%|███████▏  | 428/595 [00:54<00:18,  8.86it/s] 72%|███████▏  | 429/595 [00:54<00:18,  8.92it/s] 72%|███████▏  | 430/595 [00:54<00:18,  8.90it/s] 72%|███████▏  | 431/595 [00:54<00:18,  8.92it/s] 73%|███████▎  | 432/595 [00:54<00:17,  9.11it/s] 73%|███████▎  | 433/595 [00:54<00:17,  9.07it/s] 73%|███████▎  | 434/595 [00:54<00:17,  9.01it/s] 73%|███████▎  | 435/595 [00:55<00:17,  8.95it/s] 73%|███████▎  | 436/595 [00:55<00:17,  8.97it/s] 73%|███████▎  | 437/595 [00:55<00:17,  9.04it/s] 74%|███████▎  | 438/595 [00:55<00:17,  8.99it/s] 74%|███████▍  | 439/595 [00:55<00:16,  9.23it/s] 74%|███████▍  | 440/595 [00:55<00:17,  9.07it/s] 74%|███████▍  | 441/595 [00:55<00:17,  8.90it/s] 74%|███████▍  | 442/595 [00:55<00:17,  8.95it/s] 74%|███████▍  | 443/595 [00:55<00:17,  8.89it/s] 75%|███████▍  | 444/595 [00:56<00:16,  8.94it/s] 75%|███████▍  | 445/595 [00:56<00:16,  8.87it/s] 75%|███████▍  | 446/595 [00:56<00:16,  8.99it/s] 75%|███████▌  | 447/595 [00:56<00:16,  8.92it/s] 75%|███████▌  | 448/595 [00:56<00:16,  8.86it/s] 75%|███████▌  | 449/595 [00:56<00:16,  8.93it/s] 76%|███████▌  | 450/595 [00:56<00:16,  8.95it/s] 76%|███████▌  | 451/595 [00:56<00:16,  8.93it/s] 76%|███████▌  | 452/595 [00:56<00:16,  8.88it/s] 76%|███████▌  | 453/595 [00:57<00:15,  8.91it/s] 76%|███████▋  | 454/595 [00:57<00:15,  8.82it/s] 76%|███████▋  | 455/595 [00:57<00:15,  8.91it/s] 77%|███████▋  | 456/595 [00:57<00:15,  9.04it/s] 77%|███████▋  | 457/595 [00:57<00:15,  8.96it/s] 77%|███████▋  | 458/595 [00:57<00:15,  8.90it/s] 77%|███████▋  | 459/595 [00:57<00:15,  8.86it/s] 77%|███████▋  | 460/595 [00:57<00:15,  8.93it/s] 77%|███████▋  | 461/595 [00:57<00:14,  8.97it/s] 78%|███████▊  | 462/595 [00:58<00:15,  8.86it/s] 78%|███████▊  | 464/595 [00:58<00:14,  9.08it/s] 78%|███████▊  | 465/595 [00:58<00:14,  9.01it/s] 78%|███████▊  | 466/595 [00:58<00:14,  8.93it/s] 78%|███████▊  | 467/595 [00:58<00:14,  8.94it/s] 79%|███████▊  | 468/595 [00:58<00:14,  8.95it/s] 79%|███████▉  | 469/595 [00:58<00:14,  8.90it/s] 79%|███████▉  | 470/595 [00:58<00:13,  8.96it/s] 79%|███████▉  | 471/595 [00:59<00:13,  8.96it/s] 79%|███████▉  | 472/595 [00:59<00:13,  8.91it/s] 79%|███████▉  | 473/595 [00:59<00:13,  8.97it/s] 80%|███████▉  | 474/595 [00:59<00:13,  8.97it/s] 80%|███████▉  | 475/595 [00:59<00:13,  9.07it/s]                                                  80%|████████  | 476/595 [00:59<00:13,  9.07it/s][INFO|trainer.py:755] 2023-11-15 21:23:19,800 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:23:19,801 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:23:19,802 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:23:19,802 >>   Batch size = 8
{'eval_loss': 0.6530283093452454, 'eval_accuracy': 0.7417989417989418, 'eval_micro_f1': 0.7417989417989418, 'eval_macro_f1': 0.6234134201621936, 'eval_runtime': 1.8062, 'eval_samples_per_second': 523.19, 'eval_steps_per_second': 65.883, 'epoch': 3.0}
{'loss': 0.4037, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 81.90it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 77.76it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 71.01it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 69.73it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 71.79it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 70.41it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 70.92it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 72.38it/s][A
 62%|██████▏   | 74/119 [00:01<00:00, 69.28it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 68.05it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 69.53it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 69.31it/s][A
 88%|████████▊ | 105/119 [00:01<00:00, 70.35it/s][A
 95%|█████████▍| 113/119 [00:01<00:00, 69.57it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [01:01<00:13,  9.07it/s]
100%|██████████| 119/119 [00:01<00:00, 69.57it/s][A
                                                 [A 80%|████████  | 477/595 [01:01<00:58,  2.03it/s] 80%|████████  | 478/595 [01:01<00:46,  2.49it/s] 81%|████████  | 479/595 [01:01<00:37,  3.07it/s] 81%|████████  | 480/595 [01:01<00:30,  3.73it/s] 81%|████████  | 481/595 [01:01<00:25,  4.45it/s] 81%|████████  | 482/595 [01:01<00:21,  5.19it/s] 81%|████████  | 483/595 [01:02<00:18,  5.94it/s] 81%|████████▏ | 484/595 [01:02<00:16,  6.56it/s] 82%|████████▏ | 485/595 [01:02<00:15,  7.02it/s] 82%|████████▏ | 486/595 [01:02<00:14,  7.50it/s] 82%|████████▏ | 487/595 [01:02<00:13,  7.89it/s] 82%|████████▏ | 488/595 [01:02<00:13,  8.15it/s] 82%|████████▏ | 489/595 [01:02<00:12,  8.30it/s] 82%|████████▏ | 490/595 [01:02<00:12,  8.74it/s] 83%|████████▎ | 491/595 [01:02<00:11,  8.74it/s] 83%|████████▎ | 492/595 [01:03<00:11,  8.73it/s] 83%|████████▎ | 493/595 [01:03<00:11,  8.72it/s] 83%|████████▎ | 494/595 [01:03<00:11,  8.78it/s] 83%|████████▎ | 495/595 [01:03<00:11,  8.84it/s] 83%|████████▎ | 496/595 [01:03<00:11,  8.79it/s] 84%|████████▎ | 497/595 [01:03<00:10,  8.96it/s] 84%|████████▎ | 498/595 [01:03<00:10,  8.92it/s] 84%|████████▍ | 499/595 [01:03<00:10,  8.84it/s] 84%|████████▍ | 500/595 [01:03<00:10,  8.89it/s] 84%|████████▍ | 501/595 [01:04<00:10,  8.91it/s] 84%|████████▍ | 502/595 [01:04<00:10,  8.93it/s] 85%|████████▍ | 503/595 [01:04<00:10,  8.91it/s] 85%|████████▍ | 504/595 [01:04<00:10,  9.00it/s] 85%|████████▍ | 505/595 [01:04<00:10,  8.89it/s] 85%|████████▌ | 506/595 [01:04<00:10,  8.82it/s] 85%|████████▌ | 507/595 [01:04<00:09,  8.94it/s] 85%|████████▌ | 508/595 [01:04<00:09,  8.92it/s] 86%|████████▌ | 509/595 [01:04<00:09,  8.94it/s] 86%|████████▌ | 510/595 [01:05<00:09,  8.88it/s] 86%|████████▌ | 511/595 [01:05<00:09,  8.96it/s] 86%|████████▌ | 512/595 [01:05<00:09,  8.85it/s] 86%|████████▌ | 513/595 [01:05<00:09,  8.83it/s] 86%|████████▋ | 514/595 [01:05<00:09,  8.98it/s] 87%|████████▋ | 515/595 [01:05<00:08,  8.98it/s] 87%|████████▋ | 516/595 [01:05<00:08,  9.02it/s] 87%|████████▋ | 517/595 [01:05<00:08,  8.99it/s] 87%|████████▋ | 518/595 [01:05<00:08,  9.22it/s] 87%|████████▋ | 519/595 [01:06<00:08,  9.08it/s] 87%|████████▋ | 520/595 [01:06<00:08,  8.95it/s] 88%|████████▊ | 521/595 [01:06<00:08,  9.00it/s] 88%|████████▊ | 522/595 [01:06<00:08,  8.99it/s] 88%|████████▊ | 523/595 [01:06<00:07,  9.00it/s] 88%|████████▊ | 524/595 [01:06<00:07,  8.96it/s] 88%|████████▊ | 525/595 [01:06<00:07,  9.21it/s] 88%|████████▊ | 526/595 [01:06<00:07,  9.05it/s] 89%|████████▊ | 527/595 [01:06<00:07,  8.88it/s] 89%|████████▊ | 528/595 [01:07<00:07,  8.91it/s] 89%|████████▉ | 529/595 [01:07<00:07,  8.93it/s] 89%|████████▉ | 530/595 [01:07<00:07,  8.97it/s] 89%|████████▉ | 531/595 [01:07<00:07,  9.01it/s] 89%|████████▉ | 532/595 [01:07<00:06,  9.11it/s] 90%|████████▉ | 533/595 [01:07<00:06,  9.01it/s] 90%|████████▉ | 534/595 [01:07<00:06,  8.98it/s] 90%|████████▉ | 535/595 [01:07<00:06,  8.85it/s] 90%|█████████ | 536/595 [01:07<00:06,  8.87it/s] 90%|█████████ | 537/595 [01:08<00:06,  8.90it/s] 90%|█████████ | 538/595 [01:08<00:06,  8.97it/s] 91%|█████████ | 539/595 [01:08<00:06,  9.11it/s] 91%|█████████ | 540/595 [01:08<00:06,  9.00it/s] 91%|█████████ | 541/595 [01:08<00:06,  8.95it/s] 91%|█████████ | 542/595 [01:08<00:05,  8.90it/s] 91%|█████████▏| 543/595 [01:08<00:05,  8.87it/s] 91%|█████████▏| 544/595 [01:08<00:05,  8.93it/s] 92%|█████████▏| 545/595 [01:08<00:05,  8.97it/s] 92%|█████████▏| 546/595 [01:09<00:05,  9.15it/s] 92%|█████████▏| 547/595 [01:09<00:05,  9.06it/s] 92%|█████████▏| 548/595 [01:09<00:05,  8.92it/s] 92%|█████████▏| 549/595 [01:09<00:05,  8.84it/s] 92%|█████████▏| 550/595 [01:09<00:05,  8.86it/s] 93%|█████████▎| 551/595 [01:09<00:04,  8.90it/s] 93%|█████████▎| 552/595 [01:09<00:04,  8.68it/s] 93%|█████████▎| 553/595 [01:09<00:04,  8.88it/s] 93%|█████████▎| 554/595 [01:09<00:04,  8.89it/s] 93%|█████████▎| 555/595 [01:10<00:04,  8.84it/s] 93%|█████████▎| 556/595 [01:10<00:04,  8.86it/s] 94%|█████████▎| 557/595 [01:10<00:04,  8.92it/s] 94%|█████████▍| 558/595 [01:10<00:04,  8.95it/s] 94%|█████████▍| 559/595 [01:10<00:04,  8.86it/s] 94%|█████████▍| 560/595 [01:10<00:03,  9.02it/s] 94%|█████████▍| 561/595 [01:10<00:03,  8.96it/s] 94%|█████████▍| 562/595 [01:10<00:03,  8.98it/s] 95%|█████████▍| 563/595 [01:10<00:03,  8.91it/s] 95%|█████████▍| 564/595 [01:11<00:03,  8.92it/s] 95%|█████████▍| 565/595 [01:11<00:03,  8.95it/s] 95%|█████████▌| 566/595 [01:11<00:03,  8.86it/s] 95%|█████████▌| 567/595 [01:11<00:03,  8.92it/s] 95%|█████████▌| 568/595 [01:11<00:03,  8.88it/s] 96%|█████████▌| 569/595 [01:11<00:02,  8.93it/s] 96%|█████████▌| 570/595 [01:11<00:02,  8.99it/s] 96%|█████████▌| 571/595 [01:11<00:02,  8.92it/s] 96%|█████████▌| 572/595 [01:12<00:02,  8.86it/s] 96%|█████████▋| 573/595 [01:12<00:02,  8.91it/s] 96%|█████████▋| 574/595 [01:12<00:02,  8.90it/s] 97%|█████████▋| 575/595 [01:12<00:02,  8.91it/s] 97%|█████████▋| 576/595 [01:12<00:02,  8.95it/s] 97%|█████████▋| 577/595 [01:12<00:01,  9.03it/s] 97%|█████████▋| 578/595 [01:12<00:01,  8.93it/s] 97%|█████████▋| 579/595 [01:12<00:01,  8.86it/s] 97%|█████████▋| 580/595 [01:12<00:01,  8.97it/s] 98%|█████████▊| 581/595 [01:13<00:01,  8.95it/s] 98%|█████████▊| 582/595 [01:13<00:01,  9.00it/s] 98%|█████████▊| 583/595 [01:13<00:01,  8.89it/s] 98%|█████████▊| 584/595 [01:13<00:01,  9.06it/s] 98%|█████████▊| 585/595 [01:13<00:01,  8.97it/s] 98%|█████████▊| 586/595 [01:13<00:01,  8.90it/s] 99%|█████████▊| 587/595 [01:13<00:00,  8.95it/s] 99%|█████████▉| 588/595 [01:13<00:00,  9.01it/s] 99%|█████████▉| 589/595 [01:13<00:00,  9.03it/s] 99%|█████████▉| 590/595 [01:14<00:00,  8.96it/s] 99%|█████████▉| 591/595 [01:14<00:00,  9.13it/s] 99%|█████████▉| 592/595 [01:14<00:00,  9.03it/s]100%|█████████▉| 593/595 [01:14<00:00,  9.02it/s]100%|█████████▉| 594/595 [01:14<00:00,  9.12it/s]                                                 100%|██████████| 595/595 [01:14<00:00,  9.12it/s][INFO|trainer.py:755] 2023-11-15 21:23:34,769 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:23:34,771 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:23:34,772 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:23:34,772 >>   Batch size = 8
{'eval_loss': 0.6019604802131653, 'eval_accuracy': 0.7597883597883598, 'eval_micro_f1': 0.7597883597883598, 'eval_macro_f1': 0.6701069214940579, 'eval_runtime': 1.7231, 'eval_samples_per_second': 548.443, 'eval_steps_per_second': 69.063, 'epoch': 4.0}
{'loss': 0.3533, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 83.81it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 70.81it/s][A
 23%|██▎       | 27/119 [00:00<00:01, 74.31it/s][A
 29%|██▉       | 35/119 [00:00<00:01, 70.79it/s][A
 36%|███▌      | 43/119 [00:00<00:01, 70.55it/s][A
 43%|████▎     | 51/119 [00:00<00:00, 71.54it/s][A
 50%|████▉     | 59/119 [00:00<00:00, 68.80it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 69.10it/s][A
 61%|██████▏   | 73/119 [00:01<00:00, 68.17it/s][A
 68%|██████▊   | 81/119 [00:01<00:00, 69.84it/s][A
 75%|███████▍  | 89/119 [00:01<00:00, 70.34it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 68.04it/s][A
 88%|████████▊ | 105/119 [00:01<00:00, 71.05it/s][A
 95%|█████████▍| 113/119 [00:01<00:00, 68.83it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:16<00:00,  9.12it/s]
100%|██████████| 119/119 [00:01<00:00, 68.83it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 21:23:36,520 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:16<00:00,  9.12it/s]100%|██████████| 595/595 [01:16<00:00,  7.80it/s]
[INFO|trainer.py:2855] 2023-11-15 21:23:36,523 >> Saving model checkpoint to ./result/restaurant_bert-base-cased_adapter__seed4
[INFO|configuration_utils.py:460] 2023-11-15 21:23:36,526 >> Configuration saved in ./result/restaurant_bert-base-cased_adapter__seed4/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:23:37,559 >> Model weights saved in ./result/restaurant_bert-base-cased_adapter__seed4/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:23:37,562 >> tokenizer config file saved in ./result/restaurant_bert-base-cased_adapter__seed4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:23:37,564 >> Special tokens file saved in ./result/restaurant_bert-base-cased_adapter__seed4/special_tokens_map.json
{'eval_loss': 0.6015011668205261, 'eval_accuracy': 0.7661375661375661, 'eval_micro_f1': 0.7661375661375661, 'eval_macro_f1': 0.6836201587029672, 'eval_runtime': 1.7453, 'eval_samples_per_second': 541.444, 'eval_steps_per_second': 68.182, 'epoch': 5.0}
{'train_runtime': 76.2479, 'train_samples_per_second': 247.679, 'train_steps_per_second': 7.803, 'train_loss': 0.5328932754131926, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.5329
  train_runtime            = 0:01:16.24
  train_samples            =       3777
  train_samples_per_second =    247.679
  train_steps_per_second   =      7.803
11/15/2023 21:23:37 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:23:37,607 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:23:37,609 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:23:37,609 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:23:37,609 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  7%|▋         | 8/119 [00:00<00:01, 77.77it/s] 14%|█▍        | 17/119 [00:00<00:01, 78.23it/s] 21%|██        | 25/119 [00:00<00:01, 75.39it/s] 28%|██▊       | 33/119 [00:00<00:01, 74.74it/s] 34%|███▍      | 41/119 [00:00<00:01, 75.13it/s] 41%|████      | 49/119 [00:00<00:00, 74.42it/s] 48%|████▊     | 57/119 [00:00<00:00, 71.58it/s] 55%|█████▍    | 65/119 [00:00<00:00, 70.70it/s] 61%|██████▏   | 73/119 [00:01<00:00, 70.66it/s] 68%|██████▊   | 81/119 [00:01<00:00, 71.85it/s] 75%|███████▍  | 89/119 [00:01<00:00, 71.11it/s] 82%|████████▏ | 97/119 [00:01<00:00, 71.97it/s] 88%|████████▊ | 105/119 [00:01<00:00, 69.85it/s] 95%|█████████▍| 113/119 [00:01<00:00, 70.79it/s]100%|██████████| 119/119 [00:01<00:00, 70.80it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.7661
  eval_loss               =     0.6015
  eval_macro_f1           =     0.6836
  eval_micro_f1           =     0.7661
  eval_runtime            = 0:00:01.70
  eval_samples            =        945
  eval_samples_per_second =    554.559
  eval_steps_per_second   =     69.833
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▆▆▇██
wandb:                      eval/loss █▄▅▁▁▁
wandb:                  eval/macro_f1 ▁▅▆███
wandb:                  eval/micro_f1 ▁▆▆▇██
wandb:                   eval/runtime ▄▇█▂▄▁
wandb:        eval/samples_per_second ▅▂▁▇▅█
wandb:          eval/steps_per_second ▅▂▁▇▅█
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.76614
wandb:                      eval/loss 0.6015
wandb:                  eval/macro_f1 0.68362
wandb:                  eval/micro_f1 0.76614
wandb:                   eval/runtime 1.7041
wandb:        eval/samples_per_second 554.559
wandb:          eval/steps_per_second 69.833
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.3533
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.53289
wandb:            train/train_runtime 76.2479
wandb: train/train_samples_per_second 247.679
wandb:   train/train_steps_per_second 7.803
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_212133-k1rp8gpv
wandb: Find logs at: ./wandb/offline-run-20231115_212133-k1rp8gpv/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='restaurant', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4/runs/Nov15_21-23-49_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:23:49 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:23:49 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4/runs/Nov15_21-23-49_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/4722 [00:00<?, ? examples/s]Map:  84%|████████▍ | 3979/4722 [00:00<00:00, 39532.73 examples/s]Map: 100%|██████████| 4722/4722 [00:00<00:00, 38124.68 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 21:24:05,500 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:24:05,512 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 21:24:15,530 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 21:24:25,547 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:24:25,548 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:24:45,586 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:24:45,586 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:24:45,587 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:24:45,587 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:24:45,587 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 21:24:45,588 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:24:45,589 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 21:24:45,611 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:24:45,612 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:25:05,747 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 21:25:07,084 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:25:07,085 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/3777 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 21415.54 examples/s]Running tokenizer on dataset: 100%|██████████| 3777/3777 [00:00<00:00, 21138.86 examples/s]
Running tokenizer on dataset:   0%|          | 0/945 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 945/945 [00:00<00:00, 26202.62 examples/s]
11/15/2023 21:25:07 - INFO - __main__ - Sample 791 of the training set: {'text': 'plain pizza <SEP> The plain pizza was soggy and the creative wild mushroom(third generation-Fornini) pizza we had was drenched with truffle oil in the middle( again making it soggy) and nothingon the rest.', 'label': 2, 'input_ids': [102, 11456, 2628, 10207, 30110, 962, 9892, 1374, 111, 11456, 2628, 10207, 30110, 241, 24461, 15970, 137, 111, 7153, 3530, 26391, 9272, 145, 2765, 3014, 579, 168, 4564, 4564, 546, 2628, 10207, 30110, 185, 883, 241, 14124, 5297, 683, 190, 265, 4479, 143, 4981, 121, 111, 4413, 145, 1573, 3469, 256, 24461, 15970, 546, 137, 11392, 110, 111, 2619, 205, 103, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}.
11/15/2023 21:25:07 - INFO - __main__ - Sample 1124 of the training set: {'text': "lamb sausages <SEP> The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).", 'label': 0, 'input_ids': [102, 16282, 2204, 16907, 2150, 962, 9892, 1374, 111, 19272, 8232, 267, 3454, 422, 1248, 1553, 1134, 137, 5893, 263, 111, 16282, 2204, 16907, 2150, 422, 6460, 28934, 30113, 190, 5742, 8594, 800, 422, 1135, 2868, 27277, 147, 111, 15618, 140, 20793, 29036, 4481, 30112, 6282, 29905, 145, 111, 2172, 137, 5893, 327, 259, 2505, 1613, 1661, 883, 546, 205, 103, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}.
11/15/2023 21:25:07 - INFO - __main__ - Sample 659 of the training set: {'text': 'ingredients <SEP> Great value for the quality ingredients.', 'label': 0, 'input_ids': [102, 18617, 962, 9892, 1374, 2815, 973, 168, 111, 1671, 18617, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:25:07 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:25:08,719 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:25:08,726 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:25:08,726 >>   Num examples = 3,777
[INFO|trainer.py:1717] 2023-11-15 21:25:08,727 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:25:08,727 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:25:08,727 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:25:08,727 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:25:08,728 >>   Total optimization steps = 595
[INFO|trainer.py:1724] 2023-11-15 21:25:08,728 >>   Number of trainable parameters = 109,920,771
[INFO|integration_utils.py:716] 2023-11-15 21:25:08,729 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/595 [00:00<?, ?it/s]  0%|          | 1/595 [00:01<13:26,  1.36s/it]  0%|          | 2/595 [00:01<06:07,  1.61it/s]  1%|          | 3/595 [00:01<03:48,  2.59it/s]  1%|          | 4/595 [00:01<02:42,  3.64it/s]  1%|          | 5/595 [00:01<02:05,  4.70it/s]  1%|          | 6/595 [00:01<01:44,  5.65it/s]  1%|          | 7/595 [00:01<01:30,  6.48it/s]  1%|▏         | 8/595 [00:02<01:21,  7.21it/s]  2%|▏         | 9/595 [00:02<01:15,  7.80it/s]  2%|▏         | 10/595 [00:02<01:11,  8.18it/s]  2%|▏         | 11/595 [00:02<01:09,  8.44it/s]  2%|▏         | 12/595 [00:02<01:06,  8.77it/s]  2%|▏         | 13/595 [00:02<01:04,  9.03it/s]  2%|▏         | 14/595 [00:02<01:03,  9.10it/s]  3%|▎         | 15/595 [00:02<01:03,  9.19it/s]  3%|▎         | 16/595 [00:02<01:02,  9.32it/s]  3%|▎         | 17/595 [00:03<01:01,  9.40it/s]  3%|▎         | 18/595 [00:03<01:01,  9.42it/s]  3%|▎         | 19/595 [00:03<01:01,  9.36it/s]  3%|▎         | 20/595 [00:03<01:00,  9.44it/s]  4%|▎         | 21/595 [00:03<01:00,  9.47it/s]  4%|▎         | 22/595 [00:03<01:00,  9.51it/s]  4%|▍         | 23/595 [00:03<01:00,  9.42it/s]  4%|▍         | 24/595 [00:03<01:00,  9.39it/s]  4%|▍         | 25/595 [00:03<01:01,  9.34it/s]  4%|▍         | 26/595 [00:04<01:00,  9.39it/s]  5%|▍         | 27/595 [00:04<01:00,  9.39it/s]  5%|▍         | 28/595 [00:04<01:00,  9.42it/s]  5%|▍         | 29/595 [00:04<01:00,  9.41it/s]  5%|▌         | 30/595 [00:04<00:59,  9.45it/s]  5%|▌         | 31/595 [00:04<00:58,  9.58it/s]  5%|▌         | 32/595 [00:04<00:59,  9.45it/s]  6%|▌         | 33/595 [00:04<00:59,  9.47it/s]  6%|▌         | 34/595 [00:04<00:59,  9.47it/s]  6%|▌         | 35/595 [00:04<00:59,  9.49it/s]  6%|▌         | 36/595 [00:05<00:59,  9.44it/s]  6%|▌         | 37/595 [00:05<00:59,  9.37it/s]  6%|▋         | 38/595 [00:05<00:59,  9.36it/s]  7%|▋         | 39/595 [00:05<00:59,  9.42it/s]  7%|▋         | 40/595 [00:05<00:59,  9.38it/s]  7%|▋         | 41/595 [00:05<00:58,  9.45it/s]  7%|▋         | 42/595 [00:05<00:58,  9.40it/s]  7%|▋         | 43/595 [00:05<00:58,  9.50it/s]  7%|▋         | 44/595 [00:05<00:57,  9.59it/s]  8%|▊         | 45/595 [00:06<00:58,  9.48it/s]  8%|▊         | 46/595 [00:06<00:58,  9.44it/s]  8%|▊         | 47/595 [00:06<00:57,  9.47it/s]  8%|▊         | 48/595 [00:06<00:57,  9.49it/s]  8%|▊         | 49/595 [00:06<00:58,  9.33it/s]  8%|▊         | 50/595 [00:06<00:58,  9.31it/s]  9%|▊         | 51/595 [00:06<00:58,  9.33it/s]  9%|▊         | 52/595 [00:06<00:57,  9.38it/s]  9%|▉         | 53/595 [00:06<00:58,  9.34it/s]  9%|▉         | 54/595 [00:06<00:57,  9.34it/s]  9%|▉         | 55/595 [00:07<00:57,  9.34it/s]  9%|▉         | 56/595 [00:07<00:57,  9.41it/s] 10%|▉         | 57/595 [00:07<00:56,  9.46it/s] 10%|▉         | 58/595 [00:07<00:57,  9.39it/s] 10%|▉         | 59/595 [00:07<00:56,  9.48it/s] 10%|█         | 60/595 [00:07<00:56,  9.52it/s] 10%|█         | 61/595 [00:07<00:56,  9.44it/s] 10%|█         | 62/595 [00:07<00:56,  9.41it/s] 11%|█         | 63/595 [00:07<00:56,  9.37it/s] 11%|█         | 64/595 [00:08<00:56,  9.44it/s] 11%|█         | 65/595 [00:08<00:56,  9.35it/s] 11%|█         | 66/595 [00:08<00:56,  9.36it/s] 11%|█▏        | 67/595 [00:08<00:56,  9.35it/s] 11%|█▏        | 68/595 [00:08<00:55,  9.44it/s] 12%|█▏        | 69/595 [00:08<00:55,  9.41it/s] 12%|█▏        | 70/595 [00:08<00:55,  9.42it/s] 12%|█▏        | 71/595 [00:08<00:55,  9.43it/s] 12%|█▏        | 72/595 [00:08<00:54,  9.51it/s] 12%|█▏        | 73/595 [00:08<00:54,  9.57it/s] 12%|█▏        | 74/595 [00:09<00:55,  9.46it/s] 13%|█▎        | 75/595 [00:09<00:54,  9.49it/s] 13%|█▎        | 76/595 [00:09<00:54,  9.58it/s] 13%|█▎        | 77/595 [00:09<00:54,  9.58it/s] 13%|█▎        | 78/595 [00:09<00:54,  9.46it/s] 13%|█▎        | 79/595 [00:09<00:55,  9.37it/s] 13%|█▎        | 80/595 [00:09<00:54,  9.41it/s] 14%|█▎        | 81/595 [00:09<00:54,  9.40it/s] 14%|█▍        | 82/595 [00:09<00:54,  9.36it/s] 14%|█▍        | 83/595 [00:10<00:54,  9.35it/s] 14%|█▍        | 84/595 [00:10<00:54,  9.39it/s] 14%|█▍        | 85/595 [00:10<00:53,  9.47it/s] 14%|█▍        | 86/595 [00:10<00:53,  9.52it/s] 15%|█▍        | 87/595 [00:10<00:54,  9.37it/s] 15%|█▍        | 88/595 [00:10<00:53,  9.46it/s] 15%|█▍        | 89/595 [00:10<00:52,  9.56it/s] 15%|█▌        | 90/595 [00:10<00:53,  9.51it/s] 15%|█▌        | 91/595 [00:10<00:53,  9.46it/s] 15%|█▌        | 92/595 [00:10<00:52,  9.52it/s] 16%|█▌        | 93/595 [00:11<00:52,  9.58it/s] 16%|█▌        | 94/595 [00:11<00:52,  9.49it/s] 16%|█▌        | 95/595 [00:11<00:52,  9.46it/s] 16%|█▌        | 96/595 [00:11<00:52,  9.53it/s] 16%|█▋        | 97/595 [00:11<00:52,  9.56it/s] 16%|█▋        | 98/595 [00:11<00:52,  9.49it/s] 17%|█▋        | 99/595 [00:11<00:52,  9.49it/s] 17%|█▋        | 100/595 [00:11<00:51,  9.53it/s] 17%|█▋        | 101/595 [00:11<00:51,  9.56it/s] 17%|█▋        | 102/595 [00:12<00:50,  9.68it/s] 17%|█▋        | 103/595 [00:12<00:50,  9.65it/s] 17%|█▋        | 104/595 [00:12<00:51,  9.56it/s] 18%|█▊        | 105/595 [00:12<00:50,  9.64it/s] 18%|█▊        | 106/595 [00:12<00:50,  9.66it/s] 18%|█▊        | 107/595 [00:12<00:50,  9.64it/s] 18%|█▊        | 108/595 [00:12<00:51,  9.52it/s] 18%|█▊        | 109/595 [00:12<00:51,  9.53it/s] 18%|█▊        | 110/595 [00:12<00:50,  9.55it/s] 19%|█▊        | 111/595 [00:12<00:50,  9.53it/s] 19%|█▉        | 112/595 [00:13<00:50,  9.51it/s] 19%|█▉        | 113/595 [00:13<00:50,  9.47it/s] 19%|█▉        | 114/595 [00:13<00:50,  9.54it/s] 19%|█▉        | 115/595 [00:13<00:49,  9.65it/s] 19%|█▉        | 116/595 [00:13<00:50,  9.55it/s] 20%|█▉        | 117/595 [00:13<00:50,  9.53it/s] 20%|█▉        | 118/595 [00:13<00:49,  9.62it/s]                                                  20%|██        | 119/595 [00:13<00:49,  9.62it/s][INFO|trainer.py:755] 2023-11-15 21:25:22,501 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:25:22,502 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:25:22,503 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:25:22,503 >>   Batch size = 8
{'loss': 0.7399, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 10/119 [00:00<00:01, 90.30it/s][A
 17%|█▋        | 20/119 [00:00<00:01, 77.63it/s][A
 24%|██▍       | 29/119 [00:00<00:01, 79.47it/s][A
 32%|███▏      | 38/119 [00:00<00:01, 75.68it/s][A
 39%|███▊      | 46/119 [00:00<00:00, 75.08it/s][A
 46%|████▌     | 55/119 [00:00<00:00, 77.14it/s][A
 53%|█████▎    | 63/119 [00:00<00:00, 74.83it/s][A
 60%|█████▉    | 71/119 [00:00<00:00, 74.65it/s][A
 66%|██████▋   | 79/119 [00:01<00:00, 75.50it/s][A
 73%|███████▎  | 87/119 [00:01<00:00, 75.73it/s][A
 80%|███████▉  | 95/119 [00:01<00:00, 74.87it/s][A
 87%|████████▋ | 103/119 [00:01<00:00, 74.63it/s][A
 93%|█████████▎| 111/119 [00:01<00:00, 74.99it/s][A
100%|██████████| 119/119 [00:01<00:00, 75.86it/s][A                                                 
                                                 [A 20%|██        | 119/595 [00:15<00:49,  9.62it/s]
100%|██████████| 119/119 [00:01<00:00, 75.86it/s][A
                                                 [A 20%|██        | 120/595 [00:15<03:41,  2.15it/s] 20%|██        | 121/595 [00:15<02:58,  2.65it/s] 21%|██        | 122/595 [00:15<02:24,  3.27it/s] 21%|██        | 123/595 [00:15<01:58,  3.99it/s] 21%|██        | 124/595 [00:15<01:39,  4.74it/s] 21%|██        | 125/595 [00:16<01:25,  5.51it/s] 21%|██        | 126/595 [00:16<01:14,  6.29it/s] 21%|██▏       | 127/595 [00:16<01:06,  6.99it/s] 22%|██▏       | 128/595 [00:16<01:02,  7.50it/s] 22%|██▏       | 129/595 [00:16<00:58,  7.98it/s] 22%|██▏       | 130/595 [00:16<00:55,  8.31it/s] 22%|██▏       | 131/595 [00:16<00:53,  8.67it/s] 22%|██▏       | 132/595 [00:16<00:52,  8.88it/s] 22%|██▏       | 133/595 [00:16<00:51,  9.05it/s] 23%|██▎       | 134/595 [00:16<00:50,  9.12it/s] 23%|██▎       | 135/595 [00:17<00:49,  9.28it/s] 23%|██▎       | 136/595 [00:17<00:48,  9.41it/s] 23%|██▎       | 137/595 [00:17<00:48,  9.39it/s] 23%|██▎       | 138/595 [00:17<00:48,  9.41it/s] 23%|██▎       | 139/595 [00:17<00:48,  9.40it/s] 24%|██▎       | 140/595 [00:17<00:47,  9.49it/s] 24%|██▎       | 141/595 [00:17<00:48,  9.42it/s] 24%|██▍       | 142/595 [00:17<00:48,  9.43it/s] 24%|██▍       | 143/595 [00:17<00:48,  9.38it/s] 24%|██▍       | 144/595 [00:18<00:47,  9.45it/s] 24%|██▍       | 145/595 [00:18<00:47,  9.42it/s] 25%|██▍       | 146/595 [00:18<00:47,  9.46it/s] 25%|██▍       | 147/595 [00:18<00:47,  9.42it/s] 25%|██▍       | 148/595 [00:18<00:47,  9.42it/s] 25%|██▌       | 149/595 [00:18<00:47,  9.46it/s] 25%|██▌       | 150/595 [00:18<00:47,  9.39it/s] 25%|██▌       | 151/595 [00:18<00:47,  9.36it/s] 26%|██▌       | 152/595 [00:18<00:46,  9.45it/s] 26%|██▌       | 153/595 [00:18<00:46,  9.42it/s] 26%|██▌       | 154/595 [00:19<00:47,  9.37it/s] 26%|██▌       | 155/595 [00:19<00:47,  9.31it/s] 26%|██▌       | 156/595 [00:19<00:46,  9.43it/s] 26%|██▋       | 157/595 [00:19<00:46,  9.42it/s] 27%|██▋       | 158/595 [00:19<00:46,  9.38it/s] 27%|██▋       | 159/595 [00:19<00:46,  9.37it/s] 27%|██▋       | 160/595 [00:19<00:46,  9.43it/s] 27%|██▋       | 161/595 [00:19<00:45,  9.46it/s] 27%|██▋       | 162/595 [00:19<00:45,  9.47it/s] 27%|██▋       | 163/595 [00:20<00:46,  9.39it/s] 28%|██▊       | 164/595 [00:20<00:45,  9.44it/s] 28%|██▊       | 165/595 [00:20<00:44,  9.57it/s] 28%|██▊       | 166/595 [00:20<00:45,  9.47it/s] 28%|██▊       | 167/595 [00:20<00:45,  9.38it/s] 28%|██▊       | 168/595 [00:20<00:45,  9.47it/s] 28%|██▊       | 169/595 [00:20<00:44,  9.51it/s] 29%|██▊       | 170/595 [00:20<00:44,  9.46it/s] 29%|██▊       | 171/595 [00:20<00:44,  9.43it/s] 29%|██▉       | 172/595 [00:21<00:44,  9.44it/s] 29%|██▉       | 173/595 [00:21<00:44,  9.47it/s] 29%|██▉       | 174/595 [00:21<00:44,  9.46it/s] 29%|██▉       | 175/595 [00:21<00:44,  9.50it/s] 30%|██▉       | 176/595 [00:21<00:44,  9.45it/s] 30%|██▉       | 177/595 [00:21<00:43,  9.52it/s] 30%|██▉       | 178/595 [00:21<00:43,  9.59it/s] 30%|███       | 179/595 [00:21<00:43,  9.50it/s] 30%|███       | 180/595 [00:21<00:44,  9.41it/s] 30%|███       | 181/595 [00:21<00:43,  9.50it/s] 31%|███       | 182/595 [00:22<00:43,  9.47it/s] 31%|███       | 183/595 [00:22<00:44,  9.35it/s] 31%|███       | 184/595 [00:22<00:43,  9.37it/s] 31%|███       | 185/595 [00:22<00:43,  9.48it/s] 31%|███▏      | 186/595 [00:22<00:43,  9.36it/s] 31%|███▏      | 187/595 [00:22<00:43,  9.41it/s] 32%|███▏      | 188/595 [00:22<00:43,  9.43it/s] 32%|███▏      | 189/595 [00:22<00:42,  9.47it/s] 32%|███▏      | 190/595 [00:22<00:43,  9.42it/s] 32%|███▏      | 191/595 [00:23<00:42,  9.47it/s] 32%|███▏      | 192/595 [00:23<00:42,  9.43it/s] 32%|███▏      | 193/595 [00:23<00:42,  9.43it/s] 33%|███▎      | 194/595 [00:23<00:42,  9.49it/s] 33%|███▎      | 195/595 [00:23<00:42,  9.40it/s] 33%|███▎      | 196/595 [00:23<00:42,  9.40it/s] 33%|███▎      | 197/595 [00:23<00:41,  9.48it/s] 33%|███▎      | 198/595 [00:23<00:41,  9.45it/s] 33%|███▎      | 199/595 [00:23<00:42,  9.43it/s] 34%|███▎      | 200/595 [00:23<00:42,  9.35it/s] 34%|███▍      | 201/595 [00:24<00:41,  9.42it/s] 34%|███▍      | 202/595 [00:24<00:41,  9.42it/s] 34%|███▍      | 203/595 [00:24<00:41,  9.39it/s] 34%|███▍      | 204/595 [00:24<00:41,  9.40it/s] 34%|███▍      | 205/595 [00:24<00:40,  9.51it/s] 35%|███▍      | 206/595 [00:24<00:41,  9.36it/s] 35%|███▍      | 207/595 [00:24<00:41,  9.41it/s] 35%|███▍      | 208/595 [00:24<00:41,  9.40it/s] 35%|███▌      | 209/595 [00:24<00:40,  9.44it/s] 35%|███▌      | 210/595 [00:25<00:40,  9.49it/s] 35%|███▌      | 211/595 [00:25<00:40,  9.43it/s] 36%|███▌      | 212/595 [00:25<00:40,  9.43it/s] 36%|███▌      | 213/595 [00:25<00:40,  9.51it/s] 36%|███▌      | 214/595 [00:25<00:39,  9.53it/s] 36%|███▌      | 215/595 [00:25<00:40,  9.43it/s] 36%|███▋      | 216/595 [00:25<00:40,  9.45it/s] 36%|███▋      | 217/595 [00:25<00:39,  9.52it/s] 37%|███▋      | 218/595 [00:25<00:39,  9.45it/s] 37%|███▋      | 219/595 [00:25<00:39,  9.46it/s] 37%|███▋      | 220/595 [00:26<00:39,  9.40it/s] 37%|███▋      | 221/595 [00:26<00:39,  9.44it/s] 37%|███▋      | 222/595 [00:26<00:39,  9.44it/s] 37%|███▋      | 223/595 [00:26<00:39,  9.47it/s] 38%|███▊      | 224/595 [00:26<00:39,  9.43it/s] 38%|███▊      | 225/595 [00:26<00:38,  9.49it/s] 38%|███▊      | 226/595 [00:26<00:38,  9.52it/s] 38%|███▊      | 227/595 [00:26<00:39,  9.40it/s] 38%|███▊      | 228/595 [00:26<00:38,  9.47it/s] 38%|███▊      | 229/595 [00:27<00:38,  9.55it/s] 39%|███▊      | 230/595 [00:27<00:38,  9.52it/s] 39%|███▉      | 231/595 [00:27<00:38,  9.48it/s] 39%|███▉      | 232/595 [00:27<00:38,  9.42it/s] 39%|███▉      | 233/595 [00:27<00:38,  9.52it/s] 39%|███▉      | 234/595 [00:27<00:37,  9.57it/s] 39%|███▉      | 235/595 [00:27<00:38,  9.45it/s] 40%|███▉      | 236/595 [00:27<00:38,  9.43it/s] 40%|███▉      | 237/595 [00:27<00:37,  9.57it/s]                                                  40%|████      | 238/595 [00:27<00:37,  9.57it/s][INFO|trainer.py:755] 2023-11-15 21:25:36,652 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:25:36,654 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:25:36,654 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:25:36,655 >>   Batch size = 8
{'eval_loss': 0.5787397623062134, 'eval_accuracy': 0.7534391534391535, 'eval_micro_f1': 0.7534391534391535, 'eval_macro_f1': 0.6714368472671591, 'eval_runtime': 1.6158, 'eval_samples_per_second': 584.84, 'eval_steps_per_second': 73.647, 'epoch': 1.0}
{'loss': 0.4749, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 10/119 [00:00<00:01, 93.76it/s][A
 17%|█▋        | 20/119 [00:00<00:01, 80.03it/s][A
 24%|██▍       | 29/119 [00:00<00:01, 80.27it/s][A
 32%|███▏      | 38/119 [00:00<00:01, 79.85it/s][A
 39%|███▉      | 47/119 [00:00<00:00, 77.17it/s][A
 46%|████▌     | 55/119 [00:00<00:00, 77.36it/s][A
 54%|█████▍    | 64/119 [00:00<00:00, 79.21it/s][A
 61%|██████    | 72/119 [00:00<00:00, 76.33it/s][A
 67%|██████▋   | 80/119 [00:01<00:00, 76.05it/s][A
 75%|███████▍  | 89/119 [00:01<00:00, 78.34it/s][A
 82%|████████▏ | 97/119 [00:01<00:00, 78.41it/s][A
 88%|████████▊ | 105/119 [00:01<00:00, 75.71it/s][A
 95%|█████████▍| 113/119 [00:01<00:00, 75.58it/s][A                                                 
                                                 [A 40%|████      | 238/595 [00:29<00:37,  9.57it/s]
100%|██████████| 119/119 [00:01<00:00, 75.58it/s][A
                                                 [A 40%|████      | 239/595 [00:29<02:41,  2.21it/s] 40%|████      | 240/595 [00:29<02:10,  2.73it/s] 41%|████      | 241/595 [00:29<01:45,  3.35it/s] 41%|████      | 242/595 [00:29<01:27,  4.05it/s] 41%|████      | 243/595 [00:30<01:12,  4.83it/s] 41%|████      | 244/595 [00:30<01:02,  5.65it/s] 41%|████      | 245/595 [00:30<00:54,  6.36it/s] 41%|████▏     | 246/595 [00:30<00:49,  7.01it/s] 42%|████▏     | 247/595 [00:30<00:45,  7.61it/s] 42%|████▏     | 248/595 [00:30<00:42,  8.10it/s] 42%|████▏     | 249/595 [00:30<00:41,  8.37it/s] 42%|████▏     | 250/595 [00:30<00:40,  8.62it/s] 42%|████▏     | 251/595 [00:30<00:38,  8.86it/s] 42%|████▏     | 252/595 [00:30<00:37,  9.06it/s] 43%|████▎     | 253/595 [00:31<00:37,  9.07it/s] 43%|████▎     | 254/595 [00:31<00:37,  9.18it/s] 43%|████▎     | 255/595 [00:31<00:36,  9.27it/s] 43%|████▎     | 256/595 [00:31<00:36,  9.38it/s] 43%|████▎     | 257/595 [00:31<00:35,  9.40it/s] 43%|████▎     | 258/595 [00:31<00:36,  9.32it/s] 44%|████▎     | 259/595 [00:31<00:35,  9.35it/s] 44%|████▎     | 260/595 [00:31<00:35,  9.44it/s] 44%|████▍     | 261/595 [00:31<00:35,  9.36it/s] 44%|████▍     | 262/595 [00:32<00:35,  9.32it/s] 44%|████▍     | 263/595 [00:32<00:35,  9.34it/s] 44%|████▍     | 264/595 [00:32<00:35,  9.43it/s] 45%|████▍     | 265/595 [00:32<00:34,  9.45it/s] 45%|████▍     | 266/595 [00:32<00:34,  9.41it/s] 45%|████▍     | 267/595 [00:32<00:34,  9.41it/s] 45%|████▌     | 268/595 [00:32<00:34,  9.48it/s] 45%|████▌     | 269/595 [00:32<00:34,  9.44it/s] 45%|████▌     | 270/595 [00:32<00:34,  9.44it/s] 46%|████▌     | 271/595 [00:32<00:34,  9.44it/s] 46%|████▌     | 272/595 [00:33<00:34,  9.49it/s] 46%|████▌     | 273/595 [00:33<00:34,  9.44it/s] 46%|████▌     | 274/595 [00:33<00:34,  9.40it/s] 46%|████▌     | 275/595 [00:33<00:34,  9.38it/s] 46%|████▋     | 276/595 [00:33<00:33,  9.49it/s] 47%|████▋     | 277/595 [00:33<00:33,  9.50it/s] 47%|████▋     | 278/595 [00:33<00:33,  9.45it/s] 47%|████▋     | 279/595 [00:33<00:33,  9.40it/s] 47%|████▋     | 280/595 [00:33<00:33,  9.46it/s] 47%|████▋     | 281/595 [00:34<00:33,  9.38it/s] 47%|████▋     | 282/595 [00:34<00:33,  9.35it/s] 48%|████▊     | 283/595 [00:34<00:33,  9.35it/s] 48%|████▊     | 284/595 [00:34<00:32,  9.44it/s] 48%|████▊     | 285/595 [00:34<00:32,  9.41it/s] 48%|████▊     | 286/595 [00:34<00:32,  9.48it/s] 48%|████▊     | 287/595 [00:34<00:32,  9.42it/s] 48%|████▊     | 288/595 [00:34<00:32,  9.50it/s] 49%|████▊     | 289/595 [00:34<00:31,  9.63it/s] 49%|████▊     | 290/595 [00:35<00:31,  9.54it/s] 49%|████▉     | 291/595 [00:35<00:31,  9.51it/s] 49%|████▉     | 292/595 [00:35<00:31,  9.57it/s] 49%|████▉     | 293/595 [00:35<00:31,  9.54it/s] 49%|████▉     | 294/595 [00:35<00:31,  9.44it/s] 50%|████▉     | 295/595 [00:35<00:31,  9.40it/s] 50%|████▉     | 296/595 [00:35<00:31,  9.46it/s] 50%|████▉     | 297/595 [00:35<00:31,  9.45it/s] 50%|█████     | 298/595 [00:35<00:31,  9.38it/s] 50%|█████     | 299/595 [00:35<00:31,  9.39it/s] 50%|█████     | 300/595 [00:36<00:31,  9.45it/s] 51%|█████     | 301/595 [00:36<00:31,  9.42it/s] 51%|█████     | 302/595 [00:36<00:30,  9.53it/s] 51%|█████     | 303/595 [00:36<00:30,  9.46it/s] 51%|█████     | 304/595 [00:36<00:30,  9.54it/s] 51%|█████▏    | 305/595 [00:36<00:30,  9.62it/s] 51%|█████▏    | 306/595 [00:36<00:30,  9.48it/s] 52%|█████▏    | 307/595 [00:36<00:30,  9.41it/s] 52%|█████▏    | 308/595 [00:36<00:30,  9.41it/s] 52%|█████▏    | 309/595 [00:37<00:30,  9.36it/s] 52%|█████▏    | 310/595 [00:37<00:30,  9.42it/s] 52%|█████▏    | 311/595 [00:37<00:30,  9.40it/s] 52%|█████▏    | 312/595 [00:37<00:29,  9.44it/s] 53%|█████▎    | 313/595 [00:37<00:29,  9.49it/s] 53%|█████▎    | 314/595 [00:37<00:29,  9.38it/s] 53%|█████▎    | 315/595 [00:37<00:29,  9.38it/s] 53%|█████▎    | 316/595 [00:37<00:29,  9.43it/s] 53%|█████▎    | 317/595 [00:37<00:29,  9.43it/s] 53%|█████▎    | 318/595 [00:37<00:29,  9.45it/s] 54%|█████▎    | 319/595 [00:38<00:29,  9.35it/s] 54%|█████▍    | 320/595 [00:38<00:29,  9.43it/s] 54%|█████▍    | 321/595 [00:38<00:28,  9.50it/s] 54%|█████▍    | 322/595 [00:38<00:28,  9.48it/s] 54%|█████▍    | 323/595 [00:38<00:28,  9.44it/s] 54%|█████▍    | 324/595 [00:38<00:28,  9.41it/s] 55%|█████▍    | 325/595 [00:38<00:28,  9.45it/s] 55%|█████▍    | 326/595 [00:38<00:28,  9.36it/s] 55%|█████▍    | 327/595 [00:38<00:28,  9.32it/s] 55%|█████▌    | 328/595 [00:39<00:28,  9.41it/s] 55%|█████▌    | 329/595 [00:39<00:28,  9.37it/s] 55%|█████▌    | 330/595 [00:39<00:28,  9.36it/s] 56%|█████▌    | 331/595 [00:39<00:28,  9.39it/s] 56%|█████▌    | 332/595 [00:39<00:27,  9.43it/s] 56%|█████▌    | 333/595 [00:39<00:28,  9.35it/s] 56%|█████▌    | 334/595 [00:39<00:27,  9.38it/s] 56%|█████▋    | 335/595 [00:39<00:27,  9.37it/s] 56%|█████▋    | 336/595 [00:39<00:27,  9.45it/s] 57%|█████▋    | 337/595 [00:39<00:27,  9.51it/s] 57%|█████▋    | 338/595 [00:40<00:27,  9.43it/s] 57%|█████▋    | 339/595 [00:40<00:27,  9.40it/s] 57%|█████▋    | 340/595 [00:40<00:26,  9.47it/s] 57%|█████▋    | 341/595 [00:40<00:27,  9.40it/s] 57%|█████▋    | 342/595 [00:40<00:26,  9.39it/s] 58%|█████▊    | 343/595 [00:40<00:26,  9.34it/s] 58%|█████▊    | 344/595 [00:40<00:26,  9.41it/s] 58%|█████▊    | 345/595 [00:40<00:26,  9.44it/s] 58%|█████▊    | 346/595 [00:40<00:26,  9.36it/s] 58%|█████▊    | 347/595 [00:41<00:26,  9.39it/s] 58%|█████▊    | 348/595 [00:41<00:26,  9.45it/s] 59%|█████▊    | 349/595 [00:41<00:26,  9.40it/s] 59%|█████▉    | 350/595 [00:41<00:25,  9.45it/s] 59%|█████▉    | 351/595 [00:41<00:25,  9.41it/s] 59%|█████▉    | 352/595 [00:41<00:25,  9.43it/s] 59%|█████▉    | 353/595 [00:41<00:25,  9.59it/s] 59%|█████▉    | 354/595 [00:41<00:25,  9.52it/s] 60%|█████▉    | 355/595 [00:41<00:25,  9.40it/s] 60%|█████▉    | 356/595 [00:41<00:25,  9.51it/s]                                                  60%|██████    | 357/595 [00:42<00:25,  9.51it/s][INFO|trainer.py:755] 2023-11-15 21:25:50,775 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:25:50,776 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:25:50,777 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:25:50,777 >>   Batch size = 8
{'eval_loss': 0.49111077189445496, 'eval_accuracy': 0.8074074074074075, 'eval_micro_f1': 0.8074074074074074, 'eval_macro_f1': 0.7347340231106037, 'eval_runtime': 1.5719, 'eval_samples_per_second': 601.168, 'eval_steps_per_second': 75.703, 'epoch': 2.0}
{'loss': 0.3153, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 86.44it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 78.80it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 78.43it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 75.29it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 76.54it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 77.13it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 74.27it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 73.63it/s][A
 63%|██████▎   | 75/119 [00:00<00:00, 76.44it/s][A
 70%|██████▉   | 83/119 [00:01<00:00, 74.40it/s][A
 76%|███████▋  | 91/119 [00:01<00:00, 73.88it/s][A
 83%|████████▎ | 99/119 [00:01<00:00, 74.71it/s][A
 90%|████████▉ | 107/119 [00:01<00:00, 75.34it/s][A
 97%|█████████▋| 115/119 [00:01<00:00, 73.83it/s][A                                                 
                                                 [A 60%|██████    | 357/595 [00:43<00:25,  9.51it/s]
100%|██████████| 119/119 [00:01<00:00, 73.83it/s][A
                                                 [A 60%|██████    | 358/595 [00:43<01:50,  2.15it/s] 60%|██████    | 359/595 [00:43<01:28,  2.66it/s] 61%|██████    | 360/595 [00:43<01:11,  3.27it/s] 61%|██████    | 361/595 [00:44<00:58,  3.99it/s] 61%|██████    | 362/595 [00:44<00:49,  4.74it/s] 61%|██████    | 363/595 [00:44<00:42,  5.50it/s] 61%|██████    | 364/595 [00:44<00:36,  6.27it/s] 61%|██████▏   | 365/595 [00:44<00:32,  6.97it/s] 62%|██████▏   | 366/595 [00:44<00:30,  7.50it/s] 62%|██████▏   | 367/595 [00:44<00:28,  7.96it/s] 62%|██████▏   | 368/595 [00:44<00:27,  8.34it/s] 62%|██████▏   | 369/595 [00:44<00:26,  8.64it/s] 62%|██████▏   | 370/595 [00:45<00:25,  8.82it/s] 62%|██████▏   | 371/595 [00:45<00:24,  9.03it/s] 63%|██████▎   | 372/595 [00:45<00:24,  9.11it/s] 63%|██████▎   | 373/595 [00:45<00:24,  9.24it/s] 63%|██████▎   | 374/595 [00:45<00:23,  9.31it/s] 63%|██████▎   | 375/595 [00:45<00:23,  9.25it/s] 63%|██████▎   | 376/595 [00:45<00:23,  9.27it/s] 63%|██████▎   | 377/595 [00:45<00:23,  9.41it/s] 64%|██████▎   | 378/595 [00:45<00:23,  9.36it/s] 64%|██████▎   | 379/595 [00:46<00:23,  9.36it/s] 64%|██████▍   | 380/595 [00:46<00:22,  9.37it/s] 64%|██████▍   | 381/595 [00:46<00:22,  9.46it/s] 64%|██████▍   | 382/595 [00:46<00:22,  9.44it/s] 64%|██████▍   | 383/595 [00:46<00:22,  9.40it/s] 65%|██████▍   | 384/595 [00:46<00:22,  9.38it/s] 65%|██████▍   | 385/595 [00:46<00:22,  9.44it/s] 65%|██████▍   | 386/595 [00:46<00:22,  9.38it/s] 65%|██████▌   | 387/595 [00:46<00:21,  9.46it/s] 65%|██████▌   | 388/595 [00:46<00:22,  9.40it/s] 65%|██████▌   | 389/595 [00:47<00:21,  9.41it/s] 66%|██████▌   | 390/595 [00:47<00:21,  9.47it/s] 66%|██████▌   | 391/595 [00:47<00:21,  9.40it/s] 66%|██████▌   | 392/595 [00:47<00:21,  9.42it/s] 66%|██████▌   | 393/595 [00:47<00:21,  9.52it/s] 66%|██████▌   | 394/595 [00:47<00:21,  9.56it/s] 66%|██████▋   | 395/595 [00:47<00:21,  9.42it/s] 67%|██████▋   | 396/595 [00:47<00:21,  9.45it/s] 67%|██████▋   | 397/595 [00:47<00:20,  9.51it/s] 67%|██████▋   | 398/595 [00:48<00:20,  9.47it/s] 67%|██████▋   | 399/595 [00:48<00:20,  9.42it/s] 67%|██████▋   | 400/595 [00:48<00:20,  9.42it/s] 67%|██████▋   | 401/595 [00:48<00:20,  9.42it/s] 68%|██████▊   | 402/595 [00:48<00:20,  9.44it/s] 68%|██████▊   | 403/595 [00:48<00:20,  9.50it/s] 68%|██████▊   | 404/595 [00:48<00:20,  9.46it/s] 68%|██████▊   | 405/595 [00:48<00:20,  9.48it/s] 68%|██████▊   | 406/595 [00:48<00:19,  9.52it/s] 68%|██████▊   | 407/595 [00:48<00:20,  9.40it/s] 69%|██████▊   | 408/595 [00:49<00:20,  9.32it/s] 69%|██████▊   | 409/595 [00:49<00:19,  9.44it/s] 69%|██████▉   | 410/595 [00:49<00:19,  9.50it/s] 69%|██████▉   | 411/595 [00:49<00:19,  9.42it/s] 69%|██████▉   | 412/595 [00:49<00:19,  9.33it/s] 69%|██████▉   | 413/595 [00:49<00:19,  9.42it/s] 70%|██████▉   | 414/595 [00:49<00:19,  9.44it/s] 70%|██████▉   | 415/595 [00:49<00:19,  9.37it/s] 70%|██████▉   | 416/595 [00:49<00:19,  9.37it/s] 70%|███████   | 417/595 [00:50<00:18,  9.39it/s] 70%|███████   | 418/595 [00:50<00:18,  9.38it/s] 70%|███████   | 419/595 [00:50<00:18,  9.41it/s] 71%|███████   | 420/595 [00:50<00:18,  9.31it/s] 71%|███████   | 421/595 [00:50<00:18,  9.32it/s] 71%|███████   | 422/595 [00:50<00:18,  9.41it/s] 71%|███████   | 423/595 [00:50<00:18,  9.34it/s] 71%|███████▏  | 424/595 [00:50<00:18,  9.29it/s] 71%|███████▏  | 425/595 [00:50<00:18,  9.39it/s] 72%|███████▏  | 426/595 [00:50<00:18,  9.37it/s] 72%|███████▏  | 427/595 [00:51<00:18,  9.32it/s] 72%|███████▏  | 428/595 [00:51<00:17,  9.30it/s] 72%|███████▏  | 429/595 [00:51<00:17,  9.32it/s] 72%|███████▏  | 430/595 [00:51<00:17,  9.28it/s] 72%|███████▏  | 431/595 [00:51<00:17,  9.25it/s] 73%|███████▎  | 432/595 [00:51<00:17,  9.26it/s] 73%|███████▎  | 433/595 [00:51<00:17,  9.38it/s] 73%|███████▎  | 434/595 [00:51<00:17,  9.31it/s] 73%|███████▎  | 435/595 [00:51<00:17,  9.31it/s] 73%|███████▎  | 436/595 [00:52<00:16,  9.35it/s] 73%|███████▎  | 437/595 [00:52<00:16,  9.43it/s] 74%|███████▎  | 438/595 [00:52<00:16,  9.40it/s] 74%|███████▍  | 439/595 [00:52<00:16,  9.34it/s] 74%|███████▍  | 440/595 [00:52<00:16,  9.31it/s] 74%|███████▍  | 441/595 [00:52<00:16,  9.42it/s] 74%|███████▍  | 442/595 [00:52<00:16,  9.40it/s] 74%|███████▍  | 443/595 [00:52<00:16,  9.33it/s] 75%|███████▍  | 444/595 [00:52<00:16,  9.39it/s] 75%|███████▍  | 445/595 [00:53<00:15,  9.47it/s] 75%|███████▍  | 446/595 [00:53<00:15,  9.44it/s] 75%|███████▌  | 447/595 [00:53<00:15,  9.39it/s] 75%|███████▌  | 448/595 [00:53<00:15,  9.36it/s] 75%|███████▌  | 449/595 [00:53<00:15,  9.35it/s] 76%|███████▌  | 450/595 [00:53<00:15,  9.37it/s] 76%|███████▌  | 451/595 [00:53<00:15,  9.37it/s] 76%|███████▌  | 452/595 [00:53<00:15,  9.34it/s] 76%|███████▌  | 453/595 [00:53<00:15,  9.39it/s] 76%|███████▋  | 454/595 [00:53<00:14,  9.47it/s] 76%|███████▋  | 455/595 [00:54<00:14,  9.35it/s] 77%|███████▋  | 456/595 [00:54<00:14,  9.38it/s] 77%|███████▋  | 457/595 [00:54<00:14,  9.49it/s] 77%|███████▋  | 458/595 [00:54<00:14,  9.45it/s] 77%|███████▋  | 459/595 [00:54<00:14,  9.32it/s] 77%|███████▋  | 460/595 [00:54<00:14,  9.32it/s] 77%|███████▋  | 461/595 [00:54<00:14,  9.40it/s] 78%|███████▊  | 462/595 [00:54<00:14,  9.32it/s] 78%|███████▊  | 463/595 [00:54<00:14,  9.33it/s] 78%|███████▊  | 464/595 [00:55<00:14,  9.32it/s] 78%|███████▊  | 465/595 [00:55<00:13,  9.36it/s] 78%|███████▊  | 466/595 [00:55<00:13,  9.37it/s] 78%|███████▊  | 467/595 [00:55<00:13,  9.41it/s] 79%|███████▊  | 468/595 [00:55<00:13,  9.37it/s] 79%|███████▉  | 469/595 [00:55<00:13,  9.35it/s] 79%|███████▉  | 470/595 [00:55<00:13,  9.38it/s] 79%|███████▉  | 471/595 [00:55<00:13,  9.34it/s] 79%|███████▉  | 472/595 [00:55<00:13,  9.35it/s] 79%|███████▉  | 473/595 [00:56<00:12,  9.39it/s] 80%|███████▉  | 474/595 [00:56<00:12,  9.34it/s] 80%|███████▉  | 475/595 [00:56<00:12,  9.37it/s]                                                  80%|████████  | 476/595 [00:56<00:12,  9.37it/s][INFO|trainer.py:755] 2023-11-15 21:26:05,004 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:26:05,005 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:26:05,006 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:26:05,006 >>   Batch size = 8
{'eval_loss': 0.5099793672561646, 'eval_accuracy': 0.8126984126984127, 'eval_micro_f1': 0.8126984126984127, 'eval_macro_f1': 0.7350958127044048, 'eval_runtime': 1.6231, 'eval_samples_per_second': 582.224, 'eval_steps_per_second': 73.317, 'epoch': 3.0}
{'loss': 0.2237, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 87.71it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 83.67it/s][A
 23%|██▎       | 27/119 [00:00<00:01, 78.01it/s][A
 29%|██▉       | 35/119 [00:00<00:01, 77.50it/s][A
 36%|███▌      | 43/119 [00:00<00:00, 78.22it/s][A
 43%|████▎     | 51/119 [00:00<00:00, 77.88it/s][A
 50%|████▉     | 59/119 [00:00<00:00, 77.10it/s][A
 56%|█████▋    | 67/119 [00:00<00:00, 75.36it/s][A
 63%|██████▎   | 75/119 [00:00<00:00, 76.44it/s][A
 71%|███████   | 84/119 [00:01<00:00, 76.79it/s][A
 77%|███████▋  | 92/119 [00:01<00:00, 75.40it/s][A
 84%|████████▍ | 100/119 [00:01<00:00, 75.82it/s][A
 92%|█████████▏| 109/119 [00:01<00:00, 78.59it/s][A
 98%|█████████▊| 117/119 [00:01<00:00, 76.86it/s][A                                                 
                                                 [A 80%|████████  | 476/595 [00:57<00:12,  9.37it/s]
100%|██████████| 119/119 [00:01<00:00, 76.86it/s][A
                                                 [A 80%|████████  | 477/595 [00:57<00:54,  2.18it/s] 80%|████████  | 478/595 [00:58<00:43,  2.70it/s] 81%|████████  | 479/595 [00:58<00:35,  3.31it/s] 81%|████████  | 480/595 [00:58<00:28,  4.03it/s] 81%|████████  | 481/595 [00:58<00:23,  4.82it/s] 81%|████████  | 482/595 [00:58<00:20,  5.55it/s] 81%|████████  | 483/595 [00:58<00:17,  6.28it/s] 81%|████████▏ | 484/595 [00:58<00:15,  7.00it/s] 82%|████████▏ | 485/595 [00:58<00:14,  7.53it/s] 82%|████████▏ | 486/595 [00:58<00:13,  7.98it/s] 82%|████████▏ | 487/595 [00:59<00:12,  8.36it/s] 82%|████████▏ | 488/595 [00:59<00:12,  8.69it/s] 82%|████████▏ | 489/595 [00:59<00:11,  8.83it/s] 82%|████████▏ | 490/595 [00:59<00:11,  8.94it/s] 83%|████████▎ | 491/595 [00:59<00:11,  9.08it/s] 83%|████████▎ | 492/595 [00:59<00:11,  9.19it/s] 83%|████████▎ | 493/595 [00:59<00:11,  9.21it/s] 83%|████████▎ | 494/595 [00:59<00:10,  9.19it/s] 83%|████████▎ | 495/595 [00:59<00:10,  9.29it/s] 83%|████████▎ | 496/595 [00:59<00:10,  9.23it/s] 84%|████████▎ | 497/595 [01:00<00:10,  9.37it/s] 84%|████████▎ | 498/595 [01:00<00:10,  9.29it/s] 84%|████████▍ | 499/595 [01:00<00:10,  9.32it/s] 84%|████████▍ | 500/595 [01:00<00:10,  9.45it/s] 84%|████████▍ | 501/595 [01:00<00:10,  9.40it/s] 84%|████████▍ | 502/595 [01:00<00:10,  9.27it/s] 85%|████████▍ | 503/595 [01:00<00:09,  9.34it/s] 85%|████████▍ | 504/595 [01:00<00:09,  9.37it/s] 85%|████████▍ | 505/595 [01:00<00:09,  9.27it/s] 85%|████████▌ | 506/595 [01:01<00:09,  9.33it/s] 85%|████████▌ | 507/595 [01:01<00:09,  9.32it/s] 85%|████████▌ | 508/595 [01:01<00:09,  9.38it/s] 86%|████████▌ | 509/595 [01:01<00:09,  9.39it/s] 86%|████████▌ | 510/595 [01:01<00:09,  9.36it/s] 86%|████████▌ | 511/595 [01:01<00:08,  9.36it/s] 86%|████████▌ | 512/595 [01:01<00:08,  9.29it/s] 86%|████████▌ | 513/595 [01:01<00:08,  9.35it/s] 86%|████████▋ | 514/595 [01:01<00:08,  9.31it/s] 87%|████████▋ | 515/595 [01:02<00:08,  9.32it/s] 87%|████████▋ | 516/595 [01:02<00:08,  9.45it/s] 87%|████████▋ | 517/595 [01:02<00:08,  9.34it/s] 87%|████████▋ | 518/595 [01:02<00:08,  9.41it/s] 87%|████████▋ | 519/595 [01:02<00:08,  9.33it/s] 87%|████████▋ | 520/595 [01:02<00:07,  9.43it/s] 88%|████████▊ | 521/595 [01:02<00:07,  9.31it/s] 88%|████████▊ | 522/595 [01:02<00:07,  9.35it/s] 88%|████████▊ | 523/595 [01:02<00:07,  9.26it/s] 88%|████████▊ | 524/595 [01:02<00:07,  9.36it/s] 88%|████████▊ | 525/595 [01:03<00:07,  9.33it/s] 88%|████████▊ | 526/595 [01:03<00:07,  9.42it/s] 89%|████████▊ | 527/595 [01:03<00:07,  9.31it/s] 89%|████████▊ | 528/595 [01:03<00:07,  9.32it/s] 89%|████████▉ | 529/595 [01:03<00:06,  9.46it/s] 89%|████████▉ | 530/595 [01:03<00:06,  9.31it/s] 89%|████████▉ | 531/595 [01:03<00:06,  9.30it/s] 89%|████████▉ | 532/595 [01:03<00:06,  9.35it/s] 90%|████████▉ | 533/595 [01:03<00:06,  9.39it/s] 90%|████████▉ | 534/595 [01:04<00:06,  9.34it/s] 90%|████████▉ | 535/595 [01:04<00:06,  9.30it/s] 90%|█████████ | 536/595 [01:04<00:06,  9.30it/s] 90%|█████████ | 537/595 [01:04<00:06,  9.35it/s] 90%|█████████ | 538/595 [01:04<00:06,  9.37it/s] 91%|█████████ | 539/595 [01:04<00:06,  9.29it/s] 91%|█████████ | 540/595 [01:04<00:05,  9.36it/s] 91%|█████████ | 541/595 [01:04<00:05,  9.33it/s] 91%|█████████ | 542/595 [01:04<00:05,  9.34it/s] 91%|█████████▏| 543/595 [01:05<00:05,  9.29it/s] 91%|█████████▏| 544/595 [01:05<00:05,  9.28it/s] 92%|█████████▏| 545/595 [01:05<00:05,  9.40it/s] 92%|█████████▏| 546/595 [01:05<00:05,  9.35it/s] 92%|█████████▏| 547/595 [01:05<00:05,  9.40it/s] 92%|█████████▏| 548/595 [01:05<00:05,  9.31it/s] 92%|█████████▏| 549/595 [01:05<00:04,  9.40it/s] 92%|█████████▏| 550/595 [01:05<00:04,  9.41it/s] 93%|█████████▎| 551/595 [01:05<00:04,  9.36it/s] 93%|█████████▎| 552/595 [01:05<00:04,  9.33it/s] 93%|█████████▎| 553/595 [01:06<00:04,  9.00it/s] 93%|█████████▎| 554/595 [01:06<00:04,  9.15it/s] 93%|█████████▎| 555/595 [01:06<00:04,  9.17it/s] 93%|█████████▎| 556/595 [01:06<00:04,  9.24it/s] 94%|█████████▎| 557/595 [01:06<00:04,  9.22it/s] 94%|█████████▍| 558/595 [01:06<00:03,  9.33it/s] 94%|█████████▍| 559/595 [01:06<00:03,  9.30it/s] 94%|█████████▍| 560/595 [01:06<00:03,  9.31it/s] 94%|█████████▍| 561/595 [01:06<00:03,  9.42it/s] 94%|█████████▍| 562/595 [01:07<00:03,  9.34it/s] 95%|█████████▍| 563/595 [01:07<00:03,  9.30it/s] 95%|█████████▍| 564/595 [01:07<00:03,  9.31it/s] 95%|█████████▍| 565/595 [01:07<00:03,  9.38it/s] 95%|█████████▌| 566/595 [01:07<00:03,  9.36it/s] 95%|█████████▌| 567/595 [01:07<00:02,  9.34it/s] 95%|█████████▌| 568/595 [01:07<00:02,  9.22it/s] 96%|█████████▌| 569/595 [01:07<00:02,  9.24it/s] 96%|█████████▌| 570/595 [01:07<00:02,  9.23it/s] 96%|█████████▌| 571/595 [01:08<00:02,  9.26it/s] 96%|█████████▌| 572/595 [01:08<00:02,  9.26it/s] 96%|█████████▋| 573/595 [01:08<00:02,  9.26it/s] 96%|█████████▋| 574/595 [01:08<00:02,  9.45it/s] 97%|█████████▋| 575/595 [01:08<00:02,  9.35it/s] 97%|█████████▋| 576/595 [01:08<00:02,  9.29it/s] 97%|█████████▋| 577/595 [01:08<00:01,  9.37it/s] 97%|█████████▋| 578/595 [01:08<00:01,  9.34it/s] 97%|█████████▋| 579/595 [01:08<00:01,  9.30it/s] 97%|█████████▋| 580/595 [01:09<00:01,  9.25it/s] 98%|█████████▊| 581/595 [01:09<00:01,  9.30it/s] 98%|█████████▊| 582/595 [01:09<00:01,  9.27it/s] 98%|█████████▊| 583/595 [01:09<00:01,  9.29it/s] 98%|█████████▊| 584/595 [01:09<00:01,  9.21it/s] 98%|█████████▊| 585/595 [01:09<00:01,  9.32it/s] 98%|█████████▊| 586/595 [01:09<00:00,  9.30it/s] 99%|█████████▊| 587/595 [01:09<00:00,  9.35it/s] 99%|█████████▉| 588/595 [01:09<00:00,  9.31it/s] 99%|█████████▉| 589/595 [01:09<00:00,  9.32it/s] 99%|█████████▉| 590/595 [01:10<00:00,  9.42it/s] 99%|█████████▉| 591/595 [01:10<00:00,  9.43it/s] 99%|█████████▉| 592/595 [01:10<00:00,  9.30it/s]100%|█████████▉| 593/595 [01:10<00:00,  9.33it/s]100%|█████████▉| 594/595 [01:10<00:00,  9.46it/s]                                                 100%|██████████| 595/595 [01:10<00:00,  9.46it/s][INFO|trainer.py:755] 2023-11-15 21:26:19,280 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:26:19,282 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:26:19,282 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:26:19,282 >>   Batch size = 8
{'eval_loss': 0.539189338684082, 'eval_accuracy': 0.8137566137566138, 'eval_micro_f1': 0.8137566137566138, 'eval_macro_f1': 0.7434631073250083, 'eval_runtime': 1.5886, 'eval_samples_per_second': 594.872, 'eval_steps_per_second': 74.91, 'epoch': 4.0}
{'loss': 0.1596, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/119 [00:00<?, ?it/s][A
  8%|▊         | 9/119 [00:00<00:01, 86.08it/s][A
 15%|█▌        | 18/119 [00:00<00:01, 79.05it/s][A
 22%|██▏       | 26/119 [00:00<00:01, 75.00it/s][A
 29%|██▊       | 34/119 [00:00<00:01, 75.12it/s][A
 35%|███▌      | 42/119 [00:00<00:01, 76.54it/s][A
 42%|████▏     | 50/119 [00:00<00:00, 74.21it/s][A
 49%|████▊     | 58/119 [00:00<00:00, 72.59it/s][A
 55%|█████▌    | 66/119 [00:00<00:00, 73.97it/s][A
 62%|██████▏   | 74/119 [00:00<00:00, 73.96it/s][A
 69%|██████▉   | 82/119 [00:01<00:00, 72.35it/s][A
 76%|███████▌  | 90/119 [00:01<00:00, 72.78it/s][A
 82%|████████▏ | 98/119 [00:01<00:00, 74.39it/s][A
 89%|████████▉ | 106/119 [00:01<00:00, 72.64it/s][A
 96%|█████████▌| 114/119 [00:01<00:00, 72.43it/s][A                                                 
                                                 [A100%|██████████| 595/595 [01:12<00:00,  9.46it/s]
100%|██████████| 119/119 [00:01<00:00, 72.43it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 21:26:20,921 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 595/595 [01:12<00:00,  9.46it/s]100%|██████████| 595/595 [01:12<00:00,  8.24it/s]
[INFO|trainer.py:2855] 2023-11-15 21:26:20,924 >> Saving model checkpoint to ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4
[INFO|configuration_utils.py:460] 2023-11-15 21:26:20,926 >> Configuration saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:26:21,966 >> Model weights saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:26:21,968 >> tokenizer config file saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:26:21,971 >> Special tokens file saved in ./result/restaurant_allenai/scibert_scivocab_uncased_adapter__seed4/special_tokens_map.json
{'eval_loss': 0.5572054386138916, 'eval_accuracy': 0.816931216931217, 'eval_micro_f1': 0.816931216931217, 'eval_macro_f1': 0.7519146826481248, 'eval_runtime': 1.6353, 'eval_samples_per_second': 577.889, 'eval_steps_per_second': 72.771, 'epoch': 5.0}
{'train_runtime': 72.1924, 'train_samples_per_second': 261.593, 'train_steps_per_second': 8.242, 'train_loss': 0.38267781874712775, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.3827
  train_runtime            = 0:01:12.19
  train_samples            =       3777
  train_samples_per_second =    261.593
  train_steps_per_second   =      8.242
11/15/2023 21:26:22 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:26:22,014 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:26:22,015 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:26:22,016 >>   Num examples = 945
[INFO|trainer.py:3134] 2023-11-15 21:26:22,016 >>   Batch size = 8
  0%|          | 0/119 [00:00<?, ?it/s]  8%|▊         | 9/119 [00:00<00:01, 83.00it/s] 15%|█▌        | 18/119 [00:00<00:01, 81.17it/s] 23%|██▎       | 27/119 [00:00<00:01, 80.57it/s] 30%|███       | 36/119 [00:00<00:01, 76.03it/s] 37%|███▋      | 44/119 [00:00<00:00, 76.39it/s] 44%|████▎     | 52/119 [00:00<00:00, 76.52it/s] 50%|█████     | 60/119 [00:00<00:00, 75.28it/s] 57%|█████▋    | 68/119 [00:00<00:00, 74.95it/s] 64%|██████▍   | 76/119 [00:00<00:00, 75.03it/s] 71%|███████   | 84/119 [00:01<00:00, 75.63it/s] 77%|███████▋  | 92/119 [00:01<00:00, 74.75it/s] 84%|████████▍ | 100/119 [00:01<00:00, 75.10it/s] 91%|█████████ | 108/119 [00:01<00:00, 74.55it/s] 97%|█████████▋| 116/119 [00:01<00:00, 75.64it/s]100%|██████████| 119/119 [00:01<00:00, 74.81it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8169
  eval_loss               =     0.5572
  eval_macro_f1           =     0.7519
  eval_micro_f1           =     0.8169
  eval_runtime            = 0:00:01.61
  eval_samples            =        945
  eval_samples_per_second =    586.643
  eval_steps_per_second   =     73.874
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▇████
wandb:                      eval/loss █▁▃▅▆▆
wandb:                  eval/macro_f1 ▁▇▇▇██
wandb:                  eval/micro_f1 ▁▇████
wandb:                   eval/runtime ▆▁▇▃█▅
wandb:        eval/samples_per_second ▃█▂▆▁▄
wandb:          eval/steps_per_second ▃█▂▆▁▄
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.81693
wandb:                      eval/loss 0.55721
wandb:                  eval/macro_f1 0.75191
wandb:                  eval/micro_f1 0.81693
wandb:                   eval/runtime 1.6109
wandb:        eval/samples_per_second 586.643
wandb:          eval/steps_per_second 73.874
wandb:                    train/epoch 5.0
wandb:              train/global_step 595
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1596
wandb:               train/total_flos 621112111724160.0
wandb:               train/train_loss 0.38268
wandb:            train/train_runtime 72.1924
wandb: train/train_samples_per_second 261.593
wandb:   train/train_steps_per_second 8.242
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_212351-d5m9elyn
wandb: Find logs at: ./wandb/offline-run-20231115_212351-d5m9elyn/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_roberta-base_adapter__seed4/runs/Nov15_21-26-33_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_roberta-base_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_roberta-base_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:26:33 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:26:33 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_roberta-base_adapter__seed4/runs/Nov15_21-26-32_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_roberta-base_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_roberta-base_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  36%|███▋      | 4013/11020 [00:00<00:00, 38632.38 examples/s]Map:  74%|███████▍  | 8174/11020 [00:00<00:00, 40351.13 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 40058.75 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 21:26:49,554 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:26:49,567 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 21:26:59,584 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 21:27:09,603 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:27:09,604 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:27:29,646 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:27:29,646 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:27:29,647 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:27:29,647 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:27:29,647 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:27:29,648 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 21:27:29,649 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:27:29,650 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:27:49,830 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 21:27:50,568 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:27:50,569 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  34%|███▍      | 3000/8816 [00:00<00:00, 20833.08 examples/s]Running tokenizer on dataset:  79%|███████▉  | 7000/8816 [00:00<00:00, 22118.42 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 21911.08 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 23855.13 examples/s]
11/15/2023 21:27:51 - INFO - __main__ - Sample 3167 of the training set: {'text': 'Other studies showed that ACR could affect the cellular energy generation and the deficiency of energy induced the neurotoxicity [7, 8].', 'label': 0, 'input_ids': [0, 24989, 3218, 969, 14, 7224, 500, 115, 3327, 5, 19729, 1007, 2706, 8, 5, 30367, 9, 1007, 26914, 5, 44978, 46513, 646, 406, 6, 290, 8174, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:27:51 - INFO - __main__ - Sample 4498 of the training set: {'text': 'Left renal glucose utilization and splanchnic glucose utilization (utilization) were calculated using the formula\n utilization 5 FEGlc 3 3Glc4a 3 R1H2PF (4)\n where R(H)PF equals either unilateral renal plasma flow or hepatic plasma flow.', 'label': 1, 'input_ids': [0, 39961, 39729, 26071, 21429, 8, 11743, 260, 13212, 636, 26071, 21429, 36, 32843, 1938, 43, 58, 9658, 634, 5, 9288, 50118, 21429, 195, 274, 7170, 45071, 155, 155, 16389, 438, 306, 102, 155, 248, 134, 725, 176, 16088, 36, 306, 43, 50118, 147, 248, 1640, 725, 43, 16088, 27601, 1169, 23077, 39729, 29051, 3041, 50, 45441, 5183, 29051, 3041, 4, 2, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]}.
11/15/2023 21:27:51 - INFO - __main__ - Sample 2638 of the training set: {'text': 'The randomized controlled trials (RCTs) which evaluated the efficacy of PEG for mechanical bowel preparation in prevention of postoperative complications in colorectal surgery were considered for inclusion.', 'label': 1, 'input_ids': [0, 133, 36861, 4875, 7341, 36, 500, 7164, 29, 43, 61, 15423, 5, 22081, 9, 221, 7170, 13, 12418, 29928, 7094, 11, 8555, 9, 618, 23655, 12385, 11, 11311, 1688, 3894, 337, 3012, 58, 1687, 13, 9290, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:27:51 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:27:52,577 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:27:52,585 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:27:52,585 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 21:27:52,585 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:27:52,585 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:27:52,586 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:27:52,586 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:27:52,586 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 21:27:52,587 >>   Number of trainable parameters = 124,647,939
[INFO|integration_utils.py:716] 2023-11-15 21:27:52,588 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<30:48,  1.34s/it]  0%|          | 2/1380 [00:01<14:04,  1.63it/s]  0%|          | 3/1380 [00:01<08:45,  2.62it/s]  0%|          | 4/1380 [00:01<06:13,  3.68it/s]  0%|          | 5/1380 [00:01<04:53,  4.68it/s]  0%|          | 6/1380 [00:01<04:04,  5.63it/s]  1%|          | 7/1380 [00:01<03:30,  6.51it/s]  1%|          | 8/1380 [00:02<03:10,  7.22it/s]  1%|          | 9/1380 [00:02<02:57,  7.74it/s]  1%|          | 10/1380 [00:02<02:47,  8.19it/s]  1%|          | 11/1380 [00:02<02:39,  8.57it/s]  1%|          | 12/1380 [00:02<02:35,  8.82it/s]  1%|          | 13/1380 [00:02<02:33,  8.93it/s]  1%|          | 14/1380 [00:02<02:30,  9.07it/s]  1%|          | 15/1380 [00:02<02:29,  9.15it/s]  1%|          | 16/1380 [00:02<02:28,  9.17it/s]  1%|          | 17/1380 [00:03<02:28,  9.18it/s]  1%|▏         | 18/1380 [00:03<02:26,  9.27it/s]  1%|▏         | 19/1380 [00:03<02:27,  9.20it/s]  1%|▏         | 20/1380 [00:03<02:27,  9.23it/s]  2%|▏         | 21/1380 [00:03<02:26,  9.27it/s]  2%|▏         | 22/1380 [00:03<02:25,  9.35it/s]  2%|▏         | 23/1380 [00:03<02:25,  9.34it/s]  2%|▏         | 24/1380 [00:03<02:25,  9.31it/s]  2%|▏         | 25/1380 [00:03<02:25,  9.34it/s]  2%|▏         | 26/1380 [00:04<02:24,  9.38it/s]  2%|▏         | 27/1380 [00:04<02:25,  9.29it/s]  2%|▏         | 28/1380 [00:04<02:24,  9.32it/s]  2%|▏         | 29/1380 [00:04<02:23,  9.40it/s]  2%|▏         | 30/1380 [00:04<02:23,  9.39it/s]  2%|▏         | 31/1380 [00:04<02:24,  9.35it/s]  2%|▏         | 32/1380 [00:04<02:23,  9.36it/s]  2%|▏         | 33/1380 [00:04<02:21,  9.50it/s]  2%|▏         | 34/1380 [00:04<02:22,  9.42it/s]  3%|▎         | 35/1380 [00:04<02:24,  9.33it/s]  3%|▎         | 36/1380 [00:05<02:23,  9.38it/s]  3%|▎         | 37/1380 [00:05<02:22,  9.41it/s]  3%|▎         | 38/1380 [00:05<02:23,  9.33it/s]  3%|▎         | 39/1380 [00:05<02:24,  9.26it/s]  3%|▎         | 40/1380 [00:05<02:24,  9.26it/s]  3%|▎         | 41/1380 [00:05<02:24,  9.29it/s]  3%|▎         | 42/1380 [00:05<02:24,  9.26it/s]  3%|▎         | 43/1380 [00:05<02:25,  9.20it/s]  3%|▎         | 44/1380 [00:05<02:25,  9.18it/s]  3%|▎         | 45/1380 [00:06<02:24,  9.25it/s]  3%|▎         | 46/1380 [00:06<02:24,  9.23it/s]  3%|▎         | 47/1380 [00:06<02:25,  9.19it/s]  3%|▎         | 48/1380 [00:06<02:24,  9.21it/s]  4%|▎         | 49/1380 [00:06<02:23,  9.30it/s]  4%|▎         | 50/1380 [00:06<02:22,  9.31it/s]  4%|▎         | 51/1380 [00:06<02:24,  9.21it/s]  4%|▍         | 52/1380 [00:06<02:23,  9.24it/s]  4%|▍         | 53/1380 [00:06<02:23,  9.24it/s]  4%|▍         | 54/1380 [00:07<02:23,  9.25it/s]  4%|▍         | 55/1380 [00:07<02:23,  9.25it/s]  4%|▍         | 56/1380 [00:07<02:24,  9.13it/s]  4%|▍         | 57/1380 [00:07<02:24,  9.18it/s]  4%|▍         | 58/1380 [00:07<02:23,  9.21it/s]  4%|▍         | 59/1380 [00:07<02:24,  9.12it/s]  4%|▍         | 60/1380 [00:07<02:24,  9.13it/s]  4%|▍         | 61/1380 [00:07<02:23,  9.20it/s]  4%|▍         | 62/1380 [00:07<02:22,  9.22it/s]  5%|▍         | 63/1380 [00:08<02:22,  9.25it/s]  5%|▍         | 64/1380 [00:08<02:22,  9.25it/s]  5%|▍         | 65/1380 [00:08<02:23,  9.16it/s]  5%|▍         | 66/1380 [00:08<02:23,  9.17it/s]  5%|▍         | 67/1380 [00:08<02:22,  9.24it/s]  5%|▍         | 68/1380 [00:08<02:22,  9.22it/s]  5%|▌         | 69/1380 [00:08<02:22,  9.20it/s]  5%|▌         | 70/1380 [00:08<02:22,  9.17it/s]  5%|▌         | 71/1380 [00:08<02:21,  9.23it/s]  5%|▌         | 72/1380 [00:08<02:21,  9.25it/s]  5%|▌         | 73/1380 [00:09<02:21,  9.22it/s]  5%|▌         | 74/1380 [00:09<02:21,  9.20it/s]  5%|▌         | 75/1380 [00:09<02:21,  9.23it/s]  6%|▌         | 76/1380 [00:09<02:21,  9.21it/s]  6%|▌         | 77/1380 [00:09<02:20,  9.25it/s]  6%|▌         | 78/1380 [00:09<02:21,  9.19it/s]  6%|▌         | 79/1380 [00:09<02:22,  9.15it/s]  6%|▌         | 80/1380 [00:09<02:20,  9.25it/s]  6%|▌         | 81/1380 [00:09<02:19,  9.30it/s]  6%|▌         | 82/1380 [00:10<02:20,  9.25it/s]  6%|▌         | 83/1380 [00:10<02:21,  9.15it/s]  6%|▌         | 84/1380 [00:10<02:20,  9.22it/s]  6%|▌         | 85/1380 [00:10<02:19,  9.27it/s]  6%|▌         | 86/1380 [00:10<02:20,  9.20it/s]  6%|▋         | 87/1380 [00:10<02:20,  9.19it/s]  6%|▋         | 88/1380 [00:10<02:20,  9.22it/s]  6%|▋         | 89/1380 [00:10<02:19,  9.23it/s]  7%|▋         | 90/1380 [00:10<02:20,  9.16it/s]  7%|▋         | 91/1380 [00:11<02:19,  9.22it/s]  7%|▋         | 92/1380 [00:11<02:21,  9.13it/s]  7%|▋         | 93/1380 [00:11<02:19,  9.24it/s]  7%|▋         | 94/1380 [00:11<02:17,  9.36it/s]  7%|▋         | 95/1380 [00:11<02:17,  9.35it/s]  7%|▋         | 96/1380 [00:11<02:18,  9.29it/s]  7%|▋         | 97/1380 [00:11<02:17,  9.32it/s]  7%|▋         | 98/1380 [00:11<02:17,  9.34it/s]  7%|▋         | 99/1380 [00:11<02:17,  9.30it/s]  7%|▋         | 100/1380 [00:12<02:17,  9.28it/s]  7%|▋         | 101/1380 [00:12<02:18,  9.21it/s]  7%|▋         | 102/1380 [00:12<02:18,  9.24it/s]  7%|▋         | 103/1380 [00:12<02:19,  9.16it/s]  8%|▊         | 104/1380 [00:12<02:18,  9.23it/s]  8%|▊         | 105/1380 [00:12<02:18,  9.22it/s]  8%|▊         | 106/1380 [00:12<02:18,  9.22it/s]  8%|▊         | 107/1380 [00:12<02:17,  9.25it/s]  8%|▊         | 108/1380 [00:12<02:17,  9.24it/s]  8%|▊         | 109/1380 [00:12<02:17,  9.21it/s]  8%|▊         | 110/1380 [00:13<02:17,  9.22it/s]  8%|▊         | 111/1380 [00:13<02:17,  9.24it/s]  8%|▊         | 112/1380 [00:13<02:17,  9.21it/s]  8%|▊         | 113/1380 [00:13<02:17,  9.19it/s]  8%|▊         | 114/1380 [00:13<02:18,  9.15it/s]  8%|▊         | 115/1380 [00:13<02:18,  9.15it/s]  8%|▊         | 116/1380 [00:13<02:18,  9.16it/s]  8%|▊         | 117/1380 [00:13<02:17,  9.18it/s]  9%|▊         | 118/1380 [00:13<02:18,  9.13it/s]  9%|▊         | 119/1380 [00:14<02:17,  9.18it/s]  9%|▊         | 120/1380 [00:14<02:16,  9.26it/s]  9%|▉         | 121/1380 [00:14<02:15,  9.26it/s]  9%|▉         | 122/1380 [00:14<02:16,  9.22it/s]  9%|▉         | 123/1380 [00:14<02:16,  9.18it/s]  9%|▉         | 124/1380 [00:14<02:16,  9.23it/s]  9%|▉         | 125/1380 [00:14<02:15,  9.24it/s]  9%|▉         | 126/1380 [00:14<02:15,  9.27it/s]  9%|▉         | 127/1380 [00:14<02:15,  9.25it/s]  9%|▉         | 128/1380 [00:15<02:15,  9.25it/s]  9%|▉         | 129/1380 [00:15<02:15,  9.24it/s]  9%|▉         | 130/1380 [00:15<02:14,  9.32it/s]  9%|▉         | 131/1380 [00:15<02:14,  9.28it/s] 10%|▉         | 132/1380 [00:15<02:15,  9.18it/s] 10%|▉         | 133/1380 [00:15<02:15,  9.21it/s] 10%|▉         | 134/1380 [00:15<02:14,  9.24it/s] 10%|▉         | 135/1380 [00:15<02:14,  9.26it/s] 10%|▉         | 136/1380 [00:15<02:14,  9.22it/s] 10%|▉         | 137/1380 [00:16<02:15,  9.17it/s] 10%|█         | 138/1380 [00:16<02:14,  9.22it/s] 10%|█         | 139/1380 [00:16<02:14,  9.21it/s] 10%|█         | 140/1380 [00:16<02:13,  9.27it/s] 10%|█         | 141/1380 [00:16<02:14,  9.21it/s] 10%|█         | 142/1380 [00:16<02:15,  9.16it/s] 10%|█         | 143/1380 [00:16<02:14,  9.20it/s] 10%|█         | 144/1380 [00:16<02:14,  9.22it/s] 11%|█         | 145/1380 [00:16<02:14,  9.16it/s] 11%|█         | 146/1380 [00:17<02:14,  9.16it/s] 11%|█         | 147/1380 [00:17<02:13,  9.23it/s] 11%|█         | 148/1380 [00:17<02:12,  9.29it/s] 11%|█         | 149/1380 [00:17<02:13,  9.23it/s] 11%|█         | 150/1380 [00:17<02:13,  9.21it/s] 11%|█         | 151/1380 [00:17<02:13,  9.17it/s] 11%|█         | 152/1380 [00:17<02:13,  9.20it/s] 11%|█         | 153/1380 [00:17<02:12,  9.24it/s] 11%|█         | 154/1380 [00:17<02:13,  9.21it/s] 11%|█         | 155/1380 [00:17<02:14,  9.12it/s] 11%|█▏        | 156/1380 [00:18<02:13,  9.20it/s] 11%|█▏        | 157/1380 [00:18<02:12,  9.21it/s] 11%|█▏        | 158/1380 [00:18<02:14,  9.11it/s] 12%|█▏        | 159/1380 [00:18<02:13,  9.11it/s] 12%|█▏        | 160/1380 [00:18<02:14,  9.10it/s] 12%|█▏        | 161/1380 [00:18<02:13,  9.15it/s] 12%|█▏        | 162/1380 [00:18<02:14,  9.06it/s] 12%|█▏        | 163/1380 [00:18<02:13,  9.15it/s] 12%|█▏        | 164/1380 [00:18<02:13,  9.11it/s] 12%|█▏        | 165/1380 [00:19<02:13,  9.11it/s] 12%|█▏        | 166/1380 [00:19<02:11,  9.20it/s] 12%|█▏        | 167/1380 [00:19<02:12,  9.15it/s] 12%|█▏        | 168/1380 [00:19<02:12,  9.16it/s] 12%|█▏        | 169/1380 [00:19<02:13,  9.06it/s] 12%|█▏        | 170/1380 [00:19<02:12,  9.11it/s] 12%|█▏        | 171/1380 [00:19<02:12,  9.15it/s] 12%|█▏        | 172/1380 [00:19<02:11,  9.18it/s] 13%|█▎        | 173/1380 [00:19<02:11,  9.19it/s] 13%|█▎        | 174/1380 [00:20<02:12,  9.10it/s] 13%|█▎        | 175/1380 [00:20<02:11,  9.16it/s] 13%|█▎        | 176/1380 [00:20<02:10,  9.23it/s] 13%|█▎        | 177/1380 [00:20<02:10,  9.21it/s] 13%|█▎        | 178/1380 [00:20<02:10,  9.18it/s] 13%|█▎        | 179/1380 [00:20<02:11,  9.13it/s] 13%|█▎        | 180/1380 [00:20<02:11,  9.14it/s] 13%|█▎        | 181/1380 [00:20<02:10,  9.16it/s] 13%|█▎        | 182/1380 [00:20<02:12,  9.07it/s] 13%|█▎        | 183/1380 [00:21<02:11,  9.11it/s] 13%|█▎        | 184/1380 [00:21<02:11,  9.11it/s] 13%|█▎        | 185/1380 [00:21<02:11,  9.11it/s] 13%|█▎        | 186/1380 [00:21<02:09,  9.23it/s] 14%|█▎        | 187/1380 [00:21<02:10,  9.15it/s] 14%|█▎        | 188/1380 [00:21<02:09,  9.18it/s] 14%|█▎        | 189/1380 [00:21<02:11,  9.09it/s] 14%|█▍        | 190/1380 [00:21<02:10,  9.13it/s] 14%|█▍        | 191/1380 [00:21<02:10,  9.10it/s] 14%|█▍        | 192/1380 [00:22<02:09,  9.14it/s] 14%|█▍        | 193/1380 [00:22<02:10,  9.08it/s] 14%|█▍        | 194/1380 [00:22<02:09,  9.14it/s] 14%|█▍        | 195/1380 [00:22<02:08,  9.19it/s] 14%|█▍        | 196/1380 [00:22<02:08,  9.19it/s] 14%|█▍        | 197/1380 [00:22<02:09,  9.13it/s] 14%|█▍        | 198/1380 [00:22<02:09,  9.13it/s] 14%|█▍        | 199/1380 [00:22<02:08,  9.23it/s] 14%|█▍        | 200/1380 [00:22<02:08,  9.19it/s] 15%|█▍        | 201/1380 [00:23<02:08,  9.18it/s] 15%|█▍        | 202/1380 [00:23<02:09,  9.12it/s] 15%|█▍        | 203/1380 [00:23<02:07,  9.21it/s] 15%|█▍        | 204/1380 [00:23<02:08,  9.18it/s] 15%|█▍        | 205/1380 [00:23<02:08,  9.16it/s] 15%|█▍        | 206/1380 [00:23<02:08,  9.14it/s] 15%|█▌        | 207/1380 [00:23<02:07,  9.18it/s] 15%|█▌        | 208/1380 [00:23<02:07,  9.17it/s] 15%|█▌        | 209/1380 [00:23<02:07,  9.19it/s] 15%|█▌        | 210/1380 [00:23<02:08,  9.10it/s] 15%|█▌        | 211/1380 [00:24<02:07,  9.16it/s] 15%|█▌        | 212/1380 [00:24<02:06,  9.21it/s] 15%|█▌        | 213/1380 [00:24<02:07,  9.18it/s] 16%|█▌        | 214/1380 [00:24<02:07,  9.14it/s] 16%|█▌        | 215/1380 [00:24<02:06,  9.18it/s] 16%|█▌        | 216/1380 [00:24<02:05,  9.27it/s] 16%|█▌        | 217/1380 [00:24<02:05,  9.26it/s] 16%|█▌        | 218/1380 [00:24<02:05,  9.22it/s] 16%|█▌        | 219/1380 [00:24<02:05,  9.22it/s] 16%|█▌        | 220/1380 [00:25<02:05,  9.26it/s] 16%|█▌        | 221/1380 [00:25<02:05,  9.27it/s] 16%|█▌        | 222/1380 [00:25<02:05,  9.24it/s] 16%|█▌        | 223/1380 [00:25<02:06,  9.14it/s] 16%|█▌        | 224/1380 [00:25<02:06,  9.12it/s] 16%|█▋        | 225/1380 [00:25<02:05,  9.20it/s] 16%|█▋        | 226/1380 [00:25<02:05,  9.20it/s] 16%|█▋        | 227/1380 [00:25<02:05,  9.19it/s] 17%|█▋        | 228/1380 [00:25<02:06,  9.08it/s] 17%|█▋        | 229/1380 [00:26<02:06,  9.09it/s] 17%|█▋        | 230/1380 [00:26<02:05,  9.15it/s] 17%|█▋        | 231/1380 [00:26<02:05,  9.14it/s] 17%|█▋        | 232/1380 [00:26<02:05,  9.17it/s] 17%|█▋        | 233/1380 [00:26<02:05,  9.11it/s] 17%|█▋        | 234/1380 [00:26<02:05,  9.14it/s] 17%|█▋        | 235/1380 [00:26<02:04,  9.20it/s] 17%|█▋        | 236/1380 [00:26<02:03,  9.25it/s] 17%|█▋        | 237/1380 [00:26<02:03,  9.23it/s] 17%|█▋        | 238/1380 [00:27<02:04,  9.15it/s] 17%|█▋        | 239/1380 [00:27<02:04,  9.14it/s] 17%|█▋        | 240/1380 [00:27<02:04,  9.18it/s] 17%|█▋        | 241/1380 [00:27<02:05,  9.09it/s] 18%|█▊        | 242/1380 [00:27<02:04,  9.11it/s] 18%|█▊        | 243/1380 [00:27<02:05,  9.08it/s] 18%|█▊        | 244/1380 [00:27<02:05,  9.06it/s] 18%|█▊        | 245/1380 [00:27<02:04,  9.13it/s] 18%|█▊        | 246/1380 [00:27<02:04,  9.12it/s] 18%|█▊        | 247/1380 [00:28<02:04,  9.10it/s] 18%|█▊        | 248/1380 [00:28<02:05,  9.04it/s] 18%|█▊        | 249/1380 [00:28<02:04,  9.07it/s] 18%|█▊        | 250/1380 [00:28<02:04,  9.07it/s] 18%|█▊        | 251/1380 [00:28<02:03,  9.12it/s] 18%|█▊        | 252/1380 [00:28<02:02,  9.18it/s] 18%|█▊        | 253/1380 [00:28<02:03,  9.15it/s] 18%|█▊        | 254/1380 [00:28<02:03,  9.13it/s] 18%|█▊        | 255/1380 [00:28<02:02,  9.16it/s] 19%|█▊        | 256/1380 [00:29<02:02,  9.16it/s] 19%|█▊        | 257/1380 [00:29<02:03,  9.13it/s] 19%|█▊        | 258/1380 [00:29<02:03,  9.08it/s] 19%|█▉        | 259/1380 [00:29<02:02,  9.15it/s] 19%|█▉        | 260/1380 [00:29<02:02,  9.17it/s] 19%|█▉        | 261/1380 [00:29<02:02,  9.13it/s] 19%|█▉        | 262/1380 [00:29<02:02,  9.09it/s] 19%|█▉        | 263/1380 [00:29<02:02,  9.15it/s] 19%|█▉        | 264/1380 [00:29<02:01,  9.20it/s] 19%|█▉        | 265/1380 [00:30<02:00,  9.23it/s] 19%|█▉        | 266/1380 [00:30<02:00,  9.21it/s] 19%|█▉        | 267/1380 [00:30<02:01,  9.16it/s] 19%|█▉        | 268/1380 [00:30<02:00,  9.22it/s] 19%|█▉        | 269/1380 [00:30<02:01,  9.14it/s] 20%|█▉        | 270/1380 [00:30<02:01,  9.14it/s] 20%|█▉        | 271/1380 [00:30<02:01,  9.13it/s] 20%|█▉        | 272/1380 [00:30<02:00,  9.19it/s] 20%|█▉        | 273/1380 [00:30<01:59,  9.25it/s] 20%|█▉        | 274/1380 [00:30<01:59,  9.23it/s] 20%|█▉        | 275/1380 [00:31<01:59,  9.24it/s]                                                   20%|██        | 276/1380 [00:31<01:59,  9.24it/s][INFO|trainer.py:755] 2023-11-15 21:28:23,757 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:28:23,759 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:28:23,760 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:28:23,760 >>   Batch size = 8
{'loss': 0.482, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 87.81it/s][A
  7%|▋         | 18/276 [00:00<00:03, 83.91it/s][A
 10%|▉         | 27/276 [00:00<00:03, 78.22it/s][A
 13%|█▎        | 35/276 [00:00<00:03, 75.08it/s][A
 16%|█▌        | 43/276 [00:00<00:03, 75.94it/s][A
 18%|█▊        | 51/276 [00:00<00:02, 75.91it/s][A
 21%|██▏       | 59/276 [00:00<00:02, 74.63it/s][A
 24%|██▍       | 67/276 [00:00<00:02, 73.64it/s][A
 27%|██▋       | 75/276 [00:00<00:02, 74.02it/s][A
 30%|███       | 83/276 [00:01<00:02, 74.59it/s][A
 33%|███▎      | 91/276 [00:01<00:02, 75.01it/s][A
 36%|███▌      | 99/276 [00:01<00:02, 74.62it/s][A
 39%|███▉      | 107/276 [00:01<00:02, 72.17it/s][A
 42%|████▏     | 115/276 [00:01<00:02, 72.77it/s][A
 45%|████▍     | 123/276 [00:01<00:02, 74.56it/s][A
 47%|████▋     | 131/276 [00:01<00:01, 73.82it/s][A
 50%|█████     | 139/276 [00:01<00:01, 73.00it/s][A
 53%|█████▎    | 147/276 [00:01<00:01, 72.91it/s][A
 56%|█████▌    | 155/276 [00:02<00:01, 74.60it/s][A
 59%|█████▉    | 163/276 [00:02<00:01, 75.03it/s][A
 62%|██████▏   | 171/276 [00:02<00:01, 74.37it/s][A
 65%|██████▍   | 179/276 [00:02<00:01, 73.74it/s][A
 68%|██████▊   | 187/276 [00:02<00:01, 73.26it/s][A
 71%|███████   | 195/276 [00:02<00:01, 73.96it/s][A
 74%|███████▎  | 203/276 [00:02<00:00, 74.79it/s][A
 76%|███████▋  | 211/276 [00:02<00:00, 73.64it/s][A
 79%|███████▉  | 219/276 [00:02<00:00, 72.16it/s][A
 82%|████████▏ | 227/276 [00:03<00:00, 73.72it/s][A
 85%|████████▌ | 235/276 [00:03<00:00, 74.90it/s][A
 88%|████████▊ | 243/276 [00:03<00:00, 74.22it/s][A
 91%|█████████ | 251/276 [00:03<00:00, 73.82it/s][A
 94%|█████████▍| 259/276 [00:03<00:00, 73.33it/s][A
 97%|█████████▋| 267/276 [00:03<00:00, 74.70it/s][A
100%|█████████▉| 275/276 [00:03<00:00, 75.35it/s][A                                                  
                                                 [A 20%|██        | 276/1380 [00:34<01:59,  9.24it/s]
100%|██████████| 276/276 [00:03<00:00, 75.35it/s][A
                                                 [A 20%|██        | 277/1380 [00:35<17:51,  1.03it/s] 20%|██        | 278/1380 [00:35<13:54,  1.32it/s] 20%|██        | 279/1380 [00:35<10:47,  1.70it/s] 20%|██        | 280/1380 [00:35<08:23,  2.18it/s] 20%|██        | 281/1380 [00:35<06:36,  2.77it/s] 20%|██        | 282/1380 [00:35<05:16,  3.47it/s] 21%|██        | 283/1380 [00:35<04:18,  4.24it/s] 21%|██        | 284/1380 [00:35<03:38,  5.02it/s] 21%|██        | 285/1380 [00:35<03:09,  5.79it/s] 21%|██        | 286/1380 [00:36<02:48,  6.51it/s] 21%|██        | 287/1380 [00:36<02:32,  7.16it/s] 21%|██        | 288/1380 [00:36<02:22,  7.64it/s] 21%|██        | 289/1380 [00:36<02:16,  7.97it/s] 21%|██        | 290/1380 [00:36<02:11,  8.30it/s] 21%|██        | 291/1380 [00:36<02:06,  8.58it/s] 21%|██        | 292/1380 [00:36<02:04,  8.74it/s] 21%|██        | 293/1380 [00:36<02:02,  8.86it/s] 21%|██▏       | 294/1380 [00:36<02:01,  8.94it/s] 21%|██▏       | 295/1380 [00:37<02:00,  9.03it/s] 21%|██▏       | 296/1380 [00:37<01:58,  9.13it/s] 22%|██▏       | 297/1380 [00:37<01:58,  9.17it/s] 22%|██▏       | 298/1380 [00:37<01:58,  9.11it/s] 22%|██▏       | 299/1380 [00:37<01:58,  9.13it/s] 22%|██▏       | 300/1380 [00:37<01:57,  9.18it/s] 22%|██▏       | 301/1380 [00:37<01:57,  9.21it/s] 22%|██▏       | 302/1380 [00:37<01:58,  9.13it/s] 22%|██▏       | 303/1380 [00:37<01:57,  9.14it/s] 22%|██▏       | 304/1380 [00:37<01:57,  9.18it/s] 22%|██▏       | 305/1380 [00:38<01:57,  9.11it/s] 22%|██▏       | 306/1380 [00:38<01:58,  9.08it/s] 22%|██▏       | 307/1380 [00:38<01:57,  9.10it/s] 22%|██▏       | 308/1380 [00:38<01:57,  9.14it/s] 22%|██▏       | 309/1380 [00:38<01:57,  9.14it/s] 22%|██▏       | 310/1380 [00:38<01:56,  9.15it/s] 23%|██▎       | 311/1380 [00:38<01:57,  9.10it/s] 23%|██▎       | 312/1380 [00:38<01:55,  9.22it/s] 23%|██▎       | 313/1380 [00:38<01:55,  9.22it/s] 23%|██▎       | 314/1380 [00:39<01:56,  9.18it/s] 23%|██▎       | 315/1380 [00:39<01:56,  9.15it/s] 23%|██▎       | 316/1380 [00:39<01:55,  9.21it/s] 23%|██▎       | 317/1380 [00:39<01:54,  9.25it/s] 23%|██▎       | 318/1380 [00:39<01:56,  9.14it/s] 23%|██▎       | 319/1380 [00:39<01:56,  9.11it/s] 23%|██▎       | 320/1380 [00:39<01:56,  9.11it/s] 23%|██▎       | 321/1380 [00:39<01:55,  9.14it/s] 23%|██▎       | 322/1380 [00:39<01:55,  9.16it/s] 23%|██▎       | 323/1380 [00:40<01:56,  9.08it/s] 23%|██▎       | 324/1380 [00:40<01:56,  9.07it/s] 24%|██▎       | 325/1380 [00:40<01:54,  9.19it/s] 24%|██▎       | 326/1380 [00:40<01:54,  9.19it/s] 24%|██▎       | 327/1380 [00:40<01:55,  9.12it/s] 24%|██▍       | 328/1380 [00:40<01:56,  9.06it/s] 24%|██▍       | 329/1380 [00:40<01:54,  9.14it/s] 24%|██▍       | 330/1380 [00:40<01:54,  9.20it/s] 24%|██▍       | 331/1380 [00:40<01:54,  9.13it/s] 24%|██▍       | 332/1380 [00:41<01:55,  9.07it/s] 24%|██▍       | 333/1380 [00:41<01:55,  9.08it/s] 24%|██▍       | 334/1380 [00:41<01:54,  9.11it/s] 24%|██▍       | 335/1380 [00:41<01:53,  9.21it/s] 24%|██▍       | 336/1380 [00:41<01:53,  9.17it/s] 24%|██▍       | 337/1380 [00:41<01:54,  9.09it/s] 24%|██▍       | 338/1380 [00:41<01:53,  9.19it/s] 25%|██▍       | 339/1380 [00:41<01:52,  9.24it/s] 25%|██▍       | 340/1380 [00:41<01:53,  9.16it/s] 25%|██▍       | 341/1380 [00:42<01:54,  9.09it/s] 25%|██▍       | 342/1380 [00:42<01:53,  9.12it/s] 25%|██▍       | 343/1380 [00:42<01:53,  9.14it/s] 25%|██▍       | 344/1380 [00:42<01:54,  9.09it/s] 25%|██▌       | 345/1380 [00:42<01:53,  9.08it/s] 25%|██▌       | 346/1380 [00:42<01:53,  9.09it/s] 25%|██▌       | 347/1380 [00:42<01:53,  9.13it/s] 25%|██▌       | 348/1380 [00:42<01:52,  9.19it/s] 25%|██▌       | 349/1380 [00:42<01:52,  9.12it/s] 25%|██▌       | 350/1380 [00:43<01:52,  9.13it/s] 25%|██▌       | 351/1380 [00:43<01:52,  9.16it/s] 26%|██▌       | 352/1380 [00:43<01:52,  9.17it/s] 26%|██▌       | 353/1380 [00:43<01:52,  9.13it/s] 26%|██▌       | 354/1380 [00:43<01:53,  9.05it/s] 26%|██▌       | 355/1380 [00:43<01:53,  9.04it/s] 26%|██▌       | 356/1380 [00:43<01:52,  9.14it/s] 26%|██▌       | 357/1380 [00:43<01:52,  9.07it/s] 26%|██▌       | 358/1380 [00:43<01:54,  8.93it/s] 26%|██▌       | 359/1380 [00:44<01:53,  9.01it/s] 26%|██▌       | 360/1380 [00:44<01:52,  9.06it/s] 26%|██▌       | 361/1380 [00:44<01:51,  9.14it/s] 26%|██▌       | 362/1380 [00:44<01:52,  9.03it/s] 26%|██▋       | 363/1380 [00:44<01:52,  9.03it/s] 26%|██▋       | 364/1380 [00:44<01:51,  9.14it/s] 26%|██▋       | 365/1380 [00:44<01:51,  9.11it/s] 27%|██▋       | 366/1380 [00:44<01:51,  9.09it/s] 27%|██▋       | 367/1380 [00:44<01:51,  9.08it/s] 27%|██▋       | 368/1380 [00:45<01:50,  9.14it/s] 27%|██▋       | 369/1380 [00:45<01:49,  9.21it/s] 27%|██▋       | 370/1380 [00:45<01:50,  9.13it/s] 27%|██▋       | 371/1380 [00:45<01:51,  9.04it/s] 27%|██▋       | 372/1380 [00:45<01:51,  9.07it/s] 27%|██▋       | 373/1380 [00:45<01:50,  9.10it/s] 27%|██▋       | 374/1380 [00:45<01:50,  9.11it/s] 27%|██▋       | 375/1380 [00:45<01:51,  9.01it/s] 27%|██▋       | 376/1380 [00:45<01:50,  9.05it/s] 27%|██▋       | 377/1380 [00:45<01:50,  9.11it/s] 27%|██▋       | 378/1380 [00:46<01:50,  9.08it/s] 27%|██▋       | 379/1380 [00:46<01:50,  9.07it/s] 28%|██▊       | 380/1380 [00:46<01:49,  9.09it/s] 28%|██▊       | 381/1380 [00:46<01:49,  9.15it/s] 28%|██▊       | 382/1380 [00:46<01:49,  9.10it/s] 28%|██▊       | 383/1380 [00:46<01:50,  9.06it/s] 28%|██▊       | 384/1380 [00:46<01:49,  9.08it/s] 28%|██▊       | 385/1380 [00:46<01:48,  9.13it/s] 28%|██▊       | 386/1380 [00:46<01:48,  9.17it/s] 28%|██▊       | 387/1380 [00:47<01:49,  9.05it/s] 28%|██▊       | 388/1380 [00:47<01:49,  9.08it/s] 28%|██▊       | 389/1380 [00:47<01:48,  9.15it/s] 28%|██▊       | 390/1380 [00:47<01:49,  9.01it/s] 28%|██▊       | 391/1380 [00:47<01:49,  9.05it/s] 28%|██▊       | 392/1380 [00:47<01:49,  9.03it/s] 28%|██▊       | 393/1380 [00:47<01:47,  9.14it/s] 29%|██▊       | 394/1380 [00:47<01:47,  9.14it/s] 29%|██▊       | 395/1380 [00:47<01:48,  9.09it/s] 29%|██▊       | 396/1380 [00:48<01:49,  9.02it/s] 29%|██▉       | 397/1380 [00:48<01:47,  9.11it/s] 29%|██▉       | 398/1380 [00:48<01:47,  9.10it/s] 29%|██▉       | 399/1380 [00:48<01:47,  9.09it/s] 29%|██▉       | 400/1380 [00:48<01:47,  9.10it/s] 29%|██▉       | 401/1380 [00:48<01:47,  9.11it/s] 29%|██▉       | 402/1380 [00:48<01:46,  9.17it/s] 29%|██▉       | 403/1380 [00:48<01:46,  9.18it/s] 29%|██▉       | 404/1380 [00:48<01:47,  9.11it/s] 29%|██▉       | 405/1380 [00:49<01:46,  9.15it/s] 29%|██▉       | 406/1380 [00:49<01:45,  9.23it/s] 29%|██▉       | 407/1380 [00:49<01:45,  9.20it/s] 30%|██▉       | 408/1380 [00:49<01:46,  9.12it/s] 30%|██▉       | 409/1380 [00:49<01:46,  9.14it/s] 30%|██▉       | 410/1380 [00:49<01:45,  9.18it/s] 30%|██▉       | 411/1380 [00:49<01:45,  9.18it/s] 30%|██▉       | 412/1380 [00:49<01:46,  9.08it/s] 30%|██▉       | 413/1380 [00:49<01:45,  9.16it/s] 30%|███       | 414/1380 [00:50<01:45,  9.18it/s] 30%|███       | 415/1380 [00:50<01:46,  9.10it/s] 30%|███       | 416/1380 [00:50<01:45,  9.12it/s] 30%|███       | 417/1380 [00:50<01:45,  9.15it/s] 30%|███       | 418/1380 [00:50<01:44,  9.18it/s] 30%|███       | 419/1380 [00:50<01:44,  9.21it/s] 30%|███       | 420/1380 [00:50<01:44,  9.17it/s] 31%|███       | 421/1380 [00:50<01:45,  9.09it/s] 31%|███       | 422/1380 [00:50<01:44,  9.15it/s] 31%|███       | 423/1380 [00:51<01:44,  9.15it/s] 31%|███       | 424/1380 [00:51<01:45,  9.10it/s] 31%|███       | 425/1380 [00:51<01:44,  9.13it/s] 31%|███       | 426/1380 [00:51<01:43,  9.18it/s] 31%|███       | 427/1380 [00:51<01:44,  9.09it/s] 31%|███       | 428/1380 [00:51<01:45,  8.99it/s] 31%|███       | 429/1380 [00:51<01:44,  9.12it/s] 31%|███       | 430/1380 [00:51<01:43,  9.18it/s] 31%|███       | 431/1380 [00:51<01:43,  9.17it/s] 31%|███▏      | 432/1380 [00:52<01:44,  9.10it/s] 31%|███▏      | 433/1380 [00:52<01:43,  9.13it/s] 31%|███▏      | 434/1380 [00:52<01:42,  9.21it/s] 32%|███▏      | 435/1380 [00:52<01:42,  9.22it/s] 32%|███▏      | 436/1380 [00:52<01:43,  9.11it/s] 32%|███▏      | 437/1380 [00:52<01:43,  9.13it/s] 32%|███▏      | 438/1380 [00:52<01:42,  9.17it/s] 32%|███▏      | 439/1380 [00:52<01:42,  9.15it/s] 32%|███▏      | 440/1380 [00:52<01:43,  9.11it/s] 32%|███▏      | 441/1380 [00:53<01:42,  9.20it/s] 32%|███▏      | 442/1380 [00:53<01:41,  9.21it/s] 32%|███▏      | 443/1380 [00:53<01:42,  9.12it/s] 32%|███▏      | 444/1380 [00:53<01:41,  9.19it/s] 32%|███▏      | 445/1380 [00:53<01:41,  9.24it/s] 32%|███▏      | 446/1380 [00:53<01:41,  9.16it/s] 32%|███▏      | 447/1380 [00:53<01:42,  9.07it/s] 32%|███▏      | 448/1380 [00:53<01:41,  9.15it/s] 33%|███▎      | 449/1380 [00:53<01:41,  9.21it/s] 33%|███▎      | 450/1380 [00:53<01:41,  9.14it/s] 33%|███▎      | 451/1380 [00:54<01:40,  9.23it/s] 33%|███▎      | 452/1380 [00:54<01:40,  9.26it/s] 33%|███▎      | 453/1380 [00:54<01:40,  9.21it/s] 33%|███▎      | 454/1380 [00:54<01:41,  9.11it/s] 33%|███▎      | 455/1380 [00:54<01:40,  9.20it/s] 33%|███▎      | 456/1380 [00:54<01:40,  9.19it/s] 33%|███▎      | 457/1380 [00:54<01:40,  9.20it/s] 33%|███▎      | 458/1380 [00:54<01:40,  9.18it/s] 33%|███▎      | 459/1380 [00:54<01:40,  9.20it/s] 33%|███▎      | 460/1380 [00:55<01:40,  9.18it/s] 33%|███▎      | 461/1380 [00:55<01:40,  9.11it/s] 33%|███▎      | 462/1380 [00:55<01:39,  9.20it/s] 34%|███▎      | 463/1380 [00:55<01:39,  9.24it/s] 34%|███▎      | 464/1380 [00:55<01:39,  9.22it/s] 34%|███▎      | 465/1380 [00:55<01:39,  9.18it/s] 34%|███▍      | 466/1380 [00:55<01:38,  9.24it/s] 34%|███▍      | 467/1380 [00:55<01:38,  9.25it/s] 34%|███▍      | 468/1380 [00:55<01:39,  9.16it/s] 34%|███▍      | 469/1380 [00:56<01:38,  9.21it/s] 34%|███▍      | 470/1380 [00:56<01:38,  9.25it/s] 34%|███▍      | 471/1380 [00:56<01:38,  9.24it/s] 34%|███▍      | 472/1380 [00:56<01:38,  9.21it/s] 34%|███▍      | 473/1380 [00:56<01:38,  9.24it/s] 34%|███▍      | 474/1380 [00:56<01:37,  9.28it/s] 34%|███▍      | 475/1380 [00:56<01:38,  9.17it/s] 34%|███▍      | 476/1380 [00:56<01:38,  9.17it/s] 35%|███▍      | 477/1380 [00:56<01:37,  9.22it/s] 35%|███▍      | 478/1380 [00:57<01:37,  9.22it/s] 35%|███▍      | 479/1380 [00:57<01:38,  9.19it/s] 35%|███▍      | 480/1380 [00:57<01:38,  9.16it/s] 35%|███▍      | 481/1380 [00:57<01:37,  9.22it/s] 35%|███▍      | 482/1380 [00:57<01:37,  9.24it/s] 35%|███▌      | 483/1380 [00:57<01:38,  9.15it/s] 35%|███▌      | 484/1380 [00:57<01:37,  9.19it/s] 35%|███▌      | 485/1380 [00:57<01:36,  9.26it/s] 35%|███▌      | 486/1380 [00:57<01:37,  9.19it/s] 35%|███▌      | 487/1380 [00:58<01:37,  9.17it/s] 35%|███▌      | 488/1380 [00:58<01:36,  9.24it/s] 35%|███▌      | 489/1380 [00:58<01:36,  9.26it/s] 36%|███▌      | 490/1380 [00:58<01:36,  9.25it/s] 36%|███▌      | 491/1380 [00:58<01:36,  9.23it/s] 36%|███▌      | 492/1380 [00:58<01:36,  9.22it/s] 36%|███▌      | 493/1380 [00:58<01:36,  9.17it/s] 36%|███▌      | 494/1380 [00:58<01:36,  9.18it/s] 36%|███▌      | 495/1380 [00:58<01:36,  9.22it/s] 36%|███▌      | 496/1380 [00:58<01:35,  9.25it/s] 36%|███▌      | 497/1380 [00:59<01:35,  9.21it/s] 36%|███▌      | 498/1380 [00:59<01:36,  9.12it/s] 36%|███▌      | 499/1380 [00:59<01:36,  9.15it/s] 36%|███▌      | 500/1380 [00:59<01:36,  9.13it/s] 36%|███▋      | 501/1380 [00:59<01:36,  9.09it/s] 36%|███▋      | 502/1380 [00:59<01:36,  9.08it/s] 36%|███▋      | 503/1380 [00:59<01:36,  9.11it/s] 37%|███▋      | 504/1380 [00:59<01:36,  9.08it/s] 37%|███▋      | 505/1380 [00:59<01:35,  9.11it/s] 37%|███▋      | 506/1380 [01:00<01:35,  9.14it/s] 37%|███▋      | 507/1380 [01:00<01:35,  9.18it/s] 37%|███▋      | 508/1380 [01:00<01:35,  9.10it/s] 37%|███▋      | 509/1380 [01:00<01:35,  9.11it/s] 37%|███▋      | 510/1380 [01:00<01:34,  9.22it/s] 37%|███▋      | 511/1380 [01:00<01:34,  9.17it/s] 37%|███▋      | 512/1380 [01:00<01:35,  9.05it/s] 37%|███▋      | 513/1380 [01:00<01:35,  9.12it/s] 37%|███▋      | 514/1380 [01:00<01:34,  9.16it/s] 37%|███▋      | 515/1380 [01:01<01:35,  9.07it/s] 37%|███▋      | 516/1380 [01:01<01:35,  9.09it/s] 37%|███▋      | 517/1380 [01:01<01:34,  9.10it/s] 38%|███▊      | 518/1380 [01:01<01:34,  9.15it/s] 38%|███▊      | 519/1380 [01:01<01:34,  9.08it/s] 38%|███▊      | 520/1380 [01:01<01:34,  9.13it/s] 38%|███▊      | 521/1380 [01:01<01:33,  9.18it/s] 38%|███▊      | 522/1380 [01:01<01:34,  9.13it/s] 38%|███▊      | 523/1380 [01:01<01:34,  9.05it/s] 38%|███▊      | 524/1380 [01:02<01:34,  9.10it/s] 38%|███▊      | 525/1380 [01:02<01:33,  9.13it/s] 38%|███▊      | 526/1380 [01:02<01:33,  9.14it/s] 38%|███▊      | 527/1380 [01:02<01:33,  9.09it/s] 38%|███▊      | 528/1380 [01:02<01:33,  9.12it/s] 38%|███▊      | 529/1380 [01:02<01:32,  9.19it/s] 38%|███▊      | 530/1380 [01:02<01:33,  9.06it/s] 38%|███▊      | 531/1380 [01:02<01:33,  9.09it/s] 39%|███▊      | 532/1380 [01:02<01:32,  9.14it/s] 39%|███▊      | 533/1380 [01:03<01:32,  9.13it/s] 39%|███▊      | 534/1380 [01:03<01:33,  9.07it/s] 39%|███▉      | 535/1380 [01:03<01:32,  9.15it/s] 39%|███▉      | 536/1380 [01:03<01:31,  9.18it/s] 39%|███▉      | 537/1380 [01:03<01:32,  9.10it/s] 39%|███▉      | 538/1380 [01:03<01:32,  9.13it/s] 39%|███▉      | 539/1380 [01:03<01:31,  9.19it/s] 39%|███▉      | 540/1380 [01:03<01:31,  9.17it/s] 39%|███▉      | 541/1380 [01:03<01:31,  9.19it/s] 39%|███▉      | 542/1380 [01:04<01:31,  9.17it/s] 39%|███▉      | 543/1380 [01:04<01:31,  9.18it/s] 39%|███▉      | 544/1380 [01:04<01:31,  9.11it/s] 39%|███▉      | 545/1380 [01:04<01:32,  9.04it/s] 40%|███▉      | 546/1380 [01:04<01:31,  9.10it/s] 40%|███▉      | 547/1380 [01:04<01:31,  9.08it/s] 40%|███▉      | 548/1380 [01:04<01:31,  9.06it/s] 40%|███▉      | 549/1380 [01:04<01:31,  9.12it/s] 40%|███▉      | 550/1380 [01:04<01:30,  9.12it/s] 40%|███▉      | 551/1380 [01:05<01:29,  9.21it/s]                                                   40%|████      | 552/1380 [01:05<01:29,  9.21it/s][INFO|trainer.py:755] 2023-11-15 21:28:57,684 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:28:57,686 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:28:57,686 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:28:57,686 >>   Batch size = 8
{'eval_loss': 0.41349419951438904, 'eval_accuracy': 0.8489110707803993, 'eval_micro_f1': 0.8489110707803994, 'eval_macro_f1': 0.8413225254185774, 'eval_runtime': 3.7719, 'eval_samples_per_second': 584.327, 'eval_steps_per_second': 73.173, 'epoch': 1.0}
{'loss': 0.3198, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 82.47it/s][A
  7%|▋         | 18/276 [00:00<00:03, 82.33it/s][A
 10%|▉         | 27/276 [00:00<00:03, 76.76it/s][A
 13%|█▎        | 35/276 [00:00<00:03, 74.97it/s][A
 16%|█▌        | 43/276 [00:00<00:03, 76.51it/s][A
 18%|█▊        | 51/276 [00:00<00:03, 74.96it/s][A
 21%|██▏       | 59/276 [00:00<00:02, 72.55it/s][A
 24%|██▍       | 67/276 [00:00<00:02, 73.73it/s][A
 27%|██▋       | 75/276 [00:00<00:02, 74.80it/s][A
 30%|███       | 83/276 [00:01<00:02, 73.35it/s][A
 33%|███▎      | 91/276 [00:01<00:02, 73.08it/s][A
 36%|███▌      | 99/276 [00:01<00:02, 73.64it/s][A
 39%|███▉      | 107/276 [00:01<00:02, 74.66it/s][A
 42%|████▏     | 115/276 [00:01<00:02, 73.85it/s][A
 45%|████▍     | 123/276 [00:01<00:02, 73.12it/s][A
 47%|████▋     | 131/276 [00:01<00:01, 73.76it/s][A
 50%|█████     | 139/276 [00:01<00:01, 74.57it/s][A
 53%|█████▎    | 147/276 [00:01<00:01, 74.70it/s][A
 56%|█████▌    | 155/276 [00:02<00:01, 73.13it/s][A
 59%|█████▉    | 163/276 [00:02<00:01, 73.48it/s][A
 62%|██████▏   | 171/276 [00:02<00:01, 75.16it/s][A
 65%|██████▍   | 179/276 [00:02<00:01, 73.72it/s][A
 68%|██████▊   | 187/276 [00:02<00:01, 72.46it/s][A
 71%|███████   | 195/276 [00:02<00:01, 73.95it/s][A
 74%|███████▎  | 203/276 [00:02<00:00, 74.67it/s][A
 76%|███████▋  | 211/276 [00:02<00:00, 74.37it/s][A
 79%|███████▉  | 219/276 [00:02<00:00, 72.65it/s][A
 82%|████████▏ | 227/276 [00:03<00:00, 73.35it/s][A
 85%|████████▌ | 235/276 [00:03<00:00, 74.01it/s][A
 88%|████████▊ | 243/276 [00:03<00:00, 73.84it/s][A
 91%|█████████ | 251/276 [00:03<00:00, 72.62it/s][A
 94%|█████████▍| 259/276 [00:03<00:00, 72.86it/s][A
 97%|█████████▋| 267/276 [00:03<00:00, 74.01it/s][A
100%|█████████▉| 275/276 [00:03<00:00, 74.23it/s][A                                                  
                                                 [A 40%|████      | 552/1380 [01:08<01:29,  9.21it/s]
100%|██████████| 276/276 [00:03<00:00, 74.23it/s][A
                                                 [A 40%|████      | 553/1380 [01:08<13:27,  1.02it/s] 40%|████      | 554/1380 [01:09<10:29,  1.31it/s] 40%|████      | 555/1380 [01:09<08:09,  1.69it/s] 40%|████      | 556/1380 [01:09<06:20,  2.17it/s] 40%|████      | 557/1380 [01:09<04:59,  2.75it/s] 40%|████      | 558/1380 [01:09<03:59,  3.44it/s] 41%|████      | 559/1380 [01:09<03:16,  4.19it/s] 41%|████      | 560/1380 [01:09<02:44,  4.99it/s] 41%|████      | 561/1380 [01:09<02:21,  5.78it/s] 41%|████      | 562/1380 [01:09<02:06,  6.45it/s] 41%|████      | 563/1380 [01:10<01:55,  7.08it/s] 41%|████      | 564/1380 [01:10<01:47,  7.60it/s] 41%|████      | 565/1380 [01:10<01:41,  8.04it/s] 41%|████      | 566/1380 [01:10<01:38,  8.26it/s] 41%|████      | 567/1380 [01:10<01:36,  8.47it/s] 41%|████      | 568/1380 [01:10<01:33,  8.69it/s] 41%|████      | 569/1380 [01:10<01:32,  8.81it/s] 41%|████▏     | 570/1380 [01:10<01:31,  8.89it/s] 41%|████▏     | 571/1380 [01:10<01:30,  8.95it/s] 41%|████▏     | 572/1380 [01:11<01:30,  8.97it/s] 42%|████▏     | 573/1380 [01:11<01:29,  9.01it/s] 42%|████▏     | 574/1380 [01:11<01:29,  9.02it/s] 42%|████▏     | 575/1380 [01:11<01:29,  9.01it/s] 42%|████▏     | 576/1380 [01:11<01:28,  9.08it/s] 42%|████▏     | 577/1380 [01:11<01:28,  9.12it/s] 42%|████▏     | 578/1380 [01:11<01:28,  9.06it/s] 42%|████▏     | 579/1380 [01:11<01:29,  8.98it/s] 42%|████▏     | 580/1380 [01:11<01:28,  9.08it/s] 42%|████▏     | 581/1380 [01:12<01:27,  9.12it/s] 42%|████▏     | 582/1380 [01:12<01:28,  9.02it/s] 42%|████▏     | 583/1380 [01:12<01:27,  9.07it/s] 42%|████▏     | 584/1380 [01:12<01:27,  9.15it/s] 42%|████▏     | 585/1380 [01:12<01:27,  9.08it/s] 42%|████▏     | 586/1380 [01:12<01:27,  9.06it/s] 43%|████▎     | 587/1380 [01:12<01:27,  9.10it/s] 43%|████▎     | 588/1380 [01:12<01:26,  9.15it/s] 43%|████▎     | 589/1380 [01:12<01:26,  9.11it/s] 43%|████▎     | 590/1380 [01:13<01:26,  9.08it/s] 43%|████▎     | 591/1380 [01:13<01:26,  9.14it/s] 43%|████▎     | 592/1380 [01:13<01:26,  9.14it/s] 43%|████▎     | 593/1380 [01:13<01:25,  9.15it/s] 43%|████▎     | 594/1380 [01:13<01:27,  9.00it/s] 43%|████▎     | 595/1380 [01:13<01:26,  9.12it/s] 43%|████▎     | 596/1380 [01:13<01:25,  9.18it/s] 43%|████▎     | 597/1380 [01:13<01:25,  9.13it/s] 43%|████▎     | 598/1380 [01:13<01:26,  9.04it/s] 43%|████▎     | 599/1380 [01:14<01:25,  9.15it/s] 43%|████▎     | 600/1380 [01:14<01:24,  9.19it/s] 44%|████▎     | 601/1380 [01:14<01:25,  9.12it/s] 44%|████▎     | 602/1380 [01:14<01:25,  9.07it/s] 44%|████▎     | 603/1380 [01:14<01:25,  9.12it/s] 44%|████▍     | 604/1380 [01:14<01:24,  9.15it/s] 44%|████▍     | 605/1380 [01:14<01:25,  9.11it/s] 44%|████▍     | 606/1380 [01:14<01:24,  9.11it/s] 44%|████▍     | 607/1380 [01:14<01:24,  9.14it/s] 44%|████▍     | 608/1380 [01:15<01:24,  9.14it/s] 44%|████▍     | 609/1380 [01:15<01:24,  9.15it/s] 44%|████▍     | 610/1380 [01:15<01:24,  9.11it/s] 44%|████▍     | 611/1380 [01:15<01:24,  9.12it/s] 44%|████▍     | 612/1380 [01:15<01:24,  9.14it/s] 44%|████▍     | 613/1380 [01:15<01:24,  9.11it/s] 44%|████▍     | 614/1380 [01:15<01:23,  9.14it/s] 45%|████▍     | 615/1380 [01:15<01:22,  9.22it/s] 45%|████▍     | 616/1380 [01:15<01:23,  9.14it/s] 45%|████▍     | 617/1380 [01:16<01:23,  9.09it/s] 45%|████▍     | 618/1380 [01:16<01:23,  9.18it/s] 45%|████▍     | 619/1380 [01:16<01:23,  9.16it/s] 45%|████▍     | 620/1380 [01:16<01:23,  9.10it/s] 45%|████▌     | 621/1380 [01:16<01:23,  9.09it/s] 45%|████▌     | 622/1380 [01:16<01:22,  9.19it/s] 45%|████▌     | 623/1380 [01:16<01:22,  9.15it/s] 45%|████▌     | 624/1380 [01:16<01:23,  9.09it/s] 45%|████▌     | 625/1380 [01:16<01:23,  9.09it/s] 45%|████▌     | 626/1380 [01:17<01:22,  9.17it/s] 45%|████▌     | 627/1380 [01:17<01:22,  9.12it/s] 46%|████▌     | 628/1380 [01:17<01:22,  9.06it/s] 46%|████▌     | 629/1380 [01:17<01:22,  9.13it/s] 46%|████▌     | 630/1380 [01:17<01:22,  9.14it/s] 46%|████▌     | 631/1380 [01:17<01:21,  9.20it/s] 46%|████▌     | 632/1380 [01:17<01:21,  9.15it/s] 46%|████▌     | 633/1380 [01:17<01:21,  9.15it/s] 46%|████▌     | 634/1380 [01:17<01:21,  9.18it/s] 46%|████▌     | 635/1380 [01:17<01:20,  9.21it/s] 46%|████▌     | 636/1380 [01:18<01:21,  9.08it/s] 46%|████▌     | 637/1380 [01:18<01:21,  9.12it/s] 46%|████▌     | 638/1380 [01:18<01:21,  9.14it/s] 46%|████▋     | 639/1380 [01:18<01:20,  9.18it/s] 46%|████▋     | 640/1380 [01:18<01:20,  9.14it/s] 46%|████▋     | 641/1380 [01:18<01:20,  9.20it/s] 47%|████▋     | 642/1380 [01:18<01:20,  9.22it/s] 47%|████▋     | 643/1380 [01:18<01:20,  9.17it/s] 47%|████▋     | 644/1380 [01:18<01:20,  9.15it/s] 47%|████▋     | 645/1380 [01:19<01:20,  9.16it/s] 47%|████▋     | 646/1380 [01:19<01:20,  9.15it/s] 47%|████▋     | 647/1380 [01:19<01:20,  9.16it/s] 47%|████▋     | 648/1380 [01:19<01:20,  9.07it/s] 47%|████▋     | 649/1380 [01:19<01:20,  9.10it/s] 47%|████▋     | 650/1380 [01:19<01:19,  9.15it/s] 47%|████▋     | 651/1380 [01:19<01:20,  9.11it/s] 47%|████▋     | 652/1380 [01:19<01:20,  9.00it/s] 47%|████▋     | 653/1380 [01:19<01:19,  9.10it/s] 47%|████▋     | 654/1380 [01:20<01:19,  9.15it/s] 47%|████▋     | 655/1380 [01:20<01:19,  9.09it/s] 48%|████▊     | 656/1380 [01:20<01:20,  9.03it/s] 48%|████▊     | 657/1380 [01:20<01:19,  9.05it/s] 48%|████▊     | 658/1380 [01:20<01:19,  9.10it/s] 48%|████▊     | 659/1380 [01:20<01:20,  9.01it/s] 48%|████▊     | 660/1380 [01:20<01:20,  9.00it/s] 48%|████▊     | 661/1380 [01:20<01:19,  9.09it/s] 48%|████▊     | 662/1380 [01:20<01:19,  9.06it/s] 48%|████▊     | 663/1380 [01:21<01:19,  9.04it/s] 48%|████▊     | 664/1380 [01:21<01:19,  9.04it/s] 48%|████▊     | 665/1380 [01:21<01:18,  9.09it/s] 48%|████▊     | 666/1380 [01:21<01:17,  9.16it/s] 48%|████▊     | 667/1380 [01:21<01:18,  9.10it/s] 48%|████▊     | 668/1380 [01:21<01:18,  9.01it/s] 48%|████▊     | 669/1380 [01:21<01:18,  9.08it/s] 49%|████▊     | 670/1380 [01:21<01:18,  9.00it/s] 49%|████▊     | 671/1380 [01:21<01:19,  8.95it/s] 49%|████▊     | 672/1380 [01:22<01:18,  9.00it/s] 49%|████▉     | 673/1380 [01:22<01:18,  8.99it/s] 49%|████▉     | 674/1380 [01:22<01:18,  8.99it/s] 49%|████▉     | 675/1380 [01:22<01:18,  8.96it/s] 49%|████▉     | 676/1380 [01:22<01:17,  9.06it/s] 49%|████▉     | 677/1380 [01:22<01:17,  9.02it/s] 49%|████▉     | 678/1380 [01:22<01:17,  9.01it/s] 49%|████▉     | 679/1380 [01:22<01:17,  9.03it/s] 49%|████▉     | 680/1380 [01:22<01:17,  9.02it/s] 49%|████▉     | 681/1380 [01:23<01:17,  9.02it/s] 49%|████▉     | 682/1380 [01:23<01:16,  9.08it/s] 49%|████▉     | 683/1380 [01:23<01:17,  9.04it/s] 50%|████▉     | 684/1380 [01:23<01:17,  9.00it/s] 50%|████▉     | 685/1380 [01:23<01:16,  9.12it/s] 50%|████▉     | 686/1380 [01:23<01:15,  9.15it/s] 50%|████▉     | 687/1380 [01:23<01:16,  9.08it/s] 50%|████▉     | 688/1380 [01:23<01:16,  9.09it/s] 50%|████▉     | 689/1380 [01:23<01:15,  9.12it/s] 50%|█████     | 690/1380 [01:24<01:15,  9.18it/s] 50%|█████     | 691/1380 [01:24<01:14,  9.20it/s] 50%|█████     | 692/1380 [01:24<01:15,  9.10it/s] 50%|█████     | 693/1380 [01:24<01:15,  9.10it/s] 50%|█████     | 694/1380 [01:24<01:15,  9.09it/s] 50%|█████     | 695/1380 [01:24<01:15,  9.12it/s] 50%|█████     | 696/1380 [01:24<01:15,  9.03it/s] 51%|█████     | 697/1380 [01:24<01:15,  9.02it/s] 51%|█████     | 698/1380 [01:24<01:14,  9.19it/s] 51%|█████     | 699/1380 [01:25<01:14,  9.12it/s] 51%|█████     | 700/1380 [01:25<01:15,  9.04it/s] 51%|█████     | 701/1380 [01:25<01:15,  9.02it/s] 51%|█████     | 702/1380 [01:25<01:14,  9.06it/s] 51%|█████     | 703/1380 [01:25<01:14,  9.06it/s] 51%|█████     | 704/1380 [01:25<01:15,  8.96it/s] 51%|█████     | 705/1380 [01:25<01:15,  8.99it/s] 51%|█████     | 706/1380 [01:25<01:14,  9.02it/s] 51%|█████     | 707/1380 [01:25<01:14,  9.03it/s] 51%|█████▏    | 708/1380 [01:26<01:14,  9.01it/s] 51%|█████▏    | 709/1380 [01:26<01:14,  9.01it/s] 51%|█████▏    | 710/1380 [01:26<01:14,  9.04it/s] 52%|█████▏    | 711/1380 [01:26<01:12,  9.18it/s] 52%|█████▏    | 712/1380 [01:26<01:13,  9.07it/s] 52%|█████▏    | 713/1380 [01:26<01:13,  9.05it/s] 52%|█████▏    | 714/1380 [01:26<01:13,  9.05it/s] 52%|█████▏    | 715/1380 [01:26<01:12,  9.14it/s] 52%|█████▏    | 716/1380 [01:26<01:13,  9.09it/s] 52%|█████▏    | 717/1380 [01:27<01:12,  9.10it/s] 52%|█████▏    | 718/1380 [01:27<01:13,  9.00it/s] 52%|█████▏    | 719/1380 [01:27<01:13,  9.05it/s] 52%|█████▏    | 720/1380 [01:27<01:13,  8.97it/s] 52%|█████▏    | 721/1380 [01:27<01:13,  9.02it/s] 52%|█████▏    | 722/1380 [01:27<01:12,  9.02it/s] 52%|█████▏    | 723/1380 [01:27<01:12,  9.04it/s] 52%|█████▏    | 724/1380 [01:27<01:12,  9.10it/s] 53%|█████▎    | 725/1380 [01:27<01:12,  9.04it/s] 53%|█████▎    | 726/1380 [01:28<01:12,  9.01it/s] 53%|█████▎    | 727/1380 [01:28<01:12,  9.02it/s] 53%|█████▎    | 728/1380 [01:28<01:11,  9.06it/s] 53%|█████▎    | 729/1380 [01:28<01:11,  9.06it/s] 53%|█████▎    | 730/1380 [01:28<01:12,  9.02it/s] 53%|█████▎    | 731/1380 [01:28<01:12,  8.90it/s] 53%|█████▎    | 732/1380 [01:28<01:11,  9.05it/s] 53%|█████▎    | 733/1380 [01:28<01:11,  9.10it/s] 53%|█████▎    | 734/1380 [01:28<01:10,  9.11it/s] 53%|█████▎    | 735/1380 [01:29<01:11,  9.03it/s] 53%|█████▎    | 736/1380 [01:29<01:11,  8.96it/s] 53%|█████▎    | 737/1380 [01:29<01:11,  9.05it/s] 53%|█████▎    | 738/1380 [01:29<01:11,  9.02it/s] 54%|█████▎    | 739/1380 [01:29<01:11,  8.98it/s] 54%|█████▎    | 740/1380 [01:29<01:11,  8.90it/s] 54%|█████▎    | 741/1380 [01:29<01:11,  8.99it/s] 54%|█████▍    | 742/1380 [01:29<01:10,  9.04it/s] 54%|█████▍    | 743/1380 [01:29<01:10,  9.01it/s] 54%|█████▍    | 744/1380 [01:30<01:10,  8.96it/s] 54%|█████▍    | 745/1380 [01:30<01:10,  8.96it/s] 54%|█████▍    | 746/1380 [01:30<01:10,  8.95it/s] 54%|█████▍    | 747/1380 [01:30<01:10,  9.02it/s] 54%|█████▍    | 748/1380 [01:30<01:10,  8.97it/s] 54%|█████▍    | 749/1380 [01:30<01:10,  9.00it/s] 54%|█████▍    | 750/1380 [01:30<01:09,  9.05it/s] 54%|█████▍    | 751/1380 [01:30<01:09,  9.06it/s] 54%|█████▍    | 752/1380 [01:30<01:09,  9.05it/s] 55%|█████▍    | 753/1380 [01:31<01:09,  8.98it/s] 55%|█████▍    | 754/1380 [01:31<01:09,  8.97it/s] 55%|█████▍    | 755/1380 [01:31<01:09,  9.03it/s] 55%|█████▍    | 756/1380 [01:31<01:09,  8.98it/s] 55%|█████▍    | 757/1380 [01:31<01:08,  9.05it/s] 55%|█████▍    | 758/1380 [01:31<01:09,  8.97it/s] 55%|█████▌    | 759/1380 [01:31<01:09,  8.99it/s] 55%|█████▌    | 760/1380 [01:31<01:08,  9.10it/s] 55%|█████▌    | 761/1380 [01:31<01:08,  9.09it/s] 55%|█████▌    | 762/1380 [01:32<01:08,  9.06it/s] 55%|█████▌    | 763/1380 [01:32<01:08,  9.00it/s] 55%|█████▌    | 764/1380 [01:32<01:08,  8.98it/s] 55%|█████▌    | 765/1380 [01:32<01:08,  9.01it/s] 56%|█████▌    | 766/1380 [01:32<01:07,  9.05it/s] 56%|█████▌    | 767/1380 [01:32<01:07,  9.02it/s] 56%|█████▌    | 768/1380 [01:32<01:08,  8.99it/s] 56%|█████▌    | 769/1380 [01:32<01:07,  8.99it/s] 56%|█████▌    | 770/1380 [01:32<01:07,  9.05it/s] 56%|█████▌    | 771/1380 [01:33<01:07,  9.08it/s] 56%|█████▌    | 772/1380 [01:33<01:06,  9.08it/s] 56%|█████▌    | 773/1380 [01:33<01:07,  8.96it/s] 56%|█████▌    | 774/1380 [01:33<01:07,  9.02it/s] 56%|█████▌    | 775/1380 [01:33<01:06,  9.04it/s] 56%|█████▌    | 776/1380 [01:33<01:07,  8.99it/s] 56%|█████▋    | 777/1380 [01:33<01:07,  8.98it/s] 56%|█████▋    | 778/1380 [01:33<01:06,  8.99it/s] 56%|█████▋    | 779/1380 [01:33<01:06,  9.03it/s] 57%|█████▋    | 780/1380 [01:34<01:06,  9.03it/s] 57%|█████▋    | 781/1380 [01:34<01:06,  9.03it/s] 57%|█████▋    | 782/1380 [01:34<01:06,  9.02it/s] 57%|█████▋    | 783/1380 [01:34<01:05,  9.07it/s] 57%|█████▋    | 784/1380 [01:34<01:05,  9.06it/s] 57%|█████▋    | 785/1380 [01:34<01:05,  9.05it/s] 57%|█████▋    | 786/1380 [01:34<01:05,  9.00it/s] 57%|█████▋    | 787/1380 [01:34<01:06,  8.97it/s] 57%|█████▋    | 788/1380 [01:34<01:05,  9.04it/s] 57%|█████▋    | 789/1380 [01:35<01:05,  9.03it/s] 57%|█████▋    | 790/1380 [01:35<01:05,  9.00it/s] 57%|█████▋    | 791/1380 [01:35<01:05,  8.97it/s] 57%|█████▋    | 792/1380 [01:35<01:05,  9.00it/s] 57%|█████▋    | 793/1380 [01:35<01:04,  9.10it/s] 58%|█████▊    | 794/1380 [01:35<01:04,  9.05it/s] 58%|█████▊    | 795/1380 [01:35<01:05,  8.99it/s] 58%|█████▊    | 796/1380 [01:35<01:05,  8.97it/s] 58%|█████▊    | 797/1380 [01:35<01:04,  9.01it/s] 58%|█████▊    | 798/1380 [01:36<01:04,  8.98it/s] 58%|█████▊    | 799/1380 [01:36<01:04,  8.97it/s] 58%|█████▊    | 800/1380 [01:36<01:04,  8.98it/s] 58%|█████▊    | 801/1380 [01:36<01:04,  8.98it/s] 58%|█████▊    | 802/1380 [01:36<01:04,  9.01it/s] 58%|█████▊    | 803/1380 [01:36<01:03,  9.05it/s] 58%|█████▊    | 804/1380 [01:36<01:04,  8.99it/s] 58%|█████▊    | 805/1380 [01:36<01:04,  8.88it/s] 58%|█████▊    | 806/1380 [01:36<01:03,  8.98it/s] 58%|█████▊    | 807/1380 [01:37<01:03,  9.02it/s] 59%|█████▊    | 808/1380 [01:37<01:03,  8.96it/s] 59%|█████▊    | 809/1380 [01:37<01:03,  8.97it/s] 59%|█████▊    | 810/1380 [01:37<01:03,  8.94it/s] 59%|█████▉    | 811/1380 [01:37<01:03,  9.02it/s] 59%|█████▉    | 812/1380 [01:37<01:02,  9.04it/s] 59%|█████▉    | 813/1380 [01:37<01:02,  9.11it/s] 59%|█████▉    | 814/1380 [01:37<01:03,  8.98it/s] 59%|█████▉    | 815/1380 [01:37<01:03,  8.96it/s] 59%|█████▉    | 816/1380 [01:38<01:02,  9.01it/s] 59%|█████▉    | 817/1380 [01:38<01:02,  9.03it/s] 59%|█████▉    | 818/1380 [01:38<01:02,  8.99it/s] 59%|█████▉    | 819/1380 [01:38<01:02,  8.95it/s] 59%|█████▉    | 820/1380 [01:38<01:02,  8.95it/s] 59%|█████▉    | 821/1380 [01:38<01:02,  8.89it/s] 60%|█████▉    | 822/1380 [01:38<01:02,  8.98it/s] 60%|█████▉    | 823/1380 [01:38<01:01,  8.99it/s] 60%|█████▉    | 824/1380 [01:38<01:02,  8.96it/s] 60%|█████▉    | 825/1380 [01:39<01:02,  8.91it/s] 60%|█████▉    | 826/1380 [01:39<01:01,  9.04it/s] 60%|█████▉    | 827/1380 [01:39<01:01,  8.98it/s]                                                   60%|██████    | 828/1380 [01:39<01:01,  8.98it/s][INFO|trainer.py:755] 2023-11-15 21:29:31,918 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:29:31,919 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:29:31,920 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:29:31,920 >>   Batch size = 8
{'eval_loss': 0.3868441581726074, 'eval_accuracy': 0.8493647912885662, 'eval_micro_f1': 0.8493647912885661, 'eval_macro_f1': 0.8409975613370338, 'eval_runtime': 3.7909, 'eval_samples_per_second': 581.385, 'eval_steps_per_second': 72.805, 'epoch': 2.0}
{'loss': 0.247, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 78.97it/s][A
  6%|▌         | 17/276 [00:00<00:03, 74.22it/s][A
  9%|▉         | 25/276 [00:00<00:03, 74.72it/s][A
 12%|█▏        | 33/276 [00:00<00:03, 73.25it/s][A
 15%|█▍        | 41/276 [00:00<00:03, 73.62it/s][A
 18%|█▊        | 49/276 [00:00<00:03, 72.17it/s][A
 21%|██        | 57/276 [00:00<00:03, 71.78it/s][A
 24%|██▎       | 65/276 [00:00<00:02, 71.48it/s][A
 26%|██▋       | 73/276 [00:01<00:02, 72.23it/s][A
 29%|██▉       | 81/276 [00:01<00:02, 71.79it/s][A
 32%|███▏      | 89/276 [00:01<00:02, 70.71it/s][A
 35%|███▌      | 97/276 [00:01<00:02, 71.15it/s][A
 38%|███▊      | 105/276 [00:01<00:02, 71.31it/s][A
 41%|████      | 113/276 [00:01<00:02, 70.86it/s][A
 44%|████▍     | 121/276 [00:01<00:02, 72.84it/s][A
 47%|████▋     | 129/276 [00:01<00:02, 71.39it/s][A
 50%|████▉     | 137/276 [00:01<00:01, 70.90it/s][A
 53%|█████▎    | 145/276 [00:02<00:01, 71.09it/s][A
 55%|█████▌    | 153/276 [00:02<00:01, 72.41it/s][A
 58%|█████▊    | 161/276 [00:02<00:01, 71.87it/s][A
 61%|██████    | 169/276 [00:02<00:01, 71.43it/s][A
 64%|██████▍   | 177/276 [00:02<00:01, 70.81it/s][A
 67%|██████▋   | 185/276 [00:02<00:01, 72.37it/s][A
 70%|██████▉   | 193/276 [00:02<00:01, 71.95it/s][A
 73%|███████▎  | 201/276 [00:02<00:01, 72.70it/s][A
 76%|███████▌  | 209/276 [00:02<00:00, 70.75it/s][A
 79%|███████▊  | 217/276 [00:03<00:00, 70.33it/s][A
 82%|████████▏ | 225/276 [00:03<00:00, 70.69it/s][A
 84%|████████▍ | 233/276 [00:03<00:00, 71.77it/s][A
 87%|████████▋ | 241/276 [00:03<00:00, 71.12it/s][A
 90%|█████████ | 249/276 [00:03<00:00, 69.62it/s][A
 93%|█████████▎| 257/276 [00:03<00:00, 70.66it/s][A
 96%|█████████▌| 265/276 [00:03<00:00, 70.98it/s][A
 99%|█████████▉| 273/276 [00:03<00:00, 71.42it/s][A                                                  
                                                 [A 60%|██████    | 828/1380 [01:43<01:01,  8.98it/s]
100%|██████████| 276/276 [00:03<00:00, 71.42it/s][A
                                                 [A 60%|██████    | 829/1380 [01:43<09:15,  1.01s/it] 60%|██████    | 830/1380 [01:43<07:12,  1.27it/s] 60%|██████    | 831/1380 [01:43<05:35,  1.64it/s] 60%|██████    | 832/1380 [01:43<04:20,  2.10it/s] 60%|██████    | 833/1380 [01:43<03:24,  2.67it/s] 60%|██████    | 834/1380 [01:43<02:44,  3.33it/s] 61%|██████    | 835/1380 [01:44<02:13,  4.08it/s] 61%|██████    | 836/1380 [01:44<01:52,  4.82it/s] 61%|██████    | 837/1380 [01:44<01:36,  5.60it/s] 61%|██████    | 838/1380 [01:44<01:25,  6.31it/s] 61%|██████    | 839/1380 [01:44<01:18,  6.92it/s] 61%|██████    | 840/1380 [01:44<01:12,  7.40it/s] 61%|██████    | 841/1380 [01:44<01:09,  7.77it/s] 61%|██████    | 842/1380 [01:44<01:06,  8.10it/s] 61%|██████    | 843/1380 [01:44<01:04,  8.37it/s] 61%|██████    | 844/1380 [01:45<01:03,  8.49it/s] 61%|██████    | 845/1380 [01:45<01:01,  8.68it/s] 61%|██████▏   | 846/1380 [01:45<01:01,  8.70it/s] 61%|██████▏   | 847/1380 [01:45<01:01,  8.74it/s] 61%|██████▏   | 848/1380 [01:45<00:59,  8.89it/s] 62%|██████▏   | 849/1380 [01:45<00:59,  8.88it/s] 62%|██████▏   | 850/1380 [01:45<00:59,  8.87it/s] 62%|██████▏   | 851/1380 [01:45<00:59,  8.86it/s] 62%|██████▏   | 852/1380 [01:45<00:59,  8.91it/s] 62%|██████▏   | 853/1380 [01:46<00:58,  8.95it/s] 62%|██████▏   | 854/1380 [01:46<00:58,  8.92it/s] 62%|██████▏   | 855/1380 [01:46<00:58,  8.95it/s] 62%|██████▏   | 856/1380 [01:46<00:58,  8.93it/s] 62%|██████▏   | 857/1380 [01:46<00:58,  8.91it/s] 62%|██████▏   | 858/1380 [01:46<00:58,  8.95it/s] 62%|██████▏   | 859/1380 [01:46<00:57,  8.98it/s] 62%|██████▏   | 860/1380 [01:46<00:58,  8.95it/s] 62%|██████▏   | 861/1380 [01:46<00:58,  8.92it/s] 62%|██████▏   | 862/1380 [01:47<00:57,  8.94it/s] 63%|██████▎   | 863/1380 [01:47<00:57,  8.94it/s] 63%|██████▎   | 864/1380 [01:47<00:57,  8.97it/s] 63%|██████▎   | 865/1380 [01:47<00:57,  8.92it/s] 63%|██████▎   | 866/1380 [01:47<00:57,  8.88it/s] 63%|██████▎   | 867/1380 [01:47<00:57,  8.92it/s] 63%|██████▎   | 868/1380 [01:47<00:57,  8.93it/s] 63%|██████▎   | 869/1380 [01:47<00:57,  8.95it/s] 63%|██████▎   | 870/1380 [01:47<00:57,  8.90it/s] 63%|██████▎   | 871/1380 [01:48<00:56,  8.96it/s] 63%|██████▎   | 872/1380 [01:48<00:56,  8.99it/s] 63%|██████▎   | 873/1380 [01:48<00:56,  9.01it/s] 63%|██████▎   | 874/1380 [01:48<00:56,  8.98it/s] 63%|██████▎   | 875/1380 [01:48<00:56,  8.93it/s] 63%|██████▎   | 876/1380 [01:48<00:56,  8.95it/s] 64%|██████▎   | 877/1380 [01:48<00:56,  8.98it/s] 64%|██████▎   | 878/1380 [01:48<00:55,  9.08it/s] 64%|██████▎   | 879/1380 [01:48<00:55,  8.95it/s] 64%|██████▍   | 880/1380 [01:49<00:55,  8.95it/s] 64%|██████▍   | 881/1380 [01:49<00:55,  8.99it/s] 64%|██████▍   | 882/1380 [01:49<00:55,  9.03it/s] 64%|██████▍   | 883/1380 [01:49<00:55,  8.97it/s] 64%|██████▍   | 884/1380 [01:49<00:55,  8.92it/s] 64%|██████▍   | 885/1380 [01:49<00:55,  8.90it/s] 64%|██████▍   | 886/1380 [01:49<00:55,  8.96it/s] 64%|██████▍   | 887/1380 [01:49<00:55,  8.93it/s] 64%|██████▍   | 888/1380 [01:49<00:54,  9.00it/s] 64%|██████▍   | 889/1380 [01:50<00:55,  8.91it/s] 64%|██████▍   | 890/1380 [01:50<00:54,  8.92it/s] 65%|██████▍   | 891/1380 [01:50<00:54,  9.00it/s] 65%|██████▍   | 892/1380 [01:50<00:54,  9.00it/s] 65%|██████▍   | 893/1380 [01:50<00:54,  8.93it/s] 65%|██████▍   | 894/1380 [01:50<00:54,  8.91it/s] 65%|██████▍   | 895/1380 [01:50<00:54,  8.95it/s] 65%|██████▍   | 896/1380 [01:50<00:54,  8.90it/s] 65%|██████▌   | 897/1380 [01:50<00:54,  8.86it/s] 65%|██████▌   | 898/1380 [01:51<00:54,  8.85it/s] 65%|██████▌   | 899/1380 [01:51<00:53,  8.91it/s] 65%|██████▌   | 900/1380 [01:51<00:53,  8.93it/s] 65%|██████▌   | 901/1380 [01:51<00:52,  9.05it/s] 65%|██████▌   | 902/1380 [01:51<00:53,  8.95it/s] 65%|██████▌   | 903/1380 [01:51<00:53,  8.96it/s] 66%|██████▌   | 904/1380 [01:51<00:52,  8.98it/s] 66%|██████▌   | 905/1380 [01:51<00:52,  8.98it/s] 66%|██████▌   | 906/1380 [01:51<00:52,  8.95it/s] 66%|██████▌   | 907/1380 [01:52<00:52,  8.99it/s] 66%|██████▌   | 908/1380 [01:52<00:52,  8.95it/s] 66%|██████▌   | 909/1380 [01:52<00:52,  8.96it/s] 66%|██████▌   | 910/1380 [01:52<00:52,  8.97it/s] 66%|██████▌   | 911/1380 [01:52<00:52,  8.97it/s] 66%|██████▌   | 912/1380 [01:52<00:52,  8.87it/s] 66%|██████▌   | 913/1380 [01:52<00:52,  8.92it/s] 66%|██████▌   | 914/1380 [01:52<00:51,  9.00it/s] 66%|██████▋   | 915/1380 [01:52<00:51,  9.01it/s] 66%|██████▋   | 916/1380 [01:53<00:51,  8.99it/s] 66%|██████▋   | 917/1380 [01:53<00:51,  8.97it/s] 67%|██████▋   | 918/1380 [01:53<00:52,  8.87it/s] 67%|██████▋   | 919/1380 [01:53<00:51,  8.97it/s] 67%|██████▋   | 920/1380 [01:53<00:51,  8.94it/s] 67%|██████▋   | 921/1380 [01:53<00:50,  9.02it/s] 67%|██████▋   | 922/1380 [01:53<00:50,  8.98it/s] 67%|██████▋   | 923/1380 [01:53<00:50,  8.99it/s] 67%|██████▋   | 924/1380 [01:53<00:50,  9.04it/s] 67%|██████▋   | 925/1380 [01:54<00:50,  8.93it/s] 67%|██████▋   | 926/1380 [01:54<00:50,  9.00it/s] 67%|██████▋   | 927/1380 [01:54<00:50,  8.97it/s] 67%|██████▋   | 928/1380 [01:54<00:50,  8.93it/s] 67%|██████▋   | 929/1380 [01:54<00:50,  8.89it/s] 67%|██████▋   | 930/1380 [01:54<00:50,  8.90it/s] 67%|██████▋   | 931/1380 [01:54<00:50,  8.89it/s] 68%|██████▊   | 932/1380 [01:54<00:50,  8.85it/s] 68%|██████▊   | 933/1380 [01:54<00:50,  8.84it/s] 68%|██████▊   | 934/1380 [01:55<00:49,  8.94it/s] 68%|██████▊   | 935/1380 [01:55<00:49,  8.96it/s] 68%|██████▊   | 936/1380 [01:55<00:50,  8.83it/s] 68%|██████▊   | 937/1380 [01:55<00:50,  8.84it/s] 68%|██████▊   | 938/1380 [01:55<00:49,  8.91it/s] 68%|██████▊   | 939/1380 [01:55<00:49,  8.92it/s] 68%|██████▊   | 940/1380 [01:55<00:49,  8.85it/s] 68%|██████▊   | 941/1380 [01:55<00:49,  8.82it/s] 68%|██████▊   | 942/1380 [01:56<00:49,  8.86it/s] 68%|██████▊   | 943/1380 [01:56<00:48,  8.94it/s] 68%|██████▊   | 944/1380 [01:56<00:48,  9.00it/s] 68%|██████▊   | 945/1380 [01:56<00:48,  8.99it/s] 69%|██████▊   | 946/1380 [01:56<00:48,  8.98it/s] 69%|██████▊   | 947/1380 [01:56<00:48,  8.93it/s] 69%|██████▊   | 948/1380 [01:56<00:48,  8.94it/s] 69%|██████▉   | 949/1380 [01:56<00:48,  8.94it/s] 69%|██████▉   | 950/1380 [01:56<00:47,  8.98it/s] 69%|██████▉   | 951/1380 [01:57<00:48,  8.91it/s] 69%|██████▉   | 952/1380 [01:57<00:47,  8.96it/s] 69%|██████▉   | 953/1380 [01:57<00:47,  8.96it/s] 69%|██████▉   | 954/1380 [01:57<00:47,  8.99it/s] 69%|██████▉   | 955/1380 [01:57<00:47,  8.93it/s] 69%|██████▉   | 956/1380 [01:57<00:47,  8.87it/s] 69%|██████▉   | 957/1380 [01:57<00:47,  8.96it/s] 69%|██████▉   | 958/1380 [01:57<00:47,  8.97it/s] 69%|██████▉   | 959/1380 [01:57<00:46,  8.97it/s] 70%|██████▉   | 960/1380 [01:58<00:47,  8.89it/s] 70%|██████▉   | 961/1380 [01:58<00:47,  8.89it/s] 70%|██████▉   | 962/1380 [01:58<00:46,  8.93it/s] 70%|██████▉   | 963/1380 [01:58<00:46,  8.96it/s] 70%|██████▉   | 964/1380 [01:58<00:46,  8.96it/s] 70%|██████▉   | 965/1380 [01:58<00:46,  8.91it/s] 70%|███████   | 966/1380 [01:58<00:46,  8.86it/s] 70%|███████   | 967/1380 [01:58<00:46,  8.93it/s] 70%|███████   | 968/1380 [01:58<00:46,  8.95it/s] 70%|███████   | 969/1380 [01:59<00:46,  8.86it/s] 70%|███████   | 970/1380 [01:59<00:45,  8.92it/s] 70%|███████   | 971/1380 [01:59<00:45,  8.91it/s] 70%|███████   | 972/1380 [01:59<00:45,  8.94it/s] 71%|███████   | 973/1380 [01:59<00:45,  8.97it/s] 71%|███████   | 974/1380 [01:59<00:45,  9.00it/s] 71%|███████   | 975/1380 [01:59<00:45,  8.87it/s] 71%|███████   | 976/1380 [01:59<00:45,  8.86it/s] 71%|███████   | 977/1380 [01:59<00:44,  8.98it/s] 71%|███████   | 978/1380 [02:00<00:44,  8.95it/s] 71%|███████   | 979/1380 [02:00<00:44,  8.92it/s] 71%|███████   | 980/1380 [02:00<00:44,  8.94it/s] 71%|███████   | 981/1380 [02:00<00:44,  9.01it/s] 71%|███████   | 982/1380 [02:00<00:43,  9.05it/s] 71%|███████   | 983/1380 [02:00<00:43,  9.04it/s] 71%|███████▏  | 984/1380 [02:00<00:43,  9.04it/s] 71%|███████▏  | 985/1380 [02:00<00:44,  8.94it/s] 71%|███████▏  | 986/1380 [02:00<00:43,  8.98it/s] 72%|███████▏  | 987/1380 [02:01<00:43,  9.08it/s] 72%|███████▏  | 988/1380 [02:01<00:43,  9.06it/s] 72%|███████▏  | 989/1380 [02:01<00:43,  9.02it/s] 72%|███████▏  | 990/1380 [02:01<00:43,  8.99it/s] 72%|███████▏  | 991/1380 [02:01<00:43,  9.03it/s] 72%|███████▏  | 992/1380 [02:01<00:43,  9.02it/s] 72%|███████▏  | 993/1380 [02:01<00:43,  9.00it/s] 72%|███████▏  | 994/1380 [02:01<00:42,  9.00it/s] 72%|███████▏  | 995/1380 [02:01<00:42,  8.98it/s] 72%|███████▏  | 996/1380 [02:02<00:42,  9.01it/s] 72%|███████▏  | 997/1380 [02:02<00:42,  9.10it/s] 72%|███████▏  | 998/1380 [02:02<00:42,  9.06it/s] 72%|███████▏  | 999/1380 [02:02<00:42,  8.94it/s] 72%|███████▏  | 1000/1380 [02:02<00:42,  8.97it/s] 73%|███████▎  | 1001/1380 [02:02<00:42,  8.98it/s] 73%|███████▎  | 1002/1380 [02:02<00:42,  8.95it/s] 73%|███████▎  | 1003/1380 [02:02<00:42,  8.89it/s] 73%|███████▎  | 1004/1380 [02:02<00:42,  8.88it/s] 73%|███████▎  | 1005/1380 [02:03<00:41,  8.99it/s] 73%|███████▎  | 1006/1380 [02:03<00:41,  8.99it/s] 73%|███████▎  | 1007/1380 [02:03<00:41,  9.06it/s] 73%|███████▎  | 1008/1380 [02:03<00:41,  8.95it/s] 73%|███████▎  | 1009/1380 [02:03<00:41,  8.97it/s] 73%|███████▎  | 1010/1380 [02:03<00:41,  9.00it/s] 73%|███████▎  | 1011/1380 [02:03<00:40,  9.02it/s] 73%|███████▎  | 1012/1380 [02:03<00:41,  8.96it/s] 73%|███████▎  | 1013/1380 [02:03<00:41,  8.95it/s] 73%|███████▎  | 1014/1380 [02:04<00:40,  8.99it/s] 74%|███████▎  | 1015/1380 [02:04<00:40,  9.00it/s] 74%|███████▎  | 1016/1380 [02:04<00:40,  8.98it/s] 74%|███████▎  | 1017/1380 [02:04<00:40,  8.96it/s] 74%|███████▍  | 1018/1380 [02:04<00:40,  8.96it/s] 74%|███████▍  | 1019/1380 [02:04<00:40,  9.00it/s] 74%|███████▍  | 1020/1380 [02:04<00:39,  9.06it/s] 74%|███████▍  | 1021/1380 [02:04<00:39,  8.99it/s] 74%|███████▍  | 1022/1380 [02:04<00:40,  8.95it/s] 74%|███████▍  | 1023/1380 [02:05<00:39,  8.97it/s] 74%|███████▍  | 1024/1380 [02:05<00:39,  8.98it/s] 74%|███████▍  | 1025/1380 [02:05<00:39,  9.00it/s] 74%|███████▍  | 1026/1380 [02:05<00:39,  8.86it/s] 74%|███████▍  | 1027/1380 [02:05<00:39,  8.88it/s] 74%|███████▍  | 1028/1380 [02:05<00:39,  9.00it/s] 75%|███████▍  | 1029/1380 [02:05<00:38,  9.05it/s] 75%|███████▍  | 1030/1380 [02:05<00:38,  9.06it/s] 75%|███████▍  | 1031/1380 [02:05<00:39,  8.95it/s] 75%|███████▍  | 1032/1380 [02:06<00:38,  8.95it/s] 75%|███████▍  | 1033/1380 [02:06<00:38,  9.02it/s] 75%|███████▍  | 1034/1380 [02:06<00:38,  9.00it/s] 75%|███████▌  | 1035/1380 [02:06<00:38,  8.90it/s] 75%|███████▌  | 1036/1380 [02:06<00:38,  8.88it/s] 75%|███████▌  | 1037/1380 [02:06<00:38,  8.92it/s] 75%|███████▌  | 1038/1380 [02:06<00:38,  8.91it/s] 75%|███████▌  | 1039/1380 [02:06<00:38,  8.92it/s] 75%|███████▌  | 1040/1380 [02:06<00:38,  8.87it/s] 75%|███████▌  | 1041/1380 [02:07<00:38,  8.87it/s] 76%|███████▌  | 1042/1380 [02:07<00:37,  8.94it/s] 76%|███████▌  | 1043/1380 [02:07<00:37,  8.99it/s] 76%|███████▌  | 1044/1380 [02:07<00:37,  8.95it/s] 76%|███████▌  | 1045/1380 [02:07<00:37,  8.93it/s] 76%|███████▌  | 1046/1380 [02:07<00:37,  8.93it/s] 76%|███████▌  | 1047/1380 [02:07<00:37,  8.95it/s] 76%|███████▌  | 1048/1380 [02:07<00:37,  8.92it/s] 76%|███████▌  | 1049/1380 [02:07<00:37,  8.89it/s] 76%|███████▌  | 1050/1380 [02:08<00:37,  8.90it/s] 76%|███████▌  | 1051/1380 [02:08<00:36,  8.94it/s] 76%|███████▌  | 1052/1380 [02:08<00:36,  8.92it/s] 76%|███████▋  | 1053/1380 [02:08<00:36,  8.88it/s] 76%|███████▋  | 1054/1380 [02:08<00:36,  8.90it/s] 76%|███████▋  | 1055/1380 [02:08<00:36,  8.91it/s] 77%|███████▋  | 1056/1380 [02:08<00:35,  9.02it/s] 77%|███████▋  | 1057/1380 [02:08<00:36,  8.96it/s] 77%|███████▋  | 1058/1380 [02:08<00:36,  8.92it/s] 77%|███████▋  | 1059/1380 [02:09<00:36,  8.85it/s] 77%|███████▋  | 1060/1380 [02:09<00:35,  8.96it/s] 77%|███████▋  | 1061/1380 [02:09<00:35,  9.02it/s] 77%|███████▋  | 1062/1380 [02:09<00:35,  8.95it/s] 77%|███████▋  | 1063/1380 [02:09<00:35,  8.92it/s] 77%|███████▋  | 1064/1380 [02:09<00:35,  8.91it/s] 77%|███████▋  | 1065/1380 [02:09<00:35,  8.93it/s] 77%|███████▋  | 1066/1380 [02:09<00:34,  8.99it/s] 77%|███████▋  | 1067/1380 [02:09<00:34,  8.95it/s] 77%|███████▋  | 1068/1380 [02:10<00:35,  8.87it/s] 77%|███████▋  | 1069/1380 [02:10<00:34,  8.93it/s] 78%|███████▊  | 1070/1380 [02:10<00:34,  8.93it/s] 78%|███████▊  | 1071/1380 [02:10<00:34,  8.93it/s] 78%|███████▊  | 1072/1380 [02:10<00:34,  8.98it/s] 78%|███████▊  | 1073/1380 [02:10<00:34,  8.92it/s] 78%|███████▊  | 1074/1380 [02:10<00:34,  8.98it/s] 78%|███████▊  | 1075/1380 [02:10<00:34,  8.93it/s] 78%|███████▊  | 1076/1380 [02:10<00:33,  9.00it/s] 78%|███████▊  | 1077/1380 [02:11<00:34,  8.91it/s] 78%|███████▊  | 1078/1380 [02:11<00:33,  8.91it/s] 78%|███████▊  | 1079/1380 [02:11<00:33,  8.99it/s] 78%|███████▊  | 1080/1380 [02:11<00:33,  8.95it/s] 78%|███████▊  | 1081/1380 [02:11<00:33,  8.85it/s] 78%|███████▊  | 1082/1380 [02:11<00:33,  8.83it/s] 78%|███████▊  | 1083/1380 [02:11<00:33,  8.93it/s] 79%|███████▊  | 1084/1380 [02:11<00:33,  8.92it/s] 79%|███████▊  | 1085/1380 [02:11<00:33,  8.88it/s] 79%|███████▊  | 1086/1380 [02:12<00:33,  8.87it/s] 79%|███████▉  | 1087/1380 [02:12<00:33,  8.87it/s] 79%|███████▉  | 1088/1380 [02:12<00:32,  8.87it/s] 79%|███████▉  | 1089/1380 [02:12<00:32,  8.97it/s] 79%|███████▉  | 1090/1380 [02:12<00:32,  8.90it/s] 79%|███████▉  | 1091/1380 [02:12<00:32,  8.94it/s] 79%|███████▉  | 1092/1380 [02:12<00:32,  8.98it/s] 79%|███████▉  | 1093/1380 [02:12<00:31,  8.99it/s] 79%|███████▉  | 1094/1380 [02:12<00:31,  9.05it/s] 79%|███████▉  | 1095/1380 [02:13<00:31,  8.92it/s] 79%|███████▉  | 1096/1380 [02:13<00:32,  8.84it/s] 79%|███████▉  | 1097/1380 [02:13<00:31,  8.93it/s] 80%|███████▉  | 1098/1380 [02:13<00:31,  8.88it/s] 80%|███████▉  | 1099/1380 [02:13<00:31,  8.89it/s] 80%|███████▉  | 1100/1380 [02:13<00:31,  8.80it/s] 80%|███████▉  | 1101/1380 [02:13<00:31,  8.84it/s] 80%|███████▉  | 1102/1380 [02:13<00:31,  8.96it/s] 80%|███████▉  | 1103/1380 [02:13<00:30,  8.95it/s]                                                    80%|████████  | 1104/1380 [02:14<00:30,  8.95it/s][INFO|trainer.py:755] 2023-11-15 21:30:06,668 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:30:06,670 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:30:06,670 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:30:06,670 >>   Batch size = 8
{'eval_loss': 0.41830387711524963, 'eval_accuracy': 0.852087114337568, 'eval_micro_f1': 0.852087114337568, 'eval_macro_f1': 0.842349265727111, 'eval_runtime': 3.911, 'eval_samples_per_second': 563.542, 'eval_steps_per_second': 70.571, 'epoch': 3.0}
{'loss': 0.1834, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 78.22it/s][A
  6%|▌         | 17/276 [00:00<00:03, 76.41it/s][A
  9%|▉         | 25/276 [00:00<00:03, 73.34it/s][A
 12%|█▏        | 33/276 [00:00<00:03, 71.74it/s][A
 15%|█▍        | 41/276 [00:00<00:03, 72.76it/s][A
 18%|█▊        | 49/276 [00:00<00:03, 72.28it/s][A
 21%|██        | 57/276 [00:00<00:02, 73.29it/s][A
 24%|██▎       | 65/276 [00:00<00:02, 73.46it/s][A
 26%|██▋       | 73/276 [00:01<00:02, 71.76it/s][A
 29%|██▉       | 81/276 [00:01<00:02, 71.03it/s][A
 32%|███▏      | 89/276 [00:01<00:02, 71.18it/s][A
 35%|███▌      | 97/276 [00:01<00:02, 72.52it/s][A
 38%|███▊      | 105/276 [00:01<00:02, 72.46it/s][A
 41%|████      | 113/276 [00:01<00:02, 71.08it/s][A
 44%|████▍     | 121/276 [00:01<00:02, 71.23it/s][A
 47%|████▋     | 129/276 [00:01<00:02, 71.19it/s][A
 50%|████▉     | 137/276 [00:01<00:01, 71.33it/s][A
 53%|█████▎    | 145/276 [00:02<00:01, 72.03it/s][A
 55%|█████▌    | 153/276 [00:02<00:01, 71.00it/s][A
 58%|█████▊    | 161/276 [00:02<00:01, 71.56it/s][A
 61%|██████    | 169/276 [00:02<00:01, 71.72it/s][A
 64%|██████▍   | 177/276 [00:02<00:01, 72.10it/s][A
 67%|██████▋   | 185/276 [00:02<00:01, 71.56it/s][A
 70%|██████▉   | 193/276 [00:02<00:01, 70.93it/s][A
 73%|███████▎  | 201/276 [00:02<00:01, 71.39it/s][A
 76%|███████▌  | 209/276 [00:02<00:00, 71.70it/s][A
 79%|███████▊  | 217/276 [00:03<00:00, 70.31it/s][A
 82%|████████▏ | 225/276 [00:03<00:00, 71.12it/s][A
 84%|████████▍ | 233/276 [00:03<00:00, 71.09it/s][A
 87%|████████▋ | 241/276 [00:03<00:00, 70.95it/s][A
 90%|█████████ | 249/276 [00:03<00:00, 72.37it/s][A
 93%|█████████▎| 257/276 [00:03<00:00, 70.19it/s][A
 96%|█████████▌| 265/276 [00:03<00:00, 70.49it/s][A
 99%|█████████▉| 273/276 [00:03<00:00, 70.89it/s][A                                                   
                                                 [A 80%|████████  | 1104/1380 [02:17<00:30,  8.95it/s]
100%|██████████| 276/276 [00:03<00:00, 70.89it/s][A
                                                 [A 80%|████████  | 1105/1380 [02:18<04:36,  1.01s/it] 80%|████████  | 1106/1380 [02:18<03:35,  1.27it/s] 80%|████████  | 1107/1380 [02:18<02:46,  1.64it/s] 80%|████████  | 1108/1380 [02:18<02:08,  2.11it/s] 80%|████████  | 1109/1380 [02:18<01:41,  2.68it/s] 80%|████████  | 1110/1380 [02:18<01:20,  3.36it/s] 81%|████████  | 1111/1380 [02:18<01:05,  4.10it/s] 81%|████████  | 1112/1380 [02:18<00:55,  4.86it/s] 81%|████████  | 1113/1380 [02:18<00:47,  5.59it/s] 81%|████████  | 1114/1380 [02:19<00:42,  6.29it/s] 81%|████████  | 1115/1380 [02:19<00:38,  6.91it/s] 81%|████████  | 1116/1380 [02:19<00:35,  7.40it/s] 81%|████████  | 1117/1380 [02:19<00:33,  7.80it/s] 81%|████████  | 1118/1380 [02:19<00:32,  8.14it/s] 81%|████████  | 1119/1380 [02:19<00:31,  8.36it/s] 81%|████████  | 1120/1380 [02:19<00:30,  8.52it/s] 81%|████████  | 1121/1380 [02:19<00:29,  8.64it/s] 81%|████████▏ | 1122/1380 [02:19<00:29,  8.75it/s] 81%|████████▏ | 1123/1380 [02:20<00:28,  8.86it/s] 81%|████████▏ | 1124/1380 [02:20<00:28,  8.91it/s] 82%|████████▏ | 1125/1380 [02:20<00:28,  8.91it/s] 82%|████████▏ | 1126/1380 [02:20<00:28,  8.96it/s] 82%|████████▏ | 1127/1380 [02:20<00:28,  9.03it/s] 82%|████████▏ | 1128/1380 [02:20<00:27,  9.02it/s] 82%|████████▏ | 1129/1380 [02:20<00:27,  8.98it/s] 82%|████████▏ | 1130/1380 [02:20<00:27,  9.01it/s] 82%|████████▏ | 1131/1380 [02:20<00:27,  8.96it/s] 82%|████████▏ | 1132/1380 [02:21<00:27,  9.02it/s] 82%|████████▏ | 1133/1380 [02:21<00:27,  9.10it/s] 82%|████████▏ | 1134/1380 [02:21<00:27,  8.99it/s] 82%|████████▏ | 1135/1380 [02:21<00:27,  8.94it/s] 82%|████████▏ | 1136/1380 [02:21<00:27,  8.98it/s] 82%|████████▏ | 1137/1380 [02:21<00:26,  9.00it/s] 82%|████████▏ | 1138/1380 [02:21<00:26,  8.98it/s] 83%|████████▎ | 1139/1380 [02:21<00:26,  8.94it/s] 83%|████████▎ | 1140/1380 [02:22<00:26,  8.91it/s] 83%|████████▎ | 1141/1380 [02:22<00:26,  8.98it/s] 83%|████████▎ | 1142/1380 [02:22<00:26,  8.99it/s] 83%|████████▎ | 1143/1380 [02:22<00:26,  9.02it/s] 83%|████████▎ | 1144/1380 [02:22<00:26,  8.95it/s] 83%|████████▎ | 1145/1380 [02:22<00:26,  8.97it/s] 83%|████████▎ | 1146/1380 [02:22<00:25,  9.01it/s] 83%|████████▎ | 1147/1380 [02:22<00:25,  9.01it/s] 83%|████████▎ | 1148/1380 [02:22<00:25,  8.98it/s] 83%|████████▎ | 1149/1380 [02:23<00:25,  8.98it/s] 83%|████████▎ | 1150/1380 [02:23<00:25,  8.99it/s] 83%|████████▎ | 1151/1380 [02:23<00:25,  9.03it/s] 83%|████████▎ | 1152/1380 [02:23<00:25,  9.03it/s] 84%|████████▎ | 1153/1380 [02:23<00:25,  9.01it/s] 84%|████████▎ | 1154/1380 [02:23<00:25,  8.95it/s] 84%|████████▎ | 1155/1380 [02:23<00:25,  8.99it/s] 84%|████████▍ | 1156/1380 [02:23<00:24,  9.07it/s] 84%|████████▍ | 1157/1380 [02:23<00:24,  8.98it/s] 84%|████████▍ | 1158/1380 [02:24<00:24,  8.95it/s] 84%|████████▍ | 1159/1380 [02:24<00:24,  8.91it/s] 84%|████████▍ | 1160/1380 [02:24<00:24,  9.00it/s] 84%|████████▍ | 1161/1380 [02:24<00:24,  8.99it/s] 84%|████████▍ | 1162/1380 [02:24<00:24,  8.86it/s] 84%|████████▍ | 1163/1380 [02:24<00:24,  8.88it/s] 84%|████████▍ | 1164/1380 [02:24<00:24,  8.86it/s] 84%|████████▍ | 1165/1380 [02:24<00:24,  8.89it/s] 84%|████████▍ | 1166/1380 [02:24<00:24,  8.86it/s] 85%|████████▍ | 1167/1380 [02:25<00:24,  8.86it/s] 85%|████████▍ | 1168/1380 [02:25<00:24,  8.80it/s] 85%|████████▍ | 1169/1380 [02:25<00:23,  8.96it/s] 85%|████████▍ | 1170/1380 [02:25<00:23,  8.94it/s] 85%|████████▍ | 1171/1380 [02:25<00:23,  8.92it/s] 85%|████████▍ | 1172/1380 [02:25<00:23,  8.93it/s] 85%|████████▌ | 1173/1380 [02:25<00:23,  8.93it/s] 85%|████████▌ | 1174/1380 [02:25<00:22,  9.00it/s] 85%|████████▌ | 1175/1380 [02:25<00:22,  8.92it/s] 85%|████████▌ | 1176/1380 [02:26<00:22,  8.91it/s] 85%|████████▌ | 1177/1380 [02:26<00:22,  8.88it/s] 85%|████████▌ | 1178/1380 [02:26<00:22,  8.92it/s] 85%|████████▌ | 1179/1380 [02:26<00:22,  8.97it/s] 86%|████████▌ | 1180/1380 [02:26<00:22,  8.97it/s] 86%|████████▌ | 1181/1380 [02:26<00:22,  8.87it/s] 86%|████████▌ | 1182/1380 [02:26<00:22,  8.85it/s] 86%|████████▌ | 1183/1380 [02:26<00:22,  8.92it/s] 86%|████████▌ | 1184/1380 [02:26<00:21,  8.92it/s] 86%|████████▌ | 1185/1380 [02:27<00:21,  8.92it/s] 86%|████████▌ | 1186/1380 [02:27<00:21,  8.90it/s] 86%|████████▌ | 1187/1380 [02:27<00:21,  8.88it/s] 86%|████████▌ | 1188/1380 [02:27<00:21,  8.94it/s] 86%|████████▌ | 1189/1380 [02:27<00:21,  8.99it/s] 86%|████████▌ | 1190/1380 [02:27<00:21,  8.92it/s] 86%|████████▋ | 1191/1380 [02:27<00:21,  8.97it/s] 86%|████████▋ | 1192/1380 [02:27<00:20,  8.99it/s] 86%|████████▋ | 1193/1380 [02:27<00:20,  9.03it/s] 87%|████████▋ | 1194/1380 [02:28<00:20,  8.95it/s] 87%|████████▋ | 1195/1380 [02:28<00:20,  8.94it/s] 87%|████████▋ | 1196/1380 [02:28<00:20,  8.86it/s] 87%|████████▋ | 1197/1380 [02:28<00:20,  8.89it/s] 87%|████████▋ | 1198/1380 [02:28<00:20,  8.93it/s] 87%|████████▋ | 1199/1380 [02:28<00:20,  8.95it/s] 87%|████████▋ | 1200/1380 [02:28<00:20,  8.92it/s] 87%|████████▋ | 1201/1380 [02:28<00:19,  8.99it/s] 87%|████████▋ | 1202/1380 [02:28<00:19,  9.02it/s] 87%|████████▋ | 1203/1380 [02:29<00:19,  8.97it/s] 87%|████████▋ | 1204/1380 [02:29<00:19,  8.87it/s] 87%|████████▋ | 1205/1380 [02:29<00:19,  8.93it/s] 87%|████████▋ | 1206/1380 [02:29<00:19,  8.90it/s] 87%|████████▋ | 1207/1380 [02:29<00:19,  8.89it/s] 88%|████████▊ | 1208/1380 [02:29<00:19,  8.89it/s] 88%|████████▊ | 1209/1380 [02:29<00:19,  8.94it/s] 88%|████████▊ | 1210/1380 [02:29<00:19,  8.93it/s] 88%|████████▊ | 1211/1380 [02:29<00:18,  8.94it/s] 88%|████████▊ | 1212/1380 [02:30<00:18,  9.00it/s] 88%|████████▊ | 1213/1380 [02:30<00:18,  8.98it/s] 88%|████████▊ | 1214/1380 [02:30<00:18,  8.88it/s] 88%|████████▊ | 1215/1380 [02:30<00:18,  8.85it/s] 88%|████████▊ | 1216/1380 [02:30<00:18,  8.91it/s] 88%|████████▊ | 1217/1380 [02:30<00:18,  8.89it/s] 88%|████████▊ | 1218/1380 [02:30<00:18,  8.91it/s] 88%|████████▊ | 1219/1380 [02:30<00:18,  8.84it/s] 88%|████████▊ | 1220/1380 [02:30<00:17,  8.91it/s] 88%|████████▊ | 1221/1380 [02:31<00:17,  8.89it/s] 89%|████████▊ | 1222/1380 [02:31<00:17,  8.95it/s] 89%|████████▊ | 1223/1380 [02:31<00:17,  8.88it/s] 89%|████████▊ | 1224/1380 [02:31<00:17,  8.90it/s] 89%|████████▉ | 1225/1380 [02:31<00:17,  8.94it/s] 89%|████████▉ | 1226/1380 [02:31<00:17,  8.99it/s] 89%|████████▉ | 1227/1380 [02:31<00:17,  8.94it/s] 89%|████████▉ | 1228/1380 [02:31<00:17,  8.89it/s] 89%|████████▉ | 1229/1380 [02:31<00:17,  8.86it/s] 89%|████████▉ | 1230/1380 [02:32<00:16,  8.92it/s] 89%|████████▉ | 1231/1380 [02:32<00:16,  8.92it/s] 89%|████████▉ | 1232/1380 [02:32<00:16,  8.95it/s] 89%|████████▉ | 1233/1380 [02:32<00:16,  8.95it/s] 89%|████████▉ | 1234/1380 [02:32<00:16,  8.90it/s] 89%|████████▉ | 1235/1380 [02:32<00:16,  8.97it/s] 90%|████████▉ | 1236/1380 [02:32<00:16,  8.99it/s] 90%|████████▉ | 1237/1380 [02:32<00:15,  8.98it/s] 90%|████████▉ | 1238/1380 [02:32<00:15,  8.97it/s] 90%|████████▉ | 1239/1380 [02:33<00:15,  8.96it/s] 90%|████████▉ | 1240/1380 [02:33<00:15,  9.03it/s] 90%|████████▉ | 1241/1380 [02:33<00:15,  8.99it/s] 90%|█████████ | 1242/1380 [02:33<00:15,  8.98it/s] 90%|█████████ | 1243/1380 [02:33<00:15,  8.82it/s] 90%|█████████ | 1244/1380 [02:33<00:15,  8.84it/s] 90%|█████████ | 1245/1380 [02:33<00:15,  8.91it/s] 90%|█████████ | 1246/1380 [02:33<00:15,  8.91it/s] 90%|█████████ | 1247/1380 [02:33<00:14,  8.90it/s] 90%|█████████ | 1248/1380 [02:34<00:15,  8.78it/s] 91%|█████████ | 1249/1380 [02:34<00:14,  8.86it/s] 91%|█████████ | 1250/1380 [02:34<00:14,  8.95it/s] 91%|█████████ | 1251/1380 [02:34<00:14,  8.85it/s] 91%|█████████ | 1252/1380 [02:34<00:14,  8.84it/s] 91%|█████████ | 1253/1380 [02:34<00:14,  8.82it/s] 91%|█████████ | 1254/1380 [02:34<00:14,  8.84it/s] 91%|█████████ | 1255/1380 [02:34<00:13,  8.93it/s] 91%|█████████ | 1256/1380 [02:34<00:13,  8.91it/s] 91%|█████████ | 1257/1380 [02:35<00:13,  8.85it/s] 91%|█████████ | 1258/1380 [02:35<00:13,  8.89it/s] 91%|█████████ | 1259/1380 [02:35<00:13,  8.99it/s] 91%|█████████▏| 1260/1380 [02:35<00:13,  8.93it/s] 91%|█████████▏| 1261/1380 [02:35<00:13,  8.89it/s] 91%|█████████▏| 1262/1380 [02:35<00:13,  8.94it/s] 92%|█████████▏| 1263/1380 [02:35<00:13,  8.94it/s] 92%|█████████▏| 1264/1380 [02:35<00:13,  8.87it/s] 92%|█████████▏| 1265/1380 [02:35<00:12,  8.93it/s] 92%|█████████▏| 1266/1380 [02:36<00:12,  8.85it/s] 92%|█████████▏| 1267/1380 [02:36<00:12,  8.83it/s] 92%|█████████▏| 1268/1380 [02:36<00:12,  8.95it/s] 92%|█████████▏| 1269/1380 [02:36<00:12,  8.94it/s] 92%|█████████▏| 1270/1380 [02:36<00:12,  8.89it/s] 92%|█████████▏| 1271/1380 [02:36<00:12,  8.91it/s] 92%|█████████▏| 1272/1380 [02:36<00:12,  8.94it/s] 92%|█████████▏| 1273/1380 [02:36<00:11,  8.94it/s] 92%|█████████▏| 1274/1380 [02:37<00:11,  8.96it/s] 92%|█████████▏| 1275/1380 [02:37<00:11,  8.97it/s] 92%|█████████▏| 1276/1380 [02:37<00:11,  8.91it/s] 93%|█████████▎| 1277/1380 [02:37<00:11,  8.96it/s] 93%|█████████▎| 1278/1380 [02:37<00:11,  9.07it/s] 93%|█████████▎| 1279/1380 [02:37<00:11,  9.02it/s] 93%|█████████▎| 1280/1380 [02:37<00:11,  8.91it/s] 93%|█████████▎| 1281/1380 [02:37<00:11,  8.89it/s] 93%|█████████▎| 1282/1380 [02:37<00:10,  8.95it/s] 93%|█████████▎| 1283/1380 [02:38<00:10,  9.03it/s] 93%|█████████▎| 1284/1380 [02:38<00:10,  8.99it/s] 93%|█████████▎| 1285/1380 [02:38<00:10,  8.95it/s] 93%|█████████▎| 1286/1380 [02:38<00:10,  8.98it/s] 93%|█████████▎| 1287/1380 [02:38<00:10,  8.98it/s] 93%|█████████▎| 1288/1380 [02:38<00:10,  9.05it/s] 93%|█████████▎| 1289/1380 [02:38<00:10,  9.04it/s] 93%|█████████▎| 1290/1380 [02:38<00:09,  9.01it/s] 94%|█████████▎| 1291/1380 [02:38<00:09,  8.97it/s] 94%|█████████▎| 1292/1380 [02:39<00:09,  9.00it/s] 94%|█████████▎| 1293/1380 [02:39<00:09,  8.95it/s] 94%|█████████▍| 1294/1380 [02:39<00:09,  8.90it/s] 94%|█████████▍| 1295/1380 [02:39<00:09,  8.87it/s] 94%|█████████▍| 1296/1380 [02:39<00:09,  8.87it/s] 94%|█████████▍| 1297/1380 [02:39<00:09,  8.94it/s] 94%|█████████▍| 1298/1380 [02:39<00:09,  9.00it/s] 94%|█████████▍| 1299/1380 [02:39<00:09,  8.91it/s] 94%|█████████▍| 1300/1380 [02:39<00:08,  9.00it/s] 94%|█████████▍| 1301/1380 [02:40<00:08,  9.01it/s] 94%|█████████▍| 1302/1380 [02:40<00:08,  9.00it/s] 94%|█████████▍| 1303/1380 [02:40<00:08,  8.98it/s] 94%|█████████▍| 1304/1380 [02:40<00:08,  8.98it/s] 95%|█████████▍| 1305/1380 [02:40<00:08,  8.95it/s] 95%|█████████▍| 1306/1380 [02:40<00:08,  8.97it/s] 95%|█████████▍| 1307/1380 [02:40<00:08,  8.97it/s] 95%|█████████▍| 1308/1380 [02:40<00:07,  9.02it/s] 95%|█████████▍| 1309/1380 [02:40<00:07,  8.89it/s] 95%|█████████▍| 1310/1380 [02:41<00:07,  8.93it/s] 95%|█████████▌| 1311/1380 [02:41<00:07,  8.99it/s] 95%|█████████▌| 1312/1380 [02:41<00:07,  8.98it/s] 95%|█████████▌| 1313/1380 [02:41<00:07,  8.90it/s] 95%|█████████▌| 1314/1380 [02:41<00:07,  8.83it/s] 95%|█████████▌| 1315/1380 [02:41<00:07,  8.95it/s] 95%|█████████▌| 1316/1380 [02:41<00:07,  8.98it/s] 95%|█████████▌| 1317/1380 [02:41<00:07,  8.89it/s] 96%|█████████▌| 1318/1380 [02:41<00:06,  8.92it/s] 96%|█████████▌| 1319/1380 [02:42<00:06,  8.95it/s] 96%|█████████▌| 1320/1380 [02:42<00:06,  8.99it/s] 96%|█████████▌| 1321/1380 [02:42<00:06,  9.03it/s] 96%|█████████▌| 1322/1380 [02:42<00:06,  8.97it/s] 96%|█████████▌| 1323/1380 [02:42<00:06,  8.94it/s] 96%|█████████▌| 1324/1380 [02:42<00:06,  8.98it/s] 96%|█████████▌| 1325/1380 [02:42<00:06,  9.04it/s] 96%|█████████▌| 1326/1380 [02:42<00:06,  8.99it/s] 96%|█████████▌| 1327/1380 [02:42<00:05,  8.94it/s] 96%|█████████▌| 1328/1380 [02:43<00:05,  8.92it/s] 96%|█████████▋| 1329/1380 [02:43<00:05,  8.95it/s] 96%|█████████▋| 1330/1380 [02:43<00:05,  8.93it/s] 96%|█████████▋| 1331/1380 [02:43<00:05,  8.96it/s] 97%|█████████▋| 1332/1380 [02:43<00:05,  8.90it/s] 97%|█████████▋| 1333/1380 [02:43<00:05,  8.88it/s] 97%|█████████▋| 1334/1380 [02:43<00:05,  8.94it/s] 97%|█████████▋| 1335/1380 [02:43<00:05,  8.97it/s] 97%|█████████▋| 1336/1380 [02:43<00:04,  8.94it/s] 97%|█████████▋| 1337/1380 [02:44<00:04,  8.96it/s] 97%|█████████▋| 1338/1380 [02:44<00:04,  8.96it/s] 97%|█████████▋| 1339/1380 [02:44<00:04,  9.02it/s] 97%|█████████▋| 1340/1380 [02:44<00:04,  8.95it/s] 97%|█████████▋| 1341/1380 [02:44<00:04,  8.94it/s] 97%|█████████▋| 1342/1380 [02:44<00:04,  9.00it/s] 97%|█████████▋| 1343/1380 [02:44<00:04,  8.93it/s] 97%|█████████▋| 1344/1380 [02:44<00:03,  9.04it/s] 97%|█████████▋| 1345/1380 [02:44<00:03,  8.96it/s] 98%|█████████▊| 1346/1380 [02:45<00:03,  8.96it/s] 98%|█████████▊| 1347/1380 [02:45<00:03,  8.92it/s] 98%|█████████▊| 1348/1380 [02:45<00:03,  8.94it/s] 98%|█████████▊| 1349/1380 [02:45<00:03,  8.95it/s] 98%|█████████▊| 1350/1380 [02:45<00:03,  8.94it/s] 98%|█████████▊| 1351/1380 [02:45<00:03,  8.86it/s] 98%|█████████▊| 1352/1380 [02:45<00:03,  8.87it/s] 98%|█████████▊| 1353/1380 [02:45<00:03,  8.93it/s] 98%|█████████▊| 1354/1380 [02:45<00:02,  8.98it/s] 98%|█████████▊| 1355/1380 [02:46<00:02,  8.94it/s] 98%|█████████▊| 1356/1380 [02:46<00:02,  8.91it/s] 98%|█████████▊| 1357/1380 [02:46<00:02,  8.95it/s] 98%|█████████▊| 1358/1380 [02:46<00:02,  8.98it/s] 98%|█████████▊| 1359/1380 [02:46<00:02,  8.94it/s] 99%|█████████▊| 1360/1380 [02:46<00:02,  8.93it/s] 99%|█████████▊| 1361/1380 [02:46<00:02,  8.88it/s] 99%|█████████▊| 1362/1380 [02:46<00:02,  8.96it/s] 99%|█████████▉| 1363/1380 [02:46<00:01,  8.95it/s] 99%|█████████▉| 1364/1380 [02:47<00:01,  8.98it/s] 99%|█████████▉| 1365/1380 [02:47<00:01,  8.92it/s] 99%|█████████▉| 1366/1380 [02:47<00:01,  8.88it/s] 99%|█████████▉| 1367/1380 [02:47<00:01,  9.01it/s] 99%|█████████▉| 1368/1380 [02:47<00:01,  8.99it/s] 99%|█████████▉| 1369/1380 [02:47<00:01,  9.04it/s] 99%|█████████▉| 1370/1380 [02:47<00:01,  9.01it/s] 99%|█████████▉| 1371/1380 [02:47<00:01,  8.99it/s] 99%|█████████▉| 1372/1380 [02:47<00:00,  8.99it/s] 99%|█████████▉| 1373/1380 [02:48<00:00,  8.99it/s]100%|█████████▉| 1374/1380 [02:48<00:00,  8.95it/s]100%|█████████▉| 1375/1380 [02:48<00:00,  8.92it/s]100%|█████████▉| 1376/1380 [02:48<00:00,  9.00it/s]100%|█████████▉| 1377/1380 [02:48<00:00,  9.04it/s]100%|█████████▉| 1378/1380 [02:48<00:00,  9.05it/s]100%|█████████▉| 1379/1380 [02:48<00:00,  8.94it/s]                                                   100%|██████████| 1380/1380 [02:48<00:00,  8.94it/s][INFO|trainer.py:755] 2023-11-15 21:30:41,405 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:30:41,407 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:30:41,407 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:30:41,407 >>   Batch size = 8
{'eval_loss': 0.4982248842716217, 'eval_accuracy': 0.8498185117967332, 'eval_micro_f1': 0.8498185117967332, 'eval_macro_f1': 0.8423481145871535, 'eval_runtime': 3.9088, 'eval_samples_per_second': 563.853, 'eval_steps_per_second': 70.609, 'epoch': 4.0}
{'loss': 0.1386, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 81.40it/s][A
  7%|▋         | 18/276 [00:00<00:03, 76.80it/s][A
  9%|▉         | 26/276 [00:00<00:03, 72.05it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 71.92it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 71.49it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 71.67it/s][A
 21%|██        | 58/276 [00:00<00:03, 72.61it/s][A
 24%|██▍       | 66/276 [00:00<00:02, 71.37it/s][A
 27%|██▋       | 74/276 [00:01<00:02, 70.98it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 71.74it/s][A
 33%|███▎      | 90/276 [00:01<00:02, 71.86it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 70.38it/s][A
 38%|███▊      | 106/276 [00:01<00:02, 70.64it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 70.77it/s][A
 44%|████▍     | 122/276 [00:01<00:02, 72.27it/s][A
 47%|████▋     | 130/276 [00:01<00:02, 71.47it/s][A
 50%|█████     | 138/276 [00:01<00:01, 71.93it/s][A
 53%|█████▎    | 146/276 [00:02<00:01, 70.41it/s][A
 56%|█████▌    | 154/276 [00:02<00:01, 71.79it/s][A
 59%|█████▊    | 162/276 [00:02<00:01, 72.12it/s][A
 62%|██████▏   | 170/276 [00:02<00:01, 71.58it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 70.26it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 70.48it/s][A
 70%|███████   | 194/276 [00:02<00:01, 70.86it/s][A
 73%|███████▎  | 202/276 [00:02<00:01, 71.49it/s][A
 76%|███████▌  | 210/276 [00:02<00:00, 69.67it/s][A
 79%|███████▉  | 218/276 [00:03<00:00, 71.01it/s][A
 82%|████████▏ | 226/276 [00:03<00:00, 70.91it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 71.07it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 72.03it/s][A
 91%|█████████ | 250/276 [00:03<00:00, 70.99it/s][A
 93%|█████████▎| 258/276 [00:03<00:00, 70.62it/s][A
 96%|█████████▋| 266/276 [00:03<00:00, 70.61it/s][A
 99%|█████████▉| 274/276 [00:03<00:00, 72.08it/s][A                                                   
                                                 [A100%|██████████| 1380/1380 [02:52<00:00,  8.94it/s]
100%|██████████| 276/276 [00:03<00:00, 72.08it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 21:30:45,331 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:52<00:00,  8.94it/s]100%|██████████| 1380/1380 [02:52<00:00,  7.99it/s]
[INFO|trainer.py:2855] 2023-11-15 21:30:45,336 >> Saving model checkpoint to ./result/acl_roberta-base_adapter__seed4
[INFO|configuration_utils.py:460] 2023-11-15 21:30:45,339 >> Configuration saved in ./result/acl_roberta-base_adapter__seed4/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:30:46,496 >> Model weights saved in ./result/acl_roberta-base_adapter__seed4/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:30:46,498 >> tokenizer config file saved in ./result/acl_roberta-base_adapter__seed4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:30:46,500 >> Special tokens file saved in ./result/acl_roberta-base_adapter__seed4/special_tokens_map.json
{'eval_loss': 0.5392947793006897, 'eval_accuracy': 0.8507259528130672, 'eval_micro_f1': 0.8507259528130672, 'eval_macro_f1': 0.8423665770935584, 'eval_runtime': 3.9204, 'eval_samples_per_second': 562.186, 'eval_steps_per_second': 70.401, 'epoch': 5.0}
{'train_runtime': 172.7442, 'train_samples_per_second': 255.175, 'train_steps_per_second': 7.989, 'train_loss': 0.27417727207791975, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2742
  train_runtime            = 0:02:52.74
  train_samples            =       8816
  train_samples_per_second =    255.175
  train_steps_per_second   =      7.989
11/15/2023 21:30:46 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:30:46,594 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:30:46,596 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:30:46,596 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:30:46,596 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  3%|▎         | 9/276 [00:00<00:03, 85.45it/s]  7%|▋         | 18/276 [00:00<00:03, 78.83it/s]  9%|▉         | 26/276 [00:00<00:03, 74.16it/s] 12%|█▏        | 34/276 [00:00<00:03, 72.87it/s] 15%|█▌        | 42/276 [00:00<00:03, 70.65it/s] 18%|█▊        | 50/276 [00:00<00:03, 72.17it/s] 21%|██        | 58/276 [00:00<00:03, 72.61it/s] 24%|██▍       | 66/276 [00:00<00:02, 71.50it/s] 27%|██▋       | 74/276 [00:01<00:02, 70.39it/s] 30%|██▉       | 82/276 [00:01<00:02, 70.65it/s] 33%|███▎      | 90/276 [00:01<00:02, 71.83it/s] 36%|███▌      | 98/276 [00:01<00:02, 71.50it/s] 38%|███▊      | 106/276 [00:01<00:02, 70.39it/s] 41%|████▏     | 114/276 [00:01<00:02, 70.59it/s] 44%|████▍     | 122/276 [00:01<00:02, 72.11it/s] 47%|████▋     | 130/276 [00:01<00:02, 72.38it/s] 50%|█████     | 138/276 [00:01<00:01, 72.51it/s] 53%|█████▎    | 146/276 [00:02<00:01, 71.01it/s] 56%|█████▌    | 154/276 [00:02<00:01, 72.08it/s] 59%|█████▊    | 162/276 [00:02<00:01, 73.49it/s] 62%|██████▏   | 170/276 [00:02<00:01, 72.40it/s] 64%|██████▍   | 178/276 [00:02<00:01, 71.55it/s] 67%|██████▋   | 186/276 [00:02<00:01, 72.21it/s] 70%|███████   | 194/276 [00:02<00:01, 73.26it/s] 73%|███████▎  | 202/276 [00:02<00:01, 72.45it/s] 76%|███████▌  | 210/276 [00:02<00:00, 71.39it/s] 79%|███████▉  | 218/276 [00:03<00:00, 72.10it/s] 82%|████████▏ | 226/276 [00:03<00:00, 73.05it/s] 85%|████████▍ | 234/276 [00:03<00:00, 72.25it/s] 88%|████████▊ | 242/276 [00:03<00:00, 72.50it/s] 91%|█████████ | 250/276 [00:03<00:00, 71.65it/s] 93%|█████████▎| 258/276 [00:03<00:00, 72.76it/s] 96%|█████████▋| 266/276 [00:03<00:00, 73.35it/s] 99%|█████████▉| 274/276 [00:03<00:00, 72.51it/s]100%|██████████| 276/276 [00:03<00:00, 71.38it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8507
  eval_loss               =     0.5393
  eval_macro_f1           =     0.8424
  eval_micro_f1           =     0.8507
  eval_runtime            = 0:00:03.88
  eval_samples            =       2204
  eval_samples_per_second =    567.274
  eval_steps_per_second   =     71.038
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▂█▃▅▅
wandb:                      eval/loss ▂▁▂▆██
wandb:                  eval/macro_f1 ▃▁████
wandb:                  eval/micro_f1 ▁▂█▃▅▅
wandb:                   eval/runtime ▁▂█▇█▆
wandb:        eval/samples_per_second █▇▁▂▁▃
wandb:          eval/steps_per_second █▇▁▂▁▃
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.85073
wandb:                      eval/loss 0.53929
wandb:                  eval/macro_f1 0.84237
wandb:                  eval/micro_f1 0.85073
wandb:                   eval/runtime 3.8852
wandb:        eval/samples_per_second 567.274
wandb:          eval/steps_per_second 71.038
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1386
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.27418
wandb:            train/train_runtime 172.7442
wandb: train/train_samples_per_second 255.175
wandb:   train/train_steps_per_second 7.989
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_212634-x1b7fx4y
wandb: Find logs at: ./wandb/offline-run-20231115_212634-x1b7fx4y/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_bert-base-cased_adapter__seed4/runs/Nov15_21-31-00_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_bert-base-cased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_bert-base-cased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:31:00 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:31:00 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_bert-base-cased_adapter__seed4/runs/Nov15_21-31-00_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_bert-base-cased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_bert-base-cased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  35%|███▌      | 3880/11020 [00:00<00:00, 38561.73 examples/s]Map:  88%|████████▊ | 9720/11020 [00:00<00:00, 38811.60 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 38072.09 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 21:31:17,001 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:31:17,011 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 21:31:27,028 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:31:27,029 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:31:27,032 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:31:27,032 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:31:27,032 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:31:27,032 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:31:27,033 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 21:31:27,034 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:31:27,034 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:31:47,165 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 21:31:47,802 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:31:47,803 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  34%|███▍      | 3000/8816 [00:00<00:00, 21114.32 examples/s]Running tokenizer on dataset:  79%|███████▉  | 7000/8816 [00:00<00:00, 22051.21 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 21870.68 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 22127.97 examples/s]
11/15/2023 21:31:48 - INFO - __main__ - Sample 3167 of the training set: {'text': 'Other studies showed that ACR could affect the cellular energy generation and the deficiency of energy induced the neurotoxicity [7, 8].', 'label': 0, 'input_ids': [101, 2189, 2527, 2799, 1115, 9690, 2069, 1180, 6975, 1103, 14391, 2308, 3964, 1105, 1103, 21344, 1104, 2308, 10645, 1103, 24928, 11955, 2430, 8745, 9041, 164, 128, 117, 129, 166, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:31:48 - INFO - __main__ - Sample 4498 of the training set: {'text': 'Left renal glucose utilization and splanchnic glucose utilization (utilization) were calculated using the formula\n utilization 5 FEGlc 3 3Glc4a 3 R1H2PF (4)\n where R(H)PF equals either unilateral renal plasma flow or hepatic plasma flow.', 'label': 1, 'input_ids': [101, 8123, 1231, 7050, 20636, 190, 19621, 2734, 1105, 188, 1643, 4371, 1732, 7770, 20636, 190, 19621, 2734, 113, 190, 19621, 2734, 114, 1127, 10056, 1606, 1103, 7893, 190, 19621, 2734, 126, 143, 17020, 1233, 1665, 124, 124, 2349, 1233, 1665, 1527, 1161, 124, 155, 1475, 3048, 1477, 2101, 2271, 113, 125, 114, 1187, 155, 113, 145, 114, 153, 2271, 22455, 1719, 8362, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 21:31:48 - INFO - __main__ - Sample 2638 of the training set: {'text': 'The randomized controlled trials (RCTs) which evaluated the efficacy of PEG for mechanical bowel preparation in prevention of postoperative complications in colorectal surgery were considered for inclusion.', 'label': 1, 'input_ids': [101, 1109, 7091, 2200, 4013, 7356, 113, 25157, 1942, 1116, 114, 1134, 17428, 1103, 23891, 1104, 153, 17020, 1111, 6676, 7125, 1883, 7288, 1107, 13347, 1104, 2112, 19807, 5838, 13522, 1107, 2942, 10294, 6163, 6059, 1127, 1737, 1111, 10838, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:31:48 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:31:49,729 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:31:49,736 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:31:49,737 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 21:31:49,737 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:31:49,737 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:31:49,737 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:31:49,738 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:31:49,738 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 21:31:49,739 >>   Number of trainable parameters = 108,312,579
[INFO|integration_utils.py:716] 2023-11-15 21:31:49,740 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<29:53,  1.30s/it]  0%|          | 2/1380 [00:01<13:43,  1.67it/s]  0%|          | 3/1380 [00:01<08:34,  2.68it/s]  0%|          | 4/1380 [00:01<06:08,  3.73it/s]  0%|          | 5/1380 [00:01<04:49,  4.75it/s]  0%|          | 6/1380 [00:01<04:02,  5.68it/s]  1%|          | 7/1380 [00:01<03:29,  6.54it/s]  1%|          | 8/1380 [00:02<03:08,  7.26it/s]  1%|          | 9/1380 [00:02<02:56,  7.79it/s]  1%|          | 10/1380 [00:02<02:47,  8.19it/s]  1%|          | 11/1380 [00:02<02:40,  8.52it/s]  1%|          | 12/1380 [00:02<02:36,  8.77it/s]  1%|          | 13/1380 [00:02<02:32,  8.94it/s]  1%|          | 14/1380 [00:02<02:31,  8.99it/s]  1%|          | 15/1380 [00:02<02:29,  9.10it/s]  1%|          | 16/1380 [00:02<02:28,  9.17it/s]  1%|          | 17/1380 [00:03<02:26,  9.30it/s]  1%|▏         | 18/1380 [00:03<02:26,  9.33it/s]  1%|▏         | 19/1380 [00:03<02:26,  9.27it/s]  1%|▏         | 20/1380 [00:03<02:27,  9.23it/s]  2%|▏         | 21/1380 [00:03<02:26,  9.27it/s]  2%|▏         | 22/1380 [00:03<02:25,  9.33it/s]  2%|▏         | 23/1380 [00:03<02:26,  9.27it/s]  2%|▏         | 24/1380 [00:03<02:26,  9.26it/s]  2%|▏         | 25/1380 [00:03<02:25,  9.31it/s]  2%|▏         | 26/1380 [00:03<02:25,  9.34it/s]  2%|▏         | 27/1380 [00:04<02:25,  9.33it/s]  2%|▏         | 28/1380 [00:04<02:25,  9.31it/s]  2%|▏         | 29/1380 [00:04<02:24,  9.33it/s]  2%|▏         | 30/1380 [00:04<02:23,  9.38it/s]  2%|▏         | 31/1380 [00:04<02:23,  9.43it/s]  2%|▏         | 32/1380 [00:04<02:24,  9.33it/s]  2%|▏         | 33/1380 [00:04<02:24,  9.33it/s]  2%|▏         | 34/1380 [00:04<02:24,  9.34it/s]  3%|▎         | 35/1380 [00:04<02:23,  9.37it/s]  3%|▎         | 36/1380 [00:05<02:23,  9.36it/s]  3%|▎         | 37/1380 [00:05<02:23,  9.36it/s]  3%|▎         | 38/1380 [00:05<02:22,  9.39it/s]  3%|▎         | 39/1380 [00:05<02:22,  9.40it/s]  3%|▎         | 40/1380 [00:05<02:21,  9.48it/s]  3%|▎         | 41/1380 [00:05<02:21,  9.48it/s]  3%|▎         | 42/1380 [00:05<02:21,  9.43it/s]  3%|▎         | 43/1380 [00:05<02:22,  9.37it/s]  3%|▎         | 44/1380 [00:05<02:22,  9.39it/s]  3%|▎         | 45/1380 [00:06<02:21,  9.41it/s]  3%|▎         | 46/1380 [00:06<02:23,  9.32it/s]  3%|▎         | 47/1380 [00:06<02:22,  9.37it/s]  3%|▎         | 48/1380 [00:06<02:22,  9.36it/s]  4%|▎         | 49/1380 [00:06<02:21,  9.38it/s]  4%|▎         | 50/1380 [00:06<02:20,  9.47it/s]  4%|▎         | 51/1380 [00:06<02:21,  9.41it/s]  4%|▍         | 52/1380 [00:06<02:21,  9.40it/s]  4%|▍         | 53/1380 [00:06<02:21,  9.35it/s]  4%|▍         | 54/1380 [00:06<02:21,  9.38it/s]  4%|▍         | 55/1380 [00:07<02:20,  9.40it/s]  4%|▍         | 56/1380 [00:07<02:21,  9.37it/s]  4%|▍         | 57/1380 [00:07<02:21,  9.33it/s]  4%|▍         | 58/1380 [00:07<02:21,  9.34it/s]  4%|▍         | 59/1380 [00:07<02:20,  9.38it/s]  4%|▍         | 60/1380 [00:07<02:19,  9.46it/s]  4%|▍         | 61/1380 [00:07<02:20,  9.36it/s]  4%|▍         | 62/1380 [00:07<02:21,  9.31it/s]  5%|▍         | 63/1380 [00:07<02:20,  9.38it/s]  5%|▍         | 64/1380 [00:08<02:20,  9.37it/s]  5%|▍         | 65/1380 [00:08<02:21,  9.30it/s]  5%|▍         | 66/1380 [00:08<02:22,  9.22it/s]  5%|▍         | 67/1380 [00:08<02:22,  9.24it/s]  5%|▍         | 68/1380 [00:08<02:21,  9.26it/s]  5%|▌         | 69/1380 [00:08<02:22,  9.20it/s]  5%|▌         | 70/1380 [00:08<02:21,  9.24it/s]  5%|▌         | 71/1380 [00:08<02:22,  9.20it/s]  5%|▌         | 72/1380 [00:08<02:21,  9.26it/s]  5%|▌         | 73/1380 [00:09<02:19,  9.38it/s]  5%|▌         | 74/1380 [00:09<02:20,  9.31it/s]  5%|▌         | 75/1380 [00:09<02:20,  9.29it/s]  6%|▌         | 76/1380 [00:09<02:20,  9.28it/s]  6%|▌         | 77/1380 [00:09<02:19,  9.31it/s]  6%|▌         | 78/1380 [00:09<02:19,  9.36it/s]  6%|▌         | 79/1380 [00:09<02:19,  9.34it/s]  6%|▌         | 80/1380 [00:09<02:18,  9.37it/s]  6%|▌         | 81/1380 [00:09<02:19,  9.33it/s]  6%|▌         | 82/1380 [00:09<02:18,  9.36it/s]  6%|▌         | 83/1380 [00:10<02:17,  9.40it/s]  6%|▌         | 84/1380 [00:10<02:18,  9.38it/s]  6%|▌         | 85/1380 [00:10<02:19,  9.28it/s]  6%|▌         | 86/1380 [00:10<02:20,  9.24it/s]  6%|▋         | 87/1380 [00:10<02:19,  9.27it/s]  6%|▋         | 88/1380 [00:10<02:19,  9.25it/s]  6%|▋         | 89/1380 [00:10<02:20,  9.19it/s]  7%|▋         | 90/1380 [00:10<02:20,  9.17it/s]  7%|▋         | 91/1380 [00:10<02:20,  9.17it/s]  7%|▋         | 92/1380 [00:11<02:18,  9.27it/s]  7%|▋         | 93/1380 [00:11<02:18,  9.28it/s]  7%|▋         | 94/1380 [00:11<02:18,  9.28it/s]  7%|▋         | 95/1380 [00:11<02:18,  9.26it/s]  7%|▋         | 96/1380 [00:11<02:18,  9.28it/s]  7%|▋         | 97/1380 [00:11<02:17,  9.34it/s]  7%|▋         | 98/1380 [00:11<02:18,  9.27it/s]  7%|▋         | 99/1380 [00:11<02:18,  9.28it/s]  7%|▋         | 100/1380 [00:11<02:18,  9.23it/s]  7%|▋         | 101/1380 [00:12<02:17,  9.28it/s]  7%|▋         | 102/1380 [00:12<02:19,  9.18it/s]  7%|▋         | 103/1380 [00:12<02:17,  9.28it/s]  8%|▊         | 104/1380 [00:12<02:18,  9.22it/s]  8%|▊         | 105/1380 [00:12<02:17,  9.26it/s]  8%|▊         | 106/1380 [00:12<02:16,  9.33it/s]  8%|▊         | 107/1380 [00:12<02:16,  9.34it/s]  8%|▊         | 108/1380 [00:12<02:17,  9.26it/s]  8%|▊         | 109/1380 [00:12<02:17,  9.25it/s]  8%|▊         | 110/1380 [00:12<02:16,  9.29it/s]  8%|▊         | 111/1380 [00:13<02:15,  9.35it/s]  8%|▊         | 112/1380 [00:13<02:16,  9.26it/s]  8%|▊         | 113/1380 [00:13<02:17,  9.24it/s]  8%|▊         | 114/1380 [00:13<02:16,  9.30it/s]  8%|▊         | 115/1380 [00:13<02:15,  9.36it/s]  8%|▊         | 116/1380 [00:13<02:14,  9.39it/s]  8%|▊         | 117/1380 [00:13<02:16,  9.27it/s]  9%|▊         | 118/1380 [00:13<02:15,  9.29it/s]  9%|▊         | 119/1380 [00:13<02:14,  9.36it/s]  9%|▊         | 120/1380 [00:14<02:14,  9.40it/s]  9%|▉         | 121/1380 [00:14<02:14,  9.34it/s]  9%|▉         | 122/1380 [00:14<02:15,  9.31it/s]  9%|▉         | 123/1380 [00:14<02:14,  9.36it/s]  9%|▉         | 124/1380 [00:14<02:13,  9.38it/s]  9%|▉         | 125/1380 [00:14<02:14,  9.30it/s]  9%|▉         | 126/1380 [00:14<02:13,  9.38it/s]  9%|▉         | 127/1380 [00:14<02:13,  9.36it/s]  9%|▉         | 128/1380 [00:14<02:13,  9.36it/s]  9%|▉         | 129/1380 [00:15<02:12,  9.42it/s]  9%|▉         | 130/1380 [00:15<02:13,  9.36it/s]  9%|▉         | 131/1380 [00:15<02:13,  9.33it/s] 10%|▉         | 132/1380 [00:15<02:14,  9.30it/s] 10%|▉         | 133/1380 [00:15<02:13,  9.33it/s] 10%|▉         | 134/1380 [00:15<02:13,  9.31it/s] 10%|▉         | 135/1380 [00:15<02:15,  9.21it/s] 10%|▉         | 136/1380 [00:15<02:14,  9.26it/s] 10%|▉         | 137/1380 [00:15<02:13,  9.31it/s] 10%|█         | 138/1380 [00:15<02:14,  9.27it/s] 10%|█         | 139/1380 [00:16<02:13,  9.31it/s] 10%|█         | 140/1380 [00:16<02:13,  9.26it/s] 10%|█         | 141/1380 [00:16<02:13,  9.29it/s] 10%|█         | 142/1380 [00:16<02:12,  9.33it/s] 10%|█         | 143/1380 [00:16<02:13,  9.30it/s] 10%|█         | 144/1380 [00:16<02:13,  9.26it/s] 11%|█         | 145/1380 [00:16<02:13,  9.26it/s] 11%|█         | 146/1380 [00:16<02:12,  9.30it/s] 11%|█         | 147/1380 [00:16<02:13,  9.27it/s] 11%|█         | 148/1380 [00:17<02:13,  9.20it/s] 11%|█         | 149/1380 [00:17<02:13,  9.19it/s] 11%|█         | 150/1380 [00:17<02:12,  9.26it/s] 11%|█         | 151/1380 [00:17<02:12,  9.29it/s] 11%|█         | 152/1380 [00:17<02:11,  9.32it/s] 11%|█         | 153/1380 [00:17<02:11,  9.33it/s] 11%|█         | 154/1380 [00:17<02:11,  9.35it/s] 11%|█         | 155/1380 [00:17<02:10,  9.42it/s] 11%|█▏        | 156/1380 [00:17<02:11,  9.32it/s] 11%|█▏        | 157/1380 [00:18<02:11,  9.28it/s] 11%|█▏        | 158/1380 [00:18<02:11,  9.27it/s] 12%|█▏        | 159/1380 [00:18<02:11,  9.27it/s] 12%|█▏        | 160/1380 [00:18<02:10,  9.31it/s] 12%|█▏        | 161/1380 [00:18<02:11,  9.30it/s] 12%|█▏        | 162/1380 [00:18<02:11,  9.27it/s] 12%|█▏        | 163/1380 [00:18<02:12,  9.21it/s] 12%|█▏        | 164/1380 [00:18<02:11,  9.26it/s] 12%|█▏        | 165/1380 [00:18<02:10,  9.34it/s] 12%|█▏        | 166/1380 [00:19<02:10,  9.28it/s] 12%|█▏        | 167/1380 [00:19<02:10,  9.29it/s] 12%|█▏        | 168/1380 [00:19<02:10,  9.30it/s] 12%|█▏        | 169/1380 [00:19<02:10,  9.30it/s] 12%|█▏        | 170/1380 [00:19<02:09,  9.32it/s] 12%|█▏        | 171/1380 [00:19<02:10,  9.28it/s] 12%|█▏        | 172/1380 [00:19<02:11,  9.18it/s] 13%|█▎        | 173/1380 [00:19<02:10,  9.25it/s] 13%|█▎        | 174/1380 [00:19<02:10,  9.24it/s] 13%|█▎        | 175/1380 [00:19<02:08,  9.35it/s] 13%|█▎        | 176/1380 [00:20<02:10,  9.24it/s] 13%|█▎        | 177/1380 [00:20<02:10,  9.19it/s] 13%|█▎        | 178/1380 [00:20<02:10,  9.24it/s] 13%|█▎        | 179/1380 [00:20<02:09,  9.29it/s] 13%|█▎        | 180/1380 [00:20<02:10,  9.17it/s] 13%|█▎        | 181/1380 [00:20<02:11,  9.14it/s] 13%|█▎        | 182/1380 [00:20<02:10,  9.19it/s] 13%|█▎        | 183/1380 [00:20<02:09,  9.22it/s] 13%|█▎        | 184/1380 [00:20<02:10,  9.16it/s] 13%|█▎        | 185/1380 [00:21<02:10,  9.14it/s] 13%|█▎        | 186/1380 [00:21<02:10,  9.18it/s] 14%|█▎        | 187/1380 [00:21<02:09,  9.25it/s] 14%|█▎        | 188/1380 [00:21<02:07,  9.35it/s] 14%|█▎        | 189/1380 [00:21<02:08,  9.29it/s] 14%|█▍        | 190/1380 [00:21<02:07,  9.32it/s] 14%|█▍        | 191/1380 [00:21<02:08,  9.29it/s] 14%|█▍        | 192/1380 [00:21<02:07,  9.34it/s] 14%|█▍        | 193/1380 [00:21<02:07,  9.31it/s] 14%|█▍        | 194/1380 [00:22<02:08,  9.25it/s] 14%|█▍        | 195/1380 [00:22<02:09,  9.16it/s] 14%|█▍        | 196/1380 [00:22<02:08,  9.20it/s] 14%|█▍        | 197/1380 [00:22<02:08,  9.18it/s] 14%|█▍        | 198/1380 [00:22<02:07,  9.30it/s] 14%|█▍        | 199/1380 [00:22<02:08,  9.17it/s] 14%|█▍        | 200/1380 [00:22<02:08,  9.17it/s] 15%|█▍        | 201/1380 [00:22<02:07,  9.28it/s] 15%|█▍        | 202/1380 [00:22<02:06,  9.34it/s] 15%|█▍        | 203/1380 [00:23<02:06,  9.31it/s] 15%|█▍        | 204/1380 [00:23<02:07,  9.22it/s] 15%|█▍        | 205/1380 [00:23<02:07,  9.23it/s] 15%|█▍        | 206/1380 [00:23<02:06,  9.26it/s] 15%|█▌        | 207/1380 [00:23<02:07,  9.18it/s] 15%|█▌        | 208/1380 [00:23<02:06,  9.25it/s] 15%|█▌        | 209/1380 [00:23<02:07,  9.17it/s] 15%|█▌        | 210/1380 [00:23<02:07,  9.20it/s] 15%|█▌        | 211/1380 [00:23<02:06,  9.22it/s] 15%|█▌        | 212/1380 [00:23<02:05,  9.30it/s] 15%|█▌        | 213/1380 [00:24<02:05,  9.27it/s] 16%|█▌        | 214/1380 [00:24<02:06,  9.25it/s] 16%|█▌        | 215/1380 [00:24<02:05,  9.30it/s] 16%|█▌        | 216/1380 [00:24<02:04,  9.33it/s] 16%|█▌        | 217/1380 [00:24<02:05,  9.25it/s] 16%|█▌        | 218/1380 [00:24<02:06,  9.19it/s] 16%|█▌        | 219/1380 [00:24<02:06,  9.17it/s] 16%|█▌        | 220/1380 [00:24<02:05,  9.22it/s] 16%|█▌        | 221/1380 [00:24<02:05,  9.25it/s] 16%|█▌        | 222/1380 [00:25<02:05,  9.21it/s] 16%|█▌        | 223/1380 [00:25<02:05,  9.20it/s] 16%|█▌        | 224/1380 [00:25<02:04,  9.26it/s] 16%|█▋        | 225/1380 [00:25<02:03,  9.32it/s] 16%|█▋        | 226/1380 [00:25<02:04,  9.30it/s] 16%|█▋        | 227/1380 [00:25<02:04,  9.23it/s] 17%|█▋        | 228/1380 [00:25<02:04,  9.27it/s] 17%|█▋        | 229/1380 [00:25<02:03,  9.29it/s] 17%|█▋        | 230/1380 [00:25<02:03,  9.30it/s] 17%|█▋        | 231/1380 [00:26<02:04,  9.24it/s] 17%|█▋        | 232/1380 [00:26<02:04,  9.22it/s] 17%|█▋        | 233/1380 [00:26<02:03,  9.30it/s] 17%|█▋        | 234/1380 [00:26<02:02,  9.37it/s] 17%|█▋        | 235/1380 [00:26<02:02,  9.32it/s] 17%|█▋        | 236/1380 [00:26<02:03,  9.30it/s] 17%|█▋        | 237/1380 [00:26<02:02,  9.37it/s] 17%|█▋        | 238/1380 [00:26<02:02,  9.32it/s] 17%|█▋        | 239/1380 [00:26<02:01,  9.35it/s] 17%|█▋        | 240/1380 [00:27<02:01,  9.39it/s] 17%|█▋        | 241/1380 [00:27<02:01,  9.39it/s] 18%|█▊        | 242/1380 [00:27<02:01,  9.38it/s] 18%|█▊        | 243/1380 [00:27<02:01,  9.36it/s] 18%|█▊        | 244/1380 [00:27<02:02,  9.27it/s] 18%|█▊        | 245/1380 [00:27<02:01,  9.32it/s] 18%|█▊        | 246/1380 [00:27<02:02,  9.28it/s] 18%|█▊        | 247/1380 [00:27<02:01,  9.30it/s] 18%|█▊        | 248/1380 [00:27<02:01,  9.30it/s] 18%|█▊        | 249/1380 [00:27<02:00,  9.35it/s] 18%|█▊        | 250/1380 [00:28<02:00,  9.39it/s] 18%|█▊        | 251/1380 [00:28<01:59,  9.43it/s] 18%|█▊        | 252/1380 [00:28<02:00,  9.35it/s] 18%|█▊        | 253/1380 [00:28<01:59,  9.43it/s] 18%|█▊        | 254/1380 [00:28<01:59,  9.44it/s] 18%|█▊        | 255/1380 [00:28<01:59,  9.41it/s] 19%|█▊        | 256/1380 [00:28<02:00,  9.34it/s] 19%|█▊        | 257/1380 [00:28<01:59,  9.43it/s] 19%|█▊        | 258/1380 [00:28<01:59,  9.42it/s] 19%|█▉        | 259/1380 [00:29<02:00,  9.33it/s] 19%|█▉        | 260/1380 [00:29<01:59,  9.35it/s] 19%|█▉        | 261/1380 [00:29<01:58,  9.41it/s] 19%|█▉        | 262/1380 [00:29<01:58,  9.43it/s] 19%|█▉        | 263/1380 [00:29<01:58,  9.44it/s] 19%|█▉        | 264/1380 [00:29<01:58,  9.41it/s] 19%|█▉        | 265/1380 [00:29<01:58,  9.40it/s] 19%|█▉        | 266/1380 [00:29<01:58,  9.43it/s] 19%|█▉        | 267/1380 [00:29<01:58,  9.36it/s] 19%|█▉        | 268/1380 [00:29<01:59,  9.30it/s] 19%|█▉        | 269/1380 [00:30<01:58,  9.41it/s] 20%|█▉        | 270/1380 [00:30<01:57,  9.42it/s] 20%|█▉        | 271/1380 [00:30<01:58,  9.34it/s] 20%|█▉        | 272/1380 [00:30<01:58,  9.34it/s] 20%|█▉        | 273/1380 [00:30<01:57,  9.43it/s] 20%|█▉        | 274/1380 [00:30<01:57,  9.38it/s] 20%|█▉        | 275/1380 [00:30<01:57,  9.38it/s]                                                   20%|██        | 276/1380 [00:30<01:57,  9.38it/s][INFO|trainer.py:755] 2023-11-15 21:32:20,548 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:32:20,550 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:32:20,550 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:32:20,551 >>   Batch size = 8
{'loss': 0.514, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 87.92it/s][A
  7%|▋         | 18/276 [00:00<00:03, 79.59it/s][A
 10%|▉         | 27/276 [00:00<00:03, 76.80it/s][A
 13%|█▎        | 35/276 [00:00<00:03, 77.54it/s][A
 16%|█▌        | 43/276 [00:00<00:03, 76.56it/s][A
 18%|█▊        | 51/276 [00:00<00:03, 74.92it/s][A
 21%|██▏       | 59/276 [00:00<00:02, 74.75it/s][A
 24%|██▍       | 67/276 [00:00<00:02, 76.19it/s][A
 27%|██▋       | 75/276 [00:00<00:02, 76.35it/s][A
 30%|███       | 83/276 [00:01<00:02, 74.98it/s][A
 33%|███▎      | 91/276 [00:01<00:02, 74.89it/s][A
 36%|███▌      | 99/276 [00:01<00:02, 76.10it/s][A
 39%|███▉      | 107/276 [00:01<00:02, 75.06it/s][A
 42%|████▏     | 115/276 [00:01<00:02, 73.94it/s][A
 45%|████▍     | 123/276 [00:01<00:02, 74.56it/s][A
 47%|████▋     | 131/276 [00:01<00:01, 75.96it/s][A
 50%|█████     | 139/276 [00:01<00:01, 74.51it/s][A
 53%|█████▎    | 147/276 [00:01<00:01, 73.75it/s][A
 56%|█████▌    | 155/276 [00:02<00:01, 74.75it/s][A
 59%|█████▉    | 163/276 [00:02<00:01, 75.79it/s][A
 62%|██████▏   | 171/276 [00:02<00:01, 74.18it/s][A
 65%|██████▍   | 179/276 [00:02<00:01, 73.85it/s][A
 68%|██████▊   | 187/276 [00:02<00:01, 75.22it/s][A
 71%|███████   | 195/276 [00:02<00:01, 76.03it/s][A
 74%|███████▎  | 203/276 [00:02<00:00, 74.64it/s][A
 76%|███████▋  | 211/276 [00:02<00:00, 73.70it/s][A
 79%|███████▉  | 219/276 [00:02<00:00, 74.73it/s][A
 82%|████████▏ | 227/276 [00:03<00:00, 75.67it/s][A
 85%|████████▌ | 235/276 [00:03<00:00, 74.08it/s][A
 88%|████████▊ | 243/276 [00:03<00:00, 73.01it/s][A
 91%|█████████ | 251/276 [00:03<00:00, 74.97it/s][A
 94%|█████████▍| 259/276 [00:03<00:00, 74.25it/s][A
 97%|█████████▋| 267/276 [00:03<00:00, 72.63it/s][A
100%|█████████▉| 275/276 [00:03<00:00, 73.26it/s][A                                                  
                                                 [A 20%|██        | 276/1380 [00:34<01:57,  9.38it/s]
100%|██████████| 276/276 [00:03<00:00, 73.26it/s][A
                                                 [A 20%|██        | 277/1380 [00:34<17:43,  1.04it/s] 20%|██        | 278/1380 [00:34<13:48,  1.33it/s] 20%|██        | 279/1380 [00:34<10:41,  1.72it/s] 20%|██        | 280/1380 [00:34<08:18,  2.21it/s] 20%|██        | 281/1380 [00:35<06:32,  2.80it/s] 20%|██        | 282/1380 [00:35<05:13,  3.50it/s] 21%|██        | 283/1380 [00:35<04:15,  4.29it/s] 21%|██        | 284/1380 [00:35<03:35,  5.09it/s] 21%|██        | 285/1380 [00:35<03:06,  5.88it/s] 21%|██        | 286/1380 [00:35<02:46,  6.58it/s] 21%|██        | 287/1380 [00:35<02:30,  7.24it/s] 21%|██        | 288/1380 [00:35<02:21,  7.69it/s] 21%|██        | 289/1380 [00:35<02:15,  8.06it/s] 21%|██        | 290/1380 [00:36<02:09,  8.39it/s] 21%|██        | 291/1380 [00:36<02:06,  8.61it/s] 21%|██        | 292/1380 [00:36<02:02,  8.85it/s] 21%|██        | 293/1380 [00:36<02:02,  8.87it/s] 21%|██▏       | 294/1380 [00:36<02:00,  9.02it/s] 21%|██▏       | 295/1380 [00:36<01:58,  9.14it/s] 21%|██▏       | 296/1380 [00:36<01:58,  9.13it/s] 22%|██▏       | 297/1380 [00:36<01:57,  9.23it/s] 22%|██▏       | 298/1380 [00:36<01:57,  9.22it/s] 22%|██▏       | 299/1380 [00:37<01:55,  9.32it/s] 22%|██▏       | 300/1380 [00:37<01:56,  9.23it/s] 22%|██▏       | 301/1380 [00:37<01:57,  9.22it/s] 22%|██▏       | 302/1380 [00:37<01:56,  9.26it/s] 22%|██▏       | 303/1380 [00:37<01:56,  9.26it/s] 22%|██▏       | 304/1380 [00:37<01:55,  9.28it/s] 22%|██▏       | 305/1380 [00:37<01:55,  9.30it/s] 22%|██▏       | 306/1380 [00:37<01:55,  9.34it/s] 22%|██▏       | 307/1380 [00:37<01:55,  9.28it/s] 22%|██▏       | 308/1380 [00:38<01:55,  9.29it/s] 22%|██▏       | 309/1380 [00:38<01:55,  9.30it/s] 22%|██▏       | 310/1380 [00:38<01:54,  9.32it/s] 23%|██▎       | 311/1380 [00:38<01:54,  9.31it/s] 23%|██▎       | 312/1380 [00:38<01:54,  9.30it/s] 23%|██▎       | 313/1380 [00:38<01:54,  9.34it/s] 23%|██▎       | 314/1380 [00:38<01:53,  9.41it/s] 23%|██▎       | 315/1380 [00:38<01:53,  9.35it/s] 23%|██▎       | 316/1380 [00:38<01:54,  9.29it/s] 23%|██▎       | 317/1380 [00:38<01:53,  9.33it/s] 23%|██▎       | 318/1380 [00:39<01:53,  9.36it/s] 23%|██▎       | 319/1380 [00:39<01:53,  9.35it/s] 23%|██▎       | 320/1380 [00:39<01:54,  9.28it/s] 23%|██▎       | 321/1380 [00:39<01:53,  9.33it/s] 23%|██▎       | 322/1380 [00:39<01:53,  9.36it/s] 23%|██▎       | 323/1380 [00:39<01:53,  9.31it/s] 23%|██▎       | 324/1380 [00:39<01:53,  9.32it/s] 24%|██▎       | 325/1380 [00:39<01:52,  9.36it/s] 24%|██▎       | 326/1380 [00:39<01:52,  9.36it/s] 24%|██▎       | 327/1380 [00:40<01:52,  9.39it/s] 24%|██▍       | 328/1380 [00:40<01:53,  9.28it/s] 24%|██▍       | 329/1380 [00:40<01:52,  9.35it/s] 24%|██▍       | 330/1380 [00:40<01:52,  9.33it/s] 24%|██▍       | 331/1380 [00:40<01:53,  9.28it/s] 24%|██▍       | 332/1380 [00:40<01:53,  9.26it/s] 24%|██▍       | 333/1380 [00:40<01:51,  9.38it/s] 24%|██▍       | 334/1380 [00:40<01:52,  9.34it/s] 24%|██▍       | 335/1380 [00:40<01:52,  9.29it/s] 24%|██▍       | 336/1380 [00:41<01:52,  9.30it/s] 24%|██▍       | 337/1380 [00:41<01:51,  9.33it/s] 24%|██▍       | 338/1380 [00:41<01:51,  9.31it/s] 25%|██▍       | 339/1380 [00:41<01:52,  9.27it/s] 25%|██▍       | 340/1380 [00:41<01:51,  9.31it/s] 25%|██▍       | 341/1380 [00:41<01:50,  9.39it/s] 25%|██▍       | 342/1380 [00:41<01:51,  9.30it/s] 25%|██▍       | 343/1380 [00:41<01:52,  9.21it/s] 25%|██▍       | 344/1380 [00:41<01:51,  9.26it/s] 25%|██▌       | 345/1380 [00:41<01:51,  9.30it/s] 25%|██▌       | 346/1380 [00:42<01:52,  9.21it/s] 25%|██▌       | 347/1380 [00:42<01:51,  9.22it/s] 25%|██▌       | 348/1380 [00:42<01:51,  9.25it/s] 25%|██▌       | 349/1380 [00:42<01:50,  9.30it/s] 25%|██▌       | 350/1380 [00:42<01:51,  9.21it/s] 25%|██▌       | 351/1380 [00:42<01:52,  9.18it/s] 26%|██▌       | 352/1380 [00:42<01:50,  9.31it/s] 26%|██▌       | 353/1380 [00:42<01:50,  9.27it/s] 26%|██▌       | 354/1380 [00:42<01:50,  9.29it/s] 26%|██▌       | 355/1380 [00:43<01:50,  9.28it/s] 26%|██▌       | 356/1380 [00:43<01:49,  9.37it/s] 26%|██▌       | 357/1380 [00:43<01:50,  9.26it/s] 26%|██▌       | 358/1380 [00:43<01:50,  9.26it/s] 26%|██▌       | 359/1380 [00:43<01:49,  9.28it/s] 26%|██▌       | 360/1380 [00:43<01:49,  9.35it/s] 26%|██▌       | 361/1380 [00:43<01:49,  9.26it/s] 26%|██▌       | 362/1380 [00:43<01:50,  9.24it/s] 26%|██▋       | 363/1380 [00:43<01:49,  9.31it/s] 26%|██▋       | 364/1380 [00:44<01:49,  9.25it/s] 26%|██▋       | 365/1380 [00:44<01:48,  9.32it/s] 27%|██▋       | 366/1380 [00:44<01:49,  9.25it/s] 27%|██▋       | 367/1380 [00:44<01:48,  9.32it/s] 27%|██▋       | 368/1380 [00:44<01:48,  9.34it/s] 27%|██▋       | 369/1380 [00:44<01:49,  9.22it/s] 27%|██▋       | 370/1380 [00:44<01:48,  9.28it/s] 27%|██▋       | 371/1380 [00:44<01:47,  9.39it/s] 27%|██▋       | 372/1380 [00:44<01:48,  9.31it/s] 27%|██▋       | 373/1380 [00:44<01:48,  9.30it/s] 27%|██▋       | 374/1380 [00:45<01:47,  9.34it/s] 27%|██▋       | 375/1380 [00:45<01:47,  9.38it/s] 27%|██▋       | 376/1380 [00:45<01:47,  9.38it/s] 27%|██▋       | 377/1380 [00:45<01:47,  9.35it/s] 27%|██▋       | 378/1380 [00:45<01:46,  9.40it/s] 27%|██▋       | 379/1380 [00:45<01:46,  9.39it/s] 28%|██▊       | 380/1380 [00:45<01:46,  9.37it/s] 28%|██▊       | 381/1380 [00:45<01:47,  9.30it/s] 28%|██▊       | 382/1380 [00:45<01:46,  9.39it/s] 28%|██▊       | 383/1380 [00:46<01:46,  9.35it/s] 28%|██▊       | 384/1380 [00:46<01:46,  9.33it/s] 28%|██▊       | 385/1380 [00:46<01:46,  9.31it/s] 28%|██▊       | 386/1380 [00:46<01:46,  9.33it/s] 28%|██▊       | 387/1380 [00:46<01:45,  9.40it/s] 28%|██▊       | 388/1380 [00:46<01:46,  9.31it/s] 28%|██▊       | 389/1380 [00:46<01:46,  9.33it/s] 28%|██▊       | 390/1380 [00:46<01:45,  9.40it/s] 28%|██▊       | 391/1380 [00:46<01:45,  9.35it/s] 28%|██▊       | 392/1380 [00:47<01:45,  9.36it/s] 28%|██▊       | 393/1380 [00:47<01:45,  9.34it/s] 29%|██▊       | 394/1380 [00:47<01:45,  9.38it/s] 29%|██▊       | 395/1380 [00:47<01:45,  9.36it/s] 29%|██▊       | 396/1380 [00:47<01:45,  9.33it/s] 29%|██▉       | 397/1380 [00:47<01:45,  9.35it/s] 29%|██▉       | 398/1380 [00:47<01:45,  9.33it/s] 29%|██▉       | 399/1380 [00:47<01:45,  9.29it/s] 29%|██▉       | 400/1380 [00:47<01:45,  9.27it/s] 29%|██▉       | 401/1380 [00:47<01:44,  9.38it/s] 29%|██▉       | 402/1380 [00:48<01:45,  9.31it/s] 29%|██▉       | 403/1380 [00:48<01:45,  9.26it/s] 29%|██▉       | 404/1380 [00:48<01:44,  9.30it/s] 29%|██▉       | 405/1380 [00:48<01:45,  9.29it/s] 29%|██▉       | 406/1380 [00:48<01:44,  9.32it/s] 29%|██▉       | 407/1380 [00:48<01:45,  9.26it/s] 30%|██▉       | 408/1380 [00:48<01:44,  9.33it/s] 30%|██▉       | 409/1380 [00:48<01:44,  9.30it/s] 30%|██▉       | 410/1380 [00:48<01:44,  9.25it/s] 30%|██▉       | 411/1380 [00:49<01:45,  9.21it/s] 30%|██▉       | 412/1380 [00:49<01:43,  9.31it/s] 30%|██▉       | 413/1380 [00:49<01:44,  9.30it/s] 30%|███       | 414/1380 [00:49<01:44,  9.26it/s] 30%|███       | 415/1380 [00:49<01:44,  9.26it/s] 30%|███       | 416/1380 [00:49<01:43,  9.33it/s] 30%|███       | 417/1380 [00:49<01:44,  9.25it/s] 30%|███       | 418/1380 [00:49<01:44,  9.19it/s] 30%|███       | 419/1380 [00:49<01:43,  9.27it/s] 30%|███       | 420/1380 [00:50<01:43,  9.28it/s] 31%|███       | 421/1380 [00:50<01:43,  9.26it/s] 31%|███       | 422/1380 [00:50<01:44,  9.17it/s] 31%|███       | 423/1380 [00:50<01:43,  9.27it/s] 31%|███       | 424/1380 [00:50<01:43,  9.25it/s] 31%|███       | 425/1380 [00:50<01:43,  9.27it/s] 31%|███       | 426/1380 [00:50<01:43,  9.22it/s] 31%|███       | 427/1380 [00:50<01:43,  9.24it/s] 31%|███       | 428/1380 [00:50<01:42,  9.28it/s] 31%|███       | 429/1380 [00:51<01:42,  9.24it/s] 31%|███       | 430/1380 [00:51<01:42,  9.26it/s] 31%|███       | 431/1380 [00:51<01:41,  9.32it/s] 31%|███▏      | 432/1380 [00:51<01:41,  9.30it/s] 31%|███▏      | 433/1380 [00:51<01:42,  9.25it/s] 31%|███▏      | 434/1380 [00:51<01:42,  9.27it/s] 32%|███▏      | 435/1380 [00:51<01:41,  9.33it/s] 32%|███▏      | 436/1380 [00:51<01:42,  9.21it/s] 32%|███▏      | 437/1380 [00:51<01:41,  9.25it/s] 32%|███▏      | 438/1380 [00:51<01:41,  9.27it/s] 32%|███▏      | 439/1380 [00:52<01:40,  9.34it/s] 32%|███▏      | 440/1380 [00:52<01:41,  9.25it/s] 32%|███▏      | 441/1380 [00:52<01:41,  9.25it/s] 32%|███▏      | 442/1380 [00:52<01:40,  9.30it/s] 32%|███▏      | 443/1380 [00:52<01:41,  9.26it/s] 32%|███▏      | 444/1380 [00:52<01:40,  9.34it/s] 32%|███▏      | 445/1380 [00:52<01:40,  9.29it/s] 32%|███▏      | 446/1380 [00:52<01:40,  9.31it/s] 32%|███▏      | 447/1380 [00:52<01:39,  9.36it/s] 32%|███▏      | 448/1380 [00:53<01:39,  9.32it/s] 33%|███▎      | 449/1380 [00:53<01:41,  9.22it/s] 33%|███▎      | 450/1380 [00:53<01:40,  9.29it/s] 33%|███▎      | 451/1380 [00:53<01:39,  9.34it/s] 33%|███▎      | 452/1380 [00:53<01:40,  9.25it/s] 33%|███▎      | 453/1380 [00:53<01:40,  9.25it/s] 33%|███▎      | 454/1380 [00:53<01:39,  9.27it/s] 33%|███▎      | 455/1380 [00:53<01:39,  9.29it/s] 33%|███▎      | 456/1380 [00:53<01:39,  9.26it/s] 33%|███▎      | 457/1380 [00:54<01:39,  9.29it/s] 33%|███▎      | 458/1380 [00:54<01:38,  9.34it/s] 33%|███▎      | 459/1380 [00:54<01:38,  9.32it/s] 33%|███▎      | 460/1380 [00:54<01:39,  9.24it/s] 33%|███▎      | 461/1380 [00:54<01:38,  9.31it/s] 33%|███▎      | 462/1380 [00:54<01:38,  9.28it/s] 34%|███▎      | 463/1380 [00:54<01:37,  9.39it/s] 34%|███▎      | 464/1380 [00:54<01:39,  9.23it/s] 34%|███▎      | 465/1380 [00:54<01:38,  9.26it/s] 34%|███▍      | 466/1380 [00:54<01:38,  9.33it/s] 34%|███▍      | 467/1380 [00:55<01:38,  9.24it/s] 34%|███▍      | 468/1380 [00:55<01:38,  9.29it/s] 34%|███▍      | 469/1380 [00:55<01:37,  9.37it/s] 34%|███▍      | 470/1380 [00:55<01:37,  9.37it/s] 34%|███▍      | 471/1380 [00:55<01:37,  9.31it/s] 34%|███▍      | 472/1380 [00:55<01:37,  9.27it/s] 34%|███▍      | 473/1380 [00:55<01:37,  9.32it/s] 34%|███▍      | 474/1380 [00:55<01:37,  9.31it/s] 34%|███▍      | 475/1380 [00:55<01:37,  9.25it/s] 34%|███▍      | 476/1380 [00:56<01:37,  9.27it/s] 35%|███▍      | 477/1380 [00:56<01:36,  9.31it/s] 35%|███▍      | 478/1380 [00:56<01:37,  9.25it/s] 35%|███▍      | 479/1380 [00:56<01:37,  9.21it/s] 35%|███▍      | 480/1380 [00:56<01:37,  9.25it/s] 35%|███▍      | 481/1380 [00:56<01:37,  9.22it/s] 35%|███▍      | 482/1380 [00:56<01:36,  9.28it/s] 35%|███▌      | 483/1380 [00:56<01:37,  9.24it/s] 35%|███▌      | 484/1380 [00:56<01:36,  9.29it/s] 35%|███▌      | 485/1380 [00:57<01:35,  9.37it/s] 35%|███▌      | 486/1380 [00:57<01:36,  9.31it/s] 35%|███▌      | 487/1380 [00:57<01:36,  9.27it/s] 35%|███▌      | 488/1380 [00:57<01:35,  9.32it/s] 35%|███▌      | 489/1380 [00:57<01:34,  9.42it/s] 36%|███▌      | 490/1380 [00:57<01:36,  9.27it/s] 36%|███▌      | 491/1380 [00:57<01:36,  9.23it/s] 36%|███▌      | 492/1380 [00:57<01:35,  9.34it/s] 36%|███▌      | 493/1380 [00:57<01:34,  9.35it/s] 36%|███▌      | 494/1380 [00:58<01:35,  9.32it/s] 36%|███▌      | 495/1380 [00:58<01:35,  9.29it/s] 36%|███▌      | 496/1380 [00:58<01:34,  9.32it/s] 36%|███▌      | 497/1380 [00:58<01:34,  9.30it/s] 36%|███▌      | 498/1380 [00:58<01:34,  9.34it/s] 36%|███▌      | 499/1380 [00:58<01:35,  9.24it/s] 36%|███▌      | 500/1380 [00:58<01:34,  9.27it/s] 36%|███▋      | 501/1380 [00:58<01:34,  9.28it/s] 36%|███▋      | 502/1380 [00:58<01:35,  9.20it/s] 36%|███▋      | 503/1380 [00:58<01:34,  9.25it/s] 37%|███▋      | 504/1380 [00:59<01:33,  9.33it/s] 37%|███▋      | 505/1380 [00:59<01:34,  9.26it/s] 37%|███▋      | 506/1380 [00:59<01:35,  9.20it/s] 37%|███▋      | 507/1380 [00:59<01:33,  9.33it/s] 37%|███▋      | 508/1380 [00:59<01:33,  9.30it/s] 37%|███▋      | 509/1380 [00:59<01:34,  9.20it/s] 37%|███▋      | 510/1380 [00:59<01:33,  9.26it/s] 37%|███▋      | 511/1380 [00:59<01:33,  9.32it/s] 37%|███▋      | 512/1380 [00:59<01:33,  9.31it/s] 37%|███▋      | 513/1380 [01:00<01:33,  9.23it/s] 37%|███▋      | 514/1380 [01:00<01:33,  9.24it/s] 37%|███▋      | 515/1380 [01:00<01:33,  9.27it/s] 37%|███▋      | 516/1380 [01:00<01:33,  9.26it/s] 37%|███▋      | 517/1380 [01:00<01:33,  9.21it/s] 38%|███▊      | 518/1380 [01:00<01:32,  9.28it/s] 38%|███▊      | 519/1380 [01:00<01:33,  9.24it/s] 38%|███▊      | 520/1380 [01:00<01:32,  9.26it/s] 38%|███▊      | 521/1380 [01:00<01:32,  9.24it/s] 38%|███▊      | 522/1380 [01:01<01:33,  9.20it/s] 38%|███▊      | 523/1380 [01:01<01:32,  9.28it/s] 38%|███▊      | 524/1380 [01:01<01:33,  9.16it/s] 38%|███▊      | 525/1380 [01:01<01:32,  9.26it/s] 38%|███▊      | 526/1380 [01:01<01:31,  9.31it/s] 38%|███▊      | 527/1380 [01:01<01:31,  9.32it/s] 38%|███▊      | 528/1380 [01:01<01:32,  9.25it/s] 38%|███▊      | 529/1380 [01:01<01:31,  9.28it/s] 38%|███▊      | 530/1380 [01:01<01:31,  9.32it/s] 38%|███▊      | 531/1380 [01:01<01:31,  9.24it/s] 39%|███▊      | 532/1380 [01:02<01:31,  9.28it/s] 39%|███▊      | 533/1380 [01:02<01:30,  9.31it/s] 39%|███▊      | 534/1380 [01:02<01:30,  9.35it/s] 39%|███▉      | 535/1380 [01:02<01:31,  9.28it/s] 39%|███▉      | 536/1380 [01:02<01:31,  9.21it/s] 39%|███▉      | 537/1380 [01:02<01:30,  9.28it/s] 39%|███▉      | 538/1380 [01:02<01:31,  9.23it/s] 39%|███▉      | 539/1380 [01:02<01:31,  9.24it/s] 39%|███▉      | 540/1380 [01:02<01:31,  9.23it/s] 39%|███▉      | 541/1380 [01:03<01:30,  9.27it/s] 39%|███▉      | 542/1380 [01:03<01:29,  9.31it/s] 39%|███▉      | 543/1380 [01:03<01:31,  9.16it/s] 39%|███▉      | 544/1380 [01:03<01:30,  9.23it/s] 39%|███▉      | 545/1380 [01:03<01:29,  9.33it/s] 40%|███▉      | 546/1380 [01:03<01:30,  9.25it/s] 40%|███▉      | 547/1380 [01:03<01:30,  9.21it/s] 40%|███▉      | 548/1380 [01:03<01:29,  9.27it/s] 40%|███▉      | 549/1380 [01:03<01:29,  9.31it/s] 40%|███▉      | 550/1380 [01:04<01:30,  9.21it/s] 40%|███▉      | 551/1380 [01:04<01:30,  9.17it/s]                                                   40%|████      | 552/1380 [01:04<01:30,  9.17it/s][INFO|trainer.py:755] 2023-11-15 21:32:53,980 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:32:53,982 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:32:53,983 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:32:53,983 >>   Batch size = 8
{'eval_loss': 0.40327879786491394, 'eval_accuracy': 0.8557168784029038, 'eval_micro_f1': 0.8557168784029038, 'eval_macro_f1': 0.8460032247726872, 'eval_runtime': 3.7467, 'eval_samples_per_second': 588.245, 'eval_steps_per_second': 73.664, 'epoch': 1.0}
{'loss': 0.3094, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 87.46it/s][A
  7%|▋         | 18/276 [00:00<00:03, 75.34it/s][A
  9%|▉         | 26/276 [00:00<00:03, 76.66it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 76.85it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 74.39it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 74.55it/s][A
 21%|██        | 58/276 [00:00<00:02, 74.99it/s][A
 24%|██▍       | 66/276 [00:00<00:02, 75.72it/s][A
 27%|██▋       | 74/276 [00:00<00:02, 75.66it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 73.00it/s][A
 33%|███▎      | 90/276 [00:01<00:02, 74.18it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 75.24it/s][A
 38%|███▊      | 106/276 [00:01<00:02, 73.89it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 73.49it/s][A
 44%|████▍     | 122/276 [00:01<00:02, 74.59it/s][A
 47%|████▋     | 130/276 [00:01<00:01, 75.24it/s][A
 50%|█████     | 138/276 [00:01<00:01, 72.77it/s][A
 53%|█████▎    | 146/276 [00:01<00:01, 73.00it/s][A
 56%|█████▌    | 154/276 [00:02<00:01, 74.21it/s][A
 59%|█████▊    | 162/276 [00:02<00:01, 73.44it/s][A
 62%|██████▏   | 170/276 [00:02<00:01, 73.04it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 73.76it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 74.38it/s][A
 70%|███████   | 194/276 [00:02<00:01, 73.20it/s][A
 73%|███████▎  | 202/276 [00:02<00:01, 72.95it/s][A
 76%|███████▌  | 210/276 [00:02<00:00, 74.46it/s][A
 79%|███████▉  | 218/276 [00:02<00:00, 75.23it/s][A
 82%|████████▏ | 226/276 [00:03<00:00, 75.40it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 73.84it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 74.88it/s][A
 91%|█████████ | 250/276 [00:03<00:00, 75.79it/s][A
 93%|█████████▎| 258/276 [00:03<00:00, 74.36it/s][A
 96%|█████████▋| 266/276 [00:03<00:00, 73.98it/s][A
 99%|█████████▉| 274/276 [00:03<00:00, 75.48it/s][A                                                  
                                                 [A 40%|████      | 552/1380 [01:07<01:30,  9.17it/s]
100%|██████████| 276/276 [00:03<00:00, 75.48it/s][A
                                                 [A 40%|████      | 553/1380 [01:08<13:21,  1.03it/s] 40%|████      | 554/1380 [01:08<10:24,  1.32it/s] 40%|████      | 555/1380 [01:08<08:03,  1.70it/s] 40%|████      | 556/1380 [01:08<06:16,  2.19it/s] 40%|████      | 557/1380 [01:08<04:56,  2.78it/s] 40%|████      | 558/1380 [01:08<03:56,  3.48it/s] 41%|████      | 559/1380 [01:08<03:14,  4.23it/s] 41%|████      | 560/1380 [01:08<02:42,  5.03it/s] 41%|████      | 561/1380 [01:08<02:20,  5.84it/s] 41%|████      | 562/1380 [01:09<02:05,  6.52it/s] 41%|████      | 563/1380 [01:09<01:54,  7.13it/s] 41%|████      | 564/1380 [01:09<01:45,  7.71it/s] 41%|████      | 565/1380 [01:09<01:40,  8.12it/s] 41%|████      | 566/1380 [01:09<01:36,  8.42it/s] 41%|████      | 567/1380 [01:09<01:33,  8.69it/s] 41%|████      | 568/1380 [01:09<01:31,  8.90it/s] 41%|████      | 569/1380 [01:09<01:30,  8.97it/s] 41%|████▏     | 570/1380 [01:09<01:30,  9.00it/s] 41%|████▏     | 571/1380 [01:10<01:28,  9.11it/s] 41%|████▏     | 572/1380 [01:10<01:28,  9.13it/s] 42%|████▏     | 573/1380 [01:10<01:28,  9.09it/s] 42%|████▏     | 574/1380 [01:10<01:28,  9.13it/s] 42%|████▏     | 575/1380 [01:10<01:26,  9.26it/s] 42%|████▏     | 576/1380 [01:10<01:27,  9.22it/s] 42%|████▏     | 577/1380 [01:10<01:27,  9.21it/s] 42%|████▏     | 578/1380 [01:10<01:26,  9.25it/s] 42%|████▏     | 579/1380 [01:10<01:26,  9.26it/s] 42%|████▏     | 580/1380 [01:11<01:26,  9.30it/s] 42%|████▏     | 581/1380 [01:11<01:28,  9.05it/s] 42%|████▏     | 582/1380 [01:11<01:26,  9.17it/s] 42%|████▏     | 583/1380 [01:11<01:26,  9.21it/s] 42%|████▏     | 584/1380 [01:11<01:26,  9.16it/s] 42%|████▏     | 585/1380 [01:11<01:27,  9.13it/s] 42%|████▏     | 586/1380 [01:11<01:26,  9.22it/s] 43%|████▎     | 587/1380 [01:11<01:26,  9.19it/s] 43%|████▎     | 588/1380 [01:11<01:26,  9.13it/s] 43%|████▎     | 589/1380 [01:12<01:26,  9.18it/s] 43%|████▎     | 590/1380 [01:12<01:25,  9.24it/s] 43%|████▎     | 591/1380 [01:12<01:25,  9.18it/s] 43%|████▎     | 592/1380 [01:12<01:25,  9.20it/s] 43%|████▎     | 593/1380 [01:12<01:24,  9.26it/s] 43%|████▎     | 594/1380 [01:12<01:25,  9.21it/s] 43%|████▎     | 595/1380 [01:12<01:25,  9.23it/s] 43%|████▎     | 596/1380 [01:12<01:25,  9.18it/s] 43%|████▎     | 597/1380 [01:12<01:24,  9.23it/s] 43%|████▎     | 598/1380 [01:12<01:24,  9.21it/s] 43%|████▎     | 599/1380 [01:13<01:24,  9.22it/s] 43%|████▎     | 600/1380 [01:13<01:25,  9.17it/s] 44%|████▎     | 601/1380 [01:13<01:25,  9.14it/s] 44%|████▎     | 602/1380 [01:13<01:23,  9.26it/s] 44%|████▎     | 603/1380 [01:13<01:24,  9.16it/s] 44%|████▍     | 604/1380 [01:13<01:24,  9.19it/s] 44%|████▍     | 605/1380 [01:13<01:23,  9.25it/s] 44%|████▍     | 606/1380 [01:13<01:23,  9.23it/s] 44%|████▍     | 607/1380 [01:13<01:24,  9.15it/s] 44%|████▍     | 608/1380 [01:14<01:24,  9.12it/s] 44%|████▍     | 609/1380 [01:14<01:23,  9.20it/s] 44%|████▍     | 610/1380 [01:14<01:23,  9.17it/s] 44%|████▍     | 611/1380 [01:14<01:23,  9.17it/s] 44%|████▍     | 612/1380 [01:14<01:23,  9.21it/s] 44%|████▍     | 613/1380 [01:14<01:23,  9.22it/s] 44%|████▍     | 614/1380 [01:14<01:23,  9.19it/s] 45%|████▍     | 615/1380 [01:14<01:23,  9.12it/s] 45%|████▍     | 616/1380 [01:14<01:23,  9.15it/s] 45%|████▍     | 617/1380 [01:15<01:23,  9.17it/s] 45%|████▍     | 618/1380 [01:15<01:22,  9.24it/s] 45%|████▍     | 619/1380 [01:15<01:23,  9.12it/s] 45%|████▍     | 620/1380 [01:15<01:23,  9.14it/s] 45%|████▌     | 621/1380 [01:15<01:21,  9.27it/s] 45%|████▌     | 622/1380 [01:15<01:22,  9.18it/s] 45%|████▌     | 623/1380 [01:15<01:22,  9.19it/s] 45%|████▌     | 624/1380 [01:15<01:21,  9.22it/s] 45%|████▌     | 625/1380 [01:15<01:21,  9.27it/s] 45%|████▌     | 626/1380 [01:16<01:21,  9.20it/s] 45%|████▌     | 627/1380 [01:16<01:21,  9.18it/s] 46%|████▌     | 628/1380 [01:16<01:21,  9.20it/s] 46%|████▌     | 629/1380 [01:16<01:21,  9.22it/s] 46%|████▌     | 630/1380 [01:16<01:22,  9.13it/s] 46%|████▌     | 631/1380 [01:16<01:21,  9.19it/s] 46%|████▌     | 632/1380 [01:16<01:21,  9.16it/s] 46%|████▌     | 633/1380 [01:16<01:21,  9.14it/s] 46%|████▌     | 634/1380 [01:16<01:21,  9.14it/s] 46%|████▌     | 635/1380 [01:17<01:22,  9.06it/s] 46%|████▌     | 636/1380 [01:17<01:21,  9.13it/s] 46%|████▌     | 637/1380 [01:17<01:20,  9.24it/s] 46%|████▌     | 638/1380 [01:17<01:20,  9.19it/s] 46%|████▋     | 639/1380 [01:17<01:21,  9.13it/s] 46%|████▋     | 640/1380 [01:17<01:20,  9.24it/s] 46%|████▋     | 641/1380 [01:17<01:20,  9.21it/s] 47%|████▋     | 642/1380 [01:17<01:20,  9.20it/s] 47%|████▋     | 643/1380 [01:17<01:20,  9.19it/s] 47%|████▋     | 644/1380 [01:17<01:19,  9.24it/s] 47%|████▋     | 645/1380 [01:18<01:19,  9.24it/s] 47%|████▋     | 646/1380 [01:18<01:19,  9.23it/s] 47%|████▋     | 647/1380 [01:18<01:19,  9.24it/s] 47%|████▋     | 648/1380 [01:18<01:18,  9.30it/s] 47%|████▋     | 649/1380 [01:18<01:19,  9.20it/s] 47%|████▋     | 650/1380 [01:18<01:19,  9.20it/s] 47%|████▋     | 651/1380 [01:18<01:19,  9.20it/s] 47%|████▋     | 652/1380 [01:18<01:18,  9.24it/s] 47%|████▋     | 653/1380 [01:18<01:18,  9.26it/s] 47%|████▋     | 654/1380 [01:19<01:19,  9.19it/s] 47%|████▋     | 655/1380 [01:19<01:18,  9.24it/s] 48%|████▊     | 656/1380 [01:19<01:18,  9.26it/s] 48%|████▊     | 657/1380 [01:19<01:18,  9.21it/s] 48%|████▊     | 658/1380 [01:19<01:18,  9.16it/s] 48%|████▊     | 659/1380 [01:19<01:17,  9.29it/s] 48%|████▊     | 660/1380 [01:19<01:17,  9.26it/s] 48%|████▊     | 661/1380 [01:19<01:17,  9.24it/s] 48%|████▊     | 662/1380 [01:19<01:17,  9.24it/s] 48%|████▊     | 663/1380 [01:20<01:17,  9.27it/s] 48%|████▊     | 664/1380 [01:20<01:17,  9.20it/s] 48%|████▊     | 665/1380 [01:20<01:18,  9.11it/s] 48%|████▊     | 666/1380 [01:20<01:17,  9.20it/s] 48%|████▊     | 667/1380 [01:20<01:17,  9.19it/s] 48%|████▊     | 668/1380 [01:20<01:17,  9.22it/s] 48%|████▊     | 669/1380 [01:20<01:17,  9.22it/s] 49%|████▊     | 670/1380 [01:20<01:16,  9.30it/s] 49%|████▊     | 671/1380 [01:20<01:17,  9.19it/s] 49%|████▊     | 672/1380 [01:21<01:17,  9.15it/s] 49%|████▉     | 673/1380 [01:21<01:16,  9.23it/s] 49%|████▉     | 674/1380 [01:21<01:16,  9.17it/s] 49%|████▉     | 675/1380 [01:21<01:16,  9.20it/s] 49%|████▉     | 676/1380 [01:21<01:16,  9.20it/s] 49%|████▉     | 677/1380 [01:21<01:16,  9.25it/s] 49%|████▉     | 678/1380 [01:21<01:15,  9.32it/s] 49%|████▉     | 679/1380 [01:21<01:15,  9.26it/s] 49%|████▉     | 680/1380 [01:21<01:15,  9.30it/s] 49%|████▉     | 681/1380 [01:21<01:14,  9.35it/s] 49%|████▉     | 682/1380 [01:22<01:14,  9.31it/s] 49%|████▉     | 683/1380 [01:22<01:15,  9.28it/s] 50%|████▉     | 684/1380 [01:22<01:15,  9.27it/s] 50%|████▉     | 685/1380 [01:22<01:14,  9.32it/s] 50%|████▉     | 686/1380 [01:22<01:14,  9.25it/s] 50%|████▉     | 687/1380 [01:22<01:15,  9.22it/s] 50%|████▉     | 688/1380 [01:22<01:14,  9.24it/s] 50%|████▉     | 689/1380 [01:22<01:14,  9.27it/s] 50%|█████     | 690/1380 [01:22<01:15,  9.13it/s] 50%|█████     | 691/1380 [01:23<01:15,  9.08it/s] 50%|█████     | 692/1380 [01:23<01:15,  9.15it/s] 50%|█████     | 693/1380 [01:23<01:14,  9.21it/s] 50%|█████     | 694/1380 [01:23<01:13,  9.27it/s] 50%|█████     | 695/1380 [01:23<01:14,  9.23it/s] 50%|█████     | 696/1380 [01:23<01:14,  9.16it/s] 51%|█████     | 697/1380 [01:23<01:13,  9.26it/s] 51%|█████     | 698/1380 [01:23<01:14,  9.18it/s] 51%|█████     | 699/1380 [01:23<01:14,  9.11it/s] 51%|█████     | 700/1380 [01:24<01:14,  9.17it/s] 51%|█████     | 701/1380 [01:24<01:14,  9.15it/s] 51%|█████     | 702/1380 [01:24<01:14,  9.12it/s] 51%|█████     | 703/1380 [01:24<01:14,  9.11it/s] 51%|█████     | 704/1380 [01:24<01:13,  9.16it/s] 51%|█████     | 705/1380 [01:24<01:13,  9.18it/s] 51%|█████     | 706/1380 [01:24<01:13,  9.18it/s] 51%|█████     | 707/1380 [01:24<01:14,  9.07it/s] 51%|█████▏    | 708/1380 [01:24<01:13,  9.17it/s] 51%|█████▏    | 709/1380 [01:25<01:13,  9.18it/s] 51%|█████▏    | 710/1380 [01:25<01:13,  9.17it/s] 52%|█████▏    | 711/1380 [01:25<01:13,  9.06it/s] 52%|█████▏    | 712/1380 [01:25<01:13,  9.11it/s] 52%|█████▏    | 713/1380 [01:25<01:12,  9.21it/s] 52%|█████▏    | 714/1380 [01:25<01:12,  9.18it/s] 52%|█████▏    | 715/1380 [01:25<01:12,  9.12it/s] 52%|█████▏    | 716/1380 [01:25<01:12,  9.15it/s] 52%|█████▏    | 717/1380 [01:25<01:12,  9.14it/s] 52%|█████▏    | 718/1380 [01:26<01:12,  9.12it/s] 52%|█████▏    | 719/1380 [01:26<01:13,  9.03it/s] 52%|█████▏    | 720/1380 [01:26<01:12,  9.10it/s] 52%|█████▏    | 721/1380 [01:26<01:12,  9.10it/s] 52%|█████▏    | 722/1380 [01:26<01:13,  8.95it/s] 52%|█████▏    | 723/1380 [01:26<01:12,  9.01it/s] 52%|█████▏    | 724/1380 [01:26<01:12,  9.09it/s] 53%|█████▎    | 725/1380 [01:26<01:12,  9.07it/s] 53%|█████▎    | 726/1380 [01:26<01:11,  9.12it/s] 53%|█████▎    | 727/1380 [01:27<01:11,  9.10it/s] 53%|█████▎    | 728/1380 [01:27<01:11,  9.13it/s] 53%|█████▎    | 729/1380 [01:27<01:10,  9.24it/s] 53%|█████▎    | 730/1380 [01:27<01:10,  9.18it/s] 53%|█████▎    | 731/1380 [01:27<01:11,  9.14it/s] 53%|█████▎    | 732/1380 [01:27<01:10,  9.20it/s] 53%|█████▎    | 733/1380 [01:27<01:10,  9.22it/s] 53%|█████▎    | 734/1380 [01:27<01:10,  9.14it/s] 53%|█████▎    | 735/1380 [01:27<01:10,  9.12it/s] 53%|█████▎    | 736/1380 [01:28<01:10,  9.17it/s] 53%|█████▎    | 737/1380 [01:28<01:09,  9.21it/s] 53%|█████▎    | 738/1380 [01:28<01:10,  9.15it/s] 54%|█████▎    | 739/1380 [01:28<01:10,  9.15it/s] 54%|█████▎    | 740/1380 [01:28<01:09,  9.16it/s] 54%|█████▎    | 741/1380 [01:28<01:10,  9.13it/s] 54%|█████▍    | 742/1380 [01:28<01:09,  9.13it/s] 54%|█████▍    | 743/1380 [01:28<01:09,  9.10it/s] 54%|█████▍    | 744/1380 [01:28<01:09,  9.13it/s] 54%|█████▍    | 745/1380 [01:28<01:08,  9.21it/s] 54%|█████▍    | 746/1380 [01:29<01:09,  9.16it/s] 54%|█████▍    | 747/1380 [01:29<01:09,  9.13it/s] 54%|█████▍    | 748/1380 [01:29<01:08,  9.20it/s] 54%|█████▍    | 749/1380 [01:29<01:08,  9.21it/s] 54%|█████▍    | 750/1380 [01:29<01:09,  9.12it/s] 54%|█████▍    | 751/1380 [01:29<01:08,  9.15it/s] 54%|█████▍    | 752/1380 [01:29<01:08,  9.19it/s] 55%|█████▍    | 753/1380 [01:29<01:08,  9.17it/s] 55%|█████▍    | 754/1380 [01:29<01:08,  9.14it/s] 55%|█████▍    | 755/1380 [01:30<01:08,  9.09it/s] 55%|█████▍    | 756/1380 [01:30<01:08,  9.15it/s] 55%|█████▍    | 757/1380 [01:30<01:07,  9.16it/s] 55%|█████▍    | 758/1380 [01:30<01:07,  9.21it/s] 55%|█████▌    | 759/1380 [01:30<01:08,  9.04it/s] 55%|█████▌    | 760/1380 [01:30<01:08,  9.11it/s] 55%|█████▌    | 761/1380 [01:30<01:07,  9.17it/s] 55%|█████▌    | 762/1380 [01:30<01:07,  9.15it/s] 55%|█████▌    | 763/1380 [01:30<01:07,  9.11it/s] 55%|█████▌    | 764/1380 [01:31<01:07,  9.16it/s] 55%|█████▌    | 765/1380 [01:31<01:07,  9.17it/s] 56%|█████▌    | 766/1380 [01:31<01:07,  9.15it/s] 56%|█████▌    | 767/1380 [01:31<01:07,  9.13it/s] 56%|█████▌    | 768/1380 [01:31<01:06,  9.21it/s] 56%|█████▌    | 769/1380 [01:31<01:06,  9.20it/s] 56%|█████▌    | 770/1380 [01:31<01:06,  9.14it/s] 56%|█████▌    | 771/1380 [01:31<01:06,  9.11it/s] 56%|█████▌    | 772/1380 [01:31<01:06,  9.18it/s] 56%|█████▌    | 773/1380 [01:32<01:06,  9.11it/s] 56%|█████▌    | 774/1380 [01:32<01:06,  9.09it/s] 56%|█████▌    | 775/1380 [01:32<01:06,  9.13it/s] 56%|█████▌    | 776/1380 [01:32<01:06,  9.15it/s] 56%|█████▋    | 777/1380 [01:32<01:05,  9.23it/s] 56%|█████▋    | 778/1380 [01:32<01:05,  9.15it/s] 56%|█████▋    | 779/1380 [01:32<01:05,  9.14it/s] 57%|█████▋    | 780/1380 [01:32<01:05,  9.20it/s] 57%|█████▋    | 781/1380 [01:32<01:05,  9.16it/s] 57%|█████▋    | 782/1380 [01:33<01:05,  9.13it/s] 57%|█████▋    | 783/1380 [01:33<01:05,  9.17it/s] 57%|█████▋    | 784/1380 [01:33<01:05,  9.16it/s] 57%|█████▋    | 785/1380 [01:33<01:05,  9.11it/s] 57%|█████▋    | 786/1380 [01:33<01:05,  9.13it/s] 57%|█████▋    | 787/1380 [01:33<01:04,  9.18it/s] 57%|█████▋    | 788/1380 [01:33<01:04,  9.25it/s] 57%|█████▋    | 789/1380 [01:33<01:04,  9.16it/s] 57%|█████▋    | 790/1380 [01:33<01:04,  9.11it/s] 57%|█████▋    | 791/1380 [01:34<01:04,  9.16it/s] 57%|█████▋    | 792/1380 [01:34<01:04,  9.14it/s] 57%|█████▋    | 793/1380 [01:34<01:04,  9.11it/s] 58%|█████▊    | 794/1380 [01:34<01:04,  9.15it/s] 58%|█████▊    | 795/1380 [01:34<01:03,  9.19it/s] 58%|█████▊    | 796/1380 [01:34<01:03,  9.22it/s] 58%|█████▊    | 797/1380 [01:34<01:03,  9.18it/s] 58%|█████▊    | 798/1380 [01:34<01:03,  9.16it/s] 58%|█████▊    | 799/1380 [01:34<01:02,  9.25it/s] 58%|█████▊    | 800/1380 [01:34<01:03,  9.20it/s] 58%|█████▊    | 801/1380 [01:35<01:03,  9.15it/s] 58%|█████▊    | 802/1380 [01:35<01:02,  9.20it/s] 58%|█████▊    | 803/1380 [01:35<01:02,  9.22it/s] 58%|█████▊    | 804/1380 [01:35<01:02,  9.21it/s] 58%|█████▊    | 805/1380 [01:35<01:02,  9.15it/s] 58%|█████▊    | 806/1380 [01:35<01:02,  9.17it/s] 58%|█████▊    | 807/1380 [01:35<01:02,  9.20it/s] 59%|█████▊    | 808/1380 [01:35<01:02,  9.19it/s] 59%|█████▊    | 809/1380 [01:35<01:02,  9.15it/s] 59%|█████▊    | 810/1380 [01:36<01:02,  9.15it/s] 59%|█████▉    | 811/1380 [01:36<01:01,  9.22it/s] 59%|█████▉    | 812/1380 [01:36<01:01,  9.27it/s] 59%|█████▉    | 813/1380 [01:36<01:02,  9.13it/s] 59%|█████▉    | 814/1380 [01:36<01:01,  9.16it/s] 59%|█████▉    | 815/1380 [01:36<01:01,  9.23it/s] 59%|█████▉    | 816/1380 [01:36<01:00,  9.25it/s] 59%|█████▉    | 817/1380 [01:36<01:01,  9.16it/s] 59%|█████▉    | 818/1380 [01:36<01:01,  9.14it/s] 59%|█████▉    | 819/1380 [01:37<01:00,  9.22it/s] 59%|█████▉    | 820/1380 [01:37<01:01,  9.15it/s] 59%|█████▉    | 821/1380 [01:37<01:01,  9.08it/s] 60%|█████▉    | 822/1380 [01:37<01:01,  9.04it/s] 60%|█████▉    | 823/1380 [01:37<01:00,  9.15it/s] 60%|█████▉    | 824/1380 [01:37<01:01,  9.11it/s] 60%|█████▉    | 825/1380 [01:37<01:00,  9.11it/s] 60%|█████▉    | 826/1380 [01:37<01:01,  9.08it/s] 60%|█████▉    | 827/1380 [01:37<01:00,  9.15it/s]                                                   60%|██████    | 828/1380 [01:38<01:00,  9.15it/s][INFO|trainer.py:755] 2023-11-15 21:33:27,769 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:33:27,771 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:33:27,771 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:33:27,771 >>   Batch size = 8
{'eval_loss': 0.39251384139060974, 'eval_accuracy': 0.8557168784029038, 'eval_micro_f1': 0.8557168784029038, 'eval_macro_f1': 0.8432410340972761, 'eval_runtime': 3.7544, 'eval_samples_per_second': 587.046, 'eval_steps_per_second': 73.514, 'epoch': 2.0}
{'loss': 0.2065, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 76.08it/s][A
  6%|▌         | 17/276 [00:00<00:03, 72.37it/s][A
  9%|▉         | 25/276 [00:00<00:03, 74.22it/s][A
 12%|█▏        | 33/276 [00:00<00:03, 73.89it/s][A
 15%|█▍        | 41/276 [00:00<00:03, 70.98it/s][A
 18%|█▊        | 49/276 [00:00<00:03, 70.71it/s][A
 21%|██        | 57/276 [00:00<00:03, 72.37it/s][A
 24%|██▎       | 65/276 [00:00<00:02, 72.63it/s][A
 26%|██▋       | 73/276 [00:01<00:02, 71.55it/s][A
 29%|██▉       | 81/276 [00:01<00:02, 71.07it/s][A
 32%|███▏      | 89/276 [00:01<00:02, 71.76it/s][A
 35%|███▌      | 97/276 [00:01<00:02, 70.19it/s][A
 38%|███▊      | 105/276 [00:01<00:02, 70.12it/s][A
 41%|████      | 113/276 [00:01<00:02, 70.99it/s][A
 44%|████▍     | 121/276 [00:01<00:02, 71.83it/s][A
 47%|████▋     | 129/276 [00:01<00:02, 72.21it/s][A
 50%|████▉     | 137/276 [00:01<00:01, 69.52it/s][A
 53%|█████▎    | 145/276 [00:02<00:01, 70.17it/s][A
 55%|█████▌    | 153/276 [00:02<00:01, 72.24it/s][A
 58%|█████▊    | 161/276 [00:02<00:01, 70.03it/s][A
 61%|██████    | 169/276 [00:02<00:01, 69.95it/s][A
 64%|██████▍   | 177/276 [00:02<00:01, 70.74it/s][A
 67%|██████▋   | 185/276 [00:02<00:01, 70.94it/s][A
 70%|██████▉   | 193/276 [00:02<00:01, 70.02it/s][A
 73%|███████▎  | 201/276 [00:02<00:01, 69.36it/s][A
 76%|███████▌  | 209/276 [00:02<00:00, 70.92it/s][A
 79%|███████▊  | 217/276 [00:03<00:00, 71.62it/s][A
 82%|████████▏ | 225/276 [00:03<00:00, 69.81it/s][A
 84%|████████▍ | 232/276 [00:03<00:00, 69.31it/s][A
 87%|████████▋ | 240/276 [00:03<00:00, 70.56it/s][A
 90%|████████▉ | 248/276 [00:03<00:00, 70.52it/s][A
 93%|█████████▎| 256/276 [00:03<00:00, 71.23it/s][A
 96%|█████████▌| 264/276 [00:03<00:00, 69.00it/s][A
 99%|█████████▊| 272/276 [00:03<00:00, 70.19it/s][A                                                  
                                                 [A 60%|██████    | 828/1380 [01:41<01:00,  9.15it/s]
100%|██████████| 276/276 [00:03<00:00, 70.19it/s][A
                                                 [A 60%|██████    | 829/1380 [01:42<09:19,  1.02s/it] 60%|██████    | 830/1380 [01:42<07:16,  1.26it/s] 60%|██████    | 831/1380 [01:42<05:37,  1.63it/s] 60%|██████    | 832/1380 [01:42<04:21,  2.10it/s] 60%|██████    | 833/1380 [01:42<03:24,  2.67it/s] 60%|██████    | 834/1380 [01:42<02:43,  3.34it/s] 61%|██████    | 835/1380 [01:42<02:13,  4.07it/s] 61%|██████    | 836/1380 [01:42<01:51,  4.86it/s] 61%|██████    | 837/1380 [01:42<01:36,  5.63it/s] 61%|██████    | 838/1380 [01:43<01:24,  6.38it/s] 61%|██████    | 839/1380 [01:43<01:17,  6.95it/s] 61%|██████    | 840/1380 [01:43<01:12,  7.47it/s] 61%|██████    | 841/1380 [01:43<01:08,  7.92it/s] 61%|██████    | 842/1380 [01:43<01:05,  8.24it/s] 61%|██████    | 843/1380 [01:43<01:03,  8.44it/s] 61%|██████    | 844/1380 [01:43<01:02,  8.53it/s] 61%|██████    | 845/1380 [01:43<01:01,  8.75it/s] 61%|██████▏   | 846/1380 [01:43<00:59,  8.93it/s] 61%|██████▏   | 847/1380 [01:44<00:59,  8.89it/s] 61%|██████▏   | 848/1380 [01:44<00:59,  8.90it/s] 62%|██████▏   | 849/1380 [01:44<00:59,  8.95it/s] 62%|██████▏   | 850/1380 [01:44<00:58,  9.06it/s] 62%|██████▏   | 851/1380 [01:44<00:57,  9.13it/s] 62%|██████▏   | 852/1380 [01:44<00:57,  9.15it/s] 62%|██████▏   | 853/1380 [01:44<00:58,  9.07it/s] 62%|██████▏   | 854/1380 [01:44<00:57,  9.11it/s] 62%|██████▏   | 855/1380 [01:44<00:57,  9.15it/s] 62%|██████▏   | 856/1380 [01:45<00:58,  9.03it/s] 62%|██████▏   | 857/1380 [01:45<00:58,  8.98it/s] 62%|██████▏   | 858/1380 [01:45<00:57,  9.06it/s] 62%|██████▏   | 859/1380 [01:45<00:57,  9.07it/s] 62%|██████▏   | 860/1380 [01:45<00:57,  9.07it/s] 62%|██████▏   | 861/1380 [01:45<00:56,  9.14it/s] 62%|██████▏   | 862/1380 [01:45<00:56,  9.12it/s] 63%|██████▎   | 863/1380 [01:45<00:56,  9.09it/s] 63%|██████▎   | 864/1380 [01:45<00:56,  9.14it/s] 63%|██████▎   | 865/1380 [01:46<00:56,  9.13it/s] 63%|██████▎   | 866/1380 [01:46<00:57,  8.96it/s] 63%|██████▎   | 867/1380 [01:46<00:56,  9.03it/s] 63%|██████▎   | 868/1380 [01:46<00:56,  9.08it/s] 63%|██████▎   | 869/1380 [01:46<00:56,  9.05it/s] 63%|██████▎   | 870/1380 [01:46<00:56,  9.05it/s] 63%|██████▎   | 871/1380 [01:46<00:56,  8.98it/s] 63%|██████▎   | 872/1380 [01:46<00:56,  9.05it/s] 63%|██████▎   | 873/1380 [01:46<00:56,  9.02it/s] 63%|██████▎   | 874/1380 [01:47<00:55,  9.10it/s] 63%|██████▎   | 875/1380 [01:47<00:55,  9.04it/s] 63%|██████▎   | 876/1380 [01:47<00:55,  9.02it/s] 64%|██████▎   | 877/1380 [01:47<00:55,  9.07it/s] 64%|██████▎   | 878/1380 [01:47<00:55,  9.09it/s] 64%|██████▎   | 879/1380 [01:47<00:55,  9.03it/s] 64%|██████▍   | 880/1380 [01:47<00:55,  8.99it/s] 64%|██████▍   | 881/1380 [01:47<00:55,  9.04it/s] 64%|██████▍   | 882/1380 [01:47<00:55,  9.03it/s] 64%|██████▍   | 883/1380 [01:48<00:55,  9.02it/s] 64%|██████▍   | 884/1380 [01:48<00:55,  8.98it/s] 64%|██████▍   | 885/1380 [01:48<00:55,  8.99it/s] 64%|██████▍   | 886/1380 [01:48<00:54,  9.07it/s] 64%|██████▍   | 887/1380 [01:48<00:54,  9.13it/s] 64%|██████▍   | 888/1380 [01:48<00:54,  9.07it/s] 64%|██████▍   | 889/1380 [01:48<00:54,  9.02it/s] 64%|██████▍   | 890/1380 [01:48<00:53,  9.18it/s] 65%|██████▍   | 891/1380 [01:48<00:53,  9.19it/s] 65%|██████▍   | 892/1380 [01:49<00:53,  9.14it/s] 65%|██████▍   | 893/1380 [01:49<00:53,  9.05it/s] 65%|██████▍   | 894/1380 [01:49<00:53,  9.09it/s] 65%|██████▍   | 895/1380 [01:49<00:53,  9.10it/s] 65%|██████▍   | 896/1380 [01:49<00:53,  9.06it/s] 65%|██████▌   | 897/1380 [01:49<00:53,  9.00it/s] 65%|██████▌   | 898/1380 [01:49<00:53,  9.00it/s] 65%|██████▌   | 899/1380 [01:49<00:53,  9.04it/s] 65%|██████▌   | 900/1380 [01:49<00:52,  9.11it/s] 65%|██████▌   | 901/1380 [01:50<00:53,  9.04it/s] 65%|██████▌   | 902/1380 [01:50<00:52,  9.02it/s] 65%|██████▌   | 903/1380 [01:50<00:52,  9.10it/s] 66%|██████▌   | 904/1380 [01:50<00:52,  9.12it/s] 66%|██████▌   | 905/1380 [01:50<00:52,  9.11it/s] 66%|██████▌   | 906/1380 [01:50<00:52,  9.04it/s] 66%|██████▌   | 907/1380 [01:50<00:52,  9.06it/s] 66%|██████▌   | 908/1380 [01:50<00:51,  9.11it/s] 66%|██████▌   | 909/1380 [01:50<00:51,  9.06it/s] 66%|██████▌   | 910/1380 [01:51<00:52,  8.91it/s] 66%|██████▌   | 911/1380 [01:51<00:52,  8.96it/s] 66%|██████▌   | 912/1380 [01:51<00:52,  8.98it/s] 66%|██████▌   | 913/1380 [01:51<00:51,  9.10it/s] 66%|██████▌   | 914/1380 [01:51<00:51,  9.06it/s] 66%|██████▋   | 915/1380 [01:51<00:51,  9.00it/s] 66%|██████▋   | 916/1380 [01:51<00:50,  9.10it/s] 66%|██████▋   | 917/1380 [01:51<00:51,  9.08it/s] 67%|██████▋   | 918/1380 [01:51<00:51,  9.03it/s] 67%|██████▋   | 919/1380 [01:52<00:51,  9.03it/s] 67%|██████▋   | 920/1380 [01:52<00:50,  9.09it/s] 67%|██████▋   | 921/1380 [01:52<00:50,  9.06it/s] 67%|██████▋   | 922/1380 [01:52<00:50,  9.03it/s] 67%|██████▋   | 923/1380 [01:52<00:50,  9.04it/s] 67%|██████▋   | 924/1380 [01:52<00:50,  9.00it/s] 67%|██████▋   | 925/1380 [01:52<00:50,  9.03it/s] 67%|██████▋   | 926/1380 [01:52<00:49,  9.12it/s] 67%|██████▋   | 927/1380 [01:52<00:49,  9.09it/s] 67%|██████▋   | 928/1380 [01:53<00:50,  9.02it/s] 67%|██████▋   | 929/1380 [01:53<00:49,  9.17it/s] 67%|██████▋   | 930/1380 [01:53<00:49,  9.16it/s] 67%|██████▋   | 931/1380 [01:53<00:49,  9.11it/s] 68%|██████▊   | 932/1380 [01:53<00:49,  8.99it/s] 68%|██████▊   | 933/1380 [01:53<00:49,  9.10it/s] 68%|██████▊   | 934/1380 [01:53<00:48,  9.12it/s] 68%|██████▊   | 935/1380 [01:53<00:49,  9.06it/s] 68%|██████▊   | 936/1380 [01:53<00:49,  9.03it/s] 68%|██████▊   | 937/1380 [01:54<00:49,  9.02it/s] 68%|██████▊   | 938/1380 [01:54<00:48,  9.08it/s] 68%|██████▊   | 939/1380 [01:54<00:48,  9.16it/s] 68%|██████▊   | 940/1380 [01:54<00:48,  9.09it/s] 68%|██████▊   | 941/1380 [01:54<00:48,  8.96it/s] 68%|██████▊   | 942/1380 [01:54<00:48,  9.10it/s] 68%|██████▊   | 943/1380 [01:54<00:47,  9.13it/s] 68%|██████▊   | 944/1380 [01:54<00:47,  9.14it/s] 68%|██████▊   | 945/1380 [01:54<00:47,  9.12it/s] 69%|██████▊   | 946/1380 [01:55<00:47,  9.11it/s] 69%|██████▊   | 947/1380 [01:55<00:47,  9.17it/s] 69%|██████▊   | 948/1380 [01:55<00:47,  9.13it/s] 69%|██████▉   | 949/1380 [01:55<00:46,  9.18it/s] 69%|██████▉   | 950/1380 [01:55<00:46,  9.16it/s] 69%|██████▉   | 951/1380 [01:55<00:46,  9.13it/s] 69%|██████▉   | 952/1380 [01:55<00:46,  9.21it/s] 69%|██████▉   | 953/1380 [01:55<00:46,  9.12it/s] 69%|██████▉   | 954/1380 [01:55<00:46,  9.09it/s] 69%|██████▉   | 955/1380 [01:55<00:46,  9.14it/s] 69%|██████▉   | 956/1380 [01:56<00:46,  9.15it/s] 69%|██████▉   | 957/1380 [01:56<00:46,  9.08it/s] 69%|██████▉   | 958/1380 [01:56<00:46,  9.04it/s] 69%|██████▉   | 959/1380 [01:56<00:46,  8.98it/s] 70%|██████▉   | 960/1380 [01:56<00:46,  8.98it/s] 70%|██████▉   | 961/1380 [01:56<00:46,  8.97it/s] 70%|██████▉   | 962/1380 [01:56<00:46,  9.06it/s] 70%|██████▉   | 963/1380 [01:56<00:46,  9.00it/s] 70%|██████▉   | 964/1380 [01:56<00:46,  9.01it/s] 70%|██████▉   | 965/1380 [01:57<00:45,  9.08it/s] 70%|███████   | 966/1380 [01:57<00:45,  9.07it/s] 70%|███████   | 967/1380 [01:57<00:45,  8.99it/s] 70%|███████   | 968/1380 [01:57<00:45,  9.00it/s] 70%|███████   | 969/1380 [01:57<00:45,  9.06it/s] 70%|███████   | 970/1380 [01:57<00:45,  9.00it/s] 70%|███████   | 971/1380 [01:57<00:45,  9.02it/s] 70%|███████   | 972/1380 [01:57<00:45,  8.95it/s] 71%|███████   | 973/1380 [01:57<00:45,  9.00it/s] 71%|███████   | 974/1380 [01:58<00:45,  9.01it/s] 71%|███████   | 975/1380 [01:58<00:44,  9.09it/s] 71%|███████   | 976/1380 [01:58<00:44,  8.98it/s] 71%|███████   | 977/1380 [01:58<00:45,  8.94it/s] 71%|███████   | 978/1380 [01:58<00:44,  9.03it/s] 71%|███████   | 979/1380 [01:58<00:44,  9.07it/s] 71%|███████   | 980/1380 [01:58<00:44,  9.04it/s] 71%|███████   | 981/1380 [01:58<00:44,  9.01it/s] 71%|███████   | 982/1380 [01:58<00:44,  9.01it/s] 71%|███████   | 983/1380 [01:59<00:43,  9.06it/s] 71%|███████▏  | 984/1380 [01:59<00:44,  8.98it/s] 71%|███████▏  | 985/1380 [01:59<00:43,  9.01it/s] 71%|███████▏  | 986/1380 [01:59<00:43,  9.01it/s] 72%|███████▏  | 987/1380 [01:59<00:43,  9.04it/s] 72%|███████▏  | 988/1380 [01:59<00:42,  9.14it/s] 72%|███████▏  | 989/1380 [01:59<00:43,  9.07it/s] 72%|███████▏  | 990/1380 [01:59<00:43,  9.04it/s] 72%|███████▏  | 991/1380 [01:59<00:43,  8.98it/s] 72%|███████▏  | 992/1380 [02:00<00:42,  9.10it/s] 72%|███████▏  | 993/1380 [02:00<00:42,  9.05it/s] 72%|███████▏  | 994/1380 [02:00<00:42,  9.03it/s] 72%|███████▏  | 995/1380 [02:00<00:42,  8.97it/s] 72%|███████▏  | 996/1380 [02:00<00:42,  9.03it/s] 72%|███████▏  | 997/1380 [02:00<00:42,  8.99it/s] 72%|███████▏  | 998/1380 [02:00<00:42,  9.04it/s] 72%|███████▏  | 999/1380 [02:00<00:42,  8.93it/s] 72%|███████▏  | 1000/1380 [02:00<00:42,  8.96it/s] 73%|███████▎  | 1001/1380 [02:01<00:41,  9.09it/s] 73%|███████▎  | 1002/1380 [02:01<00:42,  9.00it/s] 73%|███████▎  | 1003/1380 [02:01<00:42,  8.96it/s] 73%|███████▎  | 1004/1380 [02:01<00:41,  8.97it/s] 73%|███████▎  | 1005/1380 [02:01<00:41,  9.04it/s] 73%|███████▎  | 1006/1380 [02:01<00:41,  9.00it/s] 73%|███████▎  | 1007/1380 [02:01<00:41,  8.98it/s] 73%|███████▎  | 1008/1380 [02:01<00:41,  8.93it/s] 73%|███████▎  | 1009/1380 [02:01<00:41,  8.96it/s] 73%|███████▎  | 1010/1380 [02:02<00:41,  8.96it/s] 73%|███████▎  | 1011/1380 [02:02<00:40,  9.03it/s] 73%|███████▎  | 1012/1380 [02:02<00:40,  9.03it/s] 73%|███████▎  | 1013/1380 [02:02<00:40,  8.99it/s] 73%|███████▎  | 1014/1380 [02:02<00:40,  9.09it/s] 74%|███████▎  | 1015/1380 [02:02<00:40,  9.10it/s] 74%|███████▎  | 1016/1380 [02:02<00:40,  9.08it/s] 74%|███████▎  | 1017/1380 [02:02<00:40,  9.03it/s] 74%|███████▍  | 1018/1380 [02:02<00:40,  9.03it/s] 74%|███████▍  | 1019/1380 [02:03<00:39,  9.08it/s] 74%|███████▍  | 1020/1380 [02:03<00:39,  9.07it/s] 74%|███████▍  | 1021/1380 [02:03<00:39,  9.04it/s] 74%|███████▍  | 1022/1380 [02:03<00:39,  9.04it/s] 74%|███████▍  | 1023/1380 [02:03<00:39,  9.09it/s] 74%|███████▍  | 1024/1380 [02:03<00:39,  9.09it/s] 74%|███████▍  | 1025/1380 [02:03<00:39,  9.00it/s] 74%|███████▍  | 1026/1380 [02:03<00:39,  8.98it/s] 74%|███████▍  | 1027/1380 [02:03<00:38,  9.09it/s] 74%|███████▍  | 1028/1380 [02:04<00:38,  9.09it/s] 75%|███████▍  | 1029/1380 [02:04<00:38,  9.08it/s] 75%|███████▍  | 1030/1380 [02:04<00:38,  9.05it/s] 75%|███████▍  | 1031/1380 [02:04<00:38,  9.09it/s] 75%|███████▍  | 1032/1380 [02:04<00:38,  9.12it/s] 75%|███████▍  | 1033/1380 [02:04<00:38,  9.12it/s] 75%|███████▍  | 1034/1380 [02:04<00:37,  9.11it/s] 75%|███████▌  | 1035/1380 [02:04<00:38,  9.04it/s] 75%|███████▌  | 1036/1380 [02:04<00:37,  9.10it/s] 75%|███████▌  | 1037/1380 [02:05<00:37,  9.14it/s] 75%|███████▌  | 1038/1380 [02:05<00:37,  9.08it/s] 75%|███████▌  | 1039/1380 [02:05<00:37,  9.08it/s] 75%|███████▌  | 1040/1380 [02:05<00:37,  9.07it/s] 75%|███████▌  | 1041/1380 [02:05<00:37,  9.09it/s] 76%|███████▌  | 1042/1380 [02:05<00:37,  9.06it/s] 76%|███████▌  | 1043/1380 [02:05<00:37,  9.08it/s] 76%|███████▌  | 1044/1380 [02:05<00:37,  9.00it/s] 76%|███████▌  | 1045/1380 [02:05<00:36,  9.06it/s] 76%|███████▌  | 1046/1380 [02:06<00:37,  9.00it/s] 76%|███████▌  | 1047/1380 [02:06<00:36,  9.07it/s] 76%|███████▌  | 1048/1380 [02:06<00:36,  9.02it/s] 76%|███████▌  | 1049/1380 [02:06<00:36,  8.99it/s] 76%|███████▌  | 1050/1380 [02:06<00:36,  9.08it/s] 76%|███████▌  | 1051/1380 [02:06<00:36,  9.03it/s] 76%|███████▌  | 1052/1380 [02:06<00:36,  9.07it/s] 76%|███████▋  | 1053/1380 [02:06<00:36,  8.99it/s] 76%|███████▋  | 1054/1380 [02:06<00:36,  9.05it/s] 76%|███████▋  | 1055/1380 [02:07<00:35,  9.08it/s] 77%|███████▋  | 1056/1380 [02:07<00:35,  9.02it/s] 77%|███████▋  | 1057/1380 [02:07<00:35,  9.03it/s] 77%|███████▋  | 1058/1380 [02:07<00:35,  9.07it/s] 77%|███████▋  | 1059/1380 [02:07<00:35,  9.11it/s] 77%|███████▋  | 1060/1380 [02:07<00:34,  9.17it/s] 77%|███████▋  | 1061/1380 [02:07<00:35,  9.07it/s] 77%|███████▋  | 1062/1380 [02:07<00:35,  9.05it/s] 77%|███████▋  | 1063/1380 [02:07<00:34,  9.09it/s] 77%|███████▋  | 1064/1380 [02:08<00:34,  9.09it/s] 77%|███████▋  | 1065/1380 [02:08<00:34,  9.06it/s] 77%|███████▋  | 1066/1380 [02:08<00:34,  9.05it/s] 77%|███████▋  | 1067/1380 [02:08<00:34,  9.09it/s] 77%|███████▋  | 1068/1380 [02:08<00:34,  9.09it/s] 77%|███████▋  | 1069/1380 [02:08<00:34,  9.09it/s] 78%|███████▊  | 1070/1380 [02:08<00:34,  9.02it/s] 78%|███████▊  | 1071/1380 [02:08<00:34,  9.06it/s] 78%|███████▊  | 1072/1380 [02:08<00:33,  9.07it/s] 78%|███████▊  | 1073/1380 [02:09<00:33,  9.19it/s] 78%|███████▊  | 1074/1380 [02:09<00:33,  9.08it/s] 78%|███████▊  | 1075/1380 [02:09<00:33,  9.06it/s] 78%|███████▊  | 1076/1380 [02:09<00:33,  9.16it/s] 78%|███████▊  | 1077/1380 [02:09<00:33,  9.16it/s] 78%|███████▊  | 1078/1380 [02:09<00:33,  9.10it/s] 78%|███████▊  | 1079/1380 [02:09<00:33,  9.05it/s] 78%|███████▊  | 1080/1380 [02:09<00:32,  9.11it/s] 78%|███████▊  | 1081/1380 [02:09<00:32,  9.12it/s] 78%|███████▊  | 1082/1380 [02:10<00:32,  9.12it/s] 78%|███████▊  | 1083/1380 [02:10<00:32,  9.07it/s] 79%|███████▊  | 1084/1380 [02:10<00:32,  9.06it/s] 79%|███████▊  | 1085/1380 [02:10<00:32,  9.02it/s] 79%|███████▊  | 1086/1380 [02:10<00:32,  9.12it/s] 79%|███████▉  | 1087/1380 [02:10<00:32,  9.11it/s] 79%|███████▉  | 1088/1380 [02:10<00:32,  9.02it/s] 79%|███████▉  | 1089/1380 [02:10<00:31,  9.14it/s] 79%|███████▉  | 1090/1380 [02:10<00:31,  9.17it/s] 79%|███████▉  | 1091/1380 [02:11<00:31,  9.20it/s] 79%|███████▉  | 1092/1380 [02:11<00:31,  9.06it/s] 79%|███████▉  | 1093/1380 [02:11<00:31,  9.14it/s] 79%|███████▉  | 1094/1380 [02:11<00:31,  9.15it/s] 79%|███████▉  | 1095/1380 [02:11<00:31,  9.11it/s] 79%|███████▉  | 1096/1380 [02:11<00:31,  9.12it/s] 79%|███████▉  | 1097/1380 [02:11<00:31,  9.12it/s] 80%|███████▉  | 1098/1380 [02:11<00:30,  9.14it/s] 80%|███████▉  | 1099/1380 [02:11<00:30,  9.17it/s] 80%|███████▉  | 1100/1380 [02:12<00:30,  9.12it/s] 80%|███████▉  | 1101/1380 [02:12<00:30,  9.10it/s] 80%|███████▉  | 1102/1380 [02:12<00:30,  9.19it/s] 80%|███████▉  | 1103/1380 [02:12<00:30,  9.18it/s]                                                    80%|████████  | 1104/1380 [02:12<00:30,  9.18it/s][INFO|trainer.py:755] 2023-11-15 21:34:02,151 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:34:02,153 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:34:02,153 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:34:02,153 >>   Batch size = 8
{'eval_loss': 0.4504414200782776, 'eval_accuracy': 0.8579854809437386, 'eval_micro_f1': 0.8579854809437386, 'eval_macro_f1': 0.8452568912931252, 'eval_runtime': 3.955, 'eval_samples_per_second': 557.271, 'eval_steps_per_second': 69.785, 'epoch': 3.0}
{'loss': 0.1414, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 85.29it/s][A
  7%|▋         | 18/276 [00:00<00:03, 79.31it/s][A
  9%|▉         | 26/276 [00:00<00:03, 76.12it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 73.43it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 73.41it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 73.09it/s][A
 21%|██        | 58/276 [00:00<00:02, 73.02it/s][A
 24%|██▍       | 66/276 [00:00<00:02, 72.94it/s][A
 27%|██▋       | 74/276 [00:01<00:02, 72.55it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 72.21it/s][A
 33%|███▎      | 90/276 [00:01<00:02, 73.65it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 72.59it/s][A
 38%|███▊      | 106/276 [00:01<00:02, 72.09it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 71.16it/s][A
 44%|████▍     | 122/276 [00:01<00:02, 72.73it/s][A
 47%|████▋     | 130/276 [00:01<00:02, 72.30it/s][A
 50%|█████     | 138/276 [00:01<00:01, 72.29it/s][A
 53%|█████▎    | 146/276 [00:02<00:01, 71.68it/s][A
 56%|█████▌    | 154/276 [00:02<00:01, 72.81it/s][A
 59%|█████▊    | 162/276 [00:02<00:01, 72.90it/s][A
 62%|██████▏   | 170/276 [00:02<00:01, 73.39it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 72.00it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 72.16it/s][A
 70%|███████   | 194/276 [00:02<00:01, 73.59it/s][A
 73%|███████▎  | 202/276 [00:02<00:01, 72.40it/s][A
 76%|███████▌  | 210/276 [00:02<00:00, 71.25it/s][A
 79%|███████▉  | 218/276 [00:02<00:00, 71.16it/s][A
 82%|████████▏ | 226/276 [00:03<00:00, 72.84it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 72.56it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 72.59it/s][A
 91%|█████████ | 250/276 [00:03<00:00, 71.81it/s][A
 93%|█████████▎| 258/276 [00:03<00:00, 72.86it/s][A
 96%|█████████▋| 266/276 [00:03<00:00, 73.32it/s][A
 99%|█████████▉| 274/276 [00:03<00:00, 73.68it/s][A                                                   
                                                 [A 80%|████████  | 1104/1380 [02:16<00:30,  9.18it/s]
100%|██████████| 276/276 [00:03<00:00, 73.68it/s][A
                                                 [A 80%|████████  | 1105/1380 [02:16<04:32,  1.01it/s] 80%|████████  | 1106/1380 [02:16<03:32,  1.29it/s] 80%|████████  | 1107/1380 [02:16<02:44,  1.66it/s] 80%|████████  | 1108/1380 [02:16<02:07,  2.14it/s] 80%|████████  | 1109/1380 [02:16<01:39,  2.72it/s] 80%|████████  | 1110/1380 [02:16<01:19,  3.40it/s] 81%|████████  | 1111/1380 [02:17<01:04,  4.15it/s] 81%|████████  | 1112/1380 [02:17<00:54,  4.95it/s] 81%|████████  | 1113/1380 [02:17<00:46,  5.74it/s] 81%|████████  | 1114/1380 [02:17<00:41,  6.39it/s] 81%|████████  | 1115/1380 [02:17<00:37,  7.01it/s] 81%|████████  | 1116/1380 [02:17<00:34,  7.56it/s] 81%|████████  | 1117/1380 [02:17<00:32,  8.00it/s] 81%|████████  | 1118/1380 [02:17<00:31,  8.26it/s] 81%|████████  | 1119/1380 [02:17<00:30,  8.47it/s] 81%|████████  | 1120/1380 [02:18<00:29,  8.69it/s] 81%|████████  | 1121/1380 [02:18<00:29,  8.82it/s] 81%|████████▏ | 1122/1380 [02:18<00:29,  8.87it/s] 81%|████████▏ | 1123/1380 [02:18<00:28,  8.92it/s] 81%|████████▏ | 1124/1380 [02:18<00:28,  9.00it/s] 82%|████████▏ | 1125/1380 [02:18<00:28,  9.09it/s] 82%|████████▏ | 1126/1380 [02:18<00:27,  9.24it/s] 82%|████████▏ | 1127/1380 [02:18<00:27,  9.15it/s] 82%|████████▏ | 1128/1380 [02:18<00:27,  9.11it/s] 82%|████████▏ | 1129/1380 [02:19<00:27,  9.21it/s] 82%|████████▏ | 1130/1380 [02:19<00:26,  9.27it/s] 82%|████████▏ | 1131/1380 [02:19<00:27,  9.18it/s] 82%|████████▏ | 1132/1380 [02:19<00:27,  9.16it/s] 82%|████████▏ | 1133/1380 [02:19<00:26,  9.21it/s] 82%|████████▏ | 1134/1380 [02:19<00:26,  9.27it/s] 82%|████████▏ | 1135/1380 [02:19<00:26,  9.23it/s] 82%|████████▏ | 1136/1380 [02:19<00:26,  9.11it/s] 82%|████████▏ | 1137/1380 [02:19<00:26,  9.21it/s] 82%|████████▏ | 1138/1380 [02:19<00:26,  9.22it/s] 83%|████████▎ | 1139/1380 [02:20<00:26,  9.25it/s] 83%|████████▎ | 1140/1380 [02:20<00:26,  9.19it/s] 83%|████████▎ | 1141/1380 [02:20<00:26,  9.17it/s] 83%|████████▎ | 1142/1380 [02:20<00:25,  9.24it/s] 83%|████████▎ | 1143/1380 [02:20<00:25,  9.21it/s] 83%|████████▎ | 1144/1380 [02:20<00:25,  9.19it/s] 83%|████████▎ | 1145/1380 [02:20<00:25,  9.15it/s] 83%|████████▎ | 1146/1380 [02:20<00:25,  9.19it/s] 83%|████████▎ | 1147/1380 [02:20<00:25,  9.21it/s] 83%|████████▎ | 1148/1380 [02:21<00:25,  9.23it/s] 83%|████████▎ | 1149/1380 [02:21<00:24,  9.27it/s] 83%|████████▎ | 1150/1380 [02:21<00:24,  9.23it/s] 83%|████████▎ | 1151/1380 [02:21<00:24,  9.17it/s] 83%|████████▎ | 1152/1380 [02:21<00:24,  9.18it/s] 84%|████████▎ | 1153/1380 [02:21<00:24,  9.20it/s] 84%|████████▎ | 1154/1380 [02:21<00:24,  9.19it/s] 84%|████████▎ | 1155/1380 [02:21<00:24,  9.22it/s] 84%|████████▍ | 1156/1380 [02:21<00:24,  9.17it/s] 84%|████████▍ | 1157/1380 [02:22<00:24,  9.16it/s] 84%|████████▍ | 1158/1380 [02:22<00:24,  9.18it/s] 84%|████████▍ | 1159/1380 [02:22<00:23,  9.28it/s] 84%|████████▍ | 1160/1380 [02:22<00:24,  9.16it/s] 84%|████████▍ | 1161/1380 [02:22<00:24,  9.11it/s] 84%|████████▍ | 1162/1380 [02:22<00:23,  9.14it/s] 84%|████████▍ | 1163/1380 [02:22<00:23,  9.18it/s] 84%|████████▍ | 1164/1380 [02:22<00:23,  9.08it/s] 84%|████████▍ | 1165/1380 [02:22<00:23,  9.01it/s] 84%|████████▍ | 1166/1380 [02:23<00:23,  9.11it/s] 85%|████████▍ | 1167/1380 [02:23<00:23,  9.13it/s] 85%|████████▍ | 1168/1380 [02:23<00:23,  9.18it/s] 85%|████████▍ | 1169/1380 [02:23<00:23,  9.12it/s] 85%|████████▍ | 1170/1380 [02:23<00:23,  9.07it/s] 85%|████████▍ | 1171/1380 [02:23<00:22,  9.17it/s] 85%|████████▍ | 1172/1380 [02:23<00:22,  9.18it/s] 85%|████████▌ | 1173/1380 [02:23<00:22,  9.14it/s] 85%|████████▌ | 1174/1380 [02:23<00:22,  9.09it/s] 85%|████████▌ | 1175/1380 [02:24<00:22,  9.16it/s] 85%|████████▌ | 1176/1380 [02:24<00:22,  9.14it/s] 85%|████████▌ | 1177/1380 [02:24<00:22,  9.13it/s] 85%|████████▌ | 1178/1380 [02:24<00:22,  9.00it/s] 85%|████████▌ | 1179/1380 [02:24<00:22,  9.08it/s] 86%|████████▌ | 1180/1380 [02:24<00:22,  9.02it/s] 86%|████████▌ | 1181/1380 [02:24<00:21,  9.15it/s] 86%|████████▌ | 1182/1380 [02:24<00:21,  9.10it/s] 86%|████████▌ | 1183/1380 [02:24<00:21,  9.05it/s] 86%|████████▌ | 1184/1380 [02:25<00:21,  9.13it/s] 86%|████████▌ | 1185/1380 [02:25<00:21,  9.07it/s] 86%|████████▌ | 1186/1380 [02:25<00:21,  9.08it/s] 86%|████████▌ | 1187/1380 [02:25<00:21,  9.07it/s] 86%|████████▌ | 1188/1380 [02:25<00:21,  9.10it/s] 86%|████████▌ | 1189/1380 [02:25<00:21,  9.03it/s] 86%|████████▌ | 1190/1380 [02:25<00:20,  9.11it/s] 86%|████████▋ | 1191/1380 [02:25<00:20,  9.06it/s] 86%|████████▋ | 1192/1380 [02:25<00:20,  9.17it/s] 86%|████████▋ | 1193/1380 [02:26<00:20,  9.15it/s] 87%|████████▋ | 1194/1380 [02:26<00:20,  9.20it/s] 87%|████████▋ | 1195/1380 [02:26<00:20,  9.17it/s] 87%|████████▋ | 1196/1380 [02:26<00:20,  9.12it/s] 87%|████████▋ | 1197/1380 [02:26<00:19,  9.20it/s] 87%|████████▋ | 1198/1380 [02:26<00:19,  9.13it/s] 87%|████████▋ | 1199/1380 [02:26<00:19,  9.12it/s] 87%|████████▋ | 1200/1380 [02:26<00:19,  9.07it/s] 87%|████████▋ | 1201/1380 [02:26<00:19,  9.15it/s] 87%|████████▋ | 1202/1380 [02:26<00:19,  9.09it/s] 87%|████████▋ | 1203/1380 [02:27<00:19,  9.10it/s] 87%|████████▋ | 1204/1380 [02:27<00:19,  9.01it/s] 87%|████████▋ | 1205/1380 [02:27<00:19,  9.06it/s] 87%|████████▋ | 1206/1380 [02:27<00:19,  9.09it/s] 87%|████████▋ | 1207/1380 [02:27<00:18,  9.15it/s] 88%|████████▊ | 1208/1380 [02:27<00:19,  9.05it/s] 88%|████████▊ | 1209/1380 [02:27<00:18,  9.07it/s] 88%|████████▊ | 1210/1380 [02:27<00:18,  9.12it/s] 88%|████████▊ | 1211/1380 [02:27<00:18,  9.11it/s] 88%|████████▊ | 1212/1380 [02:28<00:18,  9.12it/s] 88%|████████▊ | 1213/1380 [02:28<00:18,  9.10it/s] 88%|████████▊ | 1214/1380 [02:28<00:18,  9.13it/s] 88%|████████▊ | 1215/1380 [02:28<00:18,  9.09it/s] 88%|████████▊ | 1216/1380 [02:28<00:18,  9.05it/s] 88%|████████▊ | 1217/1380 [02:28<00:18,  9.03it/s] 88%|████████▊ | 1218/1380 [02:28<00:17,  9.10it/s] 88%|████████▊ | 1219/1380 [02:28<00:17,  9.13it/s] 88%|████████▊ | 1220/1380 [02:28<00:17,  9.07it/s] 88%|████████▊ | 1221/1380 [02:29<00:17,  9.13it/s] 89%|████████▊ | 1222/1380 [02:29<00:17,  9.11it/s] 89%|████████▊ | 1223/1380 [02:29<00:17,  9.19it/s] 89%|████████▊ | 1224/1380 [02:29<00:17,  9.14it/s] 89%|████████▉ | 1225/1380 [02:29<00:16,  9.24it/s] 89%|████████▉ | 1226/1380 [02:29<00:16,  9.20it/s] 89%|████████▉ | 1227/1380 [02:29<00:16,  9.21it/s] 89%|████████▉ | 1228/1380 [02:29<00:16,  9.19it/s] 89%|████████▉ | 1229/1380 [02:29<00:16,  9.16it/s] 89%|████████▉ | 1230/1380 [02:30<00:16,  9.07it/s] 89%|████████▉ | 1231/1380 [02:30<00:16,  9.16it/s] 89%|████████▉ | 1232/1380 [02:30<00:16,  9.07it/s] 89%|████████▉ | 1233/1380 [02:30<00:16,  9.11it/s] 89%|████████▉ | 1234/1380 [02:30<00:16,  9.10it/s] 89%|████████▉ | 1235/1380 [02:30<00:15,  9.11it/s] 90%|████████▉ | 1236/1380 [02:30<00:15,  9.23it/s] 90%|████████▉ | 1237/1380 [02:30<00:15,  9.18it/s] 90%|████████▉ | 1238/1380 [02:30<00:15,  9.20it/s] 90%|████████▉ | 1239/1380 [02:31<00:15,  9.15it/s] 90%|████████▉ | 1240/1380 [02:31<00:15,  9.16it/s] 90%|████████▉ | 1241/1380 [02:31<00:15,  9.11it/s] 90%|█████████ | 1242/1380 [02:31<00:15,  9.03it/s] 90%|█████████ | 1243/1380 [02:31<00:15,  9.12it/s] 90%|█████████ | 1244/1380 [02:31<00:14,  9.13it/s] 90%|█████████ | 1245/1380 [02:31<00:14,  9.10it/s] 90%|█████████ | 1246/1380 [02:31<00:14,  9.03it/s] 90%|█████████ | 1247/1380 [02:31<00:14,  9.10it/s] 90%|█████████ | 1248/1380 [02:32<00:14,  9.15it/s] 91%|█████████ | 1249/1380 [02:32<00:14,  9.18it/s] 91%|█████████ | 1250/1380 [02:32<00:14,  9.16it/s] 91%|█████████ | 1251/1380 [02:32<00:14,  9.13it/s] 91%|█████████ | 1252/1380 [02:32<00:13,  9.19it/s] 91%|█████████ | 1253/1380 [02:32<00:13,  9.21it/s] 91%|█████████ | 1254/1380 [02:32<00:13,  9.14it/s] 91%|█████████ | 1255/1380 [02:32<00:13,  9.14it/s] 91%|█████████ | 1256/1380 [02:32<00:13,  9.18it/s] 91%|█████████ | 1257/1380 [02:33<00:13,  9.16it/s] 91%|█████████ | 1258/1380 [02:33<00:13,  9.21it/s] 91%|█████████ | 1259/1380 [02:33<00:13,  9.12it/s] 91%|█████████▏| 1260/1380 [02:33<00:13,  9.18it/s] 91%|█████████▏| 1261/1380 [02:33<00:13,  9.15it/s] 91%|█████████▏| 1262/1380 [02:33<00:12,  9.20it/s] 92%|█████████▏| 1263/1380 [02:33<00:12,  9.23it/s] 92%|█████████▏| 1264/1380 [02:33<00:12,  9.26it/s] 92%|█████████▏| 1265/1380 [02:33<00:12,  9.29it/s] 92%|█████████▏| 1266/1380 [02:33<00:12,  9.20it/s] 92%|█████████▏| 1267/1380 [02:34<00:12,  9.19it/s] 92%|█████████▏| 1268/1380 [02:34<00:12,  9.17it/s] 92%|█████████▏| 1269/1380 [02:34<00:12,  9.19it/s] 92%|█████████▏| 1270/1380 [02:34<00:12,  9.11it/s] 92%|█████████▏| 1271/1380 [02:34<00:12,  9.08it/s] 92%|█████████▏| 1272/1380 [02:34<00:11,  9.09it/s] 92%|█████████▏| 1273/1380 [02:34<00:11,  9.17it/s] 92%|█████████▏| 1274/1380 [02:34<00:11,  9.11it/s] 92%|█████████▏| 1275/1380 [02:34<00:11,  9.13it/s] 92%|█████████▏| 1276/1380 [02:35<00:11,  9.10it/s] 93%|█████████▎| 1277/1380 [02:35<00:11,  9.14it/s] 93%|█████████▎| 1278/1380 [02:35<00:11,  9.23it/s] 93%|█████████▎| 1279/1380 [02:35<00:10,  9.22it/s] 93%|█████████▎| 1280/1380 [02:35<00:10,  9.13it/s] 93%|█████████▎| 1281/1380 [02:35<00:10,  9.19it/s] 93%|█████████▎| 1282/1380 [02:35<00:10,  9.19it/s] 93%|█████████▎| 1283/1380 [02:35<00:10,  9.10it/s] 93%|█████████▎| 1284/1380 [02:35<00:10,  9.13it/s] 93%|█████████▎| 1285/1380 [02:36<00:10,  9.20it/s] 93%|█████████▎| 1286/1380 [02:36<00:10,  9.24it/s] 93%|█████████▎| 1287/1380 [02:36<00:10,  9.21it/s] 93%|█████████▎| 1288/1380 [02:36<00:10,  9.13it/s] 93%|█████████▎| 1289/1380 [02:36<00:09,  9.20it/s] 93%|█████████▎| 1290/1380 [02:36<00:09,  9.20it/s] 94%|█████████▎| 1291/1380 [02:36<00:09,  9.15it/s] 94%|█████████▎| 1292/1380 [02:36<00:09,  9.22it/s] 94%|█████████▎| 1293/1380 [02:36<00:09,  9.16it/s] 94%|█████████▍| 1294/1380 [02:37<00:09,  9.24it/s] 94%|█████████▍| 1295/1380 [02:37<00:09,  9.20it/s] 94%|█████████▍| 1296/1380 [02:37<00:09,  9.18it/s] 94%|█████████▍| 1297/1380 [02:37<00:09,  9.18it/s] 94%|█████████▍| 1298/1380 [02:37<00:08,  9.18it/s] 94%|█████████▍| 1299/1380 [02:37<00:08,  9.21it/s] 94%|█████████▍| 1300/1380 [02:37<00:08,  9.15it/s] 94%|█████████▍| 1301/1380 [02:37<00:08,  9.12it/s] 94%|█████████▍| 1302/1380 [02:37<00:08,  9.08it/s] 94%|█████████▍| 1303/1380 [02:38<00:08,  9.17it/s] 94%|█████████▍| 1304/1380 [02:38<00:08,  9.20it/s] 95%|█████████▍| 1305/1380 [02:38<00:08,  9.08it/s] 95%|█████████▍| 1306/1380 [02:38<00:08,  9.04it/s] 95%|█████████▍| 1307/1380 [02:38<00:07,  9.15it/s] 95%|█████████▍| 1308/1380 [02:38<00:07,  9.07it/s] 95%|█████████▍| 1309/1380 [02:38<00:07,  9.07it/s] 95%|█████████▍| 1310/1380 [02:38<00:07,  9.02it/s] 95%|█████████▌| 1311/1380 [02:38<00:07,  9.05it/s] 95%|█████████▌| 1312/1380 [02:39<00:07,  9.07it/s] 95%|█████████▌| 1313/1380 [02:39<00:07,  9.05it/s] 95%|█████████▌| 1314/1380 [02:39<00:07,  8.96it/s] 95%|█████████▌| 1315/1380 [02:39<00:07,  9.04it/s] 95%|█████████▌| 1316/1380 [02:39<00:07,  9.05it/s] 95%|█████████▌| 1317/1380 [02:39<00:06,  9.09it/s] 96%|█████████▌| 1318/1380 [02:39<00:06,  9.13it/s] 96%|█████████▌| 1319/1380 [02:39<00:06,  9.11it/s] 96%|█████████▌| 1320/1380 [02:39<00:06,  9.18it/s] 96%|█████████▌| 1321/1380 [02:40<00:06,  9.18it/s] 96%|█████████▌| 1322/1380 [02:40<00:06,  9.16it/s] 96%|█████████▌| 1323/1380 [02:40<00:06,  9.13it/s] 96%|█████████▌| 1324/1380 [02:40<00:06,  9.14it/s] 96%|█████████▌| 1325/1380 [02:40<00:06,  9.09it/s] 96%|█████████▌| 1326/1380 [02:40<00:05,  9.13it/s] 96%|█████████▌| 1327/1380 [02:40<00:05,  9.14it/s] 96%|█████████▌| 1328/1380 [02:40<00:05,  9.11it/s] 96%|█████████▋| 1329/1380 [02:40<00:05,  9.04it/s] 96%|█████████▋| 1330/1380 [02:40<00:05,  9.05it/s] 96%|█████████▋| 1331/1380 [02:41<00:05,  9.03it/s] 97%|█████████▋| 1332/1380 [02:41<00:05,  9.06it/s] 97%|█████████▋| 1333/1380 [02:41<00:05,  9.13it/s] 97%|█████████▋| 1334/1380 [02:41<00:05,  9.06it/s] 97%|█████████▋| 1335/1380 [02:41<00:04,  9.10it/s] 97%|█████████▋| 1336/1380 [02:41<00:04,  9.14it/s] 97%|█████████▋| 1337/1380 [02:41<00:04,  9.13it/s] 97%|█████████▋| 1338/1380 [02:41<00:04,  9.07it/s] 97%|█████████▋| 1339/1380 [02:41<00:04,  9.10it/s] 97%|█████████▋| 1340/1380 [02:42<00:04,  9.12it/s] 97%|█████████▋| 1341/1380 [02:42<00:04,  9.13it/s] 97%|█████████▋| 1342/1380 [02:42<00:04,  9.08it/s] 97%|█████████▋| 1343/1380 [02:42<00:04,  9.04it/s] 97%|█████████▋| 1344/1380 [02:42<00:03,  9.08it/s] 97%|█████████▋| 1345/1380 [02:42<00:03,  9.06it/s] 98%|█████████▊| 1346/1380 [02:42<00:03,  9.15it/s] 98%|█████████▊| 1347/1380 [02:42<00:03,  9.05it/s] 98%|█████████▊| 1348/1380 [02:42<00:03,  9.09it/s] 98%|█████████▊| 1349/1380 [02:43<00:03,  9.13it/s] 98%|█████████▊| 1350/1380 [02:43<00:03,  9.15it/s] 98%|█████████▊| 1351/1380 [02:43<00:03,  9.15it/s] 98%|█████████▊| 1352/1380 [02:43<00:03,  9.07it/s] 98%|█████████▊| 1353/1380 [02:43<00:02,  9.07it/s] 98%|█████████▊| 1354/1380 [02:43<00:02,  9.12it/s] 98%|█████████▊| 1355/1380 [02:43<00:02,  9.00it/s] 98%|█████████▊| 1356/1380 [02:43<00:02,  9.04it/s] 98%|█████████▊| 1357/1380 [02:43<00:02,  9.04it/s] 98%|█████████▊| 1358/1380 [02:44<00:02,  9.03it/s] 98%|█████████▊| 1359/1380 [02:44<00:02,  9.14it/s] 99%|█████████▊| 1360/1380 [02:44<00:02,  9.05it/s] 99%|█████████▊| 1361/1380 [02:44<00:02,  9.02it/s] 99%|█████████▊| 1362/1380 [02:44<00:01,  9.08it/s] 99%|█████████▉| 1363/1380 [02:44<00:01,  9.12it/s] 99%|█████████▉| 1364/1380 [02:44<00:01,  9.05it/s] 99%|█████████▉| 1365/1380 [02:44<00:01,  9.04it/s] 99%|█████████▉| 1366/1380 [02:44<00:01,  9.00it/s] 99%|█████████▉| 1367/1380 [02:45<00:01,  9.07it/s] 99%|█████████▉| 1368/1380 [02:45<00:01,  8.99it/s] 99%|█████████▉| 1369/1380 [02:45<00:01,  8.99it/s] 99%|█████████▉| 1370/1380 [02:45<00:01,  8.99it/s] 99%|█████████▉| 1371/1380 [02:45<00:00,  9.07it/s] 99%|█████████▉| 1372/1380 [02:45<00:00,  9.14it/s] 99%|█████████▉| 1373/1380 [02:45<00:00,  9.04it/s]100%|█████████▉| 1374/1380 [02:45<00:00,  8.97it/s]100%|█████████▉| 1375/1380 [02:45<00:00,  9.01it/s]100%|█████████▉| 1376/1380 [02:46<00:00,  9.10it/s]100%|█████████▉| 1377/1380 [02:46<00:00,  8.99it/s]100%|█████████▉| 1378/1380 [02:46<00:00,  9.04it/s]100%|█████████▉| 1379/1380 [02:46<00:00,  9.06it/s]                                                   100%|██████████| 1380/1380 [02:46<00:00,  9.06it/s][INFO|trainer.py:755] 2023-11-15 21:34:36,228 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:34:36,230 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:34:36,230 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:34:36,230 >>   Batch size = 8
{'eval_loss': 0.5344268083572388, 'eval_accuracy': 0.8498185117967332, 'eval_micro_f1': 0.8498185117967332, 'eval_macro_f1': 0.8379045966587335, 'eval_runtime': 3.8502, 'eval_samples_per_second': 572.444, 'eval_steps_per_second': 71.685, 'epoch': 4.0}
{'loss': 0.1007, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 8/276 [00:00<00:03, 76.98it/s][A
  6%|▌         | 16/276 [00:00<00:03, 77.51it/s][A
  9%|▊         | 24/276 [00:00<00:03, 72.90it/s][A
 12%|█▏        | 32/276 [00:00<00:03, 71.82it/s][A
 14%|█▍        | 40/276 [00:00<00:03, 73.88it/s][A
 17%|█▋        | 48/276 [00:00<00:03, 72.30it/s][A
 20%|██        | 56/276 [00:00<00:03, 70.41it/s][A
 23%|██▎       | 64/276 [00:00<00:02, 70.84it/s][A
 26%|██▌       | 72/276 [00:00<00:02, 71.61it/s][A
 29%|██▉       | 80/276 [00:01<00:02, 69.74it/s][A
 32%|███▏      | 87/276 [00:01<00:02, 69.35it/s][A
 34%|███▍      | 94/276 [00:01<00:02, 69.24it/s][A
 37%|███▋      | 102/276 [00:01<00:02, 70.78it/s][A
 40%|███▉      | 110/276 [00:01<00:02, 71.60it/s][A
 43%|████▎     | 118/276 [00:01<00:02, 71.34it/s][A
 46%|████▌     | 126/276 [00:01<00:02, 70.68it/s][A
 49%|████▊     | 134/276 [00:01<00:02, 70.18it/s][A
 51%|█████▏    | 142/276 [00:01<00:01, 71.33it/s][A
 54%|█████▍    | 150/276 [00:02<00:01, 70.21it/s][A
 57%|█████▋    | 158/276 [00:02<00:01, 69.27it/s][A
 60%|██████    | 166/276 [00:02<00:01, 70.74it/s][A
 63%|██████▎   | 174/276 [00:02<00:01, 70.64it/s][A
 66%|██████▌   | 182/276 [00:02<00:01, 70.41it/s][A
 69%|██████▉   | 190/276 [00:02<00:01, 69.49it/s][A
 72%|███████▏  | 198/276 [00:02<00:01, 71.39it/s][A
 75%|███████▍  | 206/276 [00:02<00:00, 71.51it/s][A
 78%|███████▊  | 214/276 [00:03<00:00, 70.26it/s][A
 80%|████████  | 222/276 [00:03<00:00, 69.91it/s][A
 83%|████████▎ | 230/276 [00:03<00:00, 71.07it/s][A
 86%|████████▌ | 238/276 [00:03<00:00, 70.66it/s][A
 89%|████████▉ | 246/276 [00:03<00:00, 70.22it/s][A
 92%|█████████▏| 254/276 [00:03<00:00, 69.83it/s][A
 95%|█████████▍| 262/276 [00:03<00:00, 69.93it/s][A
 98%|█████████▊| 270/276 [00:03<00:00, 70.89it/s][A                                                   
                                                 [A100%|██████████| 1380/1380 [02:50<00:00,  9.06it/s]
100%|██████████| 276/276 [00:03<00:00, 70.89it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 21:34:40,184 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:50<00:00,  9.06it/s]100%|██████████| 1380/1380 [02:50<00:00,  8.10it/s]
[INFO|trainer.py:2855] 2023-11-15 21:34:40,187 >> Saving model checkpoint to ./result/acl_bert-base-cased_adapter__seed4
[INFO|configuration_utils.py:460] 2023-11-15 21:34:40,189 >> Configuration saved in ./result/acl_bert-base-cased_adapter__seed4/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:34:41,231 >> Model weights saved in ./result/acl_bert-base-cased_adapter__seed4/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:34:41,233 >> tokenizer config file saved in ./result/acl_bert-base-cased_adapter__seed4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:34:41,235 >> Special tokens file saved in ./result/acl_bert-base-cased_adapter__seed4/special_tokens_map.json
{'eval_loss': 0.5772781372070312, 'eval_accuracy': 0.8539019963702359, 'eval_micro_f1': 0.8539019963702359, 'eval_macro_f1': 0.845250236833261, 'eval_runtime': 3.9506, 'eval_samples_per_second': 557.894, 'eval_steps_per_second': 69.863, 'epoch': 5.0}
{'train_runtime': 170.4453, 'train_samples_per_second': 258.617, 'train_steps_per_second': 8.096, 'train_loss': 0.25439986353335176, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2544
  train_runtime            = 0:02:50.44
  train_samples            =       8816
  train_samples_per_second =    258.617
  train_steps_per_second   =      8.096
11/15/2023 21:34:41 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:34:41,278 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:34:41,279 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:34:41,279 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:34:41,280 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  3%|▎         | 9/276 [00:00<00:03, 87.00it/s]  7%|▋         | 18/276 [00:00<00:03, 77.83it/s]  9%|▉         | 26/276 [00:00<00:03, 73.01it/s] 12%|█▏        | 34/276 [00:00<00:03, 74.15it/s] 15%|█▌        | 42/276 [00:00<00:03, 74.90it/s] 18%|█▊        | 50/276 [00:00<00:03, 73.76it/s] 21%|██        | 58/276 [00:00<00:03, 71.83it/s] 24%|██▍       | 66/276 [00:00<00:02, 72.95it/s] 27%|██▋       | 74/276 [00:00<00:02, 73.89it/s] 30%|██▉       | 82/276 [00:01<00:02, 72.56it/s] 33%|███▎      | 90/276 [00:01<00:02, 72.13it/s] 36%|███▌      | 98/276 [00:01<00:02, 73.45it/s] 38%|███▊      | 106/276 [00:01<00:02, 73.53it/s] 41%|████▏     | 114/276 [00:01<00:02, 73.08it/s] 44%|████▍     | 122/276 [00:01<00:02, 71.40it/s] 47%|████▋     | 130/276 [00:01<00:01, 73.09it/s] 50%|█████     | 138/276 [00:01<00:01, 73.96it/s] 53%|█████▎    | 146/276 [00:01<00:01, 74.35it/s] 56%|█████▌    | 154/276 [00:02<00:01, 72.98it/s] 59%|█████▊    | 162/276 [00:02<00:01, 73.28it/s] 62%|██████▏   | 170/276 [00:02<00:01, 74.87it/s] 64%|██████▍   | 178/276 [00:02<00:01, 73.59it/s] 67%|██████▋   | 186/276 [00:02<00:01, 72.13it/s] 70%|███████   | 194/276 [00:02<00:01, 73.38it/s] 73%|███████▎  | 202/276 [00:02<00:00, 74.36it/s] 76%|███████▌  | 210/276 [00:02<00:00, 72.77it/s] 79%|███████▉  | 218/276 [00:02<00:00, 72.84it/s] 82%|████████▏ | 226/276 [00:03<00:00, 73.52it/s] 85%|████████▍ | 234/276 [00:03<00:00, 73.96it/s] 88%|████████▊ | 242/276 [00:03<00:00, 71.97it/s] 91%|█████████ | 250/276 [00:03<00:00, 72.57it/s] 93%|█████████▎| 258/276 [00:03<00:00, 73.65it/s] 96%|█████████▋| 266/276 [00:03<00:00, 74.03it/s] 99%|█████████▉| 274/276 [00:03<00:00, 73.93it/s]100%|██████████| 276/276 [00:03<00:00, 72.57it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8539
  eval_loss               =     0.5773
  eval_macro_f1           =     0.8453
  eval_micro_f1           =     0.8539
  eval_runtime            = 0:00:03.81
  eval_samples            =       2204
  eval_samples_per_second =    577.477
  eval_steps_per_second   =     72.316
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▆▆█▁▄▄
wandb:                      eval/loss ▁▁▃▆██
wandb:                  eval/macro_f1 █▆▇▁▇▇
wandb:                  eval/micro_f1 ▆▆█▁▄▄
wandb:                   eval/runtime ▁▁█▄█▃
wandb:        eval/samples_per_second ██▁▄▁▆
wandb:          eval/steps_per_second ██▁▄▁▆
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.8539
wandb:                      eval/loss 0.57728
wandb:                  eval/macro_f1 0.84525
wandb:                  eval/micro_f1 0.8539
wandb:                   eval/runtime 3.8166
wandb:        eval/samples_per_second 577.477
wandb:          eval/steps_per_second 72.316
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.1007
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.2544
wandb:            train/train_runtime 170.4453
wandb: train/train_samples_per_second 258.617
wandb:   train/train_steps_per_second 8.096
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_213102-4qjefsui
wandb: Find logs at: ./wandb/offline-run-20231115_213102-4qjefsui/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='acl', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4/runs/Nov15_21-34-55_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:34:55 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:34:55 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4/runs/Nov15_21-34-54_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Map:   0%|          | 0/11020 [00:00<?, ? examples/s]Map:  37%|███▋      | 4111/11020 [00:00<00:00, 40030.33 examples/s]Map:  92%|█████████▏| 10125/11020 [00:00<00:00, 40033.89 examples/s]Map: 100%|██████████| 11020/11020 [00:00<00:00, 39802.14 examples/s]
[INFO|configuration_utils.py:715] 2023-11-15 21:35:11,495 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:35:11,505 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 21:35:21,522 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 21:35:31,541 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:35:31,542 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:35:51,579 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:35:51,579 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:35:51,579 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:35:51,579 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:35:51,580 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 21:35:51,581 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:35:51,582 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 21:35:51,604 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:35:51,606 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:36:11,758 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 21:36:13,119 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:36:13,120 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/8816 [00:00<?, ? examples/s]Running tokenizer on dataset:  23%|██▎       | 2000/8816 [00:00<00:00, 16802.86 examples/s]Running tokenizer on dataset:  68%|██████▊   | 6000/8816 [00:00<00:00, 20780.74 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 21448.89 examples/s]Running tokenizer on dataset: 100%|██████████| 8816/8816 [00:00<00:00, 20806.19 examples/s]
Running tokenizer on dataset:   0%|          | 0/2204 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 2204/2204 [00:00<00:00, 23153.80 examples/s]
11/15/2023 21:36:13 - INFO - __main__ - Sample 3167 of the training set: {'text': 'Other studies showed that ACR could affect the cellular energy generation and the deficiency of energy induced the neurotoxicity [7, 8].', 'label': 0, 'input_ids': [102, 494, 826, 1367, 198, 14290, 968, 2606, 111, 3431, 1333, 3014, 137, 111, 7411, 131, 1333, 2651, 111, 29257, 260, 450, 422, 493, 1901, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:36:13 - INFO - __main__ - Sample 4498 of the training set: {'text': 'Left renal glucose utilization and splanchnic glucose utilization (utilization) were calculated using the formula\n utilization 5 FEGlc 3 3Glc4a 3 R1H2PF (4)\n where R(H)PF equals either unilateral renal plasma flow or hepatic plasma flow.', 'label': 1, 'input_ids': [102, 2101, 4283, 3667, 6861, 137, 3675, 5006, 12057, 3667, 6861, 145, 6861, 546, 267, 2030, 487, 111, 4535, 6861, 305, 588, 2439, 30116, 239, 239, 2439, 30116, 30140, 30110, 239, 182, 30130, 30117, 30132, 9036, 145, 286, 546, 582, 182, 145, 151, 546, 5273, 11172, 1676, 14986, 4283, 2780, 1505, 234, 7221, 2780, 1505, 205, 103, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:36:13 - INFO - __main__ - Sample 2638 of the training set: {'text': 'The randomized controlled trials (RCTs) which evaluated the efficacy of PEG for mechanical bowel preparation in prevention of postoperative complications in colorectal surgery were considered for inclusion.', 'label': 1, 'input_ids': [102, 111, 5460, 3643, 3270, 145, 22475, 546, 334, 2840, 111, 4684, 131, 10850, 168, 4487, 11321, 4737, 121, 5200, 131, 6467, 4929, 121, 10095, 2797, 267, 1574, 168, 5117, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:36:13 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:36:15,136 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:36:15,143 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:36:15,144 >>   Num examples = 8,816
[INFO|trainer.py:1717] 2023-11-15 21:36:15,144 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:36:15,144 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:36:15,145 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:36:15,145 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:36:15,145 >>   Total optimization steps = 1,380
[INFO|trainer.py:1724] 2023-11-15 21:36:15,146 >>   Number of trainable parameters = 109,920,771
[INFO|integration_utils.py:716] 2023-11-15 21:36:15,147 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1380 [00:00<?, ?it/s]  0%|          | 1/1380 [00:01<32:47,  1.43s/it]  0%|          | 2/1380 [00:01<14:58,  1.53it/s]  0%|          | 3/1380 [00:01<09:16,  2.47it/s]  0%|          | 4/1380 [00:01<06:33,  3.50it/s]  0%|          | 5/1380 [00:01<05:05,  4.51it/s]  0%|          | 6/1380 [00:01<04:10,  5.48it/s]  1%|          | 7/1380 [00:02<03:37,  6.31it/s]  1%|          | 8/1380 [00:02<03:16,  6.99it/s]  1%|          | 9/1380 [00:02<03:01,  7.57it/s]  1%|          | 10/1380 [00:02<02:49,  8.10it/s]  1%|          | 11/1380 [00:02<02:43,  8.36it/s]  1%|          | 12/1380 [00:02<02:39,  8.58it/s]  1%|          | 13/1380 [00:02<02:35,  8.79it/s]  1%|          | 14/1380 [00:02<02:33,  8.87it/s]  1%|          | 15/1380 [00:02<02:32,  8.96it/s]  1%|          | 16/1380 [00:03<02:30,  9.04it/s]  1%|          | 17/1380 [00:03<02:30,  9.06it/s]  1%|▏         | 18/1380 [00:03<02:29,  9.13it/s]  1%|▏         | 19/1380 [00:03<02:29,  9.11it/s]  1%|▏         | 20/1380 [00:03<02:27,  9.24it/s]  2%|▏         | 21/1380 [00:03<02:28,  9.18it/s]  2%|▏         | 22/1380 [00:03<02:28,  9.16it/s]  2%|▏         | 23/1380 [00:03<02:26,  9.29it/s]  2%|▏         | 24/1380 [00:03<02:26,  9.28it/s]  2%|▏         | 25/1380 [00:04<02:26,  9.25it/s]  2%|▏         | 26/1380 [00:04<02:26,  9.24it/s]  2%|▏         | 27/1380 [00:04<02:25,  9.27it/s]  2%|▏         | 28/1380 [00:04<02:26,  9.23it/s]  2%|▏         | 29/1380 [00:04<02:26,  9.24it/s]  2%|▏         | 30/1380 [00:04<02:25,  9.26it/s]  2%|▏         | 31/1380 [00:04<02:27,  9.15it/s]  2%|▏         | 32/1380 [00:04<02:27,  9.11it/s]  2%|▏         | 33/1380 [00:04<02:25,  9.26it/s]  2%|▏         | 34/1380 [00:05<02:25,  9.24it/s]  3%|▎         | 35/1380 [00:05<02:25,  9.22it/s]  3%|▎         | 36/1380 [00:05<02:25,  9.22it/s]  3%|▎         | 37/1380 [00:05<02:24,  9.27it/s]  3%|▎         | 38/1380 [00:05<02:26,  9.17it/s]  3%|▎         | 39/1380 [00:05<02:26,  9.17it/s]  3%|▎         | 40/1380 [00:05<02:25,  9.22it/s]  3%|▎         | 41/1380 [00:05<02:25,  9.19it/s]  3%|▎         | 42/1380 [00:05<02:26,  9.12it/s]  3%|▎         | 43/1380 [00:05<02:23,  9.29it/s]  3%|▎         | 44/1380 [00:06<02:24,  9.27it/s]  3%|▎         | 45/1380 [00:06<02:24,  9.24it/s]  3%|▎         | 46/1380 [00:06<02:24,  9.23it/s]  3%|▎         | 47/1380 [00:06<02:24,  9.26it/s]  3%|▎         | 48/1380 [00:06<02:24,  9.20it/s]  4%|▎         | 49/1380 [00:06<02:24,  9.19it/s]  4%|▎         | 50/1380 [00:06<02:24,  9.23it/s]  4%|▎         | 51/1380 [00:06<02:24,  9.21it/s]  4%|▍         | 52/1380 [00:06<02:24,  9.19it/s]  4%|▍         | 53/1380 [00:07<02:22,  9.30it/s]  4%|▍         | 54/1380 [00:07<02:23,  9.24it/s]  4%|▍         | 55/1380 [00:07<02:23,  9.26it/s]  4%|▍         | 56/1380 [00:07<02:23,  9.21it/s]  4%|▍         | 57/1380 [00:07<02:24,  9.18it/s]  4%|▍         | 58/1380 [00:07<02:25,  9.09it/s]  4%|▍         | 59/1380 [00:07<02:24,  9.12it/s]  4%|▍         | 60/1380 [00:07<02:25,  9.07it/s]  4%|▍         | 61/1380 [00:07<02:24,  9.11it/s]  4%|▍         | 62/1380 [00:08<02:24,  9.15it/s]  5%|▍         | 63/1380 [00:08<02:21,  9.31it/s]  5%|▍         | 64/1380 [00:08<02:22,  9.25it/s]  5%|▍         | 65/1380 [00:08<02:22,  9.23it/s]  5%|▍         | 66/1380 [00:08<02:21,  9.28it/s]  5%|▍         | 67/1380 [00:08<02:22,  9.24it/s]  5%|▍         | 68/1380 [00:08<02:22,  9.18it/s]  5%|▌         | 69/1380 [00:08<02:22,  9.19it/s]  5%|▌         | 70/1380 [00:08<02:22,  9.20it/s]  5%|▌         | 71/1380 [00:09<02:22,  9.21it/s]  5%|▌         | 72/1380 [00:09<02:21,  9.25it/s]  5%|▌         | 73/1380 [00:09<02:20,  9.32it/s]  5%|▌         | 74/1380 [00:09<02:20,  9.27it/s]  5%|▌         | 75/1380 [00:09<02:21,  9.23it/s]  6%|▌         | 76/1380 [00:09<02:19,  9.37it/s]  6%|▌         | 77/1380 [00:09<02:20,  9.30it/s]  6%|▌         | 78/1380 [00:09<02:20,  9.29it/s]  6%|▌         | 79/1380 [00:09<02:20,  9.27it/s]  6%|▌         | 80/1380 [00:09<02:20,  9.24it/s]  6%|▌         | 81/1380 [00:10<02:20,  9.21it/s]  6%|▌         | 82/1380 [00:10<02:20,  9.24it/s]  6%|▌         | 83/1380 [00:10<02:18,  9.36it/s]  6%|▌         | 84/1380 [00:10<02:18,  9.33it/s]  6%|▌         | 85/1380 [00:10<02:18,  9.32it/s]  6%|▌         | 86/1380 [00:10<02:17,  9.38it/s]  6%|▋         | 87/1380 [00:10<02:18,  9.34it/s]  6%|▋         | 88/1380 [00:10<02:18,  9.30it/s]  6%|▋         | 89/1380 [00:10<02:18,  9.31it/s]  7%|▋         | 90/1380 [00:11<02:19,  9.28it/s]  7%|▋         | 91/1380 [00:11<02:19,  9.27it/s]  7%|▋         | 92/1380 [00:11<02:19,  9.27it/s]  7%|▋         | 93/1380 [00:11<02:17,  9.35it/s]  7%|▋         | 94/1380 [00:11<02:17,  9.35it/s]  7%|▋         | 95/1380 [00:11<02:18,  9.28it/s]  7%|▋         | 96/1380 [00:11<02:16,  9.39it/s]  7%|▋         | 97/1380 [00:11<02:16,  9.40it/s]  7%|▋         | 98/1380 [00:11<02:17,  9.32it/s]  7%|▋         | 99/1380 [00:12<02:17,  9.29it/s]  7%|▋         | 100/1380 [00:12<02:17,  9.33it/s]  7%|▋         | 101/1380 [00:12<02:17,  9.31it/s]  7%|▋         | 102/1380 [00:12<02:17,  9.27it/s]  7%|▋         | 103/1380 [00:12<02:16,  9.33it/s]  8%|▊         | 104/1380 [00:12<02:16,  9.35it/s]  8%|▊         | 105/1380 [00:12<02:17,  9.29it/s]  8%|▊         | 106/1380 [00:12<02:15,  9.40it/s]  8%|▊         | 107/1380 [00:12<02:15,  9.38it/s]  8%|▊         | 108/1380 [00:12<02:16,  9.34it/s]  8%|▊         | 109/1380 [00:13<02:15,  9.39it/s]  8%|▊         | 110/1380 [00:13<02:15,  9.41it/s]  8%|▊         | 111/1380 [00:13<02:14,  9.40it/s]  8%|▊         | 112/1380 [00:13<02:15,  9.35it/s]  8%|▊         | 113/1380 [00:13<02:14,  9.41it/s]  8%|▊         | 114/1380 [00:13<02:15,  9.37it/s]  8%|▊         | 115/1380 [00:13<02:16,  9.27it/s]  8%|▊         | 116/1380 [00:13<02:13,  9.44it/s]  8%|▊         | 117/1380 [00:13<02:15,  9.35it/s]  9%|▊         | 118/1380 [00:14<02:15,  9.31it/s]  9%|▊         | 119/1380 [00:14<02:15,  9.32it/s]  9%|▊         | 120/1380 [00:14<02:14,  9.38it/s]  9%|▉         | 121/1380 [00:14<02:14,  9.34it/s]  9%|▉         | 122/1380 [00:14<02:15,  9.31it/s]  9%|▉         | 123/1380 [00:14<02:15,  9.28it/s]  9%|▉         | 124/1380 [00:14<02:16,  9.20it/s]  9%|▉         | 125/1380 [00:14<02:15,  9.28it/s]  9%|▉         | 126/1380 [00:14<02:13,  9.40it/s]  9%|▉         | 127/1380 [00:15<02:13,  9.38it/s]  9%|▉         | 128/1380 [00:15<02:13,  9.36it/s]  9%|▉         | 129/1380 [00:15<02:13,  9.39it/s]  9%|▉         | 130/1380 [00:15<02:13,  9.36it/s]  9%|▉         | 131/1380 [00:15<02:13,  9.33it/s] 10%|▉         | 132/1380 [00:15<02:14,  9.31it/s] 10%|▉         | 133/1380 [00:15<02:13,  9.31it/s] 10%|▉         | 134/1380 [00:15<02:13,  9.30it/s] 10%|▉         | 135/1380 [00:15<02:13,  9.31it/s] 10%|▉         | 136/1380 [00:15<02:12,  9.40it/s] 10%|▉         | 137/1380 [00:16<02:12,  9.38it/s] 10%|█         | 138/1380 [00:16<02:12,  9.36it/s] 10%|█         | 139/1380 [00:16<02:11,  9.42it/s] 10%|█         | 140/1380 [00:16<02:11,  9.42it/s] 10%|█         | 141/1380 [00:16<02:12,  9.36it/s] 10%|█         | 142/1380 [00:16<02:13,  9.30it/s] 10%|█         | 143/1380 [00:16<02:13,  9.28it/s] 10%|█         | 144/1380 [00:16<02:12,  9.31it/s] 11%|█         | 145/1380 [00:16<02:13,  9.27it/s] 11%|█         | 146/1380 [00:17<02:11,  9.36it/s] 11%|█         | 147/1380 [00:17<02:12,  9.30it/s] 11%|█         | 148/1380 [00:17<02:12,  9.28it/s] 11%|█         | 149/1380 [00:17<02:10,  9.44it/s] 11%|█         | 150/1380 [00:17<02:11,  9.35it/s] 11%|█         | 151/1380 [00:17<02:12,  9.31it/s] 11%|█         | 152/1380 [00:17<02:13,  9.20it/s] 11%|█         | 153/1380 [00:17<02:12,  9.28it/s] 11%|█         | 154/1380 [00:17<02:11,  9.32it/s] 11%|█         | 155/1380 [00:18<02:11,  9.32it/s] 11%|█▏        | 156/1380 [00:18<02:11,  9.33it/s] 11%|█▏        | 157/1380 [00:18<02:12,  9.26it/s] 11%|█▏        | 158/1380 [00:18<02:11,  9.32it/s] 12%|█▏        | 159/1380 [00:18<02:10,  9.38it/s] 12%|█▏        | 160/1380 [00:18<02:11,  9.29it/s] 12%|█▏        | 161/1380 [00:18<02:10,  9.31it/s] 12%|█▏        | 162/1380 [00:18<02:10,  9.31it/s] 12%|█▏        | 163/1380 [00:18<02:10,  9.35it/s] 12%|█▏        | 164/1380 [00:18<02:10,  9.32it/s] 12%|█▏        | 165/1380 [00:19<02:10,  9.30it/s] 12%|█▏        | 166/1380 [00:19<02:11,  9.25it/s] 12%|█▏        | 167/1380 [00:19<02:11,  9.23it/s] 12%|█▏        | 168/1380 [00:19<02:10,  9.28it/s] 12%|█▏        | 169/1380 [00:19<02:08,  9.40it/s] 12%|█▏        | 170/1380 [00:19<02:09,  9.34it/s] 12%|█▏        | 171/1380 [00:19<02:10,  9.25it/s] 12%|█▏        | 172/1380 [00:19<02:09,  9.34it/s] 13%|█▎        | 173/1380 [00:19<02:09,  9.30it/s] 13%|█▎        | 174/1380 [00:20<02:10,  9.26it/s] 13%|█▎        | 175/1380 [00:20<02:10,  9.23it/s] 13%|█▎        | 176/1380 [00:20<02:10,  9.25it/s] 13%|█▎        | 177/1380 [00:20<02:10,  9.24it/s] 13%|█▎        | 178/1380 [00:20<02:09,  9.29it/s] 13%|█▎        | 179/1380 [00:20<02:08,  9.35it/s] 13%|█▎        | 180/1380 [00:20<02:08,  9.32it/s] 13%|█▎        | 181/1380 [00:20<02:09,  9.23it/s] 13%|█▎        | 182/1380 [00:20<02:07,  9.39it/s] 13%|█▎        | 183/1380 [00:21<02:08,  9.35it/s] 13%|█▎        | 184/1380 [00:21<02:09,  9.26it/s] 13%|█▎        | 185/1380 [00:21<02:09,  9.26it/s] 13%|█▎        | 186/1380 [00:21<02:08,  9.27it/s] 14%|█▎        | 187/1380 [00:21<02:08,  9.29it/s] 14%|█▎        | 188/1380 [00:21<02:08,  9.24it/s] 14%|█▎        | 189/1380 [00:21<02:09,  9.22it/s] 14%|█▍        | 190/1380 [00:21<02:09,  9.18it/s] 14%|█▍        | 191/1380 [00:21<02:08,  9.22it/s] 14%|█▍        | 192/1380 [00:22<02:07,  9.32it/s] 14%|█▍        | 193/1380 [00:22<02:08,  9.27it/s] 14%|█▍        | 194/1380 [00:22<02:08,  9.25it/s] 14%|█▍        | 195/1380 [00:22<02:08,  9.21it/s] 14%|█▍        | 196/1380 [00:22<02:07,  9.31it/s] 14%|█▍        | 197/1380 [00:22<02:07,  9.26it/s] 14%|█▍        | 198/1380 [00:22<02:07,  9.24it/s] 14%|█▍        | 199/1380 [00:22<02:08,  9.20it/s] 14%|█▍        | 200/1380 [00:22<02:07,  9.23it/s] 15%|█▍        | 201/1380 [00:22<02:07,  9.27it/s] 15%|█▍        | 202/1380 [00:23<02:05,  9.37it/s] 15%|█▍        | 203/1380 [00:23<02:06,  9.27it/s] 15%|█▍        | 204/1380 [00:23<02:06,  9.28it/s] 15%|█▍        | 205/1380 [00:23<02:06,  9.31it/s] 15%|█▍        | 206/1380 [00:23<02:06,  9.27it/s] 15%|█▌        | 207/1380 [00:23<02:06,  9.29it/s] 15%|█▌        | 208/1380 [00:23<02:06,  9.29it/s] 15%|█▌        | 209/1380 [00:23<02:06,  9.26it/s] 15%|█▌        | 210/1380 [00:23<02:06,  9.23it/s] 15%|█▌        | 211/1380 [00:24<02:06,  9.24it/s] 15%|█▌        | 212/1380 [00:24<02:05,  9.32it/s] 15%|█▌        | 213/1380 [00:24<02:06,  9.24it/s] 16%|█▌        | 214/1380 [00:24<02:06,  9.22it/s] 16%|█▌        | 215/1380 [00:24<02:04,  9.33it/s] 16%|█▌        | 216/1380 [00:24<02:05,  9.27it/s] 16%|█▌        | 217/1380 [00:24<02:06,  9.21it/s] 16%|█▌        | 218/1380 [00:24<02:05,  9.25it/s] 16%|█▌        | 219/1380 [00:24<02:05,  9.22it/s] 16%|█▌        | 220/1380 [00:25<02:05,  9.25it/s] 16%|█▌        | 221/1380 [00:25<02:05,  9.23it/s] 16%|█▌        | 222/1380 [00:25<02:05,  9.25it/s] 16%|█▌        | 223/1380 [00:25<02:05,  9.25it/s] 16%|█▌        | 224/1380 [00:25<02:05,  9.25it/s] 16%|█▋        | 225/1380 [00:25<02:03,  9.35it/s] 16%|█▋        | 226/1380 [00:25<02:04,  9.26it/s] 16%|█▋        | 227/1380 [00:25<02:04,  9.25it/s] 17%|█▋        | 228/1380 [00:25<02:05,  9.21it/s] 17%|█▋        | 229/1380 [00:26<02:04,  9.28it/s] 17%|█▋        | 230/1380 [00:26<02:04,  9.24it/s] 17%|█▋        | 231/1380 [00:26<02:04,  9.22it/s] 17%|█▋        | 232/1380 [00:26<02:04,  9.19it/s] 17%|█▋        | 233/1380 [00:26<02:04,  9.20it/s] 17%|█▋        | 234/1380 [00:26<02:03,  9.28it/s] 17%|█▋        | 235/1380 [00:26<02:01,  9.39it/s] 17%|█▋        | 236/1380 [00:26<02:02,  9.31it/s] 17%|█▋        | 237/1380 [00:26<02:02,  9.30it/s] 17%|█▋        | 238/1380 [00:26<02:02,  9.34it/s] 17%|█▋        | 239/1380 [00:27<02:02,  9.34it/s] 17%|█▋        | 240/1380 [00:27<02:02,  9.29it/s] 17%|█▋        | 241/1380 [00:27<02:02,  9.26it/s] 18%|█▊        | 242/1380 [00:27<02:02,  9.28it/s] 18%|█▊        | 243/1380 [00:27<02:01,  9.34it/s] 18%|█▊        | 244/1380 [00:27<02:02,  9.28it/s] 18%|█▊        | 245/1380 [00:27<02:02,  9.30it/s] 18%|█▊        | 246/1380 [00:27<02:02,  9.25it/s] 18%|█▊        | 247/1380 [00:27<02:02,  9.26it/s] 18%|█▊        | 248/1380 [00:28<02:00,  9.36it/s] 18%|█▊        | 249/1380 [00:28<02:02,  9.26it/s] 18%|█▊        | 250/1380 [00:28<02:01,  9.28it/s] 18%|█▊        | 251/1380 [00:28<02:01,  9.29it/s] 18%|█▊        | 252/1380 [00:28<02:01,  9.31it/s] 18%|█▊        | 253/1380 [00:28<02:01,  9.28it/s] 18%|█▊        | 254/1380 [00:28<02:01,  9.29it/s] 18%|█▊        | 255/1380 [00:28<02:01,  9.29it/s] 19%|█▊        | 256/1380 [00:28<02:00,  9.31it/s] 19%|█▊        | 257/1380 [00:29<02:01,  9.23it/s] 19%|█▊        | 258/1380 [00:29<02:01,  9.24it/s] 19%|█▉        | 259/1380 [00:29<02:00,  9.31it/s] 19%|█▉        | 260/1380 [00:29<02:00,  9.30it/s] 19%|█▉        | 261/1380 [00:29<01:58,  9.45it/s] 19%|█▉        | 262/1380 [00:29<01:59,  9.35it/s] 19%|█▉        | 263/1380 [00:29<01:59,  9.35it/s] 19%|█▉        | 264/1380 [00:29<01:59,  9.30it/s] 19%|█▉        | 265/1380 [00:29<01:59,  9.37it/s] 19%|█▉        | 266/1380 [00:29<01:58,  9.36it/s] 19%|█▉        | 267/1380 [00:30<01:59,  9.32it/s] 19%|█▉        | 268/1380 [00:30<02:00,  9.23it/s] 19%|█▉        | 269/1380 [00:30<02:00,  9.24it/s] 20%|█▉        | 270/1380 [00:30<02:00,  9.21it/s] 20%|█▉        | 271/1380 [00:30<01:59,  9.28it/s] 20%|█▉        | 272/1380 [00:30<01:59,  9.30it/s] 20%|█▉        | 273/1380 [00:30<01:59,  9.27it/s] 20%|█▉        | 274/1380 [00:30<01:57,  9.43it/s] 20%|█▉        | 275/1380 [00:30<01:57,  9.43it/s]                                                   20%|██        | 276/1380 [00:31<01:57,  9.43it/s][INFO|trainer.py:755] 2023-11-15 21:36:46,177 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:36:46,179 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:36:46,179 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:36:46,179 >>   Batch size = 8
{'loss': 0.4303, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 87.40it/s][A
  7%|▋         | 18/276 [00:00<00:03, 80.97it/s][A
 10%|▉         | 27/276 [00:00<00:03, 75.43it/s][A
 13%|█▎        | 35/276 [00:00<00:03, 73.78it/s][A
 16%|█▌        | 43/276 [00:00<00:03, 75.05it/s][A
 18%|█▊        | 51/276 [00:00<00:03, 74.23it/s][A
 21%|██▏       | 59/276 [00:00<00:02, 73.21it/s][A
 24%|██▍       | 67/276 [00:00<00:02, 72.41it/s][A
 27%|██▋       | 75/276 [00:01<00:02, 72.72it/s][A
 30%|███       | 83/276 [00:01<00:02, 73.62it/s][A
 33%|███▎      | 91/276 [00:01<00:02, 73.76it/s][A
 36%|███▌      | 99/276 [00:01<00:02, 72.93it/s][A
 39%|███▉      | 107/276 [00:01<00:02, 72.91it/s][A
 42%|████▏     | 115/276 [00:01<00:02, 74.43it/s][A
 45%|████▍     | 123/276 [00:01<00:02, 73.87it/s][A
 47%|████▋     | 131/276 [00:01<00:01, 73.38it/s][A
 50%|█████     | 139/276 [00:01<00:01, 72.97it/s][A
 53%|█████▎    | 147/276 [00:01<00:01, 73.56it/s][A
 56%|█████▌    | 155/276 [00:02<00:01, 72.98it/s][A
 59%|█████▉    | 163/276 [00:02<00:01, 71.55it/s][A
 62%|██████▏   | 171/276 [00:02<00:01, 72.54it/s][A
 65%|██████▍   | 179/276 [00:02<00:01, 73.35it/s][A
 68%|██████▊   | 187/276 [00:02<00:01, 71.45it/s][A
 71%|███████   | 195/276 [00:02<00:01, 71.94it/s][A
 74%|███████▎  | 203/276 [00:02<00:01, 72.79it/s][A
 76%|███████▋  | 211/276 [00:02<00:00, 73.18it/s][A
 79%|███████▉  | 219/276 [00:02<00:00, 74.05it/s][A
 82%|████████▏ | 227/276 [00:03<00:00, 72.60it/s][A
 85%|████████▌ | 235/276 [00:03<00:00, 72.13it/s][A
 88%|████████▊ | 243/276 [00:03<00:00, 74.19it/s][A
 91%|█████████ | 251/276 [00:03<00:00, 73.99it/s][A
 94%|█████████▍| 259/276 [00:03<00:00, 71.89it/s][A
 97%|█████████▋| 267/276 [00:03<00:00, 71.70it/s][A
100%|█████████▉| 275/276 [00:03<00:00, 73.37it/s][A                                                  
                                                 [A 20%|██        | 276/1380 [00:34<01:57,  9.43it/s]
100%|██████████| 276/276 [00:03<00:00, 73.37it/s][A
                                                 [A 20%|██        | 277/1380 [00:34<18:03,  1.02it/s] 20%|██        | 278/1380 [00:35<14:02,  1.31it/s] 20%|██        | 279/1380 [00:35<10:53,  1.69it/s] 20%|██        | 280/1380 [00:35<08:28,  2.16it/s] 20%|██        | 281/1380 [00:35<06:38,  2.76it/s] 20%|██        | 282/1380 [00:35<05:18,  3.45it/s] 21%|██        | 283/1380 [00:35<04:20,  4.21it/s] 21%|██        | 284/1380 [00:35<03:38,  5.02it/s] 21%|██        | 285/1380 [00:35<03:08,  5.82it/s] 21%|██        | 286/1380 [00:35<02:48,  6.50it/s] 21%|██        | 287/1380 [00:36<02:32,  7.16it/s] 21%|██        | 288/1380 [00:36<02:21,  7.74it/s] 21%|██        | 289/1380 [00:36<02:13,  8.14it/s] 21%|██        | 290/1380 [00:36<02:09,  8.40it/s] 21%|██        | 291/1380 [00:36<02:05,  8.69it/s] 21%|██        | 292/1380 [00:36<02:02,  8.85it/s] 21%|██        | 293/1380 [00:36<02:01,  8.93it/s] 21%|██▏       | 294/1380 [00:36<02:01,  8.95it/s] 21%|██▏       | 295/1380 [00:36<02:00,  9.01it/s] 21%|██▏       | 296/1380 [00:37<01:59,  9.06it/s] 22%|██▏       | 297/1380 [00:37<01:58,  9.17it/s] 22%|██▏       | 298/1380 [00:37<01:56,  9.27it/s] 22%|██▏       | 299/1380 [00:37<01:56,  9.26it/s] 22%|██▏       | 300/1380 [00:37<01:57,  9.23it/s] 22%|██▏       | 301/1380 [00:37<01:57,  9.22it/s] 22%|██▏       | 302/1380 [00:37<01:56,  9.24it/s] 22%|██▏       | 303/1380 [00:37<01:55,  9.31it/s] 22%|██▏       | 304/1380 [00:37<01:56,  9.21it/s] 22%|██▏       | 305/1380 [00:37<01:57,  9.16it/s] 22%|██▏       | 306/1380 [00:38<01:56,  9.20it/s] 22%|██▏       | 307/1380 [00:38<01:55,  9.27it/s] 22%|██▏       | 308/1380 [00:38<01:54,  9.35it/s] 22%|██▏       | 309/1380 [00:38<01:55,  9.26it/s] 22%|██▏       | 310/1380 [00:38<01:55,  9.23it/s] 23%|██▎       | 311/1380 [00:38<01:54,  9.31it/s] 23%|██▎       | 312/1380 [00:38<01:55,  9.25it/s] 23%|██▎       | 313/1380 [00:38<01:55,  9.21it/s] 23%|██▎       | 314/1380 [00:38<01:55,  9.26it/s] 23%|██▎       | 315/1380 [00:39<01:55,  9.25it/s] 23%|██▎       | 316/1380 [00:39<01:55,  9.22it/s] 23%|██▎       | 317/1380 [00:39<01:56,  9.15it/s] 23%|██▎       | 318/1380 [00:39<01:55,  9.22it/s] 23%|██▎       | 319/1380 [00:39<01:55,  9.21it/s] 23%|██▎       | 320/1380 [00:39<01:55,  9.20it/s] 23%|██▎       | 321/1380 [00:39<01:53,  9.30it/s] 23%|██▎       | 322/1380 [00:39<01:53,  9.28it/s] 23%|██▎       | 323/1380 [00:39<01:55,  9.18it/s] 23%|██▎       | 324/1380 [00:40<01:54,  9.20it/s] 24%|██▎       | 325/1380 [00:40<01:54,  9.23it/s] 24%|██▎       | 326/1380 [00:40<01:54,  9.23it/s] 24%|██▎       | 327/1380 [00:40<01:54,  9.21it/s] 24%|██▍       | 328/1380 [00:40<01:53,  9.26it/s] 24%|██▍       | 329/1380 [00:40<01:54,  9.20it/s] 24%|██▍       | 330/1380 [00:40<01:53,  9.22it/s] 24%|██▍       | 331/1380 [00:40<01:52,  9.33it/s] 24%|██▍       | 332/1380 [00:40<01:53,  9.26it/s] 24%|██▍       | 333/1380 [00:41<01:53,  9.25it/s] 24%|██▍       | 334/1380 [00:41<01:52,  9.27it/s] 24%|██▍       | 335/1380 [00:41<01:53,  9.22it/s] 24%|██▍       | 336/1380 [00:41<01:53,  9.17it/s] 24%|██▍       | 337/1380 [00:41<01:53,  9.16it/s] 24%|██▍       | 338/1380 [00:41<01:53,  9.15it/s] 25%|██▍       | 339/1380 [00:41<01:53,  9.17it/s] 25%|██▍       | 340/1380 [00:41<01:53,  9.20it/s] 25%|██▍       | 341/1380 [00:41<01:51,  9.33it/s] 25%|██▍       | 342/1380 [00:41<01:51,  9.28it/s] 25%|██▍       | 343/1380 [00:42<01:52,  9.24it/s] 25%|██▍       | 344/1380 [00:42<01:51,  9.33it/s] 25%|██▌       | 345/1380 [00:42<01:50,  9.36it/s] 25%|██▌       | 346/1380 [00:42<01:50,  9.32it/s] 25%|██▌       | 347/1380 [00:42<01:51,  9.28it/s] 25%|██▌       | 348/1380 [00:42<01:51,  9.26it/s] 25%|██▌       | 349/1380 [00:42<01:52,  9.20it/s] 25%|██▌       | 350/1380 [00:42<01:51,  9.21it/s] 25%|██▌       | 351/1380 [00:42<01:50,  9.28it/s] 26%|██▌       | 352/1380 [00:43<01:51,  9.23it/s] 26%|██▌       | 353/1380 [00:43<01:50,  9.25it/s] 26%|██▌       | 354/1380 [00:43<01:49,  9.36it/s] 26%|██▌       | 355/1380 [00:43<01:50,  9.26it/s] 26%|██▌       | 356/1380 [00:43<01:50,  9.30it/s] 26%|██▌       | 357/1380 [00:43<01:50,  9.27it/s] 26%|██▌       | 358/1380 [00:43<01:50,  9.28it/s] 26%|██▌       | 359/1380 [00:43<01:50,  9.25it/s] 26%|██▌       | 360/1380 [00:43<01:50,  9.27it/s] 26%|██▌       | 361/1380 [00:44<01:50,  9.22it/s] 26%|██▌       | 362/1380 [00:44<01:49,  9.27it/s] 26%|██▋       | 363/1380 [00:44<01:49,  9.25it/s] 26%|██▋       | 364/1380 [00:44<01:48,  9.37it/s] 26%|██▋       | 365/1380 [00:44<01:49,  9.28it/s] 27%|██▋       | 366/1380 [00:44<01:48,  9.33it/s] 27%|██▋       | 367/1380 [00:44<01:48,  9.38it/s] 27%|██▋       | 368/1380 [00:44<01:47,  9.39it/s] 27%|██▋       | 369/1380 [00:44<01:48,  9.33it/s] 27%|██▋       | 370/1380 [00:45<01:48,  9.27it/s] 27%|██▋       | 371/1380 [00:45<01:49,  9.23it/s] 27%|██▋       | 372/1380 [00:45<01:49,  9.20it/s] 27%|██▋       | 373/1380 [00:45<01:49,  9.18it/s] 27%|██▋       | 374/1380 [00:45<01:48,  9.25it/s] 27%|██▋       | 375/1380 [00:45<01:48,  9.24it/s] 27%|██▋       | 376/1380 [00:45<01:48,  9.25it/s] 27%|██▋       | 377/1380 [00:45<01:46,  9.39it/s] 27%|██▋       | 378/1380 [00:45<01:47,  9.32it/s] 27%|██▋       | 379/1380 [00:45<01:48,  9.27it/s] 28%|██▊       | 380/1380 [00:46<01:48,  9.22it/s] 28%|██▊       | 381/1380 [00:46<01:48,  9.24it/s] 28%|██▊       | 382/1380 [00:46<01:48,  9.18it/s] 28%|██▊       | 383/1380 [00:46<01:48,  9.15it/s] 28%|██▊       | 384/1380 [00:46<01:49,  9.12it/s] 28%|██▊       | 385/1380 [00:46<01:49,  9.09it/s] 28%|██▊       | 386/1380 [00:46<01:49,  9.10it/s] 28%|██▊       | 387/1380 [00:46<01:48,  9.17it/s] 28%|██▊       | 388/1380 [00:46<01:48,  9.16it/s] 28%|██▊       | 389/1380 [00:47<01:48,  9.14it/s] 28%|██▊       | 390/1380 [00:47<01:46,  9.27it/s] 28%|██▊       | 391/1380 [00:47<01:47,  9.23it/s] 28%|██▊       | 392/1380 [00:47<01:47,  9.22it/s] 28%|██▊       | 393/1380 [00:47<01:47,  9.19it/s] 29%|██▊       | 394/1380 [00:47<01:47,  9.20it/s] 29%|██▊       | 395/1380 [00:47<01:47,  9.19it/s] 29%|██▊       | 396/1380 [00:47<01:47,  9.16it/s] 29%|██▉       | 397/1380 [00:47<01:47,  9.14it/s] 29%|██▉       | 398/1380 [00:48<01:47,  9.12it/s] 29%|██▉       | 399/1380 [00:48<01:47,  9.10it/s] 29%|██▉       | 400/1380 [00:48<01:46,  9.22it/s] 29%|██▉       | 401/1380 [00:48<01:46,  9.16it/s] 29%|██▉       | 402/1380 [00:48<01:47,  9.13it/s] 29%|██▉       | 403/1380 [00:48<01:45,  9.30it/s] 29%|██▉       | 404/1380 [00:48<01:45,  9.25it/s] 29%|██▉       | 405/1380 [00:48<01:45,  9.23it/s] 29%|██▉       | 406/1380 [00:48<01:45,  9.22it/s] 29%|██▉       | 407/1380 [00:49<01:45,  9.25it/s] 30%|██▉       | 408/1380 [00:49<01:45,  9.25it/s] 30%|██▉       | 409/1380 [00:49<01:45,  9.19it/s] 30%|██▉       | 410/1380 [00:49<01:45,  9.20it/s] 30%|██▉       | 411/1380 [00:49<01:44,  9.25it/s] 30%|██▉       | 412/1380 [00:49<01:44,  9.28it/s] 30%|██▉       | 413/1380 [00:49<01:43,  9.31it/s] 30%|███       | 414/1380 [00:49<01:44,  9.24it/s] 30%|███       | 415/1380 [00:49<01:44,  9.22it/s] 30%|███       | 416/1380 [00:49<01:43,  9.29it/s] 30%|███       | 417/1380 [00:50<01:42,  9.35it/s] 30%|███       | 418/1380 [00:50<01:43,  9.31it/s] 30%|███       | 419/1380 [00:50<01:43,  9.28it/s] 30%|███       | 420/1380 [00:50<01:43,  9.27it/s] 31%|███       | 421/1380 [00:50<01:42,  9.34it/s] 31%|███       | 422/1380 [00:50<01:43,  9.21it/s] 31%|███       | 423/1380 [00:50<01:43,  9.24it/s] 31%|███       | 424/1380 [00:50<01:43,  9.25it/s] 31%|███       | 425/1380 [00:50<01:43,  9.19it/s] 31%|███       | 426/1380 [00:51<01:43,  9.23it/s] 31%|███       | 427/1380 [00:51<01:43,  9.21it/s] 31%|███       | 428/1380 [00:51<01:43,  9.18it/s] 31%|███       | 429/1380 [00:51<01:42,  9.29it/s] 31%|███       | 430/1380 [00:51<01:41,  9.35it/s] 31%|███       | 431/1380 [00:51<01:42,  9.25it/s] 31%|███▏      | 432/1380 [00:51<01:42,  9.27it/s] 31%|███▏      | 433/1380 [00:51<01:41,  9.29it/s] 31%|███▏      | 434/1380 [00:51<01:41,  9.31it/s] 32%|███▏      | 435/1380 [00:52<01:41,  9.30it/s] 32%|███▏      | 436/1380 [00:52<01:41,  9.25it/s] 32%|███▏      | 437/1380 [00:52<01:41,  9.25it/s] 32%|███▏      | 438/1380 [00:52<01:41,  9.24it/s] 32%|███▏      | 439/1380 [00:52<01:41,  9.31it/s] 32%|███▏      | 440/1380 [00:52<01:41,  9.27it/s] 32%|███▏      | 441/1380 [00:52<01:41,  9.25it/s] 32%|███▏      | 442/1380 [00:52<01:40,  9.29it/s] 32%|███▏      | 443/1380 [00:52<01:40,  9.33it/s] 32%|███▏      | 444/1380 [00:53<01:40,  9.27it/s] 32%|███▏      | 445/1380 [00:53<01:40,  9.29it/s] 32%|███▏      | 446/1380 [00:53<01:40,  9.29it/s] 32%|███▏      | 447/1380 [00:53<01:40,  9.32it/s] 32%|███▏      | 448/1380 [00:53<01:40,  9.27it/s] 33%|███▎      | 449/1380 [00:53<01:40,  9.29it/s] 33%|███▎      | 450/1380 [00:53<01:40,  9.23it/s] 33%|███▎      | 451/1380 [00:53<01:40,  9.28it/s] 33%|███▎      | 452/1380 [00:53<01:39,  9.36it/s] 33%|███▎      | 453/1380 [00:53<01:39,  9.30it/s] 33%|███▎      | 454/1380 [00:54<01:40,  9.23it/s] 33%|███▎      | 455/1380 [00:54<01:40,  9.23it/s] 33%|███▎      | 456/1380 [00:54<01:39,  9.28it/s] 33%|███▎      | 457/1380 [00:54<01:39,  9.29it/s] 33%|███▎      | 458/1380 [00:54<01:39,  9.28it/s] 33%|███▎      | 459/1380 [00:54<01:39,  9.22it/s] 33%|███▎      | 460/1380 [00:54<01:39,  9.28it/s] 33%|███▎      | 461/1380 [00:54<01:38,  9.30it/s] 33%|███▎      | 462/1380 [00:54<01:38,  9.36it/s] 34%|███▎      | 463/1380 [00:55<01:39,  9.26it/s] 34%|███▎      | 464/1380 [00:55<01:39,  9.24it/s] 34%|███▎      | 465/1380 [00:55<01:38,  9.32it/s] 34%|███▍      | 466/1380 [00:55<01:38,  9.28it/s] 34%|███▍      | 467/1380 [00:55<01:38,  9.23it/s] 34%|███▍      | 468/1380 [00:55<01:38,  9.26it/s] 34%|███▍      | 469/1380 [00:55<01:38,  9.26it/s] 34%|███▍      | 470/1380 [00:55<01:38,  9.28it/s] 34%|███▍      | 471/1380 [00:55<01:38,  9.23it/s] 34%|███▍      | 472/1380 [00:56<01:38,  9.20it/s] 34%|███▍      | 473/1380 [00:56<01:39,  9.14it/s] 34%|███▍      | 474/1380 [00:56<01:38,  9.19it/s] 34%|███▍      | 475/1380 [00:56<01:37,  9.26it/s] 34%|███▍      | 476/1380 [00:56<01:38,  9.18it/s] 35%|███▍      | 477/1380 [00:56<01:39,  9.11it/s] 35%|███▍      | 478/1380 [00:56<01:37,  9.29it/s] 35%|███▍      | 479/1380 [00:56<01:37,  9.25it/s] 35%|███▍      | 480/1380 [00:56<01:37,  9.19it/s] 35%|███▍      | 481/1380 [00:57<01:37,  9.19it/s] 35%|███▍      | 482/1380 [00:57<01:37,  9.24it/s] 35%|███▌      | 483/1380 [00:57<01:36,  9.28it/s] 35%|███▌      | 484/1380 [00:57<01:37,  9.22it/s] 35%|███▌      | 485/1380 [00:57<01:37,  9.22it/s] 35%|███▌      | 486/1380 [00:57<01:36,  9.25it/s] 35%|███▌      | 487/1380 [00:57<01:36,  9.21it/s] 35%|███▌      | 488/1380 [00:57<01:36,  9.28it/s] 35%|███▌      | 489/1380 [00:57<01:37,  9.18it/s] 36%|███▌      | 490/1380 [00:57<01:36,  9.26it/s] 36%|███▌      | 491/1380 [00:58<01:35,  9.33it/s] 36%|███▌      | 492/1380 [00:58<01:35,  9.33it/s] 36%|███▌      | 493/1380 [00:58<01:35,  9.24it/s] 36%|███▌      | 494/1380 [00:58<01:36,  9.23it/s] 36%|███▌      | 495/1380 [00:58<01:36,  9.20it/s] 36%|███▌      | 496/1380 [00:58<01:35,  9.26it/s] 36%|███▌      | 497/1380 [00:58<01:35,  9.27it/s] 36%|███▌      | 498/1380 [00:58<01:34,  9.31it/s] 36%|███▌      | 499/1380 [00:58<01:35,  9.20it/s] 36%|███▌      | 500/1380 [00:59<01:35,  9.21it/s] 36%|███▋      | 501/1380 [00:59<01:34,  9.29it/s] 36%|███▋      | 502/1380 [00:59<01:35,  9.20it/s] 36%|███▋      | 503/1380 [00:59<01:35,  9.15it/s] 37%|███▋      | 504/1380 [00:59<01:35,  9.16it/s] 37%|███▋      | 505/1380 [00:59<01:35,  9.15it/s] 37%|███▋      | 506/1380 [00:59<01:35,  9.15it/s] 37%|███▋      | 507/1380 [00:59<01:35,  9.17it/s] 37%|███▋      | 508/1380 [00:59<01:35,  9.16it/s] 37%|███▋      | 509/1380 [01:00<01:34,  9.23it/s] 37%|███▋      | 510/1380 [01:00<01:34,  9.18it/s] 37%|███▋      | 511/1380 [01:00<01:33,  9.26it/s] 37%|███▋      | 512/1380 [01:00<01:34,  9.22it/s] 37%|███▋      | 513/1380 [01:00<01:34,  9.22it/s] 37%|███▋      | 514/1380 [01:00<01:33,  9.25it/s] 37%|███▋      | 515/1380 [01:00<01:33,  9.26it/s] 37%|███▋      | 516/1380 [01:00<01:33,  9.21it/s] 37%|███▋      | 517/1380 [01:00<01:33,  9.21it/s] 38%|███▊      | 518/1380 [01:01<01:33,  9.23it/s] 38%|███▊      | 519/1380 [01:01<01:33,  9.21it/s] 38%|███▊      | 520/1380 [01:01<01:34,  9.15it/s] 38%|███▊      | 521/1380 [01:01<01:32,  9.24it/s] 38%|███▊      | 522/1380 [01:01<01:32,  9.23it/s] 38%|███▊      | 523/1380 [01:01<01:33,  9.17it/s] 38%|███▊      | 524/1380 [01:01<01:32,  9.24it/s] 38%|███▊      | 525/1380 [01:01<01:32,  9.22it/s] 38%|███▊      | 526/1380 [01:01<01:33,  9.16it/s] 38%|███▊      | 527/1380 [01:02<01:32,  9.19it/s] 38%|███▊      | 528/1380 [01:02<01:32,  9.18it/s] 38%|███▊      | 529/1380 [01:02<01:32,  9.22it/s] 38%|███▊      | 530/1380 [01:02<01:32,  9.18it/s] 38%|███▊      | 531/1380 [01:02<01:31,  9.30it/s] 39%|███▊      | 532/1380 [01:02<01:31,  9.22it/s] 39%|███▊      | 533/1380 [01:02<01:32,  9.16it/s] 39%|███▊      | 534/1380 [01:02<01:32,  9.19it/s] 39%|███▉      | 535/1380 [01:02<01:31,  9.23it/s] 39%|███▉      | 536/1380 [01:02<01:32,  9.16it/s] 39%|███▉      | 537/1380 [01:03<01:32,  9.16it/s] 39%|███▉      | 538/1380 [01:03<01:32,  9.10it/s] 39%|███▉      | 539/1380 [01:03<01:32,  9.10it/s] 39%|███▉      | 540/1380 [01:03<01:32,  9.08it/s] 39%|███▉      | 541/1380 [01:03<01:31,  9.19it/s] 39%|███▉      | 542/1380 [01:03<01:31,  9.18it/s] 39%|███▉      | 543/1380 [01:03<01:32,  9.03it/s] 39%|███▉      | 544/1380 [01:03<01:31,  9.17it/s] 39%|███▉      | 545/1380 [01:03<01:31,  9.13it/s] 40%|███▉      | 546/1380 [01:04<01:31,  9.08it/s] 40%|███▉      | 547/1380 [01:04<01:31,  9.11it/s] 40%|███▉      | 548/1380 [01:04<01:31,  9.11it/s] 40%|███▉      | 549/1380 [01:04<01:31,  9.12it/s] 40%|███▉      | 550/1380 [01:04<01:31,  9.11it/s] 40%|███▉      | 551/1380 [01:04<01:29,  9.24it/s]                                                   40%|████      | 552/1380 [01:04<01:29,  9.24it/s][INFO|trainer.py:755] 2023-11-15 21:37:19,856 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:37:19,857 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:37:19,857 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:37:19,858 >>   Batch size = 8
{'eval_loss': 0.4041086733341217, 'eval_accuracy': 0.8439201451905626, 'eval_micro_f1': 0.8439201451905627, 'eval_macro_f1': 0.8383285092286455, 'eval_runtime': 3.8222, 'eval_samples_per_second': 576.626, 'eval_steps_per_second': 72.209, 'epoch': 1.0}
{'loss': 0.2846, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 77.07it/s][A
  6%|▌         | 17/276 [00:00<00:03, 77.44it/s][A
  9%|▉         | 25/276 [00:00<00:03, 74.02it/s][A
 12%|█▏        | 33/276 [00:00<00:03, 73.04it/s][A
 15%|█▍        | 41/276 [00:00<00:03, 71.89it/s][A
 18%|█▊        | 49/276 [00:00<00:03, 72.70it/s][A
 21%|██        | 57/276 [00:00<00:03, 72.66it/s][A
 24%|██▎       | 65/276 [00:00<00:02, 72.39it/s][A
 26%|██▋       | 73/276 [00:00<00:02, 72.63it/s][A
 29%|██▉       | 81/276 [00:01<00:02, 71.72it/s][A
 32%|███▏      | 89/276 [00:01<00:02, 71.84it/s][A
 35%|███▌      | 97/276 [00:01<00:02, 72.76it/s][A
 38%|███▊      | 105/276 [00:01<00:02, 71.92it/s][A
 41%|████      | 113/276 [00:01<00:02, 71.41it/s][A
 44%|████▍     | 121/276 [00:01<00:02, 70.64it/s][A
 47%|████▋     | 129/276 [00:01<00:02, 72.02it/s][A
 50%|████▉     | 137/276 [00:01<00:01, 72.43it/s][A
 53%|█████▎    | 145/276 [00:02<00:01, 71.78it/s][A
 55%|█████▌    | 153/276 [00:02<00:01, 72.27it/s][A
 58%|█████▊    | 161/276 [00:02<00:01, 71.94it/s][A
 61%|██████    | 169/276 [00:02<00:01, 71.33it/s][A
 64%|██████▍   | 177/276 [00:02<00:01, 72.76it/s][A
 67%|██████▋   | 185/276 [00:02<00:01, 71.68it/s][A
 70%|██████▉   | 193/276 [00:02<00:01, 71.12it/s][A
 73%|███████▎  | 201/276 [00:02<00:01, 70.85it/s][A
 76%|███████▌  | 209/276 [00:02<00:00, 72.25it/s][A
 79%|███████▊  | 217/276 [00:03<00:00, 71.23it/s][A
 82%|████████▏ | 225/276 [00:03<00:00, 71.25it/s][A
 84%|████████▍ | 233/276 [00:03<00:00, 71.50it/s][A
 87%|████████▋ | 241/276 [00:03<00:00, 72.05it/s][A
 90%|█████████ | 249/276 [00:03<00:00, 72.32it/s][A
 93%|█████████▎| 257/276 [00:03<00:00, 73.41it/s][A
 96%|█████████▌| 265/276 [00:03<00:00, 71.95it/s][A
 99%|█████████▉| 273/276 [00:03<00:00, 72.28it/s][A                                                  
                                                 [A 40%|████      | 552/1380 [01:08<01:29,  9.24it/s]
100%|██████████| 276/276 [00:03<00:00, 72.28it/s][A
                                                 [A 40%|████      | 553/1380 [01:08<13:46,  1.00it/s] 40%|████      | 554/1380 [01:08<10:44,  1.28it/s] 40%|████      | 555/1380 [01:08<08:19,  1.65it/s] 40%|████      | 556/1380 [01:09<06:27,  2.12it/s] 40%|████      | 557/1380 [01:09<05:05,  2.70it/s] 40%|████      | 558/1380 [01:09<04:04,  3.37it/s] 41%|████      | 559/1380 [01:09<03:19,  4.11it/s] 41%|████      | 560/1380 [01:09<02:47,  4.90it/s] 41%|████      | 561/1380 [01:09<02:25,  5.62it/s] 41%|████      | 562/1380 [01:09<02:08,  6.36it/s] 41%|████      | 563/1380 [01:09<01:56,  7.01it/s] 41%|████      | 564/1380 [01:09<01:49,  7.47it/s] 41%|████      | 565/1380 [01:10<01:43,  7.91it/s] 41%|████      | 566/1380 [01:10<01:38,  8.26it/s] 41%|████      | 567/1380 [01:10<01:35,  8.49it/s] 41%|████      | 568/1380 [01:10<01:33,  8.64it/s] 41%|████      | 569/1380 [01:10<01:32,  8.75it/s] 41%|████▏     | 570/1380 [01:10<01:31,  8.88it/s] 41%|████▏     | 571/1380 [01:10<01:30,  8.94it/s] 41%|████▏     | 572/1380 [01:10<01:30,  8.96it/s] 42%|████▏     | 573/1380 [01:10<01:29,  9.00it/s] 42%|████▏     | 574/1380 [01:11<01:29,  8.99it/s] 42%|████▏     | 575/1380 [01:11<01:29,  8.99it/s] 42%|████▏     | 576/1380 [01:11<01:28,  9.13it/s] 42%|████▏     | 577/1380 [01:11<01:30,  8.90it/s] 42%|████▏     | 578/1380 [01:11<01:29,  8.95it/s] 42%|████▏     | 579/1380 [01:11<01:29,  8.97it/s] 42%|████▏     | 580/1380 [01:11<01:28,  9.01it/s] 42%|████▏     | 581/1380 [01:11<01:28,  9.02it/s] 42%|████▏     | 582/1380 [01:11<01:28,  9.02it/s] 42%|████▏     | 583/1380 [01:12<01:27,  9.06it/s] 42%|████▏     | 584/1380 [01:12<01:28,  9.01it/s] 42%|████▏     | 585/1380 [01:12<01:28,  9.00it/s] 42%|████▏     | 586/1380 [01:12<01:26,  9.18it/s] 43%|████▎     | 587/1380 [01:12<01:27,  9.06it/s] 43%|████▎     | 588/1380 [01:12<01:27,  9.04it/s] 43%|████▎     | 589/1380 [01:12<01:27,  9.03it/s] 43%|████▎     | 590/1380 [01:12<01:27,  9.06it/s] 43%|████▎     | 591/1380 [01:12<01:27,  8.99it/s] 43%|████▎     | 592/1380 [01:13<01:27,  8.99it/s] 43%|████▎     | 593/1380 [01:13<01:27,  9.02it/s] 43%|████▎     | 594/1380 [01:13<01:26,  9.04it/s] 43%|████▎     | 595/1380 [01:13<01:26,  9.03it/s] 43%|████▎     | 596/1380 [01:13<01:25,  9.15it/s] 43%|████▎     | 597/1380 [01:13<01:25,  9.12it/s] 43%|████▎     | 598/1380 [01:13<01:26,  9.06it/s] 43%|████▎     | 599/1380 [01:13<01:27,  8.98it/s] 43%|████▎     | 600/1380 [01:13<01:26,  8.99it/s] 44%|████▎     | 601/1380 [01:14<01:26,  9.01it/s] 44%|████▎     | 602/1380 [01:14<01:26,  8.96it/s] 44%|████▎     | 603/1380 [01:14<01:26,  9.03it/s] 44%|████▍     | 604/1380 [01:14<01:26,  9.02it/s] 44%|████▍     | 605/1380 [01:14<01:26,  8.99it/s] 44%|████▍     | 606/1380 [01:14<01:26,  8.97it/s] 44%|████▍     | 607/1380 [01:14<01:25,  9.00it/s] 44%|████▍     | 608/1380 [01:14<01:26,  8.96it/s] 44%|████▍     | 609/1380 [01:14<01:26,  8.95it/s] 44%|████▍     | 610/1380 [01:15<01:26,  8.90it/s] 44%|████▍     | 611/1380 [01:15<01:26,  8.89it/s] 44%|████▍     | 612/1380 [01:15<01:26,  8.87it/s] 44%|████▍     | 613/1380 [01:15<01:25,  9.01it/s] 44%|████▍     | 614/1380 [01:15<01:25,  8.92it/s] 45%|████▍     | 615/1380 [01:15<01:25,  8.95it/s] 45%|████▍     | 616/1380 [01:15<01:25,  8.94it/s] 45%|████▍     | 617/1380 [01:15<01:24,  9.01it/s] 45%|████▍     | 618/1380 [01:15<01:24,  9.01it/s] 45%|████▍     | 619/1380 [01:16<01:24,  9.00it/s] 45%|████▍     | 620/1380 [01:16<01:24,  8.96it/s] 45%|████▌     | 621/1380 [01:16<01:24,  9.02it/s] 45%|████▌     | 622/1380 [01:16<01:24,  9.02it/s] 45%|████▌     | 623/1380 [01:16<01:22,  9.12it/s] 45%|████▌     | 624/1380 [01:16<01:23,  9.05it/s] 45%|████▌     | 625/1380 [01:16<01:23,  9.05it/s] 45%|████▌     | 626/1380 [01:16<01:24,  8.92it/s] 45%|████▌     | 627/1380 [01:16<01:23,  8.97it/s] 46%|████▌     | 628/1380 [01:17<01:23,  9.04it/s] 46%|████▌     | 629/1380 [01:17<01:23,  9.03it/s] 46%|████▌     | 630/1380 [01:17<01:22,  9.05it/s] 46%|████▌     | 631/1380 [01:17<01:23,  9.01it/s] 46%|████▌     | 632/1380 [01:17<01:24,  8.88it/s] 46%|████▌     | 633/1380 [01:17<01:22,  9.04it/s] 46%|████▌     | 634/1380 [01:17<01:23,  8.97it/s] 46%|████▌     | 635/1380 [01:17<01:23,  8.93it/s] 46%|████▌     | 636/1380 [01:17<01:22,  8.97it/s] 46%|████▌     | 637/1380 [01:18<01:22,  8.99it/s] 46%|████▌     | 638/1380 [01:18<01:22,  8.98it/s] 46%|████▋     | 639/1380 [01:18<01:22,  8.95it/s] 46%|████▋     | 640/1380 [01:18<01:22,  9.02it/s] 46%|████▋     | 641/1380 [01:18<01:22,  8.98it/s] 47%|████▋     | 642/1380 [01:18<01:21,  9.03it/s] 47%|████▋     | 643/1380 [01:18<01:21,  9.07it/s] 47%|████▋     | 644/1380 [01:18<01:21,  9.08it/s] 47%|████▋     | 645/1380 [01:18<01:22,  8.93it/s] 47%|████▋     | 646/1380 [01:19<01:21,  8.99it/s] 47%|████▋     | 647/1380 [01:19<01:21,  8.95it/s] 47%|████▋     | 648/1380 [01:19<01:21,  8.98it/s] 47%|████▋     | 649/1380 [01:19<01:21,  8.98it/s] 47%|████▋     | 650/1380 [01:19<01:20,  9.11it/s] 47%|████▋     | 651/1380 [01:19<01:20,  9.08it/s] 47%|████▋     | 652/1380 [01:19<01:20,  9.05it/s] 47%|████▋     | 653/1380 [01:19<01:19,  9.09it/s] 47%|████▋     | 654/1380 [01:19<01:20,  9.05it/s] 47%|████▋     | 655/1380 [01:20<01:20,  9.02it/s] 48%|████▊     | 656/1380 [01:20<01:20,  8.97it/s] 48%|████▊     | 657/1380 [01:20<01:20,  8.97it/s] 48%|████▊     | 658/1380 [01:20<01:20,  8.98it/s] 48%|████▊     | 659/1380 [01:20<01:20,  9.01it/s] 48%|████▊     | 660/1380 [01:20<01:18,  9.12it/s] 48%|████▊     | 661/1380 [01:20<01:19,  9.06it/s] 48%|████▊     | 662/1380 [01:20<01:19,  8.98it/s] 48%|████▊     | 663/1380 [01:20<01:19,  9.05it/s] 48%|████▊     | 664/1380 [01:21<01:18,  9.07it/s] 48%|████▊     | 665/1380 [01:21<01:19,  9.01it/s] 48%|████▊     | 666/1380 [01:21<01:18,  9.05it/s] 48%|████▊     | 667/1380 [01:21<01:19,  8.99it/s] 48%|████▊     | 668/1380 [01:21<01:19,  8.99it/s] 48%|████▊     | 669/1380 [01:21<01:19,  8.99it/s] 49%|████▊     | 670/1380 [01:21<01:17,  9.12it/s] 49%|████▊     | 671/1380 [01:21<01:18,  9.06it/s] 49%|████▊     | 672/1380 [01:21<01:18,  8.98it/s] 49%|████▉     | 673/1380 [01:22<01:18,  9.06it/s] 49%|████▉     | 674/1380 [01:22<01:18,  9.04it/s] 49%|████▉     | 675/1380 [01:22<01:18,  9.01it/s] 49%|████▉     | 676/1380 [01:22<01:18,  9.00it/s] 49%|████▉     | 677/1380 [01:22<01:17,  9.08it/s] 49%|████▉     | 678/1380 [01:22<01:17,  9.02it/s] 49%|████▉     | 679/1380 [01:22<01:17,  9.07it/s] 49%|████▉     | 680/1380 [01:22<01:16,  9.15it/s] 49%|████▉     | 681/1380 [01:22<01:16,  9.10it/s] 49%|████▉     | 682/1380 [01:23<01:17,  9.00it/s] 49%|████▉     | 683/1380 [01:23<01:17,  9.05it/s] 50%|████▉     | 684/1380 [01:23<01:16,  9.05it/s] 50%|████▉     | 685/1380 [01:23<01:16,  9.03it/s] 50%|████▉     | 686/1380 [01:23<01:17,  9.00it/s] 50%|████▉     | 687/1380 [01:23<01:16,  9.02it/s] 50%|████▉     | 688/1380 [01:23<01:17,  8.97it/s] 50%|████▉     | 689/1380 [01:23<01:16,  9.00it/s] 50%|█████     | 690/1380 [01:23<01:15,  9.13it/s] 50%|█████     | 691/1380 [01:24<01:15,  9.07it/s] 50%|█████     | 692/1380 [01:24<01:15,  9.08it/s] 50%|█████     | 693/1380 [01:24<01:15,  9.09it/s] 50%|█████     | 694/1380 [01:24<01:15,  9.06it/s] 50%|█████     | 695/1380 [01:24<01:15,  9.01it/s] 50%|█████     | 696/1380 [01:24<01:15,  9.09it/s] 51%|█████     | 697/1380 [01:24<01:15,  9.03it/s] 51%|█████     | 698/1380 [01:24<01:15,  9.03it/s] 51%|█████     | 699/1380 [01:24<01:15,  9.02it/s] 51%|█████     | 700/1380 [01:25<01:14,  9.08it/s] 51%|█████     | 701/1380 [01:25<01:15,  9.00it/s] 51%|█████     | 702/1380 [01:25<01:15,  9.02it/s] 51%|█████     | 703/1380 [01:25<01:15,  9.02it/s] 51%|█████     | 704/1380 [01:25<01:14,  9.05it/s] 51%|█████     | 705/1380 [01:25<01:14,  9.05it/s] 51%|█████     | 706/1380 [01:25<01:14,  9.03it/s] 51%|█████     | 707/1380 [01:25<01:14,  9.05it/s] 51%|█████▏    | 708/1380 [01:25<01:14,  9.06it/s] 51%|█████▏    | 709/1380 [01:26<01:14,  9.02it/s] 51%|█████▏    | 710/1380 [01:26<01:13,  9.08it/s] 52%|█████▏    | 711/1380 [01:26<01:13,  9.10it/s] 52%|█████▏    | 712/1380 [01:26<01:14,  9.00it/s] 52%|█████▏    | 713/1380 [01:26<01:13,  9.08it/s] 52%|█████▏    | 714/1380 [01:26<01:13,  9.10it/s] 52%|█████▏    | 715/1380 [01:26<01:13,  9.01it/s] 52%|█████▏    | 716/1380 [01:26<01:13,  9.01it/s] 52%|█████▏    | 717/1380 [01:26<01:13,  8.99it/s] 52%|█████▏    | 718/1380 [01:27<01:14,  8.93it/s] 52%|█████▏    | 719/1380 [01:27<01:13,  8.98it/s] 52%|█████▏    | 720/1380 [01:27<01:13,  9.01it/s] 52%|█████▏    | 721/1380 [01:27<01:13,  9.03it/s] 52%|█████▏    | 722/1380 [01:27<01:12,  9.04it/s] 52%|█████▏    | 723/1380 [01:27<01:11,  9.13it/s] 52%|█████▏    | 724/1380 [01:27<01:12,  9.08it/s] 53%|█████▎    | 725/1380 [01:27<01:12,  9.05it/s] 53%|█████▎    | 726/1380 [01:27<01:12,  9.02it/s] 53%|█████▎    | 727/1380 [01:27<01:12,  9.03it/s] 53%|█████▎    | 728/1380 [01:28<01:12,  9.01it/s] 53%|█████▎    | 729/1380 [01:28<01:12,  9.01it/s] 53%|█████▎    | 730/1380 [01:28<01:11,  9.03it/s] 53%|█████▎    | 731/1380 [01:28<01:11,  9.02it/s] 53%|█████▎    | 732/1380 [01:28<01:12,  8.99it/s] 53%|█████▎    | 733/1380 [01:28<01:11,  9.05it/s] 53%|█████▎    | 734/1380 [01:28<01:12,  8.96it/s] 53%|█████▎    | 735/1380 [01:28<01:11,  9.04it/s] 53%|█████▎    | 736/1380 [01:28<01:12,  8.94it/s] 53%|█████▎    | 737/1380 [01:29<01:11,  9.02it/s] 53%|█████▎    | 738/1380 [01:29<01:11,  9.04it/s] 54%|█████▎    | 739/1380 [01:29<01:10,  9.05it/s] 54%|█████▎    | 740/1380 [01:29<01:10,  9.04it/s] 54%|█████▎    | 741/1380 [01:29<01:11,  8.97it/s] 54%|█████▍    | 742/1380 [01:29<01:10,  9.00it/s] 54%|█████▍    | 743/1380 [01:29<01:10,  9.08it/s] 54%|█████▍    | 744/1380 [01:29<01:10,  9.00it/s] 54%|█████▍    | 745/1380 [01:29<01:10,  9.05it/s] 54%|█████▍    | 746/1380 [01:30<01:10,  9.03it/s] 54%|█████▍    | 747/1380 [01:30<01:10,  9.03it/s] 54%|█████▍    | 748/1380 [01:30<01:10,  8.98it/s] 54%|█████▍    | 749/1380 [01:30<01:10,  8.93it/s] 54%|█████▍    | 750/1380 [01:30<01:10,  8.94it/s] 54%|█████▍    | 751/1380 [01:30<01:10,  8.91it/s] 54%|█████▍    | 752/1380 [01:30<01:09,  8.99it/s] 55%|█████▍    | 753/1380 [01:30<01:08,  9.10it/s] 55%|█████▍    | 754/1380 [01:30<01:09,  9.03it/s] 55%|█████▍    | 755/1380 [01:31<01:09,  9.01it/s] 55%|█████▍    | 756/1380 [01:31<01:09,  9.01it/s] 55%|█████▍    | 757/1380 [01:31<01:09,  8.98it/s] 55%|█████▍    | 758/1380 [01:31<01:09,  8.96it/s] 55%|█████▌    | 759/1380 [01:31<01:08,  9.02it/s] 55%|█████▌    | 760/1380 [01:31<01:08,  9.01it/s] 55%|█████▌    | 761/1380 [01:31<01:08,  8.99it/s] 55%|█████▌    | 762/1380 [01:31<01:08,  9.02it/s] 55%|█████▌    | 763/1380 [01:31<01:07,  9.10it/s] 55%|█████▌    | 764/1380 [01:32<01:08,  8.98it/s] 55%|█████▌    | 765/1380 [01:32<01:08,  9.00it/s] 56%|█████▌    | 766/1380 [01:32<01:08,  9.00it/s] 56%|█████▌    | 767/1380 [01:32<01:07,  9.05it/s] 56%|█████▌    | 768/1380 [01:32<01:07,  9.01it/s] 56%|█████▌    | 769/1380 [01:32<01:07,  9.02it/s] 56%|█████▌    | 770/1380 [01:32<01:08,  8.93it/s] 56%|█████▌    | 771/1380 [01:32<01:07,  8.96it/s] 56%|█████▌    | 772/1380 [01:32<01:07,  8.96it/s] 56%|█████▌    | 773/1380 [01:33<01:07,  8.99it/s] 56%|█████▌    | 774/1380 [01:33<01:07,  8.94it/s] 56%|█████▌    | 775/1380 [01:33<01:08,  8.89it/s] 56%|█████▌    | 776/1380 [01:33<01:07,  8.99it/s] 56%|█████▋    | 777/1380 [01:33<01:06,  9.03it/s] 56%|█████▋    | 778/1380 [01:33<01:06,  9.02it/s] 56%|█████▋    | 779/1380 [01:33<01:06,  9.03it/s] 57%|█████▋    | 780/1380 [01:33<01:06,  8.98it/s] 57%|█████▋    | 781/1380 [01:33<01:06,  8.96it/s] 57%|█████▋    | 782/1380 [01:34<01:06,  8.94it/s] 57%|█████▋    | 783/1380 [01:34<01:05,  9.06it/s] 57%|█████▋    | 784/1380 [01:34<01:05,  9.07it/s] 57%|█████▋    | 785/1380 [01:34<01:05,  9.07it/s] 57%|█████▋    | 786/1380 [01:34<01:05,  9.08it/s] 57%|█████▋    | 787/1380 [01:34<01:05,  9.11it/s] 57%|█████▋    | 788/1380 [01:34<01:05,  8.98it/s] 57%|█████▋    | 789/1380 [01:34<01:05,  9.02it/s] 57%|█████▋    | 790/1380 [01:34<01:05,  8.99it/s] 57%|█████▋    | 791/1380 [01:35<01:05,  9.00it/s] 57%|█████▋    | 792/1380 [01:35<01:05,  8.97it/s] 57%|█████▋    | 793/1380 [01:35<01:04,  9.08it/s] 58%|█████▊    | 794/1380 [01:35<01:05,  8.97it/s] 58%|█████▊    | 795/1380 [01:35<01:04,  9.02it/s] 58%|█████▊    | 796/1380 [01:35<01:04,  9.05it/s] 58%|█████▊    | 797/1380 [01:35<01:04,  9.05it/s] 58%|█████▊    | 798/1380 [01:35<01:04,  9.01it/s] 58%|█████▊    | 799/1380 [01:35<01:04,  9.03it/s] 58%|█████▊    | 800/1380 [01:36<01:03,  9.08it/s] 58%|█████▊    | 801/1380 [01:36<01:03,  9.06it/s] 58%|█████▊    | 802/1380 [01:36<01:03,  9.04it/s] 58%|█████▊    | 803/1380 [01:36<01:03,  9.13it/s] 58%|█████▊    | 804/1380 [01:36<01:03,  9.09it/s] 58%|█████▊    | 805/1380 [01:36<01:03,  9.01it/s] 58%|█████▊    | 806/1380 [01:36<01:03,  9.06it/s] 58%|█████▊    | 807/1380 [01:36<01:03,  9.01it/s] 59%|█████▊    | 808/1380 [01:36<01:03,  9.05it/s] 59%|█████▊    | 809/1380 [01:37<01:02,  9.07it/s] 59%|█████▊    | 810/1380 [01:37<01:03,  9.04it/s] 59%|█████▉    | 811/1380 [01:37<01:03,  8.97it/s] 59%|█████▉    | 812/1380 [01:37<01:03,  8.98it/s] 59%|█████▉    | 813/1380 [01:37<01:03,  8.98it/s] 59%|█████▉    | 814/1380 [01:37<01:02,  9.05it/s] 59%|█████▉    | 815/1380 [01:37<01:02,  9.05it/s] 59%|█████▉    | 816/1380 [01:37<01:01,  9.11it/s] 59%|█████▉    | 817/1380 [01:37<01:01,  9.08it/s] 59%|█████▉    | 818/1380 [01:38<01:02,  9.06it/s] 59%|█████▉    | 819/1380 [01:38<01:01,  9.11it/s] 59%|█████▉    | 820/1380 [01:38<01:01,  9.11it/s] 59%|█████▉    | 821/1380 [01:38<01:01,  9.05it/s] 60%|█████▉    | 822/1380 [01:38<01:01,  9.04it/s] 60%|█████▉    | 823/1380 [01:38<01:01,  9.12it/s] 60%|█████▉    | 824/1380 [01:38<01:01,  9.09it/s] 60%|█████▉    | 825/1380 [01:38<01:01,  9.08it/s] 60%|█████▉    | 826/1380 [01:38<01:00,  9.10it/s] 60%|█████▉    | 827/1380 [01:39<01:00,  9.15it/s]                                                   60%|██████    | 828/1380 [01:39<01:00,  9.15it/s][INFO|trainer.py:755] 2023-11-15 21:37:54,306 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:37:54,308 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:37:54,308 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:37:54,309 >>   Batch size = 8
{'eval_loss': 0.38797831535339355, 'eval_accuracy': 0.8561705989110708, 'eval_micro_f1': 0.8561705989110708, 'eval_macro_f1': 0.847566668613475, 'eval_runtime': 3.8855, 'eval_samples_per_second': 567.237, 'eval_steps_per_second': 71.033, 'epoch': 2.0}
{'loss': 0.1878, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 8/276 [00:00<00:03, 79.62it/s][A
  6%|▌         | 16/276 [00:00<00:03, 73.96it/s][A
  9%|▊         | 24/276 [00:00<00:03, 73.39it/s][A
 12%|█▏        | 32/276 [00:00<00:03, 71.36it/s][A
 14%|█▍        | 40/276 [00:00<00:03, 72.58it/s][A
 17%|█▋        | 48/276 [00:00<00:03, 70.30it/s][A
 20%|██        | 56/276 [00:00<00:03, 70.05it/s][A
 23%|██▎       | 64/276 [00:00<00:02, 71.51it/s][A
 26%|██▌       | 72/276 [00:01<00:02, 70.25it/s][A
 29%|██▉       | 80/276 [00:01<00:02, 69.44it/s][A
 32%|███▏      | 87/276 [00:01<00:02, 69.47it/s][A
 34%|███▍      | 95/276 [00:01<00:02, 69.80it/s][A
 37%|███▋      | 103/276 [00:01<00:02, 69.65it/s][A
 40%|████      | 111/276 [00:01<00:02, 70.65it/s][A
 43%|████▎     | 119/276 [00:01<00:02, 70.21it/s][A
 46%|████▌     | 127/276 [00:01<00:02, 70.60it/s][A
 49%|████▉     | 135/276 [00:01<00:02, 70.24it/s][A
 52%|█████▏    | 143/276 [00:02<00:01, 71.42it/s][A
 55%|█████▍    | 151/276 [00:02<00:01, 69.92it/s][A
 58%|█████▊    | 159/276 [00:02<00:01, 69.22it/s][A
 60%|██████    | 166/276 [00:02<00:01, 68.75it/s][A
 63%|██████▎   | 174/276 [00:02<00:01, 70.41it/s][A
 66%|██████▌   | 182/276 [00:02<00:01, 68.85it/s][A
 68%|██████▊   | 189/276 [00:02<00:01, 68.90it/s][A
 71%|███████▏  | 197/276 [00:02<00:01, 69.14it/s][A
 74%|███████▍  | 205/276 [00:02<00:01, 69.54it/s][A
 77%|███████▋  | 212/276 [00:03<00:00, 69.42it/s][A
 80%|███████▉  | 220/276 [00:03<00:00, 69.98it/s][A
 82%|████████▏ | 227/276 [00:03<00:00, 69.87it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 68.79it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 69.41it/s][A
 90%|█████████ | 249/276 [00:03<00:00, 69.33it/s][A
 93%|█████████▎| 256/276 [00:03<00:00, 69.34it/s][A
 95%|█████████▌| 263/276 [00:03<00:00, 68.61it/s][A
 98%|█████████▊| 271/276 [00:03<00:00, 70.19it/s][A                                                  
                                                 [A 60%|██████    | 828/1380 [01:43<01:00,  9.15it/s]
100%|██████████| 276/276 [00:03<00:00, 70.19it/s][A
                                                 [A 60%|██████    | 829/1380 [01:43<09:26,  1.03s/it] 60%|██████    | 830/1380 [01:43<07:20,  1.25it/s] 60%|██████    | 831/1380 [01:43<05:40,  1.61it/s] 60%|██████    | 832/1380 [01:43<04:24,  2.07it/s] 60%|██████    | 833/1380 [01:43<03:27,  2.64it/s] 60%|██████    | 834/1380 [01:43<02:45,  3.31it/s] 61%|██████    | 835/1380 [01:43<02:14,  4.05it/s] 61%|██████    | 836/1380 [01:44<01:52,  4.83it/s] 61%|██████    | 837/1380 [01:44<01:36,  5.63it/s] 61%|██████    | 838/1380 [01:44<01:25,  6.32it/s] 61%|██████    | 839/1380 [01:44<01:17,  6.94it/s] 61%|██████    | 840/1380 [01:44<01:12,  7.47it/s] 61%|██████    | 841/1380 [01:44<01:08,  7.86it/s] 61%|██████    | 842/1380 [01:44<01:05,  8.16it/s] 61%|██████    | 843/1380 [01:44<01:04,  8.38it/s] 61%|██████    | 844/1380 [01:44<01:02,  8.64it/s] 61%|██████    | 845/1380 [01:45<01:01,  8.69it/s] 61%|██████▏   | 846/1380 [01:45<01:00,  8.81it/s] 61%|██████▏   | 847/1380 [01:45<01:00,  8.85it/s] 61%|██████▏   | 848/1380 [01:45<00:59,  8.90it/s] 62%|██████▏   | 849/1380 [01:45<00:59,  8.89it/s] 62%|██████▏   | 850/1380 [01:45<00:59,  8.98it/s] 62%|██████▏   | 851/1380 [01:45<00:59,  8.86it/s] 62%|██████▏   | 852/1380 [01:45<00:59,  8.89it/s] 62%|██████▏   | 853/1380 [01:45<00:59,  8.92it/s] 62%|██████▏   | 854/1380 [01:46<00:58,  9.03it/s] 62%|██████▏   | 855/1380 [01:46<00:58,  8.97it/s] 62%|██████▏   | 856/1380 [01:46<00:58,  8.95it/s] 62%|██████▏   | 857/1380 [01:46<00:58,  8.90it/s] 62%|██████▏   | 858/1380 [01:46<00:58,  8.93it/s] 62%|██████▏   | 859/1380 [01:46<00:58,  8.96it/s] 62%|██████▏   | 860/1380 [01:46<00:58,  8.88it/s] 62%|██████▏   | 861/1380 [01:46<00:58,  8.94it/s] 62%|██████▏   | 862/1380 [01:46<00:57,  8.93it/s] 63%|██████▎   | 863/1380 [01:47<00:57,  8.95it/s] 63%|██████▎   | 864/1380 [01:47<00:56,  9.08it/s] 63%|██████▎   | 865/1380 [01:47<00:57,  9.01it/s] 63%|██████▎   | 866/1380 [01:47<00:56,  9.04it/s] 63%|██████▎   | 867/1380 [01:47<00:56,  9.00it/s] 63%|██████▎   | 868/1380 [01:47<00:56,  8.99it/s] 63%|██████▎   | 869/1380 [01:47<00:56,  8.98it/s] 63%|██████▎   | 870/1380 [01:47<00:56,  8.96it/s] 63%|██████▎   | 871/1380 [01:47<00:56,  9.02it/s] 63%|██████▎   | 872/1380 [01:48<00:56,  8.97it/s] 63%|██████▎   | 873/1380 [01:48<00:56,  8.94it/s] 63%|██████▎   | 874/1380 [01:48<00:55,  9.09it/s] 63%|██████▎   | 875/1380 [01:48<00:55,  9.03it/s] 63%|██████▎   | 876/1380 [01:48<00:55,  9.04it/s] 64%|██████▎   | 877/1380 [01:48<00:55,  9.01it/s] 64%|██████▎   | 878/1380 [01:48<00:56,  8.93it/s] 64%|██████▎   | 879/1380 [01:48<00:56,  8.92it/s] 64%|██████▍   | 880/1380 [01:48<00:56,  8.90it/s] 64%|██████▍   | 881/1380 [01:49<00:55,  8.99it/s] 64%|██████▍   | 882/1380 [01:49<00:55,  8.98it/s] 64%|██████▍   | 883/1380 [01:49<00:55,  8.97it/s] 64%|██████▍   | 884/1380 [01:49<00:55,  9.01it/s] 64%|██████▍   | 885/1380 [01:49<00:54,  9.06it/s] 64%|██████▍   | 886/1380 [01:49<00:54,  9.02it/s] 64%|██████▍   | 887/1380 [01:49<00:54,  9.06it/s] 64%|██████▍   | 888/1380 [01:49<00:54,  9.01it/s] 64%|██████▍   | 889/1380 [01:49<00:54,  8.97it/s] 64%|██████▍   | 890/1380 [01:50<00:54,  9.01it/s] 65%|██████▍   | 891/1380 [01:50<00:53,  9.09it/s] 65%|██████▍   | 892/1380 [01:50<00:54,  9.02it/s] 65%|██████▍   | 893/1380 [01:50<00:54,  8.99it/s] 65%|██████▍   | 894/1380 [01:50<00:54,  8.93it/s] 65%|██████▍   | 895/1380 [01:50<00:54,  8.92it/s] 65%|██████▍   | 896/1380 [01:50<00:54,  8.88it/s] 65%|██████▌   | 897/1380 [01:50<00:53,  8.96it/s] 65%|██████▌   | 898/1380 [01:50<00:54,  8.91it/s] 65%|██████▌   | 899/1380 [01:51<00:53,  8.94it/s] 65%|██████▌   | 900/1380 [01:51<00:53,  8.97it/s] 65%|██████▌   | 901/1380 [01:51<00:53,  9.03it/s] 65%|██████▌   | 902/1380 [01:51<00:53,  8.95it/s] 65%|██████▌   | 903/1380 [01:51<00:52,  9.00it/s] 66%|██████▌   | 904/1380 [01:51<00:53,  8.88it/s] 66%|██████▌   | 905/1380 [01:51<00:52,  8.98it/s] 66%|██████▌   | 906/1380 [01:51<00:52,  9.01it/s] 66%|██████▌   | 907/1380 [01:51<00:52,  9.01it/s] 66%|██████▌   | 908/1380 [01:52<00:52,  8.97it/s] 66%|██████▌   | 909/1380 [01:52<00:52,  8.99it/s] 66%|██████▌   | 910/1380 [01:52<00:52,  8.91it/s] 66%|██████▌   | 911/1380 [01:52<00:51,  9.04it/s] 66%|██████▌   | 912/1380 [01:52<00:52,  9.00it/s] 66%|██████▌   | 913/1380 [01:52<00:51,  8.99it/s] 66%|██████▌   | 914/1380 [01:52<00:51,  8.97it/s] 66%|██████▋   | 915/1380 [01:52<00:52,  8.92it/s] 66%|██████▋   | 916/1380 [01:52<00:51,  8.96it/s] 66%|██████▋   | 917/1380 [01:53<00:51,  8.92it/s] 67%|██████▋   | 918/1380 [01:53<00:51,  9.02it/s] 67%|██████▋   | 919/1380 [01:53<00:51,  9.00it/s] 67%|██████▋   | 920/1380 [01:53<00:51,  8.95it/s] 67%|██████▋   | 921/1380 [01:53<00:50,  9.02it/s] 67%|██████▋   | 922/1380 [01:53<00:50,  9.03it/s] 67%|██████▋   | 923/1380 [01:53<00:51,  8.95it/s] 67%|██████▋   | 924/1380 [01:53<00:50,  8.98it/s] 67%|██████▋   | 925/1380 [01:53<00:50,  8.96it/s] 67%|██████▋   | 926/1380 [01:54<00:50,  8.95it/s] 67%|██████▋   | 927/1380 [01:54<00:50,  8.97it/s] 67%|██████▋   | 928/1380 [01:54<00:49,  9.08it/s] 67%|██████▋   | 929/1380 [01:54<00:50,  8.93it/s] 67%|██████▋   | 930/1380 [01:54<00:50,  8.99it/s] 67%|██████▋   | 931/1380 [01:54<00:50,  8.91it/s] 68%|██████▊   | 932/1380 [01:54<00:50,  8.93it/s] 68%|██████▊   | 933/1380 [01:54<00:49,  8.99it/s] 68%|██████▊   | 934/1380 [01:54<00:50,  8.92it/s] 68%|██████▊   | 935/1380 [01:55<00:49,  9.01it/s] 68%|██████▊   | 936/1380 [01:55<00:49,  9.00it/s] 68%|██████▊   | 937/1380 [01:55<00:49,  9.02it/s] 68%|██████▊   | 938/1380 [01:55<00:48,  9.06it/s] 68%|██████▊   | 939/1380 [01:55<00:48,  9.03it/s] 68%|██████▊   | 940/1380 [01:55<00:49,  8.92it/s] 68%|██████▊   | 941/1380 [01:55<00:49,  8.96it/s] 68%|██████▊   | 942/1380 [01:55<00:48,  8.95it/s] 68%|██████▊   | 943/1380 [01:55<00:49,  8.91it/s] 68%|██████▊   | 944/1380 [01:56<00:48,  8.94it/s] 68%|██████▊   | 945/1380 [01:56<00:48,  9.00it/s] 69%|██████▊   | 946/1380 [01:56<00:48,  8.86it/s] 69%|██████▊   | 947/1380 [01:56<00:48,  8.88it/s] 69%|██████▊   | 948/1380 [01:56<00:48,  8.87it/s] 69%|██████▉   | 949/1380 [01:56<00:48,  8.89it/s] 69%|██████▉   | 950/1380 [01:56<00:48,  8.85it/s] 69%|██████▉   | 951/1380 [01:56<00:48,  8.85it/s] 69%|██████▉   | 952/1380 [01:56<00:48,  8.85it/s] 69%|██████▉   | 953/1380 [01:57<00:48,  8.82it/s] 69%|██████▉   | 954/1380 [01:57<00:47,  8.89it/s] 69%|██████▉   | 955/1380 [01:57<00:47,  8.99it/s] 69%|██████▉   | 956/1380 [01:57<00:47,  8.98it/s] 69%|██████▉   | 957/1380 [01:57<00:47,  8.94it/s] 69%|██████▉   | 958/1380 [01:57<00:47,  8.91it/s] 69%|██████▉   | 959/1380 [01:57<00:47,  8.94it/s] 70%|██████▉   | 960/1380 [01:57<00:47,  8.91it/s] 70%|██████▉   | 961/1380 [01:57<00:47,  8.85it/s] 70%|██████▉   | 962/1380 [01:58<00:46,  8.94it/s] 70%|██████▉   | 963/1380 [01:58<00:46,  8.90it/s] 70%|██████▉   | 964/1380 [01:58<00:47,  8.82it/s] 70%|██████▉   | 965/1380 [01:58<00:46,  8.95it/s] 70%|███████   | 966/1380 [01:58<00:46,  8.91it/s] 70%|███████   | 967/1380 [01:58<00:46,  8.91it/s] 70%|███████   | 968/1380 [01:58<00:46,  8.90it/s] 70%|███████   | 969/1380 [01:58<00:46,  8.89it/s] 70%|███████   | 970/1380 [01:59<00:46,  8.87it/s] 70%|███████   | 971/1380 [01:59<00:46,  8.84it/s] 70%|███████   | 972/1380 [01:59<00:45,  8.91it/s] 71%|███████   | 973/1380 [01:59<00:45,  8.91it/s] 71%|███████   | 974/1380 [01:59<00:45,  8.93it/s] 71%|███████   | 975/1380 [01:59<00:45,  8.98it/s] 71%|███████   | 976/1380 [01:59<00:45,  8.94it/s] 71%|███████   | 977/1380 [01:59<00:45,  8.93it/s] 71%|███████   | 978/1380 [01:59<00:45,  8.93it/s] 71%|███████   | 979/1380 [02:00<00:45,  8.88it/s] 71%|███████   | 980/1380 [02:00<00:45,  8.86it/s] 71%|███████   | 981/1380 [02:00<00:44,  8.87it/s] 71%|███████   | 982/1380 [02:00<00:44,  9.01it/s] 71%|███████   | 983/1380 [02:00<00:44,  8.99it/s] 71%|███████▏  | 984/1380 [02:00<00:44,  8.97it/s] 71%|███████▏  | 985/1380 [02:00<00:44,  8.91it/s] 71%|███████▏  | 986/1380 [02:00<00:43,  8.97it/s] 72%|███████▏  | 987/1380 [02:00<00:43,  8.95it/s] 72%|███████▏  | 988/1380 [02:01<00:44,  8.89it/s] 72%|███████▏  | 989/1380 [02:01<00:43,  8.98it/s] 72%|███████▏  | 990/1380 [02:01<00:43,  8.88it/s] 72%|███████▏  | 991/1380 [02:01<00:44,  8.81it/s] 72%|███████▏  | 992/1380 [02:01<00:43,  8.85it/s] 72%|███████▏  | 993/1380 [02:01<00:43,  8.83it/s] 72%|███████▏  | 994/1380 [02:01<00:43,  8.78it/s] 72%|███████▏  | 995/1380 [02:01<00:43,  8.80it/s] 72%|███████▏  | 996/1380 [02:01<00:43,  8.79it/s] 72%|███████▏  | 997/1380 [02:02<00:43,  8.85it/s] 72%|███████▏  | 998/1380 [02:02<00:43,  8.84it/s] 72%|███████▏  | 999/1380 [02:02<00:42,  8.97it/s] 72%|███████▏  | 1000/1380 [02:02<00:43,  8.82it/s] 73%|███████▎  | 1001/1380 [02:02<00:43,  8.80it/s] 73%|███████▎  | 1002/1380 [02:02<00:42,  8.87it/s] 73%|███████▎  | 1003/1380 [02:02<00:42,  8.88it/s] 73%|███████▎  | 1004/1380 [02:02<00:42,  8.89it/s] 73%|███████▎  | 1005/1380 [02:02<00:42,  8.91it/s] 73%|███████▎  | 1006/1380 [02:03<00:42,  8.86it/s] 73%|███████▎  | 1007/1380 [02:03<00:42,  8.83it/s] 73%|███████▎  | 1008/1380 [02:03<00:41,  8.87it/s] 73%|███████▎  | 1009/1380 [02:03<00:41,  8.94it/s] 73%|███████▎  | 1010/1380 [02:03<00:41,  8.94it/s] 73%|███████▎  | 1011/1380 [02:03<00:41,  8.91it/s] 73%|███████▎  | 1012/1380 [02:03<00:41,  8.86it/s] 73%|███████▎  | 1013/1380 [02:03<00:41,  8.89it/s] 73%|███████▎  | 1014/1380 [02:03<00:40,  8.95it/s] 74%|███████▎  | 1015/1380 [02:04<00:40,  8.97it/s] 74%|███████▎  | 1016/1380 [02:04<00:40,  9.00it/s] 74%|███████▎  | 1017/1380 [02:04<00:40,  8.87it/s] 74%|███████▍  | 1018/1380 [02:04<00:40,  8.85it/s] 74%|███████▍  | 1019/1380 [02:04<00:40,  8.91it/s] 74%|███████▍  | 1020/1380 [02:04<00:40,  8.92it/s] 74%|███████▍  | 1021/1380 [02:04<00:40,  8.91it/s] 74%|███████▍  | 1022/1380 [02:04<00:40,  8.83it/s] 74%|███████▍  | 1023/1380 [02:04<00:40,  8.89it/s] 74%|███████▍  | 1024/1380 [02:05<00:40,  8.88it/s] 74%|███████▍  | 1025/1380 [02:05<00:39,  8.88it/s] 74%|███████▍  | 1026/1380 [02:05<00:39,  8.90it/s] 74%|███████▍  | 1027/1380 [02:05<00:39,  8.86it/s] 74%|███████▍  | 1028/1380 [02:05<00:39,  8.86it/s] 75%|███████▍  | 1029/1380 [02:05<00:39,  8.82it/s] 75%|███████▍  | 1030/1380 [02:05<00:39,  8.90it/s] 75%|███████▍  | 1031/1380 [02:05<00:39,  8.90it/s] 75%|███████▍  | 1032/1380 [02:05<00:39,  8.85it/s] 75%|███████▍  | 1033/1380 [02:06<00:38,  8.99it/s] 75%|███████▍  | 1034/1380 [02:06<00:39,  8.83it/s] 75%|███████▌  | 1035/1380 [02:06<00:38,  8.89it/s] 75%|███████▌  | 1036/1380 [02:06<00:38,  8.97it/s] 75%|███████▌  | 1037/1380 [02:06<00:38,  8.99it/s] 75%|███████▌  | 1038/1380 [02:06<00:38,  8.98it/s] 75%|███████▌  | 1039/1380 [02:06<00:38,  8.84it/s] 75%|███████▌  | 1040/1380 [02:06<00:38,  8.85it/s] 75%|███████▌  | 1041/1380 [02:06<00:38,  8.85it/s] 76%|███████▌  | 1042/1380 [02:07<00:38,  8.84it/s] 76%|███████▌  | 1043/1380 [02:07<00:37,  8.97it/s] 76%|███████▌  | 1044/1380 [02:07<00:37,  8.98it/s] 76%|███████▌  | 1045/1380 [02:07<00:37,  8.93it/s] 76%|███████▌  | 1046/1380 [02:07<00:37,  8.84it/s] 76%|███████▌  | 1047/1380 [02:07<00:37,  8.93it/s] 76%|███████▌  | 1048/1380 [02:07<00:37,  8.94it/s] 76%|███████▌  | 1049/1380 [02:07<00:37,  8.86it/s] 76%|███████▌  | 1050/1380 [02:07<00:36,  8.95it/s] 76%|███████▌  | 1051/1380 [02:08<00:36,  8.92it/s] 76%|███████▌  | 1052/1380 [02:08<00:36,  8.90it/s] 76%|███████▋  | 1053/1380 [02:08<00:36,  8.96it/s] 76%|███████▋  | 1054/1380 [02:08<00:36,  8.93it/s] 76%|███████▋  | 1055/1380 [02:08<00:36,  8.93it/s] 77%|███████▋  | 1056/1380 [02:08<00:36,  8.91it/s] 77%|███████▋  | 1057/1380 [02:08<00:36,  8.87it/s] 77%|███████▋  | 1058/1380 [02:08<00:36,  8.83it/s] 77%|███████▋  | 1059/1380 [02:09<00:36,  8.87it/s] 77%|███████▋  | 1060/1380 [02:09<00:35,  8.93it/s] 77%|███████▋  | 1061/1380 [02:09<00:36,  8.86it/s] 77%|███████▋  | 1062/1380 [02:09<00:36,  8.76it/s] 77%|███████▋  | 1063/1380 [02:09<00:36,  8.76it/s] 77%|███████▋  | 1064/1380 [02:09<00:35,  8.83it/s] 77%|███████▋  | 1065/1380 [02:09<00:35,  8.83it/s] 77%|███████▋  | 1066/1380 [02:09<00:36,  8.71it/s] 77%|███████▋  | 1067/1380 [02:09<00:35,  8.81it/s] 77%|███████▋  | 1068/1380 [02:10<00:35,  8.80it/s] 77%|███████▋  | 1069/1380 [02:10<00:35,  8.79it/s] 78%|███████▊  | 1070/1380 [02:10<00:35,  8.84it/s] 78%|███████▊  | 1071/1380 [02:10<00:35,  8.82it/s] 78%|███████▊  | 1072/1380 [02:10<00:35,  8.79it/s] 78%|███████▊  | 1073/1380 [02:10<00:34,  8.79it/s] 78%|███████▊  | 1074/1380 [02:10<00:34,  8.79it/s] 78%|███████▊  | 1075/1380 [02:10<00:34,  8.84it/s] 78%|███████▊  | 1076/1380 [02:10<00:34,  8.76it/s] 78%|███████▊  | 1077/1380 [02:11<00:34,  8.88it/s] 78%|███████▊  | 1078/1380 [02:11<00:34,  8.83it/s] 78%|███████▊  | 1079/1380 [02:11<00:34,  8.80it/s] 78%|███████▊  | 1080/1380 [02:11<00:33,  8.89it/s] 78%|███████▊  | 1081/1380 [02:11<00:33,  8.89it/s] 78%|███████▊  | 1082/1380 [02:11<00:33,  8.78it/s] 78%|███████▊  | 1083/1380 [02:11<00:33,  8.84it/s] 79%|███████▊  | 1084/1380 [02:11<00:33,  8.79it/s] 79%|███████▊  | 1085/1380 [02:11<00:33,  8.84it/s] 79%|███████▊  | 1086/1380 [02:12<00:33,  8.90it/s] 79%|███████▉  | 1087/1380 [02:12<00:32,  9.01it/s] 79%|███████▉  | 1088/1380 [02:12<00:32,  8.97it/s] 79%|███████▉  | 1089/1380 [02:12<00:32,  8.86it/s] 79%|███████▉  | 1090/1380 [02:12<00:32,  8.93it/s] 79%|███████▉  | 1091/1380 [02:12<00:32,  9.00it/s] 79%|███████▉  | 1092/1380 [02:12<00:32,  8.92it/s] 79%|███████▉  | 1093/1380 [02:12<00:32,  8.94it/s] 79%|███████▉  | 1094/1380 [02:12<00:32,  8.89it/s] 79%|███████▉  | 1095/1380 [02:13<00:31,  8.91it/s] 79%|███████▉  | 1096/1380 [02:13<00:31,  8.98it/s] 79%|███████▉  | 1097/1380 [02:13<00:31,  9.03it/s] 80%|███████▉  | 1098/1380 [02:13<00:31,  9.04it/s] 80%|███████▉  | 1099/1380 [02:13<00:31,  8.96it/s] 80%|███████▉  | 1100/1380 [02:13<00:30,  9.04it/s] 80%|███████▉  | 1101/1380 [02:13<00:30,  9.05it/s] 80%|███████▉  | 1102/1380 [02:13<00:31,  8.96it/s] 80%|███████▉  | 1103/1380 [02:13<00:30,  8.96it/s]                                                    80%|████████  | 1104/1380 [02:14<00:30,  8.96it/s][INFO|trainer.py:755] 2023-11-15 21:38:29,188 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:38:29,190 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:38:29,191 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:38:29,191 >>   Batch size = 8
{'eval_loss': 0.4521194100379944, 'eval_accuracy': 0.8539019963702359, 'eval_micro_f1': 0.8539019963702359, 'eval_macro_f1': 0.8446874134242042, 'eval_runtime': 4.0042, 'eval_samples_per_second': 550.416, 'eval_steps_per_second': 68.927, 'epoch': 3.0}
{'loss': 0.1209, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 9/276 [00:00<00:03, 83.29it/s][A
  7%|▋         | 18/276 [00:00<00:03, 76.27it/s][A
  9%|▉         | 26/276 [00:00<00:03, 72.99it/s][A
 12%|█▏        | 34/276 [00:00<00:03, 71.26it/s][A
 15%|█▌        | 42/276 [00:00<00:03, 70.72it/s][A
 18%|█▊        | 50/276 [00:00<00:03, 72.03it/s][A
 21%|██        | 58/276 [00:00<00:03, 69.38it/s][A
 24%|██▍       | 66/276 [00:00<00:03, 69.89it/s][A
 27%|██▋       | 74/276 [00:01<00:02, 69.79it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 71.12it/s][A
 33%|███▎      | 90/276 [00:01<00:02, 70.07it/s][A
 36%|███▌      | 98/276 [00:01<00:02, 70.59it/s][A
 38%|███▊      | 106/276 [00:01<00:02, 70.13it/s][A
 41%|████▏     | 114/276 [00:01<00:02, 70.10it/s][A
 44%|████▍     | 122/276 [00:01<00:02, 70.78it/s][A
 47%|████▋     | 130/276 [00:01<00:02, 71.71it/s][A
 50%|█████     | 138/276 [00:01<00:01, 70.09it/s][A
 53%|█████▎    | 146/276 [00:02<00:01, 71.01it/s][A
 56%|█████▌    | 154/276 [00:02<00:01, 71.34it/s][A
 59%|█████▊    | 162/276 [00:02<00:01, 71.17it/s][A
 62%|██████▏   | 170/276 [00:02<00:01, 70.37it/s][A
 64%|██████▍   | 178/276 [00:02<00:01, 70.24it/s][A
 67%|██████▋   | 186/276 [00:02<00:01, 70.20it/s][A
 70%|███████   | 194/276 [00:02<00:01, 70.73it/s][A
 73%|███████▎  | 202/276 [00:02<00:01, 69.56it/s][A
 76%|███████▌  | 210/276 [00:02<00:00, 70.45it/s][A
 79%|███████▉  | 218/276 [00:03<00:00, 69.99it/s][A
 82%|████████▏ | 226/276 [00:03<00:00, 70.46it/s][A
 85%|████████▍ | 234/276 [00:03<00:00, 71.19it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 69.69it/s][A
 90%|█████████ | 249/276 [00:03<00:00, 69.20it/s][A
 93%|█████████▎| 257/276 [00:03<00:00, 69.11it/s][A
 96%|█████████▌| 265/276 [00:03<00:00, 70.40it/s][A
 99%|█████████▉| 273/276 [00:03<00:00, 69.88it/s][A                                                   
                                                 [A 80%|████████  | 1104/1380 [02:18<00:30,  8.96it/s]
100%|██████████| 276/276 [00:03<00:00, 69.88it/s][A
                                                 [A 80%|████████  | 1105/1380 [02:18<04:40,  1.02s/it] 80%|████████  | 1106/1380 [02:18<03:37,  1.26it/s] 80%|████████  | 1107/1380 [02:18<02:48,  1.62it/s] 80%|████████  | 1108/1380 [02:18<02:10,  2.08it/s] 80%|████████  | 1109/1380 [02:18<01:42,  2.65it/s] 80%|████████  | 1110/1380 [02:18<01:21,  3.31it/s] 81%|████████  | 1111/1380 [02:18<01:06,  4.06it/s] 81%|████████  | 1112/1380 [02:18<00:55,  4.82it/s] 81%|████████  | 1113/1380 [02:19<00:47,  5.58it/s] 81%|████████  | 1114/1380 [02:19<00:42,  6.31it/s] 81%|████████  | 1115/1380 [02:19<00:38,  6.96it/s] 81%|████████  | 1116/1380 [02:19<00:35,  7.39it/s] 81%|████████  | 1117/1380 [02:19<00:33,  7.79it/s] 81%|████████  | 1118/1380 [02:19<00:32,  8.15it/s] 81%|████████  | 1119/1380 [02:19<00:31,  8.37it/s] 81%|████████  | 1120/1380 [02:19<00:30,  8.55it/s] 81%|████████  | 1121/1380 [02:19<00:29,  8.73it/s] 81%|████████▏ | 1122/1380 [02:20<00:29,  8.79it/s] 81%|████████▏ | 1123/1380 [02:20<00:29,  8.80it/s] 81%|████████▏ | 1124/1380 [02:20<00:28,  8.89it/s] 82%|████████▏ | 1125/1380 [02:20<00:28,  8.95it/s] 82%|████████▏ | 1126/1380 [02:20<00:28,  8.89it/s] 82%|████████▏ | 1127/1380 [02:20<00:28,  8.92it/s] 82%|████████▏ | 1128/1380 [02:20<00:28,  8.94it/s] 82%|████████▏ | 1129/1380 [02:20<00:28,  8.94it/s] 82%|████████▏ | 1130/1380 [02:20<00:28,  8.90it/s] 82%|████████▏ | 1131/1380 [02:21<00:27,  8.94it/s] 82%|████████▏ | 1132/1380 [02:21<00:27,  8.92it/s] 82%|████████▏ | 1133/1380 [02:21<00:27,  8.94it/s] 82%|████████▏ | 1134/1380 [02:21<00:27,  8.98it/s] 82%|████████▏ | 1135/1380 [02:21<00:27,  9.06it/s] 82%|████████▏ | 1136/1380 [02:21<00:27,  9.02it/s] 82%|████████▏ | 1137/1380 [02:21<00:27,  9.00it/s] 82%|████████▏ | 1138/1380 [02:21<00:26,  9.04it/s] 83%|████████▎ | 1139/1380 [02:21<00:26,  9.04it/s] 83%|████████▎ | 1140/1380 [02:22<00:26,  8.98it/s] 83%|████████▎ | 1141/1380 [02:22<00:26,  9.02it/s] 83%|████████▎ | 1142/1380 [02:22<00:26,  9.00it/s] 83%|████████▎ | 1143/1380 [02:22<00:26,  9.00it/s] 83%|████████▎ | 1144/1380 [02:22<00:26,  8.99it/s] 83%|████████▎ | 1145/1380 [02:22<00:25,  9.14it/s] 83%|████████▎ | 1146/1380 [02:22<00:25,  9.08it/s] 83%|████████▎ | 1147/1380 [02:22<00:25,  8.98it/s] 83%|████████▎ | 1148/1380 [02:22<00:25,  8.94it/s] 83%|████████▎ | 1149/1380 [02:23<00:25,  8.97it/s] 83%|████████▎ | 1150/1380 [02:23<00:25,  8.91it/s] 83%|████████▎ | 1151/1380 [02:23<00:25,  8.97it/s] 83%|████████▎ | 1152/1380 [02:23<00:25,  8.96it/s] 84%|████████▎ | 1153/1380 [02:23<00:25,  8.92it/s] 84%|████████▎ | 1154/1380 [02:23<00:25,  8.99it/s] 84%|████████▎ | 1155/1380 [02:23<00:24,  9.08it/s] 84%|████████▍ | 1156/1380 [02:23<00:24,  9.00it/s] 84%|████████▍ | 1157/1380 [02:23<00:24,  8.98it/s] 84%|████████▍ | 1158/1380 [02:24<00:24,  8.93it/s] 84%|████████▍ | 1159/1380 [02:24<00:24,  8.90it/s] 84%|████████▍ | 1160/1380 [02:24<00:24,  8.89it/s] 84%|████████▍ | 1161/1380 [02:24<00:24,  8.86it/s] 84%|████████▍ | 1162/1380 [02:24<00:24,  8.87it/s] 84%|████████▍ | 1163/1380 [02:24<00:24,  8.92it/s] 84%|████████▍ | 1164/1380 [02:24<00:24,  8.84it/s] 84%|████████▍ | 1165/1380 [02:24<00:23,  8.98it/s] 84%|████████▍ | 1166/1380 [02:24<00:23,  8.96it/s] 85%|████████▍ | 1167/1380 [02:25<00:23,  8.92it/s] 85%|████████▍ | 1168/1380 [02:25<00:23,  8.92it/s] 85%|████████▍ | 1169/1380 [02:25<00:23,  8.95it/s] 85%|████████▍ | 1170/1380 [02:25<00:23,  8.92it/s] 85%|████████▍ | 1171/1380 [02:25<00:23,  8.88it/s] 85%|████████▍ | 1172/1380 [02:25<00:23,  8.92it/s] 85%|████████▌ | 1173/1380 [02:25<00:23,  8.86it/s] 85%|████████▌ | 1174/1380 [02:25<00:23,  8.94it/s] 85%|████████▌ | 1175/1380 [02:25<00:22,  9.01it/s] 85%|████████▌ | 1176/1380 [02:26<00:22,  9.00it/s] 85%|████████▌ | 1177/1380 [02:26<00:22,  8.97it/s] 85%|████████▌ | 1178/1380 [02:26<00:22,  8.94it/s] 85%|████████▌ | 1179/1380 [02:26<00:22,  8.99it/s] 86%|████████▌ | 1180/1380 [02:26<00:22,  8.92it/s] 86%|████████▌ | 1181/1380 [02:26<00:22,  8.91it/s] 86%|████████▌ | 1182/1380 [02:26<00:22,  8.95it/s] 86%|████████▌ | 1183/1380 [02:26<00:22,  8.93it/s] 86%|████████▌ | 1184/1380 [02:26<00:21,  8.93it/s] 86%|████████▌ | 1185/1380 [02:27<00:21,  9.03it/s] 86%|████████▌ | 1186/1380 [02:27<00:21,  8.95it/s] 86%|████████▌ | 1187/1380 [02:27<00:21,  8.92it/s] 86%|████████▌ | 1188/1380 [02:27<00:21,  8.90it/s] 86%|████████▌ | 1189/1380 [02:27<00:21,  8.86it/s] 86%|████████▌ | 1190/1380 [02:27<00:21,  8.85it/s] 86%|████████▋ | 1191/1380 [02:27<00:21,  8.74it/s] 86%|████████▋ | 1192/1380 [02:27<00:21,  8.93it/s] 86%|████████▋ | 1193/1380 [02:27<00:21,  8.82it/s] 87%|████████▋ | 1194/1380 [02:28<00:20,  8.90it/s] 87%|████████▋ | 1195/1380 [02:28<00:20,  8.91it/s] 87%|████████▋ | 1196/1380 [02:28<00:20,  8.90it/s] 87%|████████▋ | 1197/1380 [02:28<00:20,  8.83it/s] 87%|████████▋ | 1198/1380 [02:28<00:20,  8.87it/s] 87%|████████▋ | 1199/1380 [02:28<00:20,  8.91it/s] 87%|████████▋ | 1200/1380 [02:28<00:20,  8.95it/s] 87%|████████▋ | 1201/1380 [02:28<00:20,  8.85it/s] 87%|████████▋ | 1202/1380 [02:28<00:19,  8.99it/s] 87%|████████▋ | 1203/1380 [02:29<00:19,  9.01it/s] 87%|████████▋ | 1204/1380 [02:29<00:19,  8.89it/s] 87%|████████▋ | 1205/1380 [02:29<00:19,  8.94it/s] 87%|████████▋ | 1206/1380 [02:29<00:19,  8.80it/s] 87%|████████▋ | 1207/1380 [02:29<00:19,  8.82it/s] 88%|████████▊ | 1208/1380 [02:29<00:19,  8.83it/s] 88%|████████▊ | 1209/1380 [02:29<00:19,  8.93it/s] 88%|████████▊ | 1210/1380 [02:29<00:19,  8.90it/s] 88%|████████▊ | 1211/1380 [02:29<00:19,  8.87it/s] 88%|████████▊ | 1212/1380 [02:30<00:19,  8.80it/s] 88%|████████▊ | 1213/1380 [02:30<00:19,  8.78it/s] 88%|████████▊ | 1214/1380 [02:30<00:18,  8.85it/s] 88%|████████▊ | 1215/1380 [02:30<00:18,  8.76it/s] 88%|████████▊ | 1216/1380 [02:30<00:18,  8.78it/s] 88%|████████▊ | 1217/1380 [02:30<00:18,  8.74it/s] 88%|████████▊ | 1218/1380 [02:30<00:18,  8.78it/s] 88%|████████▊ | 1219/1380 [02:30<00:18,  8.88it/s] 88%|████████▊ | 1220/1380 [02:31<00:18,  8.89it/s] 88%|████████▊ | 1221/1380 [02:31<00:18,  8.81it/s] 89%|████████▊ | 1222/1380 [02:31<00:17,  8.85it/s] 89%|████████▊ | 1223/1380 [02:31<00:17,  8.83it/s] 89%|████████▊ | 1224/1380 [02:31<00:17,  8.80it/s] 89%|████████▉ | 1225/1380 [02:31<00:17,  8.83it/s] 89%|████████▉ | 1226/1380 [02:31<00:17,  8.91it/s] 89%|████████▉ | 1227/1380 [02:31<00:17,  8.89it/s] 89%|████████▉ | 1228/1380 [02:31<00:17,  8.78it/s] 89%|████████▉ | 1229/1380 [02:32<00:17,  8.80it/s] 89%|████████▉ | 1230/1380 [02:32<00:17,  8.77it/s] 89%|████████▉ | 1231/1380 [02:32<00:16,  8.79it/s] 89%|████████▉ | 1232/1380 [02:32<00:16,  8.79it/s] 89%|████████▉ | 1233/1380 [02:32<00:16,  8.92it/s] 89%|████████▉ | 1234/1380 [02:32<00:16,  8.84it/s] 89%|████████▉ | 1235/1380 [02:32<00:16,  8.79it/s] 90%|████████▉ | 1236/1380 [02:32<00:16,  8.82it/s] 90%|████████▉ | 1237/1380 [02:32<00:16,  8.88it/s] 90%|████████▉ | 1238/1380 [02:33<00:16,  8.87it/s] 90%|████████▉ | 1239/1380 [02:33<00:16,  8.80it/s] 90%|████████▉ | 1240/1380 [02:33<00:15,  8.89it/s] 90%|████████▉ | 1241/1380 [02:33<00:15,  8.87it/s] 90%|█████████ | 1242/1380 [02:33<00:15,  8.90it/s] 90%|█████████ | 1243/1380 [02:33<00:15,  8.94it/s] 90%|█████████ | 1244/1380 [02:33<00:15,  8.87it/s] 90%|█████████ | 1245/1380 [02:33<00:15,  8.89it/s] 90%|█████████ | 1246/1380 [02:33<00:15,  8.84it/s] 90%|█████████ | 1247/1380 [02:34<00:15,  8.80it/s] 90%|█████████ | 1248/1380 [02:34<00:15,  8.79it/s] 91%|█████████ | 1249/1380 [02:34<00:14,  8.81it/s] 91%|█████████ | 1250/1380 [02:34<00:14,  8.88it/s] 91%|█████████ | 1251/1380 [02:34<00:14,  8.89it/s] 91%|█████████ | 1252/1380 [02:34<00:14,  8.86it/s] 91%|█████████ | 1253/1380 [02:34<00:14,  8.85it/s] 91%|█████████ | 1254/1380 [02:34<00:14,  8.80it/s] 91%|█████████ | 1255/1380 [02:34<00:14,  8.84it/s] 91%|█████████ | 1256/1380 [02:35<00:13,  8.86it/s] 91%|█████████ | 1257/1380 [02:35<00:13,  8.96it/s] 91%|█████████ | 1258/1380 [02:35<00:13,  8.87it/s] 91%|█████████ | 1259/1380 [02:35<00:13,  8.83it/s] 91%|█████████▏| 1260/1380 [02:35<00:13,  8.79it/s] 91%|█████████▏| 1261/1380 [02:35<00:13,  8.81it/s] 91%|█████████▏| 1262/1380 [02:35<00:13,  8.81it/s] 92%|█████████▏| 1263/1380 [02:35<00:13,  8.74it/s] 92%|█████████▏| 1264/1380 [02:35<00:13,  8.80it/s] 92%|█████████▏| 1265/1380 [02:36<00:13,  8.83it/s] 92%|█████████▏| 1266/1380 [02:36<00:12,  8.82it/s] 92%|█████████▏| 1267/1380 [02:36<00:12,  8.91it/s] 92%|█████████▏| 1268/1380 [02:36<00:12,  8.86it/s] 92%|█████████▏| 1269/1380 [02:36<00:12,  8.80it/s] 92%|█████████▏| 1270/1380 [02:36<00:12,  8.80it/s] 92%|█████████▏| 1271/1380 [02:36<00:12,  8.84it/s] 92%|█████████▏| 1272/1380 [02:36<00:12,  8.84it/s] 92%|█████████▏| 1273/1380 [02:37<00:12,  8.80it/s] 92%|█████████▏| 1274/1380 [02:37<00:11,  8.87it/s] 92%|█████████▏| 1275/1380 [02:37<00:11,  8.82it/s] 92%|█████████▏| 1276/1380 [02:37<00:11,  8.84it/s] 93%|█████████▎| 1277/1380 [02:37<00:11,  8.85it/s] 93%|█████████▎| 1278/1380 [02:37<00:11,  8.84it/s] 93%|█████████▎| 1279/1380 [02:37<00:11,  8.80it/s] 93%|█████████▎| 1280/1380 [02:37<00:11,  8.83it/s] 93%|█████████▎| 1281/1380 [02:37<00:11,  8.96it/s] 93%|█████████▎| 1282/1380 [02:38<00:11,  8.77it/s] 93%|█████████▎| 1283/1380 [02:38<00:10,  8.85it/s] 93%|█████████▎| 1284/1380 [02:38<00:10,  8.75it/s] 93%|█████████▎| 1285/1380 [02:38<00:10,  8.82it/s] 93%|█████████▎| 1286/1380 [02:38<00:10,  8.86it/s] 93%|█████████▎| 1287/1380 [02:38<00:10,  8.74it/s] 93%|█████████▎| 1288/1380 [02:38<00:10,  8.85it/s] 93%|█████████▎| 1289/1380 [02:38<00:10,  8.78it/s] 93%|█████████▎| 1290/1380 [02:38<00:10,  8.73it/s] 94%|█████████▎| 1291/1380 [02:39<00:10,  8.86it/s] 94%|█████████▎| 1292/1380 [02:39<00:09,  8.85it/s] 94%|█████████▎| 1293/1380 [02:39<00:09,  8.80it/s] 94%|█████████▍| 1294/1380 [02:39<00:09,  8.85it/s] 94%|█████████▍| 1295/1380 [02:39<00:09,  8.84it/s] 94%|█████████▍| 1296/1380 [02:39<00:09,  8.83it/s] 94%|█████████▍| 1297/1380 [02:39<00:09,  8.81it/s] 94%|█████████▍| 1298/1380 [02:39<00:09,  8.91it/s] 94%|█████████▍| 1299/1380 [02:39<00:09,  8.82it/s] 94%|█████████▍| 1300/1380 [02:40<00:09,  8.77it/s] 94%|█████████▍| 1301/1380 [02:40<00:09,  8.77it/s] 94%|█████████▍| 1302/1380 [02:40<00:08,  8.77it/s] 94%|█████████▍| 1303/1380 [02:40<00:08,  8.76it/s] 94%|█████████▍| 1304/1380 [02:40<00:08,  8.77it/s] 95%|█████████▍| 1305/1380 [02:40<00:08,  8.90it/s] 95%|█████████▍| 1306/1380 [02:40<00:08,  8.79it/s] 95%|█████████▍| 1307/1380 [02:40<00:08,  8.82it/s] 95%|█████████▍| 1308/1380 [02:40<00:08,  8.77it/s] 95%|█████████▍| 1309/1380 [02:41<00:08,  8.80it/s] 95%|█████████▍| 1310/1380 [02:41<00:07,  8.81it/s] 95%|█████████▌| 1311/1380 [02:41<00:07,  8.77it/s] 95%|█████████▌| 1312/1380 [02:41<00:07,  8.74it/s] 95%|█████████▌| 1313/1380 [02:41<00:07,  8.70it/s] 95%|█████████▌| 1314/1380 [02:41<00:07,  8.78it/s] 95%|█████████▌| 1315/1380 [02:41<00:07,  8.82it/s] 95%|█████████▌| 1316/1380 [02:41<00:07,  8.81it/s] 95%|█████████▌| 1317/1380 [02:41<00:07,  8.85it/s] 96%|█████████▌| 1318/1380 [02:42<00:06,  8.87it/s] 96%|█████████▌| 1319/1380 [02:42<00:06,  8.88it/s] 96%|█████████▌| 1320/1380 [02:42<00:06,  8.78it/s] 96%|█████████▌| 1321/1380 [02:42<00:06,  8.80it/s] 96%|█████████▌| 1322/1380 [02:42<00:06,  8.92it/s] 96%|█████████▌| 1323/1380 [02:42<00:06,  8.90it/s] 96%|█████████▌| 1324/1380 [02:42<00:06,  8.84it/s] 96%|█████████▌| 1325/1380 [02:42<00:06,  8.89it/s] 96%|█████████▌| 1326/1380 [02:43<00:06,  8.82it/s] 96%|█████████▌| 1327/1380 [02:43<00:06,  8.83it/s] 96%|█████████▌| 1328/1380 [02:43<00:05,  8.84it/s] 96%|█████████▋| 1329/1380 [02:43<00:05,  8.90it/s] 96%|█████████▋| 1330/1380 [02:43<00:05,  8.82it/s] 96%|█████████▋| 1331/1380 [02:43<00:05,  8.87it/s] 97%|█████████▋| 1332/1380 [02:43<00:05,  8.76it/s] 97%|█████████▋| 1333/1380 [02:43<00:05,  8.77it/s] 97%|█████████▋| 1334/1380 [02:43<00:05,  8.76it/s] 97%|█████████▋| 1335/1380 [02:44<00:05,  8.71it/s] 97%|█████████▋| 1336/1380 [02:44<00:05,  8.75it/s] 97%|█████████▋| 1337/1380 [02:44<00:04,  8.71it/s] 97%|█████████▋| 1338/1380 [02:44<00:04,  8.77it/s] 97%|█████████▋| 1339/1380 [02:44<00:04,  8.85it/s] 97%|█████████▋| 1340/1380 [02:44<00:04,  8.82it/s] 97%|█████████▋| 1341/1380 [02:44<00:04,  8.83it/s] 97%|█████████▋| 1342/1380 [02:44<00:04,  8.81it/s] 97%|█████████▋| 1343/1380 [02:44<00:04,  8.77it/s] 97%|█████████▋| 1344/1380 [02:45<00:04,  8.80it/s] 97%|█████████▋| 1345/1380 [02:45<00:03,  8.77it/s] 98%|█████████▊| 1346/1380 [02:45<00:03,  8.83it/s] 98%|█████████▊| 1347/1380 [02:45<00:03,  8.79it/s] 98%|█████████▊| 1348/1380 [02:45<00:03,  8.73it/s] 98%|█████████▊| 1349/1380 [02:45<00:03,  8.76it/s] 98%|█████████▊| 1350/1380 [02:45<00:03,  8.71it/s] 98%|█████████▊| 1351/1380 [02:45<00:03,  8.70it/s] 98%|█████████▊| 1352/1380 [02:45<00:03,  8.67it/s] 98%|█████████▊| 1353/1380 [02:46<00:03,  8.80it/s] 98%|█████████▊| 1354/1380 [02:46<00:02,  8.82it/s] 98%|█████████▊| 1355/1380 [02:46<00:02,  8.85it/s] 98%|█████████▊| 1356/1380 [02:46<00:02,  8.82it/s] 98%|█████████▊| 1357/1380 [02:46<00:02,  8.82it/s] 98%|█████████▊| 1358/1380 [02:46<00:02,  8.86it/s] 98%|█████████▊| 1359/1380 [02:46<00:02,  8.79it/s] 99%|█████████▊| 1360/1380 [02:46<00:02,  8.92it/s] 99%|█████████▊| 1361/1380 [02:46<00:02,  8.86it/s] 99%|█████████▊| 1362/1380 [02:47<00:02,  8.88it/s] 99%|█████████▉| 1363/1380 [02:47<00:01,  8.82it/s] 99%|█████████▉| 1364/1380 [02:47<00:01,  8.76it/s] 99%|█████████▉| 1365/1380 [02:47<00:01,  8.76it/s] 99%|█████████▉| 1366/1380 [02:47<00:01,  8.75it/s] 99%|█████████▉| 1367/1380 [02:47<00:01,  8.81it/s] 99%|█████████▉| 1368/1380 [02:47<00:01,  8.82it/s] 99%|█████████▉| 1369/1380 [02:47<00:01,  8.82it/s] 99%|█████████▉| 1370/1380 [02:48<00:01,  8.82it/s] 99%|█████████▉| 1371/1380 [02:48<00:01,  8.78it/s] 99%|█████████▉| 1372/1380 [02:48<00:00,  8.75it/s] 99%|█████████▉| 1373/1380 [02:48<00:00,  8.65it/s]100%|█████████▉| 1374/1380 [02:48<00:00,  8.68it/s]100%|█████████▉| 1375/1380 [02:48<00:00,  8.67it/s]100%|█████████▉| 1376/1380 [02:48<00:00,  8.63it/s]100%|█████████▉| 1377/1380 [02:48<00:00,  8.73it/s]100%|█████████▉| 1378/1380 [02:48<00:00,  8.74it/s]100%|█████████▉| 1379/1380 [02:49<00:00,  8.81it/s]                                                   100%|██████████| 1380/1380 [02:49<00:00,  8.81it/s][INFO|trainer.py:755] 2023-11-15 21:39:04,283 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:39:04,285 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:39:04,285 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:39:04,286 >>   Batch size = 8
{'eval_loss': 0.5324488282203674, 'eval_accuracy': 0.853448275862069, 'eval_micro_f1': 0.853448275862069, 'eval_macro_f1': 0.8427280467283985, 'eval_runtime': 3.9724, 'eval_samples_per_second': 554.828, 'eval_steps_per_second': 69.479, 'epoch': 4.0}
{'loss': 0.0775, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/276 [00:00<?, ?it/s][A
  3%|▎         | 8/276 [00:00<00:03, 76.53it/s][A
  6%|▌         | 16/276 [00:00<00:03, 70.93it/s][A
  9%|▊         | 24/276 [00:00<00:03, 68.59it/s][A
 12%|█▏        | 32/276 [00:00<00:03, 70.64it/s][A
 14%|█▍        | 40/276 [00:00<00:03, 68.24it/s][A
 17%|█▋        | 47/276 [00:00<00:03, 66.50it/s][A
 20%|█▉        | 54/276 [00:00<00:03, 66.75it/s][A
 22%|██▏       | 61/276 [00:00<00:03, 67.03it/s][A
 25%|██▍       | 68/276 [00:01<00:03, 66.55it/s][A
 27%|██▋       | 75/276 [00:01<00:03, 66.79it/s][A
 30%|██▉       | 82/276 [00:01<00:02, 65.95it/s][A
 32%|███▏      | 89/276 [00:01<00:02, 66.69it/s][A
 35%|███▍      | 96/276 [00:01<00:02, 67.43it/s][A
 37%|███▋      | 103/276 [00:01<00:02, 67.30it/s][A
 40%|████      | 111/276 [00:01<00:02, 68.47it/s][A
 43%|████▎     | 118/276 [00:01<00:02, 67.76it/s][A
 45%|████▌     | 125/276 [00:01<00:02, 67.20it/s][A
 48%|████▊     | 132/276 [00:01<00:02, 66.24it/s][A
 51%|█████     | 140/276 [00:02<00:02, 66.94it/s][A
 53%|█████▎    | 147/276 [00:02<00:01, 67.16it/s][A
 56%|█████▌    | 154/276 [00:02<00:01, 67.28it/s][A
 58%|█████▊    | 161/276 [00:02<00:01, 65.92it/s][A
 61%|██████    | 168/276 [00:02<00:01, 66.56it/s][A
 63%|██████▎   | 175/276 [00:02<00:01, 67.26it/s][A
 66%|██████▋   | 183/276 [00:02<00:01, 67.55it/s][A
 69%|██████▉   | 191/276 [00:02<00:01, 68.57it/s][A
 72%|███████▏  | 198/276 [00:02<00:01, 67.09it/s][A
 74%|███████▍  | 205/276 [00:03<00:01, 67.14it/s][A
 77%|███████▋  | 212/276 [00:03<00:00, 66.91it/s][A
 80%|███████▉  | 220/276 [00:03<00:00, 66.89it/s][A
 82%|████████▏ | 227/276 [00:03<00:00, 66.93it/s][A
 85%|████████▌ | 235/276 [00:03<00:00, 67.70it/s][A
 88%|████████▊ | 242/276 [00:03<00:00, 68.31it/s][A
 90%|█████████ | 249/276 [00:03<00:00, 68.24it/s][A
 93%|█████████▎| 256/276 [00:03<00:00, 67.71it/s][A
 95%|█████████▌| 263/276 [00:03<00:00, 67.48it/s][A
 98%|█████████▊| 271/276 [00:04<00:00, 67.97it/s][A                                                   
                                                 [A100%|██████████| 1380/1380 [02:53<00:00,  8.81it/s]
100%|██████████| 276/276 [00:04<00:00, 67.97it/s][A
                                                 [A[INFO|trainer.py:1963] 2023-11-15 21:39:08,435 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1380/1380 [02:53<00:00,  8.81it/s]100%|██████████| 1380/1380 [02:53<00:00,  7.96it/s]
[INFO|trainer.py:2855] 2023-11-15 21:39:08,439 >> Saving model checkpoint to ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4
[INFO|configuration_utils.py:460] 2023-11-15 21:39:08,441 >> Configuration saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:39:09,506 >> Model weights saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:39:09,509 >> tokenizer config file saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:39:09,512 >> Special tokens file saved in ./result/acl_allenai/scibert_scivocab_uncased_adapter__seed4/special_tokens_map.json
{'eval_loss': 0.6186205148696899, 'eval_accuracy': 0.852994555353902, 'eval_micro_f1': 0.852994555353902, 'eval_macro_f1': 0.843255478986082, 'eval_runtime': 4.146, 'eval_samples_per_second': 531.596, 'eval_steps_per_second': 66.57, 'epoch': 5.0}
{'train_runtime': 173.2896, 'train_samples_per_second': 254.372, 'train_steps_per_second': 7.964, 'train_loss': 0.22022682134655938, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2202
  train_runtime            = 0:02:53.28
  train_samples            =       8816
  train_samples_per_second =    254.372
  train_steps_per_second   =      7.964
11/15/2023 21:39:09 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:39:09,559 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:39:09,560 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:39:09,560 >>   Num examples = 2204
[INFO|trainer.py:3134] 2023-11-15 21:39:09,561 >>   Batch size = 8
  0%|          | 0/276 [00:00<?, ?it/s]  3%|▎         | 9/276 [00:00<00:03, 82.65it/s]  7%|▋         | 18/276 [00:00<00:03, 76.11it/s]  9%|▉         | 26/276 [00:00<00:03, 73.66it/s] 12%|█▏        | 34/276 [00:00<00:03, 71.09it/s] 15%|█▌        | 42/276 [00:00<00:03, 70.85it/s] 18%|█▊        | 50/276 [00:00<00:03, 70.51it/s] 21%|██        | 58/276 [00:00<00:03, 70.45it/s] 24%|██▍       | 66/276 [00:00<00:02, 70.75it/s] 27%|██▋       | 74/276 [00:01<00:02, 71.58it/s] 30%|██▉       | 82/276 [00:01<00:02, 69.08it/s] 33%|███▎      | 90/276 [00:01<00:02, 70.03it/s] 36%|███▌      | 98/276 [00:01<00:02, 70.19it/s] 38%|███▊      | 106/276 [00:01<00:02, 71.09it/s] 41%|████▏     | 114/276 [00:01<00:02, 70.78it/s] 44%|████▍     | 122/276 [00:01<00:02, 68.78it/s] 47%|████▋     | 130/276 [00:01<00:02, 69.77it/s] 50%|████▉     | 137/276 [00:01<00:02, 69.36it/s] 52%|█████▏    | 144/276 [00:02<00:01, 69.03it/s] 55%|█████▌    | 152/276 [00:02<00:01, 70.04it/s] 58%|█████▊    | 160/276 [00:02<00:01, 70.10it/s] 61%|██████    | 168/276 [00:02<00:01, 69.19it/s] 63%|██████▎   | 175/276 [00:02<00:01, 68.40it/s] 66%|██████▋   | 183/276 [00:02<00:01, 69.55it/s] 69%|██████▉   | 190/276 [00:02<00:01, 69.67it/s] 72%|███████▏  | 198/276 [00:02<00:01, 69.54it/s] 75%|███████▍  | 206/276 [00:02<00:00, 70.40it/s] 78%|███████▊  | 214/276 [00:03<00:00, 71.15it/s] 80%|████████  | 222/276 [00:03<00:00, 70.95it/s] 83%|████████▎ | 230/276 [00:03<00:00, 68.95it/s] 86%|████████▌ | 238/276 [00:03<00:00, 70.04it/s] 89%|████████▉ | 246/276 [00:03<00:00, 70.12it/s] 92%|█████████▏| 254/276 [00:03<00:00, 70.04it/s] 95%|█████████▍| 262/276 [00:03<00:00, 71.85it/s] 98%|█████████▊| 270/276 [00:03<00:00, 69.92it/s]100%|██████████| 276/276 [00:03<00:00, 69.62it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.853
  eval_loss               =     0.6186
  eval_macro_f1           =     0.8433
  eval_micro_f1           =      0.853
  eval_runtime            = 0:00:03.98
  eval_samples            =       2204
  eval_samples_per_second =    552.458
  eval_steps_per_second   =     69.183
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁█▇▆▆▆
wandb:                      eval/loss ▁▁▃▅██
wandb:                  eval/macro_f1 ▁█▆▄▅▅
wandb:                  eval/micro_f1 ▁█▇▆▆▆
wandb:                   eval/runtime ▁▂▅▄█▅
wandb:        eval/samples_per_second █▇▄▅▁▄
wandb:          eval/steps_per_second █▇▄▅▁▄
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▅▅▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▅▃▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.85299
wandb:                      eval/loss 0.61862
wandb:                  eval/macro_f1 0.84326
wandb:                  eval/micro_f1 0.85299
wandb:                   eval/runtime 3.9894
wandb:        eval/samples_per_second 552.458
wandb:          eval/steps_per_second 69.183
wandb:                    train/epoch 5.0
wandb:              train/global_step 1380
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0775
wandb:               train/total_flos 1449754931681280.0
wandb:               train/train_loss 0.22023
wandb:            train/train_runtime 173.2896
wandb: train/train_samples_per_second 254.372
wandb:   train/train_steps_per_second 7.964
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_213456-2f24ipbg
wandb: Find logs at: ./wandb/offline-run-20231115_213456-2f24ipbg/logs
(ModelArguments(model_name_or_path='roberta-base', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_roberta-base_adapter__seed4/runs/Nov15_21-39-23_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_roberta-base_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_roberta-base_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:39:23 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:39:23 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_roberta-base_adapter__seed4/runs/Nov15_21-39-23_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_roberta-base_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_roberta-base_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 21:39:39,470 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:39:39,481 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:535] 2023-11-15 21:39:49,497 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 21:39:59,516 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:39:59,517 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:40:19,567 >> loading file vocab.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:40:19,567 >> loading file merges.txt from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:40:19,568 >> loading file tokenizer.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:40:19,568 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:40:19,568 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:40:19,569 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 21:40:19,570 >> loading configuration file config.json from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:40:19,571 >> Model config RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:40:39,753 >> loading weights file model.safetensors from cache at ./cache/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 21:40:40,499 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:40:40,500 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  29%|██▉       | 2000/6840 [00:00<00:00, 18166.13 examples/s]Running tokenizer on dataset:  58%|█████▊    | 4000/6840 [00:00<00:00, 18533.17 examples/s]Running tokenizer on dataset:  88%|████████▊ | 6000/6840 [00:00<00:00, 18694.93 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 18447.31 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 15649.01 examples/s]
11/15/2023 21:40:40 - INFO - __main__ - Sample 1583 of the training set: {'text': 'SA-India Test: South Africa declare at 510 for 9 : Sports India: Cricket  gt; Kanpur, Nov 22 : South Africa declared their first innings at 510 for nine on the third day of the first cricket Test against India here today.', 'label': 0, 'input_ids': [0, 3603, 12, 11015, 4500, 35, 391, 1327, 10152, 23, 30703, 13, 361, 4832, 1847, 666, 35, 10424, 1437, 821, 90, 131, 7542, 7748, 6, 1442, 820, 4832, 391, 1327, 2998, 49, 78, 2699, 23, 30703, 13, 1117, 15, 5, 371, 183, 9, 5, 78, 5630, 4500, 136, 666, 259, 452, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:40:40 - INFO - __main__ - Sample 2249 of the training set: {'text': 'FTSE 100 lifted by bright Dow The FTSE 100 has climbed as a surge by US shares gives a boost to European markets. Shire Pharmaceuticals SHP.L jumped after winning approval for a key drug and consumer goods giant Unilever ULVR.', 'label': 1, 'input_ids': [0, 597, 2685, 717, 727, 4639, 30, 4520, 4614, 20, 274, 2685, 717, 727, 34, 7334, 25, 10, 6564, 30, 382, 327, 2029, 10, 2501, 7, 796, 1048, 4, 840, 1885, 7937, 29, 4584, 510, 4, 574, 4262, 71, 1298, 2846, 13, 10, 762, 1262, 8, 2267, 3057, 3065, 1890, 1848, 2802, 33987, 13055, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:40:40 - INFO - __main__ - Sample 1319 of the training set: {'text': 'Language of goals what counts for tongue-tied Ronnie and Michael England striker Michael Owen said his lack of Spanish and Ronaldo #39;s lack of English did not hinder celebrations of the Brazilian #39;s matchwinner for Real Madrid in Sunday #39;s 1-0 win at Mallorca.', 'label': 0, 'input_ids': [0, 46969, 9, 1175, 99, 3948, 13, 15686, 12, 90, 2550, 21127, 8, 988, 1156, 5955, 988, 12212, 26, 39, 1762, 9, 3453, 8, 7991, 849, 3416, 131, 29, 1762, 9, 2370, 222, 45, 26679, 9570, 9, 5, 6606, 849, 3416, 131, 29, 914, 20547, 13, 2822, 3622, 11, 395, 849, 3416, 131, 29, 112, 12, 288, 339, 23, 6633, 368, 3245, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 21:40:41 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:40:42,397 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:40:42,404 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:40:42,404 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 21:40:42,404 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:40:42,405 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:40:42,405 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:40:42,405 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:40:42,406 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 21:40:42,406 >>   Number of trainable parameters = 124,648,708
[INFO|integration_utils.py:716] 2023-11-15 21:40:42,407 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<23:51,  1.34s/it]  0%|          | 2/1070 [00:01<11:00,  1.62it/s]  0%|          | 3/1070 [00:01<06:51,  2.59it/s]  0%|          | 4/1070 [00:01<04:54,  3.63it/s]  0%|          | 5/1070 [00:01<03:49,  4.65it/s]  1%|          | 6/1070 [00:01<03:12,  5.53it/s]  1%|          | 7/1070 [00:01<02:46,  6.37it/s]  1%|          | 8/1070 [00:02<02:30,  7.04it/s]  1%|          | 9/1070 [00:02<02:19,  7.61it/s]  1%|          | 10/1070 [00:02<02:12,  8.01it/s]  1%|          | 11/1070 [00:02<02:05,  8.43it/s]  1%|          | 12/1070 [00:02<02:03,  8.58it/s]  1%|          | 13/1070 [00:02<02:01,  8.72it/s]  1%|▏         | 14/1070 [00:02<01:59,  8.87it/s]  1%|▏         | 15/1070 [00:02<01:58,  8.93it/s]  1%|▏         | 16/1070 [00:02<01:57,  8.99it/s]  2%|▏         | 17/1070 [00:03<01:57,  8.93it/s]  2%|▏         | 18/1070 [00:03<01:57,  8.99it/s]  2%|▏         | 19/1070 [00:03<01:56,  9.02it/s]  2%|▏         | 20/1070 [00:03<01:56,  9.05it/s]  2%|▏         | 21/1070 [00:03<01:55,  9.11it/s]  2%|▏         | 22/1070 [00:03<01:56,  9.02it/s]  2%|▏         | 23/1070 [00:03<01:55,  9.03it/s]  2%|▏         | 24/1070 [00:03<01:55,  9.08it/s]  2%|▏         | 25/1070 [00:03<01:54,  9.09it/s]  2%|▏         | 26/1070 [00:04<01:54,  9.10it/s]  3%|▎         | 27/1070 [00:04<01:55,  9.04it/s]  3%|▎         | 28/1070 [00:04<01:55,  9.01it/s]  3%|▎         | 29/1070 [00:04<01:56,  8.96it/s]  3%|▎         | 30/1070 [00:04<01:55,  9.01it/s]  3%|▎         | 31/1070 [00:04<01:54,  9.07it/s]  3%|▎         | 32/1070 [00:04<01:54,  9.03it/s]  3%|▎         | 33/1070 [00:04<01:54,  9.02it/s]  3%|▎         | 34/1070 [00:04<01:54,  9.09it/s]  3%|▎         | 35/1070 [00:05<01:53,  9.11it/s]  3%|▎         | 36/1070 [00:05<01:53,  9.10it/s]  3%|▎         | 37/1070 [00:05<01:53,  9.07it/s]  4%|▎         | 38/1070 [00:05<01:53,  9.06it/s]  4%|▎         | 39/1070 [00:05<01:53,  9.08it/s]  4%|▎         | 40/1070 [00:05<01:53,  9.09it/s]  4%|▍         | 41/1070 [00:05<01:51,  9.22it/s]  4%|▍         | 42/1070 [00:05<01:51,  9.20it/s]  4%|▍         | 43/1070 [00:05<01:53,  9.08it/s]  4%|▍         | 44/1070 [00:06<01:53,  9.06it/s]  4%|▍         | 45/1070 [00:06<01:52,  9.09it/s]  4%|▍         | 46/1070 [00:06<01:51,  9.15it/s]  4%|▍         | 47/1070 [00:06<01:52,  9.13it/s]  4%|▍         | 48/1070 [00:06<01:51,  9.16it/s]  5%|▍         | 49/1070 [00:06<01:52,  9.09it/s]  5%|▍         | 50/1070 [00:06<01:52,  9.07it/s]  5%|▍         | 51/1070 [00:06<01:50,  9.19it/s]  5%|▍         | 52/1070 [00:06<01:50,  9.19it/s]  5%|▍         | 53/1070 [00:07<01:51,  9.09it/s]  5%|▌         | 54/1070 [00:07<01:52,  9.05it/s]  5%|▌         | 55/1070 [00:07<01:51,  9.09it/s]  5%|▌         | 56/1070 [00:07<01:51,  9.07it/s]  5%|▌         | 57/1070 [00:07<01:52,  9.04it/s]  5%|▌         | 58/1070 [00:07<01:50,  9.14it/s]  6%|▌         | 59/1070 [00:07<01:51,  9.07it/s]  6%|▌         | 60/1070 [00:07<01:51,  9.05it/s]  6%|▌         | 61/1070 [00:07<01:49,  9.21it/s]  6%|▌         | 62/1070 [00:08<01:49,  9.21it/s]  6%|▌         | 63/1070 [00:08<01:50,  9.11it/s]  6%|▌         | 64/1070 [00:08<01:50,  9.09it/s]  6%|▌         | 65/1070 [00:08<01:50,  9.13it/s]  6%|▌         | 66/1070 [00:08<01:49,  9.17it/s]  6%|▋         | 67/1070 [00:08<01:49,  9.16it/s]  6%|▋         | 68/1070 [00:08<01:49,  9.18it/s]  6%|▋         | 69/1070 [00:08<01:50,  9.05it/s]  7%|▋         | 70/1070 [00:08<01:50,  9.06it/s]  7%|▋         | 71/1070 [00:09<01:49,  9.14it/s]  7%|▋         | 72/1070 [00:09<01:50,  9.03it/s]  7%|▋         | 73/1070 [00:09<01:51,  8.98it/s]  7%|▋         | 74/1070 [00:09<01:50,  9.01it/s]  7%|▋         | 75/1070 [00:09<01:50,  9.02it/s]  7%|▋         | 76/1070 [00:09<01:50,  9.00it/s]  7%|▋         | 77/1070 [00:09<01:50,  8.97it/s]  7%|▋         | 78/1070 [00:09<01:49,  9.08it/s]  7%|▋         | 79/1070 [00:09<01:49,  9.02it/s]  7%|▋         | 80/1070 [00:10<01:49,  9.01it/s]  8%|▊         | 81/1070 [00:10<01:47,  9.16it/s]  8%|▊         | 82/1070 [00:10<01:48,  9.07it/s]  8%|▊         | 83/1070 [00:10<01:48,  9.08it/s]  8%|▊         | 84/1070 [00:10<01:48,  9.07it/s]  8%|▊         | 85/1070 [00:10<01:48,  9.08it/s]  8%|▊         | 86/1070 [00:10<01:47,  9.12it/s]  8%|▊         | 87/1070 [00:10<01:47,  9.11it/s]  8%|▊         | 88/1070 [00:10<01:47,  9.13it/s]  8%|▊         | 89/1070 [00:11<01:48,  9.08it/s]  8%|▊         | 90/1070 [00:11<01:47,  9.08it/s]  9%|▊         | 91/1070 [00:11<01:46,  9.17it/s]  9%|▊         | 92/1070 [00:11<01:46,  9.19it/s]  9%|▊         | 93/1070 [00:11<01:46,  9.15it/s]  9%|▉         | 94/1070 [00:11<01:47,  9.05it/s]  9%|▉         | 95/1070 [00:11<01:47,  9.06it/s]  9%|▉         | 96/1070 [00:11<01:47,  9.06it/s]  9%|▉         | 97/1070 [00:11<01:47,  9.01it/s]  9%|▉         | 98/1070 [00:12<01:46,  9.11it/s]  9%|▉         | 99/1070 [00:12<01:47,  9.06it/s]  9%|▉         | 100/1070 [00:12<01:47,  9.06it/s]  9%|▉         | 101/1070 [00:12<01:45,  9.18it/s] 10%|▉         | 102/1070 [00:12<01:45,  9.19it/s] 10%|▉         | 103/1070 [00:12<01:45,  9.17it/s] 10%|▉         | 104/1070 [00:12<01:46,  9.04it/s] 10%|▉         | 105/1070 [00:12<01:46,  9.05it/s] 10%|▉         | 106/1070 [00:12<01:47,  9.00it/s] 10%|█         | 107/1070 [00:12<01:45,  9.09it/s] 10%|█         | 108/1070 [00:13<01:44,  9.17it/s] 10%|█         | 109/1070 [00:13<01:44,  9.16it/s] 10%|█         | 110/1070 [00:13<01:45,  9.07it/s] 10%|█         | 111/1070 [00:13<01:44,  9.15it/s] 10%|█         | 112/1070 [00:13<01:44,  9.13it/s] 11%|█         | 113/1070 [00:13<01:44,  9.19it/s] 11%|█         | 114/1070 [00:13<01:44,  9.13it/s] 11%|█         | 115/1070 [00:13<01:45,  9.06it/s] 11%|█         | 116/1070 [00:13<01:44,  9.10it/s] 11%|█         | 117/1070 [00:14<01:44,  9.10it/s] 11%|█         | 118/1070 [00:14<01:42,  9.26it/s] 11%|█         | 119/1070 [00:14<01:43,  9.19it/s] 11%|█         | 120/1070 [00:14<01:44,  9.13it/s] 11%|█▏        | 121/1070 [00:14<01:43,  9.14it/s] 11%|█▏        | 122/1070 [00:14<01:43,  9.17it/s] 11%|█▏        | 123/1070 [00:14<01:43,  9.18it/s] 12%|█▏        | 124/1070 [00:14<01:43,  9.11it/s] 12%|█▏        | 125/1070 [00:14<01:43,  9.11it/s] 12%|█▏        | 126/1070 [00:15<01:43,  9.14it/s] 12%|█▏        | 127/1070 [00:15<01:43,  9.15it/s] 12%|█▏        | 128/1070 [00:15<01:42,  9.17it/s] 12%|█▏        | 129/1070 [00:15<01:42,  9.19it/s] 12%|█▏        | 130/1070 [00:15<01:42,  9.13it/s] 12%|█▏        | 131/1070 [00:15<01:42,  9.20it/s] 12%|█▏        | 132/1070 [00:15<01:42,  9.17it/s] 12%|█▏        | 133/1070 [00:15<01:42,  9.18it/s] 13%|█▎        | 134/1070 [00:15<01:42,  9.09it/s] 13%|█▎        | 135/1070 [00:16<01:41,  9.22it/s] 13%|█▎        | 136/1070 [00:16<01:42,  9.13it/s] 13%|█▎        | 137/1070 [00:16<01:42,  9.07it/s] 13%|█▎        | 138/1070 [00:16<01:41,  9.21it/s] 13%|█▎        | 139/1070 [00:16<01:41,  9.21it/s] 13%|█▎        | 140/1070 [00:16<01:41,  9.15it/s] 13%|█▎        | 141/1070 [00:16<01:42,  9.09it/s] 13%|█▎        | 142/1070 [00:16<01:41,  9.15it/s] 13%|█▎        | 143/1070 [00:16<01:41,  9.13it/s] 13%|█▎        | 144/1070 [00:17<01:41,  9.10it/s] 14%|█▎        | 145/1070 [00:17<01:40,  9.18it/s] 14%|█▎        | 146/1070 [00:17<01:41,  9.12it/s] 14%|█▎        | 147/1070 [00:17<01:41,  9.09it/s] 14%|█▍        | 148/1070 [00:17<01:40,  9.19it/s] 14%|█▍        | 149/1070 [00:17<01:39,  9.25it/s] 14%|█▍        | 150/1070 [00:17<01:39,  9.24it/s] 14%|█▍        | 151/1070 [00:17<01:40,  9.19it/s] 14%|█▍        | 152/1070 [00:17<01:40,  9.10it/s] 14%|█▍        | 153/1070 [00:18<01:40,  9.12it/s] 14%|█▍        | 154/1070 [00:18<01:40,  9.14it/s] 14%|█▍        | 155/1070 [00:18<01:39,  9.24it/s] 15%|█▍        | 156/1070 [00:18<01:39,  9.15it/s] 15%|█▍        | 157/1070 [00:18<01:40,  9.12it/s] 15%|█▍        | 158/1070 [00:18<01:39,  9.19it/s] 15%|█▍        | 159/1070 [00:18<01:39,  9.20it/s] 15%|█▍        | 160/1070 [00:18<01:39,  9.14it/s] 15%|█▌        | 161/1070 [00:18<01:40,  9.08it/s] 15%|█▌        | 162/1070 [00:19<01:40,  9.06it/s] 15%|█▌        | 163/1070 [00:19<01:40,  9.06it/s] 15%|█▌        | 164/1070 [00:19<01:39,  9.14it/s] 15%|█▌        | 165/1070 [00:19<01:37,  9.24it/s] 16%|█▌        | 166/1070 [00:19<01:38,  9.20it/s] 16%|█▌        | 167/1070 [00:19<01:38,  9.15it/s] 16%|█▌        | 168/1070 [00:19<01:37,  9.21it/s] 16%|█▌        | 169/1070 [00:19<01:38,  9.17it/s] 16%|█▌        | 170/1070 [00:19<01:37,  9.19it/s] 16%|█▌        | 171/1070 [00:19<01:37,  9.20it/s] 16%|█▌        | 172/1070 [00:20<01:38,  9.16it/s] 16%|█▌        | 173/1070 [00:20<01:37,  9.20it/s] 16%|█▋        | 174/1070 [00:20<01:37,  9.23it/s] 16%|█▋        | 175/1070 [00:20<01:36,  9.28it/s] 16%|█▋        | 176/1070 [00:20<01:36,  9.24it/s] 17%|█▋        | 177/1070 [00:20<01:37,  9.20it/s] 17%|█▋        | 178/1070 [00:20<01:36,  9.20it/s] 17%|█▋        | 179/1070 [00:20<01:37,  9.15it/s] 17%|█▋        | 180/1070 [00:20<01:37,  9.16it/s] 17%|█▋        | 181/1070 [00:21<01:37,  9.13it/s] 17%|█▋        | 182/1070 [00:21<01:37,  9.10it/s] 17%|█▋        | 183/1070 [00:21<01:38,  9.05it/s] 17%|█▋        | 184/1070 [00:21<01:37,  9.11it/s] 17%|█▋        | 185/1070 [00:21<01:35,  9.23it/s] 17%|█▋        | 186/1070 [00:21<01:36,  9.12it/s] 17%|█▋        | 187/1070 [00:21<01:36,  9.13it/s] 18%|█▊        | 188/1070 [00:21<01:36,  9.18it/s] 18%|█▊        | 189/1070 [00:21<01:36,  9.15it/s] 18%|█▊        | 190/1070 [00:22<01:37,  9.05it/s] 18%|█▊        | 191/1070 [00:22<01:36,  9.09it/s] 18%|█▊        | 192/1070 [00:22<01:36,  9.06it/s] 18%|█▊        | 193/1070 [00:22<01:36,  9.08it/s] 18%|█▊        | 194/1070 [00:22<01:36,  9.06it/s] 18%|█▊        | 195/1070 [00:22<01:35,  9.12it/s] 18%|█▊        | 196/1070 [00:22<01:36,  9.06it/s] 18%|█▊        | 197/1070 [00:22<01:36,  9.07it/s] 19%|█▊        | 198/1070 [00:22<01:35,  9.16it/s] 19%|█▊        | 199/1070 [00:23<01:35,  9.10it/s] 19%|█▊        | 200/1070 [00:23<01:36,  9.06it/s] 19%|█▉        | 201/1070 [00:23<01:35,  9.07it/s] 19%|█▉        | 202/1070 [00:23<01:35,  9.13it/s] 19%|█▉        | 203/1070 [00:23<01:34,  9.17it/s] 19%|█▉        | 204/1070 [00:23<01:34,  9.15it/s] 19%|█▉        | 205/1070 [00:23<01:34,  9.12it/s] 19%|█▉        | 206/1070 [00:23<01:35,  9.09it/s] 19%|█▉        | 207/1070 [00:23<01:34,  9.09it/s] 19%|█▉        | 208/1070 [00:24<01:33,  9.21it/s] 20%|█▉        | 209/1070 [00:24<01:34,  9.10it/s] 20%|█▉        | 210/1070 [00:24<01:35,  9.04it/s] 20%|█▉        | 211/1070 [00:24<01:35,  9.04it/s] 20%|█▉        | 212/1070 [00:24<01:35,  9.02it/s] 20%|█▉        | 213/1070 [00:24<01:34,  9.06it/s]                                                   20%|██        | 214/1070 [00:24<01:34,  9.06it/s][INFO|trainer.py:755] 2023-11-15 21:41:07,106 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:41:07,108 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:41:07,109 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:41:07,109 >>   Batch size = 8
{'loss': 0.4485, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 83.99it/s][A
 19%|█▉        | 18/95 [00:00<00:00, 79.17it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 76.71it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 77.42it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 73.16it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 73.05it/s][A
 61%|██████    | 58/95 [00:00<00:00, 74.55it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 73.79it/s][A
 78%|███████▊  | 74/95 [00:00<00:00, 72.03it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 71.86it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 72.38it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:26<01:34,  9.06it/s]
100%|██████████| 95/95 [00:01<00:00, 72.38it/s][A
                                               [A 20%|██        | 215/1070 [00:26<05:56,  2.40it/s] 20%|██        | 216/1070 [00:26<04:50,  2.94it/s] 20%|██        | 217/1070 [00:26<03:59,  3.56it/s] 20%|██        | 218/1070 [00:26<03:19,  4.26it/s] 20%|██        | 219/1070 [00:26<02:49,  5.02it/s] 21%|██        | 220/1070 [00:26<02:27,  5.74it/s] 21%|██        | 221/1070 [00:26<02:12,  6.41it/s] 21%|██        | 222/1070 [00:26<02:01,  6.98it/s] 21%|██        | 223/1070 [00:27<01:53,  7.45it/s] 21%|██        | 224/1070 [00:27<01:47,  7.84it/s] 21%|██        | 225/1070 [00:27<01:42,  8.21it/s] 21%|██        | 226/1070 [00:27<01:39,  8.49it/s] 21%|██        | 227/1070 [00:27<01:37,  8.62it/s] 21%|██▏       | 228/1070 [00:27<01:36,  8.69it/s] 21%|██▏       | 229/1070 [00:27<01:34,  8.89it/s] 21%|██▏       | 230/1070 [00:27<01:34,  8.94it/s] 22%|██▏       | 231/1070 [00:27<01:33,  8.94it/s] 22%|██▏       | 232/1070 [00:28<01:33,  8.93it/s] 22%|██▏       | 233/1070 [00:28<01:33,  9.00it/s] 22%|██▏       | 234/1070 [00:28<01:32,  9.03it/s] 22%|██▏       | 235/1070 [00:28<01:32,  9.00it/s] 22%|██▏       | 236/1070 [00:28<01:31,  9.09it/s] 22%|██▏       | 237/1070 [00:28<01:32,  9.04it/s] 22%|██▏       | 238/1070 [00:28<01:32,  9.04it/s] 22%|██▏       | 239/1070 [00:28<01:30,  9.16it/s] 22%|██▏       | 240/1070 [00:28<01:30,  9.15it/s] 23%|██▎       | 241/1070 [00:29<01:31,  9.10it/s] 23%|██▎       | 242/1070 [00:29<01:30,  9.12it/s] 23%|██▎       | 243/1070 [00:29<01:30,  9.12it/s] 23%|██▎       | 244/1070 [00:29<01:30,  9.08it/s] 23%|██▎       | 245/1070 [00:29<01:31,  9.03it/s] 23%|██▎       | 246/1070 [00:29<01:30,  9.07it/s] 23%|██▎       | 247/1070 [00:29<01:30,  9.06it/s] 23%|██▎       | 248/1070 [00:29<01:30,  9.03it/s] 23%|██▎       | 249/1070 [00:29<01:29,  9.17it/s] 23%|██▎       | 250/1070 [00:30<01:30,  9.10it/s] 23%|██▎       | 251/1070 [00:30<01:30,  9.05it/s] 24%|██▎       | 252/1070 [00:30<01:30,  9.03it/s] 24%|██▎       | 253/1070 [00:30<01:30,  9.03it/s] 24%|██▎       | 254/1070 [00:30<01:30,  9.03it/s] 24%|██▍       | 255/1070 [00:30<01:30,  8.98it/s] 24%|██▍       | 256/1070 [00:30<01:30,  8.99it/s] 24%|██▍       | 257/1070 [00:30<01:30,  9.03it/s] 24%|██▍       | 258/1070 [00:30<01:29,  9.07it/s] 24%|██▍       | 259/1070 [00:30<01:28,  9.14it/s] 24%|██▍       | 260/1070 [00:31<01:29,  9.06it/s] 24%|██▍       | 261/1070 [00:31<01:29,  9.01it/s] 24%|██▍       | 262/1070 [00:31<01:28,  9.11it/s] 25%|██▍       | 263/1070 [00:31<01:28,  9.09it/s] 25%|██▍       | 264/1070 [00:31<01:28,  9.07it/s] 25%|██▍       | 265/1070 [00:31<01:29,  9.04it/s] 25%|██▍       | 266/1070 [00:31<01:28,  9.07it/s] 25%|██▍       | 267/1070 [00:31<01:28,  9.07it/s] 25%|██▌       | 268/1070 [00:31<01:28,  9.08it/s] 25%|██▌       | 269/1070 [00:32<01:28,  9.09it/s] 25%|██▌       | 270/1070 [00:32<01:28,  9.04it/s] 25%|██▌       | 271/1070 [00:32<01:28,  9.00it/s] 25%|██▌       | 272/1070 [00:32<01:27,  9.13it/s] 26%|██▌       | 273/1070 [00:32<01:28,  9.03it/s] 26%|██▌       | 274/1070 [00:32<01:28,  9.02it/s] 26%|██▌       | 275/1070 [00:32<01:27,  9.04it/s] 26%|██▌       | 276/1070 [00:32<01:27,  9.06it/s] 26%|██▌       | 277/1070 [00:32<01:27,  9.04it/s] 26%|██▌       | 278/1070 [00:33<01:28,  8.99it/s] 26%|██▌       | 279/1070 [00:33<01:28,  8.96it/s] 26%|██▌       | 280/1070 [00:33<01:27,  9.00it/s] 26%|██▋       | 281/1070 [00:33<01:27,  9.06it/s] 26%|██▋       | 282/1070 [00:33<01:26,  9.12it/s] 26%|██▋       | 283/1070 [00:33<01:27,  9.02it/s] 27%|██▋       | 284/1070 [00:33<01:27,  8.99it/s] 27%|██▋       | 285/1070 [00:33<01:26,  9.10it/s] 27%|██▋       | 286/1070 [00:33<01:26,  9.08it/s] 27%|██▋       | 287/1070 [00:34<01:26,  9.02it/s] 27%|██▋       | 288/1070 [00:34<01:26,  9.02it/s] 27%|██▋       | 289/1070 [00:34<01:26,  9.07it/s] 27%|██▋       | 290/1070 [00:34<01:25,  9.09it/s] 27%|██▋       | 291/1070 [00:34<01:25,  9.11it/s] 27%|██▋       | 292/1070 [00:34<01:25,  9.13it/s] 27%|██▋       | 293/1070 [00:34<01:26,  9.03it/s] 27%|██▋       | 294/1070 [00:34<01:25,  9.04it/s] 28%|██▊       | 295/1070 [00:34<01:24,  9.12it/s] 28%|██▊       | 296/1070 [00:35<01:25,  9.09it/s] 28%|██▊       | 297/1070 [00:35<01:25,  9.03it/s] 28%|██▊       | 298/1070 [00:35<01:25,  9.03it/s] 28%|██▊       | 299/1070 [00:35<01:25,  9.07it/s] 28%|██▊       | 300/1070 [00:35<01:24,  9.09it/s] 28%|██▊       | 301/1070 [00:35<01:24,  9.09it/s] 28%|██▊       | 302/1070 [00:35<01:24,  9.11it/s] 28%|██▊       | 303/1070 [00:35<01:24,  9.11it/s] 28%|██▊       | 304/1070 [00:35<01:25,  9.00it/s] 29%|██▊       | 305/1070 [00:36<01:24,  9.11it/s] 29%|██▊       | 306/1070 [00:36<01:24,  9.03it/s] 29%|██▊       | 307/1070 [00:36<01:24,  9.05it/s] 29%|██▉       | 308/1070 [00:36<01:24,  9.05it/s] 29%|██▉       | 309/1070 [00:36<01:24,  8.99it/s] 29%|██▉       | 310/1070 [00:36<01:24,  9.03it/s] 29%|██▉       | 311/1070 [00:36<01:25,  8.91it/s] 29%|██▉       | 312/1070 [00:36<01:25,  8.91it/s] 29%|██▉       | 313/1070 [00:36<01:24,  8.97it/s] 29%|██▉       | 314/1070 [00:37<01:23,  9.04it/s] 29%|██▉       | 315/1070 [00:37<01:22,  9.15it/s] 30%|██▉       | 316/1070 [00:37<01:23,  8.99it/s] 30%|██▉       | 317/1070 [00:37<01:23,  8.97it/s] 30%|██▉       | 318/1070 [00:37<01:23,  9.01it/s] 30%|██▉       | 319/1070 [00:37<01:23,  9.00it/s] 30%|██▉       | 320/1070 [00:37<01:22,  9.06it/s] 30%|███       | 321/1070 [00:37<01:23,  8.93it/s] 30%|███       | 322/1070 [00:37<01:23,  8.97it/s] 30%|███       | 323/1070 [00:38<01:23,  8.94it/s] 30%|███       | 324/1070 [00:38<01:22,  9.01it/s] 30%|███       | 325/1070 [00:38<01:21,  9.15it/s] 30%|███       | 326/1070 [00:38<01:21,  9.12it/s] 31%|███       | 327/1070 [00:38<01:21,  9.07it/s] 31%|███       | 328/1070 [00:38<01:21,  9.11it/s] 31%|███       | 329/1070 [00:38<01:20,  9.15it/s] 31%|███       | 330/1070 [00:38<01:21,  9.09it/s] 31%|███       | 331/1070 [00:38<01:22,  8.98it/s] 31%|███       | 332/1070 [00:39<01:22,  8.93it/s] 31%|███       | 333/1070 [00:39<01:22,  8.96it/s] 31%|███       | 334/1070 [00:39<01:21,  8.98it/s] 31%|███▏      | 335/1070 [00:39<01:21,  9.06it/s] 31%|███▏      | 336/1070 [00:39<01:22,  8.93it/s] 31%|███▏      | 337/1070 [00:39<01:21,  8.95it/s] 32%|███▏      | 338/1070 [00:39<01:20,  9.05it/s] 32%|███▏      | 339/1070 [00:39<01:20,  9.05it/s] 32%|███▏      | 340/1070 [00:39<01:21,  8.98it/s] 32%|███▏      | 341/1070 [00:40<01:20,  9.00it/s] 32%|███▏      | 342/1070 [00:40<01:21,  8.93it/s] 32%|███▏      | 343/1070 [00:40<01:21,  8.94it/s] 32%|███▏      | 344/1070 [00:40<01:20,  8.98it/s] 32%|███▏      | 345/1070 [00:40<01:20,  9.04it/s] 32%|███▏      | 346/1070 [00:40<01:20,  8.96it/s] 32%|███▏      | 347/1070 [00:40<01:20,  8.97it/s] 33%|███▎      | 348/1070 [00:40<01:19,  9.09it/s] 33%|███▎      | 349/1070 [00:40<01:19,  9.11it/s] 33%|███▎      | 350/1070 [00:41<01:19,  9.08it/s] 33%|███▎      | 351/1070 [00:41<01:20,  8.94it/s] 33%|███▎      | 352/1070 [00:41<01:19,  9.01it/s] 33%|███▎      | 353/1070 [00:41<01:19,  9.00it/s] 33%|███▎      | 354/1070 [00:41<01:19,  8.98it/s] 33%|███▎      | 355/1070 [00:41<01:18,  9.07it/s] 33%|███▎      | 356/1070 [00:41<01:19,  8.95it/s] 33%|███▎      | 357/1070 [00:41<01:19,  8.97it/s] 33%|███▎      | 358/1070 [00:41<01:18,  9.04it/s] 34%|███▎      | 359/1070 [00:42<01:18,  9.02it/s] 34%|███▎      | 360/1070 [00:42<01:19,  8.94it/s] 34%|███▎      | 361/1070 [00:42<01:18,  8.98it/s] 34%|███▍      | 362/1070 [00:42<01:18,  8.98it/s] 34%|███▍      | 363/1070 [00:42<01:18,  9.00it/s] 34%|███▍      | 364/1070 [00:42<01:19,  8.93it/s] 34%|███▍      | 365/1070 [00:42<01:19,  8.92it/s] 34%|███▍      | 366/1070 [00:42<01:18,  8.92it/s] 34%|███▍      | 367/1070 [00:42<01:18,  8.99it/s] 34%|███▍      | 368/1070 [00:43<01:17,  9.05it/s] 34%|███▍      | 369/1070 [00:43<01:17,  9.04it/s] 35%|███▍      | 370/1070 [00:43<01:17,  8.98it/s] 35%|███▍      | 371/1070 [00:43<01:17,  9.03it/s] 35%|███▍      | 372/1070 [00:43<01:17,  9.06it/s] 35%|███▍      | 373/1070 [00:43<01:17,  9.05it/s] 35%|███▍      | 374/1070 [00:43<01:18,  8.92it/s] 35%|███▌      | 375/1070 [00:43<01:17,  8.95it/s] 35%|███▌      | 376/1070 [00:43<01:17,  8.98it/s] 35%|███▌      | 377/1070 [00:44<01:16,  9.02it/s] 35%|███▌      | 378/1070 [00:44<01:16,  9.08it/s] 35%|███▌      | 379/1070 [00:44<01:16,  9.05it/s] 36%|███▌      | 380/1070 [00:44<01:16,  8.99it/s] 36%|███▌      | 381/1070 [00:44<01:15,  9.08it/s] 36%|███▌      | 382/1070 [00:44<01:15,  9.10it/s] 36%|███▌      | 383/1070 [00:44<01:15,  9.06it/s] 36%|███▌      | 384/1070 [00:44<01:16,  9.01it/s] 36%|███▌      | 385/1070 [00:44<01:17,  8.88it/s] 36%|███▌      | 386/1070 [00:45<01:16,  8.89it/s] 36%|███▌      | 387/1070 [00:45<01:16,  8.87it/s] 36%|███▋      | 388/1070 [00:45<01:16,  8.91it/s] 36%|███▋      | 389/1070 [00:45<01:17,  8.84it/s] 36%|███▋      | 390/1070 [00:45<01:16,  8.88it/s] 37%|███▋      | 391/1070 [00:45<01:15,  9.04it/s] 37%|███▋      | 392/1070 [00:45<01:15,  8.97it/s] 37%|███▋      | 393/1070 [00:45<01:15,  8.93it/s] 37%|███▋      | 394/1070 [00:45<01:15,  8.96it/s] 37%|███▋      | 395/1070 [00:46<01:15,  8.97it/s] 37%|███▋      | 396/1070 [00:46<01:14,  9.00it/s] 37%|███▋      | 397/1070 [00:46<01:15,  8.97it/s] 37%|███▋      | 398/1070 [00:46<01:14,  8.98it/s] 37%|███▋      | 399/1070 [00:46<01:14,  8.97it/s] 37%|███▋      | 400/1070 [00:46<01:14,  9.02it/s] 37%|███▋      | 401/1070 [00:46<01:13,  9.08it/s] 38%|███▊      | 402/1070 [00:46<01:14,  9.02it/s] 38%|███▊      | 403/1070 [00:46<01:14,  8.95it/s] 38%|███▊      | 404/1070 [00:47<01:14,  9.00it/s] 38%|███▊      | 405/1070 [00:47<01:14,  8.96it/s] 38%|███▊      | 406/1070 [00:47<01:13,  9.06it/s] 38%|███▊      | 407/1070 [00:47<01:13,  8.96it/s] 38%|███▊      | 408/1070 [00:47<01:13,  9.03it/s] 38%|███▊      | 409/1070 [00:47<01:13,  8.95it/s] 38%|███▊      | 410/1070 [00:47<01:13,  9.01it/s] 38%|███▊      | 411/1070 [00:47<01:12,  9.07it/s] 39%|███▊      | 412/1070 [00:47<01:12,  9.08it/s] 39%|███▊      | 413/1070 [00:48<01:12,  9.03it/s] 39%|███▊      | 414/1070 [00:48<01:11,  9.17it/s] 39%|███▉      | 415/1070 [00:48<01:11,  9.11it/s] 39%|███▉      | 416/1070 [00:48<01:12,  9.03it/s] 39%|███▉      | 417/1070 [00:48<01:12,  9.03it/s] 39%|███▉      | 418/1070 [00:48<01:11,  9.07it/s] 39%|███▉      | 419/1070 [00:48<01:11,  9.08it/s] 39%|███▉      | 420/1070 [00:48<01:12,  9.02it/s] 39%|███▉      | 421/1070 [00:48<01:11,  9.05it/s] 39%|███▉      | 422/1070 [00:49<01:11,  9.09it/s] 40%|███▉      | 423/1070 [00:49<01:11,  9.11it/s] 40%|███▉      | 424/1070 [00:49<01:10,  9.13it/s] 40%|███▉      | 425/1070 [00:49<01:11,  9.07it/s] 40%|███▉      | 426/1070 [00:49<01:11,  9.00it/s] 40%|███▉      | 427/1070 [00:49<01:10,  9.12it/s]                                                   40%|████      | 428/1070 [00:49<01:10,  9.12it/s][INFO|trainer.py:755] 2023-11-15 21:41:32,134 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:41:32,135 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:41:32,136 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:41:32,136 >>   Batch size = 8
{'eval_loss': 0.2897040545940399, 'eval_accuracy': 0.9078947368421053, 'eval_micro_f1': 0.9078947368421053, 'eval_macro_f1': 0.9053481358393722, 'eval_runtime': 1.339, 'eval_samples_per_second': 567.598, 'eval_steps_per_second': 70.95, 'epoch': 1.0}
{'loss': 0.2228, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 79.13it/s][A
 18%|█▊        | 17/95 [00:00<00:01, 76.40it/s][A
 26%|██▋       | 25/95 [00:00<00:00, 76.55it/s][A
 35%|███▍      | 33/95 [00:00<00:00, 75.57it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 72.62it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 72.44it/s][A
 60%|██████    | 57/95 [00:00<00:00, 72.96it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 73.99it/s][A
 77%|███████▋  | 73/95 [00:00<00:00, 74.95it/s][A
 85%|████████▌ | 81/95 [00:01<00:00, 72.27it/s][A
 94%|█████████▎| 89/95 [00:01<00:00, 72.48it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:51<01:10,  9.12it/s]
100%|██████████| 95/95 [00:01<00:00, 72.48it/s][A
                                               [A 40%|████      | 429/1070 [00:51<04:28,  2.39it/s] 40%|████      | 430/1070 [00:51<03:39,  2.91it/s] 40%|████      | 431/1070 [00:51<03:00,  3.54it/s] 40%|████      | 432/1070 [00:51<02:30,  4.24it/s] 40%|████      | 433/1070 [00:51<02:07,  4.98it/s] 41%|████      | 434/1070 [00:51<01:51,  5.71it/s] 41%|████      | 435/1070 [00:51<01:39,  6.41it/s] 41%|████      | 436/1070 [00:51<01:30,  6.98it/s] 41%|████      | 437/1070 [00:52<01:24,  7.48it/s] 41%|████      | 438/1070 [00:52<01:19,  7.97it/s] 41%|████      | 439/1070 [00:52<01:16,  8.21it/s] 41%|████      | 440/1070 [00:52<01:14,  8.41it/s] 41%|████      | 441/1070 [00:52<01:13,  8.58it/s] 41%|████▏     | 442/1070 [00:52<01:11,  8.76it/s] 41%|████▏     | 443/1070 [00:52<01:10,  8.87it/s] 41%|████▏     | 444/1070 [00:52<01:10,  8.94it/s] 42%|████▏     | 445/1070 [00:52<01:09,  8.93it/s] 42%|████▏     | 446/1070 [00:53<01:10,  8.90it/s] 42%|████▏     | 447/1070 [00:53<01:09,  9.00it/s] 42%|████▏     | 448/1070 [00:53<01:08,  9.11it/s] 42%|████▏     | 449/1070 [00:53<01:08,  9.03it/s] 42%|████▏     | 450/1070 [00:53<01:08,  9.03it/s] 42%|████▏     | 451/1070 [00:53<01:08,  9.07it/s] 42%|████▏     | 452/1070 [00:53<01:08,  9.06it/s] 42%|████▏     | 453/1070 [00:53<01:08,  9.05it/s] 42%|████▏     | 454/1070 [00:53<01:08,  9.01it/s] 43%|████▎     | 455/1070 [00:54<01:08,  8.96it/s] 43%|████▎     | 456/1070 [00:54<01:08,  9.02it/s] 43%|████▎     | 457/1070 [00:54<01:07,  9.02it/s] 43%|████▎     | 458/1070 [00:54<01:07,  9.07it/s] 43%|████▎     | 459/1070 [00:54<01:07,  9.00it/s] 43%|████▎     | 460/1070 [00:54<01:07,  9.00it/s] 43%|████▎     | 461/1070 [00:54<01:06,  9.17it/s] 43%|████▎     | 462/1070 [00:54<01:06,  9.09it/s] 43%|████▎     | 463/1070 [00:54<01:07,  9.00it/s] 43%|████▎     | 464/1070 [00:55<01:07,  8.96it/s] 43%|████▎     | 465/1070 [00:55<01:07,  8.98it/s] 44%|████▎     | 466/1070 [00:55<01:07,  8.98it/s] 44%|████▎     | 467/1070 [00:55<01:07,  8.89it/s] 44%|████▎     | 468/1070 [00:55<01:07,  8.86it/s] 44%|████▍     | 469/1070 [00:55<01:07,  8.96it/s] 44%|████▍     | 470/1070 [00:55<01:06,  8.99it/s] 44%|████▍     | 471/1070 [00:55<01:06,  9.06it/s] 44%|████▍     | 472/1070 [00:55<01:06,  8.98it/s] 44%|████▍     | 473/1070 [00:56<01:07,  8.88it/s] 44%|████▍     | 474/1070 [00:56<01:06,  8.98it/s] 44%|████▍     | 475/1070 [00:56<01:06,  9.00it/s] 44%|████▍     | 476/1070 [00:56<01:06,  8.98it/s] 45%|████▍     | 477/1070 [00:56<01:06,  8.97it/s] 45%|████▍     | 478/1070 [00:56<01:06,  8.90it/s] 45%|████▍     | 479/1070 [00:56<01:06,  8.94it/s] 45%|████▍     | 480/1070 [00:56<01:05,  8.96it/s] 45%|████▍     | 481/1070 [00:56<01:04,  9.06it/s] 45%|████▌     | 482/1070 [00:57<01:05,  9.02it/s] 45%|████▌     | 483/1070 [00:57<01:05,  8.96it/s] 45%|████▌     | 484/1070 [00:57<01:04,  9.10it/s] 45%|████▌     | 485/1070 [00:57<01:04,  9.10it/s] 45%|████▌     | 486/1070 [00:57<01:05,  8.96it/s] 46%|████▌     | 487/1070 [00:57<01:04,  8.98it/s] 46%|████▌     | 488/1070 [00:57<01:04,  8.97it/s] 46%|████▌     | 489/1070 [00:57<01:04,  8.99it/s] 46%|████▌     | 490/1070 [00:57<01:04,  8.96it/s] 46%|████▌     | 491/1070 [00:58<01:04,  8.93it/s] 46%|████▌     | 492/1070 [00:58<01:05,  8.89it/s] 46%|████▌     | 493/1070 [00:58<01:04,  8.95it/s] 46%|████▌     | 494/1070 [00:58<01:03,  9.06it/s] 46%|████▋     | 495/1070 [00:58<01:03,  8.99it/s] 46%|████▋     | 496/1070 [00:58<01:04,  8.94it/s] 46%|████▋     | 497/1070 [00:58<01:03,  9.01it/s] 47%|████▋     | 498/1070 [00:58<01:03,  9.01it/s] 47%|████▋     | 499/1070 [00:58<01:03,  9.05it/s] 47%|████▋     | 500/1070 [00:59<01:03,  9.02it/s] 47%|████▋     | 501/1070 [00:59<01:03,  8.90it/s] 47%|████▋     | 502/1070 [00:59<01:03,  8.92it/s] 47%|████▋     | 503/1070 [00:59<01:02,  9.01it/s] 47%|████▋     | 504/1070 [00:59<01:02,  9.09it/s] 47%|████▋     | 505/1070 [00:59<01:03,  8.94it/s] 47%|████▋     | 506/1070 [00:59<01:03,  8.93it/s] 47%|████▋     | 507/1070 [00:59<01:02,  9.04it/s] 47%|████▋     | 508/1070 [00:59<01:02,  9.04it/s] 48%|████▊     | 509/1070 [01:00<01:02,  8.98it/s] 48%|████▊     | 510/1070 [01:00<01:02,  8.94it/s] 48%|████▊     | 511/1070 [01:00<01:02,  8.97it/s] 48%|████▊     | 512/1070 [01:00<01:02,  8.98it/s] 48%|████▊     | 513/1070 [01:00<01:02,  8.96it/s] 48%|████▊     | 514/1070 [01:00<01:01,  9.02it/s] 48%|████▊     | 515/1070 [01:00<01:02,  8.91it/s] 48%|████▊     | 516/1070 [01:00<01:02,  8.93it/s] 48%|████▊     | 517/1070 [01:00<01:01,  9.02it/s] 48%|████▊     | 518/1070 [01:01<01:01,  8.98it/s] 49%|████▊     | 519/1070 [01:01<01:01,  8.95it/s] 49%|████▊     | 520/1070 [01:01<01:01,  8.98it/s] 49%|████▊     | 521/1070 [01:01<01:00,  9.03it/s] 49%|████▉     | 522/1070 [01:01<01:00,  9.07it/s] 49%|████▉     | 523/1070 [01:01<01:01,  8.96it/s] 49%|████▉     | 524/1070 [01:01<01:01,  8.89it/s] 49%|████▉     | 525/1070 [01:01<01:01,  8.90it/s] 49%|████▉     | 526/1070 [01:01<01:01,  8.90it/s] 49%|████▉     | 527/1070 [01:02<01:00,  8.97it/s] 49%|████▉     | 528/1070 [01:02<01:00,  8.90it/s] 49%|████▉     | 529/1070 [01:02<01:00,  8.95it/s] 50%|████▉     | 530/1070 [01:02<00:59,  9.05it/s] 50%|████▉     | 531/1070 [01:02<00:59,  9.05it/s] 50%|████▉     | 532/1070 [01:02<00:59,  9.03it/s] 50%|████▉     | 533/1070 [01:02<01:00,  8.95it/s] 50%|████▉     | 534/1070 [01:02<00:59,  8.95it/s] 50%|█████     | 535/1070 [01:02<00:59,  8.99it/s] 50%|█████     | 536/1070 [01:03<00:59,  8.91it/s] 50%|█████     | 537/1070 [01:03<00:59,  8.97it/s] 50%|█████     | 538/1070 [01:03<00:59,  8.92it/s] 50%|█████     | 539/1070 [01:03<00:59,  8.97it/s] 50%|█████     | 540/1070 [01:03<00:58,  9.06it/s] 51%|█████     | 541/1070 [01:03<00:58,  9.00it/s] 51%|█████     | 542/1070 [01:03<00:58,  8.96it/s] 51%|█████     | 543/1070 [01:03<00:58,  8.96it/s] 51%|█████     | 544/1070 [01:03<00:58,  8.96it/s] 51%|█████     | 545/1070 [01:04<00:58,  8.99it/s] 51%|█████     | 546/1070 [01:04<00:58,  8.91it/s] 51%|█████     | 547/1070 [01:04<00:58,  8.88it/s] 51%|█████     | 548/1070 [01:04<00:58,  8.87it/s] 51%|█████▏    | 549/1070 [01:04<00:58,  8.92it/s] 51%|█████▏    | 550/1070 [01:04<00:57,  8.99it/s] 51%|█████▏    | 551/1070 [01:04<00:58,  8.92it/s] 52%|█████▏    | 552/1070 [01:04<00:58,  8.85it/s] 52%|█████▏    | 553/1070 [01:04<00:57,  8.99it/s] 52%|█████▏    | 554/1070 [01:05<00:57,  9.03it/s] 52%|█████▏    | 555/1070 [01:05<00:57,  8.93it/s] 52%|█████▏    | 556/1070 [01:05<00:57,  8.92it/s] 52%|█████▏    | 557/1070 [01:05<00:57,  8.95it/s] 52%|█████▏    | 558/1070 [01:05<00:57,  8.94it/s] 52%|█████▏    | 559/1070 [01:05<00:57,  8.93it/s] 52%|█████▏    | 560/1070 [01:05<00:56,  8.97it/s] 52%|█████▏    | 561/1070 [01:05<00:56,  9.00it/s] 53%|█████▎    | 562/1070 [01:05<00:56,  8.98it/s] 53%|█████▎    | 563/1070 [01:06<00:55,  9.12it/s] 53%|█████▎    | 564/1070 [01:06<00:55,  9.11it/s] 53%|█████▎    | 565/1070 [01:06<00:56,  9.01it/s] 53%|█████▎    | 566/1070 [01:06<00:56,  8.86it/s] 53%|█████▎    | 567/1070 [01:06<00:56,  8.96it/s] 53%|█████▎    | 568/1070 [01:06<00:56,  8.95it/s] 53%|█████▎    | 569/1070 [01:06<00:55,  8.98it/s] 53%|█████▎    | 570/1070 [01:06<00:55,  8.97it/s] 53%|█████▎    | 571/1070 [01:06<00:56,  8.91it/s] 53%|█████▎    | 572/1070 [01:07<00:56,  8.89it/s] 54%|█████▎    | 573/1070 [01:07<00:55,  9.01it/s] 54%|█████▎    | 574/1070 [01:07<00:55,  8.97it/s] 54%|█████▎    | 575/1070 [01:07<00:55,  8.95it/s] 54%|█████▍    | 576/1070 [01:07<00:55,  8.94it/s] 54%|█████▍    | 577/1070 [01:07<00:55,  8.94it/s] 54%|█████▍    | 578/1070 [01:07<00:54,  8.95it/s] 54%|█████▍    | 579/1070 [01:07<00:54,  8.94it/s] 54%|█████▍    | 580/1070 [01:07<00:54,  9.00it/s] 54%|█████▍    | 581/1070 [01:08<00:54,  8.92it/s] 54%|█████▍    | 582/1070 [01:08<00:54,  8.96it/s] 54%|█████▍    | 583/1070 [01:08<00:54,  9.01it/s] 55%|█████▍    | 584/1070 [01:08<00:54,  8.92it/s] 55%|█████▍    | 585/1070 [01:08<00:54,  8.84it/s] 55%|█████▍    | 586/1070 [01:08<00:54,  8.90it/s] 55%|█████▍    | 587/1070 [01:08<00:54,  8.93it/s] 55%|█████▍    | 588/1070 [01:08<00:53,  8.97it/s] 55%|█████▌    | 589/1070 [01:08<00:53,  8.98it/s] 55%|█████▌    | 590/1070 [01:09<00:53,  8.97it/s] 55%|█████▌    | 591/1070 [01:09<00:53,  8.93it/s] 55%|█████▌    | 592/1070 [01:09<00:53,  8.95it/s] 55%|█████▌    | 593/1070 [01:09<00:52,  9.04it/s] 56%|█████▌    | 594/1070 [01:09<00:53,  8.92it/s] 56%|█████▌    | 595/1070 [01:09<00:53,  8.92it/s] 56%|█████▌    | 596/1070 [01:09<00:52,  8.98it/s] 56%|█████▌    | 597/1070 [01:09<00:52,  8.97it/s] 56%|█████▌    | 598/1070 [01:09<00:52,  9.00it/s] 56%|█████▌    | 599/1070 [01:10<00:52,  9.01it/s] 56%|█████▌    | 600/1070 [01:10<00:52,  8.96it/s] 56%|█████▌    | 601/1070 [01:10<00:52,  8.93it/s] 56%|█████▋    | 602/1070 [01:10<00:52,  8.94it/s] 56%|█████▋    | 603/1070 [01:10<00:51,  9.01it/s] 56%|█████▋    | 604/1070 [01:10<00:52,  8.89it/s] 57%|█████▋    | 605/1070 [01:10<00:52,  8.85it/s] 57%|█████▋    | 606/1070 [01:10<00:51,  8.98it/s] 57%|█████▋    | 607/1070 [01:11<00:51,  9.01it/s] 57%|█████▋    | 608/1070 [01:11<00:51,  8.99it/s] 57%|█████▋    | 609/1070 [01:11<00:51,  8.93it/s] 57%|█████▋    | 610/1070 [01:11<00:51,  8.96it/s] 57%|█████▋    | 611/1070 [01:11<00:51,  8.99it/s] 57%|█████▋    | 612/1070 [01:11<00:51,  8.98it/s] 57%|█████▋    | 613/1070 [01:11<00:50,  9.02it/s] 57%|█████▋    | 614/1070 [01:11<00:51,  8.92it/s] 57%|█████▋    | 615/1070 [01:11<00:50,  8.93it/s] 58%|█████▊    | 616/1070 [01:12<00:50,  9.06it/s] 58%|█████▊    | 617/1070 [01:12<00:50,  9.02it/s] 58%|█████▊    | 618/1070 [01:12<00:50,  9.00it/s] 58%|█████▊    | 619/1070 [01:12<00:50,  8.96it/s] 58%|█████▊    | 620/1070 [01:12<00:50,  8.97it/s] 58%|█████▊    | 621/1070 [01:12<00:50,  8.95it/s] 58%|█████▊    | 622/1070 [01:12<00:50,  8.82it/s] 58%|█████▊    | 623/1070 [01:12<00:50,  8.88it/s] 58%|█████▊    | 624/1070 [01:12<00:50,  8.88it/s] 58%|█████▊    | 625/1070 [01:13<00:49,  8.93it/s] 59%|█████▊    | 626/1070 [01:13<00:49,  8.98it/s] 59%|█████▊    | 627/1070 [01:13<00:49,  8.98it/s] 59%|█████▊    | 628/1070 [01:13<00:49,  8.88it/s] 59%|█████▉    | 629/1070 [01:13<00:49,  8.95it/s] 59%|█████▉    | 630/1070 [01:13<00:49,  8.95it/s] 59%|█████▉    | 631/1070 [01:13<00:48,  8.96it/s] 59%|█████▉    | 632/1070 [01:13<00:49,  8.93it/s] 59%|█████▉    | 633/1070 [01:13<00:49,  8.89it/s] 59%|█████▉    | 634/1070 [01:14<00:48,  8.91it/s] 59%|█████▉    | 635/1070 [01:14<00:48,  8.95it/s] 59%|█████▉    | 636/1070 [01:14<00:48,  9.01it/s] 60%|█████▉    | 637/1070 [01:14<00:48,  8.99it/s] 60%|█████▉    | 638/1070 [01:14<00:48,  8.96it/s] 60%|█████▉    | 639/1070 [01:14<00:47,  9.07it/s] 60%|█████▉    | 640/1070 [01:14<00:47,  9.05it/s] 60%|█████▉    | 641/1070 [01:14<00:48,  8.88it/s]                                                   60%|██████    | 642/1070 [01:14<00:48,  8.88it/s][INFO|trainer.py:755] 2023-11-15 21:41:57,316 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:41:57,317 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:41:57,318 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:41:57,318 >>   Batch size = 8
{'eval_loss': 0.2904055118560791, 'eval_accuracy': 0.9105263157894737, 'eval_micro_f1': 0.9105263157894739, 'eval_macro_f1': 0.9083762179095141, 'eval_runtime': 1.3452, 'eval_samples_per_second': 564.973, 'eval_steps_per_second': 70.622, 'epoch': 2.0}
{'loss': 0.1553, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:00, 89.39it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 76.42it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 74.22it/s][A
 40%|████      | 38/95 [00:00<00:00, 88.38it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 95.50it/s][A
 63%|██████▎   | 60/95 [00:00<00:00, 100.18it/s][A
 75%|███████▍  | 71/95 [00:00<00:00, 103.25it/s][A
 86%|████████▋ | 82/95 [00:00<00:00, 105.03it/s][A
 98%|█████████▊| 93/95 [00:00<00:00, 106.17it/s][A                                                  
                                                [A 60%|██████    | 642/1070 [01:15<00:48,  8.88it/s]
100%|██████████| 95/95 [00:01<00:00, 106.17it/s][A
                                                [A 60%|██████    | 643/1070 [01:16<02:27,  2.90it/s] 60%|██████    | 644/1070 [01:16<02:02,  3.49it/s] 60%|██████    | 645/1070 [01:16<01:42,  4.13it/s] 60%|██████    | 646/1070 [01:16<01:27,  4.85it/s] 60%|██████    | 647/1070 [01:16<01:15,  5.57it/s] 61%|██████    | 648/1070 [01:16<01:07,  6.24it/s] 61%|██████    | 649/1070 [01:16<01:01,  6.87it/s] 61%|██████    | 650/1070 [01:16<00:57,  7.32it/s] 61%|██████    | 651/1070 [01:16<00:54,  7.71it/s] 61%|██████    | 652/1070 [01:17<00:51,  8.14it/s] 61%|██████    | 653/1070 [01:17<00:50,  8.29it/s] 61%|██████    | 654/1070 [01:17<00:49,  8.49it/s] 61%|██████    | 655/1070 [01:17<00:48,  8.64it/s] 61%|██████▏   | 656/1070 [01:17<00:47,  8.74it/s] 61%|██████▏   | 657/1070 [01:17<00:47,  8.76it/s] 61%|██████▏   | 658/1070 [01:17<00:47,  8.71it/s] 62%|██████▏   | 659/1070 [01:17<00:46,  8.81it/s] 62%|██████▏   | 660/1070 [01:17<00:46,  8.87it/s] 62%|██████▏   | 661/1070 [01:18<00:45,  8.90it/s] 62%|██████▏   | 662/1070 [01:18<00:45,  8.94it/s] 62%|██████▏   | 663/1070 [01:18<00:45,  8.89it/s] 62%|██████▏   | 664/1070 [01:18<00:45,  8.87it/s] 62%|██████▏   | 665/1070 [01:18<00:44,  9.01it/s] 62%|██████▏   | 666/1070 [01:18<00:44,  8.98it/s] 62%|██████▏   | 667/1070 [01:18<00:44,  8.98it/s] 62%|██████▏   | 668/1070 [01:18<00:45,  8.87it/s] 63%|██████▎   | 669/1070 [01:18<00:45,  8.91it/s] 63%|██████▎   | 670/1070 [01:19<00:44,  8.97it/s] 63%|██████▎   | 671/1070 [01:19<00:44,  8.89it/s] 63%|██████▎   | 672/1070 [01:19<00:44,  8.87it/s] 63%|██████▎   | 673/1070 [01:19<00:44,  8.90it/s] 63%|██████▎   | 674/1070 [01:19<00:44,  8.92it/s] 63%|██████▎   | 675/1070 [01:19<00:43,  9.00it/s] 63%|██████▎   | 676/1070 [01:19<00:43,  8.98it/s] 63%|██████▎   | 677/1070 [01:19<00:43,  8.98it/s] 63%|██████▎   | 678/1070 [01:19<00:43,  8.97it/s] 63%|██████▎   | 679/1070 [01:20<00:43,  8.94it/s] 64%|██████▎   | 680/1070 [01:20<00:43,  8.89it/s] 64%|██████▎   | 681/1070 [01:20<00:43,  8.91it/s] 64%|██████▎   | 682/1070 [01:20<00:43,  8.93it/s] 64%|██████▍   | 683/1070 [01:20<00:43,  8.86it/s] 64%|██████▍   | 684/1070 [01:20<00:43,  8.88it/s] 64%|██████▍   | 685/1070 [01:20<00:43,  8.93it/s] 64%|██████▍   | 686/1070 [01:20<00:42,  8.94it/s] 64%|██████▍   | 687/1070 [01:20<00:43,  8.91it/s] 64%|██████▍   | 688/1070 [01:21<00:42,  8.97it/s] 64%|██████▍   | 689/1070 [01:21<00:42,  8.95it/s] 64%|██████▍   | 690/1070 [01:21<00:42,  8.91it/s] 65%|██████▍   | 691/1070 [01:21<00:42,  8.90it/s] 65%|██████▍   | 692/1070 [01:21<00:42,  8.88it/s] 65%|██████▍   | 693/1070 [01:21<00:42,  8.92it/s] 65%|██████▍   | 694/1070 [01:21<00:42,  8.93it/s] 65%|██████▍   | 695/1070 [01:21<00:41,  8.93it/s] 65%|██████▌   | 696/1070 [01:21<00:42,  8.87it/s] 65%|██████▌   | 697/1070 [01:22<00:42,  8.85it/s] 65%|██████▌   | 698/1070 [01:22<00:41,  8.98it/s] 65%|██████▌   | 699/1070 [01:22<00:41,  8.93it/s] 65%|██████▌   | 700/1070 [01:22<00:41,  8.82it/s] 66%|██████▌   | 701/1070 [01:22<00:41,  8.83it/s] 66%|██████▌   | 702/1070 [01:22<00:41,  8.81it/s] 66%|██████▌   | 703/1070 [01:22<00:41,  8.85it/s] 66%|██████▌   | 704/1070 [01:22<00:41,  8.79it/s] 66%|██████▌   | 705/1070 [01:22<00:41,  8.90it/s] 66%|██████▌   | 706/1070 [01:23<00:41,  8.86it/s] 66%|██████▌   | 707/1070 [01:23<00:40,  8.92it/s] 66%|██████▌   | 708/1070 [01:23<00:40,  9.01it/s] 66%|██████▋   | 709/1070 [01:23<00:40,  8.96it/s] 66%|██████▋   | 710/1070 [01:23<00:40,  8.94it/s] 66%|██████▋   | 711/1070 [01:23<00:40,  8.97it/s] 67%|██████▋   | 712/1070 [01:23<00:39,  8.99it/s] 67%|██████▋   | 713/1070 [01:23<00:39,  9.03it/s] 67%|██████▋   | 714/1070 [01:23<00:39,  8.92it/s] 67%|██████▋   | 715/1070 [01:24<00:39,  8.97it/s] 67%|██████▋   | 716/1070 [01:24<00:39,  8.88it/s] 67%|██████▋   | 717/1070 [01:24<00:39,  8.89it/s] 67%|██████▋   | 718/1070 [01:24<00:39,  8.96it/s] 67%|██████▋   | 719/1070 [01:24<00:39,  8.84it/s] 67%|██████▋   | 720/1070 [01:24<00:39,  8.80it/s] 67%|██████▋   | 721/1070 [01:24<00:38,  8.98it/s] 67%|██████▋   | 722/1070 [01:24<00:39,  8.86it/s] 68%|██████▊   | 723/1070 [01:25<00:39,  8.90it/s] 68%|██████▊   | 724/1070 [01:25<00:38,  8.88it/s] 68%|██████▊   | 725/1070 [01:25<00:38,  8.93it/s] 68%|██████▊   | 726/1070 [01:25<00:38,  8.90it/s] 68%|██████▊   | 727/1070 [01:25<00:38,  8.91it/s] 68%|██████▊   | 728/1070 [01:25<00:38,  8.95it/s] 68%|██████▊   | 729/1070 [01:25<00:38,  8.97it/s] 68%|██████▊   | 730/1070 [01:25<00:37,  8.98it/s] 68%|██████▊   | 731/1070 [01:25<00:37,  9.07it/s] 68%|██████▊   | 732/1070 [01:26<00:37,  8.96it/s] 69%|██████▊   | 733/1070 [01:26<00:37,  9.00it/s] 69%|██████▊   | 734/1070 [01:26<00:37,  9.00it/s] 69%|██████▊   | 735/1070 [01:26<00:37,  9.03it/s] 69%|██████▉   | 736/1070 [01:26<00:37,  8.96it/s] 69%|██████▉   | 737/1070 [01:26<00:37,  8.94it/s] 69%|██████▉   | 738/1070 [01:26<00:37,  8.90it/s] 69%|██████▉   | 739/1070 [01:26<00:37,  8.94it/s] 69%|██████▉   | 740/1070 [01:26<00:36,  8.94it/s] 69%|██████▉   | 741/1070 [01:27<00:36,  9.03it/s] 69%|██████▉   | 742/1070 [01:27<00:36,  8.88it/s] 69%|██████▉   | 743/1070 [01:27<00:36,  8.89it/s] 70%|██████▉   | 744/1070 [01:27<00:36,  9.02it/s] 70%|██████▉   | 745/1070 [01:27<00:36,  9.02it/s] 70%|██████▉   | 746/1070 [01:27<00:36,  8.96it/s] 70%|██████▉   | 747/1070 [01:27<00:36,  8.89it/s] 70%|██████▉   | 748/1070 [01:27<00:36,  8.92it/s] 70%|███████   | 749/1070 [01:27<00:35,  8.93it/s] 70%|███████   | 750/1070 [01:28<00:36,  8.84it/s] 70%|███████   | 751/1070 [01:28<00:36,  8.81it/s] 70%|███████   | 752/1070 [01:28<00:36,  8.78it/s] 70%|███████   | 753/1070 [01:28<00:35,  8.86it/s] 70%|███████   | 754/1070 [01:28<00:35,  8.96it/s] 71%|███████   | 755/1070 [01:28<00:35,  8.91it/s] 71%|███████   | 756/1070 [01:28<00:35,  8.85it/s] 71%|███████   | 757/1070 [01:28<00:34,  8.96it/s] 71%|███████   | 758/1070 [01:28<00:34,  9.04it/s] 71%|███████   | 759/1070 [01:29<00:35,  8.85it/s] 71%|███████   | 760/1070 [01:29<00:35,  8.86it/s] 71%|███████   | 761/1070 [01:29<00:34,  8.90it/s] 71%|███████   | 762/1070 [01:29<00:34,  8.95it/s] 71%|███████▏  | 763/1070 [01:29<00:34,  8.87it/s] 71%|███████▏  | 764/1070 [01:29<00:34,  8.91it/s] 71%|███████▏  | 765/1070 [01:29<00:34,  8.87it/s] 72%|███████▏  | 766/1070 [01:29<00:34,  8.88it/s] 72%|███████▏  | 767/1070 [01:29<00:33,  8.94it/s] 72%|███████▏  | 768/1070 [01:30<00:34,  8.87it/s] 72%|███████▏  | 769/1070 [01:30<00:33,  8.88it/s] 72%|███████▏  | 770/1070 [01:30<00:33,  8.95it/s] 72%|███████▏  | 771/1070 [01:30<00:33,  8.99it/s] 72%|███████▏  | 772/1070 [01:30<00:33,  8.96it/s] 72%|███████▏  | 773/1070 [01:30<00:33,  8.94it/s] 72%|███████▏  | 774/1070 [01:30<00:33,  8.90it/s] 72%|███████▏  | 775/1070 [01:30<00:33,  8.92it/s] 73%|███████▎  | 776/1070 [01:30<00:32,  8.95it/s] 73%|███████▎  | 777/1070 [01:31<00:32,  8.98it/s] 73%|███████▎  | 778/1070 [01:31<00:32,  8.96it/s] 73%|███████▎  | 779/1070 [01:31<00:32,  9.02it/s] 73%|███████▎  | 780/1070 [01:31<00:31,  9.11it/s] 73%|███████▎  | 781/1070 [01:31<00:31,  9.06it/s] 73%|███████▎  | 782/1070 [01:31<00:31,  9.06it/s] 73%|███████▎  | 783/1070 [01:31<00:31,  9.03it/s] 73%|███████▎  | 784/1070 [01:31<00:31,  9.01it/s] 73%|███████▎  | 785/1070 [01:31<00:31,  9.04it/s] 73%|███████▎  | 786/1070 [01:32<00:31,  9.01it/s] 74%|███████▎  | 787/1070 [01:32<00:31,  8.97it/s] 74%|███████▎  | 788/1070 [01:32<00:31,  8.94it/s] 74%|███████▎  | 789/1070 [01:32<00:31,  8.99it/s] 74%|███████▍  | 790/1070 [01:32<00:30,  9.08it/s] 74%|███████▍  | 791/1070 [01:32<00:31,  8.95it/s] 74%|███████▍  | 792/1070 [01:32<00:31,  8.94it/s] 74%|███████▍  | 793/1070 [01:32<00:30,  9.05it/s] 74%|███████▍  | 794/1070 [01:32<00:30,  9.02it/s] 74%|███████▍  | 795/1070 [01:33<00:30,  8.96it/s] 74%|███████▍  | 796/1070 [01:33<00:30,  8.89it/s] 74%|███████▍  | 797/1070 [01:33<00:30,  8.96it/s] 75%|███████▍  | 798/1070 [01:33<00:30,  8.95it/s] 75%|███████▍  | 799/1070 [01:33<00:30,  8.95it/s] 75%|███████▍  | 800/1070 [01:33<00:30,  8.92it/s] 75%|███████▍  | 801/1070 [01:33<00:30,  8.96it/s] 75%|███████▍  | 802/1070 [01:33<00:29,  9.00it/s] 75%|███████▌  | 803/1070 [01:33<00:29,  9.12it/s] 75%|███████▌  | 804/1070 [01:34<00:29,  9.09it/s] 75%|███████▌  | 805/1070 [01:34<00:29,  9.01it/s] 75%|███████▌  | 806/1070 [01:34<00:29,  9.03it/s] 75%|███████▌  | 807/1070 [01:34<00:29,  8.99it/s] 76%|███████▌  | 808/1070 [01:34<00:29,  9.01it/s] 76%|███████▌  | 809/1070 [01:34<00:29,  8.89it/s] 76%|███████▌  | 810/1070 [01:34<00:29,  8.95it/s] 76%|███████▌  | 811/1070 [01:34<00:28,  8.94it/s] 76%|███████▌  | 812/1070 [01:34<00:28,  9.01it/s] 76%|███████▌  | 813/1070 [01:35<00:28,  9.05it/s] 76%|███████▌  | 814/1070 [01:35<00:28,  8.96it/s] 76%|███████▌  | 815/1070 [01:35<00:28,  8.94it/s] 76%|███████▋  | 816/1070 [01:35<00:27,  9.12it/s] 76%|███████▋  | 817/1070 [01:35<00:27,  9.04it/s] 76%|███████▋  | 818/1070 [01:35<00:28,  8.99it/s] 77%|███████▋  | 819/1070 [01:35<00:28,  8.91it/s] 77%|███████▋  | 820/1070 [01:35<00:27,  9.00it/s] 77%|███████▋  | 821/1070 [01:35<00:27,  9.00it/s] 77%|███████▋  | 822/1070 [01:36<00:27,  8.95it/s] 77%|███████▋  | 823/1070 [01:36<00:27,  8.94it/s] 77%|███████▋  | 824/1070 [01:36<00:27,  8.91it/s] 77%|███████▋  | 825/1070 [01:36<00:27,  8.92it/s] 77%|███████▋  | 826/1070 [01:36<00:27,  9.02it/s] 77%|███████▋  | 827/1070 [01:36<00:27,  8.97it/s] 77%|███████▋  | 828/1070 [01:36<00:27,  8.90it/s] 77%|███████▋  | 829/1070 [01:36<00:26,  9.03it/s] 78%|███████▊  | 830/1070 [01:36<00:26,  8.99it/s] 78%|███████▊  | 831/1070 [01:37<00:26,  8.89it/s] 78%|███████▊  | 832/1070 [01:37<00:26,  8.90it/s] 78%|███████▊  | 833/1070 [01:37<00:26,  8.96it/s] 78%|███████▊  | 834/1070 [01:37<00:26,  8.98it/s] 78%|███████▊  | 835/1070 [01:37<00:26,  8.93it/s] 78%|███████▊  | 836/1070 [01:37<00:26,  8.92it/s] 78%|███████▊  | 837/1070 [01:37<00:26,  8.88it/s] 78%|███████▊  | 838/1070 [01:37<00:26,  8.92it/s] 78%|███████▊  | 839/1070 [01:37<00:25,  9.05it/s] 79%|███████▊  | 840/1070 [01:38<00:25,  8.99it/s] 79%|███████▊  | 841/1070 [01:38<00:25,  8.94it/s] 79%|███████▊  | 842/1070 [01:38<00:25,  8.98it/s] 79%|███████▉  | 843/1070 [01:38<00:25,  8.99it/s] 79%|███████▉  | 844/1070 [01:38<00:25,  8.98it/s] 79%|███████▉  | 845/1070 [01:38<00:25,  8.95it/s] 79%|███████▉  | 846/1070 [01:38<00:25,  8.89it/s] 79%|███████▉  | 847/1070 [01:38<00:24,  8.94it/s] 79%|███████▉  | 848/1070 [01:38<00:24,  8.93it/s] 79%|███████▉  | 849/1070 [01:39<00:24,  8.97it/s] 79%|███████▉  | 850/1070 [01:39<00:24,  8.95it/s] 80%|███████▉  | 851/1070 [01:39<00:24,  8.93it/s] 80%|███████▉  | 852/1070 [01:39<00:24,  9.02it/s] 80%|███████▉  | 853/1070 [01:39<00:24,  8.98it/s] 80%|███████▉  | 854/1070 [01:39<00:24,  8.90it/s] 80%|███████▉  | 855/1070 [01:39<00:24,  8.94it/s]                                                   80%|████████  | 856/1070 [01:39<00:23,  8.94it/s][INFO|trainer.py:755] 2023-11-15 21:42:22,252 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:42:22,253 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:42:22,254 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:42:22,254 >>   Batch size = 8
{'eval_loss': 0.34450599551200867, 'eval_accuracy': 0.9118421052631579, 'eval_micro_f1': 0.9118421052631579, 'eval_macro_f1': 0.9088920702590235, 'eval_runtime': 1.0156, 'eval_samples_per_second': 748.332, 'eval_steps_per_second': 93.542, 'epoch': 3.0}
{'loss': 0.117, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 81.24it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 71.08it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 72.59it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 72.81it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 71.52it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 70.66it/s][A
 61%|██████    | 58/95 [00:00<00:00, 70.92it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 71.76it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 73.17it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 71.85it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 69.93it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:41<00:23,  8.94it/s]
100%|██████████| 95/95 [00:01<00:00, 69.93it/s][A
                                               [A 80%|████████  | 857/1070 [01:41<01:30,  2.35it/s] 80%|████████  | 858/1070 [01:41<01:13,  2.88it/s] 80%|████████  | 859/1070 [01:41<01:00,  3.48it/s] 80%|████████  | 860/1070 [01:41<00:50,  4.16it/s] 80%|████████  | 861/1070 [01:41<00:42,  4.90it/s] 81%|████████  | 862/1070 [01:41<00:36,  5.64it/s] 81%|████████  | 863/1070 [01:41<00:32,  6.34it/s] 81%|████████  | 864/1070 [01:42<00:30,  6.85it/s] 81%|████████  | 865/1070 [01:42<00:27,  7.33it/s] 81%|████████  | 866/1070 [01:42<00:26,  7.80it/s] 81%|████████  | 867/1070 [01:42<00:25,  8.11it/s] 81%|████████  | 868/1070 [01:42<00:24,  8.34it/s] 81%|████████  | 869/1070 [01:42<00:23,  8.47it/s] 81%|████████▏ | 870/1070 [01:42<00:23,  8.66it/s] 81%|████████▏ | 871/1070 [01:42<00:22,  8.76it/s] 81%|████████▏ | 872/1070 [01:43<00:22,  8.73it/s] 82%|████████▏ | 873/1070 [01:43<00:22,  8.89it/s] 82%|████████▏ | 874/1070 [01:43<00:22,  8.86it/s] 82%|████████▏ | 875/1070 [01:43<00:21,  8.89it/s] 82%|████████▏ | 876/1070 [01:43<00:21,  9.01it/s] 82%|████████▏ | 877/1070 [01:43<00:21,  8.98it/s] 82%|████████▏ | 878/1070 [01:43<00:21,  8.96it/s] 82%|████████▏ | 879/1070 [01:43<00:21,  8.96it/s] 82%|████████▏ | 880/1070 [01:43<00:21,  8.99it/s] 82%|████████▏ | 881/1070 [01:44<00:21,  8.94it/s] 82%|████████▏ | 882/1070 [01:44<00:21,  8.90it/s] 83%|████████▎ | 883/1070 [01:44<00:20,  8.93it/s] 83%|████████▎ | 884/1070 [01:44<00:20,  8.96it/s] 83%|████████▎ | 885/1070 [01:44<00:20,  8.95it/s] 83%|████████▎ | 886/1070 [01:44<00:20,  9.00it/s] 83%|████████▎ | 887/1070 [01:44<00:20,  8.96it/s] 83%|████████▎ | 888/1070 [01:44<00:20,  8.97it/s] 83%|████████▎ | 889/1070 [01:44<00:19,  9.11it/s] 83%|████████▎ | 890/1070 [01:45<00:19,  9.08it/s] 83%|████████▎ | 891/1070 [01:45<00:19,  8.97it/s] 83%|████████▎ | 892/1070 [01:45<00:19,  8.98it/s] 83%|████████▎ | 893/1070 [01:45<00:19,  9.02it/s] 84%|████████▎ | 894/1070 [01:45<00:19,  9.03it/s] 84%|████████▎ | 895/1070 [01:45<00:19,  8.97it/s] 84%|████████▎ | 896/1070 [01:45<00:19,  8.99it/s] 84%|████████▍ | 897/1070 [01:45<00:19,  8.96it/s] 84%|████████▍ | 898/1070 [01:45<00:19,  8.99it/s] 84%|████████▍ | 899/1070 [01:46<00:19,  8.98it/s] 84%|████████▍ | 900/1070 [01:46<00:18,  9.03it/s] 84%|████████▍ | 901/1070 [01:46<00:18,  8.93it/s] 84%|████████▍ | 902/1070 [01:46<00:18,  8.97it/s] 84%|████████▍ | 903/1070 [01:46<00:18,  8.95it/s] 84%|████████▍ | 904/1070 [01:46<00:18,  8.85it/s] 85%|████████▍ | 905/1070 [01:46<00:18,  8.86it/s] 85%|████████▍ | 906/1070 [01:46<00:18,  8.82it/s] 85%|████████▍ | 907/1070 [01:46<00:18,  8.86it/s] 85%|████████▍ | 908/1070 [01:47<00:18,  8.91it/s] 85%|████████▍ | 909/1070 [01:47<00:17,  8.97it/s] 85%|████████▌ | 910/1070 [01:47<00:17,  8.93it/s] 85%|████████▌ | 911/1070 [01:47<00:17,  8.92it/s] 85%|████████▌ | 912/1070 [01:47<00:17,  9.04it/s] 85%|████████▌ | 913/1070 [01:47<00:17,  9.00it/s] 85%|████████▌ | 914/1070 [01:47<00:17,  8.90it/s] 86%|████████▌ | 915/1070 [01:47<00:17,  8.98it/s] 86%|████████▌ | 916/1070 [01:47<00:17,  8.98it/s] 86%|████████▌ | 917/1070 [01:48<00:16,  9.02it/s] 86%|████████▌ | 918/1070 [01:48<00:16,  9.00it/s] 86%|████████▌ | 919/1070 [01:48<00:16,  9.00it/s] 86%|████████▌ | 920/1070 [01:48<00:16,  8.99it/s] 86%|████████▌ | 921/1070 [01:48<00:16,  9.00it/s] 86%|████████▌ | 922/1070 [01:48<00:16,  8.99it/s] 86%|████████▋ | 923/1070 [01:48<00:16,  8.98it/s] 86%|████████▋ | 924/1070 [01:48<00:16,  8.92it/s] 86%|████████▋ | 925/1070 [01:48<00:16,  9.04it/s] 87%|████████▋ | 926/1070 [01:49<00:16,  8.91it/s] 87%|████████▋ | 927/1070 [01:49<00:16,  8.89it/s] 87%|████████▋ | 928/1070 [01:49<00:15,  8.98it/s] 87%|████████▋ | 929/1070 [01:49<00:15,  8.93it/s] 87%|████████▋ | 930/1070 [01:49<00:15,  8.88it/s] 87%|████████▋ | 931/1070 [01:49<00:15,  8.95it/s] 87%|████████▋ | 932/1070 [01:49<00:15,  8.99it/s] 87%|████████▋ | 933/1070 [01:49<00:15,  8.99it/s] 87%|████████▋ | 934/1070 [01:49<00:15,  8.97it/s] 87%|████████▋ | 935/1070 [01:50<00:15,  8.98it/s] 87%|████████▋ | 936/1070 [01:50<00:14,  8.96it/s] 88%|████████▊ | 937/1070 [01:50<00:14,  8.93it/s] 88%|████████▊ | 938/1070 [01:50<00:14,  9.06it/s] 88%|████████▊ | 939/1070 [01:50<00:14,  8.98it/s] 88%|████████▊ | 940/1070 [01:50<00:14,  9.01it/s] 88%|████████▊ | 941/1070 [01:50<00:14,  9.06it/s] 88%|████████▊ | 942/1070 [01:50<00:14,  9.05it/s] 88%|████████▊ | 943/1070 [01:50<00:14,  8.94it/s] 88%|████████▊ | 944/1070 [01:51<00:13,  9.06it/s] 88%|████████▊ | 945/1070 [01:51<00:13,  9.09it/s] 88%|████████▊ | 946/1070 [01:51<00:13,  8.99it/s] 89%|████████▊ | 947/1070 [01:51<00:13,  9.01it/s] 89%|████████▊ | 948/1070 [01:51<00:13,  8.98it/s] 89%|████████▊ | 949/1070 [01:51<00:13,  8.97it/s] 89%|████████▉ | 950/1070 [01:51<00:13,  9.00it/s] 89%|████████▉ | 951/1070 [01:51<00:13,  9.02it/s] 89%|████████▉ | 952/1070 [01:51<00:13,  8.96it/s] 89%|████████▉ | 953/1070 [01:52<00:13,  8.91it/s] 89%|████████▉ | 954/1070 [01:52<00:12,  9.01it/s] 89%|████████▉ | 955/1070 [01:52<00:12,  9.00it/s] 89%|████████▉ | 956/1070 [01:52<00:12,  8.92it/s] 89%|████████▉ | 957/1070 [01:52<00:12,  8.87it/s] 90%|████████▉ | 958/1070 [01:52<00:12,  8.94it/s] 90%|████████▉ | 959/1070 [01:52<00:12,  8.94it/s] 90%|████████▉ | 960/1070 [01:52<00:12,  8.94it/s] 90%|████████▉ | 961/1070 [01:52<00:12,  9.04it/s] 90%|████████▉ | 962/1070 [01:53<00:12,  8.95it/s] 90%|█████████ | 963/1070 [01:53<00:11,  8.96it/s] 90%|█████████ | 964/1070 [01:53<00:11,  9.06it/s] 90%|█████████ | 965/1070 [01:53<00:11,  9.04it/s] 90%|█████████ | 966/1070 [01:53<00:11,  8.89it/s] 90%|█████████ | 967/1070 [01:53<00:11,  8.88it/s] 90%|█████████ | 968/1070 [01:53<00:11,  8.87it/s] 91%|█████████ | 969/1070 [01:53<00:11,  8.90it/s] 91%|█████████ | 970/1070 [01:53<00:11,  8.88it/s] 91%|█████████ | 971/1070 [01:54<00:11,  8.96it/s] 91%|█████████ | 972/1070 [01:54<00:10,  8.92it/s] 91%|█████████ | 973/1070 [01:54<00:10,  8.92it/s] 91%|█████████ | 974/1070 [01:54<00:10,  9.03it/s] 91%|█████████ | 975/1070 [01:54<00:10,  9.00it/s] 91%|█████████ | 976/1070 [01:54<00:10,  8.93it/s] 91%|█████████▏| 977/1070 [01:54<00:10,  8.85it/s] 91%|█████████▏| 978/1070 [01:54<00:10,  8.88it/s] 91%|█████████▏| 979/1070 [01:54<00:10,  8.92it/s] 92%|█████████▏| 980/1070 [01:55<00:10,  8.90it/s] 92%|█████████▏| 981/1070 [01:55<00:10,  8.87it/s] 92%|█████████▏| 982/1070 [01:55<00:09,  8.86it/s] 92%|█████████▏| 983/1070 [01:55<00:09,  8.89it/s] 92%|█████████▏| 984/1070 [01:55<00:09,  8.97it/s] 92%|█████████▏| 985/1070 [01:55<00:09,  8.90it/s] 92%|█████████▏| 986/1070 [01:55<00:09,  8.89it/s] 92%|█████████▏| 987/1070 [01:55<00:09,  8.88it/s] 92%|█████████▏| 988/1070 [01:55<00:09,  8.90it/s] 92%|█████████▏| 989/1070 [01:56<00:09,  8.91it/s] 93%|█████████▎| 990/1070 [01:56<00:09,  8.81it/s] 93%|█████████▎| 991/1070 [01:56<00:08,  8.83it/s] 93%|█████████▎| 992/1070 [01:56<00:08,  8.86it/s] 93%|█████████▎| 993/1070 [01:56<00:08,  8.88it/s] 93%|█████████▎| 994/1070 [01:56<00:08,  9.02it/s] 93%|█████████▎| 995/1070 [01:56<00:08,  8.94it/s] 93%|█████████▎| 996/1070 [01:56<00:08,  8.82it/s] 93%|█████████▎| 997/1070 [01:56<00:08,  8.74it/s] 93%|█████████▎| 998/1070 [01:57<00:08,  8.74it/s] 93%|█████████▎| 999/1070 [01:57<00:08,  8.84it/s] 93%|█████████▎| 1000/1070 [01:57<00:07,  8.78it/s] 94%|█████████▎| 1001/1070 [01:57<00:07,  8.84it/s] 94%|█████████▎| 1002/1070 [01:57<00:07,  8.86it/s] 94%|█████████▎| 1003/1070 [01:57<00:07,  8.86it/s] 94%|█████████▍| 1004/1070 [01:57<00:07,  8.94it/s] 94%|█████████▍| 1005/1070 [01:57<00:07,  8.95it/s] 94%|█████████▍| 1006/1070 [01:57<00:07,  8.95it/s] 94%|█████████▍| 1007/1070 [01:58<00:07,  8.95it/s] 94%|█████████▍| 1008/1070 [01:58<00:06,  8.91it/s] 94%|█████████▍| 1009/1070 [01:58<00:06,  8.92it/s] 94%|█████████▍| 1010/1070 [01:58<00:06,  8.85it/s] 94%|█████████▍| 1011/1070 [01:58<00:06,  8.95it/s] 95%|█████████▍| 1012/1070 [01:58<00:06,  8.89it/s] 95%|█████████▍| 1013/1070 [01:58<00:06,  8.91it/s] 95%|█████████▍| 1014/1070 [01:58<00:06,  8.98it/s] 95%|█████████▍| 1015/1070 [01:58<00:06,  8.97it/s] 95%|█████████▍| 1016/1070 [01:59<00:06,  8.95it/s] 95%|█████████▌| 1017/1070 [01:59<00:05,  8.96it/s] 95%|█████████▌| 1018/1070 [01:59<00:05,  8.98it/s] 95%|█████████▌| 1019/1070 [01:59<00:05,  8.94it/s] 95%|█████████▌| 1020/1070 [01:59<00:05,  8.88it/s] 95%|█████████▌| 1021/1070 [01:59<00:05,  9.04it/s] 96%|█████████▌| 1022/1070 [01:59<00:05,  8.98it/s] 96%|█████████▌| 1023/1070 [01:59<00:05,  8.96it/s] 96%|█████████▌| 1024/1070 [01:59<00:05,  9.00it/s] 96%|█████████▌| 1025/1070 [02:00<00:04,  9.00it/s] 96%|█████████▌| 1026/1070 [02:00<00:04,  8.98it/s] 96%|█████████▌| 1027/1070 [02:00<00:04,  8.95it/s] 96%|█████████▌| 1028/1070 [02:00<00:04,  9.11it/s] 96%|█████████▌| 1029/1070 [02:00<00:04,  9.01it/s] 96%|█████████▋| 1030/1070 [02:00<00:04,  8.98it/s] 96%|█████████▋| 1031/1070 [02:00<00:04,  9.05it/s] 96%|█████████▋| 1032/1070 [02:00<00:04,  8.99it/s] 97%|█████████▋| 1033/1070 [02:00<00:04,  8.92it/s] 97%|█████████▋| 1034/1070 [02:01<00:04,  8.96it/s] 97%|█████████▋| 1035/1070 [02:01<00:03,  8.89it/s] 97%|█████████▋| 1036/1070 [02:01<00:03,  8.95it/s] 97%|█████████▋| 1037/1070 [02:01<00:03,  8.95it/s] 97%|█████████▋| 1038/1070 [02:01<00:03,  9.08it/s] 97%|█████████▋| 1039/1070 [02:01<00:03,  8.99it/s] 97%|█████████▋| 1040/1070 [02:01<00:03,  8.96it/s] 97%|█████████▋| 1041/1070 [02:01<00:03,  9.00it/s] 97%|█████████▋| 1042/1070 [02:01<00:03,  8.97it/s] 97%|█████████▋| 1043/1070 [02:02<00:02,  9.01it/s] 98%|█████████▊| 1044/1070 [02:02<00:02,  8.95it/s] 98%|█████████▊| 1045/1070 [02:02<00:02,  8.90it/s] 98%|█████████▊| 1046/1070 [02:02<00:02,  8.84it/s] 98%|█████████▊| 1047/1070 [02:02<00:02,  8.82it/s] 98%|█████████▊| 1048/1070 [02:02<00:02,  8.96it/s] 98%|█████████▊| 1049/1070 [02:02<00:02,  8.90it/s] 98%|█████████▊| 1050/1070 [02:02<00:02,  8.86it/s] 98%|█████████▊| 1051/1070 [02:03<00:02,  8.99it/s] 98%|█████████▊| 1052/1070 [02:03<00:02,  8.94it/s] 98%|█████████▊| 1053/1070 [02:03<00:01,  8.94it/s] 99%|█████████▊| 1054/1070 [02:03<00:01,  8.90it/s] 99%|█████████▊| 1055/1070 [02:03<00:01,  8.84it/s] 99%|█████████▊| 1056/1070 [02:03<00:01,  8.75it/s] 99%|█████████▉| 1057/1070 [02:03<00:01,  8.77it/s] 99%|█████████▉| 1058/1070 [02:03<00:01,  8.86it/s] 99%|█████████▉| 1059/1070 [02:03<00:01,  8.81it/s] 99%|█████████▉| 1060/1070 [02:04<00:01,  8.79it/s] 99%|█████████▉| 1061/1070 [02:04<00:01,  8.80it/s] 99%|█████████▉| 1062/1070 [02:04<00:00,  8.80it/s] 99%|█████████▉| 1063/1070 [02:04<00:00,  8.79it/s] 99%|█████████▉| 1064/1070 [02:04<00:00,  8.79it/s]100%|█████████▉| 1065/1070 [02:04<00:00,  8.86it/s]100%|█████████▉| 1066/1070 [02:04<00:00,  8.93it/s]100%|█████████▉| 1067/1070 [02:04<00:00,  8.92it/s]100%|█████████▉| 1068/1070 [02:04<00:00,  9.06it/s]100%|█████████▉| 1069/1070 [02:05<00:00,  8.95it/s]                                                   100%|██████████| 1070/1070 [02:05<00:00,  8.95it/s][INFO|trainer.py:755] 2023-11-15 21:42:47,552 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:42:47,553 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:42:47,554 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:42:47,554 >>   Batch size = 8
{'eval_loss': 0.36500003933906555, 'eval_accuracy': 0.9078947368421053, 'eval_micro_f1': 0.9078947368421053, 'eval_macro_f1': 0.9058744443710383, 'eval_runtime': 1.3698, 'eval_samples_per_second': 554.845, 'eval_steps_per_second': 69.356, 'epoch': 4.0}
{'loss': 0.084, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 79.76it/s][A
 18%|█▊        | 17/95 [00:00<00:01, 76.48it/s][A
 26%|██▋       | 25/95 [00:00<00:00, 74.39it/s][A
 35%|███▍      | 33/95 [00:00<00:00, 71.77it/s][A
 43%|████▎     | 41/95 [00:00<00:00, 70.94it/s][A
 52%|█████▏    | 49/95 [00:00<00:00, 71.61it/s][A
 60%|██████    | 57/95 [00:00<00:00, 72.43it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 74.17it/s][A
 77%|███████▋  | 73/95 [00:01<00:00, 71.06it/s][A
 85%|████████▌ | 81/95 [00:01<00:00, 72.16it/s][A
 94%|█████████▎| 89/95 [00:01<00:00, 71.60it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:06<00:00,  8.95it/s]
100%|██████████| 95/95 [00:01<00:00, 71.60it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 21:42:48,917 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:06<00:00,  8.95it/s]100%|██████████| 1070/1070 [02:06<00:00,  8.46it/s]
[INFO|trainer.py:2855] 2023-11-15 21:42:48,920 >> Saving model checkpoint to ./result/agnews_sup_roberta-base_adapter__seed4
[INFO|configuration_utils.py:460] 2023-11-15 21:42:48,924 >> Configuration saved in ./result/agnews_sup_roberta-base_adapter__seed4/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:42:50,082 >> Model weights saved in ./result/agnews_sup_roberta-base_adapter__seed4/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:42:50,085 >> tokenizer config file saved in ./result/agnews_sup_roberta-base_adapter__seed4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:42:50,088 >> Special tokens file saved in ./result/agnews_sup_roberta-base_adapter__seed4/special_tokens_map.json
{'eval_loss': 0.35296523571014404, 'eval_accuracy': 0.9131578947368421, 'eval_micro_f1': 0.9131578947368421, 'eval_macro_f1': 0.9107940036954472, 'eval_runtime': 1.3592, 'eval_samples_per_second': 559.15, 'eval_steps_per_second': 69.894, 'epoch': 5.0}
{'train_runtime': 126.5107, 'train_samples_per_second': 270.333, 'train_steps_per_second': 8.458, 'train_loss': 0.20550031751115747, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2055
  train_runtime            = 0:02:06.51
  train_samples            =       6840
  train_samples_per_second =    270.333
  train_steps_per_second   =      8.458
11/15/2023 21:42:50 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:42:50,186 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:42:50,188 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:42:50,188 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:42:50,188 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  9%|▉         | 9/95 [00:00<00:01, 85.81it/s] 19%|█▉        | 18/95 [00:00<00:00, 77.89it/s] 27%|██▋       | 26/95 [00:00<00:00, 74.21it/s] 36%|███▌      | 34/95 [00:00<00:00, 73.00it/s] 44%|████▍     | 42/95 [00:00<00:00, 71.43it/s] 53%|█████▎    | 50/95 [00:00<00:00, 71.08it/s] 61%|██████    | 58/95 [00:00<00:00, 70.55it/s] 69%|██████▉   | 66/95 [00:00<00:00, 71.82it/s] 78%|███████▊  | 74/95 [00:01<00:00, 68.98it/s] 86%|████████▋ | 82/95 [00:01<00:00, 69.84it/s] 95%|█████████▍| 90/95 [00:01<00:00, 71.29it/s]100%|██████████| 95/95 [00:01<00:00, 69.83it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9132
  eval_loss               =      0.353
  eval_macro_f1           =     0.9108
  eval_micro_f1           =     0.9132
  eval_runtime            = 0:00:01.37
  eval_samples            =        760
  eval_samples_per_second =    552.857
  eval_steps_per_second   =     69.107
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▅▆▁██
wandb:                      eval/loss ▁▁▆█▇▇
wandb:                  eval/macro_f1 ▁▅▆▂██
wandb:                  eval/micro_f1 ▁▅▆▁██
wandb:                   eval/runtime ▇▇▁███
wandb:        eval/samples_per_second ▂▁█▁▁▁
wandb:          eval/steps_per_second ▂▁█▁▁▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▂▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.91316
wandb:                      eval/loss 0.35297
wandb:                  eval/macro_f1 0.91079
wandb:                  eval/micro_f1 0.91316
wandb:                   eval/runtime 1.3747
wandb:        eval/samples_per_second 552.857
wandb:          eval/steps_per_second 69.107
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.084
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.2055
wandb:            train/train_runtime 126.5107
wandb: train/train_samples_per_second 270.333
wandb:   train/train_steps_per_second 8.458
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_213925-a3ghb5wr
wandb: Find logs at: ./wandb/offline-run-20231115_213925-a3ghb5wr/logs
(ModelArguments(model_name_or_path='bert-base-cased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_bert-base-cased_adapter__seed4/runs/Nov15_21-43-00_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_bert-base-cased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_bert-base-cased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:43:00 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:43:00 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_bert-base-cased_adapter__seed4/runs/Nov15_21-43-00_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_bert-base-cased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_bert-base-cased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 21:43:16,344 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:43:16,355 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:715] 2023-11-15 21:43:26,416 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:43:26,417 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:43:26,420 >> loading file vocab.txt from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:43:26,420 >> loading file tokenizer.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer.json
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:43:26,420 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:43:26,421 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:43:26,421 >> loading file tokenizer_config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-11-15 21:43:26,422 >> loading configuration file config.json from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:43:26,423 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:43:46,562 >> loading weights file model.safetensors from cache at ./cache/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/model.safetensors
[INFO|modeling_utils.py:3638] 2023-11-15 21:43:47,200 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:43:47,201 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 512
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  44%|████▍     | 3000/6840 [00:00<00:00, 19544.30 examples/s]Running tokenizer on dataset:  73%|███████▎  | 5000/6840 [00:00<00:00, 19368.46 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 19475.68 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 21234.72 examples/s]
11/15/2023 21:43:47 - INFO - __main__ - Sample 1583 of the training set: {'text': 'SA-India Test: South Africa declare at 510 for 9 : Sports India: Cricket  gt; Kanpur, Nov 22 : South Africa declared their first innings at 510 for nine on the third day of the first cricket Test against India here today.', 'label': 0, 'input_ids': [101, 13411, 118, 1726, 5960, 131, 1375, 2201, 14197, 1120, 26177, 1111, 130, 131, 3692, 1726, 131, 6811, 176, 1204, 132, 14812, 1179, 4093, 117, 14152, 1659, 131, 1375, 2201, 3332, 1147, 1148, 6687, 1120, 26177, 1111, 2551, 1113, 1103, 1503, 1285, 1104, 1103, 1148, 5428, 5960, 1222, 1726, 1303, 2052, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:43:47 - INFO - __main__ - Sample 2249 of the training set: {'text': 'FTSE 100 lifted by bright Dow The FTSE 100 has climbed as a surge by US shares gives a boost to European markets. Shire Pharmaceuticals SHP.L jumped after winning approval for a key drug and consumer goods giant Unilever ULVR.', 'label': 1, 'input_ids': [101, 143, 11365, 2036, 1620, 3358, 1118, 3999, 26535, 1109, 143, 11365, 2036, 1620, 1144, 5998, 1112, 170, 12814, 1118, 1646, 6117, 3114, 170, 14112, 1106, 1735, 5809, 119, 16108, 7642, 24275, 2093, 19748, 1116, 17730, 2101, 119, 149, 4874, 1170, 2183, 5684, 1111, 170, 2501, 3850, 1105, 8440, 4817, 4994, 12118, 4759, 4121, 158, 2162, 19400, 119, 102, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]}.
11/15/2023 21:43:47 - INFO - __main__ - Sample 1319 of the training set: {'text': 'Language of goals what counts for tongue-tied Ronnie and Michael England striker Michael Owen said his lack of Spanish and Ronaldo #39;s lack of English did not hinder celebrations of the Brazilian #39;s matchwinner for Real Madrid in Sunday #39;s 1-0 win at Mallorca.', 'label': 0, 'input_ids': [101, 6828, 1104, 2513, 1184, 10664, 1111, 3661, 118, 4353, 11715, 1105, 1847, 1652, 13074, 1847, 6761, 1163, 1117, 2960, 1104, 2124, 1105, 8565, 1186, 108, 3614, 132, 188, 2960, 1104, 1483, 1225, 1136, 24856, 1200, 12746, 1104, 1103, 5468, 108, 3614, 132, 188, 1801, 7445, 2511, 1111, 5230, 6331, 1107, 3625, 108, 3614, 132, 188, 122, 118, 121, 1782, 1120, 11123, 1766, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 21:43:47 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:43:49,037 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:43:49,045 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:43:49,046 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 21:43:49,046 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:43:49,046 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:43:49,046 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:43:49,047 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:43:49,047 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 21:43:49,048 >>   Number of trainable parameters = 108,313,348
[INFO|integration_utils.py:716] 2023-11-15 21:43:49,049 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<23:53,  1.34s/it]  0%|          | 2/1070 [00:01<11:01,  1.61it/s]  0%|          | 3/1070 [00:01<06:53,  2.58it/s]  0%|          | 4/1070 [00:01<04:56,  3.59it/s]  0%|          | 5/1070 [00:01<03:53,  4.57it/s]  1%|          | 6/1070 [00:01<03:15,  5.45it/s]  1%|          | 7/1070 [00:02<02:49,  6.25it/s]  1%|          | 8/1070 [00:02<02:34,  6.86it/s]  1%|          | 9/1070 [00:02<02:24,  7.36it/s]  1%|          | 10/1070 [00:02<02:15,  7.80it/s]  1%|          | 11/1070 [00:02<02:08,  8.22it/s]  1%|          | 12/1070 [00:02<02:05,  8.42it/s]  1%|          | 13/1070 [00:02<02:02,  8.63it/s]  1%|▏         | 14/1070 [00:02<02:02,  8.64it/s]  1%|▏         | 15/1070 [00:02<02:00,  8.75it/s]  1%|▏         | 16/1070 [00:03<02:01,  8.70it/s]  2%|▏         | 17/1070 [00:03<02:00,  8.77it/s]  2%|▏         | 18/1070 [00:03<01:58,  8.91it/s]  2%|▏         | 19/1070 [00:03<01:57,  8.91it/s]  2%|▏         | 20/1070 [00:03<01:57,  8.92it/s]  2%|▏         | 21/1070 [00:03<01:58,  8.88it/s]  2%|▏         | 22/1070 [00:03<01:57,  8.89it/s]  2%|▏         | 23/1070 [00:03<01:57,  8.92it/s]  2%|▏         | 24/1070 [00:03<01:57,  8.91it/s]  2%|▏         | 25/1070 [00:04<01:57,  8.89it/s]  2%|▏         | 26/1070 [00:04<01:57,  8.87it/s]  3%|▎         | 27/1070 [00:04<01:56,  8.96it/s]  3%|▎         | 28/1070 [00:04<01:54,  9.09it/s]  3%|▎         | 29/1070 [00:04<01:54,  9.10it/s]  3%|▎         | 30/1070 [00:04<01:54,  9.12it/s]  3%|▎         | 31/1070 [00:04<01:55,  9.00it/s]  3%|▎         | 32/1070 [00:04<01:54,  9.06it/s]  3%|▎         | 33/1070 [00:04<01:54,  9.05it/s]  3%|▎         | 34/1070 [00:05<01:55,  8.98it/s]  3%|▎         | 35/1070 [00:05<01:54,  9.04it/s]  3%|▎         | 36/1070 [00:05<01:55,  8.97it/s]  3%|▎         | 37/1070 [00:05<01:55,  8.95it/s]  4%|▎         | 38/1070 [00:05<01:53,  9.09it/s]  4%|▎         | 39/1070 [00:05<01:53,  9.07it/s]  4%|▎         | 40/1070 [00:05<01:54,  9.03it/s]  4%|▍         | 41/1070 [00:05<01:53,  9.04it/s]  4%|▍         | 42/1070 [00:05<01:53,  9.05it/s]  4%|▍         | 43/1070 [00:06<01:53,  9.03it/s]  4%|▍         | 44/1070 [00:06<01:53,  9.03it/s]  4%|▍         | 45/1070 [00:06<01:52,  9.10it/s]  4%|▍         | 46/1070 [00:06<01:53,  9.01it/s]  4%|▍         | 47/1070 [00:06<01:53,  8.99it/s]  4%|▍         | 48/1070 [00:06<01:53,  8.98it/s]  5%|▍         | 49/1070 [00:06<01:53,  8.98it/s]  5%|▍         | 50/1070 [00:06<01:53,  8.97it/s]  5%|▍         | 51/1070 [00:06<01:53,  8.98it/s]  5%|▍         | 52/1070 [00:07<01:53,  9.00it/s]  5%|▍         | 53/1070 [00:07<01:53,  8.96it/s]  5%|▌         | 54/1070 [00:07<01:52,  9.02it/s]  5%|▌         | 55/1070 [00:07<01:51,  9.12it/s]  5%|▌         | 56/1070 [00:07<01:51,  9.11it/s]  5%|▌         | 57/1070 [00:07<01:51,  9.06it/s]  5%|▌         | 58/1070 [00:07<01:52,  9.02it/s]  6%|▌         | 59/1070 [00:07<01:51,  9.03it/s]  6%|▌         | 60/1070 [00:07<01:52,  9.00it/s]  6%|▌         | 61/1070 [00:08<01:51,  9.02it/s]  6%|▌         | 62/1070 [00:08<01:50,  9.13it/s]  6%|▌         | 63/1070 [00:08<01:51,  9.04it/s]  6%|▌         | 64/1070 [00:08<01:51,  9.04it/s]  6%|▌         | 65/1070 [00:08<01:51,  8.98it/s]  6%|▌         | 66/1070 [00:08<01:50,  9.05it/s]  6%|▋         | 67/1070 [00:08<01:50,  9.08it/s]  6%|▋         | 68/1070 [00:08<01:50,  9.07it/s]  6%|▋         | 69/1070 [00:08<01:51,  9.01it/s]  7%|▋         | 70/1070 [00:09<01:50,  9.03it/s]  7%|▋         | 71/1070 [00:09<01:50,  9.03it/s]  7%|▋         | 72/1070 [00:09<01:49,  9.12it/s]  7%|▋         | 73/1070 [00:09<01:49,  9.09it/s]  7%|▋         | 74/1070 [00:09<01:50,  9.00it/s]  7%|▋         | 75/1070 [00:09<01:49,  9.08it/s]  7%|▋         | 76/1070 [00:09<01:49,  9.05it/s]  7%|▋         | 77/1070 [00:09<01:49,  9.04it/s]  7%|▋         | 78/1070 [00:09<01:50,  8.98it/s]  7%|▋         | 79/1070 [00:10<01:48,  9.10it/s]  7%|▋         | 80/1070 [00:10<01:48,  9.11it/s]  8%|▊         | 81/1070 [00:10<01:49,  9.04it/s]  8%|▊         | 82/1070 [00:10<01:49,  8.99it/s]  8%|▊         | 83/1070 [00:10<01:49,  8.97it/s]  8%|▊         | 84/1070 [00:10<01:48,  9.07it/s]  8%|▊         | 85/1070 [00:10<01:48,  9.04it/s]  8%|▊         | 86/1070 [00:10<01:47,  9.14it/s]  8%|▊         | 87/1070 [00:10<01:48,  9.02it/s]  8%|▊         | 88/1070 [00:11<01:50,  8.90it/s]  8%|▊         | 89/1070 [00:11<01:49,  8.97it/s]  8%|▊         | 90/1070 [00:11<01:48,  9.00it/s]  9%|▊         | 91/1070 [00:11<01:48,  9.01it/s]  9%|▊         | 92/1070 [00:11<01:49,  8.96it/s]  9%|▊         | 93/1070 [00:11<01:49,  8.90it/s]  9%|▉         | 94/1070 [00:11<01:49,  8.94it/s]  9%|▉         | 95/1070 [00:11<01:48,  8.95it/s]  9%|▉         | 96/1070 [00:11<01:47,  9.05it/s]  9%|▉         | 97/1070 [00:12<01:47,  9.02it/s]  9%|▉         | 98/1070 [00:12<01:48,  8.97it/s]  9%|▉         | 99/1070 [00:12<01:47,  9.02it/s]  9%|▉         | 100/1070 [00:12<01:47,  9.00it/s]  9%|▉         | 101/1070 [00:12<01:47,  8.99it/s] 10%|▉         | 102/1070 [00:12<01:48,  8.93it/s] 10%|▉         | 103/1070 [00:12<01:47,  9.02it/s] 10%|▉         | 104/1070 [00:12<01:48,  8.94it/s] 10%|▉         | 105/1070 [00:12<01:47,  8.94it/s] 10%|▉         | 106/1070 [00:13<01:47,  8.97it/s] 10%|█         | 107/1070 [00:13<01:47,  8.96it/s] 10%|█         | 108/1070 [00:13<01:47,  8.94it/s] 10%|█         | 109/1070 [00:13<01:47,  8.97it/s] 10%|█         | 110/1070 [00:13<01:47,  8.96it/s] 10%|█         | 111/1070 [00:13<01:47,  8.91it/s] 10%|█         | 112/1070 [00:13<01:47,  8.91it/s] 11%|█         | 113/1070 [00:13<01:45,  9.03it/s] 11%|█         | 114/1070 [00:13<01:45,  9.02it/s] 11%|█         | 115/1070 [00:14<01:46,  8.99it/s] 11%|█         | 116/1070 [00:14<01:47,  8.88it/s] 11%|█         | 117/1070 [00:14<01:47,  8.88it/s] 11%|█         | 118/1070 [00:14<01:47,  8.89it/s] 11%|█         | 119/1070 [00:14<01:46,  8.93it/s] 11%|█         | 120/1070 [00:14<01:45,  9.04it/s] 11%|█▏        | 121/1070 [00:14<01:46,  8.94it/s] 11%|█▏        | 122/1070 [00:14<01:46,  8.90it/s] 11%|█▏        | 123/1070 [00:14<01:46,  8.92it/s] 12%|█▏        | 124/1070 [00:15<01:46,  8.92it/s] 12%|█▏        | 125/1070 [00:15<01:46,  8.86it/s] 12%|█▏        | 126/1070 [00:15<01:46,  8.83it/s] 12%|█▏        | 127/1070 [00:15<01:46,  8.86it/s] 12%|█▏        | 128/1070 [00:15<01:46,  8.83it/s] 12%|█▏        | 129/1070 [00:15<01:46,  8.85it/s] 12%|█▏        | 130/1070 [00:15<01:44,  9.00it/s] 12%|█▏        | 131/1070 [00:15<01:44,  8.96it/s] 12%|█▏        | 132/1070 [00:15<01:44,  8.95it/s] 12%|█▏        | 133/1070 [00:16<01:45,  8.90it/s] 13%|█▎        | 134/1070 [00:16<01:45,  8.86it/s] 13%|█▎        | 135/1070 [00:16<01:45,  8.85it/s] 13%|█▎        | 136/1070 [00:16<01:45,  8.89it/s] 13%|█▎        | 137/1070 [00:16<01:43,  8.98it/s] 13%|█▎        | 138/1070 [00:16<01:43,  8.98it/s] 13%|█▎        | 139/1070 [00:16<01:43,  8.99it/s] 13%|█▎        | 140/1070 [00:16<01:44,  8.93it/s] 13%|█▎        | 141/1070 [00:16<01:43,  8.98it/s] 13%|█▎        | 142/1070 [00:17<01:43,  8.98it/s] 13%|█▎        | 143/1070 [00:17<01:43,  8.94it/s] 13%|█▎        | 144/1070 [00:17<01:43,  8.97it/s] 14%|█▎        | 145/1070 [00:17<01:44,  8.89it/s] 14%|█▎        | 146/1070 [00:17<01:43,  8.89it/s] 14%|█▎        | 147/1070 [00:17<01:42,  8.98it/s] 14%|█▍        | 148/1070 [00:17<01:42,  8.96it/s] 14%|█▍        | 149/1070 [00:17<01:43,  8.88it/s] 14%|█▍        | 150/1070 [00:17<01:43,  8.86it/s] 14%|█▍        | 151/1070 [00:18<01:43,  8.86it/s] 14%|█▍        | 152/1070 [00:18<01:43,  8.90it/s] 14%|█▍        | 153/1070 [00:18<01:42,  8.95it/s] 14%|█▍        | 154/1070 [00:18<01:41,  9.03it/s] 14%|█▍        | 155/1070 [00:18<01:42,  8.96it/s] 15%|█▍        | 156/1070 [00:18<01:41,  8.98it/s] 15%|█▍        | 157/1070 [00:18<01:42,  8.92it/s] 15%|█▍        | 158/1070 [00:18<01:41,  8.95it/s] 15%|█▍        | 159/1070 [00:18<01:42,  8.89it/s] 15%|█▍        | 160/1070 [00:19<01:42,  8.84it/s] 15%|█▌        | 161/1070 [00:19<01:41,  8.95it/s] 15%|█▌        | 162/1070 [00:19<01:41,  8.91it/s] 15%|█▌        | 163/1070 [00:19<01:41,  8.95it/s] 15%|█▌        | 164/1070 [00:19<01:40,  9.01it/s] 15%|█▌        | 165/1070 [00:19<01:41,  8.93it/s] 16%|█▌        | 166/1070 [00:19<01:40,  9.00it/s] 16%|█▌        | 167/1070 [00:19<01:40,  8.98it/s] 16%|█▌        | 168/1070 [00:19<01:40,  8.94it/s] 16%|█▌        | 169/1070 [00:20<01:41,  8.85it/s] 16%|█▌        | 170/1070 [00:20<01:41,  8.88it/s] 16%|█▌        | 171/1070 [00:20<01:40,  8.94it/s] 16%|█▌        | 172/1070 [00:20<01:40,  8.98it/s] 16%|█▌        | 173/1070 [00:20<01:40,  8.95it/s] 16%|█▋        | 174/1070 [00:20<01:40,  8.91it/s] 16%|█▋        | 175/1070 [00:20<01:40,  8.92it/s] 16%|█▋        | 176/1070 [00:20<01:39,  8.97it/s] 17%|█▋        | 177/1070 [00:20<01:40,  8.93it/s] 17%|█▋        | 178/1070 [00:21<01:39,  8.99it/s] 17%|█▋        | 179/1070 [00:21<01:40,  8.91it/s] 17%|█▋        | 180/1070 [00:21<01:40,  8.88it/s] 17%|█▋        | 181/1070 [00:21<01:39,  8.97it/s] 17%|█▋        | 182/1070 [00:21<01:39,  8.96it/s] 17%|█▋        | 183/1070 [00:21<01:38,  8.97it/s] 17%|█▋        | 184/1070 [00:21<01:39,  8.89it/s] 17%|█▋        | 185/1070 [00:21<01:40,  8.82it/s] 17%|█▋        | 186/1070 [00:21<01:39,  8.86it/s] 17%|█▋        | 187/1070 [00:22<01:39,  8.86it/s] 18%|█▊        | 188/1070 [00:22<01:38,  8.96it/s] 18%|█▊        | 189/1070 [00:22<01:38,  8.93it/s] 18%|█▊        | 190/1070 [00:22<01:38,  8.92it/s] 18%|█▊        | 191/1070 [00:22<01:39,  8.86it/s] 18%|█▊        | 192/1070 [00:22<01:38,  8.88it/s] 18%|█▊        | 193/1070 [00:22<01:38,  8.87it/s] 18%|█▊        | 194/1070 [00:22<01:38,  8.86it/s] 18%|█▊        | 195/1070 [00:22<01:37,  8.95it/s] 18%|█▊        | 196/1070 [00:23<01:38,  8.87it/s] 18%|█▊        | 197/1070 [00:23<01:38,  8.84it/s] 19%|█▊        | 198/1070 [00:23<01:37,  8.94it/s] 19%|█▊        | 199/1070 [00:23<01:37,  8.94it/s] 19%|█▊        | 200/1070 [00:23<01:38,  8.83it/s] 19%|█▉        | 201/1070 [00:23<01:38,  8.81it/s] 19%|█▉        | 202/1070 [00:23<01:38,  8.81it/s] 19%|█▉        | 203/1070 [00:23<01:38,  8.79it/s] 19%|█▉        | 204/1070 [00:24<01:38,  8.81it/s] 19%|█▉        | 205/1070 [00:24<01:36,  8.92it/s] 19%|█▉        | 206/1070 [00:24<01:37,  8.86it/s] 19%|█▉        | 207/1070 [00:24<01:37,  8.81it/s] 19%|█▉        | 208/1070 [00:24<01:37,  8.88it/s] 20%|█▉        | 209/1070 [00:24<01:36,  8.89it/s] 20%|█▉        | 210/1070 [00:24<01:37,  8.82it/s] 20%|█▉        | 211/1070 [00:24<01:36,  8.87it/s] 20%|█▉        | 212/1070 [00:24<01:36,  8.87it/s] 20%|█▉        | 213/1070 [00:25<01:35,  9.01it/s]                                                   20%|██        | 214/1070 [00:25<01:35,  9.01it/s][INFO|trainer.py:755] 2023-11-15 21:44:14,167 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:44:14,169 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:44:14,170 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:44:14,170 >>   Batch size = 8
{'loss': 0.5127, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 83.64it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 73.48it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 70.92it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 71.55it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 71.00it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 71.48it/s][A
 61%|██████    | 58/95 [00:00<00:00, 70.21it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 70.97it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 70.35it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 69.92it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 72.07it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:26<01:35,  9.01it/s]
100%|██████████| 95/95 [00:01<00:00, 72.07it/s][A
                                               [A 20%|██        | 215/1070 [00:26<06:06,  2.33it/s] 20%|██        | 216/1070 [00:26<04:59,  2.85it/s] 20%|██        | 217/1070 [00:26<04:06,  3.47it/s] 20%|██        | 218/1070 [00:26<03:24,  4.16it/s] 20%|██        | 219/1070 [00:27<02:53,  4.90it/s] 21%|██        | 220/1070 [00:27<02:31,  5.61it/s] 21%|██        | 221/1070 [00:27<02:15,  6.27it/s] 21%|██        | 222/1070 [00:27<02:03,  6.86it/s] 21%|██        | 223/1070 [00:27<01:54,  7.37it/s] 21%|██        | 224/1070 [00:27<01:48,  7.76it/s] 21%|██        | 225/1070 [00:27<01:44,  8.05it/s] 21%|██        | 226/1070 [00:27<01:41,  8.32it/s] 21%|██        | 227/1070 [00:27<01:39,  8.50it/s] 21%|██▏       | 228/1070 [00:28<01:37,  8.62it/s] 21%|██▏       | 229/1070 [00:28<01:36,  8.69it/s] 21%|██▏       | 230/1070 [00:28<01:34,  8.89it/s] 22%|██▏       | 231/1070 [00:28<01:35,  8.82it/s] 22%|██▏       | 232/1070 [00:28<01:35,  8.73it/s] 22%|██▏       | 233/1070 [00:28<01:35,  8.76it/s] 22%|██▏       | 234/1070 [00:28<01:34,  8.86it/s] 22%|██▏       | 235/1070 [00:28<01:33,  8.91it/s] 22%|██▏       | 236/1070 [00:28<01:33,  8.94it/s] 22%|██▏       | 237/1070 [00:29<01:32,  8.97it/s] 22%|██▏       | 238/1070 [00:29<01:33,  8.90it/s] 22%|██▏       | 239/1070 [00:29<01:33,  8.90it/s] 22%|██▏       | 240/1070 [00:29<01:32,  8.96it/s] 23%|██▎       | 241/1070 [00:29<01:32,  8.96it/s] 23%|██▎       | 242/1070 [00:29<01:32,  8.91it/s] 23%|██▎       | 243/1070 [00:29<01:32,  8.93it/s] 23%|██▎       | 244/1070 [00:29<01:32,  8.95it/s] 23%|██▎       | 245/1070 [00:29<01:32,  8.91it/s] 23%|██▎       | 246/1070 [00:30<01:32,  8.91it/s] 23%|██▎       | 247/1070 [00:30<01:31,  9.02it/s] 23%|██▎       | 248/1070 [00:30<01:31,  9.01it/s] 23%|██▎       | 249/1070 [00:30<01:32,  8.86it/s] 23%|██▎       | 250/1070 [00:30<01:32,  8.90it/s] 23%|██▎       | 251/1070 [00:30<01:31,  8.90it/s] 24%|██▎       | 252/1070 [00:30<01:32,  8.86it/s] 24%|██▎       | 253/1070 [00:30<01:31,  8.91it/s] 24%|██▎       | 254/1070 [00:30<01:31,  8.95it/s] 24%|██▍       | 255/1070 [00:31<01:31,  8.91it/s] 24%|██▍       | 256/1070 [00:31<01:30,  8.95it/s] 24%|██▍       | 257/1070 [00:31<01:30,  8.97it/s] 24%|██▍       | 258/1070 [00:31<01:30,  8.97it/s] 24%|██▍       | 259/1070 [00:31<01:30,  8.98it/s] 24%|██▍       | 260/1070 [00:31<01:30,  8.94it/s] 24%|██▍       | 261/1070 [00:31<01:29,  9.03it/s] 24%|██▍       | 262/1070 [00:31<01:30,  8.89it/s] 25%|██▍       | 263/1070 [00:31<01:30,  8.88it/s] 25%|██▍       | 264/1070 [00:32<01:29,  8.98it/s] 25%|██▍       | 265/1070 [00:32<01:29,  8.98it/s] 25%|██▍       | 266/1070 [00:32<01:29,  8.96it/s] 25%|██▍       | 267/1070 [00:32<01:30,  8.89it/s] 25%|██▌       | 268/1070 [00:32<01:30,  8.86it/s] 25%|██▌       | 269/1070 [00:32<01:30,  8.87it/s] 25%|██▌       | 270/1070 [00:32<01:30,  8.83it/s] 25%|██▌       | 271/1070 [00:32<01:28,  9.00it/s] 25%|██▌       | 272/1070 [00:33<01:29,  8.95it/s] 26%|██▌       | 273/1070 [00:33<01:29,  8.90it/s] 26%|██▌       | 274/1070 [00:33<01:29,  8.91it/s] 26%|██▌       | 275/1070 [00:33<01:28,  8.96it/s] 26%|██▌       | 276/1070 [00:33<01:29,  8.90it/s] 26%|██▌       | 277/1070 [00:33<01:28,  8.92it/s] 26%|██▌       | 278/1070 [00:33<01:28,  8.99it/s] 26%|██▌       | 279/1070 [00:33<01:28,  8.90it/s] 26%|██▌       | 280/1070 [00:33<01:28,  8.93it/s] 26%|██▋       | 281/1070 [00:34<01:27,  9.06it/s] 26%|██▋       | 282/1070 [00:34<01:27,  9.01it/s] 26%|██▋       | 283/1070 [00:34<01:27,  9.03it/s] 27%|██▋       | 284/1070 [00:34<01:28,  8.92it/s] 27%|██▋       | 285/1070 [00:34<01:27,  8.92it/s] 27%|██▋       | 286/1070 [00:34<01:28,  8.90it/s] 27%|██▋       | 287/1070 [00:34<01:27,  8.98it/s] 27%|██▋       | 288/1070 [00:34<01:26,  9.05it/s] 27%|██▋       | 289/1070 [00:34<01:27,  8.97it/s] 27%|██▋       | 290/1070 [00:35<01:27,  8.90it/s] 27%|██▋       | 291/1070 [00:35<01:27,  8.94it/s] 27%|██▋       | 292/1070 [00:35<01:26,  8.97it/s] 27%|██▋       | 293/1070 [00:35<01:26,  9.01it/s] 27%|██▋       | 294/1070 [00:35<01:26,  8.93it/s] 28%|██▊       | 295/1070 [00:35<01:26,  8.97it/s] 28%|██▊       | 296/1070 [00:35<01:26,  8.97it/s] 28%|██▊       | 297/1070 [00:35<01:26,  8.96it/s] 28%|██▊       | 298/1070 [00:35<01:25,  9.01it/s] 28%|██▊       | 299/1070 [00:36<01:25,  9.01it/s] 28%|██▊       | 300/1070 [00:36<01:25,  9.00it/s] 28%|██▊       | 301/1070 [00:36<01:25,  8.96it/s] 28%|██▊       | 302/1070 [00:36<01:25,  9.00it/s] 28%|██▊       | 303/1070 [00:36<01:25,  9.00it/s] 28%|██▊       | 304/1070 [00:36<01:25,  8.99it/s] 29%|██▊       | 305/1070 [00:36<01:24,  9.06it/s] 29%|██▊       | 306/1070 [00:36<01:24,  9.01it/s] 29%|██▊       | 307/1070 [00:36<01:24,  8.98it/s] 29%|██▉       | 308/1070 [00:37<01:24,  9.04it/s] 29%|██▉       | 309/1070 [00:37<01:23,  9.07it/s] 29%|██▉       | 310/1070 [00:37<01:24,  8.99it/s] 29%|██▉       | 311/1070 [00:37<01:24,  8.97it/s] 29%|██▉       | 312/1070 [00:37<01:25,  8.86it/s] 29%|██▉       | 313/1070 [00:37<01:24,  8.92it/s] 29%|██▉       | 314/1070 [00:37<01:25,  8.89it/s] 29%|██▉       | 315/1070 [00:37<01:23,  9.00it/s] 30%|██▉       | 316/1070 [00:37<01:24,  8.97it/s] 30%|██▉       | 317/1070 [00:38<01:23,  8.98it/s] 30%|██▉       | 318/1070 [00:38<01:24,  8.93it/s] 30%|██▉       | 319/1070 [00:38<01:23,  8.96it/s] 30%|██▉       | 320/1070 [00:38<01:23,  9.02it/s] 30%|███       | 321/1070 [00:38<01:23,  8.98it/s] 30%|███       | 322/1070 [00:38<01:22,  9.02it/s] 30%|███       | 323/1070 [00:38<01:23,  8.95it/s] 30%|███       | 324/1070 [00:38<01:23,  8.96it/s] 30%|███       | 325/1070 [00:38<01:22,  9.05it/s] 30%|███       | 326/1070 [00:39<01:22,  9.00it/s] 31%|███       | 327/1070 [00:39<01:23,  8.90it/s] 31%|███       | 328/1070 [00:39<01:24,  8.80it/s] 31%|███       | 329/1070 [00:39<01:23,  8.82it/s] 31%|███       | 330/1070 [00:39<01:23,  8.83it/s] 31%|███       | 331/1070 [00:39<01:23,  8.90it/s] 31%|███       | 332/1070 [00:39<01:22,  8.98it/s] 31%|███       | 333/1070 [00:39<01:22,  8.95it/s] 31%|███       | 334/1070 [00:39<01:23,  8.86it/s] 31%|███▏      | 335/1070 [00:40<01:22,  8.95it/s] 31%|███▏      | 336/1070 [00:40<01:22,  8.94it/s] 31%|███▏      | 337/1070 [00:40<01:21,  8.95it/s] 32%|███▏      | 338/1070 [00:40<01:22,  8.89it/s] 32%|███▏      | 339/1070 [00:40<01:22,  8.89it/s] 32%|███▏      | 340/1070 [00:40<01:22,  8.86it/s] 32%|███▏      | 341/1070 [00:40<01:21,  8.95it/s] 32%|███▏      | 342/1070 [00:40<01:20,  9.02it/s] 32%|███▏      | 343/1070 [00:40<01:21,  8.92it/s] 32%|███▏      | 344/1070 [00:41<01:21,  8.92it/s] 32%|███▏      | 345/1070 [00:41<01:21,  8.90it/s] 32%|███▏      | 346/1070 [00:41<01:21,  8.92it/s] 32%|███▏      | 347/1070 [00:41<01:21,  8.92it/s] 33%|███▎      | 348/1070 [00:41<01:20,  8.92it/s] 33%|███▎      | 349/1070 [00:41<01:19,  9.03it/s] 33%|███▎      | 350/1070 [00:41<01:19,  9.02it/s] 33%|███▎      | 351/1070 [00:41<01:20,  8.98it/s] 33%|███▎      | 352/1070 [00:41<01:19,  9.01it/s] 33%|███▎      | 353/1070 [00:42<01:20,  8.96it/s] 33%|███▎      | 354/1070 [00:42<01:19,  9.02it/s] 33%|███▎      | 355/1070 [00:42<01:19,  8.99it/s] 33%|███▎      | 356/1070 [00:42<01:19,  8.93it/s] 33%|███▎      | 357/1070 [00:42<01:19,  8.93it/s] 33%|███▎      | 358/1070 [00:42<01:19,  8.90it/s] 34%|███▎      | 359/1070 [00:42<01:18,  9.06it/s] 34%|███▎      | 360/1070 [00:42<01:18,  9.02it/s] 34%|███▎      | 361/1070 [00:42<01:19,  8.91it/s] 34%|███▍      | 362/1070 [00:43<01:20,  8.83it/s] 34%|███▍      | 363/1070 [00:43<01:19,  8.86it/s] 34%|███▍      | 364/1070 [00:43<01:19,  8.84it/s] 34%|███▍      | 365/1070 [00:43<01:19,  8.89it/s] 34%|███▍      | 366/1070 [00:43<01:18,  8.99it/s] 34%|███▍      | 367/1070 [00:43<01:19,  8.89it/s] 34%|███▍      | 368/1070 [00:43<01:18,  8.91it/s] 34%|███▍      | 369/1070 [00:43<01:18,  8.94it/s] 35%|███▍      | 370/1070 [00:43<01:18,  8.91it/s] 35%|███▍      | 371/1070 [00:44<01:18,  8.95it/s] 35%|███▍      | 372/1070 [00:44<01:18,  8.89it/s] 35%|███▍      | 373/1070 [00:44<01:18,  8.89it/s] 35%|███▍      | 374/1070 [00:44<01:18,  8.86it/s] 35%|███▌      | 375/1070 [00:44<01:18,  8.88it/s] 35%|███▌      | 376/1070 [00:44<01:17,  8.97it/s] 35%|███▌      | 377/1070 [00:44<01:17,  9.00it/s] 35%|███▌      | 378/1070 [00:44<01:16,  9.00it/s] 35%|███▌      | 379/1070 [00:44<01:17,  8.96it/s] 36%|███▌      | 380/1070 [00:45<01:17,  8.94it/s] 36%|███▌      | 381/1070 [00:45<01:17,  8.92it/s] 36%|███▌      | 382/1070 [00:45<01:17,  8.90it/s] 36%|███▌      | 383/1070 [00:45<01:17,  8.92it/s] 36%|███▌      | 384/1070 [00:45<01:16,  8.91it/s] 36%|███▌      | 385/1070 [00:45<01:16,  8.90it/s] 36%|███▌      | 386/1070 [00:45<01:15,  9.01it/s] 36%|███▌      | 387/1070 [00:45<01:16,  8.91it/s] 36%|███▋      | 388/1070 [00:45<01:16,  8.94it/s] 36%|███▋      | 389/1070 [00:46<01:16,  8.84it/s] 36%|███▋      | 390/1070 [00:46<01:16,  8.89it/s] 37%|███▋      | 391/1070 [00:46<01:16,  8.89it/s] 37%|███▋      | 392/1070 [00:46<01:16,  8.91it/s] 37%|███▋      | 393/1070 [00:46<01:15,  9.02it/s] 37%|███▋      | 394/1070 [00:46<01:15,  8.95it/s] 37%|███▋      | 395/1070 [00:46<01:15,  8.89it/s] 37%|███▋      | 396/1070 [00:46<01:15,  8.93it/s] 37%|███▋      | 397/1070 [00:46<01:15,  8.96it/s] 37%|███▋      | 398/1070 [00:47<01:14,  8.99it/s] 37%|███▋      | 399/1070 [00:47<01:14,  8.97it/s] 37%|███▋      | 400/1070 [00:47<01:14,  8.98it/s] 37%|███▋      | 401/1070 [00:47<01:14,  9.01it/s] 38%|███▊      | 402/1070 [00:47<01:14,  8.98it/s] 38%|███▊      | 403/1070 [00:47<01:13,  9.11it/s] 38%|███▊      | 404/1070 [00:47<01:13,  9.01it/s] 38%|███▊      | 405/1070 [00:47<01:13,  9.06it/s] 38%|███▊      | 406/1070 [00:47<01:13,  9.03it/s] 38%|███▊      | 407/1070 [00:48<01:13,  8.99it/s] 38%|███▊      | 408/1070 [00:48<01:13,  8.98it/s] 38%|███▊      | 409/1070 [00:48<01:13,  8.99it/s] 38%|███▊      | 410/1070 [00:48<01:12,  9.07it/s] 38%|███▊      | 411/1070 [00:48<01:14,  8.90it/s] 39%|███▊      | 412/1070 [00:48<01:14,  8.85it/s] 39%|███▊      | 413/1070 [00:48<01:14,  8.86it/s] 39%|███▊      | 414/1070 [00:48<01:14,  8.86it/s] 39%|███▉      | 415/1070 [00:48<01:13,  8.89it/s] 39%|███▉      | 416/1070 [00:49<01:13,  8.89it/s] 39%|███▉      | 417/1070 [00:49<01:13,  8.87it/s] 39%|███▉      | 418/1070 [00:49<01:13,  8.85it/s] 39%|███▉      | 419/1070 [00:49<01:13,  8.87it/s] 39%|███▉      | 420/1070 [00:49<01:12,  9.02it/s] 39%|███▉      | 421/1070 [00:49<01:12,  8.95it/s] 39%|███▉      | 422/1070 [00:49<01:12,  8.94it/s] 40%|███▉      | 423/1070 [00:49<01:12,  8.94it/s] 40%|███▉      | 424/1070 [00:49<01:12,  8.91it/s] 40%|███▉      | 425/1070 [00:50<01:12,  8.93it/s] 40%|███▉      | 426/1070 [00:50<01:12,  8.94it/s] 40%|███▉      | 427/1070 [00:50<01:10,  9.07it/s]                                                   40%|████      | 428/1070 [00:50<01:10,  9.07it/s][INFO|trainer.py:755] 2023-11-15 21:44:39,472 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:44:39,474 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:44:39,474 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:44:39,475 >>   Batch size = 8
{'eval_loss': 0.3210129737854004, 'eval_accuracy': 0.9026315789473685, 'eval_micro_f1': 0.9026315789473685, 'eval_macro_f1': 0.9007040922016386, 'eval_runtime': 1.3811, 'eval_samples_per_second': 550.294, 'eval_steps_per_second': 68.787, 'epoch': 1.0}
{'loss': 0.2278, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 78.90it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 72.51it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 71.77it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 71.49it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 69.02it/s][A
 51%|█████     | 48/95 [00:00<00:00, 68.33it/s][A
 59%|█████▉    | 56/95 [00:00<00:00, 69.76it/s][A
 66%|██████▋   | 63/95 [00:00<00:00, 69.34it/s][A
 75%|███████▍  | 71/95 [00:01<00:00, 71.19it/s][A
 83%|████████▎ | 79/95 [00:01<00:00, 68.62it/s][A
 91%|█████████ | 86/95 [00:01<00:00, 68.70it/s][A
 99%|█████████▉| 94/95 [00:01<00:00, 69.15it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:51<01:10,  9.07it/s]
100%|██████████| 95/95 [00:01<00:00, 69.15it/s][A
                                               [A 40%|████      | 429/1070 [00:51<04:38,  2.31it/s] 40%|████      | 430/1070 [00:52<03:47,  2.82it/s] 40%|████      | 431/1070 [00:52<03:06,  3.42it/s] 40%|████      | 432/1070 [00:52<02:34,  4.12it/s] 40%|████      | 433/1070 [00:52<02:11,  4.85it/s] 41%|████      | 434/1070 [00:52<01:54,  5.56it/s] 41%|████      | 435/1070 [00:52<01:41,  6.26it/s] 41%|████      | 436/1070 [00:52<01:32,  6.87it/s] 41%|████      | 437/1070 [00:52<01:25,  7.39it/s] 41%|████      | 438/1070 [00:52<01:20,  7.88it/s] 41%|████      | 439/1070 [00:53<01:17,  8.12it/s] 41%|████      | 440/1070 [00:53<01:16,  8.29it/s] 41%|████      | 441/1070 [00:53<01:14,  8.46it/s] 41%|████▏     | 442/1070 [00:53<01:13,  8.55it/s] 41%|████▏     | 443/1070 [00:53<01:12,  8.66it/s] 41%|████▏     | 444/1070 [00:53<01:11,  8.81it/s] 42%|████▏     | 445/1070 [00:53<01:09,  8.93it/s] 42%|████▏     | 446/1070 [00:53<01:10,  8.89it/s] 42%|████▏     | 447/1070 [00:53<01:09,  8.96it/s] 42%|████▏     | 448/1070 [00:54<01:09,  8.96it/s] 42%|████▏     | 449/1070 [00:54<01:09,  8.98it/s] 42%|████▏     | 450/1070 [00:54<01:08,  9.01it/s] 42%|████▏     | 451/1070 [00:54<01:09,  8.96it/s] 42%|████▏     | 452/1070 [00:54<01:09,  8.94it/s] 42%|████▏     | 453/1070 [00:54<01:08,  8.96it/s] 42%|████▏     | 454/1070 [00:54<01:09,  8.91it/s] 43%|████▎     | 455/1070 [00:54<01:07,  9.06it/s] 43%|████▎     | 456/1070 [00:54<01:08,  9.01it/s] 43%|████▎     | 457/1070 [00:55<01:09,  8.87it/s] 43%|████▎     | 458/1070 [00:55<01:08,  8.88it/s] 43%|████▎     | 459/1070 [00:55<01:08,  8.94it/s] 43%|████▎     | 460/1070 [00:55<01:08,  8.92it/s] 43%|████▎     | 461/1070 [00:55<01:08,  8.93it/s] 43%|████▎     | 462/1070 [00:55<01:07,  9.06it/s] 43%|████▎     | 463/1070 [00:55<01:07,  9.02it/s] 43%|████▎     | 464/1070 [00:55<01:08,  8.90it/s] 43%|████▎     | 465/1070 [00:55<01:07,  8.98it/s] 44%|████▎     | 466/1070 [00:56<01:07,  8.93it/s] 44%|████▎     | 467/1070 [00:56<01:06,  9.02it/s] 44%|████▎     | 468/1070 [00:56<01:07,  8.93it/s] 44%|████▍     | 469/1070 [00:56<01:07,  8.90it/s] 44%|████▍     | 470/1070 [00:56<01:07,  8.89it/s] 44%|████▍     | 471/1070 [00:56<01:07,  8.86it/s] 44%|████▍     | 472/1070 [00:56<01:06,  9.02it/s] 44%|████▍     | 473/1070 [00:56<01:06,  8.98it/s] 44%|████▍     | 474/1070 [00:56<01:06,  8.90it/s] 44%|████▍     | 475/1070 [00:57<01:06,  8.89it/s] 44%|████▍     | 476/1070 [00:57<01:06,  8.88it/s] 45%|████▍     | 477/1070 [00:57<01:06,  8.91it/s] 45%|████▍     | 478/1070 [00:57<01:06,  8.89it/s] 45%|████▍     | 479/1070 [00:57<01:05,  8.98it/s] 45%|████▍     | 480/1070 [00:57<01:06,  8.94it/s] 45%|████▍     | 481/1070 [00:57<01:06,  8.90it/s] 45%|████▌     | 482/1070 [00:57<01:05,  8.96it/s] 45%|████▌     | 483/1070 [00:57<01:05,  8.91it/s] 45%|████▌     | 484/1070 [00:58<01:05,  8.95it/s] 45%|████▌     | 485/1070 [00:58<01:06,  8.82it/s] 45%|████▌     | 486/1070 [00:58<01:06,  8.84it/s] 46%|████▌     | 487/1070 [00:58<01:06,  8.78it/s] 46%|████▌     | 488/1070 [00:58<01:06,  8.81it/s] 46%|████▌     | 489/1070 [00:58<01:04,  8.95it/s] 46%|████▌     | 490/1070 [00:58<01:05,  8.86it/s] 46%|████▌     | 491/1070 [00:58<01:05,  8.85it/s] 46%|████▌     | 492/1070 [00:59<01:05,  8.87it/s] 46%|████▌     | 493/1070 [00:59<01:04,  8.89it/s] 46%|████▌     | 494/1070 [00:59<01:04,  8.89it/s] 46%|████▋     | 495/1070 [00:59<01:04,  8.89it/s] 46%|████▋     | 496/1070 [00:59<01:04,  8.97it/s] 46%|████▋     | 497/1070 [00:59<01:04,  8.90it/s] 47%|████▋     | 498/1070 [00:59<01:04,  8.85it/s] 47%|████▋     | 499/1070 [00:59<01:03,  8.92it/s] 47%|████▋     | 500/1070 [00:59<01:04,  8.88it/s] 47%|████▋     | 501/1070 [01:00<01:04,  8.86it/s] 47%|████▋     | 502/1070 [01:00<01:04,  8.76it/s] 47%|████▋     | 503/1070 [01:00<01:04,  8.77it/s] 47%|████▋     | 504/1070 [01:00<01:04,  8.79it/s] 47%|████▋     | 505/1070 [01:00<01:04,  8.81it/s] 47%|████▋     | 506/1070 [01:00<01:03,  8.93it/s] 47%|████▋     | 507/1070 [01:00<01:03,  8.92it/s] 47%|████▋     | 508/1070 [01:00<01:03,  8.87it/s] 48%|████▊     | 509/1070 [01:00<01:03,  8.88it/s] 48%|████▊     | 510/1070 [01:01<01:02,  8.90it/s] 48%|████▊     | 511/1070 [01:01<01:03,  8.85it/s] 48%|████▊     | 512/1070 [01:01<01:03,  8.83it/s] 48%|████▊     | 513/1070 [01:01<01:02,  8.90it/s] 48%|████▊     | 514/1070 [01:01<01:02,  8.94it/s] 48%|████▊     | 515/1070 [01:01<01:02,  8.82it/s] 48%|████▊     | 516/1070 [01:01<01:02,  8.92it/s] 48%|████▊     | 517/1070 [01:01<01:02,  8.91it/s] 48%|████▊     | 518/1070 [01:01<01:02,  8.87it/s] 49%|████▊     | 519/1070 [01:02<01:02,  8.88it/s] 49%|████▊     | 520/1070 [01:02<01:02,  8.85it/s] 49%|████▊     | 521/1070 [01:02<01:02,  8.75it/s] 49%|████▉     | 522/1070 [01:02<01:02,  8.81it/s] 49%|████▉     | 523/1070 [01:02<01:01,  8.94it/s] 49%|████▉     | 524/1070 [01:02<01:01,  8.86it/s] 49%|████▉     | 525/1070 [01:02<01:01,  8.84it/s] 49%|████▉     | 526/1070 [01:02<01:02,  8.77it/s] 49%|████▉     | 527/1070 [01:02<01:01,  8.79it/s] 49%|████▉     | 528/1070 [01:03<01:01,  8.81it/s] 49%|████▉     | 529/1070 [01:03<01:01,  8.76it/s] 50%|████▉     | 530/1070 [01:03<01:01,  8.85it/s] 50%|████▉     | 531/1070 [01:03<01:01,  8.79it/s] 50%|████▉     | 532/1070 [01:03<01:00,  8.85it/s] 50%|████▉     | 533/1070 [01:03<01:00,  8.95it/s] 50%|████▉     | 534/1070 [01:03<00:59,  8.93it/s] 50%|█████     | 535/1070 [01:03<01:00,  8.85it/s] 50%|█████     | 536/1070 [01:03<01:00,  8.85it/s] 50%|█████     | 537/1070 [01:04<01:00,  8.83it/s] 50%|█████     | 538/1070 [01:04<00:59,  8.90it/s] 50%|█████     | 539/1070 [01:04<00:59,  8.94it/s] 50%|█████     | 540/1070 [01:04<00:58,  9.02it/s] 51%|█████     | 541/1070 [01:04<00:59,  8.95it/s] 51%|█████     | 542/1070 [01:04<00:59,  8.91it/s] 51%|█████     | 543/1070 [01:04<00:59,  8.90it/s] 51%|█████     | 544/1070 [01:04<00:58,  9.00it/s] 51%|█████     | 545/1070 [01:04<00:58,  8.96it/s] 51%|█████     | 546/1070 [01:05<00:58,  8.96it/s] 51%|█████     | 547/1070 [01:05<00:58,  8.90it/s] 51%|█████     | 548/1070 [01:05<00:58,  8.86it/s] 51%|█████▏    | 549/1070 [01:05<00:58,  8.93it/s] 51%|█████▏    | 550/1070 [01:05<00:57,  9.02it/s] 51%|█████▏    | 551/1070 [01:05<00:57,  9.00it/s] 52%|█████▏    | 552/1070 [01:05<00:57,  8.96it/s] 52%|█████▏    | 553/1070 [01:05<00:58,  8.87it/s] 52%|█████▏    | 554/1070 [01:05<00:57,  8.94it/s] 52%|█████▏    | 555/1070 [01:06<00:57,  8.97it/s] 52%|█████▏    | 556/1070 [01:06<00:57,  8.91it/s] 52%|█████▏    | 557/1070 [01:06<00:57,  8.98it/s] 52%|█████▏    | 558/1070 [01:06<00:57,  8.95it/s] 52%|█████▏    | 559/1070 [01:06<00:57,  8.95it/s] 52%|█████▏    | 560/1070 [01:06<00:56,  9.02it/s] 52%|█████▏    | 561/1070 [01:06<00:56,  8.97it/s] 53%|█████▎    | 562/1070 [01:06<00:56,  8.96it/s] 53%|█████▎    | 563/1070 [01:06<00:57,  8.89it/s] 53%|█████▎    | 564/1070 [01:07<00:57,  8.85it/s] 53%|█████▎    | 565/1070 [01:07<00:56,  8.89it/s] 53%|█████▎    | 566/1070 [01:07<00:57,  8.82it/s] 53%|█████▎    | 567/1070 [01:07<00:56,  8.94it/s] 53%|█████▎    | 568/1070 [01:07<00:56,  8.87it/s] 53%|█████▎    | 569/1070 [01:07<00:56,  8.82it/s] 53%|█████▎    | 570/1070 [01:07<00:56,  8.91it/s] 53%|█████▎    | 571/1070 [01:07<00:55,  8.92it/s] 53%|█████▎    | 572/1070 [01:07<00:55,  8.92it/s] 54%|█████▎    | 573/1070 [01:08<00:56,  8.83it/s] 54%|█████▎    | 574/1070 [01:08<00:56,  8.84it/s] 54%|█████▎    | 575/1070 [01:08<00:55,  8.88it/s] 54%|█████▍    | 576/1070 [01:08<00:55,  8.87it/s] 54%|█████▍    | 577/1070 [01:08<00:55,  8.93it/s] 54%|█████▍    | 578/1070 [01:08<00:55,  8.90it/s] 54%|█████▍    | 579/1070 [01:08<00:55,  8.91it/s] 54%|█████▍    | 580/1070 [01:08<00:55,  8.84it/s] 54%|█████▍    | 581/1070 [01:09<00:54,  8.89it/s] 54%|█████▍    | 582/1070 [01:09<00:55,  8.84it/s] 54%|█████▍    | 583/1070 [01:09<00:55,  8.79it/s] 55%|█████▍    | 584/1070 [01:09<00:55,  8.77it/s] 55%|█████▍    | 585/1070 [01:09<00:55,  8.80it/s] 55%|█████▍    | 586/1070 [01:09<00:54,  8.83it/s] 55%|█████▍    | 587/1070 [01:09<00:53,  9.00it/s] 55%|█████▍    | 588/1070 [01:09<00:54,  8.91it/s] 55%|█████▌    | 589/1070 [01:09<00:54,  8.86it/s] 55%|█████▌    | 590/1070 [01:10<00:54,  8.86it/s] 55%|█████▌    | 591/1070 [01:10<00:53,  8.95it/s] 55%|█████▌    | 592/1070 [01:10<00:53,  8.94it/s] 55%|█████▌    | 593/1070 [01:10<00:53,  8.91it/s] 56%|█████▌    | 594/1070 [01:10<00:52,  8.98it/s] 56%|█████▌    | 595/1070 [01:10<00:53,  8.88it/s] 56%|█████▌    | 596/1070 [01:10<00:53,  8.89it/s] 56%|█████▌    | 597/1070 [01:10<00:53,  8.90it/s] 56%|█████▌    | 598/1070 [01:10<00:53,  8.90it/s] 56%|█████▌    | 599/1070 [01:11<00:52,  8.93it/s] 56%|█████▌    | 600/1070 [01:11<00:53,  8.85it/s] 56%|█████▌    | 601/1070 [01:11<00:52,  8.89it/s] 56%|█████▋    | 602/1070 [01:11<00:52,  8.85it/s] 56%|█████▋    | 603/1070 [01:11<00:52,  8.89it/s] 56%|█████▋    | 604/1070 [01:11<00:51,  9.04it/s] 57%|█████▋    | 605/1070 [01:11<00:51,  8.99it/s] 57%|█████▋    | 606/1070 [01:11<00:52,  8.91it/s] 57%|█████▋    | 607/1070 [01:11<00:52,  8.88it/s] 57%|█████▋    | 608/1070 [01:12<00:52,  8.86it/s] 57%|█████▋    | 609/1070 [01:12<00:51,  8.93it/s] 57%|█████▋    | 610/1070 [01:12<00:51,  8.92it/s] 57%|█████▋    | 611/1070 [01:12<00:51,  8.99it/s] 57%|█████▋    | 612/1070 [01:12<00:51,  8.94it/s] 57%|█████▋    | 613/1070 [01:12<00:51,  8.82it/s] 57%|█████▋    | 614/1070 [01:12<00:51,  8.89it/s] 57%|█████▋    | 615/1070 [01:12<00:51,  8.87it/s] 58%|█████▊    | 616/1070 [01:12<00:51,  8.85it/s] 58%|█████▊    | 617/1070 [01:13<00:51,  8.84it/s] 58%|█████▊    | 618/1070 [01:13<00:51,  8.84it/s] 58%|█████▊    | 619/1070 [01:13<00:50,  8.87it/s] 58%|█████▊    | 620/1070 [01:13<00:50,  8.89it/s] 58%|█████▊    | 621/1070 [01:13<00:49,  9.00it/s] 58%|█████▊    | 622/1070 [01:13<00:50,  8.86it/s] 58%|█████▊    | 623/1070 [01:13<00:50,  8.83it/s] 58%|█████▊    | 624/1070 [01:13<00:50,  8.89it/s] 58%|█████▊    | 625/1070 [01:13<00:49,  8.91it/s] 59%|█████▊    | 626/1070 [01:14<00:49,  8.93it/s] 59%|█████▊    | 627/1070 [01:14<00:49,  8.88it/s] 59%|█████▊    | 628/1070 [01:14<00:49,  8.94it/s] 59%|█████▉    | 629/1070 [01:14<00:49,  8.94it/s] 59%|█████▉    | 630/1070 [01:14<00:49,  8.90it/s] 59%|█████▉    | 631/1070 [01:14<00:48,  9.00it/s] 59%|█████▉    | 632/1070 [01:14<00:49,  8.93it/s] 59%|█████▉    | 633/1070 [01:14<00:49,  8.86it/s] 59%|█████▉    | 634/1070 [01:14<00:49,  8.81it/s] 59%|█████▉    | 635/1070 [01:15<00:49,  8.81it/s] 59%|█████▉    | 636/1070 [01:15<00:49,  8.79it/s] 60%|█████▉    | 637/1070 [01:15<00:48,  8.86it/s] 60%|█████▉    | 638/1070 [01:15<00:48,  8.96it/s] 60%|█████▉    | 639/1070 [01:15<00:48,  8.95it/s] 60%|█████▉    | 640/1070 [01:15<00:48,  8.89it/s] 60%|█████▉    | 641/1070 [01:15<00:47,  9.01it/s]                                                   60%|██████    | 642/1070 [01:15<00:47,  9.01it/s][INFO|trainer.py:755] 2023-11-15 21:45:04,911 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:45:04,913 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:45:04,913 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:45:04,913 >>   Batch size = 8
{'eval_loss': 0.3088924288749695, 'eval_accuracy': 0.8986842105263158, 'eval_micro_f1': 0.8986842105263158, 'eval_macro_f1': 0.8965614796896765, 'eval_runtime': 1.4086, 'eval_samples_per_second': 539.541, 'eval_steps_per_second': 67.443, 'epoch': 2.0}
{'loss': 0.1338, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 78.73it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 75.45it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 72.71it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 71.85it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 70.44it/s][A
 51%|█████     | 48/95 [00:00<00:00, 70.29it/s][A
 59%|█████▉    | 56/95 [00:00<00:00, 70.41it/s][A
 67%|██████▋   | 64/95 [00:00<00:00, 71.10it/s][A
 76%|███████▌  | 72/95 [00:01<00:00, 72.04it/s][A
 84%|████████▍ | 80/95 [00:01<00:00, 70.41it/s][A
 93%|█████████▎| 88/95 [00:01<00:00, 69.77it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:17<00:47,  9.01it/s]
100%|██████████| 95/95 [00:01<00:00, 69.77it/s][A
                                               [A 60%|██████    | 643/1070 [01:17<03:02,  2.34it/s] 60%|██████    | 644/1070 [01:17<02:29,  2.86it/s] 60%|██████    | 645/1070 [01:17<02:02,  3.47it/s] 60%|██████    | 646/1070 [01:17<01:42,  4.12it/s] 60%|██████    | 647/1070 [01:17<01:27,  4.84it/s] 61%|██████    | 648/1070 [01:17<01:15,  5.58it/s] 61%|██████    | 649/1070 [01:18<01:07,  6.28it/s] 61%|██████    | 650/1070 [01:18<01:00,  6.91it/s] 61%|██████    | 651/1070 [01:18<00:56,  7.38it/s] 61%|██████    | 652/1070 [01:18<00:53,  7.80it/s] 61%|██████    | 653/1070 [01:18<00:51,  8.10it/s] 61%|██████    | 654/1070 [01:18<00:49,  8.37it/s] 61%|██████    | 655/1070 [01:18<00:48,  8.62it/s] 61%|██████▏   | 656/1070 [01:18<00:47,  8.73it/s] 61%|██████▏   | 657/1070 [01:18<00:47,  8.73it/s] 61%|██████▏   | 658/1070 [01:19<00:46,  8.91it/s] 62%|██████▏   | 659/1070 [01:19<00:46,  8.92it/s] 62%|██████▏   | 660/1070 [01:19<00:46,  8.88it/s] 62%|██████▏   | 661/1070 [01:19<00:45,  8.94it/s] 62%|██████▏   | 662/1070 [01:19<00:45,  8.92it/s] 62%|██████▏   | 663/1070 [01:19<00:45,  8.99it/s] 62%|██████▏   | 664/1070 [01:19<00:45,  8.92it/s] 62%|██████▏   | 665/1070 [01:19<00:44,  9.08it/s] 62%|██████▏   | 666/1070 [01:19<00:44,  9.03it/s] 62%|██████▏   | 667/1070 [01:20<00:44,  9.01it/s] 62%|██████▏   | 668/1070 [01:20<00:43,  9.14it/s] 63%|██████▎   | 669/1070 [01:20<00:43,  9.13it/s] 63%|██████▎   | 670/1070 [01:20<00:44,  9.04it/s] 63%|██████▎   | 671/1070 [01:20<00:44,  9.02it/s] 63%|██████▎   | 672/1070 [01:20<00:44,  9.03it/s] 63%|██████▎   | 673/1070 [01:20<00:43,  9.05it/s] 63%|██████▎   | 674/1070 [01:20<00:43,  9.05it/s] 63%|██████▎   | 675/1070 [01:20<00:43,  9.01it/s] 63%|██████▎   | 676/1070 [01:21<00:43,  9.00it/s] 63%|██████▎   | 677/1070 [01:21<00:43,  8.95it/s] 63%|██████▎   | 678/1070 [01:21<00:43,  9.01it/s] 63%|██████▎   | 679/1070 [01:21<00:43,  8.90it/s] 64%|██████▎   | 680/1070 [01:21<00:43,  8.93it/s] 64%|██████▎   | 681/1070 [01:21<00:42,  9.08it/s] 64%|██████▎   | 682/1070 [01:21<00:43,  9.02it/s] 64%|██████▍   | 683/1070 [01:21<00:43,  8.95it/s] 64%|██████▍   | 684/1070 [01:21<00:43,  8.92it/s] 64%|██████▍   | 685/1070 [01:22<00:42,  8.96it/s] 64%|██████▍   | 686/1070 [01:22<00:42,  9.04it/s] 64%|██████▍   | 687/1070 [01:22<00:42,  9.02it/s] 64%|██████▍   | 688/1070 [01:22<00:42,  8.90it/s] 64%|██████▍   | 689/1070 [01:22<00:42,  8.92it/s] 64%|██████▍   | 690/1070 [01:22<00:42,  8.99it/s] 65%|██████▍   | 691/1070 [01:22<00:41,  9.11it/s] 65%|██████▍   | 692/1070 [01:22<00:42,  8.99it/s] 65%|██████▍   | 693/1070 [01:22<00:42,  8.97it/s] 65%|██████▍   | 694/1070 [01:23<00:41,  9.09it/s] 65%|██████▍   | 695/1070 [01:23<00:41,  9.08it/s] 65%|██████▌   | 696/1070 [01:23<00:41,  9.06it/s] 65%|██████▌   | 697/1070 [01:23<00:41,  8.99it/s] 65%|██████▌   | 698/1070 [01:23<00:41,  9.05it/s] 65%|██████▌   | 699/1070 [01:23<00:40,  9.06it/s] 65%|██████▌   | 700/1070 [01:23<00:40,  9.04it/s] 66%|██████▌   | 701/1070 [01:23<00:40,  9.11it/s] 66%|██████▌   | 702/1070 [01:23<00:40,  9.01it/s] 66%|██████▌   | 703/1070 [01:24<00:40,  8.98it/s] 66%|██████▌   | 704/1070 [01:24<00:40,  9.09it/s] 66%|██████▌   | 705/1070 [01:24<00:40,  9.01it/s] 66%|██████▌   | 706/1070 [01:24<00:40,  9.07it/s] 66%|██████▌   | 707/1070 [01:24<00:40,  8.97it/s] 66%|██████▌   | 708/1070 [01:24<00:40,  9.05it/s] 66%|██████▋   | 709/1070 [01:24<00:40,  9.02it/s] 66%|██████▋   | 710/1070 [01:24<00:40,  8.91it/s] 66%|██████▋   | 711/1070 [01:24<00:40,  8.86it/s] 67%|██████▋   | 712/1070 [01:25<00:40,  8.93it/s] 67%|██████▋   | 713/1070 [01:25<00:39,  8.95it/s] 67%|██████▋   | 714/1070 [01:25<00:39,  9.04it/s] 67%|██████▋   | 715/1070 [01:25<00:39,  8.97it/s] 67%|██████▋   | 716/1070 [01:25<00:39,  8.99it/s] 67%|██████▋   | 717/1070 [01:25<00:39,  9.02it/s] 67%|██████▋   | 718/1070 [01:25<00:39,  8.99it/s] 67%|██████▋   | 719/1070 [01:25<00:39,  8.99it/s] 67%|██████▋   | 720/1070 [01:25<00:38,  8.99it/s] 67%|██████▋   | 721/1070 [01:26<00:39,  8.91it/s] 67%|██████▋   | 722/1070 [01:26<00:38,  8.93it/s] 68%|██████▊   | 723/1070 [01:26<00:38,  8.96it/s] 68%|██████▊   | 724/1070 [01:26<00:38,  9.02it/s] 68%|██████▊   | 725/1070 [01:26<00:38,  8.92it/s] 68%|██████▊   | 726/1070 [01:26<00:38,  8.89it/s] 68%|██████▊   | 727/1070 [01:26<00:37,  9.05it/s] 68%|██████▊   | 728/1070 [01:26<00:38,  8.98it/s] 68%|██████▊   | 729/1070 [01:26<00:38,  8.95it/s] 68%|██████▊   | 730/1070 [01:27<00:37,  8.95it/s] 68%|██████▊   | 731/1070 [01:27<00:37,  8.93it/s] 68%|██████▊   | 732/1070 [01:27<00:37,  8.97it/s] 69%|██████▊   | 733/1070 [01:27<00:37,  8.87it/s] 69%|██████▊   | 734/1070 [01:27<00:37,  8.94it/s] 69%|██████▊   | 735/1070 [01:27<00:37,  8.90it/s] 69%|██████▉   | 736/1070 [01:27<00:37,  8.93it/s] 69%|██████▉   | 737/1070 [01:27<00:36,  9.06it/s] 69%|██████▉   | 738/1070 [01:27<00:36,  9.00it/s] 69%|██████▉   | 739/1070 [01:28<00:37,  8.92it/s] 69%|██████▉   | 740/1070 [01:28<00:37,  8.91it/s] 69%|██████▉   | 741/1070 [01:28<00:36,  9.02it/s] 69%|██████▉   | 742/1070 [01:28<00:36,  9.01it/s] 69%|██████▉   | 743/1070 [01:28<00:36,  8.91it/s] 70%|██████▉   | 744/1070 [01:28<00:36,  9.01it/s] 70%|██████▉   | 745/1070 [01:28<00:36,  8.94it/s] 70%|██████▉   | 746/1070 [01:28<00:36,  8.94it/s] 70%|██████▉   | 747/1070 [01:28<00:35,  9.04it/s] 70%|██████▉   | 748/1070 [01:29<00:35,  8.95it/s] 70%|███████   | 749/1070 [01:29<00:35,  8.94it/s] 70%|███████   | 750/1070 [01:29<00:35,  8.91it/s] 70%|███████   | 751/1070 [01:29<00:35,  8.93it/s] 70%|███████   | 752/1070 [01:29<00:35,  8.94it/s] 70%|███████   | 753/1070 [01:29<00:36,  8.80it/s] 70%|███████   | 754/1070 [01:29<00:35,  8.90it/s] 71%|███████   | 755/1070 [01:29<00:35,  8.94it/s] 71%|███████   | 756/1070 [01:29<00:35,  8.96it/s] 71%|███████   | 757/1070 [01:30<00:34,  9.09it/s] 71%|███████   | 758/1070 [01:30<00:34,  9.03it/s] 71%|███████   | 759/1070 [01:30<00:34,  8.97it/s] 71%|███████   | 760/1070 [01:30<00:34,  8.91it/s] 71%|███████   | 761/1070 [01:30<00:34,  8.96it/s] 71%|███████   | 762/1070 [01:30<00:34,  8.96it/s] 71%|███████▏  | 763/1070 [01:30<00:34,  8.95it/s] 71%|███████▏  | 764/1070 [01:30<00:33,  9.00it/s] 71%|███████▏  | 765/1070 [01:30<00:34,  8.96it/s] 72%|███████▏  | 766/1070 [01:31<00:33,  8.98it/s] 72%|███████▏  | 767/1070 [01:31<00:33,  9.11it/s] 72%|███████▏  | 768/1070 [01:31<00:33,  9.04it/s] 72%|███████▏  | 769/1070 [01:31<00:33,  8.92it/s] 72%|███████▏  | 770/1070 [01:31<00:33,  8.87it/s] 72%|███████▏  | 771/1070 [01:31<00:33,  8.96it/s] 72%|███████▏  | 772/1070 [01:31<00:33,  8.97it/s] 72%|███████▏  | 773/1070 [01:31<00:33,  8.97it/s] 72%|███████▏  | 774/1070 [01:31<00:32,  9.02it/s] 72%|███████▏  | 775/1070 [01:32<00:32,  8.98it/s] 73%|███████▎  | 776/1070 [01:32<00:32,  8.97it/s] 73%|███████▎  | 777/1070 [01:32<00:32,  9.07it/s] 73%|███████▎  | 778/1070 [01:32<00:32,  9.01it/s] 73%|███████▎  | 779/1070 [01:32<00:32,  8.98it/s] 73%|███████▎  | 780/1070 [01:32<00:32,  8.96it/s] 73%|███████▎  | 781/1070 [01:32<00:32,  9.01it/s] 73%|███████▎  | 782/1070 [01:32<00:32,  8.98it/s] 73%|███████▎  | 783/1070 [01:32<00:32,  8.88it/s] 73%|███████▎  | 784/1070 [01:33<00:32,  8.88it/s] 73%|███████▎  | 785/1070 [01:33<00:32,  8.90it/s] 73%|███████▎  | 786/1070 [01:33<00:31,  8.89it/s] 74%|███████▎  | 787/1070 [01:33<00:31,  8.97it/s] 74%|███████▎  | 788/1070 [01:33<00:31,  8.95it/s] 74%|███████▎  | 789/1070 [01:33<00:31,  8.95it/s] 74%|███████▍  | 790/1070 [01:33<00:31,  9.01it/s] 74%|███████▍  | 791/1070 [01:33<00:30,  9.04it/s] 74%|███████▍  | 792/1070 [01:33<00:30,  8.99it/s] 74%|███████▍  | 793/1070 [01:34<00:31,  8.93it/s] 74%|███████▍  | 794/1070 [01:34<00:31,  8.89it/s] 74%|███████▍  | 795/1070 [01:34<00:30,  8.92it/s] 74%|███████▍  | 796/1070 [01:34<00:30,  8.96it/s] 74%|███████▍  | 797/1070 [01:34<00:30,  9.04it/s] 75%|███████▍  | 798/1070 [01:34<00:30,  9.01it/s] 75%|███████▍  | 799/1070 [01:34<00:30,  9.00it/s] 75%|███████▍  | 800/1070 [01:34<00:29,  9.09it/s] 75%|███████▍  | 801/1070 [01:34<00:29,  9.03it/s] 75%|███████▍  | 802/1070 [01:35<00:29,  9.01it/s] 75%|███████▌  | 803/1070 [01:35<00:30,  8.88it/s] 75%|███████▌  | 804/1070 [01:35<00:29,  8.96it/s] 75%|███████▌  | 805/1070 [01:35<00:29,  8.94it/s] 75%|███████▌  | 806/1070 [01:35<00:29,  8.94it/s] 75%|███████▌  | 807/1070 [01:35<00:29,  9.02it/s] 76%|███████▌  | 808/1070 [01:35<00:29,  8.93it/s] 76%|███████▌  | 809/1070 [01:35<00:29,  8.92it/s] 76%|███████▌  | 810/1070 [01:35<00:28,  9.05it/s] 76%|███████▌  | 811/1070 [01:36<00:28,  8.99it/s] 76%|███████▌  | 812/1070 [01:36<00:28,  8.90it/s] 76%|███████▌  | 813/1070 [01:36<00:29,  8.85it/s] 76%|███████▌  | 814/1070 [01:36<00:28,  8.92it/s] 76%|███████▌  | 815/1070 [01:36<00:28,  8.99it/s] 76%|███████▋  | 816/1070 [01:36<00:28,  8.91it/s] 76%|███████▋  | 817/1070 [01:36<00:28,  8.98it/s] 76%|███████▋  | 818/1070 [01:36<00:28,  8.98it/s] 77%|███████▋  | 819/1070 [01:36<00:28,  8.94it/s] 77%|███████▋  | 820/1070 [01:37<00:27,  9.06it/s] 77%|███████▋  | 821/1070 [01:37<00:27,  9.03it/s] 77%|███████▋  | 822/1070 [01:37<00:27,  8.94it/s] 77%|███████▋  | 823/1070 [01:37<00:27,  9.01it/s] 77%|███████▋  | 824/1070 [01:37<00:27,  8.95it/s] 77%|███████▋  | 825/1070 [01:37<00:27,  8.97it/s] 77%|███████▋  | 826/1070 [01:37<00:27,  8.96it/s] 77%|███████▋  | 827/1070 [01:37<00:27,  8.97it/s] 77%|███████▋  | 828/1070 [01:37<00:27,  8.95it/s] 77%|███████▋  | 829/1070 [01:38<00:26,  9.03it/s] 78%|███████▊  | 830/1070 [01:38<00:26,  9.08it/s] 78%|███████▊  | 831/1070 [01:38<00:26,  8.95it/s] 78%|███████▊  | 832/1070 [01:38<00:26,  8.87it/s] 78%|███████▊  | 833/1070 [01:38<00:26,  9.01it/s] 78%|███████▊  | 834/1070 [01:38<00:26,  8.99it/s] 78%|███████▊  | 835/1070 [01:38<00:26,  8.91it/s] 78%|███████▊  | 836/1070 [01:38<00:26,  8.89it/s] 78%|███████▊  | 837/1070 [01:38<00:26,  8.93it/s] 78%|███████▊  | 838/1070 [01:39<00:25,  8.95it/s] 78%|███████▊  | 839/1070 [01:39<00:26,  8.88it/s] 79%|███████▊  | 840/1070 [01:39<00:25,  8.95it/s] 79%|███████▊  | 841/1070 [01:39<00:25,  8.91it/s] 79%|███████▊  | 842/1070 [01:39<00:25,  8.93it/s] 79%|███████▉  | 843/1070 [01:39<00:25,  9.05it/s] 79%|███████▉  | 844/1070 [01:39<00:25,  8.98it/s] 79%|███████▉  | 845/1070 [01:39<00:25,  8.94it/s] 79%|███████▉  | 846/1070 [01:39<00:25,  8.92it/s] 79%|███████▉  | 847/1070 [01:40<00:24,  8.96it/s] 79%|███████▉  | 848/1070 [01:40<00:24,  8.99it/s] 79%|███████▉  | 849/1070 [01:40<00:24,  8.92it/s] 79%|███████▉  | 850/1070 [01:40<00:24,  8.86it/s] 80%|███████▉  | 851/1070 [01:40<00:24,  8.94it/s] 80%|███████▉  | 852/1070 [01:40<00:24,  9.03it/s] 80%|███████▉  | 853/1070 [01:40<00:23,  9.05it/s] 80%|███████▉  | 854/1070 [01:40<00:24,  8.96it/s] 80%|███████▉  | 855/1070 [01:40<00:24,  8.92it/s]                                                   80%|████████  | 856/1070 [01:41<00:23,  8.92it/s][INFO|trainer.py:755] 2023-11-15 21:45:30,134 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:45:30,135 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:45:30,135 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:45:30,135 >>   Batch size = 8
{'eval_loss': 0.328220397233963, 'eval_accuracy': 0.9092105263157895, 'eval_micro_f1': 0.9092105263157895, 'eval_macro_f1': 0.9071110331648223, 'eval_runtime': 1.3805, 'eval_samples_per_second': 550.522, 'eval_steps_per_second': 68.815, 'epoch': 3.0}
{'loss': 0.0832, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 78.62it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 71.05it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 71.14it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 71.57it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 71.32it/s][A
 51%|█████     | 48/95 [00:00<00:00, 70.89it/s][A
 59%|█████▉    | 56/95 [00:00<00:00, 69.50it/s][A
 66%|██████▋   | 63/95 [00:00<00:00, 68.93it/s][A
 75%|███████▍  | 71/95 [00:01<00:00, 69.91it/s][A
 83%|████████▎ | 79/95 [00:01<00:00, 72.17it/s][A
 92%|█████████▏| 87/95 [00:01<00:00, 70.72it/s][A
100%|██████████| 95/95 [00:01<00:00, 69.61it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:42<00:23,  8.92it/s]
100%|██████████| 95/95 [00:01<00:00, 69.61it/s][A
                                               [A 80%|████████  | 857/1070 [01:42<01:31,  2.33it/s] 80%|████████  | 858/1070 [01:42<01:14,  2.84it/s] 80%|████████  | 859/1070 [01:42<01:00,  3.46it/s] 80%|████████  | 860/1070 [01:42<00:50,  4.14it/s] 80%|████████  | 861/1070 [01:43<00:42,  4.88it/s] 81%|████████  | 862/1070 [01:43<00:37,  5.60it/s] 81%|████████  | 863/1070 [01:43<00:33,  6.25it/s] 81%|████████  | 864/1070 [01:43<00:30,  6.80it/s] 81%|████████  | 865/1070 [01:43<00:28,  7.32it/s] 81%|████████  | 866/1070 [01:43<00:26,  7.77it/s] 81%|████████  | 867/1070 [01:43<00:25,  8.11it/s] 81%|████████  | 868/1070 [01:43<00:24,  8.21it/s] 81%|████████  | 869/1070 [01:43<00:24,  8.30it/s] 81%|████████▏ | 870/1070 [01:44<00:23,  8.61it/s] 81%|████████▏ | 871/1070 [01:44<00:22,  8.69it/s] 81%|████████▏ | 872/1070 [01:44<00:22,  8.68it/s] 82%|████████▏ | 873/1070 [01:44<00:22,  8.73it/s] 82%|████████▏ | 874/1070 [01:44<00:22,  8.81it/s] 82%|████████▏ | 875/1070 [01:44<00:22,  8.83it/s] 82%|████████▏ | 876/1070 [01:44<00:22,  8.76it/s] 82%|████████▏ | 877/1070 [01:44<00:21,  8.80it/s] 82%|████████▏ | 878/1070 [01:44<00:21,  8.84it/s] 82%|████████▏ | 879/1070 [01:45<00:21,  8.84it/s] 82%|████████▏ | 880/1070 [01:45<00:21,  8.94it/s] 82%|████████▏ | 881/1070 [01:45<00:21,  8.87it/s] 82%|████████▏ | 882/1070 [01:45<00:21,  8.90it/s] 83%|████████▎ | 883/1070 [01:45<00:20,  8.97it/s] 83%|████████▎ | 884/1070 [01:45<00:20,  8.91it/s] 83%|████████▎ | 885/1070 [01:45<00:20,  8.93it/s] 83%|████████▎ | 886/1070 [01:45<00:20,  8.95it/s] 83%|████████▎ | 887/1070 [01:45<00:20,  8.89it/s] 83%|████████▎ | 888/1070 [01:46<00:20,  8.89it/s] 83%|████████▎ | 889/1070 [01:46<00:20,  8.92it/s] 83%|████████▎ | 890/1070 [01:46<00:20,  8.95it/s] 83%|████████▎ | 891/1070 [01:46<00:20,  8.87it/s] 83%|████████▎ | 892/1070 [01:46<00:20,  8.84it/s] 83%|████████▎ | 893/1070 [01:46<00:19,  8.97it/s] 84%|████████▎ | 894/1070 [01:46<00:19,  8.96it/s] 84%|████████▎ | 895/1070 [01:46<00:19,  8.89it/s] 84%|████████▎ | 896/1070 [01:46<00:19,  8.88it/s] 84%|████████▍ | 897/1070 [01:47<00:19,  8.95it/s] 84%|████████▍ | 898/1070 [01:47<00:19,  8.93it/s] 84%|████████▍ | 899/1070 [01:47<00:19,  8.95it/s] 84%|████████▍ | 900/1070 [01:47<00:19,  8.89it/s] 84%|████████▍ | 901/1070 [01:47<00:19,  8.84it/s] 84%|████████▍ | 902/1070 [01:47<00:18,  8.90it/s] 84%|████████▍ | 903/1070 [01:47<00:18,  9.04it/s] 84%|████████▍ | 904/1070 [01:47<00:18,  8.95it/s] 85%|████████▍ | 905/1070 [01:47<00:18,  8.93it/s] 85%|████████▍ | 906/1070 [01:48<00:18,  8.92it/s] 85%|████████▍ | 907/1070 [01:48<00:18,  8.96it/s] 85%|████████▍ | 908/1070 [01:48<00:18,  8.96it/s] 85%|████████▍ | 909/1070 [01:48<00:18,  8.93it/s] 85%|████████▌ | 910/1070 [01:48<00:18,  8.83it/s] 85%|████████▌ | 911/1070 [01:48<00:17,  8.88it/s] 85%|████████▌ | 912/1070 [01:48<00:17,  8.92it/s] 85%|████████▌ | 913/1070 [01:48<00:17,  8.99it/s] 85%|████████▌ | 914/1070 [01:48<00:17,  8.93it/s] 86%|████████▌ | 915/1070 [01:49<00:17,  8.94it/s] 86%|████████▌ | 916/1070 [01:49<00:17,  9.05it/s] 86%|████████▌ | 917/1070 [01:49<00:16,  9.02it/s] 86%|████████▌ | 918/1070 [01:49<00:17,  8.94it/s] 86%|████████▌ | 919/1070 [01:49<00:16,  8.97it/s] 86%|████████▌ | 920/1070 [01:49<00:16,  8.99it/s] 86%|████████▌ | 921/1070 [01:49<00:16,  9.02it/s] 86%|████████▌ | 922/1070 [01:49<00:16,  8.93it/s] 86%|████████▋ | 923/1070 [01:49<00:16,  8.89it/s] 86%|████████▋ | 924/1070 [01:50<00:16,  8.91it/s] 86%|████████▋ | 925/1070 [01:50<00:16,  8.99it/s] 87%|████████▋ | 926/1070 [01:50<00:15,  9.07it/s] 87%|████████▋ | 927/1070 [01:50<00:15,  8.96it/s] 87%|████████▋ | 928/1070 [01:50<00:15,  8.92it/s] 87%|████████▋ | 929/1070 [01:50<00:15,  9.07it/s] 87%|████████▋ | 930/1070 [01:50<00:15,  9.02it/s] 87%|████████▋ | 931/1070 [01:50<00:15,  8.92it/s] 87%|████████▋ | 932/1070 [01:50<00:15,  8.92it/s] 87%|████████▋ | 933/1070 [01:51<00:15,  8.93it/s] 87%|████████▋ | 934/1070 [01:51<00:15,  8.98it/s] 87%|████████▋ | 935/1070 [01:51<00:15,  8.87it/s] 87%|████████▋ | 936/1070 [01:51<00:15,  8.92it/s] 88%|████████▊ | 937/1070 [01:51<00:14,  8.93it/s] 88%|████████▊ | 938/1070 [01:51<00:14,  8.95it/s] 88%|████████▊ | 939/1070 [01:51<00:14,  8.99it/s] 88%|████████▊ | 940/1070 [01:51<00:14,  8.98it/s] 88%|████████▊ | 941/1070 [01:52<00:14,  8.99it/s] 88%|████████▊ | 942/1070 [01:52<00:13,  9.15it/s] 88%|████████▊ | 943/1070 [01:52<00:13,  9.12it/s] 88%|████████▊ | 944/1070 [01:52<00:13,  9.04it/s] 88%|████████▊ | 945/1070 [01:52<00:13,  9.04it/s] 88%|████████▊ | 946/1070 [01:52<00:13,  9.05it/s] 89%|████████▊ | 947/1070 [01:52<00:13,  9.07it/s] 89%|████████▊ | 948/1070 [01:52<00:13,  8.98it/s] 89%|████████▊ | 949/1070 [01:52<00:13,  8.91it/s] 89%|████████▉ | 950/1070 [01:53<00:13,  8.88it/s] 89%|████████▉ | 951/1070 [01:53<00:13,  8.92it/s] 89%|████████▉ | 952/1070 [01:53<00:13,  9.00it/s] 89%|████████▉ | 953/1070 [01:53<00:13,  8.96it/s] 89%|████████▉ | 954/1070 [01:53<00:12,  8.94it/s] 89%|████████▉ | 955/1070 [01:53<00:12,  9.10it/s] 89%|████████▉ | 956/1070 [01:53<00:12,  9.08it/s] 89%|████████▉ | 957/1070 [01:53<00:12,  8.96it/s] 90%|████████▉ | 958/1070 [01:53<00:12,  8.91it/s] 90%|████████▉ | 959/1070 [01:54<00:12,  8.96it/s] 90%|████████▉ | 960/1070 [01:54<00:12,  9.00it/s] 90%|████████▉ | 961/1070 [01:54<00:12,  8.99it/s] 90%|████████▉ | 962/1070 [01:54<00:12,  8.89it/s] 90%|█████████ | 963/1070 [01:54<00:12,  8.88it/s] 90%|█████████ | 964/1070 [01:54<00:11,  8.93it/s] 90%|█████████ | 965/1070 [01:54<00:11,  9.03it/s] 90%|█████████ | 966/1070 [01:54<00:11,  8.97it/s] 90%|█████████ | 967/1070 [01:54<00:11,  8.91it/s] 90%|█████████ | 968/1070 [01:55<00:11,  9.04it/s] 91%|█████████ | 969/1070 [01:55<00:11,  9.01it/s] 91%|█████████ | 970/1070 [01:55<00:11,  9.01it/s] 91%|█████████ | 971/1070 [01:55<00:10,  9.03it/s] 91%|█████████ | 972/1070 [01:55<00:10,  8.98it/s] 91%|█████████ | 973/1070 [01:55<00:10,  8.98it/s] 91%|█████████ | 974/1070 [01:55<00:10,  8.96it/s] 91%|█████████ | 975/1070 [01:55<00:10,  9.00it/s] 91%|█████████ | 976/1070 [01:55<00:10,  8.90it/s] 91%|█████████▏| 977/1070 [01:56<00:10,  8.94it/s] 91%|█████████▏| 978/1070 [01:56<00:10,  9.09it/s] 91%|█████████▏| 979/1070 [01:56<00:10,  9.00it/s] 92%|█████████▏| 980/1070 [01:56<00:10,  8.96it/s] 92%|█████████▏| 981/1070 [01:56<00:09,  8.96it/s] 92%|█████████▏| 982/1070 [01:56<00:09,  8.92it/s] 92%|█████████▏| 983/1070 [01:56<00:09,  8.99it/s] 92%|█████████▏| 984/1070 [01:56<00:09,  8.93it/s] 92%|█████████▏| 985/1070 [01:56<00:09,  8.90it/s] 92%|█████████▏| 986/1070 [01:57<00:09,  8.92it/s] 92%|█████████▏| 987/1070 [01:57<00:09,  8.94it/s] 92%|█████████▏| 988/1070 [01:57<00:09,  8.97it/s] 92%|█████████▏| 989/1070 [01:57<00:09,  8.85it/s] 93%|█████████▎| 990/1070 [01:57<00:08,  8.93it/s] 93%|█████████▎| 991/1070 [01:57<00:08,  9.04it/s] 93%|█████████▎| 992/1070 [01:57<00:08,  8.98it/s] 93%|█████████▎| 993/1070 [01:57<00:08,  8.92it/s] 93%|█████████▎| 994/1070 [01:57<00:08,  8.92it/s] 93%|█████████▎| 995/1070 [01:58<00:08,  8.96it/s] 93%|█████████▎| 996/1070 [01:58<00:08,  9.01it/s] 93%|█████████▎| 997/1070 [01:58<00:08,  8.90it/s] 93%|█████████▎| 998/1070 [01:58<00:08,  8.83it/s] 93%|█████████▎| 999/1070 [01:58<00:08,  8.84it/s] 93%|█████████▎| 1000/1070 [01:58<00:07,  8.95it/s] 94%|█████████▎| 1001/1070 [01:58<00:07,  9.01it/s] 94%|█████████▎| 1002/1070 [01:58<00:07,  8.88it/s] 94%|█████████▎| 1003/1070 [01:58<00:07,  8.87it/s] 94%|█████████▍| 1004/1070 [01:59<00:07,  8.98it/s] 94%|█████████▍| 1005/1070 [01:59<00:07,  8.96it/s] 94%|█████████▍| 1006/1070 [01:59<00:07,  8.87it/s] 94%|█████████▍| 1007/1070 [01:59<00:07,  8.84it/s] 94%|█████████▍| 1008/1070 [01:59<00:06,  8.91it/s] 94%|█████████▍| 1009/1070 [01:59<00:06,  8.96it/s] 94%|█████████▍| 1010/1070 [01:59<00:06,  8.89it/s] 94%|█████████▍| 1011/1070 [01:59<00:06,  8.81it/s] 95%|█████████▍| 1012/1070 [01:59<00:06,  8.84it/s] 95%|█████████▍| 1013/1070 [02:00<00:06,  8.90it/s] 95%|█████████▍| 1014/1070 [02:00<00:06,  9.00it/s] 95%|█████████▍| 1015/1070 [02:00<00:06,  8.97it/s] 95%|█████████▍| 1016/1070 [02:00<00:06,  8.93it/s] 95%|█████████▌| 1017/1070 [02:00<00:05,  8.97it/s] 95%|█████████▌| 1018/1070 [02:00<00:05,  8.98it/s] 95%|█████████▌| 1019/1070 [02:00<00:05,  9.00it/s] 95%|█████████▌| 1020/1070 [02:00<00:05,  8.93it/s] 95%|█████████▌| 1021/1070 [02:00<00:05,  8.86it/s] 96%|█████████▌| 1022/1070 [02:01<00:05,  8.90it/s] 96%|█████████▌| 1023/1070 [02:01<00:05,  8.90it/s] 96%|█████████▌| 1024/1070 [02:01<00:05,  8.95it/s] 96%|█████████▌| 1025/1070 [02:01<00:05,  8.85it/s] 96%|█████████▌| 1026/1070 [02:01<00:04,  8.87it/s] 96%|█████████▌| 1027/1070 [02:01<00:04,  8.99it/s] 96%|█████████▌| 1028/1070 [02:01<00:04,  8.91it/s] 96%|█████████▌| 1029/1070 [02:01<00:04,  8.86it/s] 96%|█████████▋| 1030/1070 [02:01<00:04,  8.87it/s] 96%|█████████▋| 1031/1070 [02:02<00:04,  8.88it/s] 96%|█████████▋| 1032/1070 [02:02<00:04,  8.95it/s] 97%|█████████▋| 1033/1070 [02:02<00:04,  8.93it/s] 97%|█████████▋| 1034/1070 [02:02<00:04,  8.88it/s] 97%|█████████▋| 1035/1070 [02:02<00:03,  8.84it/s] 97%|█████████▋| 1036/1070 [02:02<00:03,  8.89it/s] 97%|█████████▋| 1037/1070 [02:02<00:03,  8.99it/s] 97%|█████████▋| 1038/1070 [02:02<00:03,  8.83it/s] 97%|█████████▋| 1039/1070 [02:02<00:03,  8.83it/s] 97%|█████████▋| 1040/1070 [02:03<00:03,  8.94it/s] 97%|█████████▋| 1041/1070 [02:03<00:03,  8.96it/s] 97%|█████████▋| 1042/1070 [02:03<00:03,  8.91it/s] 97%|█████████▋| 1043/1070 [02:03<00:03,  8.89it/s] 98%|█████████▊| 1044/1070 [02:03<00:02,  8.91it/s] 98%|█████████▊| 1045/1070 [02:03<00:02,  8.96it/s] 98%|█████████▊| 1046/1070 [02:03<00:02,  8.92it/s] 98%|█████████▊| 1047/1070 [02:03<00:02,  8.95it/s] 98%|█████████▊| 1048/1070 [02:03<00:02,  8.91it/s] 98%|█████████▊| 1049/1070 [02:04<00:02,  8.91it/s] 98%|█████████▊| 1050/1070 [02:04<00:02,  8.96it/s] 98%|█████████▊| 1051/1070 [02:04<00:02,  8.97it/s] 98%|█████████▊| 1052/1070 [02:04<00:02,  8.97it/s] 98%|█████████▊| 1053/1070 [02:04<00:01,  9.03it/s] 99%|█████████▊| 1054/1070 [02:04<00:01,  9.02it/s] 99%|█████████▊| 1055/1070 [02:04<00:01,  9.00it/s] 99%|█████████▊| 1056/1070 [02:04<00:01,  8.93it/s] 99%|█████████▉| 1057/1070 [02:04<00:01,  8.94it/s] 99%|█████████▉| 1058/1070 [02:05<00:01,  8.94it/s] 99%|█████████▉| 1059/1070 [02:05<00:01,  8.96it/s] 99%|█████████▉| 1060/1070 [02:05<00:01,  8.99it/s] 99%|█████████▉| 1061/1070 [02:05<00:01,  8.93it/s] 99%|█████████▉| 1062/1070 [02:05<00:00,  8.87it/s] 99%|█████████▉| 1063/1070 [02:05<00:00,  9.01it/s] 99%|█████████▉| 1064/1070 [02:05<00:00,  9.00it/s]100%|█████████▉| 1065/1070 [02:05<00:00,  8.94it/s]100%|█████████▉| 1066/1070 [02:05<00:00,  8.97it/s]100%|█████████▉| 1067/1070 [02:06<00:00,  8.99it/s]100%|█████████▉| 1068/1070 [02:06<00:00,  8.96it/s]100%|█████████▉| 1069/1070 [02:06<00:00,  8.93it/s]                                                   100%|██████████| 1070/1070 [02:06<00:00,  8.93it/s][INFO|trainer.py:755] 2023-11-15 21:45:55,463 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:45:55,465 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:45:55,465 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:45:55,465 >>   Batch size = 8
{'eval_loss': 0.3748321831226349, 'eval_accuracy': 0.9039473684210526, 'eval_micro_f1': 0.9039473684210526, 'eval_macro_f1': 0.9016701595604495, 'eval_runtime': 1.3912, 'eval_samples_per_second': 546.297, 'eval_steps_per_second': 68.287, 'epoch': 4.0}
{'loss': 0.0535, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 82.30it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 76.53it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 73.03it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 72.68it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 72.87it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 73.56it/s][A
 61%|██████    | 58/95 [00:00<00:00, 70.91it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 70.76it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 72.71it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 71.61it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 69.95it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:07<00:00,  8.93it/s]
100%|██████████| 95/95 [00:01<00:00, 69.95it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 21:45:56,833 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:07<00:00,  8.93it/s]100%|██████████| 1070/1070 [02:07<00:00,  8.37it/s]
[INFO|trainer.py:2855] 2023-11-15 21:45:56,836 >> Saving model checkpoint to ./result/agnews_sup_bert-base-cased_adapter__seed4
[INFO|configuration_utils.py:460] 2023-11-15 21:45:56,839 >> Configuration saved in ./result/agnews_sup_bert-base-cased_adapter__seed4/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:45:57,820 >> Model weights saved in ./result/agnews_sup_bert-base-cased_adapter__seed4/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:45:57,823 >> tokenizer config file saved in ./result/agnews_sup_bert-base-cased_adapter__seed4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:45:57,825 >> Special tokens file saved in ./result/agnews_sup_bert-base-cased_adapter__seed4/special_tokens_map.json
{'eval_loss': 0.3748226761817932, 'eval_accuracy': 0.9026315789473685, 'eval_micro_f1': 0.9026315789473685, 'eval_macro_f1': 0.900427915715245, 'eval_runtime': 1.3645, 'eval_samples_per_second': 556.974, 'eval_steps_per_second': 69.622, 'epoch': 5.0}
{'train_runtime': 127.7852, 'train_samples_per_second': 267.637, 'train_steps_per_second': 8.373, 'train_loss': 0.20220763839293862, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2022
  train_runtime            = 0:02:07.78
  train_samples            =       6840
  train_samples_per_second =    267.637
  train_steps_per_second   =      8.373
11/15/2023 21:45:57 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:45:57,869 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:45:57,870 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:45:57,870 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:45:57,871 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  9%|▉         | 9/95 [00:00<00:01, 85.90it/s] 19%|█▉        | 18/95 [00:00<00:01, 73.66it/s] 27%|██▋       | 26/95 [00:00<00:00, 73.38it/s] 36%|███▌      | 34/95 [00:00<00:00, 74.79it/s] 44%|████▍     | 42/95 [00:00<00:00, 72.23it/s] 53%|█████▎    | 50/95 [00:00<00:00, 70.83it/s] 61%|██████    | 58/95 [00:00<00:00, 70.67it/s] 69%|██████▉   | 66/95 [00:00<00:00, 70.99it/s] 78%|███████▊  | 74/95 [00:01<00:00, 71.05it/s] 86%|████████▋ | 82/95 [00:01<00:00, 69.99it/s] 95%|█████████▍| 90/95 [00:01<00:00, 69.71it/s]100%|██████████| 95/95 [00:01<00:00, 69.64it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.9026
  eval_loss               =     0.3748
  eval_macro_f1           =     0.9004
  eval_micro_f1           =     0.9026
  eval_runtime            = 0:00:01.37
  eval_samples            =        760
  eval_samples_per_second =    550.735
  eval_steps_per_second   =     68.842
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▄▁█▅▄▄
wandb:                      eval/loss ▂▁▃███
wandb:                  eval/macro_f1 ▄▁█▄▄▄
wandb:                  eval/micro_f1 ▄▁█▅▄▄
wandb:                   eval/runtime ▄█▄▅▁▃
wandb:        eval/samples_per_second ▅▁▅▄█▅
wandb:          eval/steps_per_second ▅▁▅▄█▅
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▂▁▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.90263
wandb:                      eval/loss 0.37482
wandb:                  eval/macro_f1 0.90043
wandb:                  eval/micro_f1 0.90263
wandb:                   eval/runtime 1.38
wandb:        eval/samples_per_second 550.735
wandb:          eval/steps_per_second 68.842
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.0535
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.20221
wandb:            train/train_runtime 127.7852
wandb: train/train_samples_per_second 267.637
wandb:   train/train_steps_per_second 8.373
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_214302-p93rdit5
wandb: Find logs at: ./wandb/offline-run-20231115_214302-p93rdit5/logs
(ModelArguments(model_name_or_path='allenai/scibert_scivocab_uncased', cache_dir='./cache', use_adapter=False, use_lora=False), DataTrainingArguments(dataset_name='agnews_sup', max_seq_length=64), TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4/runs/Nov15_21-46-09_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
))
11/15/2023 21:46:09 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
11/15/2023 21:46:09 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4/runs/Nov15_21-46-08_node014,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
output_dir=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=555,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[INFO|configuration_utils.py:715] 2023-11-15 21:46:24,638 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:46:24,648 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_auto.py:535] 2023-11-15 21:46:35,508 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:715] 2023-11-15 21:46:45,517 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:46:45,518 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:47:05,555 >> loading file vocab.txt from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:47:05,555 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:47:05,556 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:47:05,556 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1852] 2023-11-15 21:47:05,556 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:715] 2023-11-15 21:47:05,557 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:47:05,558 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|configuration_utils.py:715] 2023-11-15 21:47:05,581 >> loading configuration file config.json from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json
[INFO|configuration_utils.py:775] 2023-11-15 21:47:05,582 >> Model config BertConfig {
  "_name_or_path": "allenai/scibert_scivocab_uncased",
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.33.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

[INFO|modeling_utils.py:2862] 2023-11-15 21:47:25,713 >> loading weights file pytorch_model.bin from cache at ./cache/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin
[INFO|modeling_utils.py:3638] 2023-11-15 21:47:27,033 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3650] 2023-11-15 21:47:27,034 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
model_max_length: 1000000000000000019884624838656
Running tokenizer on dataset:   0%|          | 0/6840 [00:00<?, ? examples/s]Running tokenizer on dataset:  44%|████▍     | 3000/6840 [00:00<00:00, 19538.32 examples/s]Running tokenizer on dataset:  88%|████████▊ | 6000/6840 [00:00<00:00, 20299.04 examples/s]Running tokenizer on dataset: 100%|██████████| 6840/6840 [00:00<00:00, 20149.19 examples/s]
Running tokenizer on dataset:   0%|          | 0/760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 760/760 [00:00<00:00, 22005.18 examples/s]
11/15/2023 21:47:27 - INFO - __main__ - Sample 1583 of the training set: {'text': 'SA-India Test: South Africa declare at 510 for 9 : Sports India: Cricket  gt; Kanpur, Nov 22 : South Africa declared their first innings at 510 for nine on the third day of the first cricket Test against India here today.', 'label': 0, 'input_ids': [102, 2204, 579, 6666, 856, 862, 4430, 7611, 10688, 235, 25801, 168, 514, 862, 11239, 6666, 862, 2132, 1927, 160, 10545, 1814, 11237, 10583, 422, 6172, 1931, 862, 4430, 7611, 12927, 547, 705, 3438, 854, 235, 25801, 168, 6909, 191, 111, 2765, 2181, 131, 111, 705, 2132, 1927, 160, 856, 2089, 6666, 1530, 7121, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:47:27 - INFO - __main__ - Sample 2249 of the training set: {'text': 'FTSE 100 lifted by bright Dow The FTSE 100 has climbed as a surge by US shares gives a boost to European markets. Shire Pharmaceuticals SHP.L jumped after winning approval for a key drug and consumer goods giant Unilever ULVR.', 'label': 1, 'input_ids': [102, 27362, 30107, 1287, 17263, 119, 214, 8932, 14581, 111, 27362, 30107, 1287, 434, 4730, 2802, 188, 106, 7565, 214, 227, 11985, 3669, 106, 12574, 147, 4425, 7838, 205, 25128, 30107, 19011, 272, 30121, 205, 152, 11758, 119, 647, 20421, 10192, 168, 106, 1519, 1698, 137, 7710, 10017, 15278, 19059, 16744, 114, 2060, 15155, 205, 103, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/15/2023 21:47:27 - INFO - __main__ - Sample 1319 of the training set: {'text': 'Language of goals what counts for tongue-tied Ronnie and Michael England striker Michael Owen said his lack of Spanish and Ronaldo #39;s lack of English did not hinder celebrations of the Brazilian #39;s matchwinner for Real Madrid in Sunday #39;s 1-0 win at Mallorca.', 'label': 0, 'input_ids': [102, 2647, 131, 5842, 1792, 7274, 168, 17589, 579, 20034, 22019, 25917, 137, 10219, 10960, 23884, 30114, 10219, 1747, 117, 6032, 1972, 2596, 131, 12998, 137, 22019, 14232, 30112, 3000, 4133, 1814, 112, 2596, 131, 6170, 1544, 302, 23215, 28377, 288, 131, 111, 17675, 3000, 4133, 1814, 112, 5795, 9320, 1347, 168, 1332, 23216, 121, 21444, 240, 3000, 4133, 1814, 112, 158, 579, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
11/15/2023 21:47:27 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:755] 2023-11-15 21:47:28,874 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1715] 2023-11-15 21:47:28,881 >> ***** Running training *****
[INFO|trainer.py:1716] 2023-11-15 21:47:28,881 >>   Num examples = 6,840
[INFO|trainer.py:1717] 2023-11-15 21:47:28,882 >>   Num Epochs = 5
[INFO|trainer.py:1718] 2023-11-15 21:47:28,882 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1721] 2023-11-15 21:47:28,882 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:1722] 2023-11-15 21:47:28,883 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1723] 2023-11-15 21:47:28,883 >>   Total optimization steps = 1,070
[INFO|trainer.py:1724] 2023-11-15 21:47:28,884 >>   Number of trainable parameters = 109,921,540
[INFO|integration_utils.py:716] 2023-11-15 21:47:28,884 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|          | 0/1070 [00:00<?, ?it/s]  0%|          | 1/1070 [00:01<24:25,  1.37s/it]  0%|          | 2/1070 [00:01<11:12,  1.59it/s]  0%|          | 3/1070 [00:01<06:58,  2.55it/s]  0%|          | 4/1070 [00:01<04:59,  3.56it/s]  0%|          | 5/1070 [00:01<03:53,  4.56it/s]  1%|          | 6/1070 [00:01<03:13,  5.51it/s]  1%|          | 7/1070 [00:02<02:47,  6.33it/s]  1%|          | 8/1070 [00:02<02:31,  7.02it/s]  1%|          | 9/1070 [00:02<02:20,  7.57it/s]  1%|          | 10/1070 [00:02<02:11,  8.08it/s]  1%|          | 11/1070 [00:02<02:06,  8.35it/s]  1%|          | 12/1070 [00:02<02:03,  8.53it/s]  1%|          | 13/1070 [00:02<02:01,  8.67it/s]  1%|▏         | 14/1070 [00:02<02:00,  8.75it/s]  1%|▏         | 15/1070 [00:02<01:58,  8.89it/s]  1%|▏         | 16/1070 [00:03<01:57,  8.95it/s]  2%|▏         | 17/1070 [00:03<01:57,  9.00it/s]  2%|▏         | 18/1070 [00:03<01:56,  9.05it/s]  2%|▏         | 19/1070 [00:03<01:56,  9.00it/s]  2%|▏         | 20/1070 [00:03<01:54,  9.17it/s]  2%|▏         | 21/1070 [00:03<01:55,  9.12it/s]  2%|▏         | 22/1070 [00:03<01:55,  9.03it/s]  2%|▏         | 23/1070 [00:03<01:56,  9.02it/s]  2%|▏         | 24/1070 [00:03<01:56,  9.00it/s]  2%|▏         | 25/1070 [00:04<01:55,  9.05it/s]  2%|▏         | 26/1070 [00:04<01:55,  9.04it/s]  3%|▎         | 27/1070 [00:04<01:55,  9.05it/s]  3%|▎         | 28/1070 [00:04<01:55,  9.06it/s]  3%|▎         | 29/1070 [00:04<01:54,  9.11it/s]  3%|▎         | 30/1070 [00:04<01:52,  9.24it/s]  3%|▎         | 31/1070 [00:04<01:53,  9.19it/s]  3%|▎         | 32/1070 [00:04<01:53,  9.12it/s]  3%|▎         | 33/1070 [00:04<01:54,  9.09it/s]  3%|▎         | 34/1070 [00:04<01:53,  9.11it/s]  3%|▎         | 35/1070 [00:05<01:53,  9.13it/s]  3%|▎         | 36/1070 [00:05<01:53,  9.10it/s]  3%|▎         | 37/1070 [00:05<01:53,  9.11it/s]  4%|▎         | 38/1070 [00:05<01:53,  9.05it/s]  4%|▎         | 39/1070 [00:05<01:53,  9.06it/s]  4%|▎         | 40/1070 [00:05<01:51,  9.22it/s]  4%|▍         | 41/1070 [00:05<01:52,  9.18it/s]  4%|▍         | 42/1070 [00:05<01:53,  9.05it/s]  4%|▍         | 43/1070 [00:05<01:53,  9.02it/s]  4%|▍         | 44/1070 [00:06<01:53,  9.05it/s]  4%|▍         | 45/1070 [00:06<01:53,  9.01it/s]  4%|▍         | 46/1070 [00:06<01:54,  8.93it/s]  4%|▍         | 47/1070 [00:06<01:54,  8.96it/s]  4%|▍         | 48/1070 [00:06<01:53,  8.98it/s]  5%|▍         | 49/1070 [00:06<01:53,  9.03it/s]  5%|▍         | 50/1070 [00:06<01:51,  9.16it/s]  5%|▍         | 51/1070 [00:06<01:52,  9.09it/s]  5%|▍         | 52/1070 [00:06<01:52,  9.06it/s]  5%|▍         | 53/1070 [00:07<01:52,  9.03it/s]  5%|▌         | 54/1070 [00:07<01:52,  9.04it/s]  5%|▌         | 55/1070 [00:07<01:51,  9.08it/s]  5%|▌         | 56/1070 [00:07<01:51,  9.05it/s]  5%|▌         | 57/1070 [00:07<01:52,  9.04it/s]  5%|▌         | 58/1070 [00:07<01:52,  8.99it/s]  6%|▌         | 59/1070 [00:07<01:51,  9.06it/s]  6%|▌         | 60/1070 [00:07<01:50,  9.18it/s]  6%|▌         | 61/1070 [00:07<01:50,  9.14it/s]  6%|▌         | 62/1070 [00:08<01:51,  9.08it/s]  6%|▌         | 63/1070 [00:08<01:51,  9.02it/s]  6%|▌         | 64/1070 [00:08<01:51,  9.03it/s]  6%|▌         | 65/1070 [00:08<01:50,  9.07it/s]  6%|▌         | 66/1070 [00:08<01:52,  8.96it/s]  6%|▋         | 67/1070 [00:08<01:50,  9.05it/s]  6%|▋         | 68/1070 [00:08<01:51,  9.02it/s]  6%|▋         | 69/1070 [00:08<01:51,  9.01it/s]  7%|▋         | 70/1070 [00:08<01:48,  9.19it/s]  7%|▋         | 71/1070 [00:09<01:49,  9.14it/s]  7%|▋         | 72/1070 [00:09<01:50,  9.07it/s]  7%|▋         | 73/1070 [00:09<01:50,  9.03it/s]  7%|▋         | 74/1070 [00:09<01:50,  9.02it/s]  7%|▋         | 75/1070 [00:09<01:50,  9.02it/s]  7%|▋         | 76/1070 [00:09<01:51,  8.93it/s]  7%|▋         | 77/1070 [00:09<01:51,  8.94it/s]  7%|▋         | 78/1070 [00:09<01:50,  8.97it/s]  7%|▋         | 79/1070 [00:09<01:50,  9.00it/s]  7%|▋         | 80/1070 [00:10<01:47,  9.18it/s]  8%|▊         | 81/1070 [00:10<01:47,  9.18it/s]  8%|▊         | 82/1070 [00:10<01:48,  9.13it/s]  8%|▊         | 83/1070 [00:10<01:48,  9.09it/s]  8%|▊         | 84/1070 [00:10<01:48,  9.07it/s]  8%|▊         | 85/1070 [00:10<01:48,  9.07it/s]  8%|▊         | 86/1070 [00:10<01:49,  9.00it/s]  8%|▊         | 87/1070 [00:10<01:48,  9.10it/s]  8%|▊         | 88/1070 [00:10<01:47,  9.11it/s]  8%|▊         | 89/1070 [00:11<01:48,  9.08it/s]  8%|▊         | 90/1070 [00:11<01:46,  9.19it/s]  9%|▊         | 91/1070 [00:11<01:46,  9.15it/s]  9%|▊         | 92/1070 [00:11<01:46,  9.16it/s]  9%|▊         | 93/1070 [00:11<01:46,  9.15it/s]  9%|▉         | 94/1070 [00:11<01:46,  9.14it/s]  9%|▉         | 95/1070 [00:11<01:46,  9.11it/s]  9%|▉         | 96/1070 [00:11<01:46,  9.12it/s]  9%|▉         | 97/1070 [00:11<01:45,  9.21it/s]  9%|▉         | 98/1070 [00:12<01:46,  9.12it/s]  9%|▉         | 99/1070 [00:12<01:46,  9.10it/s]  9%|▉         | 100/1070 [00:12<01:45,  9.17it/s]  9%|▉         | 101/1070 [00:12<01:46,  9.12it/s] 10%|▉         | 102/1070 [00:12<01:46,  9.12it/s] 10%|▉         | 103/1070 [00:12<01:46,  9.08it/s] 10%|▉         | 104/1070 [00:12<01:46,  9.05it/s] 10%|▉         | 105/1070 [00:12<01:46,  9.03it/s] 10%|▉         | 106/1070 [00:12<01:46,  9.07it/s] 10%|█         | 107/1070 [00:13<01:44,  9.18it/s] 10%|█         | 108/1070 [00:13<01:44,  9.19it/s] 10%|█         | 109/1070 [00:13<01:45,  9.11it/s] 10%|█         | 110/1070 [00:13<01:45,  9.13it/s] 10%|█         | 111/1070 [00:13<01:44,  9.14it/s] 10%|█         | 112/1070 [00:13<01:44,  9.14it/s] 11%|█         | 113/1070 [00:13<01:45,  9.05it/s] 11%|█         | 114/1070 [00:13<01:45,  9.07it/s] 11%|█         | 115/1070 [00:13<01:45,  9.05it/s] 11%|█         | 116/1070 [00:14<01:45,  9.06it/s] 11%|█         | 117/1070 [00:14<01:44,  9.16it/s] 11%|█         | 118/1070 [00:14<01:44,  9.15it/s] 11%|█         | 119/1070 [00:14<01:43,  9.16it/s] 11%|█         | 120/1070 [00:14<01:44,  9.12it/s] 11%|█▏        | 121/1070 [00:14<01:43,  9.16it/s] 11%|█▏        | 122/1070 [00:14<01:43,  9.17it/s] 11%|█▏        | 123/1070 [00:14<01:44,  9.02it/s] 12%|█▏        | 124/1070 [00:14<01:43,  9.14it/s] 12%|█▏        | 125/1070 [00:15<01:44,  9.05it/s] 12%|█▏        | 126/1070 [00:15<01:44,  9.06it/s] 12%|█▏        | 127/1070 [00:15<01:42,  9.20it/s] 12%|█▏        | 128/1070 [00:15<01:42,  9.20it/s] 12%|█▏        | 129/1070 [00:15<01:42,  9.16it/s] 12%|█▏        | 130/1070 [00:15<01:43,  9.09it/s] 12%|█▏        | 131/1070 [00:15<01:42,  9.15it/s] 12%|█▏        | 132/1070 [00:15<01:42,  9.11it/s] 12%|█▏        | 133/1070 [00:15<01:42,  9.13it/s] 13%|█▎        | 134/1070 [00:15<01:41,  9.22it/s] 13%|█▎        | 135/1070 [00:16<01:41,  9.17it/s] 13%|█▎        | 136/1070 [00:16<01:42,  9.15it/s] 13%|█▎        | 137/1070 [00:16<01:41,  9.22it/s] 13%|█▎        | 138/1070 [00:16<01:42,  9.12it/s] 13%|█▎        | 139/1070 [00:16<01:41,  9.14it/s] 13%|█▎        | 140/1070 [00:16<01:42,  9.11it/s] 13%|█▎        | 141/1070 [00:16<01:42,  9.06it/s] 13%|█▎        | 142/1070 [00:16<01:42,  9.04it/s] 13%|█▎        | 143/1070 [00:16<01:42,  9.04it/s] 13%|█▎        | 144/1070 [00:17<01:40,  9.19it/s] 14%|█▎        | 145/1070 [00:17<01:41,  9.11it/s] 14%|█▎        | 146/1070 [00:17<01:41,  9.14it/s] 14%|█▎        | 147/1070 [00:17<01:41,  9.13it/s] 14%|█▍        | 148/1070 [00:17<01:41,  9.09it/s] 14%|█▍        | 149/1070 [00:17<01:41,  9.11it/s] 14%|█▍        | 150/1070 [00:17<01:41,  9.04it/s] 14%|█▍        | 151/1070 [00:17<01:42,  8.97it/s] 14%|█▍        | 152/1070 [00:17<01:41,  9.01it/s] 14%|█▍        | 153/1070 [00:18<01:41,  9.05it/s] 14%|█▍        | 154/1070 [00:18<01:40,  9.15it/s] 14%|█▍        | 155/1070 [00:18<01:40,  9.12it/s] 15%|█▍        | 156/1070 [00:18<01:41,  9.00it/s] 15%|█▍        | 157/1070 [00:18<01:41,  8.98it/s] 15%|█▍        | 158/1070 [00:18<01:40,  9.06it/s] 15%|█▍        | 159/1070 [00:18<01:40,  9.06it/s] 15%|█▍        | 160/1070 [00:18<01:41,  8.99it/s] 15%|█▌        | 161/1070 [00:18<01:39,  9.11it/s] 15%|█▌        | 162/1070 [00:19<01:39,  9.09it/s] 15%|█▌        | 163/1070 [00:19<01:40,  8.99it/s] 15%|█▌        | 164/1070 [00:19<01:38,  9.16it/s] 15%|█▌        | 165/1070 [00:19<01:39,  9.09it/s] 16%|█▌        | 166/1070 [00:19<01:41,  8.94it/s] 16%|█▌        | 167/1070 [00:19<01:40,  8.95it/s] 16%|█▌        | 168/1070 [00:19<01:40,  8.95it/s] 16%|█▌        | 169/1070 [00:19<01:39,  9.02it/s] 16%|█▌        | 170/1070 [00:19<01:40,  8.97it/s] 16%|█▌        | 171/1070 [00:20<01:39,  9.08it/s] 16%|█▌        | 172/1070 [00:20<01:39,  9.06it/s] 16%|█▌        | 173/1070 [00:20<01:39,  9.04it/s] 16%|█▋        | 174/1070 [00:20<01:37,  9.19it/s] 16%|█▋        | 175/1070 [00:20<01:37,  9.18it/s] 16%|█▋        | 176/1070 [00:20<01:38,  9.11it/s] 17%|█▋        | 177/1070 [00:20<01:38,  9.07it/s] 17%|█▋        | 178/1070 [00:20<01:38,  9.06it/s] 17%|█▋        | 179/1070 [00:20<01:38,  9.01it/s] 17%|█▋        | 180/1070 [00:21<01:38,  9.06it/s] 17%|█▋        | 181/1070 [00:21<01:37,  9.14it/s] 17%|█▋        | 182/1070 [00:21<01:38,  9.06it/s] 17%|█▋        | 183/1070 [00:21<01:38,  9.03it/s] 17%|█▋        | 184/1070 [00:21<01:37,  9.09it/s] 17%|█▋        | 185/1070 [00:21<01:37,  9.09it/s] 17%|█▋        | 186/1070 [00:21<01:37,  9.09it/s] 17%|█▋        | 187/1070 [00:21<01:37,  9.06it/s] 18%|█▊        | 188/1070 [00:21<01:38,  8.99it/s] 18%|█▊        | 189/1070 [00:22<01:37,  8.99it/s] 18%|█▊        | 190/1070 [00:22<01:37,  9.02it/s] 18%|█▊        | 191/1070 [00:22<01:36,  9.11it/s] 18%|█▊        | 192/1070 [00:22<01:36,  9.14it/s] 18%|█▊        | 193/1070 [00:22<01:36,  9.09it/s] 18%|█▊        | 194/1070 [00:22<01:36,  9.12it/s] 18%|█▊        | 195/1070 [00:22<01:36,  9.08it/s] 18%|█▊        | 196/1070 [00:22<01:36,  9.07it/s] 18%|█▊        | 197/1070 [00:22<01:36,  9.01it/s] 19%|█▊        | 198/1070 [00:23<01:37,  8.95it/s] 19%|█▊        | 199/1070 [00:23<01:37,  8.92it/s] 19%|█▊        | 200/1070 [00:23<01:36,  8.98it/s] 19%|█▉        | 201/1070 [00:23<01:35,  9.09it/s] 19%|█▉        | 202/1070 [00:23<01:36,  9.02it/s] 19%|█▉        | 203/1070 [00:23<01:36,  9.00it/s] 19%|█▉        | 204/1070 [00:23<01:37,  8.93it/s] 19%|█▉        | 205/1070 [00:23<01:36,  8.94it/s] 19%|█▉        | 206/1070 [00:23<01:35,  9.00it/s] 19%|█▉        | 207/1070 [00:24<01:36,  8.95it/s] 19%|█▉        | 208/1070 [00:24<01:36,  8.94it/s] 20%|█▉        | 209/1070 [00:24<01:36,  8.94it/s] 20%|█▉        | 210/1070 [00:24<01:36,  8.95it/s] 20%|█▉        | 211/1070 [00:24<01:35,  9.00it/s] 20%|█▉        | 212/1070 [00:24<01:36,  8.91it/s] 20%|█▉        | 213/1070 [00:24<01:35,  8.96it/s]                                                   20%|██        | 214/1070 [00:24<01:35,  8.96it/s][INFO|trainer.py:755] 2023-11-15 21:47:53,715 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:47:53,717 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:47:53,717 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:47:53,718 >>   Batch size = 8
{'loss': 0.5256, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 82.10it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 72.21it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 71.62it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 72.71it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 72.35it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 72.20it/s][A
 61%|██████    | 58/95 [00:00<00:00, 73.21it/s][A
 69%|██████▉   | 66/95 [00:00<00:00, 71.05it/s][A
 78%|███████▊  | 74/95 [00:01<00:00, 71.33it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 73.07it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 72.42it/s][A                                                  
                                               [A 20%|██        | 214/1070 [00:26<01:35,  8.96it/s]
100%|██████████| 95/95 [00:01<00:00, 72.42it/s][A
                                               [A 20%|██        | 215/1070 [00:26<06:02,  2.36it/s] 20%|██        | 216/1070 [00:26<04:56,  2.88it/s] 20%|██        | 217/1070 [00:26<04:03,  3.50it/s] 20%|██        | 218/1070 [00:26<03:22,  4.21it/s] 20%|██        | 219/1070 [00:26<02:50,  4.98it/s] 21%|██        | 220/1070 [00:26<02:29,  5.67it/s] 21%|██        | 221/1070 [00:26<02:13,  6.37it/s] 21%|██        | 222/1070 [00:27<02:02,  6.95it/s] 21%|██        | 223/1070 [00:27<01:53,  7.46it/s] 21%|██        | 224/1070 [00:27<01:47,  7.87it/s] 21%|██        | 225/1070 [00:27<01:44,  8.11it/s] 21%|██        | 226/1070 [00:27<01:41,  8.29it/s] 21%|██        | 227/1070 [00:27<01:39,  8.47it/s] 21%|██▏       | 228/1070 [00:27<01:37,  8.62it/s] 21%|██▏       | 229/1070 [00:27<01:35,  8.78it/s] 21%|██▏       | 230/1070 [00:27<01:36,  8.75it/s] 22%|██▏       | 231/1070 [00:28<01:34,  8.85it/s] 22%|██▏       | 232/1070 [00:28<01:34,  8.91it/s] 22%|██▏       | 233/1070 [00:28<01:33,  8.94it/s] 22%|██▏       | 234/1070 [00:28<01:32,  9.02it/s] 22%|██▏       | 235/1070 [00:28<01:33,  8.93it/s] 22%|██▏       | 236/1070 [00:28<01:33,  8.90it/s] 22%|██▏       | 237/1070 [00:28<01:33,  8.87it/s] 22%|██▏       | 238/1070 [00:28<01:33,  8.92it/s] 22%|██▏       | 239/1070 [00:28<01:32,  9.00it/s] 22%|██▏       | 240/1070 [00:29<01:33,  8.91it/s] 23%|██▎       | 241/1070 [00:29<01:32,  8.99it/s] 23%|██▎       | 242/1070 [00:29<01:31,  9.06it/s] 23%|██▎       | 243/1070 [00:29<01:31,  9.04it/s] 23%|██▎       | 244/1070 [00:29<01:31,  9.02it/s] 23%|██▎       | 245/1070 [00:29<01:31,  9.02it/s] 23%|██▎       | 246/1070 [00:29<01:32,  8.95it/s] 23%|██▎       | 247/1070 [00:29<01:32,  8.88it/s] 23%|██▎       | 248/1070 [00:29<01:31,  8.96it/s] 23%|██▎       | 249/1070 [00:30<01:30,  9.05it/s] 23%|██▎       | 250/1070 [00:30<01:30,  9.05it/s] 23%|██▎       | 251/1070 [00:30<01:30,  9.01it/s] 24%|██▎       | 252/1070 [00:30<01:30,  9.05it/s] 24%|██▎       | 253/1070 [00:30<01:30,  9.04it/s] 24%|██▎       | 254/1070 [00:30<01:29,  9.07it/s] 24%|██▍       | 255/1070 [00:30<01:30,  8.98it/s] 24%|██▍       | 256/1070 [00:30<01:30,  8.96it/s] 24%|██▍       | 257/1070 [00:30<01:30,  8.99it/s] 24%|██▍       | 258/1070 [00:31<01:30,  9.02it/s] 24%|██▍       | 259/1070 [00:31<01:29,  9.07it/s] 24%|██▍       | 260/1070 [00:31<01:29,  9.03it/s] 24%|██▍       | 261/1070 [00:31<01:29,  9.07it/s] 24%|██▍       | 262/1070 [00:31<01:29,  9.00it/s] 25%|██▍       | 263/1070 [00:31<01:29,  9.02it/s] 25%|██▍       | 264/1070 [00:31<01:29,  9.04it/s] 25%|██▍       | 265/1070 [00:31<01:29,  9.00it/s] 25%|██▍       | 266/1070 [00:31<01:29,  8.95it/s] 25%|██▍       | 267/1070 [00:32<01:29,  9.00it/s] 25%|██▌       | 268/1070 [00:32<01:29,  9.00it/s] 25%|██▌       | 269/1070 [00:32<01:28,  9.09it/s] 25%|██▌       | 270/1070 [00:32<01:28,  9.07it/s] 25%|██▌       | 271/1070 [00:32<01:28,  9.00it/s] 25%|██▌       | 272/1070 [00:32<01:28,  9.06it/s] 26%|██▌       | 273/1070 [00:32<01:27,  9.10it/s] 26%|██▌       | 274/1070 [00:32<01:27,  9.08it/s] 26%|██▌       | 275/1070 [00:32<01:27,  9.11it/s] 26%|██▌       | 276/1070 [00:33<01:28,  8.97it/s] 26%|██▌       | 277/1070 [00:33<01:28,  9.01it/s] 26%|██▌       | 278/1070 [00:33<01:27,  9.03it/s] 26%|██▌       | 279/1070 [00:33<01:27,  9.08it/s] 26%|██▌       | 280/1070 [00:33<01:27,  9.06it/s] 26%|██▋       | 281/1070 [00:33<01:27,  9.04it/s] 26%|██▋       | 282/1070 [00:33<01:27,  9.04it/s] 26%|██▋       | 283/1070 [00:33<01:27,  9.01it/s] 27%|██▋       | 284/1070 [00:33<01:26,  9.04it/s] 27%|██▋       | 285/1070 [00:34<01:27,  9.01it/s] 27%|██▋       | 286/1070 [00:34<01:26,  9.03it/s] 27%|██▋       | 287/1070 [00:34<01:26,  9.03it/s] 27%|██▋       | 288/1070 [00:34<01:26,  9.02it/s] 27%|██▋       | 289/1070 [00:34<01:25,  9.10it/s] 27%|██▋       | 290/1070 [00:34<01:26,  9.06it/s] 27%|██▋       | 291/1070 [00:34<01:26,  8.97it/s] 27%|██▋       | 292/1070 [00:34<01:26,  9.01it/s] 27%|██▋       | 293/1070 [00:34<01:26,  9.03it/s] 27%|██▋       | 294/1070 [00:35<01:25,  9.05it/s] 28%|██▊       | 295/1070 [00:35<01:26,  8.93it/s] 28%|██▊       | 296/1070 [00:35<01:26,  8.92it/s] 28%|██▊       | 297/1070 [00:35<01:26,  8.89it/s] 28%|██▊       | 298/1070 [00:35<01:26,  8.97it/s] 28%|██▊       | 299/1070 [00:35<01:24,  9.08it/s] 28%|██▊       | 300/1070 [00:35<01:25,  9.03it/s] 28%|██▊       | 301/1070 [00:35<01:26,  8.94it/s] 28%|██▊       | 302/1070 [00:35<01:25,  8.98it/s] 28%|██▊       | 303/1070 [00:36<01:25,  8.96it/s] 28%|██▊       | 304/1070 [00:36<01:25,  8.97it/s] 29%|██▊       | 305/1070 [00:36<01:24,  9.02it/s] 29%|██▊       | 306/1070 [00:36<01:25,  8.94it/s] 29%|██▊       | 307/1070 [00:36<01:25,  8.97it/s] 29%|██▉       | 308/1070 [00:36<01:25,  8.96it/s] 29%|██▉       | 309/1070 [00:36<01:24,  9.02it/s] 29%|██▉       | 310/1070 [00:36<01:24,  9.03it/s] 29%|██▉       | 311/1070 [00:36<01:24,  8.97it/s] 29%|██▉       | 312/1070 [00:37<01:24,  8.97it/s] 29%|██▉       | 313/1070 [00:37<01:24,  8.97it/s] 29%|██▉       | 314/1070 [00:37<01:24,  8.97it/s] 29%|██▉       | 315/1070 [00:37<01:25,  8.82it/s] 30%|██▉       | 316/1070 [00:37<01:26,  8.75it/s] 30%|██▉       | 317/1070 [00:37<01:25,  8.79it/s] 30%|██▉       | 318/1070 [00:37<01:24,  8.88it/s] 30%|██▉       | 319/1070 [00:37<01:23,  8.96it/s] 30%|██▉       | 320/1070 [00:37<01:24,  8.87it/s] 30%|███       | 321/1070 [00:38<01:24,  8.88it/s] 30%|███       | 322/1070 [00:38<01:23,  8.98it/s] 30%|███       | 323/1070 [00:38<01:23,  8.94it/s] 30%|███       | 324/1070 [00:38<01:23,  8.95it/s] 30%|███       | 325/1070 [00:38<01:23,  8.93it/s] 30%|███       | 326/1070 [00:38<01:23,  8.93it/s] 31%|███       | 327/1070 [00:38<01:23,  8.95it/s] 31%|███       | 328/1070 [00:38<01:22,  8.95it/s] 31%|███       | 329/1070 [00:38<01:21,  9.05it/s] 31%|███       | 330/1070 [00:39<01:22,  8.93it/s] 31%|███       | 331/1070 [00:39<01:22,  8.96it/s] 31%|███       | 332/1070 [00:39<01:21,  9.04it/s] 31%|███       | 333/1070 [00:39<01:21,  9.01it/s] 31%|███       | 334/1070 [00:39<01:21,  9.03it/s] 31%|███▏      | 335/1070 [00:39<01:21,  8.98it/s] 31%|███▏      | 336/1070 [00:39<01:22,  8.89it/s] 31%|███▏      | 337/1070 [00:39<01:22,  8.94it/s] 32%|███▏      | 338/1070 [00:39<01:22,  8.92it/s] 32%|███▏      | 339/1070 [00:40<01:21,  9.02it/s] 32%|███▏      | 340/1070 [00:40<01:21,  8.93it/s] 32%|███▏      | 341/1070 [00:40<01:22,  8.87it/s] 32%|███▏      | 342/1070 [00:40<01:20,  9.02it/s] 32%|███▏      | 343/1070 [00:40<01:20,  9.00it/s] 32%|███▏      | 344/1070 [00:40<01:20,  9.02it/s] 32%|███▏      | 345/1070 [00:40<01:20,  8.98it/s] 32%|███▏      | 346/1070 [00:40<01:20,  8.97it/s] 32%|███▏      | 347/1070 [00:40<01:20,  8.97it/s] 33%|███▎      | 348/1070 [00:41<01:19,  9.03it/s] 33%|███▎      | 349/1070 [00:41<01:18,  9.14it/s] 33%|███▎      | 350/1070 [00:41<01:19,  9.06it/s] 33%|███▎      | 351/1070 [00:41<01:19,  9.02it/s] 33%|███▎      | 352/1070 [00:41<01:18,  9.09it/s] 33%|███▎      | 353/1070 [00:41<01:19,  9.03it/s] 33%|███▎      | 354/1070 [00:41<01:19,  9.04it/s] 33%|███▎      | 355/1070 [00:41<01:19,  9.04it/s] 33%|███▎      | 356/1070 [00:41<01:19,  8.97it/s] 33%|███▎      | 357/1070 [00:42<01:19,  9.00it/s] 33%|███▎      | 358/1070 [00:42<01:19,  8.98it/s] 34%|███▎      | 359/1070 [00:42<01:18,  9.07it/s] 34%|███▎      | 360/1070 [00:42<01:18,  9.02it/s] 34%|███▎      | 361/1070 [00:42<01:18,  9.00it/s] 34%|███▍      | 362/1070 [00:42<01:18,  9.01it/s] 34%|███▍      | 363/1070 [00:42<01:18,  8.97it/s] 34%|███▍      | 364/1070 [00:42<01:18,  9.01it/s] 34%|███▍      | 365/1070 [00:42<01:19,  8.88it/s] 34%|███▍      | 366/1070 [00:43<01:20,  8.79it/s] 34%|███▍      | 367/1070 [00:43<01:19,  8.85it/s] 34%|███▍      | 368/1070 [00:43<01:18,  8.90it/s] 34%|███▍      | 369/1070 [00:43<01:17,  9.01it/s] 35%|███▍      | 370/1070 [00:43<01:17,  9.02it/s] 35%|███▍      | 371/1070 [00:43<01:17,  9.01it/s] 35%|███▍      | 372/1070 [00:43<01:17,  8.98it/s] 35%|███▍      | 373/1070 [00:43<01:18,  8.94it/s] 35%|███▍      | 374/1070 [00:43<01:17,  9.01it/s] 35%|███▌      | 375/1070 [00:44<01:17,  8.98it/s] 35%|███▌      | 376/1070 [00:44<01:17,  8.95it/s] 35%|███▌      | 377/1070 [00:44<01:17,  8.95it/s] 35%|███▌      | 378/1070 [00:44<01:16,  8.99it/s] 35%|███▌      | 379/1070 [00:44<01:15,  9.17it/s] 36%|███▌      | 380/1070 [00:44<01:16,  9.07it/s] 36%|███▌      | 381/1070 [00:44<01:15,  9.08it/s] 36%|███▌      | 382/1070 [00:44<01:16,  9.04it/s] 36%|███▌      | 383/1070 [00:44<01:16,  9.00it/s] 36%|███▌      | 384/1070 [00:45<01:16,  8.99it/s] 36%|███▌      | 385/1070 [00:45<01:16,  9.00it/s] 36%|███▌      | 386/1070 [00:45<01:15,  9.10it/s] 36%|███▌      | 387/1070 [00:45<01:16,  8.98it/s] 36%|███▋      | 388/1070 [00:45<01:16,  8.95it/s] 36%|███▋      | 389/1070 [00:45<01:15,  9.05it/s] 36%|███▋      | 390/1070 [00:45<01:15,  9.00it/s] 37%|███▋      | 391/1070 [00:45<01:15,  9.00it/s] 37%|███▋      | 392/1070 [00:45<01:15,  9.00it/s] 37%|███▋      | 393/1070 [00:46<01:15,  8.93it/s] 37%|███▋      | 394/1070 [00:46<01:15,  8.91it/s] 37%|███▋      | 395/1070 [00:46<01:15,  8.95it/s] 37%|███▋      | 396/1070 [00:46<01:14,  9.05it/s] 37%|███▋      | 397/1070 [00:46<01:14,  9.03it/s] 37%|███▋      | 398/1070 [00:46<01:13,  9.08it/s] 37%|███▋      | 399/1070 [00:46<01:14,  9.06it/s] 37%|███▋      | 400/1070 [00:46<01:14,  9.02it/s] 37%|███▋      | 401/1070 [00:46<01:14,  9.04it/s] 38%|███▊      | 402/1070 [00:47<01:14,  8.96it/s] 38%|███▊      | 403/1070 [00:47<01:15,  8.86it/s] 38%|███▊      | 404/1070 [00:47<01:15,  8.85it/s] 38%|███▊      | 405/1070 [00:47<01:14,  8.92it/s] 38%|███▊      | 406/1070 [00:47<01:13,  9.04it/s] 38%|███▊      | 407/1070 [00:47<01:13,  9.02it/s] 38%|███▊      | 408/1070 [00:47<01:13,  8.96it/s] 38%|███▊      | 409/1070 [00:47<01:13,  8.99it/s] 38%|███▊      | 410/1070 [00:47<01:13,  8.99it/s] 38%|███▊      | 411/1070 [00:48<01:13,  8.98it/s] 39%|███▊      | 412/1070 [00:48<01:13,  8.92it/s] 39%|███▊      | 413/1070 [00:48<01:13,  8.93it/s] 39%|███▊      | 414/1070 [00:48<01:13,  8.88it/s] 39%|███▉      | 415/1070 [00:48<01:13,  8.91it/s] 39%|███▉      | 416/1070 [00:48<01:12,  9.00it/s] 39%|███▉      | 417/1070 [00:48<01:12,  8.95it/s] 39%|███▉      | 418/1070 [00:48<01:12,  8.96it/s] 39%|███▉      | 419/1070 [00:49<01:12,  8.93it/s] 39%|███▉      | 420/1070 [00:49<01:12,  8.93it/s] 39%|███▉      | 421/1070 [00:49<01:12,  8.92it/s] 39%|███▉      | 422/1070 [00:49<01:13,  8.87it/s] 40%|███▉      | 423/1070 [00:49<01:12,  8.95it/s] 40%|███▉      | 424/1070 [00:49<01:12,  8.85it/s] 40%|███▉      | 425/1070 [00:49<01:13,  8.80it/s] 40%|███▉      | 426/1070 [00:49<01:12,  8.93it/s] 40%|███▉      | 427/1070 [00:49<01:11,  8.93it/s]                                                   40%|████      | 428/1070 [00:50<01:11,  8.93it/s][INFO|trainer.py:755] 2023-11-15 21:48:18,892 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:48:18,894 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:48:18,894 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:48:18,894 >>   Batch size = 8
{'eval_loss': 0.33040139079093933, 'eval_accuracy': 0.8960526315789473, 'eval_micro_f1': 0.8960526315789473, 'eval_macro_f1': 0.8936446024910546, 'eval_runtime': 1.3631, 'eval_samples_per_second': 557.547, 'eval_steps_per_second': 69.693, 'epoch': 1.0}
{'loss': 0.2535, 'learning_rate': 1.2e-05, 'epoch': 2.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 75.18it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 73.96it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 72.51it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 70.33it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 69.54it/s][A
 49%|████▉     | 47/95 [00:00<00:00, 68.11it/s][A
 57%|█████▋    | 54/95 [00:00<00:00, 68.59it/s][A
 64%|██████▍   | 61/95 [00:00<00:00, 68.91it/s][A
 72%|███████▏  | 68/95 [00:00<00:00, 68.97it/s][A
 79%|███████▉  | 75/95 [00:01<00:00, 68.41it/s][A
 86%|████████▋ | 82/95 [00:01<00:00, 68.66it/s][A
 95%|█████████▍| 90/95 [00:01<00:00, 68.95it/s][A                                                  
                                               [A 40%|████      | 428/1070 [00:51<01:11,  8.93it/s]
100%|██████████| 95/95 [00:01<00:00, 68.95it/s][A
                                               [A 40%|████      | 429/1070 [00:51<04:40,  2.28it/s] 40%|████      | 430/1070 [00:51<03:49,  2.79it/s] 40%|████      | 431/1070 [00:51<03:07,  3.41it/s] 40%|████      | 432/1070 [00:51<02:35,  4.09it/s] 40%|████      | 433/1070 [00:51<02:11,  4.83it/s] 41%|████      | 434/1070 [00:52<01:55,  5.53it/s] 41%|████      | 435/1070 [00:52<01:42,  6.20it/s] 41%|████      | 436/1070 [00:52<01:33,  6.81it/s] 41%|████      | 437/1070 [00:52<01:26,  7.35it/s] 41%|████      | 438/1070 [00:52<01:21,  7.74it/s] 41%|████      | 439/1070 [00:52<01:18,  8.03it/s] 41%|████      | 440/1070 [00:52<01:15,  8.30it/s] 41%|████      | 441/1070 [00:52<01:14,  8.45it/s] 41%|████▏     | 442/1070 [00:53<01:13,  8.59it/s] 41%|████▏     | 443/1070 [00:53<01:12,  8.59it/s] 41%|████▏     | 444/1070 [00:53<01:11,  8.70it/s] 42%|████▏     | 445/1070 [00:53<01:11,  8.71it/s] 42%|████▏     | 446/1070 [00:53<01:10,  8.79it/s] 42%|████▏     | 447/1070 [00:53<01:10,  8.88it/s] 42%|████▏     | 448/1070 [00:53<01:09,  8.89it/s] 42%|████▏     | 449/1070 [00:53<01:09,  8.91it/s] 42%|████▏     | 450/1070 [00:53<01:09,  8.90it/s] 42%|████▏     | 451/1070 [00:54<01:09,  8.93it/s] 42%|████▏     | 452/1070 [00:54<01:09,  8.93it/s] 42%|████▏     | 453/1070 [00:54<01:10,  8.80it/s] 42%|████▏     | 454/1070 [00:54<01:09,  8.83it/s] 43%|████▎     | 455/1070 [00:54<01:09,  8.81it/s] 43%|████▎     | 456/1070 [00:54<01:09,  8.81it/s] 43%|████▎     | 457/1070 [00:54<01:08,  8.94it/s] 43%|████▎     | 458/1070 [00:54<01:08,  8.89it/s] 43%|████▎     | 459/1070 [00:54<01:09,  8.84it/s] 43%|████▎     | 460/1070 [00:55<01:09,  8.82it/s] 43%|████▎     | 461/1070 [00:55<01:08,  8.83it/s] 43%|████▎     | 462/1070 [00:55<01:08,  8.86it/s] 43%|████▎     | 463/1070 [00:55<01:09,  8.78it/s] 43%|████▎     | 464/1070 [00:55<01:09,  8.74it/s] 43%|████▎     | 465/1070 [00:55<01:09,  8.73it/s] 44%|████▎     | 466/1070 [00:55<01:08,  8.79it/s] 44%|████▎     | 467/1070 [00:55<01:07,  8.90it/s] 44%|████▎     | 468/1070 [00:55<01:07,  8.87it/s] 44%|████▍     | 469/1070 [00:56<01:07,  8.85it/s] 44%|████▍     | 470/1070 [00:56<01:07,  8.88it/s] 44%|████▍     | 471/1070 [00:56<01:07,  8.90it/s] 44%|████▍     | 472/1070 [00:56<01:07,  8.89it/s] 44%|████▍     | 473/1070 [00:56<01:07,  8.88it/s] 44%|████▍     | 474/1070 [00:56<01:06,  8.94it/s] 44%|████▍     | 475/1070 [00:56<01:07,  8.87it/s] 44%|████▍     | 476/1070 [00:56<01:06,  8.94it/s] 45%|████▍     | 477/1070 [00:56<01:05,  9.03it/s] 45%|████▍     | 478/1070 [00:57<01:05,  9.00it/s] 45%|████▍     | 479/1070 [00:57<01:06,  8.89it/s] 45%|████▍     | 480/1070 [00:57<01:06,  8.94it/s] 45%|████▍     | 481/1070 [00:57<01:06,  8.86it/s] 45%|████▌     | 482/1070 [00:57<01:06,  8.88it/s] 45%|████▌     | 483/1070 [00:57<01:06,  8.85it/s] 45%|████▌     | 484/1070 [00:57<01:05,  8.98it/s] 45%|████▌     | 485/1070 [00:57<01:05,  8.96it/s] 45%|████▌     | 486/1070 [00:57<01:05,  8.93it/s] 46%|████▌     | 487/1070 [00:58<01:05,  8.93it/s] 46%|████▌     | 488/1070 [00:58<01:05,  8.88it/s] 46%|████▌     | 489/1070 [00:58<01:05,  8.88it/s] 46%|████▌     | 490/1070 [00:58<01:05,  8.88it/s] 46%|████▌     | 491/1070 [00:58<01:05,  8.86it/s] 46%|████▌     | 492/1070 [00:58<01:05,  8.85it/s] 46%|████▌     | 493/1070 [00:58<01:05,  8.83it/s] 46%|████▌     | 494/1070 [00:58<01:04,  8.93it/s] 46%|████▋     | 495/1070 [00:58<01:03,  9.01it/s] 46%|████▋     | 496/1070 [00:59<01:04,  8.88it/s] 46%|████▋     | 497/1070 [00:59<01:04,  8.92it/s] 47%|████▋     | 498/1070 [00:59<01:04,  8.90it/s] 47%|████▋     | 499/1070 [00:59<01:04,  8.88it/s] 47%|████▋     | 500/1070 [00:59<01:04,  8.85it/s] 47%|████▋     | 501/1070 [00:59<01:02,  9.06it/s] 47%|████▋     | 502/1070 [00:59<01:03,  8.91it/s] 47%|████▋     | 503/1070 [00:59<01:03,  8.88it/s] 47%|████▋     | 504/1070 [00:59<01:02,  9.00it/s] 47%|████▋     | 505/1070 [01:00<01:02,  8.99it/s] 47%|████▋     | 506/1070 [01:00<01:03,  8.95it/s] 47%|████▋     | 507/1070 [01:00<01:03,  8.94it/s] 47%|████▋     | 508/1070 [01:00<01:03,  8.92it/s] 48%|████▊     | 509/1070 [01:00<01:02,  8.95it/s] 48%|████▊     | 510/1070 [01:00<01:02,  8.92it/s] 48%|████▊     | 511/1070 [01:00<01:02,  8.98it/s] 48%|████▊     | 512/1070 [01:00<01:03,  8.81it/s] 48%|████▊     | 513/1070 [01:00<01:03,  8.80it/s] 48%|████▊     | 514/1070 [01:01<01:02,  8.96it/s] 48%|████▊     | 515/1070 [01:01<01:02,  8.91it/s] 48%|████▊     | 516/1070 [01:01<01:01,  8.95it/s] 48%|████▊     | 517/1070 [01:01<01:02,  8.90it/s] 48%|████▊     | 518/1070 [01:01<01:02,  8.87it/s] 49%|████▊     | 519/1070 [01:01<01:02,  8.88it/s] 49%|████▊     | 520/1070 [01:01<01:01,  8.94it/s] 49%|████▊     | 521/1070 [01:01<01:00,  9.06it/s] 49%|████▉     | 522/1070 [01:01<01:01,  8.92it/s] 49%|████▉     | 523/1070 [01:02<01:01,  8.91it/s] 49%|████▉     | 524/1070 [01:02<01:00,  9.02it/s] 49%|████▉     | 525/1070 [01:02<01:00,  9.01it/s] 49%|████▉     | 526/1070 [01:02<01:00,  9.04it/s] 49%|████▉     | 527/1070 [01:02<01:00,  8.93it/s] 49%|████▉     | 528/1070 [01:02<01:01,  8.87it/s] 49%|████▉     | 529/1070 [01:02<01:00,  8.87it/s] 50%|████▉     | 530/1070 [01:02<01:00,  8.91it/s] 50%|████▉     | 531/1070 [01:03<00:59,  8.99it/s] 50%|████▉     | 532/1070 [01:03<01:00,  8.94it/s] 50%|████▉     | 533/1070 [01:03<01:00,  8.93it/s] 50%|████▉     | 534/1070 [01:03<00:59,  9.01it/s] 50%|█████     | 535/1070 [01:03<00:59,  8.98it/s] 50%|█████     | 536/1070 [01:03<00:59,  8.92it/s] 50%|█████     | 537/1070 [01:03<00:59,  8.94it/s] 50%|█████     | 538/1070 [01:03<00:59,  8.87it/s] 50%|█████     | 539/1070 [01:03<00:59,  8.86it/s] 50%|█████     | 540/1070 [01:04<00:59,  8.90it/s] 51%|█████     | 541/1070 [01:04<00:58,  9.05it/s] 51%|█████     | 542/1070 [01:04<00:58,  8.96it/s] 51%|█████     | 543/1070 [01:04<00:59,  8.93it/s] 51%|█████     | 544/1070 [01:04<00:58,  9.02it/s] 51%|█████     | 545/1070 [01:04<00:58,  9.01it/s] 51%|█████     | 546/1070 [01:04<00:57,  9.05it/s] 51%|█████     | 547/1070 [01:04<00:58,  8.94it/s] 51%|█████     | 548/1070 [01:04<00:59,  8.85it/s] 51%|█████▏    | 549/1070 [01:05<00:58,  8.85it/s] 51%|█████▏    | 550/1070 [01:05<00:58,  8.88it/s] 51%|█████▏    | 551/1070 [01:05<00:58,  8.94it/s] 52%|█████▏    | 552/1070 [01:05<00:58,  8.90it/s] 52%|█████▏    | 553/1070 [01:05<00:58,  8.91it/s] 52%|█████▏    | 554/1070 [01:05<00:57,  9.00it/s] 52%|█████▏    | 555/1070 [01:05<00:57,  8.99it/s] 52%|█████▏    | 556/1070 [01:05<00:57,  8.97it/s] 52%|█████▏    | 557/1070 [01:05<00:57,  8.96it/s] 52%|█████▏    | 558/1070 [01:06<00:57,  8.91it/s] 52%|█████▏    | 559/1070 [01:06<00:57,  8.92it/s] 52%|█████▏    | 560/1070 [01:06<00:57,  8.93it/s] 52%|█████▏    | 561/1070 [01:06<00:56,  9.00it/s] 53%|█████▎    | 562/1070 [01:06<00:57,  8.90it/s] 53%|█████▎    | 563/1070 [01:06<00:57,  8.89it/s] 53%|█████▎    | 564/1070 [01:06<00:56,  8.99it/s] 53%|█████▎    | 565/1070 [01:06<00:56,  8.99it/s] 53%|█████▎    | 566/1070 [01:06<00:55,  9.01it/s] 53%|█████▎    | 567/1070 [01:07<00:56,  8.98it/s] 53%|█████▎    | 568/1070 [01:07<00:56,  8.95it/s] 53%|█████▎    | 569/1070 [01:07<00:56,  8.92it/s] 53%|█████▎    | 570/1070 [01:07<00:55,  8.96it/s] 53%|█████▎    | 571/1070 [01:07<00:55,  9.07it/s] 53%|█████▎    | 572/1070 [01:07<00:55,  8.94it/s] 54%|█████▎    | 573/1070 [01:07<00:56,  8.87it/s] 54%|█████▎    | 574/1070 [01:07<00:55,  8.98it/s] 54%|█████▎    | 575/1070 [01:07<00:55,  8.93it/s] 54%|█████▍    | 576/1070 [01:08<00:55,  8.92it/s] 54%|█████▍    | 577/1070 [01:08<00:55,  8.91it/s] 54%|█████▍    | 578/1070 [01:08<00:55,  8.94it/s] 54%|█████▍    | 579/1070 [01:08<00:54,  8.94it/s] 54%|█████▍    | 580/1070 [01:08<00:54,  8.99it/s] 54%|█████▍    | 581/1070 [01:08<00:53,  9.07it/s] 54%|█████▍    | 582/1070 [01:08<00:54,  8.97it/s] 54%|█████▍    | 583/1070 [01:08<00:54,  8.91it/s] 55%|█████▍    | 584/1070 [01:08<00:54,  8.98it/s] 55%|█████▍    | 585/1070 [01:09<00:54,  8.96it/s] 55%|█████▍    | 586/1070 [01:09<00:54,  8.94it/s] 55%|█████▍    | 587/1070 [01:09<00:54,  8.89it/s] 55%|█████▍    | 588/1070 [01:09<00:54,  8.89it/s] 55%|█████▌    | 589/1070 [01:09<00:53,  8.94it/s] 55%|█████▌    | 590/1070 [01:09<00:53,  8.97it/s] 55%|█████▌    | 591/1070 [01:09<00:52,  9.10it/s] 55%|█████▌    | 592/1070 [01:09<00:53,  8.98it/s] 55%|█████▌    | 593/1070 [01:09<00:53,  8.97it/s] 56%|█████▌    | 594/1070 [01:10<00:52,  9.05it/s] 56%|█████▌    | 595/1070 [01:10<00:52,  9.04it/s] 56%|█████▌    | 596/1070 [01:10<00:52,  8.96it/s] 56%|█████▌    | 597/1070 [01:10<00:52,  8.99it/s] 56%|█████▌    | 598/1070 [01:10<00:52,  8.93it/s] 56%|█████▌    | 599/1070 [01:10<00:52,  8.95it/s] 56%|█████▌    | 600/1070 [01:10<00:52,  8.94it/s] 56%|█████▌    | 601/1070 [01:10<00:52,  8.95it/s] 56%|█████▋    | 602/1070 [01:10<00:52,  8.95it/s] 56%|█████▋    | 603/1070 [01:11<00:52,  8.89it/s] 56%|█████▋    | 604/1070 [01:11<00:51,  9.05it/s] 57%|█████▋    | 605/1070 [01:11<00:51,  8.98it/s] 57%|█████▋    | 606/1070 [01:11<00:52,  8.85it/s] 57%|█████▋    | 607/1070 [01:11<00:52,  8.86it/s] 57%|█████▋    | 608/1070 [01:11<00:51,  8.89it/s] 57%|█████▋    | 609/1070 [01:11<00:51,  8.90it/s] 57%|█████▋    | 610/1070 [01:11<00:52,  8.80it/s] 57%|█████▋    | 611/1070 [01:11<00:52,  8.77it/s] 57%|█████▋    | 612/1070 [01:12<00:52,  8.81it/s] 57%|█████▋    | 613/1070 [01:12<00:51,  8.85it/s] 57%|█████▋    | 614/1070 [01:12<00:50,  8.95it/s] 57%|█████▋    | 615/1070 [01:12<00:50,  8.95it/s] 58%|█████▊    | 616/1070 [01:12<00:50,  8.93it/s] 58%|█████▊    | 617/1070 [01:12<00:50,  8.99it/s] 58%|█████▊    | 618/1070 [01:12<00:50,  8.92it/s] 58%|█████▊    | 619/1070 [01:12<00:50,  8.94it/s] 58%|█████▊    | 620/1070 [01:12<00:50,  8.88it/s] 58%|█████▊    | 621/1070 [01:13<00:50,  8.82it/s] 58%|█████▊    | 622/1070 [01:13<00:50,  8.84it/s] 58%|█████▊    | 623/1070 [01:13<00:50,  8.89it/s] 58%|█████▊    | 624/1070 [01:13<00:49,  9.00it/s] 58%|█████▊    | 625/1070 [01:13<00:49,  8.92it/s] 59%|█████▊    | 626/1070 [01:13<00:49,  8.97it/s] 59%|█████▊    | 627/1070 [01:13<00:48,  9.05it/s] 59%|█████▊    | 628/1070 [01:13<00:48,  9.03it/s] 59%|█████▉    | 629/1070 [01:13<00:49,  8.96it/s] 59%|█████▉    | 630/1070 [01:14<00:49,  8.96it/s] 59%|█████▉    | 631/1070 [01:14<00:48,  8.96it/s] 59%|█████▉    | 632/1070 [01:14<00:48,  8.95it/s] 59%|█████▉    | 633/1070 [01:14<00:48,  8.98it/s] 59%|█████▉    | 634/1070 [01:14<00:48,  9.01it/s] 59%|█████▉    | 635/1070 [01:14<00:48,  8.95it/s] 59%|█████▉    | 636/1070 [01:14<00:48,  8.94it/s] 60%|█████▉    | 637/1070 [01:14<00:47,  9.06it/s] 60%|█████▉    | 638/1070 [01:14<00:47,  9.07it/s] 60%|█████▉    | 639/1070 [01:15<00:47,  9.00it/s] 60%|█████▉    | 640/1070 [01:15<00:48,  8.92it/s] 60%|█████▉    | 641/1070 [01:15<00:47,  8.95it/s]                                                   60%|██████    | 642/1070 [01:15<00:47,  8.95it/s][INFO|trainer.py:755] 2023-11-15 21:48:44,286 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:48:44,288 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:48:44,289 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:48:44,289 >>   Batch size = 8
{'eval_loss': 0.30767035484313965, 'eval_accuracy': 0.8960526315789473, 'eval_micro_f1': 0.8960526315789473, 'eval_macro_f1': 0.8929667283320889, 'eval_runtime': 1.425, 'eval_samples_per_second': 533.328, 'eval_steps_per_second': 66.666, 'epoch': 2.0}
{'loss': 0.1637, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 74.69it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 71.89it/s][A
 25%|██▌       | 24/95 [00:00<00:01, 70.74it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 70.72it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 71.11it/s][A
 51%|█████     | 48/95 [00:00<00:00, 68.84it/s][A
 58%|█████▊    | 55/95 [00:00<00:00, 68.98it/s][A
 66%|██████▋   | 63/95 [00:00<00:00, 70.48it/s][A
 75%|███████▍  | 71/95 [00:01<00:00, 69.93it/s][A
 83%|████████▎ | 79/95 [00:01<00:00, 68.46it/s][A
 92%|█████████▏| 87/95 [00:01<00:00, 68.21it/s][A
100%|██████████| 95/95 [00:01<00:00, 69.16it/s][A                                                  
                                               [A 60%|██████    | 642/1070 [01:16<00:47,  8.95it/s]
100%|██████████| 95/95 [00:01<00:00, 69.16it/s][A
                                               [A 60%|██████    | 643/1070 [01:16<03:08,  2.27it/s] 60%|██████    | 644/1070 [01:17<02:32,  2.79it/s] 60%|██████    | 645/1070 [01:17<02:05,  3.39it/s] 60%|██████    | 646/1070 [01:17<01:44,  4.06it/s] 60%|██████    | 647/1070 [01:17<01:28,  4.80it/s] 61%|██████    | 648/1070 [01:17<01:16,  5.51it/s] 61%|██████    | 649/1070 [01:17<01:07,  6.21it/s] 61%|██████    | 650/1070 [01:17<01:01,  6.81it/s] 61%|██████    | 651/1070 [01:17<00:57,  7.34it/s] 61%|██████    | 652/1070 [01:17<00:54,  7.69it/s] 61%|██████    | 653/1070 [01:18<00:52,  8.00it/s] 61%|██████    | 654/1070 [01:18<00:49,  8.34it/s] 61%|██████    | 655/1070 [01:18<00:48,  8.48it/s] 61%|██████▏   | 656/1070 [01:18<00:48,  8.56it/s] 61%|██████▏   | 657/1070 [01:18<00:47,  8.61it/s] 61%|██████▏   | 658/1070 [01:18<00:47,  8.74it/s] 62%|██████▏   | 659/1070 [01:18<00:46,  8.85it/s] 62%|██████▏   | 660/1070 [01:18<00:46,  8.73it/s] 62%|██████▏   | 661/1070 [01:18<00:46,  8.80it/s] 62%|██████▏   | 662/1070 [01:19<00:46,  8.83it/s] 62%|██████▏   | 663/1070 [01:19<00:45,  8.87it/s] 62%|██████▏   | 664/1070 [01:19<00:45,  8.96it/s] 62%|██████▏   | 665/1070 [01:19<00:45,  8.95it/s] 62%|██████▏   | 666/1070 [01:19<00:45,  8.91it/s] 62%|██████▏   | 667/1070 [01:19<00:45,  8.88it/s] 62%|██████▏   | 668/1070 [01:19<00:45,  8.90it/s] 63%|██████▎   | 669/1070 [01:19<00:44,  8.96it/s] 63%|██████▎   | 670/1070 [01:19<00:44,  8.90it/s] 63%|██████▎   | 671/1070 [01:20<00:44,  8.92it/s] 63%|██████▎   | 672/1070 [01:20<00:44,  8.93it/s] 63%|██████▎   | 673/1070 [01:20<00:44,  8.96it/s] 63%|██████▎   | 674/1070 [01:20<00:43,  9.04it/s] 63%|██████▎   | 675/1070 [01:20<00:44,  8.95it/s] 63%|██████▎   | 676/1070 [01:20<00:44,  8.91it/s] 63%|██████▎   | 677/1070 [01:20<00:44,  8.87it/s] 63%|██████▎   | 678/1070 [01:20<00:44,  8.91it/s] 63%|██████▎   | 679/1070 [01:20<00:43,  8.92it/s] 64%|██████▎   | 680/1070 [01:21<00:44,  8.83it/s] 64%|██████▎   | 681/1070 [01:21<00:44,  8.81it/s] 64%|██████▎   | 682/1070 [01:21<00:43,  8.86it/s] 64%|██████▍   | 683/1070 [01:21<00:43,  8.88it/s] 64%|██████▍   | 684/1070 [01:21<00:43,  8.92it/s] 64%|██████▍   | 685/1070 [01:21<00:43,  8.91it/s] 64%|██████▍   | 686/1070 [01:21<00:43,  8.89it/s] 64%|██████▍   | 687/1070 [01:21<00:43,  8.87it/s] 64%|██████▍   | 688/1070 [01:22<00:43,  8.85it/s] 64%|██████▍   | 689/1070 [01:22<00:42,  8.86it/s] 64%|██████▍   | 690/1070 [01:22<00:43,  8.82it/s] 65%|██████▍   | 691/1070 [01:22<00:43,  8.78it/s] 65%|██████▍   | 692/1070 [01:22<00:42,  8.84it/s] 65%|██████▍   | 693/1070 [01:22<00:42,  8.90it/s] 65%|██████▍   | 694/1070 [01:22<00:41,  9.03it/s] 65%|██████▍   | 695/1070 [01:22<00:42,  8.87it/s] 65%|██████▌   | 696/1070 [01:22<00:42,  8.88it/s] 65%|██████▌   | 697/1070 [01:23<00:42,  8.88it/s] 65%|██████▌   | 698/1070 [01:23<00:41,  8.86it/s] 65%|██████▌   | 699/1070 [01:23<00:41,  8.92it/s] 65%|██████▌   | 700/1070 [01:23<00:41,  8.89it/s] 66%|██████▌   | 701/1070 [01:23<00:41,  8.85it/s] 66%|██████▌   | 702/1070 [01:23<00:41,  8.84it/s] 66%|██████▌   | 703/1070 [01:23<00:41,  8.87it/s] 66%|██████▌   | 704/1070 [01:23<00:40,  8.96it/s] 66%|██████▌   | 705/1070 [01:23<00:41,  8.84it/s] 66%|██████▌   | 706/1070 [01:24<00:41,  8.78it/s] 66%|██████▌   | 707/1070 [01:24<00:40,  8.91it/s] 66%|██████▌   | 708/1070 [01:24<00:40,  8.89it/s] 66%|██████▋   | 709/1070 [01:24<00:40,  8.91it/s] 66%|██████▋   | 710/1070 [01:24<00:40,  8.91it/s] 66%|██████▋   | 711/1070 [01:24<00:40,  8.82it/s] 67%|██████▋   | 712/1070 [01:24<00:40,  8.84it/s] 67%|██████▋   | 713/1070 [01:24<00:40,  8.89it/s] 67%|██████▋   | 714/1070 [01:24<00:39,  8.99it/s] 67%|██████▋   | 715/1070 [01:25<00:39,  8.89it/s] 67%|██████▋   | 716/1070 [01:25<00:39,  8.89it/s] 67%|██████▋   | 717/1070 [01:25<00:39,  8.96it/s] 67%|██████▋   | 718/1070 [01:25<00:39,  8.90it/s] 67%|██████▋   | 719/1070 [01:25<00:39,  8.90it/s] 67%|██████▋   | 720/1070 [01:25<00:39,  8.91it/s] 67%|██████▋   | 721/1070 [01:25<00:39,  8.86it/s] 67%|██████▋   | 722/1070 [01:25<00:39,  8.88it/s] 68%|██████▊   | 723/1070 [01:25<00:38,  8.96it/s] 68%|██████▊   | 724/1070 [01:26<00:38,  8.99it/s] 68%|██████▊   | 725/1070 [01:26<00:39,  8.84it/s] 68%|██████▊   | 726/1070 [01:26<00:39,  8.78it/s] 68%|██████▊   | 727/1070 [01:26<00:38,  8.92it/s] 68%|██████▊   | 728/1070 [01:26<00:38,  8.94it/s] 68%|██████▊   | 729/1070 [01:26<00:38,  8.84it/s] 68%|██████▊   | 730/1070 [01:26<00:38,  8.92it/s] 68%|██████▊   | 731/1070 [01:26<00:38,  8.87it/s] 68%|██████▊   | 732/1070 [01:26<00:38,  8.87it/s] 69%|██████▊   | 733/1070 [01:27<00:38,  8.81it/s] 69%|██████▊   | 734/1070 [01:27<00:37,  8.87it/s] 69%|██████▊   | 735/1070 [01:27<00:37,  8.83it/s] 69%|██████▉   | 736/1070 [01:27<00:37,  8.80it/s] 69%|██████▉   | 737/1070 [01:27<00:37,  8.95it/s] 69%|██████▉   | 738/1070 [01:27<00:37,  8.96it/s] 69%|██████▉   | 739/1070 [01:27<00:36,  8.95it/s] 69%|██████▉   | 740/1070 [01:27<00:36,  8.94it/s] 69%|██████▉   | 741/1070 [01:27<00:36,  8.98it/s] 69%|██████▉   | 742/1070 [01:28<00:36,  8.98it/s] 69%|██████▉   | 743/1070 [01:28<00:36,  8.90it/s] 70%|██████▉   | 744/1070 [01:28<00:36,  8.94it/s] 70%|██████▉   | 745/1070 [01:28<00:36,  8.93it/s] 70%|██████▉   | 746/1070 [01:28<00:36,  8.93it/s] 70%|██████▉   | 747/1070 [01:28<00:35,  9.00it/s] 70%|██████▉   | 748/1070 [01:28<00:36,  8.93it/s] 70%|███████   | 749/1070 [01:28<00:35,  8.93it/s] 70%|███████   | 750/1070 [01:28<00:35,  8.94it/s] 70%|███████   | 751/1070 [01:29<00:35,  8.96it/s] 70%|███████   | 752/1070 [01:29<00:35,  9.02it/s] 70%|███████   | 753/1070 [01:29<00:35,  8.99it/s] 70%|███████   | 754/1070 [01:29<00:35,  8.87it/s] 71%|███████   | 755/1070 [01:29<00:35,  8.86it/s] 71%|███████   | 756/1070 [01:29<00:35,  8.93it/s] 71%|███████   | 757/1070 [01:29<00:34,  8.96it/s] 71%|███████   | 758/1070 [01:29<00:34,  8.92it/s] 71%|███████   | 759/1070 [01:29<00:34,  8.90it/s] 71%|███████   | 760/1070 [01:30<00:34,  8.99it/s] 71%|███████   | 761/1070 [01:30<00:34,  8.97it/s] 71%|███████   | 762/1070 [01:30<00:34,  8.91it/s] 71%|███████▏  | 763/1070 [01:30<00:34,  8.91it/s] 71%|███████▏  | 764/1070 [01:30<00:34,  8.94it/s] 71%|███████▏  | 765/1070 [01:30<00:34,  8.96it/s] 72%|███████▏  | 766/1070 [01:30<00:34,  8.92it/s] 72%|███████▏  | 767/1070 [01:30<00:33,  8.93it/s] 72%|███████▏  | 768/1070 [01:30<00:33,  8.99it/s] 72%|███████▏  | 769/1070 [01:31<00:33,  8.96it/s] 72%|███████▏  | 770/1070 [01:31<00:33,  9.09it/s] 72%|███████▏  | 771/1070 [01:31<00:33,  9.02it/s] 72%|███████▏  | 772/1070 [01:31<00:32,  9.06it/s] 72%|███████▏  | 773/1070 [01:31<00:32,  9.04it/s] 72%|███████▏  | 774/1070 [01:31<00:32,  9.03it/s] 72%|███████▏  | 775/1070 [01:31<00:32,  9.07it/s] 73%|███████▎  | 776/1070 [01:31<00:32,  8.97it/s] 73%|███████▎  | 777/1070 [01:31<00:32,  8.92it/s] 73%|███████▎  | 778/1070 [01:32<00:32,  8.96it/s] 73%|███████▎  | 779/1070 [01:32<00:32,  8.99it/s] 73%|███████▎  | 780/1070 [01:32<00:31,  9.08it/s] 73%|███████▎  | 781/1070 [01:32<00:32,  9.02it/s] 73%|███████▎  | 782/1070 [01:32<00:32,  8.95it/s] 73%|███████▎  | 783/1070 [01:32<00:31,  9.09it/s] 73%|███████▎  | 784/1070 [01:32<00:31,  9.09it/s] 73%|███████▎  | 785/1070 [01:32<00:31,  8.99it/s] 73%|███████▎  | 786/1070 [01:32<00:31,  8.99it/s] 74%|███████▎  | 787/1070 [01:33<00:31,  9.05it/s] 74%|███████▎  | 788/1070 [01:33<00:31,  9.00it/s] 74%|███████▎  | 789/1070 [01:33<00:31,  8.92it/s] 74%|███████▍  | 790/1070 [01:33<00:31,  8.87it/s] 74%|███████▍  | 791/1070 [01:33<00:31,  8.90it/s] 74%|███████▍  | 792/1070 [01:33<00:31,  8.94it/s] 74%|███████▍  | 793/1070 [01:33<00:30,  9.08it/s] 74%|███████▍  | 794/1070 [01:33<00:30,  8.99it/s] 74%|███████▍  | 795/1070 [01:33<00:30,  9.01it/s] 74%|███████▍  | 796/1070 [01:34<00:30,  9.04it/s] 74%|███████▍  | 797/1070 [01:34<00:30,  9.03it/s] 75%|███████▍  | 798/1070 [01:34<00:30,  8.95it/s] 75%|███████▍  | 799/1070 [01:34<00:30,  8.95it/s] 75%|███████▍  | 800/1070 [01:34<00:30,  8.99it/s] 75%|███████▍  | 801/1070 [01:34<00:29,  9.00it/s] 75%|███████▍  | 802/1070 [01:34<00:30,  8.91it/s] 75%|███████▌  | 803/1070 [01:34<00:29,  8.96it/s] 75%|███████▌  | 804/1070 [01:34<00:29,  8.98it/s] 75%|███████▌  | 805/1070 [01:35<00:29,  8.95it/s] 75%|███████▌  | 806/1070 [01:35<00:29,  9.02it/s] 75%|███████▌  | 807/1070 [01:35<00:29,  8.91it/s] 76%|███████▌  | 808/1070 [01:35<00:29,  8.92it/s] 76%|███████▌  | 809/1070 [01:35<00:29,  8.92it/s] 76%|███████▌  | 810/1070 [01:35<00:29,  8.94it/s] 76%|███████▌  | 811/1070 [01:35<00:28,  8.97it/s] 76%|███████▌  | 812/1070 [01:35<00:28,  8.95it/s] 76%|███████▌  | 813/1070 [01:35<00:29,  8.86it/s] 76%|███████▌  | 814/1070 [01:36<00:28,  8.88it/s] 76%|███████▌  | 815/1070 [01:36<00:28,  8.92it/s] 76%|███████▋  | 816/1070 [01:36<00:28,  9.03it/s] 76%|███████▋  | 817/1070 [01:36<00:28,  8.84it/s] 76%|███████▋  | 818/1070 [01:36<00:28,  8.84it/s] 77%|███████▋  | 819/1070 [01:36<00:27,  9.00it/s] 77%|███████▋  | 820/1070 [01:36<00:27,  8.99it/s] 77%|███████▋  | 821/1070 [01:36<00:28,  8.84it/s] 77%|███████▋  | 822/1070 [01:37<00:28,  8.82it/s] 77%|███████▋  | 823/1070 [01:37<00:27,  8.91it/s] 77%|███████▋  | 824/1070 [01:37<00:27,  8.92it/s] 77%|███████▋  | 825/1070 [01:37<00:27,  8.89it/s] 77%|███████▋  | 826/1070 [01:37<00:27,  8.93it/s] 77%|███████▋  | 827/1070 [01:37<00:27,  8.89it/s] 77%|███████▋  | 828/1070 [01:37<00:26,  8.96it/s] 77%|███████▋  | 829/1070 [01:37<00:26,  9.04it/s] 78%|███████▊  | 830/1070 [01:37<00:26,  9.00it/s] 78%|███████▊  | 831/1070 [01:38<00:26,  8.94it/s] 78%|███████▊  | 832/1070 [01:38<00:26,  8.93it/s] 78%|███████▊  | 833/1070 [01:38<00:26,  8.91it/s] 78%|███████▊  | 834/1070 [01:38<00:26,  8.94it/s] 78%|███████▊  | 835/1070 [01:38<00:26,  8.85it/s] 78%|███████▊  | 836/1070 [01:38<00:26,  8.82it/s] 78%|███████▊  | 837/1070 [01:38<00:26,  8.83it/s] 78%|███████▊  | 838/1070 [01:38<00:26,  8.88it/s] 78%|███████▊  | 839/1070 [01:38<00:25,  9.00it/s] 79%|███████▊  | 840/1070 [01:39<00:25,  8.90it/s] 79%|███████▊  | 841/1070 [01:39<00:25,  8.88it/s] 79%|███████▊  | 842/1070 [01:39<00:25,  9.03it/s] 79%|███████▉  | 843/1070 [01:39<00:25,  8.98it/s] 79%|███████▉  | 844/1070 [01:39<00:25,  8.94it/s] 79%|███████▉  | 845/1070 [01:39<00:25,  8.93it/s] 79%|███████▉  | 846/1070 [01:39<00:25,  8.92it/s] 79%|███████▉  | 847/1070 [01:39<00:24,  8.95it/s] 79%|███████▉  | 848/1070 [01:39<00:25,  8.83it/s] 79%|███████▉  | 849/1070 [01:40<00:24,  8.86it/s] 79%|███████▉  | 850/1070 [01:40<00:24,  8.85it/s] 80%|███████▉  | 851/1070 [01:40<00:24,  8.90it/s] 80%|███████▉  | 852/1070 [01:40<00:24,  9.04it/s] 80%|███████▉  | 853/1070 [01:40<00:24,  8.94it/s] 80%|███████▉  | 854/1070 [01:40<00:24,  8.91it/s] 80%|███████▉  | 855/1070 [01:40<00:24,  8.91it/s]                                                   80%|████████  | 856/1070 [01:40<00:24,  8.91it/s][INFO|trainer.py:755] 2023-11-15 21:49:09,695 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:49:09,697 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:49:09,697 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:49:09,697 >>   Batch size = 8
{'eval_loss': 0.3707408607006073, 'eval_accuracy': 0.8921052631578947, 'eval_micro_f1': 0.8921052631578947, 'eval_macro_f1': 0.8886146065546326, 'eval_runtime': 1.4158, 'eval_samples_per_second': 536.808, 'eval_steps_per_second': 67.101, 'epoch': 3.0}
{'loss': 0.1027, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  9%|▉         | 9/95 [00:00<00:01, 80.07it/s][A
 19%|█▉        | 18/95 [00:00<00:01, 72.49it/s][A
 27%|██▋       | 26/95 [00:00<00:00, 72.13it/s][A
 36%|███▌      | 34/95 [00:00<00:00, 70.82it/s][A
 44%|████▍     | 42/95 [00:00<00:00, 70.01it/s][A
 53%|█████▎    | 50/95 [00:00<00:00, 69.66it/s][A
 60%|██████    | 57/95 [00:00<00:00, 69.36it/s][A
 68%|██████▊   | 65/95 [00:00<00:00, 70.11it/s][A
 77%|███████▋  | 73/95 [00:01<00:00, 71.24it/s][A
 85%|████████▌ | 81/95 [00:01<00:00, 68.25it/s][A
 94%|█████████▎| 89/95 [00:01<00:00, 68.49it/s][A                                                  
                                               [A 80%|████████  | 856/1070 [01:42<00:24,  8.91it/s]
100%|██████████| 95/95 [00:01<00:00, 68.49it/s][A
                                               [A 80%|████████  | 857/1070 [01:42<01:32,  2.30it/s] 80%|████████  | 858/1070 [01:42<01:15,  2.81it/s] 80%|████████  | 859/1070 [01:42<01:01,  3.41it/s] 80%|████████  | 860/1070 [01:42<00:51,  4.10it/s] 80%|████████  | 861/1070 [01:42<00:43,  4.83it/s] 81%|████████  | 862/1070 [01:42<00:37,  5.50it/s] 81%|████████  | 863/1070 [01:43<00:33,  6.17it/s] 81%|████████  | 864/1070 [01:43<00:30,  6.76it/s] 81%|████████  | 865/1070 [01:43<00:28,  7.29it/s] 81%|████████  | 866/1070 [01:43<00:26,  7.80it/s] 81%|████████  | 867/1070 [01:43<00:25,  8.09it/s] 81%|████████  | 868/1070 [01:43<00:24,  8.32it/s] 81%|████████  | 869/1070 [01:43<00:23,  8.51it/s] 81%|████████▏ | 870/1070 [01:43<00:23,  8.64it/s] 81%|████████▏ | 871/1070 [01:43<00:22,  8.69it/s] 81%|████████▏ | 872/1070 [01:44<00:22,  8.76it/s] 82%|████████▏ | 873/1070 [01:44<00:22,  8.76it/s] 82%|████████▏ | 874/1070 [01:44<00:22,  8.81it/s] 82%|████████▏ | 875/1070 [01:44<00:22,  8.79it/s] 82%|████████▏ | 876/1070 [01:44<00:21,  8.92it/s] 82%|████████▏ | 877/1070 [01:44<00:21,  8.90it/s] 82%|████████▏ | 878/1070 [01:44<00:21,  8.99it/s] 82%|████████▏ | 879/1070 [01:44<00:21,  9.09it/s] 82%|████████▏ | 880/1070 [01:44<00:21,  8.98it/s] 82%|████████▏ | 881/1070 [01:45<00:21,  8.96it/s] 82%|████████▏ | 882/1070 [01:45<00:20,  9.02it/s] 83%|████████▎ | 883/1070 [01:45<00:20,  9.05it/s] 83%|████████▎ | 884/1070 [01:45<00:20,  9.03it/s] 83%|████████▎ | 885/1070 [01:45<00:20,  8.93it/s] 83%|████████▎ | 886/1070 [01:45<00:20,  8.91it/s] 83%|████████▎ | 887/1070 [01:45<00:20,  8.95it/s] 83%|████████▎ | 888/1070 [01:45<00:20,  8.95it/s] 83%|████████▎ | 889/1070 [01:45<00:19,  9.06it/s] 83%|████████▎ | 890/1070 [01:46<00:19,  9.01it/s] 83%|████████▎ | 891/1070 [01:46<00:19,  8.96it/s] 83%|████████▎ | 892/1070 [01:46<00:19,  9.04it/s] 83%|████████▎ | 893/1070 [01:46<00:19,  8.98it/s] 84%|████████▎ | 894/1070 [01:46<00:19,  8.99it/s] 84%|████████▎ | 895/1070 [01:46<00:19,  8.96it/s] 84%|████████▎ | 896/1070 [01:46<00:19,  8.98it/s] 84%|████████▍ | 897/1070 [01:46<00:19,  9.00it/s] 84%|████████▍ | 898/1070 [01:46<00:19,  9.04it/s] 84%|████████▍ | 899/1070 [01:47<00:18,  9.03it/s] 84%|████████▍ | 900/1070 [01:47<00:18,  8.95it/s] 84%|████████▍ | 901/1070 [01:47<00:18,  8.92it/s] 84%|████████▍ | 902/1070 [01:47<00:18,  9.06it/s] 84%|████████▍ | 903/1070 [01:47<00:18,  8.98it/s] 84%|████████▍ | 904/1070 [01:47<00:18,  8.99it/s] 85%|████████▍ | 905/1070 [01:47<00:18,  9.01it/s] 85%|████████▍ | 906/1070 [01:47<00:18,  8.99it/s] 85%|████████▍ | 907/1070 [01:47<00:18,  9.05it/s] 85%|████████▍ | 908/1070 [01:48<00:18,  8.98it/s] 85%|████████▍ | 909/1070 [01:48<00:18,  8.89it/s] 85%|████████▌ | 910/1070 [01:48<00:18,  8.88it/s] 85%|████████▌ | 911/1070 [01:48<00:17,  8.85it/s] 85%|████████▌ | 912/1070 [01:48<00:17,  8.91it/s] 85%|████████▌ | 913/1070 [01:48<00:17,  8.95it/s] 85%|████████▌ | 914/1070 [01:48<00:17,  8.92it/s] 86%|████████▌ | 915/1070 [01:48<00:17,  9.06it/s] 86%|████████▌ | 916/1070 [01:48<00:17,  8.99it/s] 86%|████████▌ | 917/1070 [01:49<00:17,  8.99it/s] 86%|████████▌ | 918/1070 [01:49<00:17,  8.92it/s] 86%|████████▌ | 919/1070 [01:49<00:16,  8.92it/s] 86%|████████▌ | 920/1070 [01:49<00:16,  9.01it/s] 86%|████████▌ | 921/1070 [01:49<00:16,  8.96it/s] 86%|████████▌ | 922/1070 [01:49<00:16,  8.95it/s] 86%|████████▋ | 923/1070 [01:49<00:16,  8.93it/s] 86%|████████▋ | 924/1070 [01:49<00:16,  8.93it/s] 86%|████████▋ | 925/1070 [01:49<00:16,  9.04it/s] 87%|████████▋ | 926/1070 [01:50<00:16,  8.96it/s] 87%|████████▋ | 927/1070 [01:50<00:15,  8.98it/s] 87%|████████▋ | 928/1070 [01:50<00:15,  9.01it/s] 87%|████████▋ | 929/1070 [01:50<00:15,  8.96it/s] 87%|████████▋ | 930/1070 [01:50<00:15,  8.94it/s] 87%|████████▋ | 931/1070 [01:50<00:15,  8.99it/s] 87%|████████▋ | 932/1070 [01:50<00:15,  8.92it/s] 87%|████████▋ | 933/1070 [01:50<00:15,  8.93it/s] 87%|████████▋ | 934/1070 [01:50<00:15,  8.96it/s] 87%|████████▋ | 935/1070 [01:51<00:15,  8.97it/s] 87%|████████▋ | 936/1070 [01:51<00:14,  9.00it/s] 88%|████████▊ | 937/1070 [01:51<00:14,  8.94it/s] 88%|████████▊ | 938/1070 [01:51<00:14,  9.07it/s] 88%|████████▊ | 939/1070 [01:51<00:14,  9.00it/s] 88%|████████▊ | 940/1070 [01:51<00:14,  8.99it/s] 88%|████████▊ | 941/1070 [01:51<00:14,  8.96it/s] 88%|████████▊ | 942/1070 [01:51<00:14,  8.99it/s] 88%|████████▊ | 943/1070 [01:51<00:14,  8.92it/s] 88%|████████▊ | 944/1070 [01:52<00:14,  8.88it/s] 88%|████████▊ | 945/1070 [01:52<00:14,  8.85it/s] 88%|████████▊ | 946/1070 [01:52<00:14,  8.85it/s] 89%|████████▊ | 947/1070 [01:52<00:13,  8.87it/s] 89%|████████▊ | 948/1070 [01:52<00:13,  9.00it/s] 89%|████████▊ | 949/1070 [01:52<00:13,  8.93it/s] 89%|████████▉ | 950/1070 [01:52<00:13,  8.94it/s] 89%|████████▉ | 951/1070 [01:52<00:13,  9.00it/s] 89%|████████▉ | 952/1070 [01:52<00:13,  9.00it/s] 89%|████████▉ | 953/1070 [01:53<00:12,  9.01it/s] 89%|████████▉ | 954/1070 [01:53<00:12,  8.97it/s] 89%|████████▉ | 955/1070 [01:53<00:12,  8.94it/s] 89%|████████▉ | 956/1070 [01:53<00:12,  8.90it/s] 89%|████████▉ | 957/1070 [01:53<00:12,  8.85it/s] 90%|████████▉ | 958/1070 [01:53<00:12,  9.00it/s] 90%|████████▉ | 959/1070 [01:53<00:12,  8.86it/s] 90%|████████▉ | 960/1070 [01:53<00:12,  8.88it/s] 90%|████████▉ | 961/1070 [01:53<00:12,  9.03it/s] 90%|████████▉ | 962/1070 [01:54<00:11,  9.01it/s] 90%|█████████ | 963/1070 [01:54<00:11,  8.96it/s] 90%|█████████ | 964/1070 [01:54<00:11,  8.93it/s] 90%|█████████ | 965/1070 [01:54<00:11,  8.98it/s] 90%|█████████ | 966/1070 [01:54<00:11,  8.96it/s] 90%|█████████ | 967/1070 [01:54<00:11,  8.86it/s] 90%|█████████ | 968/1070 [01:54<00:11,  8.78it/s] 91%|█████████ | 969/1070 [01:54<00:11,  8.82it/s] 91%|█████████ | 970/1070 [01:54<00:11,  8.89it/s] 91%|█████████ | 971/1070 [01:55<00:11,  8.97it/s] 91%|█████████ | 972/1070 [01:55<00:10,  8.93it/s] 91%|█████████ | 973/1070 [01:55<00:10,  8.90it/s] 91%|█████████ | 974/1070 [01:55<00:10,  8.99it/s] 91%|█████████ | 975/1070 [01:55<00:10,  8.93it/s] 91%|█████████ | 976/1070 [01:55<00:10,  8.87it/s] 91%|█████████▏| 977/1070 [01:55<00:10,  8.85it/s] 91%|█████████▏| 978/1070 [01:55<00:10,  8.87it/s] 91%|█████████▏| 979/1070 [01:55<00:10,  8.95it/s] 92%|█████████▏| 980/1070 [01:56<00:10,  8.92it/s] 92%|█████████▏| 981/1070 [01:56<00:09,  8.91it/s] 92%|█████████▏| 982/1070 [01:56<00:09,  8.86it/s] 92%|█████████▏| 983/1070 [01:56<00:09,  8.88it/s] 92%|█████████▏| 984/1070 [01:56<00:09,  8.97it/s] 92%|█████████▏| 985/1070 [01:56<00:09,  8.87it/s] 92%|█████████▏| 986/1070 [01:56<00:09,  8.92it/s] 92%|█████████▏| 987/1070 [01:56<00:09,  9.01it/s] 92%|█████████▏| 988/1070 [01:56<00:09,  8.98it/s] 92%|█████████▏| 989/1070 [01:57<00:09,  8.93it/s] 93%|█████████▎| 990/1070 [01:57<00:08,  8.91it/s] 93%|█████████▎| 991/1070 [01:57<00:08,  8.95it/s] 93%|█████████▎| 992/1070 [01:57<00:08,  8.91it/s] 93%|█████████▎| 993/1070 [01:57<00:08,  8.89it/s] 93%|█████████▎| 994/1070 [01:57<00:08,  8.96it/s] 93%|█████████▎| 995/1070 [01:57<00:08,  8.99it/s] 93%|█████████▎| 996/1070 [01:57<00:08,  8.98it/s] 93%|█████████▎| 997/1070 [01:57<00:08,  9.08it/s] 93%|█████████▎| 998/1070 [01:58<00:07,  9.04it/s] 93%|█████████▎| 999/1070 [01:58<00:07,  9.00it/s] 93%|█████████▎| 1000/1070 [01:58<00:07,  8.99it/s] 94%|█████████▎| 1001/1070 [01:58<00:07,  8.99it/s] 94%|█████████▎| 1002/1070 [01:58<00:07,  8.99it/s] 94%|█████████▎| 1003/1070 [01:58<00:07,  8.95it/s] 94%|█████████▍| 1004/1070 [01:58<00:07,  8.88it/s] 94%|█████████▍| 1005/1070 [01:58<00:07,  8.92it/s] 94%|█████████▍| 1006/1070 [01:58<00:07,  8.90it/s] 94%|█████████▍| 1007/1070 [01:59<00:06,  9.02it/s] 94%|█████████▍| 1008/1070 [01:59<00:06,  8.94it/s] 94%|█████████▍| 1009/1070 [01:59<00:06,  8.89it/s] 94%|█████████▍| 1010/1070 [01:59<00:06,  9.03it/s] 94%|█████████▍| 1011/1070 [01:59<00:06,  8.95it/s] 95%|█████████▍| 1012/1070 [01:59<00:06,  8.94it/s] 95%|█████████▍| 1013/1070 [01:59<00:06,  8.90it/s] 95%|█████████▍| 1014/1070 [01:59<00:06,  8.94it/s] 95%|█████████▍| 1015/1070 [01:59<00:06,  8.86it/s] 95%|█████████▍| 1016/1070 [02:00<00:06,  8.86it/s] 95%|█████████▌| 1017/1070 [02:00<00:06,  8.78it/s] 95%|█████████▌| 1018/1070 [02:00<00:05,  8.78it/s] 95%|█████████▌| 1019/1070 [02:00<00:05,  8.86it/s] 95%|█████████▌| 1020/1070 [02:00<00:05,  8.98it/s] 95%|█████████▌| 1021/1070 [02:00<00:05,  8.91it/s] 96%|█████████▌| 1022/1070 [02:00<00:05,  8.88it/s] 96%|█████████▌| 1023/1070 [02:00<00:05,  9.01it/s] 96%|█████████▌| 1024/1070 [02:01<00:05,  9.00it/s] 96%|█████████▌| 1025/1070 [02:01<00:05,  8.93it/s] 96%|█████████▌| 1026/1070 [02:01<00:04,  8.85it/s] 96%|█████████▌| 1027/1070 [02:01<00:04,  8.91it/s] 96%|█████████▌| 1028/1070 [02:01<00:04,  8.92it/s] 96%|█████████▌| 1029/1070 [02:01<00:04,  8.85it/s] 96%|█████████▋| 1030/1070 [02:01<00:04,  8.86it/s] 96%|█████████▋| 1031/1070 [02:01<00:04,  8.86it/s] 96%|█████████▋| 1032/1070 [02:01<00:04,  8.91it/s] 97%|█████████▋| 1033/1070 [02:02<00:04,  9.00it/s] 97%|█████████▋| 1034/1070 [02:02<00:04,  8.92it/s] 97%|█████████▋| 1035/1070 [02:02<00:03,  8.93it/s] 97%|█████████▋| 1036/1070 [02:02<00:03,  8.96it/s] 97%|█████████▋| 1037/1070 [02:02<00:03,  8.86it/s] 97%|█████████▋| 1038/1070 [02:02<00:03,  8.93it/s] 97%|█████████▋| 1039/1070 [02:02<00:03,  8.94it/s] 97%|█████████▋| 1040/1070 [02:02<00:03,  8.86it/s] 97%|█████████▋| 1041/1070 [02:02<00:03,  8.86it/s] 97%|█████████▋| 1042/1070 [02:03<00:03,  8.80it/s] 97%|█████████▋| 1043/1070 [02:03<00:03,  8.89it/s] 98%|█████████▊| 1044/1070 [02:03<00:02,  8.83it/s] 98%|█████████▊| 1045/1070 [02:03<00:02,  8.85it/s] 98%|█████████▊| 1046/1070 [02:03<00:02,  8.99it/s] 98%|█████████▊| 1047/1070 [02:03<00:02,  8.96it/s] 98%|█████████▊| 1048/1070 [02:03<00:02,  8.90it/s] 98%|█████████▊| 1049/1070 [02:03<00:02,  8.85it/s] 98%|█████████▊| 1050/1070 [02:03<00:02,  8.90it/s] 98%|█████████▊| 1051/1070 [02:04<00:02,  8.93it/s] 98%|█████████▊| 1052/1070 [02:04<00:02,  8.86it/s] 98%|█████████▊| 1053/1070 [02:04<00:01,  8.85it/s] 99%|█████████▊| 1054/1070 [02:04<00:01,  8.78it/s] 99%|█████████▊| 1055/1070 [02:04<00:01,  8.80it/s] 99%|█████████▊| 1056/1070 [02:04<00:01,  8.94it/s] 99%|█████████▉| 1057/1070 [02:04<00:01,  8.90it/s] 99%|█████████▉| 1058/1070 [02:04<00:01,  8.92it/s] 99%|█████████▉| 1059/1070 [02:04<00:01,  8.97it/s] 99%|█████████▉| 1060/1070 [02:05<00:01,  8.93it/s] 99%|█████████▉| 1061/1070 [02:05<00:01,  8.90it/s] 99%|█████████▉| 1062/1070 [02:05<00:00,  8.90it/s] 99%|█████████▉| 1063/1070 [02:05<00:00,  8.85it/s] 99%|█████████▉| 1064/1070 [02:05<00:00,  8.85it/s]100%|█████████▉| 1065/1070 [02:05<00:00,  8.91it/s]100%|█████████▉| 1066/1070 [02:05<00:00,  8.99it/s]100%|█████████▉| 1067/1070 [02:05<00:00,  8.90it/s]100%|█████████▉| 1068/1070 [02:05<00:00,  8.87it/s]100%|█████████▉| 1069/1070 [02:06<00:00,  9.00it/s]                                                   100%|██████████| 1070/1070 [02:06<00:00,  9.00it/s][INFO|trainer.py:755] 2023-11-15 21:49:35,056 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:49:35,058 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:49:35,058 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:49:35,059 >>   Batch size = 8
{'eval_loss': 0.3880409300327301, 'eval_accuracy': 0.8894736842105263, 'eval_micro_f1': 0.8894736842105263, 'eval_macro_f1': 0.8868933715529157, 'eval_runtime': 1.406, 'eval_samples_per_second': 540.523, 'eval_steps_per_second': 67.565, 'epoch': 4.0}
{'loss': 0.066, 'learning_rate': 0.0, 'epoch': 5.0}

  0%|          | 0/95 [00:00<?, ?it/s][A
  8%|▊         | 8/95 [00:00<00:01, 76.69it/s][A
 17%|█▋        | 16/95 [00:00<00:01, 72.31it/s][A
 25%|██▌       | 24/95 [00:00<00:00, 72.25it/s][A
 34%|███▎      | 32/95 [00:00<00:00, 71.82it/s][A
 42%|████▏     | 40/95 [00:00<00:00, 71.42it/s][A
 51%|█████     | 48/95 [00:00<00:00, 71.22it/s][A
 59%|█████▉    | 56/95 [00:00<00:00, 69.72it/s][A
 66%|██████▋   | 63/95 [00:00<00:00, 69.10it/s][A
 75%|███████▍  | 71/95 [00:00<00:00, 71.50it/s][A
 83%|████████▎ | 79/95 [00:01<00:00, 70.93it/s][A
 92%|█████████▏| 87/95 [00:01<00:00, 68.57it/s][A
100%|██████████| 95/95 [00:01<00:00, 69.37it/s][A                                                   
                                               [A100%|██████████| 1070/1070 [02:07<00:00,  9.00it/s]
100%|██████████| 95/95 [00:01<00:00, 69.37it/s][A
                                               [A[INFO|trainer.py:1963] 2023-11-15 21:49:36,462 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1070/1070 [02:07<00:00,  9.00it/s]100%|██████████| 1070/1070 [02:07<00:00,  8.39it/s]
[INFO|trainer.py:2855] 2023-11-15 21:49:36,466 >> Saving model checkpoint to ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4
[INFO|configuration_utils.py:460] 2023-11-15 21:49:36,469 >> Configuration saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4/config.json
[INFO|modeling_utils.py:1997] 2023-11-15 21:49:37,700 >> Model weights saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4/pytorch_model.bin
[INFO|tokenization_utils_base.py:2235] 2023-11-15 21:49:37,703 >> tokenizer config file saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2242] 2023-11-15 21:49:37,705 >> Special tokens file saved in ./result/agnews_sup_allenai/scibert_scivocab_uncased_adapter__seed4/special_tokens_map.json
{'eval_loss': 0.38912340998649597, 'eval_accuracy': 0.8973684210526316, 'eval_micro_f1': 0.8973684210526317, 'eval_macro_f1': 0.8953476942104773, 'eval_runtime': 1.3991, 'eval_samples_per_second': 543.197, 'eval_steps_per_second': 67.9, 'epoch': 5.0}
{'train_runtime': 127.5788, 'train_samples_per_second': 268.07, 'train_steps_per_second': 8.387, 'train_loss': 0.2223040616400888, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.2223
  train_runtime            = 0:02:07.57
  train_samples            =       6840
  train_samples_per_second =     268.07
  train_steps_per_second   =      8.387
11/15/2023 21:49:37 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:755] 2023-11-15 21:49:37,766 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3129] 2023-11-15 21:49:37,768 >> ***** Running Evaluation *****
[INFO|trainer.py:3131] 2023-11-15 21:49:37,769 >>   Num examples = 760
[INFO|trainer.py:3134] 2023-11-15 21:49:37,769 >>   Batch size = 8
  0%|          | 0/95 [00:00<?, ?it/s]  8%|▊         | 8/95 [00:00<00:01, 76.78it/s] 17%|█▋        | 16/95 [00:00<00:01, 72.01it/s] 25%|██▌       | 24/95 [00:00<00:01, 69.96it/s] 34%|███▎      | 32/95 [00:00<00:00, 69.61it/s] 42%|████▏     | 40/95 [00:00<00:00, 70.39it/s] 51%|█████     | 48/95 [00:00<00:00, 68.52it/s] 58%|█████▊    | 55/95 [00:00<00:00, 68.59it/s] 65%|██████▌   | 62/95 [00:00<00:00, 68.63it/s] 73%|███████▎  | 69/95 [00:00<00:00, 68.82it/s] 80%|████████  | 76/95 [00:01<00:00, 67.97it/s] 87%|████████▋ | 83/95 [00:01<00:00, 68.32it/s] 96%|█████████▌| 91/95 [00:01<00:00, 69.48it/s]100%|██████████| 95/95 [00:01<00:00, 67.59it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8974
  eval_loss               =     0.3891
  eval_macro_f1           =     0.8953
  eval_micro_f1           =     0.8974
  eval_runtime            = 0:00:01.42
  eval_samples            =        760
  eval_samples_per_second =    533.162
  eval_steps_per_second   =     66.645
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▇▇▃▁██
wandb:                      eval/loss ▃▁▆███
wandb:                  eval/macro_f1 ▇▆▂▁██
wandb:                  eval/micro_f1 ▇▇▃▁██
wandb:                   eval/runtime ▁█▇▆▅█
wandb:        eval/samples_per_second █▁▂▃▄▁
wandb:          eval/steps_per_second █▁▂▃▄▁
wandb:                    train/epoch ▁▁▃▃▅▅▆▆████
wandb:              train/global_step ▁▁▃▃▄▄▆▆████
wandb:            train/learning_rate █▆▅▃▁
wandb:                     train/loss █▄▂▂▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 0.89737
wandb:                      eval/loss 0.38912
wandb:                  eval/macro_f1 0.89535
wandb:                  eval/micro_f1 0.89737
wandb:                   eval/runtime 1.4255
wandb:        eval/samples_per_second 533.162
wandb:          eval/steps_per_second 66.645
wandb:                    train/epoch 5.0
wandb:              train/global_step 1070
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.066
wandb:               train/total_flos 1124819959910400.0
wandb:               train/train_loss 0.2223
wandb:            train/train_runtime 127.5788
wandb: train/train_samples_per_second 268.07
wandb:   train/train_steps_per_second 8.387
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /ceph/home/wangyifei/a3/wandb/offline-run-20231115_214610-3lnxygtc
wandb: Find logs at: ./wandb/offline-run-20231115_214610-3lnxygtc/logs
